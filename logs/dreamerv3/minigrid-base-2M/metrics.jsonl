{"step": 1560, "time": 118.26569437980652, "eval_episode/length": 203.0, "eval_episode/score": 0.3656249940395355, "eval_episode/reward_rate": 0.004901960784313725}
{"step": 1560, "time": 119.4736864566803, "eval_episode/length": 245.0, "eval_episode/score": 0.234375, "eval_episode/reward_rate": 0.0040650406504065045}
{"step": 1560, "time": 120.2782154083252, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 120.2865526676178, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 120.29254364967346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 120.29827809333801, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 120.30395197868347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 120.30984258651733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 236.83486318588257, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.84375, "train/action_min": 0.0, "train/action_std": 1.857962965965271, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000976035837084055, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.9497416019439697, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.5924749970436096, "train/cont_loss_std": 0.24176405370235443, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.69921875, "train/cont_pos_loss": 0.5924749970436096, "train/cont_pred": 0.5683455467224121, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.98373794555664, "train/dyn_loss_std": 0.38667359948158264, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.960707664489746, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 43522.8203125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5011.9208984375, "train/image_loss_std": 40.318092346191406, "train/model_loss_mean": 5024.64501953125, "train/model_loss_std": 40.292137145996094, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50246452.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9420688152313232, "train/policy_entropy_max": 1.9420688152313232, "train/policy_entropy_mean": 1.6482970714569092, "train/policy_entropy_min": 0.8203387260437012, "train/policy_entropy_std": 0.13841043412685394, "train/policy_logprob_mag": 4.482292175292969, "train/policy_logprob_max": -0.21796420216560364, "train/policy_logprob_mean": -1.660919189453125, "train/policy_logprob_min": -4.482292175292969, "train/policy_logprob_std": 0.7178391218185425, "train/policy_randomness_mag": 0.9980260133743286, "train/policy_randomness_max": 0.9980260133743286, "train/policy_randomness_mean": 0.8470571041107178, "train/policy_randomness_min": 0.421570748090744, "train/policy_randomness_std": 0.07112890481948853, "train/post_ent_mag": 105.6280746459961, "train/post_ent_max": 105.6280746459961, "train/post_ent_mean": 105.30575561523438, "train/post_ent_min": 104.97470092773438, "train/post_ent_std": 0.11025351285934448, "train/prior_ent_mag": 106.37615966796875, "train/prior_ent_max": 106.37615966796875, "train/prior_ent_mean": 105.59617614746094, "train/prior_ent_min": 104.5743179321289, "train/prior_ent_std": 0.2625538110733032, "train/rep_loss_mean": 10.98373794555664, "train/rep_loss_std": 0.38667359948158264, "train/reward_avg": 0.0, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 0.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.6262052059173584, "report/cont_loss_std": 0.26599013805389404, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.6357421875, "report/cont_pos_loss": 0.6262052059173584, "report/cont_pred": 0.5526226758956909, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.987479209899902, "report/dyn_loss_std": 0.3606316149234772, "report/image_loss_mean": 5011.04541015625, "report/image_loss_std": 40.34561538696289, "report/model_loss_mean": 5023.8056640625, "report/model_loss_std": 40.34552764892578, "report/post_ent_mag": 105.63201904296875, "report/post_ent_max": 105.63201904296875, "report/post_ent_mean": 105.31080627441406, "report/post_ent_min": 104.94265747070312, "report/post_ent_std": 0.10664916783571243, "report/prior_ent_mag": 106.29181671142578, "report/prior_ent_max": 106.29181671142578, "report/prior_ent_mean": 105.56561279296875, "report/prior_ent_min": 104.46255493164062, "report/prior_ent_std": 0.2858469784259796, "report/rep_loss_mean": 10.987479209899902, "report/rep_loss_std": 0.3606316149234772, "report/reward_avg": 0.0, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6800854206085205, "eval/cont_loss_std": 0.28093352913856506, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.5625, "eval/cont_pos_loss": 0.6800854206085205, "eval/cont_pred": 0.5258567929267883, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.02673053741455, "eval/dyn_loss_std": 0.36255279183387756, "eval/image_loss_mean": 5001.208984375, "eval/image_loss_std": 39.92988586425781, "eval/model_loss_mean": 5014.0458984375, "eval/model_loss_std": 39.932586669921875, "eval/post_ent_mag": 105.6116943359375, "eval/post_ent_max": 105.6116943359375, "eval/post_ent_mean": 105.29248046875, "eval/post_ent_min": 104.92637634277344, "eval/post_ent_std": 0.10784097015857697, "eval/prior_ent_mag": 106.42914581298828, "eval/prior_ent_max": 106.42914581298828, "eval/prior_ent_mean": 105.57180786132812, "eval/prior_ent_min": 104.6823959350586, "eval/prior_ent_std": 0.2742690145969391, "eval/rep_loss_mean": 11.02673053741455, "eval/rep_loss_std": 0.36255279183387756, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.5189316099053187e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.237706865583147e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.3114437637872763e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.898121970040458e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 141.33405804634094, "timer/env.step_count": 196.0, "timer/env.step_total": 1.486063003540039, "timer/env.step_frac": 0.010514542807882762, "timer/env.step_avg": 0.007581954099694077, "timer/env.step_min": 0.006250619888305664, "timer/env.step_max": 0.020472049713134766, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.07600903511047363, "timer/replay._sample_frac": 0.0005377970190706023, "timer/replay._sample_avg": 0.0006786520992006574, "timer/replay._sample_min": 0.00033402442932128906, "timer/replay._sample_max": 0.0012078285217285156, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.0724942684173584, "timer/agent.save_frac": 0.014663799349324734, "timer/agent.save_avg": 2.0724942684173584, "timer/agent.save_min": 2.0724942684173584, "timer/agent.save_max": 2.0724942684173584, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 20.998212814331055, "timer/agent.policy_frac": 0.14857149865070818, "timer/agent.policy_avg": 0.07240763039424501, "timer/agent.policy_min": 0.009205341339111328, "timer/agent.policy_max": 15.67465877532959, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.170967102050781e-05, "timer/dataset_train_frac": 2.2435972941575604e-07, "timer/dataset_train_avg": 3.170967102050781e-05, "timer/dataset_train_min": 3.170967102050781e-05, "timer/dataset_train_max": 3.170967102050781e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 90.23474073410034, "timer/agent.train_frac": 0.6384500804789315, "timer/agent.train_avg": 90.23474073410034, "timer/agent.train_min": 90.23474073410034, "timer/agent.train_max": 90.23474073410034, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.110570669174194, "timer/agent.report_frac": 0.17059278564879785, "timer/agent.report_avg": 12.055285334587097, "timer/agent.report_min": 0.2451767921447754, "timer/agent.report_max": 23.86539387702942, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.1961669921875e-05, "timer/dataset_eval_frac": 2.968970855426546e-07, "timer/dataset_eval_avg": 4.1961669921875e-05, "timer/dataset_eval_min": 4.1961669921875e-05, "timer/dataset_eval_max": 4.1961669921875e-05}
{"step": 2312, "time": 259.65122866630554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.65899991989136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.66571378707886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.6724648475647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.67912125587463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.68542098999023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.69174575805664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 2312, "time": 259.6980879306793, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4464, "time": 325.8842875957489, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.7707107067108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.7785348892212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.78580045700073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.79244208335876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.79916071891785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.8059911727905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4624, "time": 330.81331157684326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 4928, "time": 340.17756175994873, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 6776, "time": 396.85892963409424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 401.8145205974579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 401.8220133781433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 401.82866168022156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 401.83528208732605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 401.84166741371155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 6936, "time": 401.8482975959778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 7240, "time": 411.17914748191833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9088, "time": 468.97782492637634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 473.87717628479004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 473.8846158981323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 473.89132356643677, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 473.89780282974243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 473.90419149398804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9248, "time": 473.9110436439514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 9552, "time": 483.2187111377716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 505.297176361084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.3045334815979, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.3117527961731, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.31938004493713, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.32619404792786, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.3325777053833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.3386721611023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 505.3447365760803, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11400, "time": 545.6302707195282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 550.6414093971252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 550.648767709732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 550.6552956104279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 550.6617512702942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 550.668221950531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11560, "time": 550.6746006011963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 11864, "time": 559.9547636508942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13712, "time": 617.0402381420135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 621.9667811393738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 621.9743475914001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 621.9817299842834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 621.9884965419769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 621.9951484203339, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 13872, "time": 622.0018649101257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14176, "time": 631.3302142620087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 14552, "time": 642.8340866565704, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 16024, "time": 688.1521453857422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 693.0562915802002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 693.06360912323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 693.0703783035278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 693.0771555900574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16184, "time": 693.0837070941925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16488, "time": 702.978563785553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 16864, "time": 714.6982598304749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18336, "time": 759.7989213466644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 764.6926202774048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 764.7006697654724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 764.7083892822266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 764.7162778377533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18496, "time": 764.7239513397217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 18800, "time": 774.007205247879, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 19176, "time": 785.3084716796875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 814.2066361904144, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 20072, "time": 819.1595981121063, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 819.1663751602173, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 819.1724674701691, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 819.1788432598114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 819.1848282814026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 819.1906876564026, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 819.1968486309052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20376, "time": 828.5209729671478, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 20648, "time": 836.8251101970673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 841.7166588306427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 841.7243919372559, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 841.73126912117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 20808, "time": 841.738034248352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21112, "time": 851.1198530197144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21488, "time": 862.7651858329773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 21832, "time": 873.0076882839203, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 22688, "time": 899.5229969024658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 912.8826694488525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 912.8900742530823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 912.8965685367584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23120, "time": 912.9030604362488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23424, "time": 922.209165096283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 23800, "time": 933.532318353653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 24144, "time": 944.4067280292511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25000, "time": 971.0804340839386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 984.3650197982788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 984.3728144168854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 984.3796277046204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25432, "time": 984.3864014148712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 25736, "time": 993.7460162639618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26112, "time": 1005.6269969940186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 26456, "time": 1015.935672044754, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27312, "time": 1042.59445810318, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1055.8670394420624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1055.874692440033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1055.891791343689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1055.898594379425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28048, "time": 1065.2977430820465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28424, "time": 1076.613487958908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 28768, "time": 1087.4996161460876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 29000, "time": 1094.3873796463013, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 29624, "time": 1113.5301067829132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1126.866133928299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1126.873571395874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1126.8802328109741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1129.3352971076965, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 30056, "time": 1132.647170305252, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1132.653652191162, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1132.6593194007874, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1132.6649634838104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1132.6712646484375, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1132.6766936779022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1132.6822700500488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30360, "time": 1142.0052955150604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 30680, "time": 1151.9276995658875, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 30736, "time": 1153.871517419815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31080, "time": 1164.2549557685852, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31312, "time": 1171.6505920886993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 31936, "time": 1190.963989019394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1204.2914600372314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32368, "time": 1204.2990238666534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32633, "time": 1213.2870819568634, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0015274519772874, "train/action_min": 0.0, "train/action_std": 2.0002538795323717, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00016453276326576518, "train/actor_opt_grad_steps": 975.0, "train/actor_opt_loss": -0.760833723465768, "train/adv_mag": 0.0004338211762153101, "train/adv_max": 0.0004337872275239011, "train/adv_mean": 0.00025725187437797856, "train/adv_min": 3.565742443217434e-05, "train/adv_std": 0.00011950717403514119, "train/cont_avg": 0.9968035196520618, "train/cont_loss_mean": 0.024748870662714927, "train/cont_loss_std": 0.30986352956139185, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.7640347119924185, "train/cont_pos_acc": 0.9982834510582009, "train/cont_pos_loss": 0.0063245207849044185, "train/cont_pred": 0.9945813564910102, "train/cont_rate": 0.9968035196520618, "train/dyn_loss_mean": 1.0693588938909708, "train/dyn_loss_std": 0.0049067559593729045, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.349023725338204, "train/extr_critic_critic_opt_grad_steps": 975.0, "train/extr_critic_critic_opt_loss": 6318.44720207293, "train/extr_critic_mag": 0.0021300039340540304, "train/extr_critic_max": 0.002129995945802669, "train/extr_critic_mean": 0.002122473655993929, "train/extr_critic_min": 0.0021156877586522055, "train/extr_critic_std": 2.33612978270203e-06, "train/extr_return_normed_mag": 0.0006842798127714922, "train/extr_return_normed_max": 0.0006842672288040297, "train/extr_return_normed_mean": 0.0005110776553098592, "train/extr_return_normed_min": 0.0002915125493410246, "train/extr_return_normed_std": 0.00011945607424029607, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0025529981560114758, "train/extr_return_raw_max": 0.0025529799361836483, "train/extr_return_raw_mean": 0.002379790500386359, "train/extr_return_raw_min": 0.0021602252575471026, "train/extr_return_raw_std": 0.00011945607426731856, "train/extr_reward_mag": 4.711962237800519e-05, "train/extr_reward_max": 4.7117164454509306e-05, "train/extr_reward_mean": 4.702892989706607e-05, "train/extr_reward_min": 4.680623713227891e-05, "train/extr_reward_std": 3.94478628697167e-08, "train/image_loss_mean": 27.027290899037702, "train/image_loss_std": 0.3952155167563367, "train/model_loss_mean": 27.801728132459306, "train/model_loss_std": 0.6605619304650223, "train/model_opt_grad_norm": 103.46786323112528, "train/model_opt_grad_steps": 965.0, "train/model_opt_loss": 528.48372415169, "train/model_opt_model_opt_grad_overflow": 0.005154639175257732, "train/model_opt_model_opt_grad_scale": 14.447084407216495, "train/policy_entropy_mag": 1.945812152218573, "train/policy_entropy_max": 1.945812152218573, "train/policy_entropy_mean": 1.9416009574821316, "train/policy_entropy_min": 1.8775560388860015, "train/policy_entropy_std": 0.0028168290683077937, "train/policy_logprob_mag": 2.3822119715287515, "train/policy_logprob_max": -1.505258791379093, "train/policy_logprob_mean": -1.9415877399985324, "train/policy_logprob_min": -2.3822119715287515, "train/policy_logprob_std": 0.08148423096491504, "train/policy_randomness_mag": 0.9999496995173779, "train/policy_randomness_max": 0.9999496995173779, "train/policy_randomness_mean": 0.9977855697735069, "train/policy_randomness_min": 0.9648729931447924, "train/policy_randomness_std": 0.0014475638833864276, "train/post_ent_mag": 79.69464408245284, "train/post_ent_max": 79.69464408245284, "train/post_ent_mean": 79.66392943785362, "train/post_ent_min": 79.47963396052724, "train/post_ent_std": 0.03659032518524177, "train/prior_ent_mag": 84.96953189495912, "train/prior_ent_max": 84.96953189495912, "train/prior_ent_mean": 84.86571585271777, "train/prior_ent_min": 84.54213915166167, "train/prior_ent_std": 0.061680399543922584, "train/rep_loss_mean": 1.0693588938909708, "train/rep_loss_std": 0.0049067559593729045, "train/reward_avg": 5.924185457730608e-05, "train/reward_loss_mean": 0.10807467846574319, "train/reward_loss_std": 0.037565444119968545, "train/reward_max_data": 0.05898840126303053, "train/reward_max_pred": 4.7152804345199744e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.10684496947424967, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.78590322577435, "train/reward_pred": 4.698921621479478e-05, "train/reward_rate": 0.0001258456829896907, "train_stats/mean_log_entropy": 1.928086977984224, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02002423256635666, "report/cont_loss_std": 0.31041979789733887, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.746687889099121, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0031976038590073586, "report/cont_pred": 0.996807336807251, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.29274842143058777, "report/image_loss_std": 0.10608969628810883, "report/model_loss_mean": 0.9232916235923767, "report/model_loss_std": 0.5713506937026978, "report/post_ent_mag": 63.85652160644531, "report/post_ent_max": 63.85652160644531, "report/post_ent_mean": 63.82052993774414, "report/post_ent_min": 63.75341796875, "report/post_ent_std": 0.014584623277187347, "report/prior_ent_mag": 72.76719665527344, "report/prior_ent_max": 72.76719665527344, "report/prior_ent_mean": 72.70492553710938, "report/prior_ent_min": 72.38761901855469, "report/prior_ent_std": 0.05183040350675583, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0008636474376544356, "report/reward_loss_mean": 0.010518909431993961, "report/reward_loss_std": 0.31654027104377747, "report/reward_max_data": 0.8843749761581421, "report/reward_max_pred": 7.033348083496094e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0006221872172318399, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.134860038757324, "report/reward_pred": 7.003720384091139e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0031979475170373917, "eval/cont_loss_std": 6.031800239725271e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0031979475170373917, "eval/cont_pred": 0.9968070387840271, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.307170033454895, "eval/image_loss_std": 0.10267280042171478, "eval/model_loss_mean": 0.9109902381896973, "eval/model_loss_std": 0.10267316550016403, "eval/post_ent_mag": 63.85579299926758, "eval/post_ent_max": 63.85579299926758, "eval/post_ent_mean": 63.82136917114258, "eval/post_ent_min": 63.75761413574219, "eval/post_ent_std": 0.013401823118329048, "eval/prior_ent_mag": 72.79545593261719, "eval/prior_ent_max": 72.79545593261719, "eval/prior_ent_mean": 72.706787109375, "eval/prior_ent_min": 72.38761901855469, "eval/prior_ent_std": 0.048142511397600174, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0006221933290362358, "eval/reward_loss_std": 1.328108623965818e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.033348083496094e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0006221933290362358, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.003732025623322e-05, "eval/reward_rate": 0.0, "replay/size": 32129.0, "replay/inserts": 31072.0, "replay/samples": 31072.0, "replay/insert_wait_avg": 1.3581387905824074e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.182133999715505e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2503913254611356e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.4361765384674, "timer/env.step_count": 3884.0, "timer/env.step_total": 38.72858238220215, "timer/env.step_frac": 0.03966319900139055, "timer/env.step_avg": 0.009971313692637011, "timer/env.step_min": 0.008369207382202148, "timer/env.step_max": 0.03619790077209473, "timer/replay._sample_count": 31072.0, "timer/replay._sample_total": 16.38738226890564, "timer/replay._sample_frac": 0.016782850392741515, "timer/replay._sample_avg": 0.000527400304740784, "timer/replay._sample_min": 0.00033974647521972656, "timer/replay._sample_max": 0.013523101806640625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4751.0, "timer/agent.policy_total": 51.60077476501465, "timer/agent.policy_frac": 0.05284602926936085, "timer/agent.policy_avg": 0.010861034469588434, "timer/agent.policy_min": 0.009165763854980469, "timer/agent.policy_max": 0.0871281623840332, "timer/dataset_train_count": 1942.0, "timer/dataset_train_total": 0.20671296119689941, "timer/dataset_train_frac": 0.00021170145695513956, "timer/dataset_train_avg": 0.00010644333738254346, "timer/dataset_train_min": 8.225440979003906e-05, "timer/dataset_train_max": 0.0003666877746582031, "timer/agent.train_count": 1942.0, "timer/agent.train_total": 871.4491028785706, "timer/agent.train_frac": 0.8924793282116162, "timer/agent.train_avg": 0.4487379520486975, "timer/agent.train_min": 0.43597412109375, "timer/agent.train_max": 0.7079513072967529, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4794590473175049, "timer/agent.report_frac": 0.000491029581694955, "timer/agent.report_avg": 0.23972952365875244, "timer/agent.report_min": 0.2325749397277832, "timer/agent.report_max": 0.24688410758972168, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.36957649732465e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 31.82136799625345}
{"step": 32672, "time": 1214.5488066673279, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 32992, "time": 1224.9591135978699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33048, "time": 1226.4697785377502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33392, "time": 1237.3651666641235, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 33624, "time": 1244.2033665180206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34248, "time": 1263.2486779689789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1276.5928757190704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34680, "time": 1276.600430727005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 34984, "time": 1285.9010615348816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35304, "time": 1295.7235643863678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35360, "time": 1297.802043914795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35704, "time": 1308.1393222808838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 35936, "time": 1315.4239089488983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36560, "time": 1334.5221071243286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1347.7273962497711, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 36992, "time": 1347.7347784042358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37296, "time": 1357.0780987739563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37616, "time": 1366.813010931015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 37672, "time": 1368.2935135364532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38016, "time": 1378.9763321876526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38248, "time": 1385.9015276432037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 38872, "time": 1405.035251379013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1418.2410039901733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39304, "time": 1418.2483088970184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39608, "time": 1427.8740746974945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39928, "time": 1437.6453518867493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 39984, "time": 1439.5999834537506, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 1442.847196340561, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 40040, "time": 1446.585224866867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1446.5929493904114, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1446.5987966060638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1446.6046786308289, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1446.610296010971, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1446.6166443824768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1446.6223800182343, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40328, "time": 1455.397653579712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 40560, "time": 1462.70103931427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41184, "time": 1482.3005318641663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1495.481043100357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41616, "time": 1495.5051591396332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 41920, "time": 1504.7900483608246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42240, "time": 1514.694137096405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42296, "time": 1516.1876289844513, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42640, "time": 1526.9479279518127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 42872, "time": 1533.8290457725525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43496, "time": 1553.0121576786041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1566.2634680271149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 43928, "time": 1566.270848274231, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44232, "time": 1575.5311789512634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44552, "time": 1585.2341613769531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44608, "time": 1587.1661944389343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 44952, "time": 1597.449527978897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45184, "time": 1604.697298526764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 45808, "time": 1623.7604825496674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1637.141417503357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46240, "time": 1637.1489877700806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46544, "time": 1646.4840309619904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46864, "time": 1656.3218250274658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 46920, "time": 1657.809146642685, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47264, "time": 1668.532649755478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 47496, "time": 1675.397251367569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48120, "time": 1694.5366368293762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1707.6800560951233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48552, "time": 1707.6872689723969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 48856, "time": 1717.092523097992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49176, "time": 1727.3064999580383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49232, "time": 1729.2557845115662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49576, "time": 1739.5376653671265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 49808, "time": 1746.894479751587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 1759.001395225525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.008113861084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.0137186050415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.0193901062012, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.024929523468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.0304412841797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.0361580848694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1759.0424284934998, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50128, "time": 1762.4168226718903, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 50432, "time": 1771.8081007003784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1785.1735627651215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 50864, "time": 1785.1815340518951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51168, "time": 1794.4096224308014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51488, "time": 1804.17946767807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 51544, "time": 1805.657823085785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52120, "time": 1823.3526828289032, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52440, "time": 1833.1023652553558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 52744, "time": 1842.4944891929626, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1855.6813373565674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 1855.6884546279907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53480, "time": 1864.944991827011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53800, "time": 1874.7627415657043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 53856, "time": 1876.676343202591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54400, "time": 1893.1521167755127, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 54432, "time": 1894.1325778961182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54752, "time": 1903.970985174179, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 54832, "time": 1906.4107990264893, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 55056, "time": 1913.1904592514038, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1926.5094714164734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 55488, "time": 1926.5169956684113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56112, "time": 1945.6282193660736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56168, "time": 1947.11554646492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 56744, "time": 1964.7717683315277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57064, "time": 1974.4935231208801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57144, "time": 1976.9544577598572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57368, "time": 1984.2709050178528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 1997.5351853370667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 57800, "time": 1997.5424642562866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58424, "time": 2016.740963459015, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 58480, "time": 2018.6735122203827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59056, "time": 2036.2504510879517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59376, "time": 2046.0847628116608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59456, "time": 2048.50634932518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 59680, "time": 2055.3575212955475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2071.7034010887146, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.7100269794464, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.715907096863, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.721611738205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.727156639099, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.732800245285, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.7384402751923, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2071.744461297989, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2075.1476349830627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60112, "time": 2075.155092716217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60736, "time": 2094.3417909145355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 60792, "time": 2095.843645811081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61248, "time": 2110.1321823596954, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 61368, "time": 2113.5819566249847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61688, "time": 2123.3605971336365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61768, "time": 2125.855278491974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 61992, "time": 2132.6943278312683, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 62424, "time": 2145.9447791576385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63048, "time": 2164.886831998825, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63104, "time": 2166.8962593078613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63560, "time": 2180.5827000141144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 63680, "time": 2184.4845776557922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64000, "time": 2194.2967867851257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64080, "time": 2196.841685771942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64304, "time": 2203.688175678253, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 64601, "time": 2213.4593057632446, "train_stats/mean_log_entropy": 1.9376429737659924, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.00148681640625, "train/action_min": 0.0, "train/action_std": 1.9993317866325377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012340216313532436, "train/actor_opt_grad_steps": 2945.0, "train/actor_opt_loss": -0.7833443993423134, "train/adv_mag": 0.00045992631232365965, "train/adv_max": 0.00045992631232365965, "train/adv_mean": 0.00025721326986968054, "train/adv_min": 1.3197597581893206e-05, "train/adv_std": 0.00012023546696582343, "train/cont_avg": 0.9964453125, "train/cont_loss_mean": 0.023662554344628006, "train/cont_loss_std": 0.32356815690518714, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6832794897335095, "train/cont_pos_acc": 0.9999999839067459, "train/cont_pos_loss": 0.003483243783703074, "train/cont_pred": 0.9965230587124825, "train/cont_rate": 0.9964453125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08173159310594201, "train/extr_critic_critic_opt_grad_steps": 2945.0, "train/extr_critic_critic_opt_loss": 5140.525600585937, "train/extr_critic_mag": 0.011759638786315918, "train/extr_critic_max": 0.011759638786315918, "train/extr_critic_mean": 0.011721717114560305, "train/extr_critic_min": 0.011686293482780457, "train/extr_critic_std": 1.3312335461250769e-05, "train/extr_return_normed_mag": 0.0008942716056481003, "train/extr_return_normed_max": 0.0008942716056481003, "train/extr_return_normed_mean": 0.0007134448806755245, "train/extr_return_normed_min": 0.0004811289976350963, "train/extr_return_normed_std": 0.00011962109616433736, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.012160313804633916, "train/extr_return_raw_max": 0.012160313804633916, "train/extr_return_raw_mean": 0.01197948768734932, "train/extr_return_raw_min": 0.011747171196620911, "train/extr_return_raw_std": 0.00011962109718297143, "train/extr_reward_mag": 7.592558860778808e-05, "train/extr_reward_max": 7.592558860778808e-05, "train/extr_reward_mean": 7.583683202028624e-05, "train/extr_reward_min": 7.574498653411865e-05, "train/extr_reward_std": 2.983786137999989e-08, "train/image_loss_mean": 0.2703822000324726, "train/image_loss_std": 0.08668140459805727, "train/model_loss_mean": 0.8962131255865097, "train/model_loss_std": 0.37713292680680754, "train/model_opt_grad_norm": 80.57021881103516, "train/model_opt_grad_steps": 2935.0, "train/model_opt_loss": 50.57538372039795, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.54296875, "train/policy_entropy_mag": 1.945890576839447, "train/policy_entropy_max": 1.945890576839447, "train/policy_entropy_mean": 1.944937802553177, "train/policy_entropy_min": 1.9287024384737015, "train/policy_entropy_std": 0.0006737353577045724, "train/policy_logprob_mag": 2.200079445838928, "train/policy_logprob_max": -1.7132121926546098, "train/policy_logprob_mean": -1.9449286901950835, "train/policy_logprob_min": -2.200079445838928, "train/policy_logprob_std": 0.043689705058932306, "train/policy_randomness_mag": 0.9999900022149086, "train/policy_randomness_max": 0.9999900022149086, "train/policy_randomness_mean": 0.9995003753900528, "train/policy_randomness_min": 0.9911570462584496, "train/policy_randomness_std": 0.00034623151404957755, "train/post_ent_mag": 53.33133020401001, "train/post_ent_max": 53.33133020401001, "train/post_ent_mean": 53.25976043701172, "train/post_ent_min": 53.193959941864016, "train/post_ent_std": 0.01871282670646906, "train/prior_ent_mag": 58.45705135345459, "train/prior_ent_max": 58.45705135345459, "train/prior_ent_mean": 58.342515029907226, "train/prior_ent_min": 58.2116051864624, "train/prior_ent_std": 0.033251827037893235, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00010148620465770364, "train/reward_loss_mean": 0.0021683531417511404, "train/reward_loss_std": 0.05390546568052877, "train/reward_max_data": 0.0971718743443489, "train/reward_max_pred": 7.594764232635498e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0003684658803831553, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.958586895104611, "train/reward_pred": 7.580022909678519e-05, "train/reward_rate": 0.0001806640625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02007201686501503, "report/cont_loss_std": 0.30464911460876465, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.640276908874512, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003558193799108267, "report/cont_pred": 0.996448278427124, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.27328670024871826, "report/image_loss_std": 0.0927671492099762, "report/model_loss_mean": 0.9033908843994141, "report/model_loss_std": 0.5682769417762756, "report/post_ent_mag": 45.327919006347656, "report/post_ent_max": 45.327919006347656, "report/post_ent_mean": 45.30073547363281, "report/post_ent_min": 45.22126770019531, "report/post_ent_std": 0.018744543194770813, "report/prior_ent_mag": 47.32246398925781, "report/prior_ent_max": 47.32246398925781, "report/prior_ent_mean": 47.117156982421875, "report/prior_ent_min": 47.07426452636719, "report/prior_ent_std": 0.03603331372141838, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005462646367959678, "report/reward_loss_mean": 0.010032125748693943, "report/reward_loss_std": 0.3125632107257843, "report/reward_max_data": 0.559374988079071, "report/reward_max_pred": 7.736682891845703e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00025975785683840513, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 10.00716781616211, "report/reward_pred": 7.734086830168962e-05, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003558180294930935, "eval/cont_loss_std": 6.113853032729821e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003558180294930935, "eval/cont_pred": 0.996448278427124, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.27122625708580017, "eval/image_loss_std": 0.0913124606013298, "eval/model_loss_mean": 0.8750442266464233, "eval/model_loss_std": 0.09131249040365219, "eval/post_ent_mag": 45.33005905151367, "eval/post_ent_max": 45.33005905151367, "eval/post_ent_mean": 45.301273345947266, "eval/post_ent_min": 45.21820831298828, "eval/post_ent_std": 0.017598439007997513, "eval/prior_ent_mag": 47.32246398925781, "eval/prior_ent_max": 47.32246398925781, "eval/prior_ent_mean": 47.11503601074219, "eval/prior_ent_min": 47.077842712402344, "eval/prior_ent_std": 0.033380087465047836, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0002597593702375889, "eval/reward_loss_std": 3.9070479829206306e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 7.736682891845703e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0002597593702375889, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.734133396297693e-05, "eval/reward_rate": 0.0, "replay/size": 64097.0, "replay/inserts": 31968.0, "replay/samples": 31968.0, "replay/insert_wait_avg": 1.3629640186871136e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.298634170173287e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2204858808506456e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1602139472961, "timer/env.step_count": 3996.0, "timer/env.step_total": 39.68445563316345, "timer/env.step_frac": 0.03967809864835779, "timer/env.step_avg": 0.009931044953244107, "timer/env.step_min": 0.008205652236938477, "timer/env.step_max": 0.03564763069152832, "timer/replay._sample_count": 31968.0, "timer/replay._sample_total": 16.90984344482422, "timer/replay._sample_frac": 0.016907134686038702, "timer/replay._sample_avg": 0.0005289615692199768, "timer/replay._sample_min": 0.0003631114959716797, "timer/replay._sample_max": 0.028343915939331055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4863.0, "timer/agent.policy_total": 51.822025775909424, "timer/agent.policy_frac": 0.05181372449458403, "timer/agent.policy_avg": 0.01065639024797644, "timer/agent.policy_min": 0.00903177261352539, "timer/agent.policy_max": 0.09391069412231445, "timer/dataset_train_count": 1998.0, "timer/dataset_train_total": 0.2069995403289795, "timer/dataset_train_frac": 0.0002069663814280533, "timer/dataset_train_avg": 0.00010360337353802777, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0003464221954345703, "timer/agent.train_count": 1998.0, "timer/agent.train_total": 893.9415030479431, "timer/agent.train_frac": 0.8937983040935576, "timer/agent.train_avg": 0.4474181696936652, "timer/agent.train_min": 0.4349386692047119, "timer/agent.train_max": 0.8417007923126221, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4739112854003906, "timer/agent.report_frac": 0.00047383537036533587, "timer/agent.report_avg": 0.2369556427001953, "timer/agent.report_min": 0.23127532005310059, "timer/agent.report_max": 0.24263596534729004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0035928792084387e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.962370252553498}
{"step": 64736, "time": 2217.588300228119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65360, "time": 2236.555562019348, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65416, "time": 2238.0423533916473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 65688, "time": 2246.697812795639, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 65872, "time": 2252.4785833358765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66312, "time": 2265.6627349853516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66392, "time": 2268.0913932323456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 66616, "time": 2274.8869004249573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67048, "time": 2288.118964910507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67672, "time": 2307.00395321846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 67728, "time": 2308.9227681159973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68000, "time": 2317.215034008026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68184, "time": 2322.5570044517517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68624, "time": 2336.0722708702087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68704, "time": 2338.490822315216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 68928, "time": 2345.2775807380676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69360, "time": 2358.38458275795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 69984, "time": 2377.44007730484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70040, "time": 2378.931739807129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 2384.4353172779083, "eval_episode/length": 199.0, "eval_episode/score": 0.37812501192092896, "eval_episode/reward_rate": 0.005}
{"step": 70096, "time": 2386.0093743801117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2386.0154650211334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2386.0208723545074, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2386.0262808799744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2386.031617164612, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2386.036847114563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2386.0421600341797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70312, "time": 2392.30198597908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70496, "time": 2398.094673871994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 70936, "time": 2411.338196992874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71016, "time": 2413.796106815338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71240, "time": 2420.582362174988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 71672, "time": 2433.6416687965393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72296, "time": 2452.6240990161896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72352, "time": 2454.544303894043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72624, "time": 2462.82972407341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 72808, "time": 2468.2780344486237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73248, "time": 2481.830311536789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73328, "time": 2484.2477192878723, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73552, "time": 2491.160244703293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 73984, "time": 2504.855133295059, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74608, "time": 2523.8999004364014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74664, "time": 2525.3787548542023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 74936, "time": 2533.786416530609, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75120, "time": 2539.5961413383484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75560, "time": 2552.787296295166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75640, "time": 2555.250136613846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 75864, "time": 2562.1733589172363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76296, "time": 2575.3151376247406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76920, "time": 2594.5096917152405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 76976, "time": 2596.4513609409332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77248, "time": 2604.7656037807465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77400, "time": 2609.2040655612946, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 77432, "time": 2610.182636499405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77872, "time": 2623.9435007572174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 77952, "time": 2626.3775215148926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78176, "time": 2633.2275195121765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 78608, "time": 2646.464861392975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79232, "time": 2665.468351840973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79560, "time": 2675.2495980262756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79712, "time": 2680.1880688667297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 79744, "time": 2681.1642632484436, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 2697.014443874359, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.0209743976593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.026871919632, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.0325887203217, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.0382006168365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.0439381599426, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.049513578415, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2697.055260181427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80184, "time": 2699.99760556221, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80264, "time": 2702.4498085975647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80488, "time": 2709.3780646324158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 80920, "time": 2722.5475652217865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81544, "time": 2741.7070124149323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 81872, "time": 2751.9749913215637, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82024, "time": 2756.844972372055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82056, "time": 2757.844703912735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82496, "time": 2771.5280861854553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82576, "time": 2773.9817147254944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 82800, "time": 2780.788379430771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83232, "time": 2793.8805615901947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 83856, "time": 2812.980570077896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84184, "time": 2822.752980709076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84336, "time": 2827.696924686432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84368, "time": 2828.675408601761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84808, "time": 2841.7873270511627, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 84888, "time": 2844.2309761047363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85112, "time": 2851.0786142349243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 85544, "time": 2864.254259824753, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86168, "time": 2883.1556136608124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86496, "time": 2893.464855194092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86648, "time": 2897.898745775223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 86680, "time": 2898.907564163208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87120, "time": 2912.5841846466064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87200, "time": 2915.0208945274353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87424, "time": 2921.933463573456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 87856, "time": 2935.615902900696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88480, "time": 2954.7380652427673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88808, "time": 2964.5511054992676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88960, "time": 2969.4072704315186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 88992, "time": 2970.3823351860046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89432, "time": 2983.6477556228638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89512, "time": 2986.079493522644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 89736, "time": 2992.968687057495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 3005.033315181732, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 90064, "time": 3009.377454996109, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3009.384055376053, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3009.3899784088135, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3009.3956096172333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3009.401525259018, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3009.407324075699, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3009.413309574127, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3012.794070005417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 90792, "time": 3031.752264738083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91120, "time": 3042.0269780158997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91272, "time": 3046.447500228882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91304, "time": 3047.4284076690674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91744, "time": 3061.051483154297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 91824, "time": 3063.489086866379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92048, "time": 3070.357899427414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 92480, "time": 3083.6215164661407, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93104, "time": 3102.7832736968994, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93432, "time": 3112.5312633514404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93584, "time": 3117.3920114040375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 93616, "time": 3118.3729286193848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94056, "time": 3131.597006559372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94136, "time": 3134.0268037319183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94360, "time": 3140.850593805313, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 94792, "time": 3153.9983897209167, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95416, "time": 3173.0852978229523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95744, "time": 3183.339365720749, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95896, "time": 3187.8646733760834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 95928, "time": 3188.8398127555847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96368, "time": 3202.5546078681946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96448, "time": 3205.022947072983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96672, "time": 3211.8651161193848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 96713, "time": 3213.856645822525, "train_stats/mean_log_entropy": 1.9383806264505976, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000538635253906, "train/action_min": 0.0, "train/action_std": 2.00020526945591, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.330588354558131e-05, "train/actor_opt_grad_steps": 4945.0, "train/actor_opt_loss": -3.4612543209642173, "train/adv_mag": 0.00027717992663383483, "train/adv_max": 0.00025928494520485404, "train/adv_mean": 0.00011699329740736175, "train/adv_min": -4.57555428147316e-05, "train/adv_std": 6.734056863933801e-05, "train/cont_avg": 0.99658203125, "train/cont_loss_mean": 0.02286926720291376, "train/cont_loss_std": 0.31998134762900177, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.67927653205638, "train/cont_pos_acc": 0.9999999848008155, "train/cont_pos_loss": 0.0034653901029378176, "train/cont_pred": 0.9965407598018646, "train/cont_rate": 0.99658203125, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021966448603197932, "train/extr_critic_critic_opt_grad_steps": 4945.0, "train/extr_critic_critic_opt_loss": 7212.700063476563, "train/extr_critic_mag": 0.019353922009468078, "train/extr_critic_max": 0.019353922009468078, "train/extr_critic_mean": 0.019291660664603114, "train/extr_critic_min": 0.019233983755111695, "train/extr_critic_std": 2.4828594141581562e-05, "train/extr_return_normed_mag": 0.00047255557030439376, "train/extr_return_normed_max": 0.0004544043634086847, "train/extr_return_normed_mean": 0.00034545886821149454, "train/extr_return_normed_min": 0.00021241089329123496, "train/extr_return_normed_std": 6.451503374137246e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.019516903329640626, "train/extr_return_raw_max": 0.019516903329640626, "train/extr_return_raw_mean": 0.019407958863303064, "train/extr_return_raw_min": 0.019274909859523178, "train/extr_return_raw_std": 6.451503382322699e-05, "train/extr_reward_mag": 7.647216320037842e-05, "train/extr_reward_max": 7.647216320037842e-05, "train/extr_reward_mean": 7.641787235115771e-05, "train/extr_reward_min": 7.63237476348877e-05, "train/extr_reward_std": 2.3906111951688124e-08, "train/image_loss_mean": 0.2609149865806103, "train/image_loss_std": 0.08483450090512633, "train/model_loss_mean": 0.8859067419171334, "train/model_loss_std": 0.3780190306529403, "train/model_opt_grad_norm": 66.31439399719238, "train/model_opt_grad_steps": 4935.0, "train/model_opt_loss": 200.30081550598143, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 226.171875, "train/policy_entropy_mag": 1.9458988338708878, "train/policy_entropy_max": 1.9458988338708878, "train/policy_entropy_mean": 1.9453348165750504, "train/policy_entropy_min": 1.9345795786380768, "train/policy_entropy_std": 0.0004218249594850931, "train/policy_logprob_mag": 2.1493165481090544, "train/policy_logprob_max": -1.7565565615892411, "train/policy_logprob_mean": -1.9453246188163758, "train/policy_logprob_min": -2.1493165481090544, "train/policy_logprob_std": 0.03386885903775692, "train/policy_randomness_mag": 0.9999942421913147, "train/policy_randomness_max": 0.9999942421913147, "train/policy_randomness_mean": 0.9997044017910958, "train/policy_randomness_min": 0.9941772988438606, "train/policy_randomness_std": 0.00021677515338524244, "train/post_ent_mag": 39.823565826416015, "train/post_ent_max": 39.823565826416015, "train/post_ent_mean": 39.78322437286377, "train/post_ent_min": 39.7115979385376, "train/post_ent_std": 0.017504972694441675, "train/prior_ent_mag": 46.97848243713379, "train/prior_ent_max": 46.97848243713379, "train/prior_ent_mean": 46.84303798675537, "train/prior_ent_min": 46.782560958862305, "train/prior_ent_std": 0.027617003018967808, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00011369323648978024, "train/reward_loss_mean": 0.002122465514112264, "train/reward_loss_std": 0.05834623734290327, "train/reward_max_data": 0.10981249898672103, "train/reward_max_pred": 7.650792598724365e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00021020230611611622, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.024264388614231, "train/reward_pred": 7.64114037156105e-05, "train/reward_rate": 0.0001904296875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014525017701089382, "report/cont_loss_std": 0.25007396936416626, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.667524814605713, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034623967949301004, "report/cont_pred": 0.9965437054634094, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2544668912887573, "report/image_loss_std": 0.09091587364673615, "report/model_loss_mean": 0.8691125512123108, "report/model_loss_std": 0.26953887939453125, "report/post_ent_mag": 36.8350830078125, "report/post_ent_max": 36.8350830078125, "report/post_ent_mean": 36.79669189453125, "report/post_ent_min": 36.73051071166992, "report/post_ent_std": 0.015895027667284012, "report/prior_ent_mag": 45.20209884643555, "report/prior_ent_max": 45.20209884643555, "report/prior_ent_mean": 45.16413879394531, "report/prior_ent_min": 44.981449127197266, "report/prior_ent_std": 0.032883480191230774, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00012063980102539062, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 4.3511390686035156e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00012063980102539062, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 4.3511390686035156e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0034623967949301004, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034623967949301004, "eval/cont_pred": 0.9965437054634094, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.266165554523468, "eval/image_loss_std": 0.08543700724840164, "eval/model_loss_mean": 0.869748592376709, "eval/model_loss_std": 0.08543702214956284, "eval/post_ent_mag": 36.8348388671875, "eval/post_ent_max": 36.8348388671875, "eval/post_ent_mean": 36.797218322753906, "eval/post_ent_min": 36.728450775146484, "eval/post_ent_std": 0.015044390223920345, "eval/prior_ent_mag": 45.20489501953125, "eval/prior_ent_max": 45.20489501953125, "eval/prior_ent_mean": 45.1640625, "eval/prior_ent_min": 45.00205612182617, "eval/prior_ent_std": 0.03103720396757126, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00012063980102539062, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 4.3511390686035156e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00012063980102539062, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.3511390686035156e-05, "eval/reward_rate": 0.0, "replay/size": 96209.0, "replay/inserts": 32112.0, "replay/samples": 32112.0, "replay/insert_wait_avg": 1.348432582233697e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.241819634506461e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1647311323929273e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3817694187164, "timer/env.step_count": 4014.0, "timer/env.step_total": 38.889976024627686, "timer/env.step_frac": 0.03887513468705569, "timer/env.step_avg": 0.00968858396228891, "timer/env.step_min": 0.007890939712524414, "timer/env.step_max": 0.06433725357055664, "timer/replay._sample_count": 32112.0, "timer/replay._sample_total": 17.019638061523438, "timer/replay._sample_frac": 0.0170131429638236, "timer/replay._sample_avg": 0.0005300086591157024, "timer/replay._sample_min": 0.0003771781921386719, "timer/replay._sample_max": 0.0312192440032959, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4881.0, "timer/agent.policy_total": 51.602527379989624, "timer/agent.policy_frac": 0.05158283463119673, "timer/agent.policy_avg": 0.010572121979100518, "timer/agent.policy_min": 0.008748292922973633, "timer/agent.policy_max": 0.08606076240539551, "timer/dataset_train_count": 2007.0, "timer/dataset_train_total": 0.21248221397399902, "timer/dataset_train_frac": 0.0002124011257196983, "timer/dataset_train_avg": 0.00010587056002690534, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0010864734649658203, "timer/agent.train_count": 2007.0, "timer/agent.train_total": 896.0835220813751, "timer/agent.train_frac": 0.8957415553484696, "timer/agent.train_avg": 0.44647908424582716, "timer/agent.train_min": 0.4343595504760742, "timer/agent.train_max": 0.9739236831665039, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795372486114502, "timer/agent.report_frac": 0.00047935424581966435, "timer/agent.report_avg": 0.2397686243057251, "timer/agent.report_min": 0.23262691497802734, "timer/agent.report_max": 0.24691033363342285, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3365863008093177e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 32.09920881842809}
{"step": 97104, "time": 3225.934648990631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 97728, "time": 3245.0779654979706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98056, "time": 3254.992744207382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98208, "time": 3259.873190879822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98240, "time": 3260.8599450588226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98680, "time": 3274.5769023895264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98760, "time": 3277.110768556595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 98984, "time": 3283.935245037079, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 99416, "time": 3297.10009765625, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100040, "time": 3316.1710419654846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 3322.010484933853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.0170311927795, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.0226793289185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.0282757282257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.033994436264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.039478778839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.04514503479, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3322.0509026050568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100264, "time": 3328.4012846946716, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 100520, "time": 3336.3065576553345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100552, "time": 3337.289365053177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 100992, "time": 3350.922466278076, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101072, "time": 3353.374648809433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101296, "time": 3360.1986107826233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 101728, "time": 3373.609426021576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102352, "time": 3392.6081500053406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102576, "time": 3399.543622493744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102832, "time": 3407.377126932144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 102864, "time": 3408.3515751361847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103304, "time": 3421.5725190639496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103384, "time": 3424.0278549194336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 103608, "time": 3430.932116508484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104040, "time": 3444.1545915603638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104664, "time": 3463.2954576015472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 104888, "time": 3470.1103360652924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105144, "time": 3477.9566493034363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105176, "time": 3478.9500403404236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105616, "time": 3492.7821142673492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105696, "time": 3495.247225999832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 105920, "time": 3502.1206867694855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106352, "time": 3515.3277821540833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 106976, "time": 3534.9537901878357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107200, "time": 3541.812353372574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107456, "time": 3549.691483974457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107480, "time": 3550.224561214447, "episode/length": 222.0, "episode/score": 0.3062500059604645, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.0}
{"step": 107488, "time": 3550.6939215660095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 107928, "time": 3563.907089471817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108232, "time": 3573.2143545150757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108544, "time": 3583.03236579895, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 108664, "time": 3586.4879760742188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 108992, "time": 3596.7126586437225, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 109288, "time": 3605.513717651367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109512, "time": 3612.4079570770264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109768, "time": 3620.251743078232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 109792, "time": 3621.2125811576843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 3632.8207511901855, "eval_episode/length": 238.0, "eval_episode/score": 0.2562499940395355, "eval_episode/reward_rate": 0.0041841004184100415}
{"step": 110032, "time": 3633.717849969864, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3633.72438287735, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3633.730137348175, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3633.735841035843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3633.7415204048157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3633.7472021579742, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3633.7533457279205, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110240, "time": 3640.134333372116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110544, "time": 3649.3999359607697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 110976, "time": 3662.586123228073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111304, "time": 3672.434279203415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111600, "time": 3681.6557142734528, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 111824, "time": 3688.4800605773926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112080, "time": 3696.3998963832855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112104, "time": 3696.9146378040314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112552, "time": 3710.6298236846924, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 3719.894137620926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113288, "time": 3733.1897871494293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113616, "time": 3743.440870285034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 113912, "time": 3752.2591993808746, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114136, "time": 3759.141593694687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114392, "time": 3766.9119234085083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114416, "time": 3767.870101213455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 114864, "time": 3782.013008117676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115168, "time": 3791.3730988502502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115600, "time": 3804.573697566986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 115928, "time": 3814.372653245926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116224, "time": 3823.736263036728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116448, "time": 3830.624029636383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116704, "time": 3838.477279663086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 116728, "time": 3839.009972333908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117176, "time": 3852.852928876877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117480, "time": 3862.1777288913727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 117912, "time": 3875.3837168216705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118240, "time": 3885.743537425995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118536, "time": 3894.677323102951, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 118760, "time": 3901.553398370743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119016, "time": 3909.49302816391, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119040, "time": 3910.4514639377594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119488, "time": 3924.0965666770935, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 119792, "time": 3933.387063026428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 3945.6109352111816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.6177475452423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.623651742935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.6293942928314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.635546684265, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.641219139099, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.6470057964325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 3945.6527132987976, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120224, "time": 3951.9949498176575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120552, "time": 3961.780430793762, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 120848, "time": 3971.127404689789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121072, "time": 3978.0333614349365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121328, "time": 3985.8492584228516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121352, "time": 3986.367526292801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 121800, "time": 4000.16850733757, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122104, "time": 4009.4636821746826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122536, "time": 4022.6867752075195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 122864, "time": 4033.0696675777435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123160, "time": 4042.3520057201385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123384, "time": 4049.1644105911255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123640, "time": 4057.0453684329987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 123664, "time": 4058.003961801529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124112, "time": 4071.6507651805878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124416, "time": 4080.894439458847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 124848, "time": 4094.1431770324707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125176, "time": 4103.92817401886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125472, "time": 4113.245094299316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125696, "time": 4120.151656866074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125952, "time": 4128.025190353394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 125976, "time": 4128.535546302795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126424, "time": 4142.175745725632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 126728, "time": 4151.549288034439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127160, "time": 4164.709530115128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127488, "time": 4175.014327287674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 127784, "time": 4183.9262573719025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128008, "time": 4190.774537086487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128264, "time": 4198.602454900742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128288, "time": 4199.595177650452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 128729, "time": 4213.918701410294, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9994085693359374, "train/action_min": 0.0, "train/action_std": 2.0007601577043532, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.632391034874672e-05, "train/actor_opt_grad_steps": 6945.0, "train/actor_opt_loss": -5.896518498137593, "train/adv_mag": 0.00018150441348552704, "train/adv_max": 0.00010362157598137856, "train/adv_mean": -1.0493735613863464e-05, "train/adv_min": -0.00012190423905849456, "train/adv_std": 4.2285165605875366e-05, "train/cont_avg": 0.996708984375, "train/cont_loss_mean": 0.022132299590157344, "train/cont_loss_std": 0.31248423611555837, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.670738300498651, "train/cont_pos_acc": 0.9999999856948852, "train/cont_pos_loss": 0.0034957675216719507, "train/cont_pred": 0.9965104848146439, "train/cont_rate": 0.996708984375, "train/dyn_loss_mean": 1.0104357141256333, "train/dyn_loss_std": 0.00020390375051647423, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.010360920852981508, "train/extr_critic_critic_opt_grad_steps": 6945.0, "train/extr_critic_critic_opt_loss": 7530.817141113282, "train/extr_critic_mag": 0.020684940814971922, "train/extr_critic_max": 0.020684940814971922, "train/extr_critic_mean": 0.020620349822565914, "train/extr_critic_min": 0.020557438731193544, "train/extr_critic_std": 2.6553339425277044e-05, "train/extr_return_normed_mag": 0.00021736109629273416, "train/extr_return_normed_max": 0.00011060426011681557, "train/extr_return_normed_mean": 3.140243481993821e-05, "train/extr_return_normed_min": -4.357405938208103e-05, "train/extr_return_normed_std": 3.772947553159156e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020689468048512936, "train/extr_return_raw_max": 0.020689468048512936, "train/extr_return_raw_mean": 0.02061026726849377, "train/extr_return_raw_min": 0.02053528972901404, "train/extr_return_raw_std": 3.77294755755031e-05, "train/extr_reward_mag": 6.031036376953125e-05, "train/extr_reward_max": 6.031036376953125e-05, "train/extr_reward_mean": 6.0258797948336e-05, "train/extr_reward_min": 6.020843982696533e-05, "train/extr_reward_std": 1.949439414783427e-08, "train/image_loss_mean": 0.25477384045720103, "train/image_loss_std": 0.0851639137417078, "train/model_loss_mean": 0.8845076423883438, "train/model_loss_std": 0.3534742957726121, "train/model_opt_grad_norm": 54.64388952255249, "train/model_opt_grad_steps": 6935.0, "train/model_opt_loss": 801.9870390319825, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 904.6875, "train/policy_entropy_mag": 1.9458948612213134, "train/policy_entropy_max": 1.9458948612213134, "train/policy_entropy_mean": 1.9452436500787735, "train/policy_entropy_min": 1.9346109902858735, "train/policy_entropy_std": 0.0004547414160333574, "train/policy_logprob_mag": 2.1390978038311004, "train/policy_logprob_max": -1.7509049201011657, "train/policy_logprob_mean": -1.945242727994919, "train/policy_logprob_min": -2.1390978038311004, "train/policy_logprob_std": 0.035473729325458406, "train/policy_randomness_mag": 0.9999922037124633, "train/policy_randomness_max": 0.9999922037124633, "train/policy_randomness_mean": 0.999657538831234, "train/policy_randomness_min": 0.9941934406757355, "train/policy_randomness_std": 0.00023369087306491566, "train/post_ent_mag": 40.34530948638916, "train/post_ent_max": 40.34530948638916, "train/post_ent_mean": 40.31852209091186, "train/post_ent_min": 40.215430393218995, "train/post_ent_std": 0.02434920074418187, "train/prior_ent_mag": 44.61564243316651, "train/prior_ent_max": 44.61564243316651, "train/prior_ent_mean": 44.57469179153443, "train/prior_ent_min": 44.42881513595581, "train/prior_ent_std": 0.029600663692690432, "train/rep_loss_mean": 1.0104357141256333, "train/rep_loss_std": 0.00020390375051647423, "train/reward_avg": 7.627868573763408e-05, "train/reward_loss_mean": 0.0013400539825670422, "train/reward_loss_std": 0.03811470276389747, "train/reward_max_data": 0.0781093741953373, "train/reward_max_pred": 6.01118803024292e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014838897852314403, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.169017752011618, "train/reward_pred": 6.0062458505854014e-05, "train/reward_rate": 0.0001171875, "train_stats/mean_log_entropy": 1.9382225930153787, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020182941108942032, "report/cont_loss_std": 0.29768210649490356, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.51185941696167, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004046768415719271, "report/cont_pred": 0.9959612488746643, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2738906145095825, "report/image_loss_std": 0.08779861778020859, "report/model_loss_mean": 0.8942042589187622, "report/model_loss_std": 0.30749496817588806, "report/post_ent_mag": 44.472938537597656, "report/post_ent_max": 44.472938537597656, "report/post_ent_mean": 44.46508026123047, "report/post_ent_min": 44.437705993652344, "report/post_ent_std": 0.006454951595515013, "report/prior_ent_mag": 42.712554931640625, "report/prior_ent_max": 42.712554931640625, "report/prior_ent_mean": 42.69408416748047, "report/prior_ent_min": 42.6356201171875, "report/prior_ent_std": 0.013683284632861614, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00013065338134765625, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 5.4717063903808594e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00013065338134765625, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 5.4717063903808594e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0040467530488967896, "eval/cont_loss_std": 4.917890237265965e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0040467530488967896, "eval/cont_pred": 0.9959613084793091, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2641168534755707, "eval/image_loss_std": 0.07734257727861404, "eval/model_loss_mean": 0.868294358253479, "eval/model_loss_std": 0.07734255492687225, "eval/post_ent_mag": 44.473655700683594, "eval/post_ent_max": 44.473655700683594, "eval/post_ent_mean": 44.46532440185547, "eval/post_ent_min": 44.43988037109375, "eval/post_ent_std": 0.006148444954305887, "eval/prior_ent_mag": 42.71327590942383, "eval/prior_ent_max": 42.71327590942383, "eval/prior_ent_mean": 42.694541931152344, "eval/prior_ent_min": 42.62852478027344, "eval/prior_ent_std": 0.012879270128905773, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00013065338134765625, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 5.4717063903808594e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00013065338134765625, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.4717063903808594e-05, "eval/reward_rate": 0.0, "replay/size": 128225.0, "replay/inserts": 32016.0, "replay/samples": 32016.0, "replay/insert_wait_avg": 1.3361300068578381e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.205840850936836e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.17590270652903e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0443534851074, "timer/env.step_count": 4002.0, "timer/env.step_total": 37.578020095825195, "timer/env.step_frac": 0.0375763534535919, "timer/env.step_avg": 0.009389810118896851, "timer/env.step_min": 0.007653474807739258, "timer/env.step_max": 0.03527188301086426, "timer/replay._sample_count": 32016.0, "timer/replay._sample_total": 17.445077180862427, "timer/replay._sample_frac": 0.017444303465208474, "timer/replay._sample_avg": 0.0005448862187925546, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.02166152000427246, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4869.0, "timer/agent.policy_total": 51.07355189323425, "timer/agent.policy_frac": 0.051071286703680024, "timer/agent.policy_avg": 0.01048953622781562, "timer/agent.policy_min": 0.008978128433227539, "timer/agent.policy_max": 0.08550143241882324, "timer/dataset_train_count": 2001.0, "timer/dataset_train_total": 0.24770545959472656, "timer/dataset_train_frac": 0.0002476944734815858, "timer/dataset_train_avg": 0.0001237908343801732, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.040976524353027344, "timer/agent.train_count": 2001.0, "timer/agent.train_total": 898.0471034049988, "timer/agent.train_frac": 0.8980072736527605, "timer/agent.train_avg": 0.4487991521264362, "timer/agent.train_min": 0.4375481605529785, "timer/agent.train_max": 0.6729030609130859, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790959358215332, "timer/agent.report_frac": 0.0004790746871895296, "timer/agent.report_avg": 0.2395479679107666, "timer/agent.report_min": 0.23400115966796875, "timer/agent.report_max": 0.24509477615356445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1231448638712606e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.014038072500185}
{"step": 128736, "time": 4213.942592144012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129040, "time": 4223.621876001358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129472, "time": 4236.954755783081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 129800, "time": 4246.755643129349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 4258.959452867508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.966036081314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.971730709076, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.97731757164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.982884168625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.99068403244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4258.997163295746, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4259.0026223659515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130096, "time": 4261.939726114273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130320, "time": 4268.842995882034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130576, "time": 4276.648923397064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 130600, "time": 4277.1593635082245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131048, "time": 4290.808949947357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131352, "time": 4300.685413122177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 131784, "time": 4313.901221513748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132112, "time": 4324.177452325821, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132408, "time": 4333.072530508041, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132632, "time": 4339.900168895721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132888, "time": 4347.788523197174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 132912, "time": 4348.793157577515, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133360, "time": 4362.59046459198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 133664, "time": 4371.865847110748, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134096, "time": 4385.052956819534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134424, "time": 4395.012228965759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134720, "time": 4404.262557029724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 134944, "time": 4411.070483446121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135200, "time": 4418.9109699726105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135224, "time": 4419.4229028224945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135672, "time": 4433.07230091095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 135976, "time": 4442.351363420486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136128, "time": 4447.350217103958, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 136408, "time": 4455.658579587936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 136736, "time": 4465.9122478961945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137032, "time": 4474.73193526268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137256, "time": 4481.676550865173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137536, "time": 4490.425086736679, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 137984, "time": 4504.0798053741455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138288, "time": 4513.497552394867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138440, "time": 4517.93616938591, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 138720, "time": 4526.711964130402, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139048, "time": 4536.5592658519745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139176, "time": 4540.47119808197, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 139344, "time": 4546.287317991257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139568, "time": 4553.083002328873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 139848, "time": 4561.406466245651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 4571.014072418213, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 140088, "time": 4574.097656488419, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4574.104162931442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4574.110020875931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4574.116157531738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4574.1218521595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4574.127594947815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4574.133228778839, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140296, "time": 4580.469605207443, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140600, "time": 4590.368295431137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 140752, "time": 4595.251307010651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141032, "time": 4603.632546901703, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141488, "time": 4617.776428461075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141656, "time": 4622.6691970825195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 141880, "time": 4629.636378288269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142160, "time": 4638.399584770203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142608, "time": 4652.067634105682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 142912, "time": 4661.4193522930145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143064, "time": 4665.8385899066925, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143344, "time": 4674.657463788986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143800, "time": 4688.411679506302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 143968, "time": 4693.75022482872, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144192, "time": 4700.552766561508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144472, "time": 4708.847093105316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 144920, "time": 4722.60573720932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 4731.85396361351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 4731.859992265701, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 145376, "time": 4736.712805509567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 145656, "time": 4745.040570259094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146280, "time": 4764.193512201309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146504, "time": 4771.050270795822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 146784, "time": 4779.974404811859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147232, "time": 4793.683531761169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147536, "time": 4803.4380486011505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147536, "time": 4803.445573806763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147688, "time": 4807.953766822815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 147968, "time": 4816.719464302063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148592, "time": 4835.74102807045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 148816, "time": 4842.622957468033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149096, "time": 4851.038326740265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149544, "time": 4864.735651731491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149848, "time": 4874.163481235504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 149848, "time": 4874.170895576477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150000, "time": 4879.089186429977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 4884.742510795593, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 150072, "time": 4887.263079881668, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4887.269783735275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4887.2758622169495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4887.282244205475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4887.289138555527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4887.295825004578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 4887.30305814743, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150280, "time": 4893.820698738098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 150704, "time": 4907.433457612991, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 150904, "time": 4913.385167598724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151128, "time": 4920.204785346985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151408, "time": 4929.261428356171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 151856, "time": 4943.040311574936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152160, "time": 4952.305858850479, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152312, "time": 4956.815579652786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 152592, "time": 4965.610462188721, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153016, "time": 4978.349293470383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153216, "time": 4984.667355537415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153440, "time": 4991.576400279999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 153720, "time": 4999.921482563019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154168, "time": 5013.60416841507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154472, "time": 5023.052516698837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154624, "time": 5027.9285254478455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 154904, "time": 5036.268794298172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155328, "time": 5049.541506052017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155528, "time": 5055.413672208786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 155752, "time": 5062.728726148605, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156032, "time": 5071.487980604172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156480, "time": 5085.246994972229, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 156576, "time": 5088.180547952652, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 156784, "time": 5094.554274559021, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157216, "time": 5107.817380428314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157640, "time": 5120.484503269196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 157840, "time": 5126.780503988266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158064, "time": 5133.583753108978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158344, "time": 5141.979327917099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158792, "time": 5155.61816573143, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 158888, "time": 5158.542865991592, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159096, "time": 5164.889948606491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159528, "time": 5178.177816390991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 159952, "time": 5191.339181423187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 5198.026961803436, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 160056, "time": 5199.727103233337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5199.73356461525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5199.739051580429, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5199.744587421417, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5199.749864816666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5199.755150318146, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5199.760730981827, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160152, "time": 5202.692238807678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160376, "time": 5209.511859416962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 160489, "time": 5213.92936873436, "train_stats/mean_log_entropy": 1.937074850090837, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9985277952261304, "train/action_min": 0.0, "train/action_std": 2.00013315737547, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 4.0542346543780745e-05, "train/actor_opt_grad_steps": 8940.0, "train/actor_opt_loss": -5.711402603729287, "train/adv_mag": 0.0001988764945885644, "train/adv_max": 0.00012581503421217952, "train/adv_mean": -8.696288562157805e-07, "train/adv_min": -0.00012246303110565972, "train/adv_std": 4.6305838964715934e-05, "train/cont_avg": 0.9965795775753769, "train/cont_loss_mean": 0.022866774257974485, "train/cont_loss_std": 0.31570561807345243, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.639836678138146, "train/cont_pos_acc": 0.9999999835263544, "train/cont_pos_loss": 0.0035906293331154026, "train/cont_pred": 0.996415960129781, "train/cont_rate": 0.9965795775753769, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.008422204880652265, "train/extr_critic_critic_opt_grad_steps": 8940.0, "train/extr_critic_critic_opt_loss": 7443.471188952575, "train/extr_critic_mag": 0.02032893746342491, "train/extr_critic_max": 0.02032893746342491, "train/extr_critic_mean": 0.020258132536806653, "train/extr_critic_min": 0.02017823056359986, "train/extr_critic_std": 2.988152722144004e-05, "train/extr_return_normed_mag": 0.00024157440542575703, "train/extr_return_normed_max": 0.00015271574857845976, "train/extr_return_normed_mean": 6.689175788910208e-05, "train/extr_return_normed_min": -1.8418752518131507e-05, "train/extr_return_normed_std": 4.139638442741879e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020345135952285185, "train/extr_return_raw_max": 0.020345135952285185, "train/extr_return_raw_mean": 0.02025931317303049, "train/extr_return_raw_min": 0.020174001451188594, "train/extr_return_raw_std": 4.139638453832058e-05, "train/extr_reward_mag": 6.0738031588607096e-05, "train/extr_reward_max": 6.0738031588607096e-05, "train/extr_reward_mean": 6.070294635427119e-05, "train/extr_reward_min": 6.066614658988301e-05, "train/extr_reward_std": 1.9129692975970216e-08, "train/image_loss_mean": 0.2510629613046071, "train/image_loss_std": 0.08533892668222064, "train/model_loss_mean": 0.8754778025138318, "train/model_loss_std": 0.3607278643690761, "train/model_opt_grad_norm": 48.73479830679582, "train/model_opt_grad_steps": 8929.547738693467, "train/model_opt_loss": 2172.422200725306, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2481.1557788944724, "train/policy_entropy_mag": 1.9458943096237566, "train/policy_entropy_max": 1.9458943096237566, "train/policy_entropy_mean": 1.945101900316363, "train/policy_entropy_min": 1.9350094250099144, "train/policy_entropy_std": 0.0005328951272750788, "train/policy_logprob_mag": 2.1408616717736324, "train/policy_logprob_max": -1.7497768647706688, "train/policy_logprob_mean": -1.9451102251982568, "train/policy_logprob_min": -2.1408616717736324, "train/policy_logprob_std": 0.040070019512619806, "train/policy_randomness_mag": 0.9999919186285393, "train/policy_randomness_max": 0.9999919186285393, "train/policy_randomness_mean": 0.9995847014925587, "train/policy_randomness_min": 0.9943981955398866, "train/policy_randomness_std": 0.0002738539350772482, "train/post_ent_mag": 45.725746078107825, "train/post_ent_max": 45.725746078107825, "train/post_ent_mean": 45.714965398587175, "train/post_ent_min": 45.690440939898465, "train/post_ent_std": 0.0057364630222732395, "train/prior_ent_mag": 42.70303490413493, "train/prior_ent_max": 42.70303490413493, "train/prior_ent_mean": 42.68124213290574, "train/prior_ent_min": 42.62215971826908, "train/prior_ent_std": 0.013108993674530157, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 8.762685521201572e-05, "train/reward_loss_mean": 0.0015480486704176994, "train/reward_loss_std": 0.04233885809955735, "train/reward_max_data": 0.08242776345967048, "train/reward_max_pred": 6.083447729522858e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.000135986403547211, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.28219669342041, "train/reward_pred": 6.0760537770824814e-05, "train/reward_rate": 0.00013740577889447236, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014592834748327732, "report/cont_loss_std": 0.24817685782909393, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6247076988220215, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003614139510318637, "report/cont_pred": 0.9963923096656799, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2483033835887909, "report/image_loss_std": 0.0871497392654419, "report/model_loss_mean": 0.8629887104034424, "report/model_loss_std": 0.26312440633773804, "report/post_ent_mag": 47.6248664855957, "report/post_ent_max": 47.6248664855957, "report/post_ent_mean": 47.6126708984375, "report/post_ent_min": 47.58489990234375, "report/post_ent_std": 0.005268455483019352, "report/prior_ent_mag": 42.615760803222656, "report/prior_ent_max": 42.615760803222656, "report/prior_ent_mean": 42.575775146484375, "report/prior_ent_min": 42.543357849121094, "report/prior_ent_std": 0.011061280965805054, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 9.250640869140625e-05, "report/reward_loss_std": 0.0, "report/reward_max_data": 0.0, "report/reward_max_pred": 3.8623809814453125e-05, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 9.250640869140625e-05, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 3.8623809814453125e-05, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003614139510318637, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003614139510318637, "eval/cont_pred": 0.9963923096656799, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2579772472381592, "eval/image_loss_std": 0.0895858108997345, "eval/model_loss_mean": 0.8616839051246643, "eval/model_loss_std": 0.0895858183503151, "eval/post_ent_mag": 47.62670135498047, "eval/post_ent_max": 47.62670135498047, "eval/post_ent_mean": 47.61284255981445, "eval/post_ent_min": 47.59241485595703, "eval/post_ent_std": 0.004967124667018652, "eval/prior_ent_mag": 42.60429382324219, "eval/prior_ent_max": 42.60429382324219, "eval/prior_ent_mean": 42.57599639892578, "eval/prior_ent_min": 42.54443359375, "eval/prior_ent_std": 0.011098849587142467, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 9.250640869140625e-05, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 3.8623809814453125e-05, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 9.250640869140625e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.8623809814453125e-05, "eval/reward_rate": 0.0, "replay/size": 159985.0, "replay/inserts": 31760.0, "replay/samples": 31760.0, "replay/insert_wait_avg": 1.3378690412122596e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.244433391004126e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40360.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2375955763160151e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9912974834442, "timer/env.step_count": 3970.0, "timer/env.step_total": 37.27935862541199, "timer/env.step_frac": 0.037279683052470945, "timer/env.step_avg": 0.00939026665627506, "timer/env.step_min": 0.007590293884277344, "timer/env.step_max": 0.037892818450927734, "timer/replay._sample_count": 31760.0, "timer/replay._sample_total": 17.3540096282959, "timer/replay._sample_frac": 0.017354160653166296, "timer/replay._sample_avg": 0.0005464108825030194, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.012810945510864258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5126.0, "timer/agent.policy_total": 54.38722276687622, "timer/agent.policy_frac": 0.05438769607670176, "timer/agent.policy_avg": 0.010610070769971952, "timer/agent.policy_min": 0.007841110229492188, "timer/agent.policy_max": 0.09354329109191895, "timer/dataset_train_count": 1985.0, "timer/dataset_train_total": 0.21042227745056152, "timer/dataset_train_frac": 0.00021042410866985097, "timer/dataset_train_avg": 0.00010600618511363301, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0004296302795410156, "timer/agent.train_count": 1985.0, "timer/agent.train_total": 891.3244113922119, "timer/agent.train_frac": 0.8913321682251626, "timer/agent.train_avg": 0.44902993017239895, "timer/agent.train_min": 0.43890833854675293, "timer/agent.train_max": 1.096343755722046, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47626638412475586, "timer/agent.report_frac": 0.00047627052887691843, "timer/agent.report_avg": 0.23813319206237793, "timer/agent.report_min": 0.23180174827575684, "timer/agent.report_max": 0.24446463584899902, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2663629592691365e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 31.75972623040632}
{"step": 160656, "time": 5219.036228179932, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161104, "time": 5232.72997379303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161200, "time": 5235.634739160538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161408, "time": 5241.957178354263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 161840, "time": 5255.073152065277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162264, "time": 5267.805530786514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162464, "time": 5274.096082687378, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162688, "time": 5280.9447066783905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 162968, "time": 5289.32536149025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163416, "time": 5302.866386651993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163480, "time": 5304.81568646431, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 163512, "time": 5305.786151885986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 163720, "time": 5312.069794654846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164152, "time": 5325.7850613594055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 164616, "time": 5339.866939306259, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 164768, "time": 5344.722474575043, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 164776, "time": 5344.751069068909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165000, "time": 5351.591747522354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165280, "time": 5360.328145980835, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165728, "time": 5373.874225854874, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165824, "time": 5376.874345302582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 165968, "time": 5381.246137857437, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 166464, "time": 5396.257013082504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 166928, "time": 5410.3608984947205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167080, "time": 5414.736262083054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167088, "time": 5415.203141450882, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167312, "time": 5422.091659069061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 167592, "time": 5430.392390012741, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168136, "time": 5446.919705867767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168280, "time": 5451.282337903976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 168776, "time": 5466.413147211075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169240, "time": 5480.458571910858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169392, "time": 5485.288170099258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169400, "time": 5485.317857027054, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169624, "time": 5492.093637466431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 169904, "time": 5500.868634700775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 5510.524481058121, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.531240701675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.5367612838745, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.5423192977905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.54779958725, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.553186655045, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.558875799179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5510.565404653549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170448, "time": 5523.12549161911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 170592, "time": 5527.616063594818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171088, "time": 5542.580610752106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171552, "time": 5556.692384004593, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171704, "time": 5561.071562767029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171712, "time": 5561.540775537491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 171920, "time": 5567.816275596619, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 171936, "time": 5568.305528640747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172216, "time": 5577.067163944244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172760, "time": 5593.5934336185455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 172904, "time": 5597.925001621246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 173864, "time": 5627.107650756836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174016, "time": 5631.913359642029, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174024, "time": 5631.941771507263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174232, "time": 5638.271694660187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174248, "time": 5638.762169837952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 174528, "time": 5647.542791366577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175072, "time": 5663.99129152298, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 175216, "time": 5668.367386341095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176176, "time": 5697.527858018875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176328, "time": 5701.898635387421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176336, "time": 5702.365355014801, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176544, "time": 5708.690998077393, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176560, "time": 5709.177415132523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 176840, "time": 5717.45272231102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177384, "time": 5733.888835906982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 177528, "time": 5738.342458486557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178488, "time": 5767.447087049484, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178640, "time": 5772.292856693268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178648, "time": 5772.3211443424225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178856, "time": 5778.648051977158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 178872, "time": 5779.13636136055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179152, "time": 5787.817194700241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179696, "time": 5804.3077557086945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 179840, "time": 5808.65934586525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 5819.200774431229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.207228422165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.212944984436, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.218495130539, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.224015235901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.229477405548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.234931468964, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 5819.240428686142, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180800, "time": 5843.513879776001, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180952, "time": 5847.897258043289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 180960, "time": 5848.364144086838, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181168, "time": 5854.653141975403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181184, "time": 5855.146234512329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 181464, "time": 5863.528519392014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182008, "time": 5879.931200027466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 182152, "time": 5884.287698507309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183112, "time": 5913.299147367477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183264, "time": 5918.2432515621185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183272, "time": 5918.271947622299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183480, "time": 5924.575268507004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183496, "time": 5925.062836885452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 183776, "time": 5933.706893920898, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184320, "time": 5950.226673364639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 184464, "time": 5954.583960056305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185424, "time": 5983.8584225177765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185576, "time": 5988.271166563034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185584, "time": 5988.744734287262, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185792, "time": 5995.067202329636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 185808, "time": 5995.559907913208, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186088, "time": 6003.855884552002, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186632, "time": 6020.516086816788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 186776, "time": 6024.895799398422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187736, "time": 6053.847114562988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187888, "time": 6058.696091413498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 187896, "time": 6058.724849224091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188104, "time": 6065.0386300086975, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188120, "time": 6065.547588825226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188400, "time": 6074.372946977615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 188944, "time": 6091.386029481888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 189088, "time": 6095.7700843811035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 6128.984705924988, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6128.991290569305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6128.996828317642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6129.002398014069, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6129.007784128189, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6129.013324975967, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6129.018775463104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6129.024242639542, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190048, "time": 6130.462519645691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190200, "time": 6134.831288099289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190208, "time": 6135.295880317688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190416, "time": 6141.620318651199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190432, "time": 6142.108040571213, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190712, "time": 6150.34015917778, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 190752, "time": 6151.770659446716, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 191256, "time": 6166.817692041397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 191400, "time": 6171.151246547699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192360, "time": 6200.215566158295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192512, "time": 6205.045188903809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192520, "time": 6205.073188304901, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192728, "time": 6211.328412055969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 192793, "time": 6214.264434576035, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9868928512724318, "train/action_min": 0.0, "train/action_std": 2.0025346975515386, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001481694085344829, "train/actor_opt_grad_steps": 10945.0, "train/actor_opt_loss": -5.268723787573895, "train/adv_mag": 0.00041710227580353765, "train/adv_max": 0.0003265333039188149, "train/adv_mean": 2.1271209025954785e-05, "train/adv_min": -0.0003080041156989513, "train/adv_std": 8.476567286649724e-05, "train/cont_avg": 0.9965433555074258, "train/cont_loss_mean": 0.02307947574293997, "train/cont_loss_std": 0.3207884202153498, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.637746860980988, "train/cont_pos_acc": 0.9999999837710125, "train/cont_pos_loss": 0.0035915472072152663, "train/cont_pred": 0.9964149871675094, "train/cont_rate": 0.9965433555074258, "train/dyn_loss_mean": 1.000000817940967, "train/dyn_loss_std": 2.008408746675768e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.006948235286814668, "train/extr_critic_critic_opt_grad_steps": 10945.0, "train/extr_critic_critic_opt_loss": 7458.42547184406, "train/extr_critic_mag": 0.02057684058009988, "train/extr_critic_max": 0.02057684058009988, "train/extr_critic_mean": 0.02032124598759531, "train/extr_critic_min": 0.02012957499759032, "train/extr_critic_std": 5.858910145380463e-05, "train/extr_return_normed_mag": 0.00044368417693836854, "train/extr_return_normed_max": 0.0003677806586469754, "train/extr_return_normed_mean": 0.000139722969124975, "train/extr_return_normed_min": -6.437509108592968e-05, "train/extr_return_normed_std": 6.987957446951197e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.020571480910893124, "train/extr_return_raw_max": 0.020571480910893124, "train/extr_return_raw_mean": 0.020343424346629935, "train/extr_return_raw_min": 0.02013932516116022, "train/extr_return_raw_std": 6.987957470589056e-05, "train/extr_reward_mag": 6.417590792816465e-05, "train/extr_reward_max": 6.417590792816465e-05, "train/extr_reward_mean": 6.411390055147043e-05, "train/extr_reward_min": 6.40283716787206e-05, "train/extr_reward_std": 3.2410071873792164e-08, "train/image_loss_mean": 0.23102349728936017, "train/image_loss_std": 0.08874422785743039, "train/model_loss_mean": 0.8555583216176175, "train/model_loss_std": 0.36417848417664517, "train/model_opt_grad_norm": 43.304868717098714, "train/model_opt_grad_steps": 10932.594059405941, "train/model_opt_loss": 2149.8418470326037, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 2500.0, "train/policy_entropy_mag": 1.9457735147806678, "train/policy_entropy_max": 1.9457735147806678, "train/policy_entropy_mean": 1.9371665533226314, "train/policy_entropy_min": 1.8510439313284242, "train/policy_entropy_std": 0.007034534263991668, "train/policy_logprob_mag": 2.5626988989291806, "train/policy_logprob_max": -1.3605665886166072, "train/policy_logprob_mean": -1.9371171080239928, "train/policy_logprob_min": -2.5626988989291806, "train/policy_logprob_std": 0.11956184386911958, "train/policy_randomness_mag": 0.9999298429725194, "train/policy_randomness_max": 0.9999298429725194, "train/policy_randomness_mean": 0.995506740442597, "train/policy_randomness_min": 0.9512484613621589, "train/policy_randomness_std": 0.0036150357320888595, "train/post_ent_mag": 48.77687395681249, "train/post_ent_max": 48.77687395681249, "train/post_ent_mean": 48.58486241633349, "train/post_ent_min": 48.46673990004133, "train/post_ent_std": 0.05362888811718636, "train/prior_ent_mag": 46.15825634191532, "train/prior_ent_max": 46.15825634191532, "train/prior_ent_mean": 44.814049352513685, "train/prior_ent_min": 43.80427237784509, "train/prior_ent_std": 0.36115289557872726, "train/rep_loss_mean": 1.000000817940967, "train/rep_loss_std": 2.008408746675768e-05, "train/reward_avg": 7.798600873315135e-05, "train/reward_loss_mean": 0.00145483904490524, "train/reward_loss_std": 0.04098530146066796, "train/reward_max_data": 0.07877475215066777, "train/reward_max_pred": 6.409269748347821e-05, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00014123866809439837, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.414667358398438, "train/reward_pred": 6.401483926202843e-05, "train/reward_rate": 0.00012569616336633664, "train_stats/mean_log_entropy": 1.9291973864210064, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025560077279806137, "report/cont_loss_std": 0.34453991055488586, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.527421474456787, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0039841532707214355, "report/cont_pred": 0.9960238933563232, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17116400599479675, "report/image_loss_std": 0.09336542338132858, "report/model_loss_mean": 0.796961784362793, "report/model_loss_std": 0.3550399839878082, "report/post_ent_mag": 50.14520263671875, "report/post_ent_max": 50.14520263671875, "report/post_ent_mean": 49.55066680908203, "report/post_ent_min": 49.21934509277344, "report/post_ent_std": 0.16108722984790802, "report/prior_ent_mag": 51.296356201171875, "report/prior_ent_max": 51.296356201171875, "report/prior_ent_mean": 48.02388381958008, "report/prior_ent_min": 44.4637451171875, "report/prior_ent_std": 1.2084074020385742, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00023768283426761627, "report/reward_loss_std": 6.838495778538345e-07, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.00011146068572998047, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00023768283426761627, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00011064449790865183, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003984153736382723, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003984153736382723, "eval/cont_pred": 0.9960238933563232, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1824353188276291, "eval/image_loss_std": 0.09622495621442795, "eval/model_loss_mean": 0.7866572141647339, "eval/model_loss_std": 0.09622473269701004, "eval/post_ent_mag": 50.071800231933594, "eval/post_ent_max": 50.071800231933594, "eval/post_ent_mean": 49.51943588256836, "eval/post_ent_min": 49.25660705566406, "eval/post_ent_std": 0.13750265538692474, "eval/prior_ent_mag": 50.61151885986328, "eval/prior_ent_max": 50.61151885986328, "eval/prior_ent_mean": 48.20720672607422, "eval/prior_ent_min": 44.4244499206543, "eval/prior_ent_std": 1.1199394464492798, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00023772940039634705, "eval/reward_loss_std": 6.907676493028703e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00011146068572998047, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00023772940039634705, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00011066824663430452, "eval/reward_rate": 0.0, "replay/size": 192289.0, "replay/inserts": 32304.0, "replay/samples": 32304.0, "replay/insert_wait_avg": 1.3232363988527748e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.072975308898654e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47296.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.198830214063739e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3180367946625, "timer/env.step_count": 4038.0, "timer/env.step_total": 37.7657310962677, "timer/env.step_frac": 0.037753724022892884, "timer/env.step_avg": 0.009352583233350099, "timer/env.step_min": 0.007437229156494141, "timer/env.step_max": 0.04895734786987305, "timer/replay._sample_count": 32304.0, "timer/replay._sample_total": 17.129769563674927, "timer/replay._sample_frac": 0.017124323398750425, "timer/replay._sample_avg": 0.0005302677551905314, "timer/replay._sample_min": 0.0004074573516845703, "timer/replay._sample_max": 0.02904224395751953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4905.0, "timer/agent.policy_total": 51.233158111572266, "timer/agent.policy_frac": 0.05121686926263933, "timer/agent.policy_avg": 0.010445088300014733, "timer/agent.policy_min": 0.008371829986572266, "timer/agent.policy_max": 0.1275653839111328, "timer/dataset_train_count": 2019.0, "timer/dataset_train_total": 0.21665668487548828, "timer/dataset_train_frac": 0.00021658780198518192, "timer/dataset_train_avg": 0.00010730890781351574, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0010819435119628906, "timer/agent.train_count": 2019.0, "timer/agent.train_total": 897.8644659519196, "timer/agent.train_frac": 0.8975790028029118, "timer/agent.train_avg": 0.44470751161561145, "timer/agent.train_min": 0.43244290351867676, "timer/agent.train_max": 0.7145085334777832, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47995543479919434, "timer/agent.report_frac": 0.00047980283984194104, "timer/agent.report_avg": 0.23997771739959717, "timer/agent.report_min": 0.2317492961883545, "timer/agent.report_max": 0.24820613861083984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1222903830050526e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 32.29317273923195}
{"step": 193024, "time": 6221.375611543655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193064, "time": 6222.359628200531, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193568, "time": 6237.7798907756805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 193712, "time": 6242.118017196655, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194064, "time": 6252.796724796295, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 194488, "time": 6265.358218431473, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 194672, "time": 6271.153506994247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 194832, "time": 6276.167214870453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195040, "time": 6282.43835568428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195336, "time": 6291.1375987529755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195376, "time": 6292.562949180603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 195936, "time": 6309.538589954376, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 196024, "time": 6311.978832244873, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196376, "time": 6322.563343286514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196800, "time": 6336.174764871597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 196984, "time": 6341.504132509232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197144, "time": 6346.3154537677765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197352, "time": 6352.577084779739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 197648, "time": 6361.701575756073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198248, "time": 6379.614080429077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198336, "time": 6382.479601621628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 198688, "time": 6393.088658571243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199112, "time": 6405.771728992462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199296, "time": 6411.5429701805115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199456, "time": 6416.364456653595, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199664, "time": 6422.6573305130005, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 199960, "time": 6431.4775602817535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 6441.6027138233185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.609215259552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.614796876907, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.620385169983, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.625856399536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.631416797638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.637649536133, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6441.64363861084, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200560, "time": 6455.607991218567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 200648, "time": 6458.144777059555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201000, "time": 6468.741612911224, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201424, "time": 6481.728493690491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201608, "time": 6487.171434402466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201768, "time": 6491.993930339813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 201976, "time": 6498.2432181835175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202272, "time": 6508.134711265564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202872, "time": 6526.07310461998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 202960, "time": 6528.946992397308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203312, "time": 6539.560958623886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203736, "time": 6552.231442689896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 203920, "time": 6557.998095035553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204080, "time": 6562.839053630829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204288, "time": 6569.101592063904, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 204584, "time": 6577.876578807831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205184, "time": 6596.744138479233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205272, "time": 6599.202238082886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 205624, "time": 6609.889441013336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206048, "time": 6622.909222602844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206232, "time": 6628.269029140472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206392, "time": 6633.088944673538, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206600, "time": 6639.397486448288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 206896, "time": 6648.538014650345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207496, "time": 6666.659691095352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207584, "time": 6669.527567625046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 207936, "time": 6680.182552099228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208360, "time": 6692.781042098999, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208544, "time": 6698.61612534523, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208704, "time": 6703.452276706696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 208912, "time": 6709.769438505173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209208, "time": 6718.486325263977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209808, "time": 6737.12374663353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 209896, "time": 6739.6018397808075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 6750.705803871155, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.712803840637, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.7185344696045, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.724013328552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.729586601257, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.735275030136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.7409324646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6750.746333122253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210248, "time": 6755.6523694992065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210672, "time": 6768.841135978699, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 210856, "time": 6774.298799037933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211016, "time": 6779.2022869586945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211224, "time": 6785.553120136261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 211520, "time": 6794.904053688049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212120, "time": 6812.898495197296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212208, "time": 6815.8132417202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212560, "time": 6826.621999502182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 212984, "time": 6839.263281106949, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213168, "time": 6845.580984830856, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213328, "time": 6850.589909076691, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213536, "time": 6856.911575317383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 213832, "time": 6865.731781244278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214432, "time": 6884.592092752457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214520, "time": 6887.108573436737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 214872, "time": 6897.82791018486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215296, "time": 6910.966753721237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215480, "time": 6916.363009214401, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215640, "time": 6921.237598180771, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 215848, "time": 6927.597230672836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216144, "time": 6936.918785572052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216744, "time": 6954.890956878662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 216832, "time": 6957.796463251114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217184, "time": 6968.624541759491, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217608, "time": 6981.325601100922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217792, "time": 6987.153882265091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 217952, "time": 6992.04369020462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218160, "time": 6998.482476472855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218456, "time": 7007.309498548508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 218784, "time": 7017.57284450531, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 219056, "time": 7025.881751060486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219144, "time": 7028.382098913193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219496, "time": 7039.100719690323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 219920, "time": 7052.225504398346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 7062.00159740448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.008147239685, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.013971090317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.019413471222, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.024886846542, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.030338525772, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.0357410907745, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7062.041400194168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220104, "time": 7063.035139799118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220472, "time": 7074.266304016113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 220768, "time": 7083.4919283390045, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221096, "time": 7093.250540018082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221368, "time": 7101.90919303894, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221456, "time": 7104.796046257019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 221808, "time": 7115.404374599457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222232, "time": 7128.124963283539, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222320, "time": 7131.025985240936, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 222416, "time": 7133.966152191162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222784, "time": 7145.185264110565, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 222808, "time": 7145.695076227188, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 223080, "time": 7154.060334444046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223312, "time": 7161.310940742493, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 223408, "time": 7164.209335565567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223680, "time": 7172.45716881752, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 223768, "time": 7174.923548221588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224120, "time": 7185.713842868805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 224728, "time": 7204.187307596207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225033, "time": 7214.511184453964, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0892880567863807, "train/action_min": 0.0, "train/action_std": 1.9621996446628476, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0002359995379622919, "train/actor_opt_grad_steps": 12960.0, "train/actor_opt_loss": -2.765305698047675, "train/adv_mag": 0.001337350035707156, "train/adv_max": 0.001231577367850797, "train/adv_mean": 0.00016738047670729719, "train/adv_min": -0.0007522254904259497, "train/adv_std": 0.0002445307682906579, "train/cont_avg": 0.9963366759950248, "train/cont_loss_mean": 0.02421246166456843, "train/cont_loss_std": 0.33115162096213346, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.631327714493025, "train/cont_pos_acc": 0.9999999833937309, "train/cont_pos_loss": 0.003592944502441296, "train/cont_pred": 0.996413509644086, "train/cont_rate": 0.9963366759950248, "train/dyn_loss_mean": 1.00000256566859, "train/dyn_loss_std": 8.206910034409951e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.008511700146612641, "train/extr_critic_critic_opt_grad_steps": 12960.0, "train/extr_critic_critic_opt_loss": 8047.292266693875, "train/extr_critic_mag": 0.023762068938260054, "train/extr_critic_max": 0.023762068938260054, "train/extr_critic_mean": 0.02299307441496434, "train/extr_critic_min": 0.02253640528342024, "train/extr_critic_std": 0.0001400830995552682, "train/extr_return_normed_mag": 0.0017529936664881399, "train/extr_return_normed_max": 0.0017334471702279144, "train/extr_return_normed_mean": 0.0006682484051194859, "train/extr_return_normed_min": 4.077682373535574e-06, "train/extr_return_normed_std": 0.000249996329371039, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.024225625612620098, "train/extr_return_raw_max": 0.024225625612620098, "train/extr_return_raw_mean": 0.023160428012633204, "train/extr_return_raw_min": 0.022496256124765718, "train/extr_return_raw_std": 0.0002499963285022679, "train/extr_reward_mag": 0.00018232971874635611, "train/extr_reward_max": 0.00018232971874635611, "train/extr_reward_mean": 8.797112794996086e-05, "train/extr_reward_min": 5.208497023701075e-05, "train/extr_reward_std": 3.286161463201704e-05, "train/image_loss_mean": 0.19890238989644976, "train/image_loss_std": 0.09742454632152965, "train/model_loss_mean": 0.8248291605740637, "train/model_loss_std": 0.3816755233119376, "train/model_opt_grad_norm": 39.91418356895447, "train/model_opt_grad_steps": 12945.92039800995, "train/model_opt_loss": 2431.936074024409, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 2935.323383084577, "train/policy_entropy_mag": 1.944332704022156, "train/policy_entropy_max": 1.944332704022156, "train/policy_entropy_mean": 1.9067917249689055, "train/policy_entropy_min": 1.7238196437038593, "train/policy_entropy_std": 0.022311924782984736, "train/policy_logprob_mag": 3.1281818596284783, "train/policy_logprob_max": -1.069609991057002, "train/policy_logprob_mean": -1.9066120593702023, "train/policy_logprob_min": -3.1281818596284783, "train/policy_logprob_std": 0.2282625852680918, "train/policy_randomness_mag": 0.9991894106366741, "train/policy_randomness_max": 0.9991894106366741, "train/policy_randomness_mean": 0.979897162510981, "train/policy_randomness_min": 0.8858681104669524, "train/policy_randomness_std": 0.011466061858580777, "train/post_ent_mag": 47.56311716487752, "train/post_ent_max": 47.56311716487752, "train/post_ent_mean": 46.976391939381465, "train/post_ent_min": 46.64748570456434, "train/post_ent_std": 0.1500957985200099, "train/prior_ent_mag": 49.53913873700953, "train/prior_ent_max": 49.53913873700953, "train/prior_ent_mean": 46.375122108269686, "train/prior_ent_min": 43.18984647532601, "train/prior_ent_std": 1.2234261543003482, "train/rep_loss_mean": 1.00000256566859, "train/rep_loss_std": 8.206910034409951e-05, "train/reward_avg": 9.045956670237121e-05, "train/reward_loss_mean": 0.0017127480487621838, "train/reward_loss_std": 0.04807800902136037, "train/reward_max_data": 0.09020522310959166, "train/reward_max_pred": 0.00016888931616028743, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015187019425640067, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 10.015932051340739, "train/reward_pred": 6.971129943704723e-05, "train/reward_rate": 0.0001554726368159204, "train_stats/mean_log_entropy": 1.8961737591287364, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014552735723555088, "report/cont_loss_std": 0.253364622592926, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.741504192352295, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0033453956712037325, "report/cont_pred": 0.9966604709625244, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18686334788799286, "report/image_loss_std": 0.11500195413827896, "report/model_loss_mean": 0.8015652894973755, "report/model_loss_std": 0.2766585350036621, "report/post_ent_mag": 43.56606674194336, "report/post_ent_max": 43.56606674194336, "report/post_ent_mean": 42.97587585449219, "report/post_ent_min": 42.612510681152344, "report/post_ent_std": 0.14954166114330292, "report/prior_ent_mag": 45.00590133666992, "report/prior_ent_max": 45.00590133666992, "report/prior_ent_mean": 43.11540222167969, "report/prior_ent_min": 40.86570358276367, "report/prior_ent_std": 0.9208058714866638, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00014913640916347504, "report/reward_loss_std": 0.00013902246428187937, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.0001939535140991211, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00014913640916347504, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 6.671447772532701e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020052650943398476, "eval/cont_loss_std": 0.3081730008125305, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.7051591873168945, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003348126308992505, "eval/cont_pred": 0.9966575503349304, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17233192920684814, "eval/image_loss_std": 0.09331487119197845, "eval/model_loss_mean": 0.7925537824630737, "eval/model_loss_std": 0.3202058672904968, "eval/post_ent_mag": 43.56496047973633, "eval/post_ent_max": 43.56496047973633, "eval/post_ent_mean": 42.96291732788086, "eval/post_ent_min": 42.63725280761719, "eval/post_ent_std": 0.1509413868188858, "eval/prior_ent_mag": 45.15346145629883, "eval/prior_ent_max": 45.15346145629883, "eval/prior_ent_mean": 43.13637161254883, "eval/prior_ent_min": 40.75480651855469, "eval/prior_ent_std": 0.9750824570655823, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00016918592154979706, "eval/reward_loss_std": 0.00014252917026169598, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00019288063049316406, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00016918592154979706, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.563375402241945e-05, "eval/reward_rate": 0.0, "replay/size": 224529.0, "replay/inserts": 32240.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.3110729364248422e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.949792710486476e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 54232.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1527689545487313e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2307260036469, "timer/env.step_count": 4030.0, "timer/env.step_total": 37.265023708343506, "timer/env.step_frac": 0.03725642768167436, "timer/env.step_avg": 0.009246904145990944, "timer/env.step_min": 0.007580280303955078, "timer/env.step_max": 0.03527259826660156, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 16.485130310058594, "timer/replay._sample_frac": 0.01648132763919761, "timer/replay._sample_avg": 0.0005113253818256388, "timer/replay._sample_min": 0.00037169456481933594, "timer/replay._sample_max": 0.011589288711547852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4897.0, "timer/agent.policy_total": 50.715322494506836, "timer/agent.policy_frac": 0.050703623850005514, "timer/agent.policy_avg": 0.01035640647222929, "timer/agent.policy_min": 0.008872747421264648, "timer/agent.policy_max": 0.09847307205200195, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.21291327476501465, "timer/dataset_train_frac": 0.00021286416146771957, "timer/dataset_train_avg": 0.00010566415621092539, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0004913806915283203, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 899.0313873291016, "timer/agent.train_frac": 0.8988240052583865, "timer/agent.train_avg": 0.44616942299210993, "timer/agent.train_min": 0.43395447731018066, "timer/agent.train_max": 1.2182927131652832, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772019386291504, "timer/agent.report_frac": 0.00047709186113065926, "timer/agent.report_avg": 0.2386009693145752, "timer/agent.report_min": 0.23206496238708496, "timer/agent.report_max": 0.24513697624206543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.0531158447265625e-05, "timer/dataset_eval_frac": 4.05218090122117e-08, "timer/dataset_eval_avg": 4.0531158447265625e-05, "timer/dataset_eval_min": 4.0531158447265625e-05, "timer/dataset_eval_max": 4.0531158447265625e-05, "fps": 32.2320125732392}
{"step": 225096, "time": 7216.318973302841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225392, "time": 7225.59437251091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225624, "time": 7232.435824871063, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225720, "time": 7235.3857421875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 225992, "time": 7243.72301864624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226080, "time": 7246.670232772827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 226432, "time": 7257.368521690369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227040, "time": 7275.926098108292, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227408, "time": 7287.056927680969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227704, "time": 7295.865374088287, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 227936, "time": 7303.173716545105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228032, "time": 7306.115366697311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228304, "time": 7314.387605905533, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228392, "time": 7316.836975097656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 228744, "time": 7327.690974235535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229352, "time": 7346.207155227661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 229720, "time": 7357.936965227127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230016, "time": 7367.115689754486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 7370.923545360565, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 230048, "time": 7373.329325675964, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7373.335902690887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7373.341685771942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7373.347143411636, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7373.352751016617, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7373.358387231827, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7373.36452293396, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230248, "time": 7379.213968515396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230344, "time": 7382.125068426132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230616, "time": 7390.4997453689575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 230704, "time": 7393.4147872924805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231056, "time": 7404.12649846077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 231336, "time": 7412.451045513153, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 231664, "time": 7422.752935171127, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232032, "time": 7433.950130701065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232328, "time": 7442.745158672333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232656, "time": 7452.956964015961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 232928, "time": 7461.175400018692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233016, "time": 7463.624669790268, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233368, "time": 7474.300576210022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233648, "time": 7483.040912628174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 233976, "time": 7492.765816926956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234344, "time": 7503.882080078125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234640, "time": 7513.1354875564575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 234968, "time": 7522.808669567108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235240, "time": 7531.0262949466705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235328, "time": 7533.921138048172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235680, "time": 7544.683828830719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 235960, "time": 7552.979325771332, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236288, "time": 7563.138121843338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236552, "time": 7571.038292646408, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 236656, "time": 7574.444167613983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 236952, "time": 7583.230636358261, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237552, "time": 7601.813292264938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237640, "time": 7604.734187602997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 237992, "time": 7615.468988418579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238272, "time": 7624.262409687042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238600, "time": 7634.122846126556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238864, "time": 7642.386683940887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 238968, "time": 7645.318854093552, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 239192, "time": 7652.170614719391, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 239216, "time": 7653.134377717972, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 239248, "time": 7654.117179632187, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 239264, "time": 7654.615580320358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 7681.587790489197, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 240032, "time": 7684.09525179863, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7684.10155081749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7684.107330560684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7684.112788915634, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7684.118206739426, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7684.123721599579, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7684.129273891449, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240304, "time": 7692.52642416954, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 240584, "time": 7700.764271974564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241176, "time": 7718.856569766998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241280, "time": 7722.245360612869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241504, "time": 7729.053683996201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241528, "time": 7729.563299655914, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241560, "time": 7730.55532002449, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 241576, "time": 7731.04358792305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242616, "time": 7762.773816585541, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 242896, "time": 7771.534707307816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243488, "time": 7789.611854553223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243592, "time": 7792.537225246429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243816, "time": 7799.3580186367035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243840, "time": 7800.318143129349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243872, "time": 7801.290233612061, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 243888, "time": 7801.780345439911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 244576, "time": 7822.570637464523, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 245208, "time": 7841.625947475433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245800, "time": 7860.204347372055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 245904, "time": 7863.62487244606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246128, "time": 7870.578938007355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246152, "time": 7871.097364187241, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246184, "time": 7872.085622549057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246200, "time": 7872.598402023315, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 246888, "time": 7893.463820934296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 247520, "time": 7912.83105134964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248112, "time": 7930.826699256897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248216, "time": 7933.743017435074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248440, "time": 7940.559102535248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248464, "time": 7941.514458179474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248496, "time": 7942.492005825043, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 248512, "time": 7942.982267856598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249200, "time": 7963.866824865341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 249832, "time": 7982.785999774933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 7993.80578660965, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.812219142914, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.8184587955475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.824114084244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.829650640488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.835268735886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.840708017349, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 7993.84624671936, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250424, "time": 8006.022036314011, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250528, "time": 8009.418339967728, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250752, "time": 8016.23468542099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250776, "time": 8016.745720863342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250808, "time": 8017.725047826767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 250824, "time": 8018.218790531158, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 251248, "time": 8031.303788900375, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 251512, "time": 8039.079426527023, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252144, "time": 8058.51787519455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 252840, "time": 8079.549374103546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253064, "time": 8086.321145057678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253088, "time": 8087.288607597351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253120, "time": 8088.2604949474335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253136, "time": 8088.752893686295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253560, "time": 8101.420526981354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 253592, "time": 8102.402191400528, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 254456, "time": 8129.125225305557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255152, "time": 8150.58705496788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255376, "time": 8157.369546890259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255400, "time": 8157.884801149368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255432, "time": 8158.856180906296, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255448, "time": 8159.342792034149, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255872, "time": 8172.48615860939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 255904, "time": 8173.453235864639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 256768, "time": 8199.816898107529, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257241, "time": 8214.961958169937, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.270930526280167, "train/action_min": 0.0, "train/action_std": 1.833061401796813, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0013739138937873378, "train/actor_opt_grad_steps": 14975.0, "train/actor_opt_loss": 3.4255742210120257, "train/adv_mag": 0.0062437939024207615, "train/adv_max": 0.005980248793517009, "train/adv_mean": 0.0008773434549852081, "train/adv_min": -0.0024314791996880333, "train/adv_std": 0.0010732974922503483, "train/cont_avg": 0.9964950108292079, "train/cont_loss_mean": 0.023246337152501143, "train/cont_loss_std": 0.31804532052385437, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.613127012642062, "train/cont_pos_acc": 0.9999999864266651, "train/cont_pos_loss": 0.0035541075740544367, "train/cont_pred": 0.9964518030681232, "train/cont_rate": 0.9964950108292079, "train/dyn_loss_mean": 1.0000056323438589, "train/dyn_loss_std": 0.00011476312935730387, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03579899204631525, "train/extr_critic_critic_opt_grad_steps": 14975.0, "train/extr_critic_critic_opt_loss": 11860.536379370358, "train/extr_critic_mag": 0.05326403780738906, "train/extr_critic_max": 0.05326403780738906, "train/extr_critic_mean": 0.05080550710790523, "train/extr_critic_min": 0.04870250378504838, "train/extr_critic_std": 0.0006395875293897502, "train/extr_return_normed_mag": 0.009328637557971005, "train/extr_return_normed_max": 0.009310532315163919, "train/extr_return_normed_mean": 0.003582508652002751, "train/extr_return_normed_min": 0.0005097441596559959, "train/extr_return_normed_std": 0.0012388468185776274, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.05741057192703875, "train/extr_return_raw_max": 0.05741057192703875, "train/extr_return_raw_mean": 0.05168255067218353, "train/extr_return_raw_min": 0.048609783789972855, "train/extr_return_raw_std": 0.0012388468180013139, "train/extr_reward_mag": 0.002016991081804332, "train/extr_reward_max": 0.002016991081804332, "train/extr_reward_mean": 0.0002815045693633953, "train/extr_reward_min": 4.5458869178696435e-06, "train/extr_reward_std": 0.0003787082947149042, "train/image_loss_mean": 0.18318991134367366, "train/image_loss_std": 0.10416449005208393, "train/model_loss_mean": 0.8079490726537043, "train/model_loss_std": 0.36718014786296554, "train/model_opt_grad_norm": 37.26417418753747, "train/model_opt_grad_steps": 14959.10891089109, "train/model_opt_loss": 2231.4397002871674, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2759.90099009901, "train/policy_entropy_mag": 1.860607890209349, "train/policy_entropy_max": 1.860607890209349, "train/policy_entropy_mean": 1.4593305103849656, "train/policy_entropy_min": 0.6087417067351317, "train/policy_entropy_std": 0.2110643878874212, "train/policy_logprob_mag": 5.42788578732179, "train/policy_logprob_max": -0.1714178112169525, "train/policy_logprob_mean": -1.459467730604776, "train/policy_logprob_min": -5.42788578732179, "train/policy_logprob_std": 0.7889297187033266, "train/policy_randomness_mag": 0.956163367127428, "train/policy_randomness_max": 0.956163367127428, "train/policy_randomness_mean": 0.7499475744691225, "train/policy_randomness_min": 0.3128313734057811, "train/policy_randomness_std": 0.10846564570202095, "train/post_ent_mag": 41.18524473964578, "train/post_ent_max": 41.18524473964578, "train/post_ent_mean": 40.708023279020104, "train/post_ent_min": 40.349546772418634, "train/post_ent_std": 0.1273801579776377, "train/prior_ent_mag": 43.08250281834366, "train/prior_ent_max": 43.08250281834366, "train/prior_ent_mean": 40.86261872017737, "train/prior_ent_min": 38.8801064255214, "train/prior_ent_std": 0.824403060249763, "train/rep_loss_mean": 1.0000056323438589, "train/rep_loss_std": 0.00011476312935730387, "train/reward_avg": 9.842674280482225e-05, "train/reward_loss_mean": 0.0015094201795129787, "train/reward_loss_std": 0.041543166707816624, "train/reward_max_data": 0.09076423197984695, "train/reward_max_pred": 0.0011924221964165716, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00015400594620046778, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.28196136413082, "train/reward_pred": 7.22302310629794e-05, "train/reward_rate": 0.00016437190594059407, "train_stats/mean_log_entropy": 1.4377921004044383, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.003415446262806654, "report/cont_loss_std": 0.0009981247130781412, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.003415446262806654, "report/cont_pred": 0.9965908527374268, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17126236855983734, "report/image_loss_std": 0.10231196135282516, "report/model_loss_mean": 0.7748785018920898, "report/model_loss_std": 0.10209089517593384, "report/post_ent_mag": 38.96485900878906, "report/post_ent_max": 38.96485900878906, "report/post_ent_mean": 38.558353424072266, "report/post_ent_min": 38.16133117675781, "report/post_ent_std": 0.13233283162117004, "report/prior_ent_mag": 39.9416389465332, "report/prior_ent_max": 39.9416389465332, "report/prior_ent_mean": 37.860294342041016, "report/prior_ent_min": 36.26524353027344, "report/prior_ent_std": 0.7714071869850159, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00020064832642674446, "report/reward_loss_std": 0.0005612679524347186, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.001828908920288086, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00020064832642674446, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 8.392427116632462e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.019328130409121513, "eval/cont_loss_std": 0.29438161849975586, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.443309307098389, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0033908700570464134, "eval/cont_pred": 0.9966120719909668, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16951662302017212, "eval/image_loss_std": 0.08967803418636322, "eval/model_loss_mean": 0.7978811860084534, "eval/model_loss_std": 0.5314033627510071, "eval/post_ent_mag": 38.944305419921875, "eval/post_ent_max": 38.944305419921875, "eval/post_ent_mean": 38.56792449951172, "eval/post_ent_min": 38.21617126464844, "eval/post_ent_std": 0.1371534913778305, "eval/prior_ent_mag": 40.531856536865234, "eval/prior_ent_max": 40.531856536865234, "eval/prior_ent_mean": 37.98735046386719, "eval/prior_ent_min": 36.28173828125, "eval/prior_ent_std": 0.8028987050056458, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0002288818359375, "eval/reward_loss_mean": 0.009036428295075893, "eval/reward_loss_std": 0.2829149663448334, "eval/reward_max_data": 0.234375, "eval/reward_max_pred": 0.0021044015884399414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00019103317754343152, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.057876586914062, "eval/reward_pred": 8.016033098101616e-05, "eval/reward_rate": 0.0009765625, "replay/size": 256737.0, "replay/inserts": 32208.0, "replay/samples": 32208.0, "replay/insert_wait_avg": 1.3068459013831362e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.014870471641665e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61168.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1462035063641295e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4315650463104, "timer/env.step_count": 4026.0, "timer/env.step_total": 37.124327421188354, "timer/env.step_frac": 0.03710831277046907, "timer/env.step_avg": 0.009221144416589258, "timer/env.step_min": 0.007540225982666016, "timer/env.step_max": 0.03530550003051758, "timer/replay._sample_count": 32208.0, "timer/replay._sample_total": 16.530515670776367, "timer/replay._sample_frac": 0.01652338475546917, "timer/replay._sample_avg": 0.0005132425382133745, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.011085748672485352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4893.0, "timer/agent.policy_total": 50.743672609329224, "timer/agent.policy_frac": 0.05072178286075997, "timer/agent.policy_avg": 0.010370666791197471, "timer/agent.policy_min": 0.008829593658447266, "timer/agent.policy_max": 0.08548331260681152, "timer/dataset_train_count": 2013.0, "timer/dataset_train_total": 0.21445703506469727, "timer/dataset_train_frac": 0.00021436452282947506, "timer/dataset_train_avg": 0.00010653603331579596, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0010745525360107422, "timer/agent.train_count": 2013.0, "timer/agent.train_total": 899.4341909885406, "timer/agent.train_frac": 0.8990461940761589, "timer/agent.train_avg": 0.4468128122148736, "timer/agent.train_min": 0.43508243560791016, "timer/agent.train_max": 0.6694633960723877, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47048306465148926, "timer/agent.report_frac": 0.0004702801081948173, "timer/agent.report_avg": 0.23524153232574463, "timer/agent.report_min": 0.22368931770324707, "timer/agent.report_max": 0.2467937469482422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050441348638108e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 32.19357180863939}
{"step": 257464, "time": 8221.471356153488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257688, "time": 8228.391719579697, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257712, "time": 8229.366321086884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257744, "time": 8230.33922624588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 257760, "time": 8230.829132795334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258184, "time": 8243.46043920517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 258216, "time": 8244.44240307808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259080, "time": 8270.667129993439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 259776, "time": 8292.0426299572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8298.838729858398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 8299.750514030457, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 260000, "time": 8302.323319196701, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 260000, "time": 8304.178413152695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8304.186205148697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8304.192149400711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8304.198745012283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8304.204886674881, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8304.210816144943, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260024, "time": 8304.726198196411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260056, "time": 8305.705236673355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260072, "time": 8306.196647882462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260288, "time": 8312.991343736649, "episode/length": 262.0, "episode/score": 0.18125000596046448, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.0}
{"step": 260528, "time": 8320.315311908722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 260568, "time": 8321.306921482086, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 261048, "time": 8335.86366224289, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 261392, "time": 8346.631874084473, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 261776, "time": 8358.310397863388, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 262112, "time": 8368.5015873909, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 262336, "time": 8375.804363965988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262368, "time": 8376.893512487411, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262384, "time": 8377.383237361908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 262464, "time": 8379.810194253922, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 262736, "time": 8388.112337589264, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 262792, "time": 8389.588976860046, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 263096, "time": 8398.831431388855, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 263360, "time": 8407.164526224136, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264088, "time": 8429.075736522675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264280, "time": 8434.974276304245, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 264384, "time": 8438.390026330948, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 264432, "time": 8439.863637208939, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 8446.203868627548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264696, "time": 8447.705637693405, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 264776, "time": 8450.141067028046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265048, "time": 8458.408647298813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265048, "time": 8458.414074897766, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 265104, "time": 8460.346935272217, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 265352, "time": 8467.736407518387, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 266304, "time": 8496.752474546432, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 266400, "time": 8499.678172111511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266696, "time": 8508.415901184082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 266960, "time": 8516.621520996094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267008, "time": 8518.097614049911, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267088, "time": 8520.51573085785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267272, "time": 8525.869626045227, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 267360, "time": 8528.806865930557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 267488, "time": 8532.670936584473, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 268616, "time": 8566.843833684921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269008, "time": 8578.965253353119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269272, "time": 8586.827761173248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269320, "time": 8588.278817892075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269392, "time": 8590.684196710587, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 269400, "time": 8590.712090969086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269584, "time": 8596.494075775146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 269672, "time": 8598.928829908371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 8612.434782981873, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 270088, "time": 8616.398061037064, "eval_episode/length": 220.0, "eval_episode/score": 0.3125, "eval_episode/reward_rate": 0.004524886877828055}
{"step": 270088, "time": 8616.874730110168, "eval_episode/length": 244.0, "eval_episode/score": 0.23749999701976776, "eval_episode/reward_rate": 0.004081632653061225}
{"step": 270088, "time": 8617.24598121643, "eval_episode/length": 263.0, "eval_episode/score": 0.17812499403953552, "eval_episode/reward_rate": 0.003787878787878788}
{"step": 270088, "time": 8617.739270925522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8617.745669841766, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8617.75195145607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8617.757742881775, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270928, "time": 8643.963193178177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271320, "time": 8655.699759721756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271584, "time": 8663.962453365326, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271632, "time": 8665.446350336075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271704, "time": 8667.411630153656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271712, "time": 8667.890363454819, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271896, "time": 8673.305715560913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 271984, "time": 8677.218571662903, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 272336, "time": 8687.991201639175, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 272344, "time": 8688.018436431885, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 272440, "time": 8690.953775167465, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 272640, "time": 8697.239035844803, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 272808, "time": 8702.117628097534, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 273160, "time": 8712.853365659714, "episode/length": 278.0, "episode/score": 0.13124999403953552, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.0}
{"step": 273208, "time": 8714.313087701797, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 273440, "time": 8721.585014820099, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 273480, "time": 8722.5864944458, "episode/length": 236.0, "episode/score": 0.26249998807907104, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.0}
{"step": 273496, "time": 8723.075448274612, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 273632, "time": 8727.435622215271, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 273832, "time": 8733.336198568344, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 274296, "time": 8747.442420482635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 274568, "time": 8755.70526599884, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 274600, "time": 8756.681152105331, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 274808, "time": 8763.02688741684, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 275176, "time": 8774.239779472351, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 275416, "time": 8781.498950719833, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 275520, "time": 8784.874514579773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275584, "time": 8786.827839136124, "episode/length": 260.0, "episode/score": 0.1875, "episode/reward_rate": 0.0038314176245210726, "episode/intrinsic_return": 0.0}
{"step": 275752, "time": 8791.696682453156, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275792, "time": 8793.145062685013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 275944, "time": 8797.638925790787, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276072, "time": 8801.529204845428, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 276240, "time": 8806.876197099686, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 276320, "time": 8809.318695306778, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 276480, "time": 8814.207628011703, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 276608, "time": 8818.14887547493, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 276912, "time": 8827.455738306046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 276952, "time": 8828.44470667839, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 277184, "time": 8835.678109884262, "episode/length": 250.0, "episode/score": 0.21875, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.0}
{"step": 277440, "time": 8843.419584035873, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 277640, "time": 8849.246873378754, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 277656, "time": 8849.736387729645, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 278256, "time": 8868.318467617035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278304, "time": 8869.76411819458, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 278456, "time": 8874.15502858162, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 278552, "time": 8877.58418560028, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278560, "time": 8878.05219912529, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 278632, "time": 8880.01492857933, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 278632, "time": 8880.021837711334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 278632, "time": 8880.027136325836, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 279040, "time": 8892.75124502182, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 279120, "time": 8895.189159154892, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 279136, "time": 8895.68033337593, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 279216, "time": 8898.137249946594, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 279400, "time": 8903.541508436203, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 279416, "time": 8904.034188270569, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 279504, "time": 8906.954617023468, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 279784, "time": 8915.25788974762, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 279952, "time": 8920.700603485107, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 280000, "time": 8922.155338525772, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 8924.59013724327, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 280072, "time": 8924.92945098877, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 280072, "time": 8924.971824884415, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 280072, "time": 8925.031754493713, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 280072, "time": 8925.359668970108, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 280072, "time": 8925.492959976196, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 280072, "time": 8925.876853227615, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 280072, "time": 8926.336454153061, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 280184, "time": 8929.744314432144, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 280184, "time": 8929.749458312988, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 280224, "time": 8931.18790769577, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 280240, "time": 8931.682186365128, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 280544, "time": 8940.902193546295, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 280544, "time": 8940.907840013504, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 280616, "time": 8942.886528730392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 280840, "time": 8949.79928278923, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 280944, "time": 8953.19003200531, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 281120, "time": 8958.5237262249, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 281200, "time": 8960.931054830551, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 281504, "time": 8970.190957546234, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 281736, "time": 8977.186785697937, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 281816, "time": 8979.632956504822, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 281816, "time": 8979.638835191727, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 281920, "time": 8983.049013853073, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 281968, "time": 8984.514254808426, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 282552, "time": 9002.05592918396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283432, "time": 9028.978814840317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 283544, "time": 9032.405024528503, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 283696, "time": 9037.36454129219, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 284048, "time": 9048.109849214554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284104, "time": 9049.59368109703, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 284128, "time": 9050.584393501282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284232, "time": 9053.518664836884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284280, "time": 9054.99953699112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 284456, "time": 9060.374930143356, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 284904, "time": 9074.11596250534, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 285152, "time": 9081.897146224976, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 285552, "time": 9094.094717502594, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 285816, "time": 9101.995748758316, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 285832, "time": 9102.487395763397, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 286008, "time": 9107.840992689133, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286360, "time": 9118.560707569122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286544, "time": 9124.3872423172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 286552, "time": 9124.415639400482, "episode/length": 283.0, "episode/score": 0.11562500149011612, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.0}
{"step": 286768, "time": 9131.72873044014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 287064, "time": 9140.514232635498, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 287104, "time": 9141.97234582901, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 287192, "time": 9144.439218759537, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 287352, "time": 9149.335450172424, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 287360, "time": 9149.80816078186, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 287472, "time": 9153.234303712845, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 287936, "time": 9167.479906082153, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 287952, "time": 9167.989862918854, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 288072, "time": 9171.420404195786, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 288072, "time": 9171.426319599152, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 288368, "time": 9180.663462877274, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 288720, "time": 9191.502549409866, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 288784, "time": 9193.474313497543, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 288864, "time": 9195.908126831055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 288960, "time": 9198.853355407715, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 288968, "time": 9198.87989282608, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 289320, "time": 9209.59865140915, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 289465, "time": 9215.019709587097, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.7134171670942164, "train/action_min": 0.0, "train/action_std": 1.8568639369746345, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00240282396020238, "train/actor_opt_grad_steps": 16990.0, "train/actor_opt_loss": 16.635731404480428, "train/adv_mag": 0.02010144808547414, "train/adv_max": 0.019979410837242258, "train/adv_mean": 0.005321105580255269, "train/adv_min": -0.004394910006380793, "train/adv_std": 0.003479016574959164, "train/cont_avg": 0.9965844605099502, "train/cont_loss_mean": 0.02221630910870188, "train/cont_loss_std": 0.30955164342022856, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.473087595934844, "train/cont_pos_acc": 0.999999985766055, "train/cont_pos_loss": 0.0035737930120557397, "train/cont_pred": 0.9964295370661798, "train/cont_rate": 0.9965844605099502, "train/dyn_loss_mean": 1.5440181232803496, "train/dyn_loss_std": 0.009920415064897412, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3586450408627534, "train/extr_critic_critic_opt_grad_steps": 16990.0, "train/extr_critic_critic_opt_loss": 10965.108108140936, "train/extr_critic_mag": 0.12802875812967024, "train/extr_critic_max": 0.12802875812967024, "train/extr_critic_mean": 0.12444452314975843, "train/extr_critic_min": 0.1184039133698193, "train/extr_critic_std": 0.0014518422288333636, "train/extr_return_normed_mag": 0.03049669677938395, "train/extr_return_normed_max": 0.030493237986345196, "train/extr_return_normed_mean": 0.014760961770517311, "train/extr_return_normed_min": 0.004091225249405524, "train/extr_return_normed_std": 0.003926271014089293, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.14549741812458086, "train/extr_return_raw_max": 0.14549741812458086, "train/extr_return_raw_mean": 0.12976514805682857, "train/extr_return_raw_min": 0.11909540538764118, "train/extr_return_raw_std": 0.003926271013799703, "train/extr_reward_mag": 0.010626698014748037, "train/extr_reward_max": 0.010626698014748037, "train/extr_reward_mean": 0.0010932289667436807, "train/extr_reward_min": 7.063595216665694e-07, "train/extr_reward_std": 0.002228311628922218, "train/image_loss_mean": 0.17158111544390817, "train/image_loss_std": 0.1063559844867507, "train/model_loss_mean": 1.1220077308849317, "train/model_loss_std": 0.36298327173907957, "train/model_opt_grad_norm": 34.37672191354173, "train/model_opt_grad_steps": 16972.402985074626, "train/model_opt_loss": 3177.857089673702, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2972.636815920398, "train/policy_entropy_mag": 1.7369875753696877, "train/policy_entropy_max": 1.7369875753696877, "train/policy_entropy_mean": 0.8857320799163325, "train/policy_entropy_min": 0.12437681483095558, "train/policy_entropy_std": 0.3223540380745385, "train/policy_logprob_mag": 6.13425433220555, "train/policy_logprob_max": -0.020635341484081093, "train/policy_logprob_mean": -0.8855940099082776, "train/policy_logprob_min": -6.13425433220555, "train/policy_logprob_std": 0.8766642930495798, "train/policy_randomness_mag": 0.8926350889514335, "train/policy_randomness_max": 0.8926350889514335, "train/policy_randomness_mean": 0.45517627650232456, "train/policy_randomness_min": 0.06391704269680218, "train/policy_randomness_std": 0.16565721444970932, "train/post_ent_mag": 39.125780551587766, "train/post_ent_max": 39.125780551587766, "train/post_ent_mean": 38.799202060225, "train/post_ent_min": 38.487127825988466, "train/post_ent_std": 0.10723191078993219, "train/prior_ent_mag": 41.490257263183594, "train/prior_ent_max": 41.490257263183594, "train/prior_ent_mean": 38.5633070457041, "train/prior_ent_min": 37.02621740844119, "train/prior_ent_std": 0.7245214181159859, "train/rep_loss_mean": 1.5440181232803496, "train/rep_loss_std": 0.009920415064897412, "train/reward_avg": 0.00014537602500290384, "train/reward_loss_mean": 0.001799428242430165, "train/reward_loss_std": 0.04588419940666961, "train/reward_max_data": 0.122185945362594, "train/reward_max_pred": 0.006073645691373455, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.0002499674587151145, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.561229159192341, "train/reward_pred": 0.00011456921054930681, "train/reward_rate": 0.00024292599502487563, "train_stats/mean_log_entropy": 0.7893148443278144, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.01923244632780552, "report/cont_loss_std": 0.2610554099082947, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.819944381713867, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005126533564180136, "report/cont_pred": 0.9948822259902954, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.17090442776679993, "report/image_loss_std": 0.11530172824859619, "report/model_loss_mean": 0.7903575897216797, "report/model_loss_std": 0.28604164719581604, "report/post_ent_mag": 45.21112823486328, "report/post_ent_max": 45.21112823486328, "report/post_ent_mean": 44.65308380126953, "report/post_ent_min": 44.194419860839844, "report/post_ent_std": 0.17632395029067993, "report/prior_ent_mag": 49.137184143066406, "report/prior_ent_max": 49.137184143066406, "report/prior_ent_mean": 45.113319396972656, "report/prior_ent_min": 43.15354919433594, "report/prior_ent_std": 0.8143624663352966, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00022067595273256302, "report/reward_loss_std": 0.0011675443965941668, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.008041143417358398, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00022067595273256302, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 9.402201976627111e-05, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.030035827308893204, "eval/cont_loss_std": 0.358366459608078, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.135182857513428, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004986040759831667, "eval/cont_pred": 0.9950256943702698, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19621482491493225, "eval/image_loss_std": 0.11177649348974228, "eval/model_loss_mean": 0.8382452726364136, "eval/model_loss_std": 0.5775344371795654, "eval/post_ent_mag": 45.14680862426758, "eval/post_ent_max": 45.14680862426758, "eval/post_ent_mean": 44.66093063354492, "eval/post_ent_min": 44.25448989868164, "eval/post_ent_std": 0.1691201627254486, "eval/prior_ent_mag": 51.00140380859375, "eval/prior_ent_max": 51.00140380859375, "eval/prior_ent_mean": 45.176361083984375, "eval/prior_ent_min": 43.04291534423828, "eval/prior_ent_std": 0.9689785838127136, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0013671874767169356, "eval/reward_loss_mean": 0.011994551867246628, "eval/reward_loss_std": 0.2665986716747284, "eval/reward_max_data": 0.699999988079071, "eval/reward_max_pred": 0.009749412536621094, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00021847820607945323, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.029568672180176, "eval/reward_pred": 9.932357352226973e-05, "eval/reward_rate": 0.001953125, "replay/size": 288961.0, "replay/inserts": 32224.0, "replay/samples": 32224.0, "replay/insert_wait_avg": 1.3285931551231528e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.161160299534121e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66664.0, "eval_replay/inserts": 5496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2051503904695247e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0455124378204, "timer/env.step_count": 4028.0, "timer/env.step_total": 37.688299894332886, "timer/env.step_frac": 0.0376865846859907, "timer/env.step_avg": 0.009356578921135275, "timer/env.step_min": 0.007652759552001953, "timer/env.step_max": 0.035709381103515625, "timer/replay._sample_count": 32224.0, "timer/replay._sample_total": 16.630128145217896, "timer/replay._sample_frac": 0.01662937130199052, "timer/replay._sample_avg": 0.0005160789518749347, "timer/replay._sample_min": 0.0004024505615234375, "timer/replay._sample_max": 0.0317533016204834, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4715.0, "timer/agent.policy_total": 49.527827978134155, "timer/agent.policy_frac": 0.0495255739485293, "timer/agent.policy_avg": 0.010504311342128135, "timer/agent.policy_min": 0.00890040397644043, "timer/agent.policy_max": 0.13990354537963867, "timer/dataset_train_count": 2014.0, "timer/dataset_train_total": 0.21813178062438965, "timer/dataset_train_frac": 0.000218121853367101, "timer/dataset_train_avg": 0.00010830773615908125, "timer/dataset_train_min": 9.489059448242188e-05, "timer/dataset_train_max": 0.002145528793334961, "timer/agent.train_count": 2014.0, "timer/agent.train_total": 900.6297652721405, "timer/agent.train_frac": 0.9005887772814127, "timer/agent.train_avg": 0.4471845905025524, "timer/agent.train_min": 0.4354057312011719, "timer/agent.train_max": 1.3636744022369385, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4702119827270508, "timer/agent.report_frac": 0.0004701905832073688, "timer/agent.report_avg": 0.2351059913635254, "timer/agent.report_min": 0.22504711151123047, "timer/agent.report_max": 0.2451648712158203, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9800966073079924e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 32.222023521107815}
{"step": 289488, "time": 9215.663174390793, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 289504, "time": 9216.328216552734, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 289664, "time": 9221.22763967514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290024, "time": 9231.977158784866, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 9233.936540603638, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 290056, "time": 9234.094469547272, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 290056, "time": 9234.234046936035, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 290056, "time": 9235.104679346085, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 290056, "time": 9235.109374761581, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 290056, "time": 9235.774124860764, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 290056, "time": 9235.853178977966, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 290056, "time": 9236.330736637115, "eval_episode/length": 171.0, "eval_episode/score": 0.46562498807907104, "eval_episode/reward_rate": 0.005813953488372093}
{"step": 290264, "time": 9242.67017030716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 290352, "time": 9245.592159509659, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 290712, "time": 9256.507491588593, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 290912, "time": 9262.857385158539, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 290920, "time": 9262.890534162521, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 291008, "time": 9265.836282968521, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 291176, "time": 9270.751807451248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291272, "time": 9273.685516357422, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291280, "time": 9274.156170368195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291536, "time": 9282.062373876572, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 291592, "time": 9283.543812274933, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 291632, "time": 9285.014791965485, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 291808, "time": 9290.414028644562, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 291880, "time": 9292.383778572083, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 291976, "time": 9295.32742524147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 292408, "time": 9308.629838228226, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 292576, "time": 9313.992924928665, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 292584, "time": 9314.020288228989, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 292616, "time": 9315.021317005157, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 292680, "time": 9316.985229969025, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 292696, "time": 9317.479602098465, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 293240, "time": 9334.067444324493, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 293384, "time": 9338.569212436676, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 293528, "time": 9342.968099355698, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 293672, "time": 9347.35978102684, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 293944, "time": 9355.670657873154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294192, "time": 9363.485362529755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294240, "time": 9364.955074310303, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 294552, "time": 9374.302049398422, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 294672, "time": 9378.189024686813, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 294688, "time": 9378.676201820374, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 294720, "time": 9379.652149915695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 294832, "time": 9383.083058595657, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 294896, "time": 9385.024862289429, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 295072, "time": 9390.87456703186, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 295120, "time": 9392.335016965866, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 295128, "time": 9392.361283779144, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 295400, "time": 9400.792925834656, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 295472, "time": 9403.221275091171, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 295568, "time": 9406.14491057396, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 295840, "time": 9414.438308954239, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 295896, "time": 9415.925018072128, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 295984, "time": 9418.840590953827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 296104, "time": 9422.269096136093, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 297000, "time": 9449.633365392685, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 297208, "time": 9456.063750505447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297712, "time": 9471.684670209885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 297880, "time": 9476.595628976822, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298064, "time": 9482.431999921799, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 298152, "time": 9484.888816833496, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298168, "time": 9485.381651163101, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 298208, "time": 9486.930381298065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298296, "time": 9489.389858007431, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 298528, "time": 9496.721800804138, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 298576, "time": 9498.199447393417, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 298728, "time": 9502.61157464981, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 298888, "time": 9507.47890162468, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 299104, "time": 9514.3090736866, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 299288, "time": 9519.798751354218, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 299288, "time": 9519.806057691574, "episode/length": 285.0, "episode/score": 0.109375, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.0}
{"step": 299960, "time": 9540.224521875381, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 300016, "time": 9542.146271467209, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 9543.22117638588, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 300040, "time": 9543.352309942245, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 300040, "time": 9543.89051246643, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 300040, "time": 9543.967387914658, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 300040, "time": 9544.657932519913, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 300040, "time": 9544.896473884583, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 300040, "time": 9544.975674390793, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 300040, "time": 9545.183198451996, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 300112, "time": 9547.70210814476, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 300160, "time": 9549.175233364105, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 300416, "time": 9556.95930147171, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 300520, "time": 9559.919083118439, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300840, "time": 9569.676078796387, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 300888, "time": 9571.140732765198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 301216, "time": 9581.47755241394, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 301352, "time": 9585.411779880524, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 301400, "time": 9586.903383255005, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 301632, "time": 9594.189721822739, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 301864, "time": 9601.047331094742, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 301936, "time": 9603.460368871689, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 302080, "time": 9607.932356357574, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 302272, "time": 9613.748458623886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302392, "time": 9617.147298574448, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 302728, "time": 9627.267361879349, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 302832, "time": 9630.643855571747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 303184, "time": 9641.773926496506, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 303192, "time": 9641.801591396332, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 303208, "time": 9642.289216518402, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 303248, "time": 9643.718958616257, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 303400, "time": 9648.127543449402, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 303520, "time": 9652.021336317062, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 303640, "time": 9655.469507694244, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 303656, "time": 9655.962961435318, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 303664, "time": 9656.441576004028, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 303712, "time": 9657.910276174545, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 304008, "time": 9666.815933704376, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 304144, "time": 9671.209994077682, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 304312, "time": 9676.113465547562, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 304448, "time": 9680.482278823853, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 304600, "time": 9684.885894298553, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 304720, "time": 9688.758295536041, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 304968, "time": 9696.217534065247, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 305056, "time": 9699.112309217453, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 305280, "time": 9705.94125175476, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 305592, "time": 9715.25019288063, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 305768, "time": 9720.610379695892, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 305776, "time": 9721.079652547836, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 305832, "time": 9722.555655002594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305952, "time": 9726.509593725204, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 305968, "time": 9727.006184101105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306176, "time": 9733.311838388443, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 306184, "time": 9733.339745283127, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 306216, "time": 9734.329581737518, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 306448, "time": 9741.603417634964, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 306608, "time": 9746.483161687851, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 306760, "time": 9750.921163797379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 306872, "time": 9754.347785949707, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 306944, "time": 9756.858989238739, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 306992, "time": 9758.338211774826, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 307088, "time": 9761.226536989212, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 307216, "time": 9765.099160194397, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 307368, "time": 9769.471703529358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 307384, "time": 9769.961721420288, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 307472, "time": 9772.867096662521, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 307544, "time": 9774.834228515625, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 307576, "time": 9775.808836460114, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 307696, "time": 9779.69816827774, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 307776, "time": 9782.117183923721, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 308008, "time": 9789.016483306885, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 308064, "time": 9790.938047170639, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 308112, "time": 9792.407330989838, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 308240, "time": 9796.259814500809, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 308264, "time": 9796.768310785294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 308376, "time": 9800.161879777908, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 308584, "time": 9806.455159187317, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 308864, "time": 9815.134788274765, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 308920, "time": 9816.73537516594, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 308936, "time": 9817.224290847778, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 309024, "time": 9820.129957437515, "episode/length": 12.0, "episode/score": 0.9624999761581421, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.0}
{"step": 309504, "time": 9834.794642686844, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 309520, "time": 9835.288949489594, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 309720, "time": 9841.189572811127, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 309856, "time": 9845.54417014122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310008, "time": 9850.105335235596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 9851.012876987457, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 310024, "time": 9851.428379535675, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 310024, "time": 9851.510350942612, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 310024, "time": 9851.594102621078, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 310024, "time": 9852.055112600327, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 310024, "time": 9852.24716591835, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 310024, "time": 9853.724954366684, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 310024, "time": 9854.026771068573, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 310240, "time": 9860.852579593658, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 310424, "time": 9866.252702713013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 310608, "time": 9872.076583623886, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 310640, "time": 9873.051555156708, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 310688, "time": 9874.540521860123, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311336, "time": 9894.597339868546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311512, "time": 9899.930124759674, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 311816, "time": 9909.212757110596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311832, "time": 9909.704373836517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 311928, "time": 9912.619116783142, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 312320, "time": 9924.840589046478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312360, "time": 9925.834203004837, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 312560, "time": 9932.161999940872, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 312560, "time": 9932.167524814606, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 312912, "time": 9943.034141778946, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 312920, "time": 9943.060201406479, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 312920, "time": 9943.067054271698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 312936, "time": 9943.556204557419, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 312952, "time": 9944.048379659653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313000, "time": 9945.51190161705, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 313192, "time": 9951.35702419281, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 313248, "time": 9953.308800935745, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 313672, "time": 9966.054735898972, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 313696, "time": 9967.010845899582, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 313832, "time": 9970.937554836273, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 314016, "time": 9976.759416103363, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 314416, "time": 9989.00657916069, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 314632, "time": 9995.346579790115, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 314672, "time": 9996.899189710617, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 314768, "time": 9999.822952985764, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 314872, "time": 10002.767114639282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315224, "time": 10013.468271493912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315312, "time": 10016.38924908638, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 315424, "time": 10019.792340993881, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 315440, "time": 10020.284828186035, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 315560, "time": 10023.725685119629, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316728, "time": 10059.38993191719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316984, "time": 10067.211833238602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 316992, "time": 10067.687072515488, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 317000, "time": 10067.714261770248, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 317184, "time": 10073.55879664421, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317536, "time": 10084.323990106583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317752, "time": 10090.742369651794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 317872, "time": 10094.62072467804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 318320, "time": 10108.310442686081, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 318480, "time": 10113.218931436539, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 318640, "time": 10118.149582624435, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 318656, "time": 10118.638946294785, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 318800, "time": 10122.989670991898, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 318880, "time": 10125.413233280182, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 318928, "time": 10126.865433216095, "episode/length": 274.0, "episode/score": 0.14374999701976776, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.0}
{"step": 319304, "time": 10138.060225486755, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319312, "time": 10138.550382852554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 319432, "time": 10141.953142642975, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 319840, "time": 10155.102503299713, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 319904, "time": 10157.042311668396, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 10161.500644683838, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 320008, "time": 10161.614968538284, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 320008, "time": 10162.8847386837, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 320008, "time": 10162.90883398056, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 320008, "time": 10163.348041534424, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 320008, "time": 10164.44336605072, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 320008, "time": 10165.191103219986, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 320008, "time": 10165.444785833359, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10165.450934886932, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10165.45659995079, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10165.46198296547, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10165.467583417892, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320064, "time": 10167.385079145432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 320384, "time": 10177.221330404282, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 320480, "time": 10180.154108047485, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 320488, "time": 10180.180958271027, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 320768, "time": 10188.999173879623, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 320832, "time": 10190.935093641281, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 320968, "time": 10194.857434272766, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321176, "time": 10201.202283382416, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 321200, "time": 10202.170115232468, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 321240, "time": 10203.188395261765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321408, "time": 10208.642637491226, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 321601, "time": 10215.03063416481, "train_stats/mean_log_entropy": 0.1787671754805095, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.294450598569652, "train/action_min": 0.0, "train/action_std": 1.7533357831376108, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004318974015015683, "train/actor_opt_grad_steps": 19000.0, "train/actor_opt_loss": 13.987088960882703, "train/adv_mag": 0.10466090815873881, "train/adv_max": 0.05484895586077847, "train/adv_mean": 0.010237692096644192, "train/adv_min": -0.07108614026610531, "train/adv_std": 0.009075248964357917, "train/cont_avg": 0.996132618159204, "train/cont_loss_mean": 0.022563273995299244, "train/cont_loss_std": 0.30236710716659826, "train/cont_neg_acc": 0.014777778089046479, "train/cont_neg_loss": 4.871891198158264, "train/cont_pos_acc": 0.9999902248382568, "train/cont_pos_loss": 0.0038187775016062667, "train/cont_pred": 0.996110206516228, "train/cont_rate": 0.996132618159204, "train/dyn_loss_mean": 1.0000201635692842, "train/dyn_loss_std": 0.0005690619496157189, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6910864705340335, "train/extr_critic_critic_opt_grad_steps": 19000.0, "train/extr_critic_critic_opt_loss": 10204.850488767102, "train/extr_critic_mag": 0.4297962414091499, "train/extr_critic_max": 0.4297962414091499, "train/extr_critic_mean": 0.4207196095541342, "train/extr_critic_min": 0.4038512084021497, "train/extr_critic_std": 0.004285836973707122, "train/extr_return_normed_mag": 0.12397825250874704, "train/extr_return_normed_max": 0.08023996161880778, "train/extr_return_normed_mean": 0.03145614549962442, "train/extr_return_normed_min": -0.051143245095044226, "train/extr_return_normed_std": 0.010562940582920292, "train/extr_return_rate": 0.2752659312660869, "train/extr_return_raw_mag": 0.47974152662860814, "train/extr_return_raw_max": 0.47974152662860814, "train/extr_return_raw_mean": 0.430957733250376, "train/extr_return_raw_min": 0.34835831991475613, "train/extr_return_raw_std": 0.010562940574811762, "train/extr_reward_mag": 0.04534082685537006, "train/extr_reward_max": 0.04534082685537006, "train/extr_reward_mean": 0.0025618882781469183, "train/extr_reward_min": -4.143560703714096e-05, "train/extr_reward_std": 0.006165997470400079, "train/image_loss_mean": 0.1536488806949326, "train/image_loss_std": 0.1083547811751342, "train/model_loss_mean": 0.7806291467514798, "train/model_loss_std": 0.3886320347809673, "train/model_opt_grad_norm": 33.46352541923523, "train/model_opt_grad_steps": 18980.621890547263, "train/model_opt_loss": 2138.148985298119, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 2736.318407960199, "train/policy_entropy_mag": 1.5331725291351774, "train/policy_entropy_max": 1.5331725291351774, "train/policy_entropy_mean": 0.2134562721892969, "train/policy_entropy_min": 0.06476355340350326, "train/policy_entropy_std": 0.2466603017120219, "train/policy_logprob_mag": 6.550827671639362, "train/policy_logprob_max": -0.008620220950030866, "train/policy_logprob_mean": -0.21397491170102684, "train/policy_logprob_min": -6.550827671639362, "train/policy_logprob_std": 0.7526113714151714, "train/policy_randomness_mag": 0.7878948678424702, "train/policy_randomness_max": 0.7878948678424702, "train/policy_randomness_mean": 0.10969483014659502, "train/policy_randomness_min": 0.03328188467974687, "train/policy_randomness_std": 0.1267583279763881, "train/post_ent_mag": 40.3316553220227, "train/post_ent_max": 40.3316553220227, "train/post_ent_mean": 39.85447763091889, "train/post_ent_min": 39.50708053361124, "train/post_ent_std": 0.1394634633811552, "train/prior_ent_mag": 46.43497975667318, "train/prior_ent_max": 46.43497975667318, "train/prior_ent_mean": 42.72682222205015, "train/prior_ent_min": 40.66892037462832, "train/prior_ent_std": 0.8109260070976333, "train/rep_loss_mean": 1.0000201635692842, "train/rep_loss_std": 0.0005690619496157189, "train/reward_avg": 0.00045216119019528945, "train/reward_loss_mean": 0.004404870255743687, "train/reward_loss_std": 0.09687330053577116, "train/reward_max_data": 0.32992848194208907, "train/reward_max_pred": 0.019594385849302683, "train/reward_neg_acc": 0.9999951313977218, "train/reward_neg_loss": 0.0006847729233069814, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.178271076895974, "train/reward_pred": 0.0003355648478641365, "train/reward_rate": 0.0007142024253731343, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.02747761830687523, "report/cont_loss_std": 0.3330731689929962, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.744828224182129, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004330655559897423, "report/cont_pred": 0.9956729412078857, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11748203635215759, "report/image_loss_std": 0.08977418392896652, "report/model_loss_mean": 0.7453604936599731, "report/model_loss_std": 0.3439749479293823, "report/post_ent_mag": 36.484962463378906, "report/post_ent_max": 36.484962463378906, "report/post_ent_mean": 36.055870056152344, "report/post_ent_min": 35.808746337890625, "report/post_ent_std": 0.1259801834821701, "report/prior_ent_mag": 42.76845169067383, "report/prior_ent_max": 42.76845169067383, "report/prior_ent_mean": 39.877716064453125, "report/prior_ent_min": 37.909481048583984, "report/prior_ent_std": 0.7801093459129333, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.00040085986256599426, "report/reward_loss_std": 0.0034160097129642963, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.027346134185791016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00040085986256599426, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00019879930187016726, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03723207488656044, "eval/cont_loss_std": 0.473038911819458, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.7292022705078125, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004396111238747835, "eval/cont_pred": 0.9956550598144531, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0004777908325195, "eval/dyn_loss_std": 0.01340289507061243, "eval/image_loss_mean": 0.22114720940589905, "eval/image_loss_std": 0.1294907182455063, "eval/model_loss_mean": 0.8588254451751709, "eval/model_loss_std": 0.48752984404563904, "eval/post_ent_mag": 36.49136734008789, "eval/post_ent_max": 36.49136734008789, "eval/post_ent_mean": 36.05812072753906, "eval/post_ent_min": 35.787227630615234, "eval/post_ent_std": 0.11795105785131454, "eval/prior_ent_mag": 45.970542907714844, "eval/prior_ent_max": 45.970542907714844, "eval/prior_ent_mean": 39.986942291259766, "eval/prior_ent_min": 37.56465148925781, "eval/prior_ent_std": 0.8304054141044617, "eval/rep_loss_mean": 1.0004777908325195, "eval/rep_loss_std": 0.01340289507061243, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001594768837094307, "eval/reward_loss_std": 0.001615275046788156, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.021395206451416016, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001594768837094307, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 7.9411081969738e-05, "eval/reward_rate": 0.0, "replay/size": 321097.0, "replay/inserts": 32136.0, "replay/samples": 32128.0, "replay/insert_wait_avg": 1.3303320473748592e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.789492963319756e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 72840.0, "eval_replay/inserts": 6176.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2005857853074147e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.994811296463, "timer/env.step_count": 4017.0, "timer/env.step_total": 37.78127408027649, "timer/env.step_frac": 0.03778147011712412, "timer/env.step_avg": 0.00940534580041735, "timer/env.step_min": 0.0076062679290771484, "timer/env.step_max": 0.03478860855102539, "timer/replay._sample_count": 32128.0, "timer/replay._sample_total": 16.03674626350403, "timer/replay._sample_frac": 0.01603682947385784, "timer/replay._sample_avg": 0.000499151713878985, "timer/replay._sample_min": 0.0003871917724609375, "timer/replay._sample_max": 0.030818462371826172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4789.0, "timer/agent.policy_total": 49.831246852874756, "timer/agent.policy_frac": 0.04983150541378315, "timer/agent.policy_avg": 0.010405355367065099, "timer/agent.policy_min": 0.008438348770141602, "timer/agent.policy_max": 0.0824747085571289, "timer/dataset_train_count": 2008.0, "timer/dataset_train_total": 0.2130908966064453, "timer/dataset_train_frac": 0.00021309200227767123, "timer/dataset_train_avg": 0.00010612096444544089, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0003516674041748047, "timer/agent.train_count": 2008.0, "timer/agent.train_total": 899.2434611320496, "timer/agent.train_frac": 0.899248127063987, "timer/agent.train_avg": 0.44783040893030357, "timer/agent.train_min": 0.43537020683288574, "timer/agent.train_max": 0.6694188117980957, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4781501293182373, "timer/agent.report_frac": 0.0004781526103103776, "timer/agent.report_avg": 0.23907506465911865, "timer/agent.report_min": 0.23239684104919434, "timer/agent.report_max": 0.24575328826904297, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1948255369635015e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.1356731271213}
{"step": 321744, "time": 10219.583574295044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 321976, "time": 10226.383304595947, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 322152, "time": 10231.737787723541, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 322280, "time": 10235.641277551651, "episode/length": 223.0, "episode/score": 0.3031249940395355, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.0}
{"step": 322696, "time": 10248.411430835724, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 322928, "time": 10255.720297574997, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 323144, "time": 10262.094180583954, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 323144, "time": 10262.101264476776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323232, "time": 10265.020317554474, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 323240, "time": 10265.047516822815, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 323488, "time": 10272.97397351265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 323560, "time": 10274.942744731903, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 323720, "time": 10279.829893112183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 324272, "time": 10296.966707229614, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 324320, "time": 10298.414128541946, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 324480, "time": 10303.268703460693, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 324544, "time": 10305.207753658295, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 324704, "time": 10310.065536260605, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 325008, "time": 10319.272385120392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325216, "time": 10325.659672737122, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 325240, "time": 10326.25358915329, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325456, "time": 10333.025321483612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325456, "time": 10333.032530069351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 325992, "time": 10349.1654047966, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 326016, "time": 10350.129354000092, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 326304, "time": 10359.06680560112, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 326632, "time": 10368.86405801773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326640, "time": 10369.340521812439, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 326792, "time": 10373.767232894897, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 326792, "time": 10373.775413274765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 326832, "time": 10375.23959493637, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 327016, "time": 10380.64756155014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327320, "time": 10390.025453329086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 327456, "time": 10394.383176803589, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 327480, "time": 10394.917288780212, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 327512, "time": 10395.895844459534, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 327632, "time": 10399.779484033585, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 327768, "time": 10404.151632547379, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 328464, "time": 10425.78161907196, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 329144, "time": 10446.422793626785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329328, "time": 10452.238158226013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329632, "time": 10461.52401638031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329792, "time": 10466.413618564606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329824, "time": 10467.393294811249, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 329944, "time": 10470.856730222702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330080, "time": 10475.253876209259, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 10477.772276163101, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 330096, "time": 10477.856288671494, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 330096, "time": 10478.570051908493, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 330096, "time": 10481.908285140991, "eval_episode/length": 285.0, "eval_episode/score": 0.109375, "eval_episode/reward_rate": 0.0034965034965034965}
{"step": 330096, "time": 10481.971484661102, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10481.977577924728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10481.983243703842, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10481.988927602768, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330520, "time": 10494.679310560226, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 330776, "time": 10502.469157218933, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 330928, "time": 10507.40646648407, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 331312, "time": 10519.102800130844, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 331456, "time": 10523.476388216019, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 331568, "time": 10526.893760919571, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 331640, "time": 10528.889132261276, "episode/length": 226.0, "episode/score": 0.29374998807907104, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.0}
{"step": 331688, "time": 10530.349012851715, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 332104, "time": 10543.097776651382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 332440, "time": 10553.348716259003, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 332456, "time": 10553.838561058044, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 332680, "time": 10560.661969661713, "episode/length": 269.0, "episode/score": 0.15937499701976776, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.0}
{"step": 332848, "time": 10566.109850406647, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 333296, "time": 10579.763970851898, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 333296, "time": 10579.77054476738, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 333312, "time": 10580.269883394241, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 333864, "time": 10596.959325551987, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 333880, "time": 10597.472841978073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 333952, "time": 10599.876807689667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334416, "time": 10613.942303419113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334424, "time": 10613.969807386398, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 334752, "time": 10624.164031267166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 334992, "time": 10631.578387975693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335320, "time": 10641.367861032486, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 335624, "time": 10650.620923995972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 335960, "time": 10661.361468315125, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 336048, "time": 10664.267868041992, "episode/length": 270.0, "episode/score": 0.15625, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.0}
{"step": 336080, "time": 10665.241006612778, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 336232, "time": 10669.631842851639, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 336264, "time": 10670.599979162216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 336600, "time": 10680.803298473358, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 336736, "time": 10685.128708600998, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337008, "time": 10693.489772558212, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 337064, "time": 10694.970400571823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337560, "time": 10710.028417348862, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 337632, "time": 10712.424268722534, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 337792, "time": 10717.348049402237, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 337936, "time": 10721.694484472275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 337960, "time": 10722.21020245552, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 338272, "time": 10731.831630468369, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338392, "time": 10735.268983125687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338576, "time": 10741.061924695969, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 338864, "time": 10749.868476867676, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 339072, "time": 10756.181716680527, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 339280, "time": 10762.516659021378, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 339320, "time": 10763.525641918182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 339440, "time": 10767.387661933899, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 339456, "time": 10767.876383066177, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 339712, "time": 10775.66796040535, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 10788.070611715317, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 340080, "time": 10789.33924627304, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 340080, "time": 10789.567476987839, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 340080, "time": 10791.83447933197, "eval_episode/length": 268.0, "eval_episode/score": 0.16249999403953552, "eval_episode/reward_rate": 0.0037174721189591076}
{"step": 340080, "time": 10792.209270477295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10792.215938568115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10792.221168518066, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 10792.226907014847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340104, "time": 10792.732682943344, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340248, "time": 10797.091325759888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340584, "time": 10807.38224864006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 340776, "time": 10813.220787525177, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 340824, "time": 10814.684828042984, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 341184, "time": 10825.862107276917, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 341552, "time": 10837.179498434067, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 341592, "time": 10838.172024965286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341768, "time": 10843.560855150223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 341848, "time": 10845.993481636047, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 341872, "time": 10846.972016096115, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 342024, "time": 10851.355083465576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342520, "time": 10866.496050357819, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 342736, "time": 10873.263462781906, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 342896, "time": 10878.11770105362, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 342928, "time": 10879.091394901276, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 343136, "time": 10885.438217878342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343496, "time": 10896.277995347977, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 343528, "time": 10897.261944055557, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 343656, "time": 10901.18994307518, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 344032, "time": 10912.861923456192, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 344144, "time": 10916.771278142929, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 344160, "time": 10917.271195411682, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344184, "time": 10917.794507741928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 344832, "time": 10937.872400045395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345192, "time": 10948.590647935867, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 345208, "time": 10949.084580421448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 345232, "time": 10950.062173604965, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 345648, "time": 10962.793993473053, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 345816, "time": 10967.675473690033, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 345840, "time": 10968.626053333282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346160, "time": 10978.379931926727, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 346328, "time": 10983.273838758469, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 346344, "time": 10983.76616692543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346424, "time": 10986.275399208069, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 346456, "time": 10987.255489110947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 346616, "time": 10992.136373996735, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 346824, "time": 10998.447013378143, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 347072, "time": 11006.20606970787, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 347256, "time": 11011.553447008133, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 347280, "time": 11012.512367486954, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 347624, "time": 11022.832557678223, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 347768, "time": 11027.220454216003, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 348088, "time": 11036.983957529068, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 348128, "time": 11038.455870389938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348152, "time": 11038.971580028534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348512, "time": 11050.210809707642, "episode/length": 210.0, "episode/score": 0.34375, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.0}
{"step": 348656, "time": 11054.598107337952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348672, "time": 11055.089283943176, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 348760, "time": 11057.551082849503, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 348768, "time": 11058.021926403046, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 348808, "time": 11059.019051074982, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 349760, "time": 11088.45771408081, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 349784, "time": 11088.97220659256, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 349936, "time": 11093.852236270905, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 11098.35314297676, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 350064, "time": 11099.446779727936, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 350064, "time": 11099.529809474945, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 350064, "time": 11099.936379432678, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 350064, "time": 11101.30406165123, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 350064, "time": 11101.462364196777, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 350064, "time": 11101.600771188736, "eval_episode/length": 200.0, "eval_episode/score": 0.375, "eval_episode/reward_rate": 0.004975124378109453}
{"step": 350064, "time": 11102.117856025696, "eval_episode/length": 227.0, "eval_episode/score": 0.2906250059604645, "eval_episode/reward_rate": 0.0043859649122807015}
{"step": 350392, "time": 11111.943697214127, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 350408, "time": 11112.4373421669, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 350424, "time": 11112.928452730179, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 350440, "time": 11113.421790838242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350464, "time": 11114.382287502289, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 350520, "time": 11115.882141113281, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 350840, "time": 11125.610230922699, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 350848, "time": 11126.077032089233, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 351080, "time": 11132.876373767853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 351120, "time": 11134.322332143784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352736, "time": 11184.321860551834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352752, "time": 11184.835482120514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352776, "time": 11185.353702783585, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 352832, "time": 11187.276744127274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353152, "time": 11197.183579921722, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353160, "time": 11197.21216058731, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353392, "time": 11205.570769071579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353432, "time": 11206.56972694397, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 353689, "time": 11215.327649354935, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.5399301147460935, "train/action_min": 0.0, "train/action_std": 1.8083461815118789, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013987522361567244, "train/actor_opt_grad_steps": 21005.0, "train/actor_opt_loss": 7.612116513426299, "train/adv_mag": 0.5264407154917717, "train/adv_max": 0.2691315078735352, "train/adv_mean": 0.0114026893141272, "train/adv_min": -0.47191627711057665, "train/adv_std": 0.03948191420175135, "train/cont_avg": 0.9958544921875, "train/cont_loss_mean": 0.0204397881712066, "train/cont_loss_std": 0.272435592552647, "train/cont_neg_acc": 0.10631313272798905, "train/cont_neg_loss": 3.9896055681235865, "train/cont_pos_acc": 0.9998431205749512, "train/cont_pos_loss": 0.003824028626549989, "train/cont_pred": 0.9958781090378761, "train/cont_rate": 0.9958544921875, "train/dyn_loss_mean": 1.0000137132406235, "train/dyn_loss_std": 0.0003882573622649943, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1764233236014843, "train/extr_critic_critic_opt_grad_steps": 21005.0, "train/extr_critic_critic_opt_loss": 11881.020288085938, "train/extr_critic_mag": 0.7419186234474182, "train/extr_critic_max": 0.7419186234474182, "train/extr_critic_mean": 0.7215629488229751, "train/extr_critic_min": 0.6922768586874009, "train/extr_critic_std": 0.00922139836475253, "train/extr_return_normed_mag": 0.5145090273022652, "train/extr_return_normed_max": 0.31323795050382613, "train/extr_return_normed_mean": 0.0451975264691282, "train/extr_return_normed_min": -0.43110313057899474, "train/extr_return_normed_std": 0.041211122749373316, "train/extr_return_rate": 0.9957344111800194, "train/extr_return_raw_mag": 1.0010068362951279, "train/extr_return_raw_max": 1.0010068362951279, "train/extr_return_raw_mean": 0.7329664552211761, "train/extr_return_raw_min": 0.256665755212307, "train/extr_return_raw_std": 0.04121112290304154, "train/extr_reward_mag": 0.2892916488647461, "train/extr_reward_max": 0.2892916488647461, "train/extr_reward_mean": 0.0037861806167347823, "train/extr_reward_min": 2.7954578399658205e-07, "train/extr_reward_std": 0.01674919827375561, "train/image_loss_mean": 0.13588050283491612, "train/image_loss_std": 0.10915276981890201, "train/model_loss_mean": 0.7626078087091446, "train/model_loss_std": 0.39105390805751084, "train/model_opt_grad_norm": 30.61905693054199, "train/model_opt_grad_steps": 20984.43, "train/model_opt_loss": 2680.0758459472654, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3512.5, "train/policy_entropy_mag": 1.5301423239707947, "train/policy_entropy_max": 1.5301423239707947, "train/policy_entropy_mean": 0.19536752600222826, "train/policy_entropy_min": 0.06469278726726771, "train/policy_entropy_std": 0.233187672495842, "train/policy_logprob_mag": 6.551064999103546, "train/policy_logprob_max": -0.008609267584979534, "train/policy_logprob_mean": -0.19561391826719046, "train/policy_logprob_min": -6.551064999103546, "train/policy_logprob_std": 0.7284418618679047, "train/policy_randomness_mag": 0.7863376483321189, "train/policy_randomness_max": 0.7863376483321189, "train/policy_randomness_mean": 0.10039905302226543, "train/policy_randomness_min": 0.03324551811441779, "train/policy_randomness_std": 0.11983476497232914, "train/post_ent_mag": 34.554935207366945, "train/post_ent_max": 34.554935207366945, "train/post_ent_mean": 34.1368776512146, "train/post_ent_min": 33.87470407485962, "train/post_ent_std": 0.11603390123695136, "train/prior_ent_mag": 39.38307319641113, "train/prior_ent_max": 39.38307319641113, "train/prior_ent_mean": 35.64666850090027, "train/prior_ent_min": 33.13426392555237, "train/prior_ent_std": 0.9873257014155388, "train/rep_loss_mean": 1.0000137132406235, "train/rep_loss_std": 0.0003882573622649943, "train/reward_avg": 0.0006940765409672167, "train/reward_loss_mean": 0.006279264314216561, "train/reward_loss_std": 0.13056194995035184, "train/reward_max_data": 0.4702656254172325, "train/reward_max_pred": 0.058968944549560545, "train/reward_neg_acc": 0.9999217677116394, "train/reward_neg_loss": 0.0010289960062800673, "train/reward_pos_acc": 0.06617647080737002, "train/reward_pos_loss": 4.822893096243634, "train/reward_pred": 0.0005261508247349411, "train/reward_rate": 0.0010791015625, "train_stats/mean_log_entropy": 0.17415661555493162, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.012386113405227661, "report/cont_loss_std": 0.20228442549705505, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 4.395254611968994, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038090720772743225, "report/cont_pred": 0.996245265007019, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0999768078327179, "report/image_loss_std": 0.09244263172149658, "report/model_loss_mean": 0.7209768295288086, "report/model_loss_std": 0.4415976405143738, "report/post_ent_mag": 32.2213249206543, "report/post_ent_max": 32.2213249206543, "report/post_ent_mean": 31.810983657836914, "report/post_ent_min": 31.529285430908203, "report/post_ent_std": 0.11614452302455902, "report/prior_ent_mag": 36.57059097290039, "report/prior_ent_max": 36.57059097290039, "report/prior_ent_mean": 32.62018585205078, "report/prior_ent_min": 29.93323516845703, "report/prior_ent_std": 1.1179310083389282, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007659912225790322, "report/reward_loss_mean": 0.008613914251327515, "report/reward_loss_std": 0.23339581489562988, "report/reward_max_data": 0.784375011920929, "report/reward_max_pred": 0.034404873847961426, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0013193002669140697, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.471004486083984, "report/reward_pred": 0.0006565290968865156, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.011083567515015602, "eval/cont_loss_std": 0.1960543990135193, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.205145835876465, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005028766114264727, "eval/cont_pred": 0.995391845703125, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22808067500591278, "eval/image_loss_std": 0.1297563761472702, "eval/model_loss_mean": 0.8392505645751953, "eval/model_loss_std": 0.23569603264331818, "eval/post_ent_mag": 32.185951232910156, "eval/post_ent_max": 32.185951232910156, "eval/post_ent_mean": 31.793453216552734, "eval/post_ent_min": 31.527589797973633, "eval/post_ent_std": 0.11348498612642288, "eval/prior_ent_mag": 36.51521301269531, "eval/prior_ent_max": 36.51521301269531, "eval/prior_ent_mean": 32.54417037963867, "eval/prior_ent_min": 29.45220375061035, "eval/prior_ent_std": 1.127995491027832, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 8.630985394120216e-05, "eval/reward_loss_std": 0.000928835419472307, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00894629955291748, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 8.630985394120216e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 4.293315578252077e-05, "eval/reward_rate": 0.0, "replay/size": 353185.0, "replay/inserts": 32088.0, "replay/samples": 32096.0, "replay/insert_wait_avg": 1.3274330356952646e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.437209664646198e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 79288.0, "eval_replay/inserts": 6448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1610334031930927e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2791826725006, "timer/env.step_count": 4011.0, "timer/env.step_total": 37.61967372894287, "timer/env.step_frac": 0.03760917389926313, "timer/env.step_avg": 0.009379125836186206, "timer/env.step_min": 0.007626533508300781, "timer/env.step_max": 0.03807425498962402, "timer/replay._sample_count": 32096.0, "timer/replay._sample_total": 15.750235319137573, "timer/replay._sample_frac": 0.015745839353626064, "timer/replay._sample_avg": 0.000490722685666051, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.02274179458618164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4817.0, "timer/agent.policy_total": 49.809396266937256, "timer/agent.policy_frac": 0.049795494227780256, "timer/agent.policy_avg": 0.010340335533929263, "timer/agent.policy_min": 0.008841991424560547, "timer/agent.policy_max": 0.08938360214233398, "timer/dataset_train_count": 2006.0, "timer/dataset_train_total": 0.2052445411682129, "timer/dataset_train_frac": 0.00020518725644159646, "timer/dataset_train_avg": 0.00010231532461027562, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0010800361633300781, "timer/agent.train_count": 2006.0, "timer/agent.train_total": 899.6150825023651, "timer/agent.train_frac": 0.8993639956585063, "timer/agent.train_avg": 0.4484621547868221, "timer/agent.train_min": 0.43560123443603516, "timer/agent.train_max": 1.4938733577728271, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4688596725463867, "timer/agent.report_frac": 0.00046872881158409064, "timer/agent.report_avg": 0.23442983627319336, "timer/agent.report_min": 0.2252206802368164, "timer/agent.report_max": 0.2436389923095703, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8363892205857385e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 32.078520153568064}
{"step": 354104, "time": 11227.869020938873, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 354360, "time": 11235.699432373047, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 354632, "time": 11244.004314899445, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 354696, "time": 11245.98670578003, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 355064, "time": 11257.273827075958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355144, "time": 11259.716492891312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355184, "time": 11261.167273759842, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 355256, "time": 11263.134151935577, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 355472, "time": 11269.949872016907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355488, "time": 11270.439921617508, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 355664, "time": 11275.797631978989, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 355744, "time": 11278.236493587494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 355848, "time": 11281.190687179565, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 356152, "time": 11290.582431554794, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 356208, "time": 11292.508661746979, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 356544, "time": 11302.724583864212, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 356728, "time": 11308.133828639984, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 357008, "time": 11316.957431316376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357376, "time": 11328.200311660767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357568, "time": 11334.053858280182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357800, "time": 11340.865229129791, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 357824, "time": 11341.81979560852, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 358040, "time": 11348.347269296646, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 358160, "time": 11352.24739074707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358424, "time": 11360.089519262314, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 358520, "time": 11363.0240380764, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 358520, "time": 11363.030989646912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358856, "time": 11373.259925603867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 358968, "time": 11376.744237661362, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 359040, "time": 11379.165775299072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359096, "time": 11380.65593624115, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 359184, "time": 11383.583182573318, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 359256, "time": 11385.553852081299, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 359320, "time": 11387.52436876297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 359600, "time": 11396.27112030983, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 359672, "time": 11398.253998041153, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 359792, "time": 11402.13419342041, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 360032, "time": 11409.549846887589, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 11410.6176507473, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 360048, "time": 11410.936178922653, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 360048, "time": 11411.236121416092, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 360048, "time": 11411.375761270523, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 360048, "time": 11411.549160003662, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 360048, "time": 11411.574247837067, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 360048, "time": 11411.83225774765, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 360048, "time": 11412.54896068573, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 360128, "time": 11414.992436647415, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 360320, "time": 11420.857983350754, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 360352, "time": 11421.826635837555, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 360520, "time": 11427.239586114883, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 360920, "time": 11439.596645832062, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 361152, "time": 11446.878544330597, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 361168, "time": 11447.37809920311, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361352, "time": 11452.77389883995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 361416, "time": 11454.748805999756, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 361544, "time": 11458.64078259468, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 361600, "time": 11460.584016561508, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 361648, "time": 11462.055129289627, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 361952, "time": 11471.381720781326, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 361976, "time": 11471.89442372322, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 361984, "time": 11472.366450548172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362096, "time": 11475.783363580704, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 362408, "time": 11485.038014173508, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 362464, "time": 11486.974668264389, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 362664, "time": 11492.82880783081, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 362712, "time": 11494.310586452484, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 362856, "time": 11498.819340467453, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 363056, "time": 11505.124236106873, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 363352, "time": 11513.936177253723, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 363480, "time": 11517.852213859558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 363552, "time": 11520.272694587708, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 363552, "time": 11520.278680801392, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 363832, "time": 11528.661666154861, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 363872, "time": 11530.110678434372, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 363960, "time": 11532.574806690216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 364072, "time": 11535.983303308487, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 364144, "time": 11538.405117034912, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 364192, "time": 11539.874036550522, "episode/length": 279.0, "episode/score": 0.12812499701976776, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.0}
{"step": 364416, "time": 11546.690811634064, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 364696, "time": 11555.003437519073, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 364704, "time": 11555.471112251282, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 364840, "time": 11559.434835910797, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 364936, "time": 11562.359951496124, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 364976, "time": 11563.794227838516, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 365168, "time": 11569.629707336426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 365232, "time": 11571.579503297806, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 365584, "time": 11582.276223897934, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 365864, "time": 11590.614498376846, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 365872, "time": 11591.10232424736, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 366080, "time": 11597.43928194046, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 366208, "time": 11601.344475030899, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 366320, "time": 11604.742970943451, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 366384, "time": 11606.70449590683, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 366456, "time": 11608.674771785736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 366632, "time": 11614.03793168068, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 367008, "time": 11625.822977542877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367224, "time": 11632.177592277527, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 367248, "time": 11633.12835597992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367288, "time": 11634.124004602432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 367544, "time": 11641.903404474258, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368072, "time": 11658.104824066162, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 368120, "time": 11659.581811904907, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 368192, "time": 11662.007906675339, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 368392, "time": 11667.909613847733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368632, "time": 11675.256091833115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 368696, "time": 11677.808039665222, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369088, "time": 11689.968663454056, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 369464, "time": 11701.182566404343, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 369536, "time": 11703.585845470428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 369560, "time": 11704.121103525162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 11719.46659040451, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 370032, "time": 11720.745805740356, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 370032, "time": 11724.838701725006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11724.844826459885, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11724.85033416748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11724.855590105057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11724.860894441605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 11724.866264104843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370384, "time": 11735.546597957611, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370432, "time": 11737.128730297089, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370504, "time": 11739.088688850403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370624, "time": 11742.975114822388, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 370680, "time": 11744.47760438919, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 370704, "time": 11745.432645082474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 370912, "time": 11751.719445228577, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 371184, "time": 11760.000264406204, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 371208, "time": 11760.514703989029, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 371336, "time": 11764.420874118805, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 371408, "time": 11766.924793958664, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 371424, "time": 11767.41904091835, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 371472, "time": 11768.90116238594, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 371560, "time": 11771.342495203018, "episode/length": 252.0, "episode/score": 0.21250000596046448, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.0}
{"step": 371608, "time": 11772.805592536926, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 371744, "time": 11777.175192594528, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 372072, "time": 11786.945480108261, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 372192, "time": 11790.825019359589, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 372648, "time": 11804.567734479904, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 372848, "time": 11810.884619235992, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 373080, "time": 11817.753266096115, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 373152, "time": 11820.154673099518, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 373496, "time": 11830.520944595337, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 373496, "time": 11830.528238773346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 373616, "time": 11834.411779403687, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 373784, "time": 11839.309828281403, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374056, "time": 11847.603487253189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374144, "time": 11850.50812959671, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 374272, "time": 11854.414784193039, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 374384, "time": 11857.915978431702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 374432, "time": 11859.384179353714, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 374456, "time": 11859.893121242523, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 374856, "time": 11872.087968111038, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 374976, "time": 11875.959837198257, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 374992, "time": 11876.469288110733, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 375152, "time": 11881.331047534943, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 375184, "time": 11882.308317184448, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 375392, "time": 11888.668836593628, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 375512, "time": 11892.087173223495, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 375536, "time": 11893.038762331009, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 375576, "time": 11894.02860713005, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 375744, "time": 11899.350175380707, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 375928, "time": 11904.724738121033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376024, "time": 11907.6504945755, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 376584, "time": 11924.781036615372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 376696, "time": 11928.200668334961, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 376832, "time": 11932.739981174469, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 377064, "time": 11939.902042150497, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 377288, "time": 11946.829890727997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377304, "time": 11947.326690196991, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377320, "time": 11947.82225394249, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 377760, "time": 11961.454270601273, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 377824, "time": 11963.402070522308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 377848, "time": 11963.911670684814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 378144, "time": 11973.19342470169, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 378168, "time": 11973.700125217438, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 378200, "time": 11974.694234371185, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 378216, "time": 11975.186213254929, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 378456, "time": 11982.580037117004, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 378800, "time": 11993.355975151062, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 378888, "time": 11995.808651447296, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 378984, "time": 11998.7284989357, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 379216, "time": 12006.10011959076, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 379240, "time": 12006.605597257614, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 379272, "time": 12007.57752251625, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 379328, "time": 12009.527031898499, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 379376, "time": 12010.974620580673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379632, "time": 12018.755946159363, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 379840, "time": 12025.0712890625, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 379944, "time": 12028.003074645996, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 12031.066425085068, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 380016, "time": 12031.884853601456, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 380016, "time": 12032.187888383865, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 380016, "time": 12032.398213624954, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 380016, "time": 12033.328679323196, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 380016, "time": 12033.664102315903, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 380016, "time": 12034.809375047684, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 380016, "time": 12036.024218797684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12036.031808137894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12036.037768602371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12036.04364490509, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12036.04915547371, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380024, "time": 12036.07385969162, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 380040, "time": 12036.567714452744, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 380040, "time": 12036.57285785675, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 380272, "time": 12043.866124391556, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 380536, "time": 12051.691821813583, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 381032, "time": 12066.892597436905, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 381296, "time": 12075.173406600952, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 381328, "time": 12076.150981903076, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 381360, "time": 12077.122129678726, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 381688, "time": 12086.875486850739, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 381928, "time": 12094.174230337143, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 381944, "time": 12094.669970273972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382144, "time": 12101.095077991486, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 382256, "time": 12104.544533729553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382352, "time": 12107.489317893982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 382600, "time": 12114.8157684803, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 383000, "time": 12127.130615711212, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 383024, "time": 12128.088192224503, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 383488, "time": 12142.238012075424, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 383504, "time": 12142.72499203682, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 383544, "time": 12143.717993497849, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 383608, "time": 12145.684207677841, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383640, "time": 12146.684741020203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 383912, "time": 12154.955075502396, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 384104, "time": 12160.918550729752, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 384256, "time": 12165.785811424255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384296, "time": 12166.803977966309, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 384456, "time": 12171.696833133698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 384536, "time": 12174.128151893616, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 384544, "time": 12174.600481510162, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 384592, "time": 12176.075979471207, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 384920, "time": 12185.930610656738, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 385184, "time": 12194.695184230804, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 385416, "time": 12201.559482574463, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 385432, "time": 12202.055488109589, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 385480, "time": 12203.51168346405, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 385849, "time": 12215.718503952026, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.433063867673352, "train/action_min": 0.0, "train/action_std": 1.8253576678423147, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011288080783792544, "train/actor_opt_grad_steps": 23010.0, "train/actor_opt_loss": -3.4302462964545732, "train/adv_mag": 0.7372686744329349, "train/adv_max": 0.28645357800953425, "train/adv_mean": 0.005535725031059788, "train/adv_min": -0.7093350581861847, "train/adv_std": 0.03680648790690955, "train/cont_avg": 0.9956710587686567, "train/cont_loss_mean": 0.016549522222821317, "train/cont_loss_std": 0.2382886554879039, "train/cont_neg_acc": 0.2820615115761757, "train/cont_neg_loss": 3.0121382091753186, "train/cont_pos_acc": 0.9998047506038229, "train/cont_pos_loss": 0.0032452737526801317, "train/cont_pred": 0.9957541434919063, "train/cont_rate": 0.9956710587686567, "train/dyn_loss_mean": 1.0000110597752814, "train/dyn_loss_std": 0.0003520289308255259, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.980493315676255, "train/extr_critic_critic_opt_grad_steps": 23010.0, "train/extr_critic_critic_opt_loss": 7004.326898223725, "train/extr_critic_mag": 0.9012505794639019, "train/extr_critic_max": 0.9012505794639019, "train/extr_critic_mean": 0.8820781345984235, "train/extr_critic_min": 0.854793390231346, "train/extr_critic_std": 0.007856641948195313, "train/extr_return_normed_mag": 0.7214178232411247, "train/extr_return_normed_max": 0.32231351184607737, "train/extr_return_normed_mean": 0.031487700377072006, "train/extr_return_normed_min": -0.6812001247311112, "train/extr_return_normed_std": 0.03839670538679877, "train/extr_return_rate": 0.9978299040106399, "train/extr_return_raw_mag": 1.1784397820335122, "train/extr_return_raw_max": 1.1784397820335122, "train/extr_return_raw_mean": 0.8876140165091747, "train/extr_return_raw_min": 0.17492614545632357, "train/extr_return_raw_std": 0.03839670511805893, "train/extr_reward_mag": 0.3300386963792108, "train/extr_reward_max": 0.3300386963792108, "train/extr_reward_mean": 0.0030620445877276546, "train/extr_reward_min": 1.9690290612367849e-07, "train/extr_reward_std": 0.013609472893303566, "train/image_loss_mean": 0.11945126428088146, "train/image_loss_std": 0.10755009726801915, "train/model_loss_mean": 0.7428605221397248, "train/model_loss_std": 0.37129528998438993, "train/model_opt_grad_norm": 28.754946400277056, "train/model_opt_grad_steps": 22987.830845771143, "train/model_opt_loss": 2247.585936892685, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3022.3880597014927, "train/policy_entropy_mag": 1.415367183993705, "train/policy_entropy_max": 1.415367183993705, "train/policy_entropy_mean": 0.1462805038735048, "train/policy_entropy_min": 0.06468682880721875, "train/policy_entropy_std": 0.18656969897041273, "train/policy_logprob_mag": 6.55107967889131, "train/policy_logprob_max": -0.008608197376354416, "train/policy_logprob_mean": -0.14684000429674168, "train/policy_logprob_min": -6.55107967889131, "train/policy_logprob_std": 0.684069282083369, "train/policy_randomness_mag": 0.727354890968076, "train/policy_randomness_max": 0.727354890968076, "train/policy_randomness_mean": 0.07517331338195658, "train/policy_randomness_min": 0.03324245583655229, "train/policy_randomness_std": 0.09587786504211117, "train/post_ent_mag": 31.197981307755654, "train/post_ent_max": 31.197981307755654, "train/post_ent_mean": 30.763926472829944, "train/post_ent_min": 30.475071332941006, "train/post_ent_std": 0.12517722970365885, "train/prior_ent_mag": 34.66638092496502, "train/prior_ent_max": 34.66638092496502, "train/prior_ent_mean": 30.47597247451099, "train/prior_ent_min": 27.797146460310145, "train/prior_ent_std": 1.176670217988503, "train/rep_loss_mean": 1.0000110597752814, "train/rep_loss_std": 0.0003520289308255259, "train/reward_avg": 0.0007816599361614129, "train/reward_loss_mean": 0.006853077208521355, "train/reward_loss_std": 0.13910573070280402, "train/reward_max_data": 0.5043065925661604, "train/reward_max_pred": 0.09939904177366797, "train/reward_neg_acc": 0.9999367378244353, "train/reward_neg_loss": 0.0011384147786956966, "train/reward_pos_acc": 0.10522222250699997, "train/reward_pos_loss": 4.573725563685099, "train/reward_pred": 0.0006273539965064149, "train/reward_rate": 0.0012583566542288557, "train_stats/mean_log_entropy": 0.11705218130149521, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.01590675860643387, "report/cont_loss_std": 0.24966935813426971, "report/cont_neg_acc": 0.4000000059604645, "report/cont_neg_loss": 2.776841402053833, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002359485486522317, "report/cont_pred": 0.9958313703536987, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11154811829328537, "report/image_loss_std": 0.1055106371641159, "report/model_loss_mean": 0.7301157116889954, "report/model_loss_std": 0.2765958607196808, "report/post_ent_mag": 29.905986785888672, "report/post_ent_max": 29.905986785888672, "report/post_ent_mean": 29.434473037719727, "report/post_ent_min": 29.13460922241211, "report/post_ent_std": 0.13569919764995575, "report/prior_ent_mag": 33.59461975097656, "report/prior_ent_max": 33.59461975097656, "report/prior_ent_mean": 29.341293334960938, "report/prior_ent_min": 26.731502532958984, "report/prior_ent_std": 1.1459839344024658, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0004364013730082661, "report/reward_loss_mean": 0.0026608179323375225, "report/reward_loss_std": 0.05326036363840103, "report/reward_max_data": 0.4468750059604645, "report/reward_max_pred": 0.410180926322937, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0009999489411711693, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 1.7017297744750977, "report/reward_pred": 0.000901456456631422, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.022791944444179535, "eval/cont_loss_std": 0.48576879501342773, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.984395980834961, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013406664365902543, "eval/cont_pred": 0.998677134513855, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19496718049049377, "eval/image_loss_std": 0.11655786633491516, "eval/model_loss_mean": 0.8303353190422058, "eval/model_loss_std": 0.848078191280365, "eval/post_ent_mag": 29.896739959716797, "eval/post_ent_max": 29.896739959716797, "eval/post_ent_mean": 29.402029037475586, "eval/post_ent_min": 29.150514602661133, "eval/post_ent_std": 0.13134972751140594, "eval/prior_ent_mag": 33.59461975097656, "eval/prior_ent_max": 33.59461975097656, "eval/prior_ent_mean": 29.45651626586914, "eval/prior_ent_min": 27.15406608581543, "eval/prior_ent_std": 1.1210730075836182, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006835937383584678, "eval/reward_loss_mean": 0.012576153501868248, "eval/reward_loss_std": 0.40101876854896545, "eval/reward_max_data": 0.699999988079071, "eval/reward_max_pred": 0.0013872385025024414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 3.81954487238545e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.838907241821289, "eval/reward_pred": 1.9146478734910488e-05, "eval/reward_rate": 0.0009765625, "replay/size": 385345.0, "replay/inserts": 32160.0, "replay/samples": 32160.0, "replay/insert_wait_avg": 1.3252247625322485e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.44991338075097e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 84984.0, "eval_replay/inserts": 5696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1659321490298496e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3734223842621, "timer/env.step_count": 4020.0, "timer/env.step_total": 37.568552017211914, "timer/env.step_frac": 0.03755452831570842, "timer/env.step_avg": 0.009345410949555202, "timer/env.step_min": 0.007715702056884766, "timer/env.step_max": 0.0455775260925293, "timer/replay._sample_count": 32160.0, "timer/replay._sample_total": 15.964819192886353, "timer/replay._sample_frac": 0.0159588597974107, "timer/replay._sample_avg": 0.0004964185072414911, "timer/replay._sample_min": 0.0003952980041503906, "timer/replay._sample_max": 0.011615276336669922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4732.0, "timer/agent.policy_total": 49.02651929855347, "timer/agent.policy_frac": 0.04900821853274053, "timer/agent.policy_avg": 0.010360633833168527, "timer/agent.policy_min": 0.008805274963378906, "timer/agent.policy_max": 0.08298659324645996, "timer/dataset_train_count": 2010.0, "timer/dataset_train_total": 0.20378875732421875, "timer/dataset_train_frac": 0.00020371268644714123, "timer/dataset_train_avg": 0.0001013874414548352, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0004892349243164062, "timer/agent.train_count": 2010.0, "timer/agent.train_total": 901.1867225170135, "timer/agent.train_frac": 0.9008503248408483, "timer/agent.train_avg": 0.4483516032422953, "timer/agent.train_min": 0.4383971691131592, "timer/agent.train_max": 0.682086706161499, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.469876766204834, "timer/agent.report_frac": 0.0004697013691996563, "timer/agent.report_avg": 0.234938383102417, "timer/agent.report_min": 0.2245323657989502, "timer/agent.report_max": 0.2453444004058838, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955286810612378e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 32.14746163582434}
{"step": 385920, "time": 12217.999667167664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 385952, "time": 12218.970893144608, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 386440, "time": 12233.531865596771, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 386608, "time": 12238.840127944946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386616, "time": 12238.867217302322, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 386768, "time": 12243.696695566177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 386776, "time": 12243.723270654678, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 387192, "time": 12256.442462921143, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 387288, "time": 12259.360973119736, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 387576, "time": 12268.090445518494, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 387744, "time": 12273.430495738983, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387792, "time": 12274.924280643463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 387856, "time": 12276.94426202774, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 388032, "time": 12282.295954704285, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 388208, "time": 12287.673873186111, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 388232, "time": 12288.196211576462, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388264, "time": 12289.175697803497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 388432, "time": 12294.55345416069, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 388472, "time": 12295.543868541718, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 388568, "time": 12298.45624423027, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 388736, "time": 12303.780786514282, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 388968, "time": 12310.67409992218, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 389024, "time": 12312.595569372177, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 389072, "time": 12314.067960500717, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 389080, "time": 12314.097315788269, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 389264, "time": 12319.909437417984, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 389432, "time": 12324.82188653946, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 389800, "time": 12336.044626712799, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 389832, "time": 12337.017706394196, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 12342.977296352386, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 390000, "time": 12343.391053438187, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 390000, "time": 12344.11743235588, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 390000, "time": 12344.316755056381, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 390000, "time": 12344.590735912323, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 390000, "time": 12344.656833648682, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 390000, "time": 12346.585518360138, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 390000, "time": 12346.704328536987, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 390520, "time": 12362.167991161346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391048, "time": 12378.213419914246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391280, "time": 12385.41057896614, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391336, "time": 12386.914636135101, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391392, "time": 12388.83025598526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391576, "time": 12394.190152406693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 391688, "time": 12397.707438707352, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 391720, "time": 12398.67830324173, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 391888, "time": 12403.997137069702, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 392040, "time": 12408.404983997345, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 392112, "time": 12410.813871860504, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392144, "time": 12411.783078432083, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 392184, "time": 12412.771486997604, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 392432, "time": 12420.487773180008, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 392480, "time": 12421.939492702484, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 392944, "time": 12436.095321893692, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 393360, "time": 12449.15650510788, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 393488, "time": 12453.061230659485, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 393504, "time": 12453.55215215683, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 393704, "time": 12459.515032529831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 393976, "time": 12467.7539229393, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 394200, "time": 12474.55452823639, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394312, "time": 12477.971092224121, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 394352, "time": 12479.429684638977, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 394368, "time": 12479.916590690613, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 394424, "time": 12481.394185066223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394456, "time": 12482.37302160263, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 394776, "time": 12492.16805100441, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 394848, "time": 12494.594586372375, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 395096, "time": 12501.864411354065, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 395720, "time": 12520.804207086563, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 395728, "time": 12521.271756410599, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 395776, "time": 12522.732883930206, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 396552, "time": 12546.21474814415, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 396664, "time": 12549.623523950577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396736, "time": 12552.01281619072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396768, "time": 12553.001465559006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 396896, "time": 12556.855058670044, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 396960, "time": 12558.817389726639, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 397088, "time": 12562.674547672272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397304, "time": 12568.993289709091, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 397408, "time": 12572.381343603134, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 397424, "time": 12572.872695684433, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 397752, "time": 12582.721136808395, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 398008, "time": 12590.41363120079, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 398088, "time": 12592.845139980316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 398088, "time": 12592.851552724838, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 398096, "time": 12593.320887804031, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 398128, "time": 12594.295462369919, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 398512, "time": 12606.1118683815, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 398720, "time": 12612.421785593033, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 398768, "time": 12613.881099939346, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 398800, "time": 12614.851465940475, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 398856, "time": 12616.34068775177, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 398920, "time": 12618.28644490242, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 398928, "time": 12618.762963056564, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 398976, "time": 12620.227677345276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 399240, "time": 12628.107520341873, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 399632, "time": 12640.349276781082, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 399648, "time": 12640.841200590134, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 399928, "time": 12649.14214682579, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 400040, "time": 12652.55194568634, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 12655.449430942535, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 400088, "time": 12655.793472290039, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 400088, "time": 12656.559830665588, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 400088, "time": 12656.622826814651, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 400088, "time": 12656.98829293251, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 400088, "time": 12657.175355196, "eval_episode/length": 165.0, "eval_episode/score": 0.484375, "eval_episode/reward_rate": 0.006024096385542169}
{"step": 400088, "time": 12658.667734146118, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 400088, "time": 12659.041340827942, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 400208, "time": 12662.909589529037, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 400312, "time": 12665.880053758621, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 400312, "time": 12665.90464258194, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 400336, "time": 12666.91126537323, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 400360, "time": 12667.423640727997, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 400752, "time": 12679.498797893524, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 400824, "time": 12681.458726644516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401080, "time": 12689.259498357773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401152, "time": 12691.659672260284, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 401200, "time": 12693.111471891403, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 401240, "time": 12694.135512828827, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 401704, "time": 12708.747479915619, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 401736, "time": 12709.735058546066, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 401912, "time": 12715.029194831848, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 401936, "time": 12715.981484651566, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 402184, "time": 12723.280345201492, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 402328, "time": 12727.725979804993, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 402432, "time": 12731.08586549759, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 402640, "time": 12737.41183257103, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 402688, "time": 12738.883182287216, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 403024, "time": 12749.081146001816, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 403392, "time": 12760.344721317291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403424, "time": 12761.323405504227, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 403480, "time": 12762.821364402771, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 403552, "time": 12765.225870609283, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 403560, "time": 12765.253472805023, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 404184, "time": 12784.279569864273, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 404496, "time": 12794.138867139816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 404744, "time": 12801.460698127747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405336, "time": 12819.546006679535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405456, "time": 12823.437583208084, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 405704, "time": 12830.74722146988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405792, "time": 12833.656603813171, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 405872, "time": 12836.105943202972, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406496, "time": 12855.214080095291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 406808, "time": 12864.48579120636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407056, "time": 12872.292090892792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407568, "time": 12888.041515350342, "episode/length": 232.0, "episode/score": 0.2750000059604645, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.0}
{"step": 407648, "time": 12890.526992321014, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407768, "time": 12893.946403741837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 407832, "time": 12895.90018248558, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 407928, "time": 12898.794164657593, "episode/length": 266.0, "episode/score": 0.16875000298023224, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.0}
{"step": 407936, "time": 12899.259052276611, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 408184, "time": 12906.707005023956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408808, "time": 12925.694720745087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 408912, "time": 12929.108220338821, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 409032, "time": 12932.529978752136, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 409120, "time": 12935.463551044464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409648, "time": 12952.11995792389, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 409880, "time": 12958.995631694794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 409920, "time": 12960.44288277626, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 12966.138536691666, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 410072, "time": 12966.294142246246, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 410072, "time": 12966.298654079437, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 410072, "time": 12966.973259449005, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 410072, "time": 12967.644470453262, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 410072, "time": 12967.890968561172, "eval_episode/length": 12.0, "eval_episode/score": 0.9624999761581421, "eval_episode/reward_rate": 0.07692307692307693}
{"step": 410072, "time": 12968.298318862915, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 410072, "time": 12968.414405584335, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 410080, "time": 12968.89065694809, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410144, "time": 12970.837549686432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410240, "time": 12973.756958961487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 410280, "time": 12974.75057888031, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 410536, "time": 12982.53851222992, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 410648, "time": 12985.960898160934, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 410976, "time": 12996.233861923218, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 411008, "time": 12997.221559047699, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 411024, "time": 12997.71231007576, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 411032, "time": 12997.73848605156, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 411120, "time": 13000.642353534698, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 411848, "time": 13022.507013320923, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 412392, "time": 13039.121896266937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 412528, "time": 13043.490827560425, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 412648, "time": 13046.919420480728, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 412960, "time": 13056.715432882309, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413080, "time": 13060.13016819954, "episode/length": 255.0, "episode/score": 0.203125, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.0}
{"step": 413288, "time": 13066.401730537415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413336, "time": 13067.845582485199, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413344, "time": 13068.309682130814, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 413432, "time": 13070.757734537125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 413496, "time": 13072.686296701431, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 413760, "time": 13080.936201572418, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 413792, "time": 13081.90108346939, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 413848, "time": 13083.377036571503, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 414160, "time": 13093.138665676117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 414248, "time": 13095.608833551407, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 414264, "time": 13096.095282316208, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 414424, "time": 13100.945343017578, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 414664, "time": 13108.241539478302, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 414664, "time": 13108.248256444931, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 415000, "time": 13118.579610586166, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 415040, "time": 13120.011267662048, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 415096, "time": 13121.48186802864, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 415224, "time": 13125.370832204819, "episode/length": 22.0, "episode/score": 0.9312499761581421, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.0}
{"step": 415352, "time": 13129.2865087986, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 415464, "time": 13132.69551563263, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 415568, "time": 13136.097549438477, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 415568, "time": 13136.103208303452, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 415744, "time": 13141.443202018738, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 415864, "time": 13144.903315782547, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 415904, "time": 13146.4246301651, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 416000, "time": 13149.36560344696, "episode/length": 275.0, "episode/score": 0.140625, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.0}
{"step": 416056, "time": 13150.848012924194, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 416088, "time": 13151.82093667984, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 416560, "time": 13166.40401315689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 416584, "time": 13166.91632938385, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 416640, "time": 13168.85935664177, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 416696, "time": 13170.323492765427, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 416992, "time": 13179.629833936691, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 417088, "time": 13182.542611122131, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 417336, "time": 13189.797256946564, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 417568, "time": 13197.039640426636, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 417736, "time": 13201.90828704834, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 417776, "time": 13203.349833965302, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 417880, "time": 13206.898746967316, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418040, "time": 13211.749320745468, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 418072, "time": 13212.720129013062, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 418153, "time": 13216.115683078766, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.342338939704517, "train/action_min": 0.0, "train/action_std": 1.8149875266717213, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01329457044306368, "train/actor_opt_grad_steps": 25025.0, "train/actor_opt_loss": -3.4943555830470703, "train/adv_mag": 0.9249926029455544, "train/adv_max": 0.255038975193949, "train/adv_mean": 0.00508742760404749, "train/adv_min": -0.9111106847182359, "train/adv_std": 0.041604647641116294, "train/cont_avg": 0.9956924891707921, "train/cont_loss_mean": 0.014719196624643547, "train/cont_loss_std": 0.21879554203582355, "train/cont_neg_acc": 0.34870040327310564, "train/cont_neg_loss": 2.682939130887389, "train/cont_pos_acc": 0.9998202300307775, "train/cont_pos_loss": 0.003090319437514253, "train/cont_pred": 0.9956165873768306, "train/cont_rate": 0.9956924891707921, "train/dyn_loss_mean": 1.0000212174831051, "train/dyn_loss_std": 0.0005757928702583776, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6708228672753171, "train/extr_critic_critic_opt_grad_steps": 25025.0, "train/extr_critic_critic_opt_loss": 12845.173562229269, "train/extr_critic_mag": 1.061751663684845, "train/extr_critic_max": 1.061751663684845, "train/extr_critic_mean": 1.0246416831960772, "train/extr_critic_min": 0.973172138232996, "train/extr_critic_std": 0.01236188646848544, "train/extr_return_normed_mag": 0.9005056778983315, "train/extr_return_normed_max": 0.2976981209646357, "train/extr_return_normed_mean": 0.03883624978773849, "train/extr_return_normed_min": -0.8807189786198115, "train/extr_return_normed_std": 0.04404832664784966, "train/extr_return_rate": 0.9974590507474276, "train/extr_return_raw_mag": 1.2885908918215496, "train/extr_return_raw_max": 1.2885908918215496, "train/extr_return_raw_mean": 1.0297290694595564, "train/extr_return_raw_min": 0.1101737922371024, "train/extr_return_raw_std": 0.044048326666291694, "train/extr_reward_mag": 0.3190561639200343, "train/extr_reward_max": 0.3190561639200343, "train/extr_reward_mean": 0.0032593671596692045, "train/extr_reward_min": 1.829449493106049e-07, "train/extr_reward_std": 0.013581726361195198, "train/image_loss_mean": 0.10749193210855569, "train/image_loss_std": 0.10477574114309679, "train/model_loss_mean": 0.7303428729571918, "train/model_loss_std": 0.37418490526552245, "train/model_opt_grad_norm": 27.47339466302702, "train/model_opt_grad_steps": 25001.430693069306, "train/model_opt_loss": 2376.4977012105505, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3254.9504950495048, "train/policy_entropy_mag": 1.4099152294716033, "train/policy_entropy_max": 1.4099152294716033, "train/policy_entropy_mean": 0.12895608280259785, "train/policy_entropy_min": 0.06468666311685402, "train/policy_entropy_std": 0.17020007997456163, "train/policy_logprob_mag": 6.551080120672093, "train/policy_logprob_max": -0.008608144389852733, "train/policy_logprob_mean": -0.12931734116950838, "train/policy_logprob_min": -6.551080120672093, "train/policy_logprob_std": 0.6686068135913056, "train/policy_randomness_mag": 0.7245531424437419, "train/policy_randomness_max": 0.7245531424437419, "train/policy_randomness_mean": 0.06627032110965488, "train/policy_randomness_min": 0.03324237106238852, "train/policy_randomness_std": 0.08746554403759466, "train/post_ent_mag": 28.79593327021835, "train/post_ent_max": 28.79593327021835, "train/post_ent_mean": 28.337746100850623, "train/post_ent_min": 28.029758094560982, "train/post_ent_std": 0.1372366769626589, "train/prior_ent_mag": 32.092974889396444, "train/prior_ent_max": 32.092974889396444, "train/prior_ent_mean": 27.601641579429703, "train/prior_ent_min": 25.29620651207348, "train/prior_ent_std": 1.1137659092350762, "train/rep_loss_mean": 1.0000212174831051, "train/rep_loss_std": 0.0005757928702583776, "train/reward_avg": 0.0009744776316888465, "train/reward_loss_mean": 0.008118993223478815, "train/reward_loss_std": 0.15487860375900042, "train/reward_max_data": 0.5702042067700094, "train/reward_max_pred": 0.10686287962564148, "train/reward_neg_acc": 0.9998691999676204, "train/reward_neg_loss": 0.0013946869641387983, "train/reward_pos_acc": 0.1300411527907407, "train/reward_pos_loss": 4.515645999967316, "train/reward_pred": 0.0007736494581417946, "train/reward_rate": 0.001489016089108911, "train_stats/mean_log_entropy": 0.1013490742817521, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.005248790606856346, "report/cont_loss_std": 0.13171471655368805, "report/cont_neg_acc": 0.75, "report/cont_neg_loss": 1.121091604232788, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0008729372057132423, "report/cont_pred": 0.996430516242981, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10070094466209412, "report/image_loss_std": 0.1136806532740593, "report/model_loss_mean": 0.7130872011184692, "report/model_loss_std": 0.3828354477882385, "report/post_ent_mag": 27.982486724853516, "report/post_ent_max": 27.982486724853516, "report/post_ent_mean": 27.48541259765625, "report/post_ent_min": 27.185707092285156, "report/post_ent_std": 0.14478465914726257, "report/prior_ent_mag": 31.36794662475586, "report/prior_ent_max": 31.36794662475586, "report/prior_ent_mean": 26.775676727294922, "report/prior_ent_min": 24.795955657958984, "report/prior_ent_std": 1.0150858163833618, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00023193359083961695, "report/reward_loss_mean": 0.007137418258935213, "report/reward_loss_std": 0.21843743324279785, "report/reward_max_data": 0.23749999701976776, "report/reward_max_pred": 0.030904531478881836, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00030835423967801034, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.993269920349121, "report/reward_pred": 0.00016512477304786444, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.026091180741786957, "eval/cont_loss_std": 0.493407279253006, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.651216506958008, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0007480120402760804, "eval/cont_pred": 0.999274730682373, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20270691812038422, "eval/image_loss_std": 0.151506245136261, "eval/model_loss_mean": 0.8497563600540161, "eval/model_loss_std": 0.9898378849029541, "eval/post_ent_mag": 27.975109100341797, "eval/post_ent_max": 27.975109100341797, "eval/post_ent_mean": 27.491191864013672, "eval/post_ent_min": 27.162649154663086, "eval/post_ent_std": 0.14382824301719666, "eval/prior_ent_mag": 31.428340911865234, "eval/prior_ent_max": 31.428340911865234, "eval/prior_ent_mean": 26.722984313964844, "eval/prior_ent_min": 24.89480209350586, "eval/prior_ent_std": 1.0803797245025635, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0010650635231286287, "eval/reward_loss_mean": 0.020958274602890015, "eval/reward_loss_std": 0.4982181787490845, "eval/reward_max_data": 0.699999988079071, "eval/reward_max_pred": 0.002100825309753418, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 2.9139788239262998e-05, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 10.715746879577637, "eval/reward_pred": 1.5560886822640896e-05, "eval/reward_rate": 0.001953125, "replay/size": 417649.0, "replay/inserts": 32304.0, "replay/samples": 32304.0, "replay/insert_wait_avg": 1.3423222843640626e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.604537121195083e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90128.0, "eval_replay/inserts": 5144.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.195059223086059e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3745546340942, "timer/env.step_count": 4038.0, "timer/env.step_total": 37.729384899139404, "timer/env.step_frac": 0.037715258474301794, "timer/env.step_avg": 0.009343582193942398, "timer/env.step_min": 0.007561445236206055, "timer/env.step_max": 0.03565549850463867, "timer/replay._sample_count": 32304.0, "timer/replay._sample_total": 16.174547910690308, "timer/replay._sample_frac": 0.016168491927112692, "timer/replay._sample_avg": 0.0005006979912918, "timer/replay._sample_min": 0.00037407875061035156, "timer/replay._sample_max": 0.03183555603027344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4681.0, "timer/agent.policy_total": 48.76195979118347, "timer/agent.policy_frac": 0.04874370261148743, "timer/agent.policy_avg": 0.010416996323687987, "timer/agent.policy_min": 0.008525371551513672, "timer/agent.policy_max": 0.09121203422546387, "timer/dataset_train_count": 2019.0, "timer/dataset_train_total": 0.20881891250610352, "timer/dataset_train_frac": 0.00020874072769921958, "timer/dataset_train_avg": 0.00010342690069643562, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0010764598846435547, "timer/agent.train_count": 2019.0, "timer/agent.train_total": 902.0300312042236, "timer/agent.train_frac": 0.901692298175415, "timer/agent.train_avg": 0.4467706940090261, "timer/agent.train_min": 0.4339745044708252, "timer/agent.train_max": 0.6999368667602539, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4684724807739258, "timer/agent.report_frac": 0.00046829707793325306, "timer/agent.report_avg": 0.2342362403869629, "timer/agent.report_min": 0.22618675231933594, "timer/agent.report_max": 0.24228572845458984, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169779846320283e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 32.29134918331683}
{"step": 418552, "time": 13227.932354211807, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 418584, "time": 13228.906367063522, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 418768, "time": 13234.688665151596, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 418872, "time": 13237.708260536194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 418952, "time": 13240.129414319992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 419016, "time": 13242.071553945541, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 419104, "time": 13244.940251588821, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 419320, "time": 13251.262446165085, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 419472, "time": 13256.07529091835, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 419592, "time": 13259.459653377533, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 419664, "time": 13261.87124323845, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 419808, "time": 13266.285628557205, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 13273.952241182327, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 420056, "time": 13274.79408288002, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 420056, "time": 13275.042827367783, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 420056, "time": 13275.49962234497, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 420056, "time": 13275.704317569733, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 420056, "time": 13275.709782361984, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 420056, "time": 13276.294896364212, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 420056, "time": 13276.408656597137, "eval_episode/length": 148.0, "eval_episode/score": 0.5375000238418579, "eval_episode/reward_rate": 0.006711409395973154}
{"step": 420088, "time": 13277.374479532242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 420656, "time": 13294.737684488297, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 420680, "time": 13295.24562883377, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 420776, "time": 13298.206546545029, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 420792, "time": 13298.697295427322, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 421128, "time": 13308.869501113892, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 421136, "time": 13309.333669185638, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 421184, "time": 13310.787574529648, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421632, "time": 13324.320588111877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421672, "time": 13325.304829359055, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 421792, "time": 13329.23683667183, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 421904, "time": 13332.62413430214, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 421960, "time": 13334.102218151093, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 422120, "time": 13338.932555437088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 422344, "time": 13345.680159330368, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 422480, "time": 13349.994306325912, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 422920, "time": 13363.159904718399, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 423088, "time": 13368.482779502869, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423496, "time": 13380.646403074265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 423640, "time": 13385.013452768326, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 423824, "time": 13390.858797311783, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 423832, "time": 13390.885902404785, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 424216, "time": 13402.443961381912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424256, "time": 13403.879647493362, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 424312, "time": 13405.362211227417, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 424432, "time": 13409.23810338974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424656, "time": 13416.139901638031, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424792, "time": 13420.034001111984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 424808, "time": 13420.518803358078, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 424880, "time": 13422.91115283966, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 424944, "time": 13424.85109782219, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 425040, "time": 13427.74808716774, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 425280, "time": 13435.103145360947, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 425688, "time": 13447.294018030167, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 426000, "time": 13457.422909736633, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 426000, "time": 13457.428327083588, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 426160, "time": 13462.256679296494, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 426400, "time": 13469.5192258358, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 426624, "time": 13476.39781332016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 426768, "time": 13480.779702663422, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 426968, "time": 13486.604486227036, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427032, "time": 13488.554432868958, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 427112, "time": 13490.9632294178, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 427192, "time": 13493.400156736374, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 427352, "time": 13498.235961675644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 427784, "time": 13511.317083120346, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 428000, "time": 13518.070159435272, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428216, "time": 13524.39075088501, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 428224, "time": 13524.854864120483, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 428312, "time": 13527.30473279953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 428512, "time": 13533.58548116684, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 428528, "time": 13534.071148633957, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 428536, "time": 13534.097778081894, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 428880, "time": 13544.839521169662, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 429080, "time": 13550.653412818909, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 429152, "time": 13553.049537181854, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 429616, "time": 13567.174623727798, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 429720, "time": 13570.120718955994, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 429976, "time": 13577.919768333435, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13579.880180597305, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 13581.40868139267, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 430040, "time": 13581.432065486908, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 430040, "time": 13581.548176050186, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 430040, "time": 13581.684560775757, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 430040, "time": 13582.198741912842, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 430040, "time": 13582.259238243103, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 430040, "time": 13582.693087816238, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 430040, "time": 13583.031982183456, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 430312, "time": 13591.262087583542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430504, "time": 13597.209995985031, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 430536, "time": 13598.202771186829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 430680, "time": 13602.57154750824, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 430696, "time": 13603.056615114212, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 430840, "time": 13607.41986823082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431048, "time": 13613.691422700882, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 431096, "time": 13615.13923215866, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 431168, "time": 13617.546146392822, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 431168, "time": 13617.551813840866, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 431392, "time": 13624.339537382126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431464, "time": 13626.426779270172, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 431600, "time": 13630.780545949936, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 431704, "time": 13633.72427868843, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 431824, "time": 13637.594573020935, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 431928, "time": 13640.496926784515, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 432008, "time": 13642.90956401825, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 432040, "time": 13643.877627372742, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 432072, "time": 13644.845988750458, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 432072, "time": 13644.85190486908, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 432368, "time": 13653.98414349556, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 432672, "time": 13663.251440763474, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 432720, "time": 13664.712738752365, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 432760, "time": 13665.716197013855, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 432912, "time": 13670.548280954361, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 432920, "time": 13670.575443983078, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 433224, "time": 13679.822668552399, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 433328, "time": 13683.198446035385, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 433480, "time": 13687.690948963165, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434384, "time": 13715.711907863617, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 434416, "time": 13716.760716199875, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 434488, "time": 13718.718257904053, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 434984, "time": 13733.741879940033, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435032, "time": 13735.215111494064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435040, "time": 13735.691617965698, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 435072, "time": 13736.659037828445, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 435072, "time": 13736.666455984116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435232, "time": 13741.584561824799, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435536, "time": 13750.830249547958, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 435952, "time": 13763.416284322739, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 436144, "time": 13769.19001865387, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 436544, "time": 13781.363061904907, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 436800, "time": 13789.20979309082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437112, "time": 13798.47263789177, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 437288, "time": 13803.820959329605, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 437344, "time": 13805.734951972961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437352, "time": 13805.763532400131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437384, "time": 13806.818091869354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 437496, "time": 13810.20579457283, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 437552, "time": 13812.136877059937, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 437992, "time": 13825.15979552269, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 438016, "time": 13826.111645936966, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 438272, "time": 13833.862629413605, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 438304, "time": 13834.856145143509, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 438448, "time": 13839.322262525558, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 438856, "time": 13851.423154592514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 438864, "time": 13851.890222072601, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 439408, "time": 13868.493409872055, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 439408, "time": 13868.504024744034, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 439600, "time": 13874.352725505829, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 439608, "time": 13874.379091978073, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 439696, "time": 13877.260806322098, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 13887.727669715881, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 440024, "time": 13888.743968009949, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 440024, "time": 13888.838738441467, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 440024, "time": 13888.985422611237, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 440024, "time": 13889.459433794022, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 440024, "time": 13889.859464168549, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 440024, "time": 13889.974199533463, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 440024, "time": 13890.281114578247, "eval_episode/length": 179.0, "eval_episode/score": 0.44062501192092896, "eval_episode/reward_rate": 0.005555555555555556}
{"step": 440080, "time": 13892.18507885933, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 440328, "time": 13899.605697393417, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440432, "time": 13902.961322784424, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 440760, "time": 13912.63261771202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 440800, "time": 13914.050786018372, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 441040, "time": 13921.301017045975, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 441112, "time": 13923.257379293442, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 441160, "time": 13924.719135761261, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 441176, "time": 13925.205384254456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441464, "time": 13934.014440774918, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 441568, "time": 13937.399296760559, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 441720, "time": 13941.791179656982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 441944, "time": 13948.595071315765, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 442008, "time": 13950.537223815918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 442192, "time": 13956.45118355751, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 442456, "time": 13964.627414941788, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 442480, "time": 13965.574871063232, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 442632, "time": 13969.955603837967, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 442808, "time": 13975.260278701782, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 443176, "time": 13986.492150306702, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 443352, "time": 13991.796929597855, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 443416, "time": 13993.729836940765, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 443520, "time": 13997.094497442245, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 443584, "time": 13999.026923179626, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 443584, "time": 13999.032789945602, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 443600, "time": 13999.520168542862, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 443896, "time": 14008.228462219238, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 443936, "time": 14009.649391889572, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 444032, "time": 14012.563332796097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444336, "time": 14021.847640991211, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 444504, "time": 14026.724207401276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 444584, "time": 14029.140521287918, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 444960, "time": 14040.780007362366, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 445336, "time": 14052.013195753098, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 445352, "time": 14052.497995376587, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 445352, "time": 14052.503244400024, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 445832, "time": 14068.252342224121, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445896, "time": 14070.207224845886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 445896, "time": 14070.213774204254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 446000, "time": 14073.590594768524, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 446056, "time": 14075.081853628159, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 446488, "time": 14088.295314788818, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 446776, "time": 14097.036234378815, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 446816, "time": 14098.463933467865, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447368, "time": 14115.123515605927, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 447552, "time": 14120.956642389297, "episode/length": 193.0, "episode/score": 0.3968749940395355, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0}
{"step": 447664, "time": 14124.360463619232, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 447672, "time": 14124.390451669693, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 448008, "time": 14134.59380030632, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 448208, "time": 14140.951893568039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448208, "time": 14140.958835363388, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448296, "time": 14143.431319713593, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 448432, "time": 14147.763150930405, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 448440, "time": 14147.789383649826, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 448800, "time": 14158.933631181717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 448896, "time": 14161.842789411545, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 449016, "time": 14165.273601770401, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 449224, "time": 14171.69525384903, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 449352, "time": 14175.581958293915, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 449560, "time": 14181.91377735138, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 449680, "time": 14185.767534017563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 449720, "time": 14186.768628358841, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 449896, "time": 14192.083689212799, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 449984, "time": 14194.969737052917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 14196.515832424164, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 450008, "time": 14196.705616235733, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 450008, "time": 14197.09561085701, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 450008, "time": 14197.23144364357, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 450008, "time": 14197.476701021194, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 450008, "time": 14198.115187168121, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 450008, "time": 14198.276787996292, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 450008, "time": 14198.519791603088, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 450088, "time": 14200.963130235672, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 450160, "time": 14203.342926502228, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 450160, "time": 14203.3480386734, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 450560, "time": 14216.422127962112, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.248397751981989, "train/action_min": 0.0, "train/action_std": 1.7926670042752044, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010321995797406497, "train/actor_opt_grad_steps": 27050.0, "train/actor_opt_loss": -6.064496899620066, "train/adv_mag": 0.9220811069892545, "train/adv_max": 0.25054049961672625, "train/adv_mean": 0.0026518999865236524, "train/adv_min": -0.9022440734167991, "train/adv_std": 0.03756618474293592, "train/cont_avg": 0.9954346905788177, "train/cont_loss_mean": 0.014444208132754552, "train/cont_loss_std": 0.21413016902613155, "train/cont_neg_acc": 0.3869931703746909, "train/cont_neg_loss": 2.5069949984628854, "train/cont_pos_acc": 0.9998115447941672, "train/cont_pos_loss": 0.002992709769449871, "train/cont_pred": 0.9954711965152195, "train/cont_rate": 0.9954346905788177, "train/dyn_loss_mean": 1.0000154737181264, "train/dyn_loss_std": 0.0003614600166840292, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.47352947977376103, "train/extr_critic_critic_opt_grad_steps": 27050.0, "train/extr_critic_critic_opt_loss": 9417.916612145937, "train/extr_critic_mag": 1.1751142628674436, "train/extr_critic_max": 1.1751142628674436, "train/extr_critic_mean": 1.1316400519732772, "train/extr_critic_min": 1.0587762282986946, "train/extr_critic_std": 0.012895072980100298, "train/extr_return_normed_mag": 0.9135758465734022, "train/extr_return_normed_max": 0.27206473514951507, "train/extr_return_normed_mean": 0.030952029010473656, "train/extr_return_normed_min": -0.8833329554261833, "train/extr_return_normed_std": 0.04078526723340814, "train/extr_return_rate": 0.9982268372779997, "train/extr_return_raw_mag": 1.37540398853753, "train/extr_return_raw_max": 1.37540398853753, "train/extr_return_raw_mean": 1.134291351722379, "train/extr_return_raw_min": 0.2200062979618317, "train/extr_return_raw_std": 0.04078526711412545, "train/extr_reward_mag": 0.3034513906892297, "train/extr_reward_max": 0.3034513906892297, "train/extr_reward_mean": 0.0029473386371159566, "train/extr_reward_min": 2.0494601996661407e-07, "train/extr_reward_std": 0.011490133291642581, "train/image_loss_mean": 0.10076231058007978, "train/image_loss_std": 0.1036477632490285, "train/model_loss_mean": 0.725047752774995, "train/model_loss_std": 0.3964071834615886, "train/model_opt_grad_norm": 26.41065067610717, "train/model_opt_grad_steps": 27024.99014778325, "train/model_opt_loss": 2695.3680419921875, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3719.2118226600987, "train/policy_entropy_mag": 1.3312378969098546, "train/policy_entropy_max": 1.3312378969098546, "train/policy_entropy_mean": 0.11533825719738242, "train/policy_entropy_min": 0.0646865414501411, "train/policy_entropy_std": 0.15013476329043582, "train/policy_logprob_mag": 6.551080215153436, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11527865875530713, "train/policy_logprob_min": -6.551080215153436, "train/policy_logprob_std": 0.6522427594720437, "train/policy_randomness_mag": 0.6841209897854058, "train/policy_randomness_max": 0.6841209897854058, "train/policy_randomness_mean": 0.05927214285202802, "train/policy_randomness_min": 0.03324230923661457, "train/policy_randomness_std": 0.07715401038747703, "train/post_ent_mag": 27.312268769212544, "train/post_ent_max": 27.312268769212544, "train/post_ent_mean": 26.863588849899216, "train/post_ent_min": 26.55963098121981, "train/post_ent_std": 0.14212682131182383, "train/prior_ent_mag": 29.69226447232251, "train/prior_ent_max": 29.69226447232251, "train/prior_ent_mean": 25.941492494103944, "train/prior_ent_min": 23.9352419341139, "train/prior_ent_std": 0.9172915654816651, "train/rep_loss_mean": 1.0000154737181264, "train/rep_loss_std": 0.0003614600166840292, "train/reward_avg": 0.0012193050316799882, "train/reward_loss_mean": 0.00983192526856942, "train/reward_loss_std": 0.18167328146134912, "train/reward_max_data": 0.6498306642465403, "train/reward_max_pred": 0.14160620167924853, "train/reward_neg_acc": 0.9997639227383243, "train/reward_neg_loss": 0.0015602224261850907, "train/reward_pos_acc": 0.09962963056233194, "train/reward_pos_loss": 4.528092594941457, "train/reward_pred": 0.0008697436911425567, "train/reward_rate": 0.0018280480295566502, "train_stats/mean_log_entropy": 0.09685191367544345, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.027470190078020096, "report/cont_loss_std": 0.38655751943588257, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 3.4461278915405273, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003939604852348566, "report/cont_pred": 0.9935917854309082, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10579171776771545, "report/image_loss_std": 0.10145697742700577, "report/model_loss_mean": 0.746985912322998, "report/model_loss_std": 0.5825198888778687, "report/post_ent_mag": 26.79435920715332, "report/post_ent_max": 26.79435920715332, "report/post_ent_mean": 26.36570167541504, "report/post_ent_min": 26.025070190429688, "report/post_ent_std": 0.14515438675880432, "report/prior_ent_mag": 28.757638931274414, "report/prior_ent_max": 28.757638931274414, "report/prior_ent_mean": 25.488929748535156, "report/prior_ent_min": 23.706022262573242, "report/prior_ent_std": 0.8017099499702454, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0015045166946947575, "report/reward_loss_mean": 0.013723969459533691, "report/reward_loss_std": 0.25390565395355225, "report/reward_max_data": 0.7875000238418579, "report/reward_max_pred": 0.1451014280319214, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.0025966032408177853, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.699808120727539, "report/reward_pred": 0.0013016621815040708, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04102378338575363, "eval/cont_loss_std": 0.6576367020606995, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.272629737854004, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0008998389239422977, "eval/cont_pred": 0.999115526676178, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20161670446395874, "eval/image_loss_std": 0.1473694145679474, "eval/model_loss_mean": 0.8427408337593079, "eval/model_loss_std": 0.6683977246284485, "eval/post_ent_mag": 26.806991577148438, "eval/post_ent_max": 26.806991577148438, "eval/post_ent_mean": 26.334434509277344, "eval/post_ent_min": 26.072296142578125, "eval/post_ent_std": 0.14147326350212097, "eval/prior_ent_mag": 28.885753631591797, "eval/prior_ent_max": 28.885753631591797, "eval/prior_ent_mean": 25.401714324951172, "eval/prior_ent_min": 23.67116928100586, "eval/prior_ent_std": 0.8760557770729065, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00010028015822172165, "eval/reward_loss_std": 0.0006140631157904863, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.004277467727661133, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00010028015822172165, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.065556615591049e-05, "eval/reward_rate": 0.0, "replay/size": 450056.0, "replay/inserts": 32407.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.333524029665508e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.646245720945758e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95352.0, "eval_replay/inserts": 5224.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1667632034325124e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2958686351776, "timer/env.step_count": 4050.0, "timer/env.step_total": 37.79196763038635, "timer/env.step_frac": 0.03778078947976704, "timer/env.step_avg": 0.009331350032194161, "timer/env.step_min": 0.007659196853637695, "timer/env.step_max": 0.03909778594970703, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.3448166847229, "timer/replay._sample_frac": 0.016339982196491597, "timer/replay._sample_avg": 0.0005044696507630525, "timer/replay._sample_min": 0.00035071372985839844, "timer/replay._sample_max": 0.03277420997619629, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4703.0, "timer/agent.policy_total": 48.2877516746521, "timer/agent.policy_frac": 0.04827346906924329, "timer/agent.policy_avg": 0.010267436035435276, "timer/agent.policy_min": 0.008592605590820312, "timer/agent.policy_max": 0.07689023017883301, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.20759010314941406, "timer/dataset_train_frac": 0.0002075287019156181, "timer/dataset_train_avg": 0.00010251363118489584, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0004134178161621094, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 902.1374068260193, "timer/agent.train_frac": 0.9018705716108899, "timer/agent.train_avg": 0.44549995398815767, "timer/agent.train_min": 0.4338338375091553, "timer/agent.train_max": 1.7034952640533447, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.6888086795806885, "timer/agent.report_frac": 0.0006886049429760336, "timer/agent.report_avg": 0.34440433979034424, "timer/agent.report_min": 0.24579691886901855, "timer/agent.report_max": 0.4430117607116699, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.764837488883801e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 32.39684742179049}
{"step": 450720, "time": 14221.463733911514, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 451208, "time": 14236.134141683578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451328, "time": 14239.99914431572, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451536, "time": 14246.288776874542, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 451576, "time": 14247.274296283722, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 451720, "time": 14251.630478143692, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 451776, "time": 14253.54315662384, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 451864, "time": 14256.073219060898, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 452256, "time": 14268.12288069725, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 452264, "time": 14268.149953365326, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 452296, "time": 14269.136828899384, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452392, "time": 14272.023584365845, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 452400, "time": 14272.494568109512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452472, "time": 14274.454236268997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 452608, "time": 14278.793977975845, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 452872, "time": 14286.698340415955, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 453448, "time": 14304.201617240906, "episode/length": 208.0, "episode/score": 0.3499999940395355, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.0}
{"step": 453448, "time": 14304.207769155502, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 454272, "time": 14329.442135572433, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 454488, "time": 14335.75664138794, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 454568, "time": 14338.20495557785, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454576, "time": 14338.675666570663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454664, "time": 14341.120438337326, "episode/length": 282.0, "episode/score": 0.11874999850988388, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.0}
{"step": 454784, "time": 14344.993844747543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454920, "time": 14348.975121498108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 454920, "time": 14348.980403900146, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 455128, "time": 14355.300628900528, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 455184, "time": 14357.239380836487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 455296, "time": 14360.686410188675, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 455352, "time": 14362.172995090485, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 455496, "time": 14366.525013685226, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 455616, "time": 14370.354876041412, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 455888, "time": 14378.664395093918, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 456016, "time": 14382.55431842804, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 456184, "time": 14387.420716047287, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 456296, "time": 14390.829353094101, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 456560, "time": 14399.013317584991, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 456600, "time": 14400.01277089119, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 456880, "time": 14408.82696723938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 456912, "time": 14409.814053297043, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 457112, "time": 14415.657624483109, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 457232, "time": 14419.547374010086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457440, "time": 14425.858810186386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457584, "time": 14430.212757349014, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 457608, "time": 14430.717853784561, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457808, "time": 14437.087152957916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 457864, "time": 14438.55605173111, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 458032, "time": 14443.85370016098, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 458152, "time": 14447.268294811249, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 458200, "time": 14448.741624832153, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 458208, "time": 14449.20919084549, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 458328, "time": 14452.60417342186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 458608, "time": 14461.327583551407, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 458624, "time": 14461.81454873085, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 458704, "time": 14464.251470327377, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 458720, "time": 14464.737771987915, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 458728, "time": 14464.765126228333, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 459424, "time": 14486.643982887268, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 459472, "time": 14488.123455047607, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 459632, "time": 14492.966829061508, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 459904, "time": 14501.255932569504, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 459920, "time": 14501.742257118225, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 459992, "time": 14503.702566862106, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 14508.265570878983, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 460096, "time": 14508.888607501984, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 460096, "time": 14509.053419589996, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 460096, "time": 14509.11470580101, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 460096, "time": 14509.511490345001, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 460096, "time": 14509.969907283783, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 460096, "time": 14510.534153461456, "eval_episode/length": 190.0, "eval_episode/score": 0.40625, "eval_episode/reward_rate": 0.005235602094240838}
{"step": 460096, "time": 14510.611285924911, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 460200, "time": 14513.539179086685, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 460344, "time": 14517.906454086304, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460520, "time": 14523.202596902847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 460680, "time": 14528.14690065384, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 460680, "time": 14528.152770757675, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 460696, "time": 14528.637026786804, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 460984, "time": 14537.358783245087, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 461040, "time": 14539.276078224182, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 461064, "time": 14539.786390304565, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 461080, "time": 14540.295281648636, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 461616, "time": 14556.863879203796, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 461640, "time": 14557.372804880142, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 461704, "time": 14559.311912536621, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 462072, "time": 14570.4623837471, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 462096, "time": 14571.418637990952, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 462096, "time": 14571.428096294403, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 462296, "time": 14577.276440858841, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 462304, "time": 14577.74614739418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 462456, "time": 14582.122277021408, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 462872, "time": 14594.817932605743, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 463152, "time": 14603.501306056976, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 463184, "time": 14604.466285467148, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 463224, "time": 14605.460392475128, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 463328, "time": 14608.834362506866, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 463376, "time": 14610.292177438736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463392, "time": 14610.783726453781, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 463456, "time": 14612.715432167053, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 463496, "time": 14613.73104596138, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 463536, "time": 14615.177390813828, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 463584, "time": 14616.738268852234, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 463632, "time": 14618.225504875183, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 464064, "time": 14631.305931329727, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 464112, "time": 14632.783114433289, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 464168, "time": 14634.25855064392, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 464264, "time": 14637.167536258698, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 464328, "time": 14639.120662212372, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 464448, "time": 14642.99421954155, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 464600, "time": 14647.461863040924, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 464744, "time": 14651.785514116287, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 464904, "time": 14656.600484371185, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 465000, "time": 14659.508174419403, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 465016, "time": 14659.991347789764, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 465456, "time": 14673.570133447647, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 465472, "time": 14674.061394691467, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 465560, "time": 14676.646112203598, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 465616, "time": 14678.569223165512, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 465896, "time": 14686.899719238281, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 465960, "time": 14688.86584687233, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 466192, "time": 14696.195210456848, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 466224, "time": 14697.168749570847, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 466368, "time": 14701.547453641891, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 466648, "time": 14709.90241765976, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 466856, "time": 14716.294344186783, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 467056, "time": 14723.125507593155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 467320, "time": 14730.950195550919, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 467496, "time": 14736.450635671616, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 467680, "time": 14742.265049695969, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 467696, "time": 14742.755786418915, "episode/length": 259.0, "episode/score": 0.19062499701976776, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 468112, "time": 14755.39411187172, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 468208, "time": 14758.29964017868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468264, "time": 14759.793601512909, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 468272, "time": 14760.283418893814, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468416, "time": 14764.64643907547, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 468680, "time": 14772.576924562454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 468824, "time": 14776.972354412079, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 468928, "time": 14780.381390571594, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 468936, "time": 14780.408073425293, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 469192, "time": 14788.170992851257, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 469368, "time": 14793.506926774979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 469456, "time": 14796.454208135605, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 469456, "time": 14796.459266662598, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 469608, "time": 14800.903430461884, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 469760, "time": 14805.769411087036, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 469808, "time": 14807.2294318676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 14817.084947109222, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 470080, "time": 14818.294135570526, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 470080, "time": 14818.437578201294, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 470080, "time": 14818.518742799759, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 470080, "time": 14818.582848787308, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 470080, "time": 14819.415583848953, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 470080, "time": 14819.704375982285, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 470080, "time": 14819.880831241608, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 470328, "time": 14827.226748943329, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 470392, "time": 14829.187665224075, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 470448, "time": 14831.110632658005, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 470608, "time": 14835.972259283066, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 471184, "time": 14853.40415430069, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 471248, "time": 14855.34012746811, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471304, "time": 14856.891772270203, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 471680, "time": 14868.441962242126, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471688, "time": 14868.468779087067, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 471768, "time": 14870.891473054886, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 471856, "time": 14873.785136461258, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 472048, "time": 14879.57740187645, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 472072, "time": 14880.084275484085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472248, "time": 14885.39886713028, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 472392, "time": 14889.833410978317, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 472640, "time": 14897.577855825424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 472736, "time": 14900.463894367218, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 472848, "time": 14903.873257637024, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 473128, "time": 14912.159348964691, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 473280, "time": 14917.122292518616, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 473368, "time": 14919.578777074814, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 473616, "time": 14927.297778367996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 473880, "time": 14935.0255048275, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 474000, "time": 14938.855121135712, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 474144, "time": 14943.23292183876, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 474208, "time": 14945.190722227097, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 474248, "time": 14946.25197505951, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 474328, "time": 14948.669628620148, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 474400, "time": 14951.086897611618, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 474584, "time": 14956.460026025772, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 474784, "time": 14962.737935304642, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 474880, "time": 14965.696269750595, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 474984, "time": 14968.615736484528, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 475048, "time": 14970.567518949509, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 475096, "time": 14972.018112897873, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 475192, "time": 14975.427389860153, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 475752, "time": 14992.459988594055, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 475816, "time": 14994.400929689407, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 476312, "time": 15009.569969415665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476376, "time": 15011.508188009262, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 476456, "time": 15013.935560464859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 476624, "time": 15019.255795955658, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 476632, "time": 15019.282302618027, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 477192, "time": 15036.266421079636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477272, "time": 15038.713339090347, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 477296, "time": 15039.663630723953, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477360, "time": 15041.598801851273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 477616, "time": 15049.42299079895, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 477776, "time": 15054.277340650558, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 478064, "time": 15063.03928732872, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 478072, "time": 15063.06632399559, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 478160, "time": 15066.000039577484, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 478688, "time": 15081.979634284973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478936, "time": 15089.241435289383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 478944, "time": 15089.710000038147, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479008, "time": 15091.667551994324, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 479448, "time": 15104.94714975357, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 479536, "time": 15107.837051868439, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 479640, "time": 15110.769874811172, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 479800, "time": 15115.604657411575, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 479840, "time": 15117.045902013779, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 479928, "time": 15119.504319667816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 479952, "time": 15120.496935606003, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 15125.267252922058, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 480064, "time": 15125.349872112274, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 480064, "time": 15125.373987674713, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 480064, "time": 15126.965744972229, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 480064, "time": 15127.431186914444, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 480064, "time": 15127.881230354309, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 480064, "time": 15128.019906520844, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 480064, "time": 15128.08069562912, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 480088, "time": 15128.584015846252, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 480256, "time": 15133.882477283478, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 480504, "time": 15141.203025579453, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 480592, "time": 15144.122495889664, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 481064, "time": 15158.211720466614, "episode/length": 201.0, "episode/score": 0.37187498807907104, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.0}
{"step": 481248, "time": 15164.04928612709, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 481416, "time": 15168.907673597336, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 481504, "time": 15171.774878025055, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 481504, "time": 15171.78114438057, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 481512, "time": 15171.808177232742, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 481608, "time": 15174.71410894394, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 481704, "time": 15177.597036361694, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 481752, "time": 15179.064671993256, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 482184, "time": 15192.234444379807, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 482304, "time": 15196.098375320435, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 482424, "time": 15199.526089429855, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 482760, "time": 15209.736587047577, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 482920, "time": 15214.588676691055, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 482944, "time": 15215.541310310364, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 482953, "time": 15216.681365966797, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.1604390663675743, "train/action_min": 0.0, "train/action_std": 1.8938782988208356, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012800344336307654, "train/actor_opt_grad_steps": 29075.0, "train/actor_opt_loss": -7.7683461687002, "train/adv_mag": 1.0115166713695716, "train/adv_max": 0.36738349423550143, "train/adv_mean": 0.002557029364841511, "train/adv_min": -0.9910564390149447, "train/adv_std": 0.040790934159448095, "train/cont_avg": 0.995426593440594, "train/cont_loss_mean": 0.014249850357283312, "train/cont_loss_std": 0.21237633048123358, "train/cont_neg_acc": 0.38198918480426075, "train/cont_neg_loss": 2.557320678846445, "train/cont_pos_acc": 0.9998591140945359, "train/cont_pos_loss": 0.0030494330356953354, "train/cont_pred": 0.995304815840013, "train/cont_rate": 0.995426593440594, "train/dyn_loss_mean": 1.0000120519411446, "train/dyn_loss_std": 0.0003591988193641168, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4989314295794114, "train/extr_critic_critic_opt_grad_steps": 29075.0, "train/extr_critic_critic_opt_loss": 4760.130378345451, "train/extr_critic_mag": 1.2709832014423785, "train/extr_critic_max": 1.2709832014423785, "train/extr_critic_mean": 1.2067386159802427, "train/extr_critic_min": 0.9702705138980752, "train/extr_critic_std": 0.016144515220352477, "train/extr_return_normed_mag": 0.9973225717497344, "train/extr_return_normed_max": 0.2973901918618986, "train/extr_return_normed_mean": 0.03282694516491403, "train/extr_return_normed_min": -0.9727818812474166, "train/extr_return_normed_std": 0.044920274157925405, "train/extr_return_rate": 0.9982896101946878, "train/extr_return_raw_mag": 1.4738589542927127, "train/extr_return_raw_max": 1.4738589542927127, "train/extr_return_raw_mean": 1.2092957785814116, "train/extr_return_raw_min": 0.20368688118339764, "train/extr_return_raw_std": 0.04492027428240912, "train/extr_reward_mag": 0.3302270770072937, "train/extr_reward_max": 0.3302270770072937, "train/extr_reward_mean": 0.0028887048241507153, "train/extr_reward_min": 8.793160466864557e-08, "train/extr_reward_std": 0.012179171864754788, "train/image_loss_mean": 0.09652817828377874, "train/image_loss_std": 0.102517515015189, "train/model_loss_mean": 0.7208354915722762, "train/model_loss_std": 0.3931472523156369, "train/model_opt_grad_norm": 25.0432123949032, "train/model_opt_grad_steps": 29048.559405940596, "train/model_opt_loss": 1954.3237377204518, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2710.3960396039606, "train/policy_entropy_mag": 1.3295562698109316, "train/policy_entropy_max": 1.3295562698109316, "train/policy_entropy_mean": 0.11353740387476317, "train/policy_entropy_min": 0.0646865144740827, "train/policy_entropy_std": 0.1467386864420801, "train/policy_logprob_mag": 6.551080231619354, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11336751400244117, "train/policy_logprob_min": -6.551080231619354, "train/policy_logprob_std": 0.6493517216479424, "train/policy_randomness_mag": 0.6832568019923597, "train/policy_randomness_max": 0.6832568019923597, "train/policy_randomness_mean": 0.05834668688476086, "train/policy_randomness_min": 0.03324229384560396, "train/policy_randomness_std": 0.07540877215047874, "train/post_ent_mag": 26.637503671174002, "train/post_ent_max": 26.637503671174002, "train/post_ent_mean": 26.152761053330828, "train/post_ent_min": 25.833518783644873, "train/post_ent_std": 0.15347670070310632, "train/prior_ent_mag": 29.631738294469248, "train/prior_ent_max": 29.631738294469248, "train/prior_ent_mean": 25.153086048541685, "train/prior_ent_min": 23.50429666160357, "train/prior_ent_std": 0.8963586773612712, "train/rep_loss_mean": 1.0000120519411446, "train/rep_loss_std": 0.0003591988193641168, "train/reward_avg": 0.0012424129067452182, "train/reward_loss_mean": 0.01005021070180885, "train/reward_loss_std": 0.1778455782303642, "train/reward_max_data": 0.6164913369287358, "train/reward_max_pred": 0.18709883536442673, "train/reward_neg_acc": 0.9997577625926178, "train/reward_neg_loss": 0.0017133572039143689, "train/reward_pos_acc": 0.16705202479238454, "train/reward_pos_loss": 4.339666597415946, "train/reward_pred": 0.0010170683271648123, "train/reward_rate": 0.0019434560643564356, "train_stats/mean_log_entropy": 0.09323683574999848, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.004091427195817232, "report/cont_loss_std": 0.08841321617364883, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 0.9471503496170044, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0013204405549913645, "report/cont_pred": 0.9966953992843628, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07357871532440186, "report/image_loss_std": 0.08540625870227814, "report/model_loss_mean": 0.6836680769920349, "report/model_loss_std": 0.27553191781044006, "report/post_ent_mag": 25.950252532958984, "report/post_ent_max": 25.950252532958984, "report/post_ent_mean": 25.482826232910156, "report/post_ent_min": 25.17310333251953, "report/post_ent_std": 0.13916781544685364, "report/prior_ent_mag": 29.28607940673828, "report/prior_ent_max": 29.28607940673828, "report/prior_ent_mean": 24.96364402770996, "report/prior_ent_min": 23.49951171875, "report/prior_ent_std": 0.8039833307266235, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003143310605082661, "report/reward_loss_mean": 0.005997872445732355, "report/reward_loss_std": 0.16021808981895447, "report/reward_max_data": 0.3218750059604645, "report/reward_max_pred": 0.04273557662963867, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.000991396140307188, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.127623081207275, "report/reward_pred": 0.0005270612891763449, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.050422847270965576, "eval/cont_loss_std": 0.7693639993667603, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.298833847045898, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.002389861037954688, "eval/cont_pred": 0.998024582862854, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19881422817707062, "eval/image_loss_std": 0.14381039142608643, "eval/model_loss_mean": 0.8493471145629883, "eval/model_loss_std": 0.7822996377944946, "eval/post_ent_mag": 25.946077346801758, "eval/post_ent_max": 25.946077346801758, "eval/post_ent_mean": 25.46314239501953, "eval/post_ent_min": 25.18657684326172, "eval/post_ent_std": 0.14139211177825928, "eval/prior_ent_mag": 29.28607940673828, "eval/prior_ent_max": 29.28607940673828, "eval/prior_ent_mean": 24.966358184814453, "eval/prior_ent_min": 23.15985107421875, "eval/prior_ent_std": 0.8264275789260864, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0001100604422390461, "eval/reward_loss_std": 0.0009571498376317322, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.010345935821533203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0001100604422390461, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 5.510426126420498e-05, "eval/reward_rate": 0.0, "replay/size": 482449.0, "replay/inserts": 32393.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.346767252307718e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.723363829247745e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1801222960154216e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2410762310028, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.09760904312134, "timer/env.step_frac": 0.038088426828736636, "timer/env.step_avg": 0.009406817047684281, "timer/env.step_min": 0.007689714431762695, "timer/env.step_max": 0.0402982234954834, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.414904594421387, "timer/replay._sample_frac": 0.01641094830485687, "timer/replay._sample_avg": 0.0005066328578525119, "timer/replay._sample_min": 0.00040411949157714844, "timer/replay._sample_max": 0.010701894760131836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4650.0, "timer/agent.policy_total": 48.28156089782715, "timer/agent.policy_frac": 0.04826992416643831, "timer/agent.policy_avg": 0.010383131375876806, "timer/agent.policy_min": 0.008937597274780273, "timer/agent.policy_max": 0.09333467483520508, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.20998334884643555, "timer/dataset_train_frac": 0.00020993273905294056, "timer/dataset_train_avg": 0.00010369548091182003, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0009572505950927734, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 902.3376815319061, "timer/agent.train_frac": 0.9021202017937462, "timer/agent.train_avg": 0.44559885507748453, "timer/agent.train_min": 0.4343445301055908, "timer/agent.train_max": 0.6927285194396973, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812142848968506, "timer/agent.report_frac": 0.00048109830353109344, "timer/agent.report_avg": 0.2406071424484253, "timer/agent.report_min": 0.23381614685058594, "timer/agent.report_max": 0.24739813804626465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.600120544433594e-05, "timer/dataset_eval_frac": 3.59925285012206e-08, "timer/dataset_eval_avg": 3.600120544433594e-05, "timer/dataset_eval_min": 3.600120544433594e-05, "timer/dataset_eval_max": 3.600120544433594e-05, "fps": 32.384640689296866}
{"step": 483360, "time": 15229.548475265503, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 483440, "time": 15231.99203300476, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 483448, "time": 15232.019104719162, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 483536, "time": 15234.955630779266, "episode/length": 11.0, "episode/score": 0.965624988079071, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0}
{"step": 483560, "time": 15235.475404024124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483816, "time": 15243.285468101501, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 483944, "time": 15247.24892115593, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 484256, "time": 15257.026619195938, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 484496, "time": 15264.37784910202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 484568, "time": 15266.352080106735, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 484664, "time": 15269.275151491165, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 484744, "time": 15271.693276166916, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 484792, "time": 15273.169812202454, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 484968, "time": 15278.666611671448, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 485048, "time": 15281.105167388916, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 485064, "time": 15281.597370147705, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 485256, "time": 15287.49578499794, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485456, "time": 15293.800050020218, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 485592, "time": 15297.748718976974, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 485672, "time": 15300.183190822601, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 485776, "time": 15303.562149047852, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 486064, "time": 15312.35189461708, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 486064, "time": 15312.357842206955, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 486704, "time": 15331.725279808044, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 486752, "time": 15333.169048309326, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 486824, "time": 15335.12309551239, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 487248, "time": 15348.237531661987, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 487296, "time": 15349.687333583832, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 487376, "time": 15352.118196487427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487568, "time": 15357.943035125732, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487712, "time": 15362.318434476852, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 487768, "time": 15363.796735525131, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 487936, "time": 15369.204588890076, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 488104, "time": 15374.065569162369, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 488152, "time": 15375.531435966492, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 488192, "time": 15376.971444606781, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 488200, "time": 15376.999406337738, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 488944, "time": 15399.86476802826, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 489064, "time": 15403.260020256042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489224, "time": 15408.118188619614, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 489272, "time": 15409.590959072113, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 489312, "time": 15411.02919960022, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 489424, "time": 15414.446378707886, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 489560, "time": 15418.391597270966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 489576, "time": 15418.880155563354, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 489816, "time": 15426.267802476883, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 15435.229443788528, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 490048, "time": 15435.627453327179, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 490048, "time": 15435.986976623535, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 490048, "time": 15436.411237716675, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 490048, "time": 15436.958400964737, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 490048, "time": 15437.26648569107, "eval_episode/length": 191.0, "eval_episode/score": 0.40312498807907104, "eval_episode/reward_rate": 0.005208333333333333}
{"step": 490048, "time": 15437.784472703934, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 490048, "time": 15437.828726530075, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 490080, "time": 15438.802681684494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 490304, "time": 15445.613078594208, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 490824, "time": 15461.296633720398, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 490856, "time": 15462.28739285469, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 490912, "time": 15464.210906028748, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 491008, "time": 15467.151340961456, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 491152, "time": 15471.53640294075, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 491376, "time": 15478.368268251419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491584, "time": 15485.190341234207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491624, "time": 15486.289710760117, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 491824, "time": 15492.627740621567, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 492176, "time": 15503.359734535217, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 492424, "time": 15510.687589406967, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 492616, "time": 15516.680925607681, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 492704, "time": 15519.580229759216, "episode/length": 211.0, "episode/score": 0.34062498807907104, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.0}
{"step": 492776, "time": 15521.54251241684, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 492928, "time": 15526.363816261292, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 492992, "time": 15528.298768758774, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 493224, "time": 15535.121966362, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 493376, "time": 15539.978378534317, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 493456, "time": 15542.418999195099, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 493864, "time": 15554.678861141205, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 493928, "time": 15556.666944265366, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 494064, "time": 15561.046276569366, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 494136, "time": 15563.011071920395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 494624, "time": 15578.28292798996, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 494944, "time": 15588.111598491669, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 495032, "time": 15590.597950220108, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 495088, "time": 15592.532799482346, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 495144, "time": 15594.005485773087, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 495200, "time": 15595.948728561401, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 495448, "time": 15603.286887168884, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 495544, "time": 15606.3154900074, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 495624, "time": 15608.74815440178, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 496224, "time": 15627.136646032333, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 496384, "time": 15631.984632492065, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 496728, "time": 15642.300281524658, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 496784, "time": 15644.231436014175, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 496936, "time": 15648.641267299652, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497008, "time": 15651.052869081497, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 497056, "time": 15652.501875638962, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 497096, "time": 15653.510475635529, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 497128, "time": 15654.484789848328, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 497128, "time": 15654.49006319046, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 497672, "time": 15671.120900392532, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 497696, "time": 15672.083719491959, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 497744, "time": 15673.565782546997, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 497760, "time": 15674.053411960602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 497776, "time": 15674.539942264557, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 497872, "time": 15677.476474523544, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 497944, "time": 15679.42962884903, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 498384, "time": 15692.962306499481, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 498432, "time": 15694.413694620132, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 498432, "time": 15694.420244932175, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 498488, "time": 15695.949136972427, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 498560, "time": 15698.382098674774, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 498624, "time": 15700.326316356659, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 498848, "time": 15707.094369649887, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 498952, "time": 15710.007682800293, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 499112, "time": 15714.840789079666, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 499416, "time": 15724.04614329338, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 499488, "time": 15726.521792173386, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 499752, "time": 15734.765110492706, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 499976, "time": 15741.588132619858, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 15744.78038930893, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 500032, "time": 15745.58346581459, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 500032, "time": 15745.86489200592, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 500032, "time": 15745.928238153458, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 500032, "time": 15746.327742815018, "eval_episode/length": 147.0, "eval_episode/score": 0.5406249761581421, "eval_episode/reward_rate": 0.006756756756756757}
{"step": 500032, "time": 15746.764647245407, "eval_episode/length": 170.0, "eval_episode/score": 0.46875, "eval_episode/reward_rate": 0.005847953216374269}
{"step": 500032, "time": 15747.588925123215, "eval_episode/length": 214.0, "eval_episode/score": 0.33125001192092896, "eval_episode/reward_rate": 0.004651162790697674}
{"step": 500032, "time": 15747.649081468582, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 500184, "time": 15752.007369279861, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500400, "time": 15758.837233066559, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 500664, "time": 15766.593762636185, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 500792, "time": 15770.457931995392, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 500800, "time": 15770.929438591003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 500832, "time": 15771.89383649826, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 501160, "time": 15781.55310845375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 501208, "time": 15783.002039670944, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 501232, "time": 15783.964657068253, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 501240, "time": 15783.991139411926, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 501256, "time": 15784.47613453865, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 501328, "time": 15786.940463066101, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 501816, "time": 15801.43845629692, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 501840, "time": 15802.38824391365, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 501880, "time": 15803.403207540512, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 501968, "time": 15806.258431911469, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 502256, "time": 15814.961467027664, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 502328, "time": 15816.997735500336, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 502368, "time": 15818.450217485428, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 502376, "time": 15818.476396799088, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 502632, "time": 15826.215090751648, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 502904, "time": 15834.461851358414, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 502936, "time": 15835.43495297432, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 503016, "time": 15837.862524032593, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 503136, "time": 15841.696251153946, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 503544, "time": 15853.957161903381, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 503568, "time": 15854.909066915512, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 503728, "time": 15859.725560188293, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 503824, "time": 15862.617889404297, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 503872, "time": 15864.06119441986, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 504192, "time": 15873.700381278992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504400, "time": 15880.091379642487, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 504600, "time": 15885.91919708252, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 504680, "time": 15888.35123515129, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 504880, "time": 15894.607453346252, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 504888, "time": 15894.633826971054, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 504944, "time": 15896.55310511589, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505368, "time": 15909.195985555649, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 505720, "time": 15919.859087467194, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 505776, "time": 15921.76724934578, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 505856, "time": 15924.169001102448, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505880, "time": 15924.695573329926, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 505912, "time": 15925.658387422562, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 506712, "time": 15949.813334941864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506800, "time": 15952.67966413498, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 506816, "time": 15953.168069839478, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 506912, "time": 15956.090191841125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 506992, "time": 15958.522987604141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 507024, "time": 15959.483817577362, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 507040, "time": 15959.968729019165, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 507168, "time": 15963.832813501358, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 507216, "time": 15965.281033039093, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 507368, "time": 15969.746888875961, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 507616, "time": 15977.425535678864, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 507632, "time": 15977.92992401123, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 507760, "time": 15981.781609296799, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 508032, "time": 15990.526112794876, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508048, "time": 15991.013752937317, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 508056, "time": 15991.040606021881, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 508152, "time": 15993.95417189598, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 508224, "time": 15996.444306373596, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 508544, "time": 16006.164690971375, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 508672, "time": 16010.038590669632, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 508688, "time": 16010.52900671959, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 508912, "time": 16017.284940242767, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 508928, "time": 16017.776233434677, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 509144, "time": 16024.053114652634, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 509144, "time": 16024.057959794998, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 509352, "time": 16030.42645740509, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 509528, "time": 16035.745955228806, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 509528, "time": 16035.752983570099, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 509592, "time": 16037.691277980804, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 509600, "time": 16038.158411026001, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 509992, "time": 16049.736031293869, "episode/length": 242.0, "episode/score": 0.24375000596046448, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 16051.835379123688, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 510016, "time": 16051.949620723724, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 510016, "time": 16052.198036670685, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 510016, "time": 16052.334902048111, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 510016, "time": 16052.43703508377, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 510016, "time": 16052.759729623795, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 510016, "time": 16053.90209889412, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 510016, "time": 16054.146305561066, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 510024, "time": 16054.171660900116, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 510088, "time": 16056.258160352707, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 510104, "time": 16056.746765375137, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 510272, "time": 16062.05487203598, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 510536, "time": 16069.851523399353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 510720, "time": 16075.62633061409, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 510864, "time": 16079.94999051094, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 510872, "time": 16079.97728562355, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 510968, "time": 16082.858884811401, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 510968, "time": 16082.864466428757, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 511088, "time": 16086.789595603943, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 511480, "time": 16098.413845539093, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 511512, "time": 16099.379432678223, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 511584, "time": 16101.763892412186, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 511720, "time": 16105.641268730164, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 511728, "time": 16106.108223199844, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 511840, "time": 16109.485232830048, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 511848, "time": 16109.512141942978, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 512096, "time": 16117.32627749443, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 512360, "time": 16125.076194286346, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 512704, "time": 16135.665070772171, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 512744, "time": 16136.645158290863, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 512848, "time": 16140.007467269897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 513416, "time": 16157.054028511047, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 513432, "time": 16157.542736530304, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 513496, "time": 16159.479018449783, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 513512, "time": 16159.963840723038, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 513592, "time": 16162.386531591415, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 513728, "time": 16166.712481021881, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 513824, "time": 16169.603711605072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514032, "time": 16175.947259902954, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 514040, "time": 16175.998317241669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514152, "time": 16179.397819042206, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 514304, "time": 16184.195959329605, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 514544, "time": 16191.443695545197, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 514904, "time": 16202.097710847855, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 514928, "time": 16203.04645228386, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 514976, "time": 16204.500839710236, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 515160, "time": 16209.932467460632, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 515353, "time": 16216.736690282822, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2945481474176415, "train/action_min": 0.0, "train/action_std": 1.8296133555802219, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.015124400714045309, "train/actor_opt_grad_steps": 31100.0, "train/actor_opt_loss": -9.751555561725729, "train/adv_mag": 1.0391330075968663, "train/adv_max": 0.3426244176667312, "train/adv_mean": 0.002325536219458058, "train/adv_min": -1.019924702021876, "train/adv_std": 0.045607269374571116, "train/cont_avg": 0.9952759390394089, "train/cont_loss_mean": 0.014692838445392993, "train/cont_loss_std": 0.21132194493631168, "train/cont_neg_acc": 0.3962311530068739, "train/cont_neg_loss": 2.358570680267812, "train/cont_pos_acc": 0.9998115271770308, "train/cont_pos_loss": 0.0032459861484787477, "train/cont_pred": 0.9951630927659021, "train/cont_rate": 0.9952759390394089, "train/dyn_loss_mean": 1.000001511550302, "train/dyn_loss_std": 4.8358237664467594e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4439481334219425, "train/extr_critic_critic_opt_grad_steps": 31100.0, "train/extr_critic_critic_opt_loss": 5212.560172846752, "train/extr_critic_mag": 1.3169538974761963, "train/extr_critic_max": 1.3169538974761963, "train/extr_critic_mean": 1.2195101001579773, "train/extr_critic_min": 1.0728561772501528, "train/extr_critic_std": 0.01825997698593316, "train/extr_return_normed_mag": 1.0140960915335293, "train/extr_return_normed_max": 0.3642082554953439, "train/extr_return_normed_mean": 0.03688970688051484, "train/extr_return_normed_min": -0.9895266940441038, "train/extr_return_normed_std": 0.05016793715285844, "train/extr_return_rate": 0.9988891074222884, "train/extr_return_raw_mag": 1.5491543432761883, "train/extr_return_raw_max": 1.5491543432761883, "train/extr_return_raw_mean": 1.2218358604778796, "train/extr_return_raw_min": 0.19541939373674064, "train/extr_return_raw_std": 0.05016793717579742, "train/extr_reward_mag": 0.37789311256314734, "train/extr_reward_max": 0.37789311256314734, "train/extr_reward_mean": 0.002921596820652026, "train/extr_reward_min": 7.692816222242534e-08, "train/extr_reward_std": 0.01475200652984416, "train/image_loss_mean": 0.09504397261172093, "train/image_loss_std": 0.1024220781079654, "train/model_loss_mean": 0.7207426695988096, "train/model_loss_std": 0.40631294577139354, "train/model_opt_grad_norm": 25.02874782297871, "train/model_opt_grad_steps": 31071.77339901478, "train/model_opt_loss": 1995.9757825729296, "train/model_opt_model_opt_grad_overflow": 0.0049261083743842365, "train/model_opt_model_opt_grad_scale": 2758.6206896551726, "train/policy_entropy_mag": 1.351834661854899, "train/policy_entropy_max": 1.351834661854899, "train/policy_entropy_mean": 0.12452746571725225, "train/policy_entropy_min": 0.06468652853090774, "train/policy_entropy_std": 0.16198791945215515, "train/policy_logprob_mag": 6.551080240991903, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.12469164454584639, "train/policy_logprob_min": -6.551080240991903, "train/policy_logprob_std": 0.661178625569555, "train/policy_randomness_mag": 0.6947056331070773, "train/policy_randomness_max": 0.6947056331070773, "train/policy_randomness_mean": 0.06399446177144943, "train/policy_randomness_min": 0.03324230163922451, "train/policy_randomness_std": 0.08324532831096884, "train/post_ent_mag": 25.44558793805503, "train/post_ent_max": 25.44558793805503, "train/post_ent_mean": 24.97746527723491, "train/post_ent_min": 24.67092391892607, "train/post_ent_std": 0.1465994598243037, "train/prior_ent_mag": 28.44004452522165, "train/prior_ent_max": 28.44004452522165, "train/prior_ent_mean": 24.128859064261903, "train/prior_ent_min": 22.656801674753574, "train/prior_ent_std": 0.8389343299301975, "train/rep_loss_mean": 1.000001511550302, "train/rep_loss_std": 4.8358237664467594e-05, "train/reward_avg": 0.0013800710332155539, "train/reward_loss_mean": 0.011004928904906687, "train/reward_loss_std": 0.19167982304945883, "train/reward_max_data": 0.6853910092943407, "train/reward_max_pred": 0.21745748825261157, "train/reward_neg_acc": 0.999691435562566, "train/reward_neg_loss": 0.001937843280990053, "train/reward_pos_acc": 0.18342151812144689, "train/reward_pos_loss": 4.230993178155687, "train/reward_pred": 0.001115899218195875, "train/reward_rate": 0.0021407404556650247, "train_stats/mean_log_entropy": 0.1035295909629809, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.016044629737734795, "report/cont_loss_std": 0.24537257850170135, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.322291135787964, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0030789566226303577, "report/cont_pred": 0.9959487915039062, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09487918019294739, "report/image_loss_std": 0.11075496673583984, "report/model_loss_mean": 0.7216705083847046, "report/model_loss_std": 0.44144728779792786, "report/post_ent_mag": 25.236440658569336, "report/post_ent_max": 25.236440658569336, "report/post_ent_mean": 24.797832489013672, "report/post_ent_min": 24.48432731628418, "report/post_ent_std": 0.14271727204322815, "report/prior_ent_mag": 29.768953323364258, "report/prior_ent_max": 29.768953323364258, "report/prior_ent_mean": 24.235050201416016, "report/prior_ent_min": 22.916400909423828, "report/prior_ent_std": 0.9243882894515991, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0013214111095294356, "report/reward_loss_mean": 0.010746701620519161, "report/reward_loss_std": 0.2029692381620407, "report/reward_max_data": 0.778124988079071, "report/reward_max_pred": 0.11376774311065674, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.001778084202669561, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.593709945678711, "report/reward_pred": 0.0008854672778397799, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0431448370218277, "eval/cont_loss_std": 0.6981068253517151, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.828580856323242, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.000849007919896394, "eval/cont_pred": 0.9991679191589355, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2007751762866974, "eval/image_loss_std": 0.16300910711288452, "eval/model_loss_mean": 0.8439935445785522, "eval/model_loss_std": 0.7160181999206543, "eval/post_ent_mag": 25.24047088623047, "eval/post_ent_max": 25.24047088623047, "eval/post_ent_mean": 24.76596450805664, "eval/post_ent_min": 24.466123580932617, "eval/post_ent_std": 0.1428682804107666, "eval/prior_ent_mag": 29.768953323364258, "eval/prior_ent_max": 29.768953323364258, "eval/prior_ent_mean": 24.109683990478516, "eval/prior_ent_min": 22.939817428588867, "eval/prior_ent_std": 0.9439524412155151, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 7.349066436290741e-05, "eval/reward_loss_std": 0.0004509032005444169, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0027227401733398438, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 7.349066436290741e-05, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 3.56544042006135e-05, "eval/reward_rate": 0.0, "replay/size": 514849.0, "replay/inserts": 32400.0, "replay/samples": 32400.0, "replay/insert_wait_avg": 1.3643503189086914e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.646319306926963e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1442184448242187e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0407068729401, "timer/env.step_count": 4050.0, "timer/env.step_total": 38.05888891220093, "timer/env.step_frac": 0.03805733971690863, "timer/env.step_avg": 0.009397256521531094, "timer/env.step_min": 0.00770115852355957, "timer/env.step_max": 0.035521745681762695, "timer/replay._sample_count": 32400.0, "timer/replay._sample_total": 16.534312963485718, "timer/replay._sample_frac": 0.01653363993070582, "timer/replay._sample_avg": 0.0005103183013421518, "timer/replay._sample_min": 0.0004088878631591797, "timer/replay._sample_max": 0.031122684478759766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4675.0, "timer/agent.policy_total": 48.288066148757935, "timer/agent.policy_frac": 0.048286100572597156, "timer/agent.policy_avg": 0.010328998106686188, "timer/agent.policy_min": 0.008988618850708008, "timer/agent.policy_max": 0.0768885612487793, "timer/dataset_train_count": 2025.0, "timer/dataset_train_total": 0.20872926712036133, "timer/dataset_train_frac": 0.00020872077075046643, "timer/dataset_train_avg": 0.00010307618129400559, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.00027060508728027344, "timer/agent.train_count": 2025.0, "timer/agent.train_total": 901.9957699775696, "timer/agent.train_frac": 0.9019590540449595, "timer/agent.train_avg": 0.44543000986546644, "timer/agent.train_min": 0.4320981502532959, "timer/agent.train_max": 0.6906518936157227, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47742128372192383, "timer/agent.report_frac": 0.00047740185018546697, "timer/agent.report_avg": 0.23871064186096191, "timer/agent.report_min": 0.23202157020568848, "timer/agent.report_max": 0.24539971351623535, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7178611661286543e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 32.39811392377157}
{"step": 515464, "time": 16219.819879055023, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 515680, "time": 16226.536629915237, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 515824, "time": 16230.884640455246, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515904, "time": 16233.299801826477, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 515912, "time": 16233.326629400253, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 515960, "time": 16234.789356470108, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 516136, "time": 16240.64795923233, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516240, "time": 16244.009145736694, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 516512, "time": 16252.233746051788, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 516616, "time": 16255.16199707985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 516784, "time": 16260.445229053497, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 517320, "time": 16276.429048776627, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 517384, "time": 16278.363873004913, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 517480, "time": 16281.288309574127, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 517984, "time": 16296.85713505745, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 517992, "time": 16296.884958744049, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518136, "time": 16301.249353170395, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518224, "time": 16304.14388871193, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518272, "time": 16305.59249329567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518496, "time": 16312.34303855896, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 518552, "time": 16313.829779624939, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 518632, "time": 16316.24238562584, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 518664, "time": 16317.210662126541, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 518880, "time": 16323.998864412308, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 518968, "time": 16326.53223824501, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 519032, "time": 16328.5035738945, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 519152, "time": 16332.436069488525, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 519264, "time": 16335.858523845673, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 519296, "time": 16336.8327627182, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 519328, "time": 16337.816193819046, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 519592, "time": 16345.548880338669, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 519904, "time": 16355.191678524017, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 519920, "time": 16355.678170204163, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 519936, "time": 16356.249553442001, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 16359.287860155106, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 520000, "time": 16359.46904873848, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 520000, "time": 16359.910709381104, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 520000, "time": 16359.934953689575, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 520000, "time": 16360.143250465393, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 520000, "time": 16361.163269996643, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 520000, "time": 16361.595965623856, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 520000, "time": 16361.714323043823, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 520160, "time": 16366.553606987, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 520232, "time": 16368.499996423721, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 520376, "time": 16372.842900037766, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 520432, "time": 16374.766021966934, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 520640, "time": 16381.022703886032, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 520696, "time": 16382.49262547493, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 521120, "time": 16395.5459690094, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 521280, "time": 16400.37020254135, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521408, "time": 16404.241051912308, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 521608, "time": 16410.053513288498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 521768, "time": 16414.91439986229, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 521904, "time": 16419.32798576355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522048, "time": 16423.703543663025, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 522064, "time": 16424.197449207306, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 522216, "time": 16428.611998558044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 522328, "time": 16431.977571487427, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 522680, "time": 16442.62534880638, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 522736, "time": 16444.53298306465, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 522952, "time": 16450.882087945938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523280, "time": 16461.02650284767, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 523368, "time": 16463.479882001877, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 523440, "time": 16465.89301800728, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 523592, "time": 16470.26735496521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 523800, "time": 16476.645364284515, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 523832, "time": 16477.616332530975, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 523880, "time": 16479.06162238121, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 524080, "time": 16485.313319921494, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524280, "time": 16491.19052529335, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 524376, "time": 16494.566610097885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 524472, "time": 16497.482849359512, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 524760, "time": 16506.250887155533, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 525064, "time": 16515.44088792801, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 525088, "time": 16516.42496728897, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 525128, "time": 16517.412271022797, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 525368, "time": 16524.669405698776, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 525640, "time": 16532.881717205048, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 525680, "time": 16534.31484079361, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525752, "time": 16536.39030981064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 525800, "time": 16537.85186624527, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 525968, "time": 16543.13871383667, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 526112, "time": 16547.489802837372, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526144, "time": 16548.458727121353, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 526280, "time": 16552.35263442993, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 526496, "time": 16559.08822798729, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 526824, "time": 16568.859557151794, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 526912, "time": 16571.74164199829, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 527216, "time": 16580.93642616272, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 527224, "time": 16580.963006973267, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 527224, "time": 16580.968532323837, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 527224, "time": 16580.975308418274, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 527440, "time": 16587.730990171432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 527896, "time": 16601.427464723587, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 527920, "time": 16602.382065057755, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 528064, "time": 16606.74455022812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 528288, "time": 16613.550042152405, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 528704, "time": 16626.19993329048, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 528896, "time": 16631.968410491943, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 529224, "time": 16641.66826939583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529360, "time": 16646.01264333725, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 529368, "time": 16646.039010047913, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 529536, "time": 16651.328608989716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529752, "time": 16657.731436491013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 529816, "time": 16659.66618323326, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 529896, "time": 16662.081991672516, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 529952, "time": 16663.98908305168, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 529968, "time": 16664.473588705063, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 16668.600013256073, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 530088, "time": 16669.931212425232, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 530088, "time": 16670.14003920555, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 530088, "time": 16670.181577920914, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 530088, "time": 16670.59435558319, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 530088, "time": 16671.762358665466, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 530088, "time": 16672.410194158554, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 530088, "time": 16672.85349535942, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 530232, "time": 16677.198461055756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 530472, "time": 16684.413771629333, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 530488, "time": 16684.897297620773, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 530504, "time": 16685.38367652893, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 530632, "time": 16689.322546720505, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 530760, "time": 16693.186235427856, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 530768, "time": 16693.649767398834, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 530840, "time": 16695.609563350677, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 531112, "time": 16703.801208734512, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 531160, "time": 16705.26543045044, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 531376, "time": 16711.999641895294, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 531536, "time": 16716.955324172974, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 531616, "time": 16719.371865034103, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 531656, "time": 16720.377388477325, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 531800, "time": 16724.72492814064, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 532000, "time": 16730.99718928337, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 532088, "time": 16733.420567035675, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 532120, "time": 16734.415647268295, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 532128, "time": 16734.883610248566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532456, "time": 16744.543756246567, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 532768, "time": 16754.82142305374, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 532784, "time": 16755.306694746017, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 532784, "time": 16755.31267261505, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 532872, "time": 16757.74823999405, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 533080, "time": 16764.02698779106, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533112, "time": 16764.9944190979, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 533160, "time": 16766.437073469162, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 533600, "time": 16780.061291217804, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 533968, "time": 16791.133088588715, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 533992, "time": 16791.639385461807, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 534104, "time": 16795.030238628387, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 534216, "time": 16798.428416013718, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 534496, "time": 16807.17250609398, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 534768, "time": 16815.403491020203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 534776, "time": 16815.430207967758, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 534864, "time": 16818.325971126556, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 535056, "time": 16824.09481573105, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 535080, "time": 16824.616728067398, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535184, "time": 16827.99468231201, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 535440, "time": 16835.807326555252, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 535456, "time": 16836.388982772827, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 535720, "time": 16844.147576093674, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 535736, "time": 16844.637324094772, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 535912, "time": 16849.965260505676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536280, "time": 16861.05264687538, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 536304, "time": 16862.00150489807, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 536336, "time": 16862.974744796753, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 536336, "time": 16862.98029780388, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 536464, "time": 16866.94566488266, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 537024, "time": 16883.829297065735, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 537176, "time": 16888.194900989532, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537264, "time": 16891.076902627945, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 537392, "time": 16894.948049545288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 537480, "time": 16897.46886062622, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 537568, "time": 16900.363782405853, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 537792, "time": 16907.170768737793, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 538032, "time": 16914.423327445984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538224, "time": 16920.20200610161, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538616, "time": 16931.885241270065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 538840, "time": 16938.673151016235, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 538880, "time": 16940.100541353226, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 538904, "time": 16940.60910654068, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 539240, "time": 16950.727570295334, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 539488, "time": 16958.569050312042, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 539616, "time": 16962.45431494713, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 539664, "time": 16963.919845581055, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 539704, "time": 16964.91170191765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 539760, "time": 16966.83316540718, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 539792, "time": 16967.826639175415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540048, "time": 16975.555818080902, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 16977.370714902878, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 540072, "time": 16977.46834588051, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 540072, "time": 16977.472887277603, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 540072, "time": 16977.740212202072, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 540072, "time": 16977.802002429962, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 540072, "time": 16977.80703139305, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 540072, "time": 16978.190680265427, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 540072, "time": 16978.73948121071, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 540104, "time": 16979.705222845078, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 540360, "time": 16987.587420225143, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 540600, "time": 16994.853094816208, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 540656, "time": 16996.771829128265, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 540832, "time": 17002.525129318237, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 540872, "time": 17003.51444387436, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 541064, "time": 17009.291682958603, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 541464, "time": 17021.49626302719, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 541488, "time": 17022.436067819595, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 541520, "time": 17023.405275583267, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 541928, "time": 17035.515847444534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542016, "time": 17038.386305093765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542048, "time": 17039.371046066284, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 542360, "time": 17048.66135430336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 542408, "time": 17050.098028421402, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 542576, "time": 17055.41067957878, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 542800, "time": 17062.170385599136, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 542856, "time": 17063.650111436844, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 542936, "time": 17066.049443483353, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 542944, "time": 17066.518904685974, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 542944, "time": 17066.52459383011, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 542952, "time": 17066.553195238113, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 543328, "time": 17078.189997673035, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 543392, "time": 17080.124429941177, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 543552, "time": 17084.94273376465, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 543632, "time": 17087.36641383171, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 543696, "time": 17089.291652441025, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 543872, "time": 17094.603615760803, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 543872, "time": 17094.608672380447, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 544208, "time": 17104.753796100616, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 544248, "time": 17105.74030995369, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 544368, "time": 17109.671028375626, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 544728, "time": 17120.327214479446, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 544736, "time": 17120.79512834549, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 544808, "time": 17122.772547483444, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 544920, "time": 17126.177062034607, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 545264, "time": 17136.909346342087, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545360, "time": 17139.799406051636, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 545440, "time": 17142.22690320015, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 545600, "time": 17147.060006141663, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 545640, "time": 17148.06118607521, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 545888, "time": 17155.77884221077, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 545896, "time": 17155.80603981018, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 546008, "time": 17159.187586307526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 546016, "time": 17159.66556620598, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 546048, "time": 17160.66284275055, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 546392, "time": 17170.944318532944, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 546456, "time": 17172.86256504059, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 546512, "time": 17174.80878186226, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 546520, "time": 17174.837111711502, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 546856, "time": 17184.966571092606, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 546872, "time": 17185.455513477325, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 547040, "time": 17190.747485160828, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 547056, "time": 17191.232622861862, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 547520, "time": 17205.406779050827, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 547624, "time": 17208.317187547684, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 547881, "time": 17217.020936489105, "train_stats/mean_log_entropy": 0.08845485493013289, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2733878901439346, "train/action_min": 0.0, "train/action_std": 1.7680662705980499, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014196950470881877, "train/actor_opt_grad_steps": 33130.0, "train/actor_opt_loss": -8.13888591065489, "train/adv_mag": 1.0783170391186117, "train/adv_max": 0.30544937420361146, "train/adv_mean": 0.0032735448012810478, "train/adv_min": -1.05357264943898, "train/adv_std": 0.039796384528572926, "train/cont_avg": 0.9951364301108374, "train/cont_loss_mean": 0.015405036627172764, "train/cont_loss_std": 0.2199497535008148, "train/cont_neg_acc": 0.3715869171425627, "train/cont_neg_loss": 2.5057663321549537, "train/cont_pos_acc": 0.9998114340998269, "train/cont_pos_loss": 0.0033851807542475574, "train/cont_pred": 0.9949567852349117, "train/cont_rate": 0.9951364301108374, "train/dyn_loss_mean": 1.0000118716009732, "train/dyn_loss_std": 0.00034652378357341286, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.46027840083015376, "train/extr_critic_critic_opt_grad_steps": 33130.0, "train/extr_critic_critic_opt_loss": 10753.740612011237, "train/extr_critic_mag": 1.364569467864013, "train/extr_critic_max": 1.364569467864013, "train/extr_critic_mean": 1.2872970820647742, "train/extr_critic_min": 1.2067000995128614, "train/extr_critic_std": 0.017921764614620233, "train/extr_return_normed_mag": 1.0615590023876997, "train/extr_return_normed_max": 0.3452776370964614, "train/extr_return_normed_mean": 0.04089685983490199, "train/extr_return_normed_min": -1.0228500659829878, "train/extr_return_normed_std": 0.044482189294850004, "train/extr_return_rate": 0.9989529257924686, "train/extr_return_raw_mag": 1.5949517541331024, "train/extr_return_raw_max": 1.5949517541331024, "train/extr_return_raw_mean": 1.2905710477547105, "train/extr_return_raw_min": 0.22682405105365322, "train/extr_return_raw_std": 0.0444821894141327, "train/extr_reward_mag": 0.35305008453688597, "train/extr_reward_max": 0.35305008453688597, "train/extr_reward_mean": 0.003014599954883747, "train/extr_reward_min": 1.0570281832088978e-07, "train/extr_reward_std": 0.012221417393250932, "train/image_loss_mean": 0.0934939572009547, "train/image_loss_std": 0.10161904807161228, "train/model_loss_mean": 0.7207944249284679, "train/model_loss_std": 0.4181723051470489, "train/model_opt_grad_norm": 23.681358633370234, "train/model_opt_grad_steps": 33100.39408866995, "train/model_opt_loss": 2447.2570878954357, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3399.014778325123, "train/policy_entropy_mag": 1.3330513649973377, "train/policy_entropy_max": 1.3330513649973377, "train/policy_entropy_mean": 0.11600305040922071, "train/policy_entropy_min": 0.06468650015997769, "train/policy_entropy_std": 0.15149142457346612, "train/policy_logprob_mag": 6.5510802386429505, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11574955640608454, "train/policy_logprob_min": -6.5510802386429505, "train/policy_logprob_std": 0.6522453894168873, "train/policy_randomness_mag": 0.685052927785319, "train/policy_randomness_max": 0.685052927785319, "train/policy_randomness_mean": 0.05961377955422613, "train/policy_randomness_min": 0.03324228558193874, "train/policy_randomness_std": 0.07785119732906079, "train/post_ent_mag": 25.05061993340553, "train/post_ent_max": 25.05061993340553, "train/post_ent_mean": 24.57661802545557, "train/post_ent_min": 24.272354266913652, "train/post_ent_std": 0.15202562254050683, "train/prior_ent_mag": 27.387132146675597, "train/prior_ent_max": 27.387132146675597, "train/prior_ent_mean": 23.874492523118192, "train/prior_ent_min": 22.494018761395235, "train/prior_ent_std": 0.6997654728701549, "train/rep_loss_mean": 1.0000118716009732, "train/rep_loss_std": 0.00034652378357341286, "train/reward_avg": 0.0015376950687272337, "train/reward_loss_mean": 0.011888283691391936, "train/reward_loss_std": 0.19635942104167026, "train/reward_max_data": 0.702755543839168, "train/reward_max_pred": 0.2148685185192841, "train/reward_neg_acc": 0.999604631820923, "train/reward_neg_loss": 0.0021609306308782656, "train/reward_pos_acc": 0.17971781463850112, "train/reward_pos_loss": 4.179331139281944, "train/reward_pred": 0.0012578690095387142, "train/reward_rate": 0.00231873460591133, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.02345171570777893, "report/cont_loss_std": 0.3077567219734192, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.963101863861084, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032181397546082735, "report/cont_pred": 0.9948076605796814, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0796755701303482, "report/image_loss_std": 0.09396190941333771, "report/model_loss_mean": 0.7144228219985962, "report/model_loss_std": 0.43599653244018555, "report/post_ent_mag": 24.94629669189453, "report/post_ent_max": 24.94629669189453, "report/post_ent_mean": 24.495182037353516, "report/post_ent_min": 24.232511520385742, "report/post_ent_std": 0.1440153568983078, "report/prior_ent_mag": 26.92544174194336, "report/prior_ent_max": 26.92544174194336, "report/prior_ent_mean": 23.465038299560547, "report/prior_ent_min": 22.09930419921875, "report/prior_ent_std": 0.6816733479499817, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023651123046875, "report/reward_loss_mean": 0.01129548717290163, "report/reward_loss_std": 0.18491633236408234, "report/reward_max_data": 0.9281250238418579, "report/reward_max_pred": 0.5315622091293335, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002170129446312785, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.1169590950012207, "report/reward_pred": 0.0016518138581886888, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.029464632272720337, "eval/cont_loss_std": 0.492275208234787, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.472471237182617, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.0046565840020775795, "eval/cont_pred": 0.9975596070289612, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21716313064098358, "eval/image_loss_std": 0.16778592765331268, "eval/model_loss_mean": 0.8539135456085205, "eval/model_loss_std": 0.6545485258102417, "eval/post_ent_mag": 24.957202911376953, "eval/post_ent_max": 24.957202911376953, "eval/post_ent_mean": 24.458602905273438, "eval/post_ent_min": 24.212453842163086, "eval/post_ent_std": 0.14437861740589142, "eval/prior_ent_mag": 26.92544174194336, "eval/prior_ent_max": 26.92544174194336, "eval/prior_ent_mean": 23.412792205810547, "eval/prior_ent_min": 21.802656173706055, "eval/prior_ent_std": 0.6702317595481873, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006866455078125, "eval/reward_loss_mean": 0.0072857472114264965, "eval/reward_loss_std": 0.22162562608718872, "eval/reward_max_data": 0.703125, "eval/reward_max_pred": 0.016799449920654297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00035699023283086717, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.095404148101807, "eval/reward_pred": 0.00017750542610883713, "eval/reward_rate": 0.0009765625, "replay/size": 547377.0, "replay/inserts": 32528.0, "replay/samples": 32528.0, "replay/insert_wait_avg": 1.355001507752996e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.757472687030273e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1648008045757116e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2633128166199, "timer/env.step_count": 4066.0, "timer/env.step_total": 38.158785343170166, "timer/env.step_frac": 0.03814874029091367, "timer/env.step_avg": 0.00938484637067638, "timer/env.step_min": 0.00768589973449707, "timer/env.step_max": 0.03491497039794922, "timer/replay._sample_count": 32528.0, "timer/replay._sample_total": 16.660969018936157, "timer/replay._sample_frac": 0.016656583127117694, "timer/replay._sample_avg": 0.0005122039172078258, "timer/replay._sample_min": 0.00040984153747558594, "timer/replay._sample_max": 0.02582859992980957, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4624.0, "timer/agent.policy_total": 48.24910020828247, "timer/agent.policy_frac": 0.048236398946212344, "timer/agent.policy_avg": 0.010434493989680466, "timer/agent.policy_min": 0.00855255126953125, "timer/agent.policy_max": 0.1367015838623047, "timer/dataset_train_count": 2033.0, "timer/dataset_train_total": 0.21136021614074707, "timer/dataset_train_frac": 0.000211304576937429, "timer/dataset_train_avg": 0.00010396469067424843, "timer/dataset_train_min": 9.250640869140625e-05, "timer/dataset_train_max": 0.0004801750183105469, "timer/agent.train_count": 2033.0, "timer/agent.train_total": 902.6774306297302, "timer/agent.train_frac": 0.9024398066624081, "timer/agent.train_avg": 0.4440125089177227, "timer/agent.train_min": 0.43426012992858887, "timer/agent.train_max": 0.7479164600372314, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4805893898010254, "timer/agent.report_frac": 0.00048046287776739915, "timer/agent.report_avg": 0.2402946949005127, "timer/agent.report_min": 0.23341727256774902, "timer/agent.report_max": 0.24717211723327637, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010251998901367188, "timer/dataset_eval_frac": 1.0249300129281764e-07, "timer/dataset_eval_avg": 0.00010251998901367188, "timer/dataset_eval_min": 0.00010251998901367188, "timer/dataset_eval_max": 0.00010251998901367188, "fps": 32.51887102356093}
{"step": 547888, "time": 17217.03752040863, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 547936, "time": 17218.892608880997, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 547992, "time": 17220.378877401352, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 548152, "time": 17225.21027779579, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 548288, "time": 17229.62374663353, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 548328, "time": 17230.613204479218, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 548360, "time": 17231.585728406906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548384, "time": 17232.545812368393, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 548680, "time": 17241.28235769272, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 548760, "time": 17243.715723991394, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 548832, "time": 17246.108751296997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 548944, "time": 17249.95268201828, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 548944, "time": 17249.95783495903, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 549016, "time": 17251.91364622116, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 549408, "time": 17264.100875377655, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 549440, "time": 17265.07406425476, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 549568, "time": 17268.953147172928, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 549744, "time": 17274.281108379364, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 17284.556959867477, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 550056, "time": 17285.180412769318, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 550056, "time": 17285.205100774765, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 550056, "time": 17285.634182691574, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 550056, "time": 17285.659134864807, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 550056, "time": 17285.92267179489, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 550056, "time": 17286.239567279816, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 550056, "time": 17286.630796670914, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 550264, "time": 17292.89988565445, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 550328, "time": 17294.829415798187, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 550336, "time": 17295.294827222824, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 550384, "time": 17296.760519742966, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 550600, "time": 17303.067292928696, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 550792, "time": 17310.330411434174, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 550816, "time": 17311.272208213806, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 551144, "time": 17321.06903386116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551328, "time": 17326.86487340927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 551488, "time": 17331.703667879105, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 551568, "time": 17334.143993377686, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 551968, "time": 17346.307541370392, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 552112, "time": 17350.657730817795, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 552208, "time": 17353.53733897209, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 552312, "time": 17356.498872041702, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 552360, "time": 17357.957203626633, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 552360, "time": 17357.963277816772, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 552640, "time": 17366.679224014282, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 552640, "time": 17366.685530662537, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 552928, "time": 17375.391633749008, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 553128, "time": 17381.335486888885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553296, "time": 17386.67886209488, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 553600, "time": 17395.844235897064, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 553696, "time": 17398.719587802887, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 553696, "time": 17398.724713087082, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 553816, "time": 17402.12020921707, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 553880, "time": 17404.0712621212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 553920, "time": 17405.50846719742, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 554000, "time": 17407.99551510811, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 554136, "time": 17411.889431476593, "episode/length": 221.0, "episode/score": 0.30937498807907104, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.0}
{"step": 554336, "time": 17418.159346818924, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 554440, "time": 17421.085108041763, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 554520, "time": 17423.524770736694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 554696, "time": 17428.84557914734, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 554760, "time": 17430.783791542053, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 554832, "time": 17433.190580129623, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 554896, "time": 17435.128581285477, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 555120, "time": 17441.98837327957, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 555424, "time": 17451.1737408638, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 555544, "time": 17454.58453297615, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 555568, "time": 17455.528640031815, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 556008, "time": 17468.66689968109, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556064, "time": 17470.57594227791, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 556192, "time": 17474.471709012985, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556224, "time": 17475.439057588577, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 556584, "time": 17486.099378585815, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 556832, "time": 17493.80824446678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 556888, "time": 17495.28275990486, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 556920, "time": 17496.342774629593, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 557000, "time": 17498.759689331055, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 557072, "time": 17501.635068178177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 557080, "time": 17501.660898208618, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 557080, "time": 17501.665694713593, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 557320, "time": 17508.900228977203, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 557416, "time": 17511.8084127903, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 557432, "time": 17512.291743516922, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 557704, "time": 17520.48969888687, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 558072, "time": 17531.73599076271, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 558536, "time": 17545.730890274048, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 558880, "time": 17556.462017297745, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 559152, "time": 17564.66096639633, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 559232, "time": 17567.058104515076, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 559312, "time": 17569.489231586456, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559384, "time": 17571.43231868744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559392, "time": 17571.90347146988, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559552, "time": 17576.742484807968, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 559728, "time": 17582.063066482544, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559744, "time": 17582.55432486534, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 559840, "time": 17585.46987247467, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 559984, "time": 17589.88637280464, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 17592.145002365112, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 560040, "time": 17592.4148478508, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 560040, "time": 17592.71651482582, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 560040, "time": 17592.800639867783, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 560040, "time": 17593.06814455986, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 560040, "time": 17593.130208730698, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 560040, "time": 17593.40016746521, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 560040, "time": 17593.484983444214, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 560128, "time": 17596.372774124146, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 560384, "time": 17604.091296195984, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 560464, "time": 17606.527968883514, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 560552, "time": 17608.964983940125, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 560616, "time": 17610.902542352676, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 560744, "time": 17614.7468585968, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 560824, "time": 17617.27516222, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 560944, "time": 17621.124999284744, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 561248, "time": 17630.31127858162, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 561328, "time": 17632.71841621399, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 561576, "time": 17639.993651390076, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 561640, "time": 17641.931402921677, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 561696, "time": 17643.82923054695, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 561728, "time": 17644.822381973267, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 561832, "time": 17647.846951961517, "episode/length": 16.0, "episode/score": 0.949999988079071, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 562160, "time": 17657.95600104332, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 562296, "time": 17661.864402770996, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562616, "time": 17671.511682987213, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 562672, "time": 17673.43071269989, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 562776, "time": 17676.42475247383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562872, "time": 17679.336099863052, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 562928, "time": 17681.247610569, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 562960, "time": 17682.21099257469, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 563344, "time": 17693.81254863739, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 563456, "time": 17697.1728951931, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 563464, "time": 17697.199261426926, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 563760, "time": 17706.425721168518, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 563888, "time": 17710.318711042404, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 563936, "time": 17711.77945303917, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 564064, "time": 17715.66846871376, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 564472, "time": 17727.741636753082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 564472, "time": 17727.747690200806, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 564720, "time": 17735.43560242653, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 564776, "time": 17736.994986772537, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 564848, "time": 17739.38742518425, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 565200, "time": 17750.050872564316, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 565384, "time": 17755.886438846588, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 565496, "time": 17759.2794175148, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 565656, "time": 17764.10087800026, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566248, "time": 17782.04379105568, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 566264, "time": 17782.532581806183, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 566376, "time": 17785.92730975151, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566536, "time": 17790.751935720444, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 566784, "time": 17798.618021965027, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566784, "time": 17798.625219106674, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 566976, "time": 17804.459679841995, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 567336, "time": 17815.174240112305, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 567512, "time": 17820.52876019478, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 567560, "time": 17821.97988677025, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 567600, "time": 17823.410231113434, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 567648, "time": 17824.89501452446, "episode/length": 5.0, "episode/score": 0.984375, "episode/reward_rate": 0.16666666666666666, "episode/intrinsic_return": 0.0}
{"step": 567704, "time": 17826.44663977623, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 568232, "time": 17842.444988965988, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 568280, "time": 17843.912471294403, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 568344, "time": 17845.851388692856, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 568416, "time": 17848.234364032745, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 568560, "time": 17852.573535203934, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 568784, "time": 17859.39544224739, "episode/length": 249.0, "episode/score": 0.22187499701976776, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.0}
{"step": 569040, "time": 17867.10229754448, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 569200, "time": 17871.94398355484, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 569288, "time": 17874.398068904877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569456, "time": 17879.688579320908, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 569576, "time": 17883.08998441696, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 569648, "time": 17885.48627948761, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 569720, "time": 17887.526007652283, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 569920, "time": 17893.77511548996, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 569960, "time": 17894.756222248077, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 17897.796447753906, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 570024, "time": 17898.424399614334, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 570024, "time": 17898.940715789795, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 570024, "time": 17899.09793162346, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 570024, "time": 17899.221029758453, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 570024, "time": 17899.322744846344, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 570024, "time": 17899.559008598328, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 570024, "time": 17899.879197835922, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 570192, "time": 17905.183773756027, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 570416, "time": 17911.93730354309, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 570448, "time": 17912.899154663086, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 570576, "time": 17916.895552635193, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 570592, "time": 17917.39230823517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 570896, "time": 17926.586636781693, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 571288, "time": 17938.187823057175, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 571592, "time": 17947.42716884613, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 571848, "time": 17955.15311074257, "episode/length": 235.0, "episode/score": 0.265625, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.0}
{"step": 571888, "time": 17956.589067220688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 571912, "time": 17957.094990968704, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 572216, "time": 17966.25742650032, "episode/length": 220.0, "episode/score": 0.3125, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0}
{"step": 572432, "time": 17972.99217748642, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 572904, "time": 17987.137911081314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 572912, "time": 17987.624381303787, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 573056, "time": 17991.96119594574, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 573056, "time": 17991.96919965744, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 573072, "time": 17992.47600889206, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 573208, "time": 17996.354719877243, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 573312, "time": 17999.735647678375, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 573440, "time": 18003.766852378845, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 573680, "time": 18011.4791431427, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 573944, "time": 18019.26489663124, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 574192, "time": 18026.96310019493, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 574440, "time": 18034.21548485756, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 574704, "time": 18042.488065242767, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 574856, "time": 18046.860564231873, "episode/length": 224.0, "episode/score": 0.30000001192092896, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.0}
{"step": 575064, "time": 18053.1454102993, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 575232, "time": 18058.409667491913, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 575328, "time": 18061.302931547165, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 575424, "time": 18064.190732479095, "episode/length": 247.0, "episode/score": 0.22812500596046448, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0}
{"step": 575520, "time": 18067.189858436584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575624, "time": 18070.104115962982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 575856, "time": 18077.330797195435, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 575888, "time": 18078.300495624542, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 576000, "time": 18081.687633275986, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 576016, "time": 18082.180248260498, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 576160, "time": 18086.532808303833, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 576272, "time": 18089.91620349884, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 576464, "time": 18095.68359375, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 576504, "time": 18096.738883256912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 576512, "time": 18097.204738140106, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 576952, "time": 18110.24291086197, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 577176, "time": 18116.998261213303, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 577376, "time": 18123.24994969368, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 577392, "time": 18123.760041475296, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 577912, "time": 18139.30222940445, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 578000, "time": 18142.18046426773, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 578056, "time": 18143.668088436127, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 578304, "time": 18151.352039813995, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 578312, "time": 18151.379727125168, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578368, "time": 18153.291091918945, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 578384, "time": 18153.773448228836, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 578496, "time": 18157.231431245804, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 578584, "time": 18159.67354774475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578816, "time": 18166.93252325058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578824, "time": 18166.96001291275, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 578848, "time": 18167.94365978241, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 579144, "time": 18176.62020468712, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 579160, "time": 18177.123212575912, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 579464, "time": 18186.35003876686, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 579688, "time": 18193.10790371895, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 579720, "time": 18194.083999872208, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 579824, "time": 18197.441183805466, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 579880, "time": 18198.92177605629, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 18203.236441612244, "eval_episode/length": 23.0, "eval_episode/score": 0.9281250238418579, "eval_episode/reward_rate": 0.041666666666666664}
{"step": 580008, "time": 18203.61058807373, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 580008, "time": 18203.768702745438, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 580008, "time": 18203.998486995697, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 580008, "time": 18204.113403081894, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 580008, "time": 18204.88177895546, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 580008, "time": 18205.40799999237, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 580008, "time": 18206.369363069534, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 580312, "time": 18215.528138399124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 580328, "time": 18216.09778237343, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 580329, "time": 18217.1004986763, "train_stats/mean_log_entropy": 0.0913592976190754, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2463715651939653, "train/action_min": 0.0, "train/action_std": 1.7447640167668534, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.016660077816214907, "train/actor_opt_grad_steps": 35160.0, "train/actor_opt_loss": -10.318393802866707, "train/adv_mag": 1.1162188103046324, "train/adv_max": 0.29702900900629353, "train/adv_mean": 0.0029189427311703095, "train/adv_min": -1.085060940293843, "train/adv_std": 0.039296330466609575, "train/cont_avg": 0.9949872998768473, "train/cont_loss_mean": 0.01668500006766623, "train/cont_loss_std": 0.23045502521391278, "train/cont_neg_acc": 0.3311526665253005, "train/cont_neg_loss": 2.6560572459284453, "train/cont_pos_acc": 0.9998646249324817, "train/cont_pos_loss": 0.0033855617337107766, "train/cont_pred": 0.9950969633210469, "train/cont_rate": 0.9949872998768473, "train/dyn_loss_mean": 1.0000203231285358, "train/dyn_loss_std": 0.00038076717557908573, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.25165285974777685, "train/extr_critic_critic_opt_grad_steps": 35160.0, "train/extr_critic_critic_opt_loss": 13194.003988031096, "train/extr_critic_mag": 1.481068837818841, "train/extr_critic_max": 1.481068837818841, "train/extr_critic_mean": 1.389632337786294, "train/extr_critic_min": 1.2904947731882481, "train/extr_critic_std": 0.02026533635030386, "train/extr_return_normed_mag": 1.1041764960500406, "train/extr_return_normed_max": 0.33834158082313726, "train/extr_return_normed_mean": 0.044240968402823794, "train/extr_return_normed_min": -1.0544925534666465, "train/extr_return_normed_std": 0.04501655011488299, "train/extr_return_rate": 0.999303780459418, "train/extr_return_raw_mag": 1.686651890501013, "train/extr_return_raw_max": 1.686651890501013, "train/extr_return_raw_mean": 1.392551346952692, "train/extr_return_raw_min": 0.29381775621122913, "train/extr_return_raw_std": 0.045016550041478254, "train/extr_reward_mag": 0.33955147231153665, "train/extr_reward_max": 0.33955147231153665, "train/extr_reward_mean": 0.0027309704739416907, "train/extr_reward_min": 1.1392414863473677e-07, "train/extr_reward_std": 0.01187630301442346, "train/image_loss_mean": 0.09094733735684103, "train/image_loss_std": 0.10101829193936193, "train/model_loss_mean": 0.7201830248527339, "train/model_loss_std": 0.4309635326780122, "train/model_opt_grad_norm": 22.614195889440076, "train/model_opt_grad_steps": 35128.901477832515, "train/model_opt_loss": 2173.633103544489, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3017.2413793103447, "train/policy_entropy_mag": 1.3341200328225573, "train/policy_entropy_max": 1.3341200328225573, "train/policy_entropy_mean": 0.11864927910231604, "train/policy_entropy_min": 0.06468649938922798, "train/policy_entropy_std": 0.15528973452563355, "train/policy_logprob_mag": 6.551080250387709, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.1188907367842538, "train/policy_logprob_min": -6.551080250387709, "train/policy_logprob_std": 0.656281068407256, "train/policy_randomness_mag": 0.6856021155864734, "train/policy_randomness_max": 0.6856021155864734, "train/policy_randomness_mean": 0.06097367172831385, "train/policy_randomness_min": 0.03324228545348045, "train/policy_randomness_std": 0.07980314231124418, "train/post_ent_mag": 24.54347773021078, "train/post_ent_max": 24.54347773021078, "train/post_ent_mean": 24.09694632168474, "train/post_ent_min": 23.802658616615634, "train/post_ent_std": 0.14597843734208, "train/prior_ent_mag": 26.050348826817103, "train/prior_ent_max": 26.050348826817103, "train/prior_ent_mean": 23.351358300946615, "train/prior_ent_min": 22.09665166920629, "train/prior_ent_std": 0.5710655503672332, "train/rep_loss_mean": 1.0000203231285358, "train/rep_loss_std": 0.00038076717557908573, "train/reward_avg": 0.0016203631275319701, "train/reward_loss_mean": 0.012538471879676131, "train/reward_loss_std": 0.2011624614965042, "train/reward_max_data": 0.7075584991812118, "train/reward_max_pred": 0.21656693672311716, "train/reward_neg_acc": 0.999604490296594, "train/reward_neg_loss": 0.0022263583182953665, "train/reward_pos_acc": 0.16957672129547785, "train/reward_pos_loss": 4.151773419329729, "train/reward_pred": 0.0013145413284139534, "train/reward_rate": 0.0024822967980295567, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.034430064260959625, "report/cont_loss_std": 0.3971419632434845, "report/cont_neg_acc": 0.30000001192092896, "report/cont_neg_loss": 3.286191940307617, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00236141006462276, "report/cont_pred": 0.994774341583252, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09180750697851181, "report/image_loss_std": 0.10375282168388367, "report/model_loss_mean": 0.7476171255111694, "report/model_loss_std": 0.6641422510147095, "report/post_ent_mag": 24.719402313232422, "report/post_ent_max": 24.719402313232422, "report/post_ent_mean": 24.238887786865234, "report/post_ent_min": 23.925182342529297, "report/post_ent_std": 0.15507932007312775, "report/prior_ent_mag": 26.182647705078125, "report/prior_ent_max": 26.182647705078125, "report/prior_ent_mean": 23.660234451293945, "report/prior_ent_min": 22.376392364501953, "report/prior_ent_std": 0.6055750250816345, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003414916805922985, "report/reward_loss_mean": 0.021379543468356133, "report/reward_loss_std": 0.3068561553955078, "report/reward_max_data": 0.824999988079071, "report/reward_max_pred": 0.5763258934020996, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0015029230853542686, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 4.072235107421875, "report/reward_pred": 0.0013629957102239132, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.04128079116344452, "eval/cont_loss_std": 0.6228371858596802, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.912616729736328, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00265794456936419, "eval/cont_pred": 0.9973821043968201, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2107025682926178, "eval/image_loss_std": 0.16748669743537903, "eval/model_loss_mean": 0.8649187684059143, "eval/model_loss_std": 0.753676176071167, "eval/post_ent_mag": 24.694507598876953, "eval/post_ent_max": 24.694507598876953, "eval/post_ent_mean": 24.21554183959961, "eval/post_ent_min": 23.910137176513672, "eval/post_ent_std": 0.15953120589256287, "eval/prior_ent_mag": 26.182647705078125, "eval/prior_ent_max": 26.182647705078125, "eval/prior_ent_mean": 23.578792572021484, "eval/prior_ent_min": 22.513626098632812, "eval/prior_ent_std": 0.5982181429862976, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0009429932106286287, "eval/reward_loss_mean": 0.012935435399413109, "eval/reward_loss_std": 0.2668021321296692, "eval/reward_max_data": 0.8031250238418579, "eval/reward_max_pred": 0.07485747337341309, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013429486425593495, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.9366960525512695, "eval/reward_pred": 0.0006951228715479374, "eval/reward_rate": 0.001953125, "replay/size": 579825.0, "replay/inserts": 32448.0, "replay/samples": 32448.0, "replay/insert_wait_avg": 1.3556676738596056e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.687397374674179e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4680.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1335071335490952e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0648372173309, "timer/env.step_count": 4056.0, "timer/env.step_total": 38.11236381530762, "timer/env.step_frac": 0.03810989287590076, "timer/env.step_avg": 0.009396539402196159, "timer/env.step_min": 0.007652997970581055, "timer/env.step_max": 0.03610515594482422, "timer/replay._sample_count": 32448.0, "timer/replay._sample_total": 16.590333700180054, "timer/replay._sample_frac": 0.01658925809884734, "timer/replay._sample_avg": 0.0005112898699513083, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.02839803695678711, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4641.0, "timer/agent.policy_total": 48.42805314064026, "timer/agent.policy_frac": 0.04842491340400565, "timer/agent.policy_avg": 0.01043483153213537, "timer/agent.policy_min": 0.008527994155883789, "timer/agent.policy_max": 0.08681821823120117, "timer/dataset_train_count": 2028.0, "timer/dataset_train_total": 0.2106935977935791, "timer/dataset_train_frac": 0.00021067993789265869, "timer/dataset_train_avg": 0.00010389230660432895, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0004930496215820312, "timer/agent.train_count": 2028.0, "timer/agent.train_total": 901.4643430709839, "timer/agent.train_frac": 0.9014058984208446, "timer/agent.train_avg": 0.44450904490679677, "timer/agent.train_min": 0.43247032165527344, "timer/agent.train_max": 1.9016599655151367, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789724349975586, "timer/agent.report_frac": 0.0004789413817710999, "timer/agent.report_avg": 0.2394862174987793, "timer/agent.report_min": 0.23349905014038086, "timer/agent.report_max": 0.24547338485717773, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194601830867744e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 32.445310297712716}
{"step": 580512, "time": 18222.606897830963, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 580688, "time": 18227.935571670532, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 580800, "time": 18231.322974443436, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 580896, "time": 18234.211985588074, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581392, "time": 18249.304903507233, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 581440, "time": 18250.759220600128, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 581736, "time": 18259.97959280014, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 581776, "time": 18261.412150859833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 581944, "time": 18266.29160451889, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 582032, "time": 18269.19539284706, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582136, "time": 18272.12140893936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582192, "time": 18274.04663515091, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582480, "time": 18282.777420282364, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 582624, "time": 18287.217019081116, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 582728, "time": 18290.183406829834, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 583000, "time": 18298.435489177704, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 583056, "time": 18300.33606028557, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 583088, "time": 18301.305550575256, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 583184, "time": 18304.21283841133, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 583448, "time": 18312.063621520996, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 583552, "time": 18315.43635249138, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 583592, "time": 18316.42940068245, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 583616, "time": 18317.375903129578, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 583904, "time": 18326.076666355133, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 584000, "time": 18328.997067689896, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 584256, "time": 18336.804302453995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584320, "time": 18338.76509666443, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 584344, "time": 18339.27548980713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 584376, "time": 18340.23824262619, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 584440, "time": 18342.190694332123, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 584680, "time": 18349.446629285812, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 584712, "time": 18350.4138610363, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 584888, "time": 18355.715488433838, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 585024, "time": 18360.046769857407, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 585040, "time": 18360.53348135948, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 585448, "time": 18372.70725297928, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 585480, "time": 18373.675256729126, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 585576, "time": 18376.578450918198, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 585848, "time": 18384.78511095047, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 585888, "time": 18386.225506544113, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 586192, "time": 18395.390276670456, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 586272, "time": 18397.89390039444, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 586312, "time": 18398.89200949669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586440, "time": 18402.763058662415, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 586632, "time": 18408.540803670883, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 586688, "time": 18410.469682216644, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 586752, "time": 18412.388119220734, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 586848, "time": 18415.292575120926, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 586872, "time": 18415.801300764084, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 586968, "time": 18418.684428930283, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 587200, "time": 18425.932344675064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587336, "time": 18429.84348320961, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 587488, "time": 18434.677161216736, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 587688, "time": 18440.531371593475, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 587776, "time": 18443.403497457504, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 587792, "time": 18443.911256313324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 587984, "time": 18449.693372249603, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 588056, "time": 18451.648862600327, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 588072, "time": 18452.135200977325, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 588136, "time": 18454.08088183403, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 588400, "time": 18462.35663485527, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 588464, "time": 18464.31580209732, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 588504, "time": 18465.302488803864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 588848, "time": 18475.91136407852, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 588976, "time": 18479.78472518921, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 589000, "time": 18480.293573379517, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 589480, "time": 18494.895178556442, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 589520, "time": 18496.318355083466, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 589544, "time": 18496.827081680298, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 589624, "time": 18499.264500379562, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 589648, "time": 18500.209278821945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 589904, "time": 18508.456147670746, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 590088, "time": 18513.79611492157, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 18515.131152153015, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 590096, "time": 18515.56728553772, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 590096, "time": 18515.591775417328, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 590096, "time": 18516.289293050766, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 590096, "time": 18517.081337928772, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 590096, "time": 18517.1989569664, "eval_episode/length": 144.0, "eval_episode/score": 0.550000011920929, "eval_episode/reward_rate": 0.006896551724137931}
{"step": 590096, "time": 18517.307453155518, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 590096, "time": 18517.536356449127, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 590208, "time": 18520.92743587494, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 590304, "time": 18523.81831932068, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 590480, "time": 18529.13517832756, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 590488, "time": 18529.161685228348, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 590768, "time": 18537.82241153717, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 590904, "time": 18541.698482751846, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 591000, "time": 18544.6061501503, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 591040, "time": 18546.143049240112, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 591160, "time": 18549.538628578186, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591240, "time": 18551.93876671791, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 591320, "time": 18554.366719722748, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 591328, "time": 18554.82966518402, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 591368, "time": 18555.818288326263, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 591832, "time": 18569.8076980114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 591832, "time": 18569.812776327133, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 591888, "time": 18571.724367380142, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 591904, "time": 18572.207775354385, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 591936, "time": 18573.172422409058, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 592136, "time": 18579.11639547348, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 592248, "time": 18582.500614643097, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 592336, "time": 18585.389681577682, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 592512, "time": 18590.7210187912, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 592728, "time": 18597.037104845047, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 592888, "time": 18601.871726989746, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 592976, "time": 18604.76155114174, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 592992, "time": 18605.249449968338, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 593208, "time": 18611.6190867424, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 593352, "time": 18615.98425388336, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 593680, "time": 18626.117597818375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594008, "time": 18635.88866686821, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 594112, "time": 18639.30530023575, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 594216, "time": 18642.230450868607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594248, "time": 18643.19815325737, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 594312, "time": 18645.131538391113, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 594688, "time": 18656.728080511093, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 595040, "time": 18667.422070980072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595096, "time": 18668.88955974579, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 595160, "time": 18670.842333078384, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 595208, "time": 18672.281405687332, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 595384, "time": 18677.568787813187, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 595520, "time": 18681.886071443558, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 595696, "time": 18687.188715696335, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 595712, "time": 18687.67849802971, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 595992, "time": 18695.93230819702, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596120, "time": 18699.824865102768, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 596240, "time": 18703.661094903946, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 596360, "time": 18707.072073221207, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 596384, "time": 18708.015602588654, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 596624, "time": 18715.262625932693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 596752, "time": 18719.127591848373, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 596760, "time": 18719.153395175934, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 597408, "time": 18738.988458395004, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597440, "time": 18739.951278209686, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 597568, "time": 18743.807971954346, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 597688, "time": 18747.190089464188, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 597696, "time": 18747.66202521324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 597960, "time": 18755.406521320343, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 598024, "time": 18757.634454011917, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598304, "time": 18766.565776348114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 598328, "time": 18767.07575750351, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 598624, "time": 18776.229518651962, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 598656, "time": 18777.192800998688, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 598672, "time": 18777.696861982346, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 598776, "time": 18780.61534190178, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 598936, "time": 18785.448900938034, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 599144, "time": 18791.78448009491, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 599280, "time": 18796.13069295883, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 599720, "time": 18809.22319507599, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600032, "time": 18818.91655397415, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 18822.08626627922, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 600080, "time": 18822.273817539215, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 600080, "time": 18822.334932088852, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 600080, "time": 18823.154218912125, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 600080, "time": 18824.20867371559, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 600080, "time": 18824.304906845093, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 600080, "time": 18825.67981505394, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 18825.68549346924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 18825.691462516785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 18825.69645833969, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600080, "time": 18825.70176100731, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 600336, "time": 18833.432592868805, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 600392, "time": 18834.8930850029, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 600480, "time": 18837.779754161835, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 600624, "time": 18842.135001420975, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 600768, "time": 18846.56309580803, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 600816, "time": 18848.009741783142, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 600848, "time": 18848.982793331146, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 600952, "time": 18851.92497777939, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 600968, "time": 18852.414869070053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601064, "time": 18855.31161260605, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 601536, "time": 18869.76720547676, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 601592, "time": 18871.253651857376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 601640, "time": 18872.69224333763, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 601776, "time": 18877.139976263046, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 602056, "time": 18885.385390281677, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 602272, "time": 18892.130787611008, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 602488, "time": 18898.43730521202, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 602792, "time": 18907.683526039124, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 602800, "time": 18908.149769067764, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 602984, "time": 18913.48432803154, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 603160, "time": 18918.83855676651, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603264, "time": 18922.194359779358, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603520, "time": 18929.93761086464, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 603600, "time": 18932.3474714756, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 603656, "time": 18933.852525234222, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 603848, "time": 18939.830088377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 603984, "time": 18944.161803007126, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 604008, "time": 18944.66598057747, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 604032, "time": 18945.609263420105, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 604160, "time": 18949.483151435852, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 604200, "time": 18950.464022636414, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 604584, "time": 18962.038662433624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 604648, "time": 18963.98780965805, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 604760, "time": 18967.442972183228, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 604800, "time": 18968.865419626236, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 604928, "time": 18972.73562312126, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 605368, "time": 18985.771644592285, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 605608, "time": 18993.01398205757, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 605728, "time": 18996.957010030746, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 605832, "time": 18999.885266542435, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606024, "time": 19005.680752038956, "episode/length": 251.0, "episode/score": 0.21562500298023224, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0}
{"step": 606240, "time": 19012.918841362, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 606344, "time": 19015.832147598267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606608, "time": 19024.021010875702, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 606776, "time": 19028.925078868866, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 606800, "time": 19029.873504638672, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 606896, "time": 19032.77657532692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 606920, "time": 19033.288291215897, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 606928, "time": 19033.754370689392, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 607112, "time": 19039.09762072563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607600, "time": 19054.035432338715, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 607680, "time": 19056.553555965424, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 607888, "time": 19062.818246364594, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 608416, "time": 19078.806121110916, "episode/length": 225.0, "episode/score": 0.296875, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.0}
{"step": 608816, "time": 19091.040440797806, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 608848, "time": 19092.00350165367, "episode/length": 240.0, "episode/score": 0.25, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.0}
{"step": 609104, "time": 19099.763336658478, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 609112, "time": 19099.792825460434, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609208, "time": 19102.6934094429, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609424, "time": 19109.46223974228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 609704, "time": 19117.819561481476, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 609768, "time": 19119.765780448914, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 609872, "time": 19123.12246274948, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 609912, "time": 19124.105504989624, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 19129.842294454575, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 610064, "time": 19131.62246823311, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 610064, "time": 19131.627740859985, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 610064, "time": 19131.854100227356, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 610064, "time": 19131.93474316597, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 610064, "time": 19132.373990297318, "eval_episode/length": 185.0, "eval_episode/score": 0.421875, "eval_episode/reward_rate": 0.005376344086021506}
{"step": 610064, "time": 19133.290273666382, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 610064, "time": 19133.407338380814, "eval_episode/length": 240.0, "eval_episode/score": 0.25, "eval_episode/reward_rate": 0.004149377593360996}
{"step": 610160, "time": 19136.305356025696, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 610272, "time": 19139.697688102722, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 610352, "time": 19142.12502670288, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 610432, "time": 19144.531868696213, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 610992, "time": 19161.463876008987, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 611048, "time": 19162.940175533295, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 611128, "time": 19165.35356736183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611416, "time": 19174.073702812195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611472, "time": 19176.08827805519, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 611736, "time": 19183.81263613701, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 611976, "time": 19191.124876976013, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 612080, "time": 19194.46361899376, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612224, "time": 19198.82351756096, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 612384, "time": 19203.666624069214, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 612472, "time": 19206.236728668213, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 612648, "time": 19211.563154459, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 612809, "time": 19217.416370391846, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2673631489570507, "train/action_min": 0.0, "train/action_std": 1.7225018123100544, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01548456848860521, "train/actor_opt_grad_steps": 37190.0, "train/actor_opt_loss": -12.382741826655241, "train/adv_mag": 1.0654677833829607, "train/adv_max": 0.2552965057307276, "train/adv_mean": 0.00191648315587838, "train/adv_min": -1.032184996041171, "train/adv_std": 0.036378674337576175, "train/cont_avg": 0.9949247613916257, "train/cont_loss_mean": 0.016738841279749322, "train/cont_loss_std": 0.22655518173143782, "train/cont_neg_acc": 0.3252706577258157, "train/cont_neg_loss": 2.60665757171586, "train/cont_pos_acc": 0.9998501597954135, "train/cont_pos_loss": 0.00350438758244582, "train/cont_pred": 0.9949395906161792, "train/cont_rate": 0.9949247613916257, "train/dyn_loss_mean": 1.0000010640750379, "train/dyn_loss_std": 3.4028776058826245e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20302604109489272, "train/extr_critic_critic_opt_grad_steps": 37190.0, "train/extr_critic_critic_opt_loss": 12588.733157904864, "train/extr_critic_mag": 1.524896863646108, "train/extr_critic_max": 1.524896863646108, "train/extr_critic_mean": 1.4307799327549675, "train/extr_critic_min": 1.348882911240526, "train/extr_critic_std": 0.021112501859811728, "train/extr_return_normed_mag": 1.0657192515622218, "train/extr_return_normed_max": 0.314567662224981, "train/extr_return_normed_mean": 0.04412864546837478, "train/extr_return_normed_min": -1.0032668841883468, "train/extr_return_normed_std": 0.04338454312915579, "train/extr_return_rate": 0.9994076866234465, "train/extr_return_raw_mag": 1.7031352696160378, "train/extr_return_raw_max": 1.7031352696160378, "train/extr_return_raw_mean": 1.4326963377703588, "train/extr_return_raw_min": 0.3853007232027101, "train/extr_return_raw_std": 0.043384543110804606, "train/extr_reward_mag": 0.2973170116029937, "train/extr_reward_max": 0.2973170116029937, "train/extr_reward_mean": 0.0025756894582148475, "train/extr_reward_min": 1.5561803808353218e-07, "train/extr_reward_std": 0.011167597906489678, "train/image_loss_mean": 0.09265677961222644, "train/image_loss_std": 0.10277324023064721, "train/model_loss_mean": 0.7229865630859225, "train/model_loss_std": 0.4443734401625953, "train/model_opt_grad_norm": 22.724541650029828, "train/model_opt_grad_steps": 37157.684729064036, "train/model_opt_loss": 3268.9776376808804, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4519.704433497537, "train/policy_entropy_mag": 1.3338634492141273, "train/policy_entropy_max": 1.3338634492141273, "train/policy_entropy_mean": 0.12014390227242644, "train/policy_entropy_min": 0.06468649465462258, "train/policy_entropy_std": 0.1573523201525505, "train/policy_logprob_mag": 6.551080243340854, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11956718417224038, "train/policy_logprob_min": -6.551080243340854, "train/policy_logprob_std": 0.6533735294647405, "train/policy_randomness_mag": 0.685470256899378, "train/policy_randomness_max": 0.685470256899378, "train/policy_randomness_mean": 0.06174175591744813, "train/policy_randomness_min": 0.03324228282926118, "train/policy_randomness_std": 0.08086310132530522, "train/post_ent_mag": 24.279161011644184, "train/post_ent_max": 24.279161011644184, "train/post_ent_mean": 23.81930841718401, "train/post_ent_min": 23.507266960707792, "train/post_ent_std": 0.1520944366901379, "train/prior_ent_mag": 25.295303532642684, "train/prior_ent_max": 25.295303532642684, "train/prior_ent_mean": 23.01085825389242, "train/prior_ent_min": 21.726437639133096, "train/prior_ent_std": 0.551501428846068, "train/rep_loss_mean": 1.0000010640750379, "train/rep_loss_std": 3.4028776058826245e-05, "train/reward_avg": 0.0016877273051899724, "train/reward_loss_mean": 0.013590278703801958, "train/reward_loss_std": 0.21566932990211132, "train/reward_max_data": 0.7078355913385382, "train/reward_max_pred": 0.2090265885949722, "train/reward_neg_acc": 0.999681737622604, "train/reward_neg_loss": 0.0023752974507999904, "train/reward_pos_acc": 0.1520848769134808, "train/reward_pos_loss": 4.301302689962436, "train/reward_pred": 0.0013740973431259173, "train/reward_rate": 0.0026169950738916255, "train_stats/mean_log_entropy": 0.09373914282601159, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.003767783986404538, "report/cont_loss_std": 0.013321777805685997, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.3164268732070923, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034621539525687695, "report/cont_pred": 0.9958758354187012, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09753972291946411, "report/image_loss_std": 0.09684166312217712, "report/model_loss_mean": 0.7070516347885132, "report/model_loss_std": 0.1442546248435974, "report/post_ent_mag": 23.842836380004883, "report/post_ent_max": 23.842836380004883, "report/post_ent_mean": 23.397626876831055, "report/post_ent_min": 23.09433364868164, "report/post_ent_std": 0.1432417780160904, "report/prior_ent_mag": 24.940723419189453, "report/prior_ent_max": 24.940723419189453, "report/prior_ent_mean": 23.089447021484375, "report/prior_ent_min": 21.564311981201172, "report/prior_ent_std": 0.6032505631446838, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021667480177711695, "report/reward_loss_mean": 0.005744078196585178, "report/reward_loss_std": 0.09403814375400543, "report/reward_max_data": 0.22187499701976776, "report/reward_max_pred": 0.4683558940887451, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002820434048771858, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 2.9966323375701904, "report/reward_pred": 0.0018692585872486234, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00855307187885046, "eval/cont_loss_std": 0.1960986852645874, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.267523765563965, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002434820169582963, "eval/cont_pred": 0.9976446628570557, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16718383133411407, "eval/image_loss_std": 0.15796619653701782, "eval/model_loss_mean": 0.7771478891372681, "eval/model_loss_std": 0.24794456362724304, "eval/post_ent_mag": 23.837121963500977, "eval/post_ent_max": 23.837121963500977, "eval/post_ent_mean": 23.360103607177734, "eval/post_ent_min": 23.1016845703125, "eval/post_ent_std": 0.14031417667865753, "eval/prior_ent_mag": 24.940723419189453, "eval/prior_ent_max": 24.940723419189453, "eval/prior_ent_mean": 23.00341796875, "eval/prior_ent_min": 21.850723266601562, "eval/prior_ent_std": 0.5295636057853699, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014109029434621334, "eval/reward_loss_std": 0.010206629522144794, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.09746408462524414, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014109029434621334, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006979585159569979, "eval/reward_rate": 0.0, "replay/size": 612305.0, "replay/inserts": 32480.0, "replay/samples": 32480.0, "replay/insert_wait_avg": 1.3400034364221132e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.739942062077264e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1289085217046668e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.295156955719, "timer/env.step_count": 4060.0, "timer/env.step_total": 38.09314322471619, "timer/env.step_frac": 0.038081903086133295, "timer/env.step_avg": 0.009382547592294628, "timer/env.step_min": 0.007657766342163086, "timer/env.step_max": 0.03557872772216797, "timer/replay._sample_count": 32480.0, "timer/replay._sample_total": 16.529510021209717, "timer/replay._sample_frac": 0.016524632660939138, "timer/replay._sample_avg": 0.0005089134858746834, "timer/replay._sample_min": 0.00039076805114746094, "timer/replay._sample_max": 0.011118650436401367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4751.0, "timer/agent.policy_total": 49.08807063102722, "timer/agent.policy_frac": 0.049073586220712104, "timer/agent.policy_avg": 0.01033215546853867, "timer/agent.policy_min": 0.008897066116333008, "timer/agent.policy_max": 0.08115220069885254, "timer/dataset_train_count": 2030.0, "timer/dataset_train_total": 0.21307015419006348, "timer/dataset_train_frac": 0.00021300728360868756, "timer/dataset_train_avg": 0.00010496066708870123, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0010750293731689453, "timer/agent.train_count": 2030.0, "timer/agent.train_total": 900.8909428119659, "timer/agent.train_frac": 0.9006251170441751, "timer/agent.train_avg": 0.44378864177929356, "timer/agent.train_min": 0.4346029758453369, "timer/agent.train_max": 0.6940410137176514, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48534584045410156, "timer/agent.report_frac": 0.0004852026295230647, "timer/agent.report_avg": 0.24267292022705078, "timer/agent.report_min": 0.23574447631835938, "timer/agent.report_max": 0.2496013641357422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.931683216255976e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 32.46981906515653}
{"step": 612864, "time": 19219.05643057823, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 612944, "time": 19221.501762628555, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 613376, "time": 19234.61713862419, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 613440, "time": 19236.71694779396, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 613520, "time": 19239.157981157303, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 613672, "time": 19243.54504776001, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 614048, "time": 19255.214255332947, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614152, "time": 19258.14030432701, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 614392, "time": 19265.42575597763, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614512, "time": 19269.86082983017, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 614648, "time": 19273.744853019714, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 614696, "time": 19275.212176799774, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 614720, "time": 19276.16362762451, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 614784, "time": 19278.10885500908, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 615112, "time": 19287.80912208557, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 615160, "time": 19289.287032842636, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 615280, "time": 19293.12646842003, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 615408, "time": 19297.127759695053, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 615488, "time": 19299.567818164825, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 615832, "time": 19309.847695350647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616032, "time": 19316.155660152435, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 616128, "time": 19319.10160303116, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 616464, "time": 19329.438575983047, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 616696, "time": 19336.279441595078, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 617096, "time": 19348.483050107956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617472, "time": 19360.28015947342, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617592, "time": 19363.736025571823, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617720, "time": 19367.674899101257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617800, "time": 19370.112577676773, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 617920, "time": 19373.994712352753, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 618264, "time": 19384.265964508057, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 618344, "time": 19386.79419374466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618440, "time": 19389.735011339188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 618712, "time": 19398.055841207504, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 618808, "time": 19400.975523471832, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 618816, "time": 19401.447075366974, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 619024, "time": 19407.803037166595, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 619408, "time": 19419.58017039299, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619640, "time": 19426.45486354828, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 619648, "time": 19426.930073022842, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 619784, "time": 19430.883534431458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 619880, "time": 19433.824718236923, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 619904, "time": 19434.791261911392, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 19439.93782234192, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 620048, "time": 19440.464025497437, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 620048, "time": 19440.620143175125, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 620048, "time": 19440.783430099487, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 620048, "time": 19441.147194862366, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 620048, "time": 19442.476759672165, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 620048, "time": 19442.522223949432, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 620048, "time": 19443.231870889664, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 620112, "time": 19445.203723192215, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 620120, "time": 19445.230759859085, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 620496, "time": 19456.968653440475, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 620880, "time": 19468.67436027527, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 620880, "time": 19468.680165052414, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 621008, "time": 19472.58917570114, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 621024, "time": 19473.081059217453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621040, "time": 19473.566618442535, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 621408, "time": 19484.86168527603, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 621720, "time": 19494.16998052597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 621856, "time": 19498.522516965866, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 621992, "time": 19502.452081918716, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 622088, "time": 19505.38763809204, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 622128, "time": 19506.913833141327, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 622432, "time": 19516.18763947487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 622552, "time": 19519.642536640167, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 622744, "time": 19525.943375587463, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 623336, "time": 19544.065311670303, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623376, "time": 19545.50474524498, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 623720, "time": 19555.779015302658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 623848, "time": 19559.69425177574, "episode/length": 231.0, "episode/score": 0.27812498807907104, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0}
{"step": 623968, "time": 19563.581612825394, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 624048, "time": 19566.107454538345, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 624168, "time": 19569.546982049942, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624216, "time": 19570.998574972153, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 624400, "time": 19576.817952871323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624440, "time": 19577.84477186203, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 624520, "time": 19580.276562452316, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 624560, "time": 19581.710121393204, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 624656, "time": 19584.650844335556, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 624696, "time": 19585.646234989166, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 624880, "time": 19591.47940826416, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 624968, "time": 19593.976682901382, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 625056, "time": 19596.95649075508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 625112, "time": 19598.46008825302, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 625120, "time": 19598.93283390999, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 625184, "time": 19600.885014295578, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 625312, "time": 19604.780375242233, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 625552, "time": 19612.122944831848, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 625880, "time": 19621.89399790764, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 626056, "time": 19627.33265066147, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 626072, "time": 19627.823848962784, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 626472, "time": 19639.99752998352, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 626720, "time": 19647.82537007332, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 626768, "time": 19649.31686449051, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 626832, "time": 19651.311451673508, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 626872, "time": 19652.309289693832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627024, "time": 19657.280510902405, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 627088, "time": 19659.238675117493, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 627384, "time": 19668.047909259796, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 627424, "time": 19669.493117570877, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 627536, "time": 19672.908012628555, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 627864, "time": 19682.681406497955, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 628032, "time": 19688.217500448227, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 628040, "time": 19688.245975971222, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 628072, "time": 19689.25423336029, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 628280, "time": 19695.688517570496, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 628464, "time": 19701.522792577744, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 628632, "time": 19706.417573213577, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 628744, "time": 19709.818617343903, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 628752, "time": 19710.312258005142, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 628872, "time": 19713.748192548752, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 629040, "time": 19719.20322418213, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 629144, "time": 19722.174383878708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629184, "time": 19723.62380218506, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 629184, "time": 19723.630640506744, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 629416, "time": 19730.514460086823, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 629552, "time": 19734.94786643982, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 629888, "time": 19745.251811504364, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 629912, "time": 19745.76903629303, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19749.768805503845, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 19750.70369052887, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 630032, "time": 19751.55335521698, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 630032, "time": 19752.936138391495, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 630032, "time": 19753.057359457016, "eval_episode/length": 140.0, "eval_episode/score": 0.5625, "eval_episode/reward_rate": 0.0070921985815602835}
{"step": 630032, "time": 19753.178238153458, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 630032, "time": 19754.175357103348, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 630032, "time": 19754.84899187088, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 630032, "time": 19755.810290813446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 19755.81632256508, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630032, "time": 19755.823048353195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 630064, "time": 19756.803723096848, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 630112, "time": 19758.29150414467, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 630384, "time": 19766.579100608826, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 630512, "time": 19770.485841989517, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 630592, "time": 19772.931300878525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 630976, "time": 19785.150458574295, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 631016, "time": 19786.16992330551, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 631056, "time": 19787.62518119812, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 631072, "time": 19788.12026977539, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 631088, "time": 19788.610942840576, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 631128, "time": 19789.60407757759, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 631208, "time": 19792.055455446243, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 631224, "time": 19792.54717183113, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 631728, "time": 19808.189016819, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 631760, "time": 19809.174840927124, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 631800, "time": 19810.196578502655, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 632240, "time": 19823.785572052002, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 632296, "time": 19825.267027139664, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 632488, "time": 19831.106828451157, "episode/length": 246.0, "episode/score": 0.23125000298023224, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.0}
{"step": 632656, "time": 19836.507016181946, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 632728, "time": 19838.46422767639, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 632728, "time": 19838.474311113358, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 632904, "time": 19843.790870428085, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 633016, "time": 19847.22239303589, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 633176, "time": 19852.08615875244, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 633400, "time": 19858.88596391678, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 633592, "time": 19864.68751859665, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 633592, "time": 19864.693225860596, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 634072, "time": 19879.324108839035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634152, "time": 19881.748087644577, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 634184, "time": 19882.724271774292, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 634280, "time": 19885.665680885315, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 634312, "time": 19886.641879320145, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 634424, "time": 19890.063317537308, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 634800, "time": 19901.838313817978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 634848, "time": 19903.320798158646, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 634928, "time": 19905.74424982071, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 635176, "time": 19913.10309767723, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 635440, "time": 19921.354428768158, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 635536, "time": 19924.278524398804, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 635568, "time": 19925.25873041153, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 635792, "time": 19932.177012205124, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 635856, "time": 19934.145426273346, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 635904, "time": 19935.603546857834, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636280, "time": 19946.89834165573, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 636384, "time": 19950.29598712921, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636736, "time": 19961.106815099716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 636808, "time": 19963.082273244858, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 636816, "time": 19963.55450963974, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 637000, "time": 19968.945974349976, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 637024, "time": 19969.91153907776, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 637160, "time": 19973.83435153961, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 637216, "time": 19975.75953912735, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 637536, "time": 19985.495840787888, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 637536, "time": 19985.5017683506, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 637656, "time": 19989.017657756805, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 637688, "time": 19990.000983953476, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 637720, "time": 19991.00784111023, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 637856, "time": 19995.403530597687, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 638288, "time": 20008.635509967804, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 638472, "time": 20014.03093647957, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 638608, "time": 20018.512986660004, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 638664, "time": 20020.000102996826, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 638736, "time": 20022.431426525116, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 638976, "time": 20029.875680685043, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 639368, "time": 20041.96364045143, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 639384, "time": 20042.45628142357, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 639472, "time": 20045.368465662003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639696, "time": 20052.287773132324, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 639848, "time": 20056.710325479507, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 639872, "time": 20057.667289972305, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 20063.406326532364, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 640016, "time": 20063.713633298874, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 640016, "time": 20064.077662944794, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 640016, "time": 20064.178206443787, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 640016, "time": 20064.33669400215, "eval_episode/length": 118.0, "eval_episode/score": 0.6312500238418579, "eval_episode/reward_rate": 0.008403361344537815}
{"step": 640016, "time": 20064.79298901558, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 640016, "time": 20064.99503827095, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 640016, "time": 20065.281437158585, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 640032, "time": 20065.779718875885, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 640128, "time": 20068.732672452927, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 640288, "time": 20073.60951066017, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 640312, "time": 20074.119277715683, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 640656, "time": 20084.900257110596, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 640680, "time": 20085.413974285126, "episode/length": 212.0, "episode/score": 0.3375000059604645, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.0}
{"step": 640744, "time": 20087.379561424255, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 640912, "time": 20092.676851034164, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 640920, "time": 20092.703788757324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 641120, "time": 20098.95057439804, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 641152, "time": 20099.928504943848, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 641168, "time": 20100.417764425278, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 641456, "time": 20109.292432785034, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 641632, "time": 20114.651804685593, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 641760, "time": 20118.57252717018, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 641840, "time": 20121.006784677505, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 641920, "time": 20123.474777698517, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 642088, "time": 20128.375341892242, "episode/length": 276.0, "episode/score": 0.13750000298023224, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.0}
{"step": 642184, "time": 20131.299472808838, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 642488, "time": 20140.647709608078, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 642512, "time": 20141.62661600113, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 642792, "time": 20149.890670776367, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 642808, "time": 20150.378594875336, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 642872, "time": 20152.32537174225, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 643056, "time": 20158.143615961075, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643248, "time": 20163.937088012695, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 643320, "time": 20166.02110004425, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 643384, "time": 20167.966316223145, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 643432, "time": 20169.43547296524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 643512, "time": 20171.872437238693, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 643608, "time": 20174.781060934067, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 643792, "time": 20180.612651348114, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 644000, "time": 20186.929257392883, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 644008, "time": 20186.95864534378, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 644168, "time": 20191.824592351913, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 644536, "time": 20203.09143924713, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 644664, "time": 20206.989896297455, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 644800, "time": 20211.32613325119, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 644824, "time": 20211.832862377167, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 644880, "time": 20213.74426627159, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 644985, "time": 20217.681168317795, "train_stats/mean_log_entropy": 0.09189527832799488, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.47156885251477, "train/action_min": 0.0, "train/action_std": 1.8525212131329436, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0144461738061512, "train/actor_opt_grad_steps": 39210.0, "train/actor_opt_loss": -15.32289851601444, "train/adv_mag": 1.0670911625250061, "train/adv_max": 0.25386341709402666, "train/adv_mean": 0.0020559553539720556, "train/adv_min": -1.0375033361994805, "train/adv_std": 0.03505875589094352, "train/cont_avg": 0.9947868081467661, "train/cont_loss_mean": 0.017289138348096637, "train/cont_loss_std": 0.23229812397922747, "train/cont_neg_acc": 0.32656541151638646, "train/cont_neg_loss": 2.625556386228818, "train/cont_pos_acc": 0.9998192517318536, "train/cont_pos_loss": 0.003728831804876415, "train/cont_pred": 0.994708735551407, "train/cont_rate": 0.9947868081467661, "train/dyn_loss_mean": 1.0000025692270762, "train/dyn_loss_std": 8.174493203440042e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.21192165909900298, "train/extr_critic_critic_opt_grad_steps": 39210.0, "train/extr_critic_critic_opt_loss": 8789.981309273942, "train/extr_critic_mag": 1.5896505526642302, "train/extr_critic_max": 1.5896505526642302, "train/extr_critic_mean": 1.503892698098178, "train/extr_critic_min": 1.4049086535154884, "train/extr_critic_std": 0.02370725785247722, "train/extr_return_normed_mag": 1.0680186511272223, "train/extr_return_normed_max": 0.3156360992744787, "train/extr_return_normed_mean": 0.05015388779129036, "train/extr_return_normed_min": -1.002678062192243, "train/extr_return_normed_std": 0.04390709524724021, "train/extr_return_rate": 0.9995077074463687, "train/extr_return_raw_mag": 1.771430505448906, "train/extr_return_raw_max": 1.771430505448906, "train/extr_return_raw_mean": 1.5059483721481628, "train/extr_return_raw_min": 0.4531163439821841, "train/extr_return_raw_std": 0.04390709526577399, "train/extr_reward_mag": 0.29935409892257764, "train/extr_reward_max": 0.29935409892257764, "train/extr_reward_mean": 0.0025773959990766883, "train/extr_reward_min": 7.710053553035604e-08, "train/extr_reward_std": 0.010845288161688777, "train/image_loss_mean": 0.0899860370922741, "train/image_loss_std": 0.10147172549915551, "train/model_loss_mean": 0.7210733991357224, "train/model_loss_std": 0.4475574252098354, "train/model_opt_grad_norm": 21.905210575654138, "train/model_opt_grad_steps": 39175.880597014926, "train/model_opt_loss": 3658.877884746191, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5099.502487562189, "train/policy_entropy_mag": 1.3294133274116327, "train/policy_entropy_max": 1.3294133274116327, "train/policy_entropy_mean": 0.11224041475140634, "train/policy_entropy_min": 0.0646864924561325, "train/policy_entropy_std": 0.1458742847267668, "train/policy_logprob_mag": 6.551080255366084, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.11204035261377174, "train/policy_logprob_min": -6.551080255366084, "train/policy_logprob_std": 0.6488392628840546, "train/policy_randomness_mag": 0.6831833429597504, "train/policy_randomness_max": 0.6831833429597504, "train/policy_randomness_mean": 0.05768016599748858, "train/policy_randomness_min": 0.03324228171166496, "train/policy_randomness_std": 0.0749645577697315, "train/post_ent_mag": 24.02398589594447, "train/post_ent_max": 24.02398589594447, "train/post_ent_mean": 23.56942667415486, "train/post_ent_min": 23.266801179344974, "train/post_ent_std": 0.14746257395886664, "train/prior_ent_mag": 24.518228170290516, "train/prior_ent_max": 24.518228170290516, "train/prior_ent_mean": 22.87191230622097, "train/prior_ent_min": 21.740240059088713, "train/prior_ent_std": 0.42613170677749673, "train/rep_loss_mean": 1.0000025692270762, "train/rep_loss_std": 8.174493203440042e-05, "train/reward_avg": 0.0017957241452586912, "train/reward_loss_mean": 0.01379665989308289, "train/reward_loss_std": 0.2164888966432425, "train/reward_max_data": 0.7291044780789916, "train/reward_max_pred": 0.2578226428719895, "train/reward_neg_acc": 0.9995273686760101, "train/reward_neg_loss": 0.002541201159622131, "train/reward_pos_acc": 0.17989144076646302, "train/reward_pos_loss": 4.2118690508017265, "train/reward_pred": 0.0014949880797527175, "train/reward_rate": 0.0027013370646766168, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.014749214053153992, "report/cont_loss_std": 0.24578304588794708, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.8022868633270264, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003817693330347538, "report/cont_pred": 0.9946057796478271, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0839189887046814, "report/image_loss_std": 0.09647466242313385, "report/model_loss_mean": 0.7067734003067017, "report/model_loss_std": 0.3816070556640625, "report/post_ent_mag": 23.770980834960938, "report/post_ent_max": 23.770980834960938, "report/post_ent_mean": 23.317779541015625, "report/post_ent_min": 23.025367736816406, "report/post_ent_std": 0.14511418342590332, "report/prior_ent_mag": 24.41185760498047, "report/prior_ent_max": 24.41185760498047, "report/prior_ent_mean": 23.039539337158203, "report/prior_ent_min": 22.025371551513672, "report/prior_ent_std": 0.3911300003528595, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005218505975790322, "report/reward_loss_mean": 0.008105222135782242, "report/reward_loss_std": 0.1660095453262329, "report/reward_max_data": 0.534375011920929, "report/reward_max_pred": 0.08034300804138184, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002928755944594741, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.3036298751831055, "report/reward_pred": 0.0014639424625784159, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.006634376477450132, "eval/cont_loss_std": 0.16366173326969147, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.216379165649414, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0015417614486068487, "eval/cont_pred": 0.9985660910606384, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19952505826950073, "eval/image_loss_std": 0.14542217552661896, "eval/model_loss_mean": 0.8065488338470459, "eval/model_loss_std": 0.21729776263237, "eval/post_ent_mag": 23.776147842407227, "eval/post_ent_max": 23.776147842407227, "eval/post_ent_mean": 23.27063751220703, "eval/post_ent_min": 23.00078773498535, "eval/post_ent_std": 0.1435551941394806, "eval/prior_ent_mag": 24.50537109375, "eval/prior_ent_max": 24.50537109375, "eval/prior_ent_mean": 23.064830780029297, "eval/prior_ent_min": 22.117589950561523, "eval/prior_ent_std": 0.3985702693462372, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0003893636167049408, "eval/reward_loss_std": 0.0018956662388518453, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.01102757453918457, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0003893636167049408, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00019674771465361118, "eval/reward_rate": 0.0, "replay/size": 644481.0, "replay/inserts": 32176.0, "replay/samples": 32176.0, "replay/insert_wait_avg": 1.348581022436141e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.819071271299783e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5360.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.132577212888803e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2468776702881, "timer/env.step_count": 4022.0, "timer/env.step_total": 37.88256859779358, "timer/env.step_frac": 0.03787321854583267, "timer/env.step_avg": 0.009418838537492188, "timer/env.step_min": 0.007722377777099609, "timer/env.step_max": 0.03865337371826172, "timer/replay._sample_count": 32176.0, "timer/replay._sample_total": 16.448336362838745, "timer/replay._sample_frac": 0.01644427663813275, "timer/replay._sample_avg": 0.000511198917293596, "timer/replay._sample_min": 0.00036787986755371094, "timer/replay._sample_max": 0.011924982070922852, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4692.0, "timer/agent.policy_total": 48.68664002418518, "timer/agent.policy_frac": 0.04867462334657123, "timer/agent.policy_avg": 0.010376521744284991, "timer/agent.policy_min": 0.008814334869384766, "timer/agent.policy_max": 0.08652925491333008, "timer/dataset_train_count": 2011.0, "timer/dataset_train_total": 0.20992732048034668, "timer/dataset_train_frac": 0.00020987550690415165, "timer/dataset_train_avg": 0.0001043895178917686, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0004930496215820312, "timer/agent.train_count": 2011.0, "timer/agent.train_total": 901.4582765102386, "timer/agent.train_frac": 0.9012357815201167, "timer/agent.train_avg": 0.4482636879712773, "timer/agent.train_min": 0.43585681915283203, "timer/agent.train_max": 0.6806917190551758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48006367683410645, "timer/agent.report_frac": 0.00047994518908395944, "timer/agent.report_avg": 0.24003183841705322, "timer/agent.report_min": 0.23208928108215332, "timer/agent.report_max": 0.24797439575195312, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.860316800870665e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 32.16751949555932}
{"step": 645176, "time": 20223.23563861847, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 645176, "time": 20223.242960453033, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 645208, "time": 20224.21164536476, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 645320, "time": 20227.720215320587, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 645672, "time": 20238.39940929413, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 645832, "time": 20243.277278900146, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 646136, "time": 20252.515747070312, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 646208, "time": 20254.94290494919, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 646272, "time": 20256.987243175507, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 646480, "time": 20263.31831765175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 646504, "time": 20263.8234770298, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 646968, "time": 20277.8525891304, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 646992, "time": 20278.818191051483, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 647136, "time": 20283.14929294586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647160, "time": 20283.673396348953, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 647192, "time": 20285.10693359375, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 647224, "time": 20286.22767829895, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 647248, "time": 20287.172344207764, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 647568, "time": 20296.83573293686, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 647600, "time": 20297.80925154686, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 647624, "time": 20298.314774751663, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 647680, "time": 20300.24311041832, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 647920, "time": 20307.519038438797, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 647984, "time": 20309.487287282944, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 648072, "time": 20311.931048870087, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 648080, "time": 20312.398470640182, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 648288, "time": 20318.843826770782, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 648368, "time": 20321.26481819153, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 648504, "time": 20325.1687104702, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 648992, "time": 20340.194586753845, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 649072, "time": 20342.624989271164, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 649120, "time": 20344.081684589386, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 649304, "time": 20349.52647447586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 649392, "time": 20352.419505357742, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 649424, "time": 20353.393905878067, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 649752, "time": 20363.092192411423, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 649992, "time": 20370.372379779816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 20371.97558283806, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 650000, "time": 20372.64017510414, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 650000, "time": 20372.75399875641, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 650000, "time": 20373.014411449432, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 650000, "time": 20373.202093839645, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 650000, "time": 20373.80717730522, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 650000, "time": 20374.518545150757, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 650000, "time": 20374.764983654022, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 650144, "time": 20379.20290994644, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 650272, "time": 20383.094212293625, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 650384, "time": 20386.50140619278, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650392, "time": 20386.528958797455, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 650488, "time": 20389.43310546875, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 650600, "time": 20392.8548412323, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 650784, "time": 20398.66528916359, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 651232, "time": 20412.296531915665, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 651280, "time": 20413.745491981506, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 651304, "time": 20414.25335407257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651440, "time": 20418.61322402954, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 651464, "time": 20419.120735645294, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 651464, "time": 20419.126250982285, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 651736, "time": 20427.37567806244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 651816, "time": 20429.813634634018, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 652000, "time": 20435.596371889114, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 652136, "time": 20439.61536717415, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 652200, "time": 20441.549224853516, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 652208, "time": 20442.018887996674, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 652368, "time": 20446.865049362183, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 652704, "time": 20457.088608264923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 652784, "time": 20459.52824807167, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 653016, "time": 20466.436937332153, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 653048, "time": 20467.41360759735, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 653064, "time": 20467.905354499817, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 653136, "time": 20470.32111310959, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 653392, "time": 20478.11894083023, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 653544, "time": 20482.494399547577, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653592, "time": 20483.962302923203, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 653616, "time": 20484.91316509247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 653776, "time": 20489.776802539825, "episode/length": 28.0, "episode/score": 0.9125000238418579, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.0}
{"step": 653904, "time": 20493.664316177368, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 654136, "time": 20500.589780807495, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 654152, "time": 20501.080433130264, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 654440, "time": 20509.83740711212, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 654520, "time": 20512.271290779114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 654776, "time": 20520.100321531296, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 654992, "time": 20526.953506469727, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 655232, "time": 20534.269651174545, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 655328, "time": 20537.21554160118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655448, "time": 20541.072483301163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 655624, "time": 20546.430836439133, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 655800, "time": 20551.783961057663, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 656096, "time": 20561.067900896072, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 656464, "time": 20572.193323373795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656608, "time": 20576.55357670784, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 656792, "time": 20581.900977373123, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 656832, "time": 20583.32837319374, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 656944, "time": 20586.81734418869, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 656960, "time": 20587.30895471573, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 657032, "time": 20589.263212919235, "episode/length": 24.0, "episode/score": 0.925000011920929, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0}
{"step": 657040, "time": 20589.727298021317, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 657088, "time": 20591.19595360756, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 657328, "time": 20598.442551136017, "episode/length": 234.0, "episode/score": 0.26875001192092896, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.0}
{"step": 657376, "time": 20599.90366411209, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 657552, "time": 20605.23118042946, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 657752, "time": 20611.07254743576, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 657904, "time": 20615.95863223076, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 657912, "time": 20616.01924586296, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 658176, "time": 20624.2403113842, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 658408, "time": 20631.060287475586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658600, "time": 20636.888701200485, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 658736, "time": 20641.24844646454, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 658920, "time": 20646.717764616013, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 658984, "time": 20648.67468714714, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 659136, "time": 20653.52033638954, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 659256, "time": 20656.9424200058, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 659344, "time": 20659.837181568146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659400, "time": 20661.313022851944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 659680, "time": 20670.013882637024, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 659712, "time": 20670.98579120636, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 659888, "time": 20676.412313461304, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 20683.1411755085, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 660088, "time": 20683.53742337227, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 660088, "time": 20683.675114393234, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 660088, "time": 20683.883368968964, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 660088, "time": 20684.052864074707, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 660088, "time": 20684.67736172676, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 660088, "time": 20685.218903303146, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 660088, "time": 20685.99337744713, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 660224, "time": 20690.357617616653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 660232, "time": 20690.384392738342, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 660296, "time": 20692.33498620987, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 660392, "time": 20695.242866277695, "episode/length": 206.0, "episode/score": 0.35624998807907104, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.0}
{"step": 660408, "time": 20695.72861480713, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 660448, "time": 20697.185091018677, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 660472, "time": 20697.69212770462, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 660656, "time": 20703.497971773148, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 660792, "time": 20707.45105457306, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 661264, "time": 20721.99559402466, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 661424, "time": 20726.853454113007, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 661632, "time": 20733.13393187523, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 661632, "time": 20733.13977432251, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 661864, "time": 20740.075246334076, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 661992, "time": 20743.940399885178, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662064, "time": 20746.354955673218, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 662280, "time": 20752.66267514229, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 662504, "time": 20759.4488594532, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 662512, "time": 20759.94239425659, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 662592, "time": 20762.355833292007, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 662656, "time": 20764.292459726334, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 662704, "time": 20765.765015125275, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 662800, "time": 20768.75869512558, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 662968, "time": 20773.64577150345, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 662984, "time": 20774.134567260742, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 663056, "time": 20776.55733036995, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 663104, "time": 20778.023072481155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 663200, "time": 20780.940931081772, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 663552, "time": 20791.766224861145, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 663672, "time": 20795.55630350113, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 663728, "time": 20797.596994400024, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 663952, "time": 20804.382297992706, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 664264, "time": 20813.575889348984, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 664576, "time": 20823.252155780792, "episode/length": 189.0, "episode/score": 0.40937501192092896, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.0}
{"step": 664704, "time": 20827.209906339645, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 664736, "time": 20828.188482046127, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 664752, "time": 20828.69842362404, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 664752, "time": 20828.705478429794, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 664816, "time": 20830.647035837173, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665224, "time": 20842.81768298149, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 665392, "time": 20848.135620832443, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 665512, "time": 20851.551403045654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 665560, "time": 20853.038328647614, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 665728, "time": 20858.4081594944, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 665736, "time": 20858.43428349495, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 665760, "time": 20859.38558292389, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 665840, "time": 20861.799317598343, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 665848, "time": 20861.82644724846, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 666680, "time": 20887.202532052994, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 666912, "time": 20894.444811344147, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 667016, "time": 20897.41250014305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667216, "time": 20903.69470357895, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 667440, "time": 20910.482788324356, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 667704, "time": 20918.348180294037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 667744, "time": 20919.78953075409, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 667760, "time": 20920.279252052307, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 667824, "time": 20922.22381711006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668040, "time": 20928.558898210526, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668040, "time": 20928.564675807953, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 668072, "time": 20929.53701376915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 668384, "time": 20939.207989931107, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 668624, "time": 20946.586173534393, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 668696, "time": 20948.542536973953, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 668840, "time": 20952.906569719315, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 669248, "time": 20967.125147104263, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 669440, "time": 20972.959602594376, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 669520, "time": 20975.400671243668, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 669752, "time": 20982.338250398636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 669784, "time": 20983.305994987488, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 669848, "time": 20985.25115132332, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 670056, "time": 20991.637182950974, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 20992.125967264175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 20993.33562850952, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 670072, "time": 20993.396601200104, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 670072, "time": 20993.894364118576, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 670072, "time": 20993.920780658722, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 670072, "time": 20994.20697617531, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 670072, "time": 20994.307546377182, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 670072, "time": 20994.630616903305, "eval_episode/length": 36.0, "eval_episode/score": 0.887499988079071, "eval_episode/reward_rate": 0.02702702702702703}
{"step": 670072, "time": 20994.675362825394, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 670256, "time": 21000.451910495758, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 670384, "time": 21004.364847421646, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 670736, "time": 21015.16568660736, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 670808, "time": 21017.143366098404, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 670864, "time": 21019.07145547867, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 671008, "time": 21023.418875932693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671200, "time": 21029.251882076263, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 671232, "time": 21030.230322360992, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 671560, "time": 21040.08306837082, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 671760, "time": 21046.8964073658, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 671944, "time": 21052.1958463192, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 671968, "time": 21053.162615299225, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 672160, "time": 21058.979244947433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672280, "time": 21062.381844997406, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 672376, "time": 21065.273058652878, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 672568, "time": 21071.1213889122, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 672896, "time": 21081.264186382294, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 672984, "time": 21083.716433525085, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 673120, "time": 21088.06851053238, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673176, "time": 21089.539953947067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 673192, "time": 21090.02825832367, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 673512, "time": 21099.871546268463, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 673712, "time": 21106.230755090714, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 673976, "time": 21113.985266923904, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 674352, "time": 21125.635075330734, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 674384, "time": 21126.702184677124, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 674456, "time": 21128.673540592194, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 674456, "time": 21128.680532455444, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 674528, "time": 21131.1123752594, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 674592, "time": 21133.059802532196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674808, "time": 21139.42359638214, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 674880, "time": 21141.831496715546, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 674896, "time": 21142.317838907242, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 674944, "time": 21143.78045463562, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 675360, "time": 21156.46114039421, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 675536, "time": 21161.800276756287, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 675680, "time": 21166.16615509987, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 675936, "time": 21173.91245174408, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 675960, "time": 21174.43853878975, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 676072, "time": 21177.821125507355, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 676152, "time": 21180.244729042053, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 676208, "time": 21182.16509628296, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 676320, "time": 21185.558620929718, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 676464, "time": 21190.054777383804, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 676712, "time": 21197.324184179306, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 676712, "time": 21197.32956314087, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 676768, "time": 21199.256140470505, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676840, "time": 21201.219039916992, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 676856, "time": 21201.707392930984, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 677168, "time": 21211.393144845963, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 677256, "time": 21213.85971403122, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 677353, "time": 21217.83152627945, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4108122268525682, "train/action_min": 0.0, "train/action_std": 1.8245566026999218, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014428893773871852, "train/actor_opt_grad_steps": 41225.0, "train/actor_opt_loss": -17.047067654014814, "train/adv_mag": 1.0733237455386926, "train/adv_max": 0.27688326634983024, "train/adv_mean": 0.001075038208479989, "train/adv_min": -1.0411170313854028, "train/adv_std": 0.037384851960151795, "train/cont_avg": 0.9945225479579208, "train/cont_loss_mean": 0.018540636728526932, "train/cont_loss_std": 0.24194249941386503, "train/cont_neg_acc": 0.32141482619808454, "train/cont_neg_loss": 2.666475101916401, "train/cont_pos_acc": 0.999844486170476, "train/cont_pos_loss": 0.0038174844449524316, "train/cont_pred": 0.9946123827802072, "train/cont_rate": 0.9945225479579208, "train/dyn_loss_mean": 1.0000001345530596, "train/dyn_loss_std": 4.295797990911668e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22134351160487917, "train/extr_critic_critic_opt_grad_steps": 41225.0, "train/extr_critic_critic_opt_loss": 4491.104345944848, "train/extr_critic_mag": 1.658313518703574, "train/extr_critic_max": 1.658313518703574, "train/extr_critic_mean": 1.565455967246896, "train/extr_critic_min": 1.4178736292489684, "train/extr_critic_std": 0.024445831923201534, "train/extr_return_normed_mag": 1.0726555385211907, "train/extr_return_normed_max": 0.31306132585695473, "train/extr_return_normed_mean": 0.05028137804405524, "train/extr_return_normed_min": -1.0033208078677112, "train/extr_return_normed_std": 0.0463619281049117, "train/extr_return_rate": 0.9994933850104266, "train/extr_return_raw_mag": 1.8293107942779465, "train/extr_return_raw_max": 1.8293107942779465, "train/extr_return_raw_mean": 1.5665309252125201, "train/extr_return_raw_min": 0.5129286605532807, "train/extr_return_raw_std": 0.04636192821556389, "train/extr_reward_mag": 0.2899584575454787, "train/extr_reward_max": 0.2899584575454787, "train/extr_reward_mean": 0.0025050016396706647, "train/extr_reward_min": 6.72765297464805e-08, "train/extr_reward_std": 0.010308447879471697, "train/image_loss_mean": 0.0909343834892653, "train/image_loss_std": 0.10308660474596637, "train/model_loss_mean": 0.7249175779300161, "train/model_loss_std": 0.46970570161200986, "train/model_opt_grad_norm": 21.366939289735097, "train/model_opt_grad_steps": 41188.762376237624, "train/model_opt_loss": 2884.7772621683557, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3985.1485148514853, "train/policy_entropy_mag": 1.3415674148219647, "train/policy_entropy_max": 1.3415674148219647, "train/policy_entropy_mean": 0.10838654644713544, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.141553234272074, "train/policy_logprob_mag": 6.551080255225154, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10820305694152813, "train/policy_logprob_min": -6.551080255225154, "train/policy_logprob_std": 0.6446522781164339, "train/policy_randomness_mag": 0.6894293096986147, "train/policy_randomness_max": 0.6894293096986147, "train/policy_randomness_mean": 0.05569966895376692, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07274397641494132, "train/post_ent_mag": 23.691565305879802, "train/post_ent_max": 23.691565305879802, "train/post_ent_mean": 23.2502024244554, "train/post_ent_min": 22.947994298273976, "train/post_ent_std": 0.1473517322746834, "train/prior_ent_mag": 23.823227051461096, "train/prior_ent_max": 23.823227051461096, "train/prior_ent_mean": 22.30235537916127, "train/prior_ent_min": 21.354830496382004, "train/prior_ent_std": 0.38100145226067833, "train/rep_loss_mean": 1.0000001345530596, "train/rep_loss_std": 4.295797990911668e-06, "train/reward_avg": 0.0020763888230546155, "train/reward_loss_mean": 0.015442456862206876, "train/reward_loss_std": 0.22659995106260966, "train/reward_max_data": 0.7382425753639477, "train/reward_max_pred": 0.26808523128528405, "train/reward_neg_acc": 0.9995053637735914, "train/reward_neg_loss": 0.002684723740296051, "train/reward_pos_acc": 0.19503449086899532, "train/reward_pos_loss": 4.079089592888717, "train/reward_pred": 0.0016358340127937644, "train/reward_rate": 0.0031279006806930695, "train_stats/mean_log_entropy": 0.08283333640930982, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.01027565449476242, "report/cont_loss_std": 0.165889173746109, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 1.333258867263794, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0024781115353107452, "report/cont_pred": 0.9940552711486816, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08023260533809662, "report/image_loss_std": 0.09543155878782272, "report/model_loss_mean": 0.701491117477417, "report/model_loss_std": 0.38897207379341125, "report/post_ent_mag": 23.90604591369629, "report/post_ent_max": 23.90604591369629, "report/post_ent_mean": 23.420394897460938, "report/post_ent_min": 23.138282775878906, "report/post_ent_std": 0.14747560024261475, "report/prior_ent_mag": 23.362098693847656, "report/prior_ent_max": 23.362098693847656, "report/prior_ent_mean": 21.625120162963867, "report/prior_ent_min": 20.727802276611328, "report/prior_ent_std": 0.3795311450958252, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0020263672340661287, "report/reward_loss_mean": 0.010982840321958065, "report/reward_loss_std": 0.1956760585308075, "report/reward_max_data": 0.796875, "report/reward_max_pred": 0.5960477590560913, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0014125700108706951, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.268064498901367, "report/reward_pred": 0.0013277673861011863, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.06492514163255692, "eval/cont_loss_std": 0.778747022151947, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.82673168182373, "eval/cont_pos_acc": 0.9990166425704956, "eval/cont_pos_loss": 0.0046177273616194725, "eval/cont_pred": 0.9963066577911377, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21150816977024078, "eval/image_loss_std": 0.15014639496803284, "eval/model_loss_mean": 0.9080429077148438, "eval/model_loss_std": 1.1860260963439941, "eval/post_ent_mag": 23.872547149658203, "eval/post_ent_max": 23.872547149658203, "eval/post_ent_mean": 23.418272018432617, "eval/post_ent_min": 23.133800506591797, "eval/post_ent_std": 0.14387063682079315, "eval/prior_ent_mag": 23.945323944091797, "eval/prior_ent_max": 23.945323944091797, "eval/prior_ent_mean": 21.656702041625977, "eval/prior_ent_min": 20.7773380279541, "eval/prior_ent_std": 0.37365803122520447, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002685546875, "eval/reward_loss_mean": 0.03160952404141426, "eval/reward_loss_std": 0.5010088682174683, "eval/reward_max_data": 0.859375, "eval/reward_max_pred": 0.04174363613128662, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.001004581805318594, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.835869789123535, "eval/reward_pred": 0.0005192805547267199, "eval/reward_rate": 0.00390625, "replay/size": 676849.0, "replay/inserts": 32368.0, "replay/samples": 32368.0, "replay/insert_wait_avg": 1.3537959067231055e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.473930414513792e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1354629742239849e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1352338790894, "timer/env.step_count": 4046.0, "timer/env.step_total": 38.124406814575195, "timer/env.step_frac": 0.03811925180028626, "timer/env.step_avg": 0.009422740191442213, "timer/env.step_min": 0.007600307464599609, "timer/env.step_max": 0.03607511520385742, "timer/replay._sample_count": 32368.0, "timer/replay._sample_total": 16.195585250854492, "timer/replay._sample_frac": 0.01619339535518498, "timer/replay._sample_avg": 0.0005003579229749905, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.01114201545715332, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4587.0, "timer/agent.policy_total": 47.37748622894287, "timer/agent.policy_frac": 0.04737108005403051, "timer/agent.policy_avg": 0.010328643171777386, "timer/agent.policy_min": 0.008614301681518555, "timer/agent.policy_max": 0.08286356925964355, "timer/dataset_train_count": 2023.0, "timer/dataset_train_total": 0.2111508846282959, "timer/dataset_train_frac": 0.00021112233373614238, "timer/dataset_train_avg": 0.00010437512833825798, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0010688304901123047, "timer/agent.train_count": 2023.0, "timer/agent.train_total": 903.711923122406, "timer/agent.train_frac": 0.9035897271784944, "timer/agent.train_avg": 0.44671869655086804, "timer/agent.train_min": 0.43238115310668945, "timer/agent.train_max": 2.1092755794525146, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4799308776855469, "timer/agent.report_frac": 0.0004798659835471488, "timer/agent.report_avg": 0.23996543884277344, "timer/agent.report_min": 0.23464035987854004, "timer/agent.report_max": 0.24529051780700684, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5510787963867188e-05, "timer/dataset_eval_frac": 2.5507338507535567e-08, "timer/dataset_eval_avg": 2.5510787963867188e-05, "timer/dataset_eval_min": 2.5510787963867188e-05, "timer/dataset_eval_max": 2.5510787963867188e-05, "fps": 32.36308888299061}
{"step": 677496, "time": 21221.938678741455, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 677616, "time": 21225.828859329224, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 677616, "time": 21225.834668636322, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 678152, "time": 21241.853831768036, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 678168, "time": 21242.33942604065, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 678416, "time": 21250.172850608826, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 678520, "time": 21253.12455391884, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 678896, "time": 21264.778747320175, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 679016, "time": 21268.222360134125, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 679024, "time": 21268.692940235138, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679080, "time": 21270.165747880936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679232, "time": 21274.998727560043, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 679336, "time": 21278.018271446228, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 679480, "time": 21282.39818072319, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679568, "time": 21285.28510737419, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 679696, "time": 21289.174267292023, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 679760, "time": 21291.111413002014, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 21301.387212991714, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 680056, "time": 21301.82137465477, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 680056, "time": 21302.42308449745, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 680056, "time": 21303.33656334877, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 680056, "time": 21303.84830880165, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 680056, "time": 21304.45027422905, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 680056, "time": 21305.10537338257, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 680056, "time": 21305.20458173752, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 680128, "time": 21307.682199716568, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 680192, "time": 21309.61593055725, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 680312, "time": 21313.034607887268, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 680560, "time": 21320.83881163597, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 680568, "time": 21320.8665702343, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 680696, "time": 21324.772819280624, "episode/length": 15.0, "episode/score": 0.953125, "episode/reward_rate": 0.0625, "episode/intrinsic_return": 0.0}
{"step": 680728, "time": 21325.7472987175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 680992, "time": 21334.02839565277, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 681392, "time": 21346.284073114395, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 681648, "time": 21354.061981916428, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 681712, "time": 21356.018991947174, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 681880, "time": 21360.908968925476, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 682032, "time": 21365.747929096222, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 682304, "time": 21374.08201599121, "episode/length": 271.0, "episode/score": 0.15312500298023224, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.0}
{"step": 682536, "time": 21380.952999830246, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 682624, "time": 21383.83769774437, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683008, "time": 21395.5057785511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683040, "time": 21396.557773590088, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683160, "time": 21399.989910125732, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 683304, "time": 21404.3495323658, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683440, "time": 21408.692405462265, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 683472, "time": 21409.67709493637, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 683656, "time": 21415.062227010727, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 683960, "time": 21424.305480480194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 683960, "time": 21424.310899734497, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 684168, "time": 21430.726850032806, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 684448, "time": 21439.43585085869, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 684616, "time": 21444.30602002144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 684936, "time": 21453.99841070175, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685072, "time": 21458.432106018066, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 685320, "time": 21465.78272628784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685496, "time": 21471.138273715973, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 685608, "time": 21474.53210401535, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 685616, "time": 21475.00238609314, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 685776, "time": 21479.860365629196, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 685856, "time": 21482.279109954834, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 685920, "time": 21484.231598615646, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 686016, "time": 21487.20705628395, "episode/length": 230.0, "episode/score": 0.28125, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.0}
{"step": 686272, "time": 21494.992477178574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 686304, "time": 21495.965737342834, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 686424, "time": 21499.399014234543, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 686536, "time": 21502.804943323135, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 686544, "time": 21503.273278474808, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 686632, "time": 21505.69723558426, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 686640, "time": 21506.169830560684, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 686656, "time": 21506.661540985107, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 686968, "time": 21515.915372610092, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 687048, "time": 21518.415745019913, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 687048, "time": 21518.420971870422, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 687376, "time": 21528.598254203796, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 687544, "time": 21533.466039657593, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 687728, "time": 21539.265552043915, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 687800, "time": 21541.242745876312, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 687832, "time": 21542.22092604637, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 688056, "time": 21549.14363384247, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 688336, "time": 21558.440901517868, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 688560, "time": 21565.249616384506, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 688592, "time": 21566.24627161026, "episode/length": 243.0, "episode/score": 0.24062499403953552, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.0}
{"step": 688616, "time": 21566.75749015808, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 688704, "time": 21569.66166996956, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 688920, "time": 21576.150613069534, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 689208, "time": 21584.89967751503, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 689216, "time": 21585.36835193634, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 689360, "time": 21589.76637482643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689584, "time": 21596.599880695343, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 689688, "time": 21599.53706908226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 689720, "time": 21600.5258436203, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 689744, "time": 21601.479780197144, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21610.336466550827, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 21611.21289753914, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 690040, "time": 21611.528344154358, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 690040, "time": 21611.685308933258, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 690040, "time": 21612.318559885025, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 690040, "time": 21612.520807504654, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 690040, "time": 21612.54626107216, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 690040, "time": 21613.46130132675, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 690040, "time": 21614.28298306465, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 690224, "time": 21620.073732614517, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 690344, "time": 21623.487755298615, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 690368, "time": 21624.457441091537, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 690776, "time": 21636.718261003494, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 690792, "time": 21637.210391283035, "episode/length": 233.0, "episode/score": 0.2718749940395355, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.0}
{"step": 690904, "time": 21640.608589172363, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 691016, "time": 21644.006739854813, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691240, "time": 21650.794591903687, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 691288, "time": 21652.240796089172, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 691672, "time": 21663.93861746788, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 691728, "time": 21665.86102414131, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 691760, "time": 21666.913323163986, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 691848, "time": 21669.36660552025, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 692136, "time": 21678.142800807953, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 692136, "time": 21678.149094820023, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 692344, "time": 21684.485563516617, "episode/length": 25.0, "episode/score": 0.921875, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.0}
{"step": 692464, "time": 21688.370858192444, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 692568, "time": 21691.30887389183, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 692656, "time": 21694.243228435516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 692880, "time": 21701.143518447876, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 692896, "time": 21701.634636878967, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 692952, "time": 21703.13053536415, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 693088, "time": 21707.49099802971, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 693104, "time": 21707.980283260345, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 693416, "time": 21717.286667346954, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 693656, "time": 21724.56803560257, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 693664, "time": 21725.037237644196, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 693808, "time": 21729.50588464737, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 693832, "time": 21730.018013715744, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 693864, "time": 21730.994486808777, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 694144, "time": 21739.729865550995, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 694304, "time": 21744.589938163757, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 694400, "time": 21747.51937675476, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 694464, "time": 21749.46271920204, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 694488, "time": 21749.970894813538, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 694616, "time": 21753.878422260284, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 694832, "time": 21760.820104122162, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 695016, "time": 21766.188524007797, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 695048, "time": 21767.162904262543, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 695360, "time": 21776.92803835869, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 695592, "time": 21783.755700826645, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 695656, "time": 21785.725225687027, "episode/length": 227.0, "episode/score": 0.2906250059604645, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0}
{"step": 695728, "time": 21788.1991815567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 695808, "time": 21790.648889541626, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 695816, "time": 21790.67694926262, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 695856, "time": 21792.124752283096, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 696432, "time": 21810.051514148712, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 696456, "time": 21810.5565867424, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 696616, "time": 21815.4012260437, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 696648, "time": 21816.46326994896, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 696992, "time": 21827.16325044632, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 697072, "time": 21829.600662469864, "episode/length": 256.0, "episode/score": 0.20000000298023224, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.0}
{"step": 697496, "time": 21842.289340257645, "episode/length": 209.0, "episode/score": 0.34687501192092896, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0}
{"step": 697576, "time": 21844.74123454094, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 697728, "time": 21849.6248626709, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 698040, "time": 21858.891429185867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698056, "time": 21859.381334781647, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 698168, "time": 21862.777344226837, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 698184, "time": 21863.273470640182, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 698232, "time": 21864.751975297928, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 698240, "time": 21865.223197460175, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 698344, "time": 21868.15226173401, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 698376, "time": 21869.1535384655, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 698528, "time": 21874.003828287125, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 698696, "time": 21878.93225288391, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 698912, "time": 21885.694571971893, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 698928, "time": 21886.18392920494, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 699064, "time": 21890.213442087173, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 699320, "time": 21897.99981403351, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 699384, "time": 21899.94901418686, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 699504, "time": 21903.82163476944, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 699600, "time": 21906.869787216187, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 699728, "time": 21910.782499551773, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 699944, "time": 21917.150359153748, "episode/length": 219.0, "episode/score": 0.31562501192092896, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 21921.060598134995, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 700024, "time": 21921.247761011124, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 700024, "time": 21921.291048049927, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 700024, "time": 21922.173732995987, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 700024, "time": 21922.3410718441, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 700024, "time": 21922.54225540161, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 700024, "time": 21923.955384731293, "eval_episode/length": 155.0, "eval_episode/score": 0.515625, "eval_episode/reward_rate": 0.00641025641025641}
{"step": 700024, "time": 21924.534237384796, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 700096, "time": 21926.925196647644, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 700192, "time": 21929.854693889618, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 700272, "time": 21932.288142204285, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 700304, "time": 21933.263880252838, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 700968, "time": 21953.333646059036, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 701080, "time": 21956.747636556625, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 701224, "time": 21961.10576891899, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701264, "time": 21962.550010442734, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 701816, "time": 21979.198033809662, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 701872, "time": 21981.139911174774, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 701984, "time": 21984.525152921677, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 702040, "time": 21986.022406578064, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702176, "time": 21990.37599158287, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 702464, "time": 21999.30403161049, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 702504, "time": 22000.296226501465, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702552, "time": 22001.763123989105, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 702584, "time": 22002.741260051727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 702712, "time": 22006.63331246376, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 702792, "time": 22009.05464911461, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 702912, "time": 22012.93073630333, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 703280, "time": 22024.12652039528, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 703408, "time": 22028.12610554695, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 703536, "time": 22032.02024412155, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 703584, "time": 22033.47603225708, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 703584, "time": 22033.481749773026, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 703720, "time": 22037.397349596024, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 703864, "time": 22041.77053284645, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 703920, "time": 22043.681702136993, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 703952, "time": 22044.67787027359, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 704088, "time": 22048.57469892502, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 704480, "time": 22060.780426502228, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 704520, "time": 22061.965567350388, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 704560, "time": 22063.69210410118, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 704888, "time": 22073.44129872322, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 705320, "time": 22086.680960416794, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 705328, "time": 22087.151235818863, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 705720, "time": 22098.93288087845, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 705736, "time": 22099.423104524612, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 705832, "time": 22102.357263803482, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 705872, "time": 22103.81338429451, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 705896, "time": 22104.323235034943, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706232, "time": 22114.53392291069, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706368, "time": 22118.967477083206, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 706400, "time": 22119.933367729187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 706464, "time": 22121.863857984543, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 706544, "time": 22124.291172027588, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 706688, "time": 22128.642515182495, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 706752, "time": 22130.585297107697, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 706880, "time": 22134.473202466965, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 706952, "time": 22136.425074100494, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 706960, "time": 22136.89329123497, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 707088, "time": 22140.77624821663, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 707200, "time": 22144.170542240143, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 707208, "time": 22144.19776749611, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 707232, "time": 22145.144285917282, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 707608, "time": 22156.389843940735, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 707672, "time": 22158.352063894272, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 707728, "time": 22160.282359838486, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 707904, "time": 22165.627037763596, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 708000, "time": 22168.55388045311, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 708128, "time": 22172.426939487457, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 708400, "time": 22180.752818346024, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 708456, "time": 22182.25551176071, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 708856, "time": 22194.384554862976, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 708872, "time": 22194.87874364853, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 709072, "time": 22201.162986278534, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 709144, "time": 22203.12220978737, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 709264, "time": 22207.075617551804, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 709272, "time": 22207.104907989502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709344, "time": 22209.50885105133, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 709536, "time": 22215.338794708252, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 709593, "time": 22217.83221888542, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3725909242535583, "train/action_min": 0.0, "train/action_std": 1.8282940848038929, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.019529696896275744, "train/actor_opt_grad_steps": 43245.0, "train/actor_opt_loss": -16.4787782170985, "train/adv_mag": 1.1529460522798027, "train/adv_max": 0.4022677245706615, "train/adv_mean": 0.0010759884601899859, "train/adv_min": -1.1058813997424475, "train/adv_std": 0.04991108599109667, "train/cont_avg": 0.9945273824257426, "train/cont_loss_mean": 0.01893772472083421, "train/cont_loss_std": 0.2445641031285914, "train/cont_neg_acc": 0.2949296780815809, "train/cont_neg_loss": 2.717977410790944, "train/cont_pos_acc": 0.9998200385287257, "train/cont_pos_loss": 0.00396261058372012, "train/cont_pred": 0.9946153063585262, "train/cont_rate": 0.9945273824257426, "train/dyn_loss_mean": 1.000007465924367, "train/dyn_loss_std": 0.00023705777965744238, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.23854466011323552, "train/extr_critic_critic_opt_grad_steps": 43245.0, "train/extr_critic_critic_opt_loss": 5183.500549920715, "train/extr_critic_mag": 1.6843971993663522, "train/extr_critic_max": 1.6843971993663522, "train/extr_critic_mean": 1.5568520739527032, "train/extr_critic_min": 1.4378912212825057, "train/extr_critic_std": 0.025379832446722702, "train/extr_return_normed_mag": 1.1364146400206159, "train/extr_return_normed_max": 0.4608049734984294, "train/extr_return_normed_mean": 0.05181027492416082, "train/extr_return_normed_min": -1.0518612442630353, "train/extr_return_normed_std": 0.05776105885679769, "train/extr_return_rate": 0.9994734029958744, "train/extr_return_raw_mag": 1.9669225788352513, "train/extr_return_raw_max": 1.9669225788352513, "train/extr_return_raw_mean": 1.557927952544524, "train/extr_return_raw_min": 0.4542563610737867, "train/extr_return_raw_std": 0.057761058967449874, "train/extr_reward_mag": 0.432004182055445, "train/extr_reward_max": 0.432004182055445, "train/extr_reward_mean": 0.0029281069228361076, "train/extr_reward_min": 1.6406030938176824e-07, "train/extr_reward_std": 0.01563016024860784, "train/image_loss_mean": 0.09077289353797932, "train/image_loss_std": 0.10306740286621717, "train/model_loss_mean": 0.7255543856927664, "train/model_loss_std": 0.4762299879647718, "train/model_opt_grad_norm": 21.184398703055805, "train/model_opt_grad_steps": 43207.5495049505, "train/model_opt_loss": 3584.020887318224, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4950.495049504951, "train/policy_entropy_mag": 1.3403329813834464, "train/policy_entropy_max": 1.3403329813834464, "train/policy_entropy_mean": 0.11009873420295149, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.14365747095187112, "train/policy_logprob_mag": 6.551080257585733, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.110019404293582, "train/policy_logprob_min": -6.551080257585733, "train/policy_logprob_std": 0.6466432910154362, "train/policy_randomness_mag": 0.6887949395297778, "train/policy_randomness_max": 0.6887949395297778, "train/policy_randomness_mean": 0.056579559266862305, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07382534023853812, "train/post_ent_mag": 23.784401912500364, "train/post_ent_max": 23.784401912500364, "train/post_ent_mean": 23.354504075380834, "train/post_ent_min": 23.04097349336832, "train/post_ent_std": 0.14962068679604199, "train/prior_ent_mag": 23.745188920804768, "train/prior_ent_max": 23.745188920804768, "train/prior_ent_mean": 22.1315500334938, "train/prior_ent_min": 21.16131604071891, "train/prior_ent_std": 0.3926690521806774, "train/rep_loss_mean": 1.000007465924367, "train/rep_loss_std": 0.00023705777965744238, "train/reward_avg": 0.002129401782764431, "train/reward_loss_mean": 0.015839266475511364, "train/reward_loss_std": 0.23094060387010548, "train/reward_max_data": 0.7502939372812167, "train/reward_max_pred": 0.2474400265382068, "train/reward_neg_acc": 0.9995536898622418, "train/reward_neg_loss": 0.0027311379637449318, "train/reward_pos_acc": 0.1610321631918403, "train/reward_pos_loss": 4.145737613370906, "train/reward_pred": 0.0016259337771951342, "train/reward_rate": 0.003171410891089109, "train_stats/mean_log_entropy": 0.09079544133309161, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.014663228765130043, "report/cont_loss_std": 0.19147635996341705, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 1.8662879467010498, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037499202881008387, "report/cont_pred": 0.9939735531806946, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0997447520494461, "report/image_loss_std": 0.11522030085325241, "report/model_loss_mean": 0.7260435223579407, "report/model_loss_std": 0.38035207986831665, "report/post_ent_mag": 23.875293731689453, "report/post_ent_max": 23.875293731689453, "report/post_ent_mean": 23.43294906616211, "report/post_ent_min": 23.12567901611328, "report/post_ent_std": 0.15334594249725342, "report/prior_ent_mag": 24.0601806640625, "report/prior_ent_max": 24.0601806640625, "report/prior_ent_mean": 22.661949157714844, "report/prior_ent_min": 21.363788604736328, "report/prior_ent_std": 0.3906814754009247, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0021240233909338713, "report/reward_loss_mean": 0.011635515838861465, "report/reward_loss_std": 0.1839473396539688, "report/reward_max_data": 0.800000011920929, "report/reward_max_pred": 0.1811290979385376, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.002344520529732108, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.173671245574951, "report/reward_pred": 0.0014639438595622778, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03133585304021835, "eval/cont_loss_std": 0.5772170424461365, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.7701416015625, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002720360178500414, "eval/cont_pred": 0.9972903728485107, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1702096164226532, "eval/image_loss_std": 0.1483636200428009, "eval/model_loss_mean": 0.808435320854187, "eval/model_loss_std": 0.6560700535774231, "eval/post_ent_mag": 23.863908767700195, "eval/post_ent_max": 23.863908767700195, "eval/post_ent_mean": 23.41873550415039, "eval/post_ent_min": 23.109569549560547, "eval/post_ent_std": 0.15748128294944763, "eval/prior_ent_mag": 24.0601806640625, "eval/prior_ent_max": 24.0601806640625, "eval/prior_ent_mean": 22.650236129760742, "eval/prior_ent_min": 21.65986442565918, "eval/prior_ent_std": 0.4048745036125183, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005065918085165322, "eval/reward_loss_mean": 0.006889823824167252, "eval/reward_loss_std": 0.1680424064397812, "eval/reward_max_data": 0.518750011920929, "eval/reward_max_pred": 0.028809785842895508, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001639174995943904, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.378303527832031, "eval/reward_pred": 0.0008463968988507986, "eval/reward_rate": 0.0009765625, "replay/size": 709089.0, "replay/inserts": 32240.0, "replay/samples": 32240.0, "replay/insert_wait_avg": 1.3484922295468616e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.477203018907874e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1479649932599375e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9821619987488, "timer/env.step_count": 4030.0, "timer/env.step_total": 38.09805083274841, "timer/env.step_frac": 0.03809873043794963, "timer/env.step_avg": 0.009453610628473552, "timer/env.step_min": 0.0075795650482177734, "timer/env.step_max": 0.05212759971618652, "timer/replay._sample_count": 32240.0, "timer/replay._sample_total": 16.21261215209961, "timer/replay._sample_frac": 0.016212901357854317, "timer/replay._sample_avg": 0.0005028725853628911, "timer/replay._sample_min": 0.0004112720489501953, "timer/replay._sample_max": 0.011053323745727539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4729.0, "timer/agent.policy_total": 49.054121017456055, "timer/agent.policy_frac": 0.04905499606053716, "timer/agent.policy_avg": 0.01037304314177544, "timer/agent.policy_min": 0.00843358039855957, "timer/agent.policy_max": 0.08660507202148438, "timer/dataset_train_count": 2015.0, "timer/dataset_train_total": 0.20741891860961914, "timer/dataset_train_frac": 0.00020742261861454953, "timer/dataset_train_avg": 0.00010293742859038171, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0005764961242675781, "timer/agent.train_count": 2015.0, "timer/agent.train_total": 900.416033744812, "timer/agent.train_frac": 0.9004320956536609, "timer/agent.train_avg": 0.4468565924291871, "timer/agent.train_min": 0.4345834255218506, "timer/agent.train_max": 0.7081403732299805, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47705793380737305, "timer/agent.report_frac": 0.000477066443719193, "timer/agent.report_avg": 0.23852896690368652, "timer/agent.report_min": 0.2316112518310547, "timer/agent.report_max": 0.24544668197631836, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6941780025982375e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 32.23997992257415}
{"step": 709648, "time": 22219.497306585312, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 709704, "time": 22220.985756397247, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 709920, "time": 22227.80967926979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 709936, "time": 22228.30577635765, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 22231.08593249321, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 710008, "time": 22231.803129196167, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 710008, "time": 22232.3093187809, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 710008, "time": 22232.754321098328, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 710008, "time": 22232.798004627228, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 710008, "time": 22232.939266204834, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 710008, "time": 22233.269701480865, "eval_episode/length": 146.0, "eval_episode/score": 0.543749988079071, "eval_episode/reward_rate": 0.006802721088435374}
{"step": 710008, "time": 22233.8346555233, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 710256, "time": 22241.688436985016, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 710496, "time": 22248.981080770493, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 710544, "time": 22250.463562250137, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 710584, "time": 22251.461146831512, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 710624, "time": 22252.899542093277, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 710880, "time": 22260.65616750717, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 711104, "time": 22267.595317840576, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 711184, "time": 22270.04988837242, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 711232, "time": 22271.50069975853, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 711376, "time": 22275.89121246338, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 711632, "time": 22283.674194574356, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 711632, "time": 22283.67981004715, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 711936, "time": 22292.871967315674, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 712008, "time": 22294.85468673706, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 712064, "time": 22296.864575862885, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 712232, "time": 22301.7616751194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712568, "time": 22311.96820783615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 712592, "time": 22312.936586380005, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 712600, "time": 22312.96305990219, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 712648, "time": 22314.42035627365, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 712832, "time": 22320.704315662384, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 712904, "time": 22322.655431509018, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 713392, "time": 22337.962596178055, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 713496, "time": 22340.907653093338, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 713504, "time": 22341.37775039673, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 713584, "time": 22343.83004617691, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 713632, "time": 22345.289670228958, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 713712, "time": 22347.723138332367, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 713880, "time": 22352.60852599144, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 713976, "time": 22355.517094373703, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 714000, "time": 22356.55111837387, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 714264, "time": 22364.372389554977, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 714304, "time": 22365.805606365204, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 714344, "time": 22366.80739402771, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 714752, "time": 22379.424544095993, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 714952, "time": 22385.291551828384, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 714984, "time": 22386.341292619705, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 715144, "time": 22391.218764781952, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 715192, "time": 22392.70086622238, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 715272, "time": 22395.123405456543, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 715336, "time": 22397.081703662872, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 715552, "time": 22403.839018583298, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 715656, "time": 22406.76833677292, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 715776, "time": 22410.604258060455, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 715896, "time": 22414.024688005447, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 716080, "time": 22419.913621902466, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 716136, "time": 22421.418073892593, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 716160, "time": 22422.379282712936, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 716384, "time": 22429.18958592415, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 716504, "time": 22432.648985147476, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 716512, "time": 22433.118385076523, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 716704, "time": 22438.940319299698, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 716744, "time": 22439.926960229874, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 717008, "time": 22448.223992586136, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 717040, "time": 22449.193295955658, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 717264, "time": 22456.00831079483, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 717456, "time": 22461.846552610397, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 717616, "time": 22466.703699827194, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 717624, "time": 22466.73072886467, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 717736, "time": 22470.141446828842, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 717816, "time": 22472.561230421066, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 717816, "time": 22472.56612277031, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 718088, "time": 22480.877063035965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718104, "time": 22481.364677906036, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 718176, "time": 22483.7720079422, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 718216, "time": 22484.774678468704, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 718392, "time": 22490.120223999023, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 718392, "time": 22490.127261400223, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 718456, "time": 22492.074023485184, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 718568, "time": 22495.47851061821, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 718728, "time": 22500.317002773285, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 719000, "time": 22508.680911779404, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 719048, "time": 22510.13769721985, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 719168, "time": 22513.994488477707, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 719184, "time": 22514.482449769974, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 719336, "time": 22518.89444708824, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 719704, "time": 22530.085869073868, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 719824, "time": 22533.974521636963, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 719960, "time": 22537.972878217697, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 720024, "time": 22539.919569015503, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 22542.862270355225, "eval_episode/length": 25.0, "eval_episode/score": 0.921875, "eval_episode/reward_rate": 0.038461538461538464}
{"step": 720096, "time": 22543.28574180603, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 720096, "time": 22543.38560962677, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 720096, "time": 22543.50693464279, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 720096, "time": 22543.512338638306, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 720096, "time": 22544.012278079987, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 720096, "time": 22544.137189865112, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 720096, "time": 22545.203503847122, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 720240, "time": 22549.60746240616, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 720344, "time": 22552.54988217354, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 720432, "time": 22555.454481124878, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 720760, "time": 22565.21966433525, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 720768, "time": 22565.694145917892, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720880, "time": 22569.190702199936, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 720968, "time": 22572.146473169327, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 721264, "time": 22581.358432769775, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 721296, "time": 22582.336745023727, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 721312, "time": 22582.830617427826, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721360, "time": 22584.28441095352, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 721632, "time": 22592.571947336197, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 721760, "time": 22596.562433242798, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 722128, "time": 22607.738652706146, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 722216, "time": 22610.19984292984, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 722288, "time": 22612.616252422333, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 722376, "time": 22615.07247209549, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 722400, "time": 22616.033161640167, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 722976, "time": 22633.656491279602, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 722984, "time": 22633.683599472046, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 723048, "time": 22635.64619898796, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 723080, "time": 22636.61818242073, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723480, "time": 22648.79017186165, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 723496, "time": 22649.278632879257, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 723672, "time": 22654.623994350433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 723808, "time": 22659.13015770912, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 723896, "time": 22661.57716679573, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 723944, "time": 22663.04309487343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 724488, "time": 22679.578051805496, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 724664, "time": 22684.927088737488, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 724760, "time": 22687.953451871872, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 724784, "time": 22688.906823396683, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 724856, "time": 22690.878652572632, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 725360, "time": 22706.384765148163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725392, "time": 22707.37396788597, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 725472, "time": 22709.799124002457, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 725600, "time": 22713.69845843315, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 725664, "time": 22715.629615306854, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 725704, "time": 22716.721694469452, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 725840, "time": 22721.055688381195, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 726048, "time": 22727.38076210022, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 726120, "time": 22729.34974384308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 726256, "time": 22733.698130369186, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 726536, "time": 22741.965193748474, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 726920, "time": 22753.693417072296, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 726976, "time": 22755.62268257141, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727008, "time": 22756.61623954773, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 727096, "time": 22759.065275907516, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 727280, "time": 22764.848048448563, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 727360, "time": 22767.29039955139, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 727776, "time": 22779.99557185173, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 727784, "time": 22780.022993803024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 727880, "time": 22782.946154117584, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 728152, "time": 22791.250880241394, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 728200, "time": 22792.698348760605, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 728248, "time": 22794.15029144287, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 728360, "time": 22797.55527615547, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 728448, "time": 22800.44477534294, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 728616, "time": 22805.31693315506, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 728712, "time": 22808.32543683052, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 728760, "time": 22809.790220975876, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 728936, "time": 22815.13503050804, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 728968, "time": 22816.114755153656, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 729024, "time": 22818.037484169006, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 729320, "time": 22827.26803970337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 729424, "time": 22830.657750844955, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 729488, "time": 22832.605890989304, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 729600, "time": 22836.11474251747, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 729696, "time": 22839.02024269104, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 729752, "time": 22840.506345510483, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 22851.74326324463, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 730080, "time": 22852.113042593002, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 730080, "time": 22852.192262887955, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 730080, "time": 22852.29148697853, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 730080, "time": 22852.862575292587, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 730080, "time": 22854.170684337616, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 730080, "time": 22854.250244379044, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 730080, "time": 22854.381261348724, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 730216, "time": 22858.282247066498, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 730248, "time": 22859.248858690262, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 730248, "time": 22859.254548311234, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 730344, "time": 22862.154098033905, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 730672, "time": 22872.47060084343, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 730816, "time": 22876.814615011215, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 731232, "time": 22889.45726442337, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 731336, "time": 22892.40858411789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731680, "time": 22903.18155837059, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 731912, "time": 22910.032302856445, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 731928, "time": 22910.522813796997, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 732008, "time": 22912.966795682907, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732344, "time": 22923.193362236023, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 732560, "time": 22930.081747293472, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732640, "time": 22932.519462823868, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 732656, "time": 22933.00977563858, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 732800, "time": 22937.394978761673, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 732952, "time": 22941.813097953796, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 732984, "time": 22942.789472579956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 733696, "time": 22964.709249973297, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 733992, "time": 22973.49134373665, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734160, "time": 22978.81137394905, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 734584, "time": 22991.55761861801, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 734608, "time": 22992.5079805851, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 734656, "time": 22993.96413421631, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734872, "time": 23000.29499936104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 734952, "time": 23002.727336406708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735088, "time": 23007.080451726913, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 735112, "time": 23007.5944917202, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735264, "time": 23012.435656785965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 735408, "time": 23016.902297496796, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 735544, "time": 23020.80774283409, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 736040, "time": 23035.96047091484, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 736304, "time": 23044.233376026154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 736768, "time": 23058.35829257965, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 736920, "time": 23062.781263828278, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 736920, "time": 23062.788982868195, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737096, "time": 23068.13739132881, "episode/length": 267.0, "episode/score": 0.16562500596046448, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.0}
{"step": 737328, "time": 23075.935087442398, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 737400, "time": 23077.98735642433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 737720, "time": 23087.711455106735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738016, "time": 23096.926008224487, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 738040, "time": 23097.45397877693, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 738088, "time": 23098.913275003433, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 738352, "time": 23107.227463006973, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 738520, "time": 23112.11151599884, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 738536, "time": 23112.59862136841, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 738872, "time": 23122.80406665802, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 739232, "time": 23134.016579151154, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739232, "time": 23134.023587226868, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739712, "time": 23148.693804740906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 739744, "time": 23149.670466661453, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 740008, "time": 23157.486718177795, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 23160.7204144001, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 740064, "time": 23160.74481368065, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 740064, "time": 23160.896790981293, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 740064, "time": 23160.937469244003, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 740064, "time": 23160.98051762581, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 740064, "time": 23162.464708328247, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 740064, "time": 23162.60379767418, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 740064, "time": 23162.66650557518, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 740208, "time": 23167.169188261032, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 740328, "time": 23170.588800668716, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740416, "time": 23173.476880550385, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 740664, "time": 23180.81470990181, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740832, "time": 23186.14640045166, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 740896, "time": 23188.084697008133, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 740936, "time": 23189.095771312714, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 741040, "time": 23192.46458363533, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 741184, "time": 23196.9495780468, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 741248, "time": 23198.915476083755, "episode/length": 187.0, "episode/score": 0.4156250059604645, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.0}
{"step": 741256, "time": 23198.941776752472, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 741448, "time": 23204.77304005623, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 741456, "time": 23205.24659562111, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 741584, "time": 23209.173606157303, "episode/length": 196.0, "episode/score": 0.38749998807907104, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.0}
{"step": 741849, "time": 23217.9508061409, "train_stats/mean_log_entropy": 0.08223181110027149, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.292208695293066, "train/action_min": 0.0, "train/action_std": 1.7691098605815452, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.017017752293552926, "train/actor_opt_grad_steps": 45260.0, "train/actor_opt_loss": -16.34226615104213, "train/adv_mag": 1.1689090681313283, "train/adv_max": 0.31902489199567197, "train/adv_mean": 0.0006401620045026061, "train/adv_min": -1.1353542656447757, "train/adv_std": 0.04031828424860885, "train/cont_avg": 0.9947187888681592, "train/cont_loss_mean": 0.018006985831023448, "train/cont_loss_std": 0.23050432977502916, "train/cont_neg_acc": 0.28549999436039236, "train/cont_neg_loss": 2.6346993200221465, "train/cont_pos_acc": 0.999814413080168, "train/cont_pos_loss": 0.004006817583597048, "train/cont_pred": 0.9946080194183843, "train/cont_rate": 0.9947187888681592, "train/dyn_loss_mean": 1.000000155387233, "train/dyn_loss_std": 4.9669619311407135e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.24089511346757708, "train/extr_critic_critic_opt_grad_steps": 45260.0, "train/extr_critic_critic_opt_loss": 4477.768193942397, "train/extr_critic_mag": 1.672357036106622, "train/extr_critic_max": 1.672357036106622, "train/extr_critic_mean": 1.5657398635475197, "train/extr_critic_min": 1.4471659043535072, "train/extr_critic_std": 0.024758673912442443, "train/extr_return_normed_mag": 1.1629723832381897, "train/extr_return_normed_max": 0.3708077182817222, "train/extr_return_normed_mean": 0.049974508838385195, "train/extr_return_normed_min": -1.099074555273673, "train/extr_return_normed_std": 0.04904953055825103, "train/extr_return_rate": 0.9994620405026337, "train/extr_return_raw_mag": 1.8872130249270158, "train/extr_return_raw_max": 1.8872130249270158, "train/extr_return_raw_mean": 1.5663798899199832, "train/extr_return_raw_min": 0.4173307513716209, "train/extr_return_raw_std": 0.049049530595318594, "train/extr_reward_mag": 0.34675988036008615, "train/extr_reward_max": 0.34675988036008615, "train/extr_reward_mean": 0.0025521450483735964, "train/extr_reward_min": 1.0438226348725125e-07, "train/extr_reward_std": 0.010924900373425427, "train/image_loss_mean": 0.09030718378611464, "train/image_loss_std": 0.10293427951152052, "train/model_loss_mean": 0.723785344641007, "train/model_loss_std": 0.4603772612650003, "train/model_opt_grad_norm": 20.408580446243285, "train/model_opt_grad_steps": 45220.59701492537, "train/model_opt_loss": 3654.122654549518, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5024.875621890547, "train/policy_entropy_mag": 1.3228920431279425, "train/policy_entropy_max": 1.3228920431279425, "train/policy_entropy_mean": 0.10642435427625381, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.13627459898368635, "train/policy_logprob_mag": 6.551080295695594, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10660106514520314, "train/policy_logprob_min": -6.551080295695594, "train/policy_logprob_std": 0.6439034757922538, "train/policy_randomness_mag": 0.6798320691383893, "train/policy_randomness_max": 0.6798320691383893, "train/policy_randomness_mean": 0.05469130166801647, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.07003129407096265, "train/post_ent_mag": 23.689386576562377, "train/post_ent_max": 23.689386576562377, "train/post_ent_mean": 23.254071676909035, "train/post_ent_min": 22.932138053932, "train/post_ent_std": 0.15385035488439436, "train/prior_ent_mag": 24.08087838585697, "train/prior_ent_max": 24.08087838585697, "train/prior_ent_mean": 22.34708960613801, "train/prior_ent_min": 21.14355837883641, "train/prior_ent_std": 0.4422923953675512, "train/rep_loss_mean": 1.000000155387233, "train/rep_loss_std": 4.9669619311407135e-06, "train/reward_avg": 0.0020918205733160807, "train/reward_loss_mean": 0.01547105598902858, "train/reward_loss_std": 0.22512658859199997, "train/reward_max_data": 0.7608986336793473, "train/reward_max_pred": 0.2687125757559022, "train/reward_neg_acc": 0.9995418084201528, "train/reward_neg_loss": 0.0028910654850665537, "train/reward_pos_acc": 0.19906725765196318, "train/reward_pos_loss": 4.012581502653889, "train/reward_pred": 0.0017038897462930548, "train/reward_rate": 0.003099735696517413, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.03516171872615814, "report/cont_loss_std": 0.3721684515476227, "report/cont_neg_acc": 0.1111111119389534, "report/cont_neg_loss": 3.406989336013794, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00526373740285635, "report/cont_pred": 0.9934731125831604, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09071657061576843, "report/image_loss_std": 0.11544784158468246, "report/model_loss_mean": 0.7437252998352051, "report/model_loss_std": 0.5471512675285339, "report/post_ent_mag": 23.443225860595703, "report/post_ent_max": 23.443225860595703, "report/post_ent_mean": 23.025657653808594, "report/post_ent_min": 22.732492446899414, "report/post_ent_std": 0.16323667764663696, "report/prior_ent_mag": 24.12655258178711, "report/prior_ent_max": 24.12655258178711, "report/prior_ent_mean": 22.075546264648438, "report/prior_ent_min": 20.478668212890625, "report/prior_ent_std": 0.5191442370414734, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023254393599927425, "report/reward_loss_mean": 0.017846960574388504, "report/reward_loss_std": 0.24021314084529877, "report/reward_max_data": 0.8343750238418579, "report/reward_max_pred": 0.21194612979888916, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0033239955082535744, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.721203327178955, "report/reward_pred": 0.00198534457013011, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.013352100737392902, "eval/cont_loss_std": 0.22909004986286163, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.158830642700195, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00328267109580338, "eval/cont_pred": 0.9968089461326599, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13224223256111145, "eval/image_loss_std": 0.13253122568130493, "eval/model_loss_mean": 0.7599164843559265, "eval/model_loss_std": 0.5560888648033142, "eval/post_ent_mag": 23.439762115478516, "eval/post_ent_max": 23.439762115478516, "eval/post_ent_mean": 22.972240447998047, "eval/post_ent_min": 22.66645050048828, "eval/post_ent_std": 0.14801958203315735, "eval/prior_ent_mag": 24.12655258178711, "eval/prior_ent_max": 24.12655258178711, "eval/prior_ent_mean": 22.023672103881836, "eval/prior_ent_min": 20.567302703857422, "eval/prior_ent_std": 0.4964127838611603, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012878417037427425, "eval/reward_loss_mean": 0.014322109520435333, "eval/reward_loss_std": 0.29039350152015686, "eval/reward_max_data": 0.7437499761581421, "eval/reward_max_pred": 0.10412287712097168, "eval/reward_neg_acc": 0.9990215301513672, "eval/reward_neg_loss": 0.0015002958243712783, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.5662689208984375, "eval/reward_pred": 0.0007507181726396084, "eval/reward_rate": 0.001953125, "replay/size": 741345.0, "replay/inserts": 32256.0, "replay/samples": 32256.0, "replay/insert_wait_avg": 1.3487620486153496e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.460632967570471e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5344.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1602383173868329e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1046347618103, "timer/env.step_count": 4032.0, "timer/env.step_total": 37.93791198730469, "timer/env.step_frac": 0.03793394277823756, "timer/env.step_avg": 0.009409204361930726, "timer/env.step_min": 0.007691144943237305, "timer/env.step_max": 0.035118818283081055, "timer/replay._sample_count": 32256.0, "timer/replay._sample_total": 16.184760570526123, "timer/replay._sample_frac": 0.016183067259138102, "timer/replay._sample_avg": 0.0005017596903064894, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.011081218719482422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4700.0, "timer/agent.policy_total": 48.88971161842346, "timer/agent.policy_frac": 0.048884596590303045, "timer/agent.policy_avg": 0.010402066301792226, "timer/agent.policy_min": 0.008862018585205078, "timer/agent.policy_max": 0.08642125129699707, "timer/dataset_train_count": 2016.0, "timer/dataset_train_total": 0.20733046531677246, "timer/dataset_train_frac": 0.0002073087736126243, "timer/dataset_train_avg": 0.000102842492716653, "timer/dataset_train_min": 8.678436279296875e-05, "timer/dataset_train_max": 0.0005414485931396484, "timer/agent.train_count": 2016.0, "timer/agent.train_total": 901.0087521076202, "timer/agent.train_frac": 0.9009144851350567, "timer/agent.train_avg": 0.4469289444978275, "timer/agent.train_min": 0.4369056224822998, "timer/agent.train_max": 0.6943292617797852, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779815673828125, "timer/agent.report_frac": 0.0004779315591279615, "timer/agent.report_avg": 0.23899078369140625, "timer/agent.report_min": 0.23160243034362793, "timer/agent.report_max": 0.24637913703918457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956081072020512e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 32.25207216072747}
{"step": 742192, "time": 23228.408332824707, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 742224, "time": 23229.368824005127, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 742344, "time": 23232.777934789658, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 742384, "time": 23234.221338748932, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 742608, "time": 23240.99072408676, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 742696, "time": 23243.430032014847, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 742856, "time": 23248.255108594894, "episode/length": 199.0, "episode/score": 0.37812501192092896, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.0}
{"step": 742856, "time": 23248.2628698349, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 743240, "time": 23259.970329761505, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 743312, "time": 23262.388050556183, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 743352, "time": 23263.3700196743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743392, "time": 23264.802221536636, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 743560, "time": 23269.65965437889, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 743624, "time": 23271.58739066124, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 743688, "time": 23273.543924331665, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 743712, "time": 23274.48809862137, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 743768, "time": 23275.95445036888, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 743768, "time": 23275.96142721176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 743896, "time": 23279.84587597847, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 744416, "time": 23295.914368391037, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 744424, "time": 23295.942230463028, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 744504, "time": 23298.385727643967, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 744528, "time": 23299.341668605804, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 744560, "time": 23300.321831464767, "episode/length": 17.0, "episode/score": 0.9468749761581421, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.0}
{"step": 744816, "time": 23308.105834007263, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 744840, "time": 23308.612760305405, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 745136, "time": 23317.910218715668, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 745320, "time": 23323.23502421379, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 745440, "time": 23327.10146665573, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 745808, "time": 23338.73353075981, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 746024, "time": 23345.048402309418, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746072, "time": 23346.629470586777, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 746080, "time": 23347.09592294693, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746168, "time": 23349.52008986473, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 746208, "time": 23350.961140155792, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 746408, "time": 23356.786276102066, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 746712, "time": 23365.95951986313, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 746736, "time": 23366.910141706467, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 746840, "time": 23369.845602035522, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 746888, "time": 23371.296026706696, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 747024, "time": 23375.617062807083, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 747056, "time": 23376.70209980011, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 747216, "time": 23381.5151116848, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 747288, "time": 23383.48339033127, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 747480, "time": 23389.315606355667, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 747728, "time": 23397.04984664917, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 747752, "time": 23397.559760332108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 747784, "time": 23398.524381637573, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 748104, "time": 23408.276068925858, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 748120, "time": 23408.78356742859, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 748168, "time": 23410.23392391205, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 748352, "time": 23416.02247095108, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 748368, "time": 23416.510573863983, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 748568, "time": 23422.345997095108, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 748608, "time": 23423.807235479355, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 748752, "time": 23428.151958942413, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 748904, "time": 23432.495989322662, "episode/length": 18.0, "episode/score": 0.9437500238418579, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.0}
{"step": 748944, "time": 23433.952555179596, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 749096, "time": 23438.424690246582, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 749160, "time": 23440.364246845245, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 749352, "time": 23446.175086975098, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 749376, "time": 23447.157470941544, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 749432, "time": 23448.673010349274, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 749448, "time": 23449.15860438347, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 749472, "time": 23450.101493120193, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 749768, "time": 23458.828521490097, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 749952, "time": 23464.598278045654, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 749976, "time": 23465.111518144608, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 23468.421218156815, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 750048, "time": 23468.819975852966, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 750048, "time": 23469.34542608261, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 750048, "time": 23469.370499134064, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 750048, "time": 23469.620692253113, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 750048, "time": 23469.852499961853, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 750048, "time": 23469.990802049637, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 750048, "time": 23469.99574804306, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 750096, "time": 23471.45211172104, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 750128, "time": 23472.415343761444, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 750392, "time": 23480.181693077087, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 750464, "time": 23482.562754631042, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 750704, "time": 23489.79873728752, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 750728, "time": 23490.304673194885, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 750792, "time": 23492.23543381691, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 751216, "time": 23505.37435078621, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751344, "time": 23509.261553287506, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 751408, "time": 23511.18896126747, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751448, "time": 23512.170562028885, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 751472, "time": 23513.13884496689, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 751640, "time": 23517.99596309662, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 751768, "time": 23521.85697555542, "episode/length": 204.0, "episode/score": 0.36250001192092896, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.0}
{"step": 751864, "time": 23524.763556957245, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 752208, "time": 23535.468728542328, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 752336, "time": 23539.346499443054, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 752392, "time": 23540.81106901169, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 752544, "time": 23545.65003299713, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 752560, "time": 23546.141536951065, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 752648, "time": 23548.60223174095, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 752840, "time": 23554.398557424545, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 752856, "time": 23554.893966197968, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 753016, "time": 23559.854932546616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 753024, "time": 23560.323840618134, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 753136, "time": 23563.74256181717, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 753736, "time": 23582.266489505768, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 754160, "time": 23595.51594901085, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 754224, "time": 23597.489734888077, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 754704, "time": 23612.08225774765, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754872, "time": 23617.0813331604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 754960, "time": 23619.95092844963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755112, "time": 23624.324390649796, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 755152, "time": 23625.787503242493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755328, "time": 23631.130650997162, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755344, "time": 23631.6184360981, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 755392, "time": 23633.062775611877, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 755448, "time": 23634.544179677963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 755536, "time": 23637.424691438675, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 755568, "time": 23638.393008232117, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 756016, "time": 23652.014890432358, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 756072, "time": 23653.4893887043, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 756136, "time": 23655.43535399437, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 756496, "time": 23666.66841864586, "episode/length": 191.0, "episode/score": 0.40312498807907104, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.0}
{"step": 756592, "time": 23669.625369548798, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 756720, "time": 23673.496169805527, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 757016, "time": 23682.309092521667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757080, "time": 23684.26837348938, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 757120, "time": 23685.69554209709, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 757248, "time": 23689.66892194748, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 757640, "time": 23701.296579360962, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757672, "time": 23702.26265358925, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 757752, "time": 23704.695108413696, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 757760, "time": 23705.165499925613, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 757808, "time": 23706.72220468521, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 758216, "time": 23719.01008248329, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 758384, "time": 23724.35769724846, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 758464, "time": 23726.78546643257, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 758576, "time": 23730.199848890305, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 758784, "time": 23736.63527083397, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 758784, "time": 23736.640821695328, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 758848, "time": 23738.611834049225, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 759032, "time": 23743.964262008667, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759272, "time": 23751.269448041916, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 759392, "time": 23755.14761543274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 759512, "time": 23758.563137292862, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 759528, "time": 23759.060104370117, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 759744, "time": 23765.897292613983, "episode/length": 190.0, "episode/score": 0.40625, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.0}
{"step": 759760, "time": 23766.45247077942, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 759760, "time": 23766.458393096924, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 759864, "time": 23769.428292751312, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 23775.888281583786, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 760032, "time": 23776.50220823288, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 760032, "time": 23776.525352716446, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 760032, "time": 23776.616480112076, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 760032, "time": 23776.895659446716, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 760032, "time": 23777.752395629883, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 760032, "time": 23777.960530519485, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 760032, "time": 23778.005564928055, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 760120, "time": 23780.461414813995, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 760528, "time": 23792.965770483017, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 760648, "time": 23796.49222755432, "episode/length": 258.0, "episode/score": 0.19374999403953552, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0}
{"step": 760704, "time": 23798.410850286484, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 760968, "time": 23806.163231611252, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 761208, "time": 23813.42498087883, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 761264, "time": 23815.35718846321, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 761384, "time": 23818.74123120308, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 761472, "time": 23821.615911245346, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 761744, "time": 23829.892899751663, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 761824, "time": 23832.320442914963, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 761832, "time": 23832.347546100616, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 762056, "time": 23839.642188310623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762176, "time": 23843.475379943848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762216, "time": 23844.49106812477, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 762432, "time": 23851.281282901764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 762472, "time": 23852.281118631363, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 762768, "time": 23861.629643201828, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 762824, "time": 23863.096391439438, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 762984, "time": 23867.937512636185, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 763024, "time": 23869.40146756172, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 763040, "time": 23869.89270591736, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 763200, "time": 23874.74573993683, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 763304, "time": 23877.676123142242, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 763568, "time": 23885.92514848709, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 763848, "time": 23894.210054159164, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 763864, "time": 23894.69833445549, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 763888, "time": 23895.655306100845, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 763968, "time": 23898.08609008789, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 763976, "time": 23898.113617181778, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 764112, "time": 23902.46862912178, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 764392, "time": 23910.734716176987, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 764560, "time": 23916.17447900772, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 764720, "time": 23921.023524045944, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 764744, "time": 23921.529800653458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 764744, "time": 23921.538271188736, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 765240, "time": 23936.565405368805, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 765600, "time": 23947.77204966545, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 766176, "time": 23965.208513259888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766200, "time": 23965.738345384598, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766280, "time": 23968.159335136414, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766384, "time": 23971.547481060028, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 766832, "time": 23985.189182281494, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 766872, "time": 23986.177419424057, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 766968, "time": 23989.108067512512, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 767032, "time": 23991.051849603653, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767056, "time": 23992.000911474228, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767112, "time": 23993.481835603714, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 767432, "time": 24003.151196479797, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 767544, "time": 24006.66888308525, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 767784, "time": 24013.931444644928, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 767912, "time": 24017.824674844742, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 767936, "time": 24018.778977394104, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 768312, "time": 24029.965043783188, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 768440, "time": 24033.844821214676, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 768528, "time": 24036.797827005386, "episode/length": 10.0, "episode/score": 0.96875, "episode/reward_rate": 0.09090909090909091, "episode/intrinsic_return": 0.0}
{"step": 768600, "time": 24038.761188030243, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 768600, "time": 24038.76648235321, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 768664, "time": 24040.700308322906, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 769064, "time": 24052.74420428276, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 769184, "time": 24056.599098205566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769192, "time": 24056.626403093338, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 769344, "time": 24061.44122505188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769552, "time": 24067.85205745697, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 769704, "time": 24072.229933023453, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 769744, "time": 24073.689199447632, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 769952, "time": 24080.01545524597, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 770000, "time": 24081.481245279312, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 24082.132398843765, "eval_episode/length": 7.0, "eval_episode/score": 0.9781249761581421, "eval_episode/reward_rate": 0.125}
{"step": 770016, "time": 24082.689730882645, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 770016, "time": 24083.07400918007, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 770016, "time": 24083.296048402786, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 770016, "time": 24083.36049389839, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 770016, "time": 24083.775850057602, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 770016, "time": 24084.74767756462, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 770016, "time": 24085.356417179108, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 770248, "time": 24092.67318534851, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 770872, "time": 24111.832208395004, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 770912, "time": 24113.26711654663, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771128, "time": 24119.590976953506, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 771376, "time": 24127.434673547745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771496, "time": 24130.880378246307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 771792, "time": 24140.16230583191, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 771872, "time": 24142.599699020386, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 771920, "time": 24144.05652308464, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 772016, "time": 24146.970066070557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772312, "time": 24155.70384812355, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772504, "time": 24161.61663222313, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 772560, "time": 24163.517270088196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 772608, "time": 24164.981082439423, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 772616, "time": 24165.008041858673, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 772856, "time": 24172.24961900711, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 773160, "time": 24181.454904556274, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 773224, "time": 24183.388476133347, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 773288, "time": 24185.353152513504, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 773288, "time": 24185.36007475853, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 773432, "time": 24189.82951450348, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 773560, "time": 24193.697821617126, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 773576, "time": 24194.188437223434, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 773920, "time": 24204.81254172325, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 773968, "time": 24206.258613824844, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 774136, "time": 24211.087319135666, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 774184, "time": 24212.53133416176, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 774288, "time": 24215.929523706436, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 774329, "time": 24217.962553977966, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3025936634082513, "train/action_min": 0.0, "train/action_std": 1.8671805418183651, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.012414293284550897, "train/actor_opt_grad_steps": 47280.0, "train/actor_opt_loss": -16.503311434402843, "train/adv_mag": 1.0101867961178859, "train/adv_max": 0.27665402560398494, "train/adv_mean": 0.0012633091449446188, "train/adv_min": -0.9579602168698617, "train/adv_std": 0.031032681868874968, "train/cont_avg": 0.9944100215517241, "train/cont_loss_mean": 0.01889749427998136, "train/cont_loss_std": 0.2384195583711924, "train/cont_neg_acc": 0.2971006744894488, "train/cont_neg_loss": 2.637090989211895, "train/cont_pos_acc": 0.9998306699574288, "train/cont_pos_loss": 0.004036948186909697, "train/cont_pred": 0.9944436943589761, "train/cont_rate": 0.9944100215517241, "train/dyn_loss_mean": 1.000000014093709, "train/dyn_loss_std": 4.5732662409745857e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.16883355311205234, "train/extr_critic_critic_opt_grad_steps": 47280.0, "train/extr_critic_critic_opt_loss": 4540.428593076509, "train/extr_critic_mag": 1.6715064318896515, "train/extr_critic_max": 1.6715064318896515, "train/extr_critic_mean": 1.5678198807345236, "train/extr_critic_min": 1.4241608163993347, "train/extr_critic_std": 0.027687483783719574, "train/extr_return_normed_mag": 1.022114429567835, "train/extr_return_normed_max": 0.31828518277905843, "train/extr_return_normed_mean": 0.05454457432875786, "train/extr_return_normed_min": -0.9308786351105263, "train/extr_return_normed_std": 0.042984824682691415, "train/extr_return_rate": 0.9996215982977392, "train/extr_return_raw_mag": 1.8328236858245774, "train/extr_return_raw_max": 1.8328236858245774, "train/extr_return_raw_mean": 1.5690831445120825, "train/extr_return_raw_min": 0.5836598679349927, "train/extr_return_raw_std": 0.04298482441659925, "train/extr_reward_mag": 0.2888999889636862, "train/extr_reward_max": 0.2888999889636862, "train/extr_reward_mean": 0.0022778001308826536, "train/extr_reward_min": 8.984739557275631e-08, "train/extr_reward_std": 0.008893329423067751, "train/image_loss_mean": 0.08802582560281448, "train/image_loss_std": 0.10156067743383605, "train/model_loss_mean": 0.7232085818727615, "train/model_loss_std": 0.478781385888607, "train/model_opt_grad_norm": 19.37237237826944, "train/model_opt_grad_steps": 47238.6157635468, "train/model_opt_loss": 3704.7188690636544, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5123.152709359606, "train/policy_entropy_mag": 1.2915665545487052, "train/policy_entropy_max": 1.2915665545487052, "train/policy_entropy_mean": 0.09846918310584693, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12416345938085922, "train/policy_logprob_mag": 6.5510802715282725, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09842054700029307, "train/policy_logprob_min": -6.5510802715282725, "train/policy_logprob_std": 0.6350563259547567, "train/policy_randomness_mag": 0.6637339506830487, "train/policy_randomness_max": 0.6637339506830487, "train/policy_randomness_mean": 0.05060315196370256, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06380739965902761, "train/post_ent_mag": 23.431209874270586, "train/post_ent_max": 23.431209874270586, "train/post_ent_mean": 22.995185354073058, "train/post_ent_min": 22.6807734484743, "train/post_ent_std": 0.15366388622469504, "train/prior_ent_mag": 24.783595287153872, "train/prior_ent_max": 24.783595287153872, "train/prior_ent_mean": 22.79080313884566, "train/prior_ent_min": 21.525907704395614, "train/prior_ent_std": 0.4760272168173579, "train/rep_loss_mean": 1.000000014093709, "train/rep_loss_std": 4.5732662409745857e-07, "train/reward_avg": 0.0021645231186779297, "train/reward_loss_mean": 0.016285230358603773, "train/reward_loss_std": 0.2379150144765016, "train/reward_max_data": 0.7667179809415282, "train/reward_max_pred": 0.267891414059794, "train/reward_neg_acc": 0.9995511732077951, "train/reward_neg_loss": 0.0028555081590087945, "train/reward_pos_acc": 0.18067857399582862, "train/reward_pos_loss": 4.108489339351654, "train/reward_pred": 0.0017148512375444688, "train/reward_rate": 0.0032520012315270935, "train_stats/mean_log_entropy": 0.08375076751442666, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.016148585826158524, "report/cont_loss_std": 0.27438634634017944, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 4.149943828582764, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004002272617071867, "report/cont_pred": 0.9951983094215393, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07145369052886963, "report/image_loss_std": 0.0823347344994545, "report/model_loss_mean": 0.6900112628936768, "report/model_loss_std": 0.28951412439346313, "report/post_ent_mag": 22.969818115234375, "report/post_ent_max": 22.969818115234375, "report/post_ent_mean": 22.504854202270508, "report/post_ent_min": 22.234737396240234, "report/post_ent_std": 0.16334234178066254, "report/prior_ent_mag": 25.022777557373047, "report/prior_ent_max": 25.022777557373047, "report/prior_ent_mean": 22.92758560180664, "report/prior_ent_min": 21.409591674804688, "report/prior_ent_std": 0.48380547761917114, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0, "report/reward_loss_mean": 0.0024089363869279623, "report/reward_loss_std": 0.012737002223730087, "report/reward_max_data": 0.0, "report/reward_max_pred": 0.1511932611465454, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.0024089363869279623, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0012050990480929613, "report/reward_rate": 0.0, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.034336842596530914, "eval/cont_loss_std": 0.4652864933013916, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.630405426025391, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.006878211162984371, "eval/cont_pred": 0.9960684776306152, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18432848155498505, "eval/image_loss_std": 0.14636573195457458, "eval/model_loss_mean": 0.8345068693161011, "eval/model_loss_std": 0.6627390384674072, "eval/post_ent_mag": 22.96369743347168, "eval/post_ent_max": 22.96369743347168, "eval/post_ent_mean": 22.50467300415039, "eval/post_ent_min": 22.22693634033203, "eval/post_ent_std": 0.16720378398895264, "eval/prior_ent_mag": 25.022777557373047, "eval/prior_ent_max": 25.022777557373047, "eval/prior_ent_mean": 22.95892906188965, "eval/prior_ent_min": 21.87966537475586, "eval/prior_ent_std": 0.49306514859199524, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0012908935314044356, "eval/reward_loss_mean": 0.015841592103242874, "eval/reward_loss_std": 0.27091872692108154, "eval/reward_max_data": 0.668749988079071, "eval/reward_max_pred": 0.0473332405090332, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012126568472012877, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.994555950164795, "eval/reward_pred": 0.0006428530905395746, "eval/reward_rate": 0.0029296875, "replay/size": 773825.0, "replay/inserts": 32480.0, "replay/samples": 32480.0, "replay/insert_wait_avg": 1.356343330420884e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.454838071550642e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1269480754167605e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9937074184418, "timer/env.step_count": 4060.0, "timer/env.step_total": 38.305957317352295, "timer/env.step_frac": 0.038306198362229676, "timer/env.step_avg": 0.009434964856490712, "timer/env.step_min": 0.00767827033996582, "timer/env.step_max": 0.04085183143615723, "timer/replay._sample_count": 32480.0, "timer/replay._sample_total": 16.465539932250977, "timer/replay._sample_frac": 0.016465643543655883, "timer/replay._sample_avg": 0.0005069439634313725, "timer/replay._sample_min": 0.00039458274841308594, "timer/replay._sample_max": 0.011643409729003906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4528.0, "timer/agent.policy_total": 46.74310064315796, "timer/agent.policy_frac": 0.04674339477978192, "timer/agent.policy_avg": 0.01032312293355962, "timer/agent.policy_min": 0.008772611618041992, "timer/agent.policy_max": 0.07780122756958008, "timer/dataset_train_count": 2030.0, "timer/dataset_train_total": 0.20933270454406738, "timer/dataset_train_frac": 0.00020933402179547245, "timer/dataset_train_avg": 0.00010311955888870314, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00043654441833496094, "timer/agent.train_count": 2030.0, "timer/agent.train_total": 904.5387465953827, "timer/agent.train_frac": 0.9045444385150351, "timer/agent.train_avg": 0.4455855894558535, "timer/agent.train_min": 0.432941198348999, "timer/agent.train_max": 0.668245792388916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.475940465927124, "timer/agent.report_frac": 0.0004759434608401685, "timer/agent.report_avg": 0.237970232963562, "timer/agent.report_min": 0.23173928260803223, "timer/agent.report_max": 0.2442011833190918, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2425130795592566e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 32.47967401877463}
{"step": 774728, "time": 24229.83507490158, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 775176, "time": 24243.45388817787, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 775304, "time": 24247.426741600037, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 775328, "time": 24248.400658369064, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 775536, "time": 24254.678770065308, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 775608, "time": 24256.622134923935, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 775888, "time": 24265.299347877502, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 776280, "time": 24277.021440267563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776448, "time": 24282.304978132248, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776600, "time": 24286.680691719055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 776648, "time": 24288.177990674973, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 776824, "time": 24293.586987257004, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 776856, "time": 24294.560510396957, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 777040, "time": 24300.330060243607, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777576, "time": 24316.394739866257, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 777640, "time": 24318.347459316254, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 777752, "time": 24321.750072479248, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 777824, "time": 24324.13769197464, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 777920, "time": 24327.060642004013, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 778040, "time": 24330.471512317657, "episode/length": 268.0, "episode/score": 0.16249999403953552, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0}
{"step": 778200, "time": 24335.302364587784, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 778208, "time": 24335.768699645996, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 778352, "time": 24340.6886241436, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 778536, "time": 24346.034715652466, "episode/length": 281.0, "episode/score": 0.12187500298023224, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.0}
{"step": 778568, "time": 24347.00049352646, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 778608, "time": 24348.432602405548, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 778904, "time": 24357.1736972332, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 779168, "time": 24365.37151169777, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 779240, "time": 24367.403069019318, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 779440, "time": 24373.68081521988, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 779592, "time": 24378.047996759415, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 779592, "time": 24378.0603659153, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 779632, "time": 24379.51908493042, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 24392.289353609085, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 780000, "time": 24392.293964862823, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 780000, "time": 24392.753660678864, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 780000, "time": 24393.06356859207, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 780000, "time": 24393.104368448257, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 780000, "time": 24394.72576856613, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 780000, "time": 24394.947736024857, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 780000, "time": 24395.400505781174, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 780064, "time": 24397.439514398575, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780104, "time": 24398.42520594597, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 780232, "time": 24402.295518398285, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 780392, "time": 24407.136428117752, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 780488, "time": 24410.03959918022, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 780568, "time": 24412.458034038544, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 780640, "time": 24414.851475954056, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 780664, "time": 24415.362966775894, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 780712, "time": 24416.81374144554, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 780840, "time": 24420.676058769226, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 780856, "time": 24421.16246986389, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 781288, "time": 24434.25444293022, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 781440, "time": 24439.083983182907, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 781584, "time": 24443.415333747864, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 781856, "time": 24451.590092897415, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 782344, "time": 24466.189847946167, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 782376, "time": 24467.19025707245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782656, "time": 24475.87090229988, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 782952, "time": 24484.581548690796, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 782976, "time": 24485.536029577255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783024, "time": 24487.10137987137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783152, "time": 24490.978307008743, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783384, "time": 24497.74009847641, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 783456, "time": 24500.128752231598, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 783504, "time": 24501.589079380035, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 783600, "time": 24504.471195459366, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 783640, "time": 24505.475446224213, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 783656, "time": 24505.961942195892, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 783672, "time": 24506.452087640762, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 783872, "time": 24512.71931052208, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 784096, "time": 24519.61598610878, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 784272, "time": 24524.97347021103, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 784424, "time": 24529.343997716904, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 784904, "time": 24543.860154628754, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 784912, "time": 24544.345564842224, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 784968, "time": 24545.881464481354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785008, "time": 24547.373180389404, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 785328, "time": 24557.075180768967, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 785752, "time": 24569.686286211014, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 785816, "time": 24571.61204123497, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 785848, "time": 24572.590454101562, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 785984, "time": 24576.99951505661, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786168, "time": 24582.32493710518, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 786304, "time": 24586.76738834381, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 786408, "time": 24589.714854478836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 786512, "time": 24593.549425840378, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 786592, "time": 24595.971618413925, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 786648, "time": 24597.440026521683, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 787024, "time": 24609.13135910034, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 787144, "time": 24612.53600859642, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 787216, "time": 24614.961732387543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787392, "time": 24620.30050587654, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 787512, "time": 24623.703356027603, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 787520, "time": 24624.17031264305, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 787640, "time": 24627.568658828735, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 787696, "time": 24629.474118947983, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 787936, "time": 24636.76902127266, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 787984, "time": 24638.233755111694, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 788088, "time": 24641.138645410538, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 788112, "time": 24642.10167646408, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 788408, "time": 24650.78535747528, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 788512, "time": 24654.16185283661, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 788616, "time": 24657.085366010666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 788624, "time": 24657.552261829376, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 789072, "time": 24671.188446998596, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 789104, "time": 24672.15811753273, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 789184, "time": 24674.566865682602, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 789704, "time": 24690.10057449341, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 789944, "time": 24697.451573848724, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 790056, "time": 24700.84610271454, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 24702.609948396683, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 790088, "time": 24703.53438973427, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 790088, "time": 24703.79388308525, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 790088, "time": 24703.914214849472, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 790088, "time": 24705.14650440216, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 790088, "time": 24705.464361190796, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 790088, "time": 24705.777321338654, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 790088, "time": 24705.821301460266, "eval_episode/length": 175.0, "eval_episode/score": 0.453125, "eval_episode/reward_rate": 0.005681818181818182}
{"step": 790192, "time": 24709.20225071907, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 790424, "time": 24715.972425460815, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790824, "time": 24728.14006948471, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 790856, "time": 24729.124266147614, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 790928, "time": 24731.52334189415, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791016, "time": 24733.979259967804, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 791496, "time": 24748.468118429184, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 791504, "time": 24748.942399978638, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 791608, "time": 24751.862159967422, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 791848, "time": 24759.246294260025, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 792296, "time": 24772.7493724823, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 792368, "time": 24775.147520542145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792504, "time": 24779.044594049454, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792536, "time": 24780.008806467056, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 792576, "time": 24781.446188926697, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 792736, "time": 24786.389028549194, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 792944, "time": 24792.67372226715, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 792968, "time": 24793.186066627502, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 793088, "time": 24797.035775899887, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 793136, "time": 24798.495922088623, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 793376, "time": 24805.74286055565, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 793456, "time": 24808.156125068665, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 793544, "time": 24810.587907791138, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 793616, "time": 24812.99154496193, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 793656, "time": 24813.981643915176, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 793808, "time": 24818.88529729843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 794056, "time": 24826.13942551613, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 794272, "time": 24832.87278342247, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 794296, "time": 24833.379769086838, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 794320, "time": 24834.32074189186, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 794408, "time": 24836.774526119232, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 794656, "time": 24844.924330711365, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 794760, "time": 24847.921885252, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 795216, "time": 24861.939423322678, "episode/length": 194.0, "episode/score": 0.39375001192092896, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.0}
{"step": 795304, "time": 24864.371397018433, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 795384, "time": 24866.79110264778, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 795400, "time": 24867.280107975006, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 795488, "time": 24870.182889699936, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 795512, "time": 24870.690690279007, "episode/length": 181.0, "episode/score": 0.43437498807907104, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.0}
{"step": 795744, "time": 24877.9980635643, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 795912, "time": 24882.844770669937, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 795912, "time": 24882.850572109222, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 796400, "time": 24897.80676651001, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 796440, "time": 24898.811403989792, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 796464, "time": 24899.756639003754, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 796544, "time": 24902.158492088318, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 796632, "time": 24904.61341238022, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 796840, "time": 24911.002457380295, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 797072, "time": 24918.280745506287, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 797248, "time": 24923.598380804062, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 797312, "time": 24925.52356338501, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 797640, "time": 24935.208902835846, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 797696, "time": 24937.21027779579, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 797800, "time": 24940.139627695084, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798008, "time": 24946.433042049408, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 798056, "time": 24947.89573788643, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798712, "time": 24967.79931664467, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 798752, "time": 24969.221232652664, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 799024, "time": 24977.42723584175, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 799072, "time": 24978.88179206848, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 799152, "time": 24981.305604934692, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799384, "time": 24988.093866825104, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799544, "time": 24992.93653845787, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 799624, "time": 24995.357261180878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 799800, "time": 25000.814713954926, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 799832, "time": 25001.777586460114, "episode/length": 35.0, "episode/score": 0.890625, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.0}
{"step": 799960, "time": 25005.65468811989, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 25010.283349514008, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 800072, "time": 25010.379715919495, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 800072, "time": 25010.586085557938, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 800072, "time": 25010.629813671112, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 800072, "time": 25011.116963624954, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 800072, "time": 25011.865426778793, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 800072, "time": 25011.982879161835, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 800072, "time": 25012.065763235092, "eval_episode/length": 162.0, "eval_episode/score": 0.4937500059604645, "eval_episode/reward_rate": 0.006134969325153374}
{"step": 800312, "time": 25019.312264442444, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 800368, "time": 25021.217730760574, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801024, "time": 25041.16796708107, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801064, "time": 25044.083621501923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801072, "time": 25044.57517528534, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 801120, "time": 25046.043879032135, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 801384, "time": 25053.84287929535, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 801536, "time": 25058.823574781418, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 801680, "time": 25063.174256801605, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 802120, "time": 25076.230978488922, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 802144, "time": 25077.175198554993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802256, "time": 25080.582138061523, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 802272, "time": 25081.06989789009, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 802312, "time": 25082.05618071556, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 802416, "time": 25085.42652130127, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 802848, "time": 25099.036712646484, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 802856, "time": 25099.063604593277, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 802896, "time": 25100.48915219307, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 803376, "time": 25114.960877418518, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 803400, "time": 25115.46575164795, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 803408, "time": 25115.97382235527, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 803696, "time": 25124.735946655273, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804136, "time": 25137.83185696602, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 804136, "time": 25137.83832883835, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 804304, "time": 25143.1421790123, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 804320, "time": 25143.634099960327, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 804328, "time": 25143.661207914352, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 804432, "time": 25147.164508104324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 804584, "time": 25151.513857364655, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 804784, "time": 25157.78227710724, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 804840, "time": 25159.25906252861, "episode/length": 248.0, "episode/score": 0.22499999403953552, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.0}
{"step": 804968, "time": 25163.12664794922, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 805264, "time": 25172.246736764908, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 805400, "time": 25176.257712364197, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 805696, "time": 25185.407730340958, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 805792, "time": 25188.309616565704, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 805904, "time": 25191.698956012726, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 805912, "time": 25191.72722697258, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 805976, "time": 25193.65978860855, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 806280, "time": 25202.825263023376, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 806448, "time": 25208.229803800583, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806616, "time": 25213.06148171425, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 806761, "time": 25218.414989233017, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.268348130099292, "train/action_min": 0.0, "train/action_std": 1.8752723456603553, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014351873004836549, "train/actor_opt_grad_steps": 49310.0, "train/actor_opt_loss": -17.4784911771126, "train/adv_mag": 1.0530335368781254, "train/adv_max": 0.33203981075380823, "train/adv_mean": -0.00011510790929534034, "train/adv_min": -0.9980059239664688, "train/adv_std": 0.03595442321665328, "train/cont_avg": 0.9942801339285714, "train/cont_loss_mean": 0.02023326951248819, "train/cont_loss_std": 0.25289448847985035, "train/cont_neg_acc": 0.26918481672045047, "train/cont_neg_loss": 2.8250891242366687, "train/cont_pos_acc": 0.9998693539591258, "train/cont_pos_loss": 0.004134352023603184, "train/cont_pred": 0.9944301975771711, "train/cont_rate": 0.9942801339285714, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20200386284644087, "train/extr_critic_critic_opt_grad_steps": 49310.0, "train/extr_critic_critic_opt_loss": 4408.616586168411, "train/extr_critic_mag": 1.676321716731405, "train/extr_critic_max": 1.676321716731405, "train/extr_critic_mean": 1.5673862037987545, "train/extr_critic_min": 1.4468661681771866, "train/extr_critic_std": 0.02558921648216952, "train/extr_return_normed_mag": 1.0562721919543638, "train/extr_return_normed_max": 0.382136881057852, "train/extr_return_normed_mean": 0.050949766608000976, "train/extr_return_normed_min": -0.9632360453676121, "train/extr_return_normed_std": 0.04558538643670787, "train/extr_return_rate": 0.9995619454994578, "train/extr_return_raw_mag": 1.898458080925965, "train/extr_return_raw_max": 1.898458080925965, "train/extr_return_raw_mean": 1.5672710435143833, "train/extr_return_raw_min": 0.5530851545005009, "train/extr_return_raw_std": 0.045585386308249584, "train/extr_reward_mag": 0.37106098388803416, "train/extr_reward_max": 0.37106098388803416, "train/extr_reward_mean": 0.002558421082060619, "train/extr_reward_min": 4.6391792485279406e-08, "train/extr_reward_std": 0.010289944960676096, "train/image_loss_mean": 0.08878906429034149, "train/image_loss_std": 0.1018811703976152, "train/model_loss_mean": 0.726351266130438, "train/model_loss_std": 0.4955322853303308, "train/model_opt_grad_norm": 19.22950755434083, "train/model_opt_grad_steps": 49266.684729064036, "train/model_opt_loss": 3862.8669253194275, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5320.1970443349755, "train/policy_entropy_mag": 1.2800580304244469, "train/policy_entropy_max": 1.2800580304244469, "train/policy_entropy_mean": 0.1004237756867127, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12805259587435885, "train/policy_logprob_mag": 6.5510802597835145, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10054052011866875, "train/policy_logprob_min": -6.5510802597835145, "train/policy_logprob_std": 0.6383646101199935, "train/policy_randomness_mag": 0.6578197397034744, "train/policy_randomness_max": 0.6578197397034744, "train/policy_randomness_mean": 0.051607613713283255, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06580602032650867, "train/post_ent_mag": 23.33111326095506, "train/post_ent_max": 23.33111326095506, "train/post_ent_mean": 22.884210455006567, "train/post_ent_min": 22.5455803424854, "train/post_ent_std": 0.1645146253073744, "train/prior_ent_mag": 24.803381304435543, "train/prior_ent_max": 24.803381304435543, "train/prior_ent_mean": 22.729547087194884, "train/prior_ent_min": 21.471859645373716, "train/prior_ent_std": 0.48916055284110194, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.002335030687175774, "train/reward_loss_mean": 0.017328912502365748, "train/reward_loss_std": 0.24474907592351874, "train/reward_max_data": 0.7710745079176766, "train/reward_max_pred": 0.31809315364349067, "train/reward_neg_acc": 0.9995943504601277, "train/reward_neg_loss": 0.0030148939557575385, "train/reward_pos_acc": 0.20890165356235887, "train/reward_pos_loss": 4.0213778363400365, "train/reward_pred": 0.0018548428710651, "train/reward_rate": 0.0035454510467980297, "train_stats/mean_log_entropy": 0.08529879491916804, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.011799750849604607, "report/cont_loss_std": 0.14476433396339417, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 2.335822582244873, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004971084650605917, "report/cont_pred": 0.9945249557495117, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07805359363555908, "report/image_loss_std": 0.10121148079633713, "report/model_loss_mean": 0.7045131325721741, "report/model_loss_std": 0.39359015226364136, "report/post_ent_mag": 22.95277976989746, "report/post_ent_max": 22.95277976989746, "report/post_ent_mean": 22.485713958740234, "report/post_ent_min": 22.11614418029785, "report/post_ent_std": 0.16768105328083038, "report/prior_ent_mag": 24.494487762451172, "report/prior_ent_max": 24.494487762451172, "report/prior_ent_mean": 22.389841079711914, "report/prior_ent_min": 21.148208618164062, "report/prior_ent_std": 0.46638885140419006, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001708984375, "report/reward_loss_mean": 0.014659754000604153, "report/reward_loss_std": 0.22292400896549225, "report/reward_max_data": 0.7093750238418579, "report/reward_max_pred": 0.3531261682510376, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004028901923447847, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.632693290710449, "report/reward_pred": 0.0024019326083362103, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04294324293732643, "eval/cont_loss_std": 0.5618329048156738, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.232069969177246, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.006465091835707426, "eval/cont_pred": 0.9942816495895386, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16444791853427887, "eval/image_loss_std": 0.16688337922096252, "eval/model_loss_mean": 0.8302751779556274, "eval/model_loss_std": 0.7800675630569458, "eval/post_ent_mag": 22.94736099243164, "eval/post_ent_max": 22.94736099243164, "eval/post_ent_mean": 22.500953674316406, "eval/post_ent_min": 22.169281005859375, "eval/post_ent_std": 0.156038299202919, "eval/prior_ent_mag": 24.494487762451172, "eval/prior_ent_max": 24.494487762451172, "eval/prior_ent_mean": 22.450719833374023, "eval/prior_ent_min": 21.128002166748047, "eval/prior_ent_std": 0.477182000875473, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0026306151412427425, "eval/reward_loss_mean": 0.02288399636745453, "eval/reward_loss_std": 0.30374157428741455, "eval/reward_max_data": 0.8031250238418579, "eval/reward_max_pred": 0.19982945919036865, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.003952936269342899, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 4.850304126739502, "eval/reward_pred": 0.0019930279813706875, "eval/reward_rate": 0.00390625, "replay/size": 806257.0, "replay/inserts": 32432.0, "replay/samples": 32432.0, "replay/insert_wait_avg": 1.3518080549047213e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.635099169181142e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1238798096373274e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.5050172805786133e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4336264133453, "timer/env.step_count": 4054.0, "timer/env.step_total": 38.087316036224365, "timer/env.step_frac": 0.03807080752850262, "timer/env.step_avg": 0.009394996555556085, "timer/env.step_min": 0.007578372955322266, "timer/env.step_max": 0.03980898857116699, "timer/replay._sample_count": 32432.0, "timer/replay._sample_total": 16.433252334594727, "timer/replay._sample_frac": 0.01642612953096107, "timer/replay._sample_avg": 0.0005066987029660436, "timer/replay._sample_min": 0.0004134178161621094, "timer/replay._sample_max": 0.011225700378417969, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4646.0, "timer/agent.policy_total": 48.35420775413513, "timer/agent.policy_frac": 0.0483332491806476, "timer/agent.policy_avg": 0.010407707222155647, "timer/agent.policy_min": 0.008542060852050781, "timer/agent.policy_max": 0.10439848899841309, "timer/dataset_train_count": 2027.0, "timer/dataset_train_total": 0.20961999893188477, "timer/dataset_train_frac": 0.00020952914156173802, "timer/dataset_train_avg": 0.00010341391165855193, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0010602474212646484, "timer/agent.train_count": 2027.0, "timer/agent.train_total": 902.5206205844879, "timer/agent.train_frac": 0.9021294334338947, "timer/agent.train_avg": 0.44524944281425155, "timer/agent.train_min": 0.4336848258972168, "timer/agent.train_max": 2.3536956310272217, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4834017753601074, "timer/agent.report_frac": 0.0004831922504375939, "timer/agent.report_avg": 0.2417008876800537, "timer/agent.report_min": 0.2387256622314453, "timer/agent.report_max": 0.2446761131286621, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.288818359375e-05, "timer/dataset_eval_frac": 2.287826297463274e-08, "timer/dataset_eval_avg": 2.288818359375e-05, "timer/dataset_eval_min": 2.288818359375e-05, "timer/dataset_eval_max": 2.288818359375e-05, "fps": 32.4173842200997}
{"step": 806936, "time": 25223.434071063995, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 807048, "time": 25226.823071479797, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 807160, "time": 25230.21502661705, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 807280, "time": 25234.05578303337, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 807328, "time": 25235.52971124649, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 807608, "time": 25243.863634824753, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 807696, "time": 25246.7563662529, "episode/length": 237.0, "episode/score": 0.2593750059604645, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.0}
{"step": 807744, "time": 25248.203755140305, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 807808, "time": 25250.152644872665, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 807840, "time": 25251.113798379898, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 807960, "time": 25254.51267004013, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 808160, "time": 25260.7675011158, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 808224, "time": 25262.686449289322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 808312, "time": 25265.140060424805, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 808472, "time": 25270.087952375412, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 808768, "time": 25279.250950098038, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 808800, "time": 25280.217327833176, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 808840, "time": 25281.200763225555, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 808872, "time": 25282.175446033478, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 808888, "time": 25282.661410570145, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 809016, "time": 25286.523384809494, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 809048, "time": 25287.481664180756, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 809112, "time": 25289.416222333908, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 809256, "time": 25293.768157720566, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 809272, "time": 25294.25761270523, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 809376, "time": 25297.68188714981, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 809384, "time": 25297.708208560944, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 809432, "time": 25299.175653219223, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 809656, "time": 25305.925629377365, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 809704, "time": 25307.38025546074, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 809712, "time": 25307.86941432953, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 809776, "time": 25309.798847436905, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 809808, "time": 25310.760541439056, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 810016, "time": 25317.052527427673, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 25318.8978972435, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 810056, "time": 25319.33192706108, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 810056, "time": 25319.58854317665, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 810056, "time": 25319.705727100372, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 810056, "time": 25319.96979880333, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 810056, "time": 25320.053789138794, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 810056, "time": 25320.2048099041, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 810056, "time": 25320.76265001297, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 810104, "time": 25322.198719263077, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 810288, "time": 25328.08131170273, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 810352, "time": 25330.022201299667, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 810424, "time": 25331.95861172676, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 810632, "time": 25338.227214097977, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 810880, "time": 25345.9359562397, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 810888, "time": 25345.962735176086, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 811168, "time": 25355.097506284714, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 811184, "time": 25355.587349891663, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 811544, "time": 25366.338180541992, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 811688, "time": 25370.675344228745, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811696, "time": 25371.139045476913, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 811720, "time": 25371.642218589783, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 811896, "time": 25376.928163051605, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 812496, "time": 25395.392155647278, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 812680, "time": 25400.729192256927, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 812712, "time": 25401.69524025917, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 812752, "time": 25403.14861679077, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 812944, "time": 25408.922084093094, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 812992, "time": 25410.375277757645, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 813000, "time": 25410.403083324432, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 813192, "time": 25416.256568431854, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813344, "time": 25421.073944568634, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 813480, "time": 25424.95455431938, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 813584, "time": 25428.33034825325, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 813712, "time": 25432.18614435196, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 813736, "time": 25432.690762758255, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 813968, "time": 25439.919799804688, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 814112, "time": 25444.26390361786, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 814168, "time": 25445.731950998306, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 814224, "time": 25447.727427959442, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 814288, "time": 25449.656883716583, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 814320, "time": 25450.626453876495, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 814536, "time": 25456.921974897385, "episode/length": 38.0, "episode/score": 0.8812500238418579, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.0}
{"step": 814592, "time": 25458.830537080765, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 814880, "time": 25467.538650989532, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 814952, "time": 25469.49500322342, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 815064, "time": 25472.879202842712, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 815064, "time": 25472.884562253952, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 815160, "time": 25475.83865714073, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 815264, "time": 25479.269565582275, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 815536, "time": 25487.543027162552, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 815560, "time": 25488.05950808525, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 815920, "time": 25499.140867471695, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 815936, "time": 25499.62431693077, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 816208, "time": 25507.915773153305, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 816248, "time": 25508.90649318695, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 816264, "time": 25509.390184402466, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 816520, "time": 25517.165177583694, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 816576, "time": 25519.08500647545, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 816728, "time": 25523.45484972, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 816760, "time": 25524.44666337967, "episode/length": 29.0, "episode/score": 0.909375011920929, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.0}
{"step": 816848, "time": 25527.318798303604, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817264, "time": 25539.97027540207, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 817472, "time": 25546.23422884941, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 817544, "time": 25548.193863868713, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 817752, "time": 25554.475762605667, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 817896, "time": 25558.8229432106, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 818424, "time": 25574.880683898926, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 818520, "time": 25577.796075344086, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 818576, "time": 25579.70894241333, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819072, "time": 25594.6407623291, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819280, "time": 25601.53042626381, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 819576, "time": 25610.23224759102, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819784, "time": 25616.48864221573, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819848, "time": 25618.431786060333, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 819856, "time": 25618.90019917488, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 819944, "time": 25621.327537298203, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 820016, "time": 25623.751036167145, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 25625.104596614838, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 820040, "time": 25625.406155586243, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 820040, "time": 25626.171835899353, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 820040, "time": 25626.585022211075, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 820040, "time": 25626.756655931473, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 820040, "time": 25627.296101808548, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 820040, "time": 25627.44670844078, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 820040, "time": 25627.76622748375, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 820112, "time": 25630.165305376053, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 820208, "time": 25633.049908399582, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820320, "time": 25636.43215727806, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 820464, "time": 25640.797648906708, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 820488, "time": 25641.305890083313, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 820536, "time": 25642.74747776985, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 820736, "time": 25649.00716495514, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 820736, "time": 25649.01388835907, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 820752, "time": 25649.526770353317, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 820944, "time": 25655.34135055542, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 820992, "time": 25656.863263130188, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 821208, "time": 25663.13734602928, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 821240, "time": 25664.123636960983, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 821504, "time": 25672.320716142654, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 821608, "time": 25675.251670598984, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 822104, "time": 25690.336982488632, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 822120, "time": 25690.824022769928, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 822144, "time": 25691.773365736008, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 822288, "time": 25696.13733482361, "episode/length": 218.0, "episode/score": 0.3187499940395355, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.0}
{"step": 822488, "time": 25701.954736232758, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 823048, "time": 25718.924817562103, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823208, "time": 25723.76269364357, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 823304, "time": 25726.656502962112, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 823520, "time": 25733.386834859848, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824112, "time": 25751.32589840889, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 824184, "time": 25753.28533911705, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 824360, "time": 25758.612052202225, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 824416, "time": 25760.514122009277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824432, "time": 25761.023319005966, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824456, "time": 25761.532633066177, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824616, "time": 25766.38271212578, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 824800, "time": 25772.13708281517, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 824824, "time": 25772.64005279541, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 825024, "time": 25779.007682561874, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 825136, "time": 25782.39060974121, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 825232, "time": 25785.311237573624, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 825312, "time": 25787.71275639534, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 825424, "time": 25791.09643983841, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 825504, "time": 25793.50176501274, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 825520, "time": 25793.985134363174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 825880, "time": 25804.695452690125, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 825952, "time": 25807.179784297943, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 826080, "time": 25811.039747714996, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 826512, "time": 25824.108461141586, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 826600, "time": 25826.54014968872, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 826784, "time": 25832.36734676361, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 826800, "time": 25832.859503507614, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 826888, "time": 25835.323160409927, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 827296, "time": 25847.964661359787, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 827336, "time": 25848.96963906288, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 827472, "time": 25853.755702495575, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 827816, "time": 25863.927897930145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828264, "time": 25877.528943300247, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828312, "time": 25878.99600172043, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 828824, "time": 25894.40233564377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 828976, "time": 25899.321969032288, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 829032, "time": 25900.78800177574, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 829096, "time": 25902.744231700897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829200, "time": 25906.09914946556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829200, "time": 25906.106235027313, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 829504, "time": 25915.28639817238, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 829648, "time": 25919.63236284256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829784, "time": 25923.518697738647, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 829872, "time": 25926.505757331848, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 830000, "time": 25930.368265867233, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 25931.80607867241, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 830024, "time": 25932.409126758575, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 830024, "time": 25933.467789411545, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 830024, "time": 25933.49237036705, "eval_episode/length": 137.0, "eval_episode/score": 0.5718749761581421, "eval_episode/reward_rate": 0.007246376811594203}
{"step": 830024, "time": 25933.921048402786, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 830024, "time": 25934.75640487671, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 830024, "time": 25935.024610996246, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 830024, "time": 25936.449191331863, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 830096, "time": 25938.85389971733, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 830312, "time": 25945.128226280212, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 830352, "time": 25946.57727622986, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 830480, "time": 25950.419167757034, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 830600, "time": 25953.831347703934, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 830624, "time": 25954.77493095398, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 830816, "time": 25960.62105703354, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 830896, "time": 25963.040781497955, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 831136, "time": 25970.286603927612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 831304, "time": 25975.117604732513, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 831464, "time": 25979.934104919434, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 831480, "time": 25980.44103884697, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 831824, "time": 25991.120579242706, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 832024, "time": 25996.964101791382, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 832408, "time": 26008.593323946, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832424, "time": 26009.07989883423, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 832624, "time": 26015.360979557037, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 832768, "time": 26019.810151338577, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 832792, "time": 26020.316098213196, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833040, "time": 26027.99788594246, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 833128, "time": 26030.43990087509, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 833232, "time": 26033.809032201767, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 833264, "time": 26034.774723768234, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 833544, "time": 26042.976207733154, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 833616, "time": 26045.377187490463, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 833776, "time": 26050.30302643776, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 834104, "time": 26059.991994142532, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 834144, "time": 26061.41300201416, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 834264, "time": 26064.818231105804, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 834488, "time": 26071.589450359344, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 834632, "time": 26075.974848747253, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 835080, "time": 26089.53780889511, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835312, "time": 26096.78796482086, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 835440, "time": 26100.645245075226, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835448, "time": 26100.6735060215, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 835576, "time": 26104.55053138733, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 835592, "time": 26105.254097223282, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 835688, "time": 26108.527891397476, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 835984, "time": 26117.685400009155, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 836016, "time": 26118.653411865234, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 836416, "time": 26130.72762489319, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 836576, "time": 26135.54481625557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 836592, "time": 26136.164271354675, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 836760, "time": 26141.02383828163, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 836792, "time": 26141.98618221283, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 836976, "time": 26147.76242518425, "episode/length": 174.0, "episode/score": 0.45625001192092896, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.0}
{"step": 837152, "time": 26153.058345794678, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 837184, "time": 26154.02096605301, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 837448, "time": 26161.791942834854, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 837488, "time": 26163.221888780594, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 837528, "time": 26164.20145726204, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 837760, "time": 26171.51895093918, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 838216, "time": 26185.04305577278, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 838224, "time": 26185.51133298874, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 838416, "time": 26191.287739515305, "episode/length": 202.0, "episode/score": 0.3687500059604645, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.0}
{"step": 838456, "time": 26192.27628660202, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 838472, "time": 26192.76541543007, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 838624, "time": 26197.69203853607, "episode/length": 20.0, "episode/score": 0.9375, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.0}
{"step": 839016, "time": 26209.29629778862, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 839064, "time": 26210.73952293396, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 839264, "time": 26216.9849691391, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 839288, "time": 26217.494736909866, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839289, "time": 26218.502569913864, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2046538855641935, "train/action_min": 0.0, "train/action_std": 1.8118160957186094, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014110572606306798, "train/actor_opt_grad_steps": 51340.0, "train/actor_opt_loss": -19.328990338471137, "train/adv_mag": 1.0258549211060473, "train/adv_max": 0.27460181302037734, "train/adv_mean": 0.0005827160299044668, "train/adv_min": -0.9897739305872048, "train/adv_std": 0.036207226072919776, "train/cont_avg": 0.9941983528325123, "train/cont_loss_mean": 0.019889400971438643, "train/cont_loss_std": 0.24762223447154602, "train/cont_neg_acc": 0.2809491881302425, "train/cont_neg_loss": 2.7362751527941724, "train/cont_pos_acc": 0.999908066735479, "train/cont_pos_loss": 0.004183569624836516, "train/cont_pred": 0.994247911598882, "train/cont_rate": 0.9941983528325123, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.20610202700266697, "train/extr_critic_critic_opt_grad_steps": 51340.0, "train/extr_critic_critic_opt_loss": 4686.432570283636, "train/extr_critic_mag": 1.679191334494229, "train/extr_critic_max": 1.679191334494229, "train/extr_critic_mean": 1.5638201131022036, "train/extr_critic_min": 1.4273306160724808, "train/extr_critic_std": 0.02795473451317825, "train/extr_return_normed_mag": 1.0367217316416097, "train/extr_return_normed_max": 0.3345987432695962, "train/extr_return_normed_mean": 0.05598763477405891, "train/extr_return_normed_min": -0.9509373468718505, "train/extr_return_normed_std": 0.047491132304659615, "train/extr_return_rate": 0.9995295528707833, "train/extr_return_raw_mag": 1.843013804534386, "train/extr_return_raw_max": 1.843013804534386, "train/extr_return_raw_mean": 1.5644027805093474, "train/extr_return_raw_min": 0.5574777143929392, "train/extr_return_raw_std": 0.04749113217620133, "train/extr_reward_mag": 0.3049554284570252, "train/extr_reward_max": 0.3049554284570252, "train/extr_reward_mean": 0.0025024363401763396, "train/extr_reward_min": 4.6391792485279406e-08, "train/extr_reward_std": 0.010220987664930192, "train/image_loss_mean": 0.0897455231786655, "train/image_loss_std": 0.10325673002327604, "train/model_loss_mean": 0.7272126301756046, "train/model_loss_std": 0.4951310221270975, "train/model_opt_grad_norm": 18.45271313014289, "train/model_opt_grad_steps": 51294.837438423645, "train/model_opt_loss": 3905.0955564000924, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5369.458128078818, "train/policy_entropy_mag": 1.3088095235119899, "train/policy_entropy_max": 1.3088095235119899, "train/policy_entropy_mean": 0.09934141255658248, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12614567673265054, "train/policy_logprob_mag": 6.551080245689805, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09980070719431186, "train/policy_logprob_min": -6.551080245689805, "train/policy_logprob_std": 0.6387047465211653, "train/policy_randomness_mag": 0.6725950840071504, "train/policy_randomness_max": 0.6725950840071504, "train/policy_randomness_mean": 0.051051388471731414, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06482605779259076, "train/post_ent_mag": 23.282383340920134, "train/post_ent_max": 23.282383340920134, "train/post_ent_mean": 22.844158604814503, "train/post_ent_min": 22.497357918123893, "train/post_ent_std": 0.16499327365400757, "train/prior_ent_mag": 24.35740182434984, "train/prior_ent_max": 24.35740182434984, "train/prior_ent_mean": 22.498542616520023, "train/prior_ent_min": 21.351621919077605, "train/prior_ent_std": 0.45396344767415464, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0024009516548418115, "train/reward_loss_mean": 0.01757768193016682, "train/reward_loss_std": 0.24528555603459332, "train/reward_max_data": 0.7791256150001376, "train/reward_max_pred": 0.30581423684294, "train/reward_neg_acc": 0.9995220611835348, "train/reward_neg_loss": 0.0031218218119365387, "train/reward_pos_acc": 0.1885236540614669, "train/reward_pos_loss": 3.99457159149113, "train/reward_pred": 0.0019084143049767231, "train/reward_rate": 0.0035935575738916255, "train_stats/mean_log_entropy": 0.08665048632284869, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.02315010316669941, "report/cont_loss_std": 0.28945428133010864, "report/cont_neg_acc": 0.375, "report/cont_neg_loss": 2.559058904647827, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0031823187600821257, "report/cont_pred": 0.9942047595977783, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.07216756790876389, "report/image_loss_std": 0.09167952835559845, "report/model_loss_mean": 0.7202103137969971, "report/model_loss_std": 0.6718196868896484, "report/post_ent_mag": 23.568950653076172, "report/post_ent_max": 23.568950653076172, "report/post_ent_mean": 23.111570358276367, "report/post_ent_min": 22.759384155273438, "report/post_ent_std": 0.1735285520553589, "report/prior_ent_mag": 24.442903518676758, "report/prior_ent_max": 24.442903518676758, "report/prior_ent_mean": 22.34596061706543, "report/prior_ent_min": 21.12977409362793, "report/prior_ent_std": 0.5528784990310669, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0034362792503088713, "report/reward_loss_mean": 0.02489260956645012, "report/reward_loss_std": 0.35511618852615356, "report/reward_max_data": 0.8218749761581421, "report/reward_max_pred": 0.3498119115829468, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0019253495847806334, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 4.705620288848877, "report/reward_pred": 0.001344481366686523, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.027670424431562424, "eval/cont_loss_std": 0.4578951597213745, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.715441703796387, "eval/cont_pos_acc": 0.9980410933494568, "eval/cont_pos_loss": 0.005081477575004101, "eval/cont_pred": 0.9964488744735718, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15784770250320435, "eval/image_loss_std": 0.13798734545707703, "eval/model_loss_mean": 0.793357789516449, "eval/model_loss_std": 0.5592719912528992, "eval/post_ent_mag": 23.575237274169922, "eval/post_ent_max": 23.575237274169922, "eval/post_ent_mean": 23.088380813598633, "eval/post_ent_min": 22.745258331298828, "eval/post_ent_std": 0.17491576075553894, "eval/prior_ent_mag": 24.442903518676758, "eval/prior_ent_max": 24.442903518676758, "eval/prior_ent_mean": 22.366104125976562, "eval/prior_ent_min": 21.22879981994629, "eval/prior_ent_std": 0.5636921525001526, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007110595470294356, "eval/reward_loss_mean": 0.007839653640985489, "eval/reward_loss_std": 0.17083695530891418, "eval/reward_max_data": 0.7281249761581421, "eval/reward_max_pred": 0.5369008779525757, "eval/reward_neg_acc": 0.9990224838256836, "eval/reward_neg_loss": 0.002799383131787181, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.164036750793457, "eval/reward_pred": 0.0010571300517767668, "eval/reward_rate": 0.0009765625, "replay/size": 838785.0, "replay/inserts": 32528.0, "replay/samples": 32528.0, "replay/insert_wait_avg": 1.338656407181289e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.679265412097487e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1435843378158143e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0705053806305, "timer/env.step_count": 4066.0, "timer/env.step_total": 37.91671872138977, "timer/env.step_frac": 0.03791404557717511, "timer/env.step_avg": 0.009325312031822373, "timer/env.step_min": 0.0076868534088134766, "timer/env.step_max": 0.034796953201293945, "timer/replay._sample_count": 32528.0, "timer/replay._sample_total": 16.473931312561035, "timer/replay._sample_frac": 0.016472769893649646, "timer/replay._sample_avg": 0.0005064538647491711, "timer/replay._sample_min": 0.0003440380096435547, "timer/replay._sample_max": 0.010914802551269531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4673.0, "timer/agent.policy_total": 48.16572856903076, "timer/agent.policy_frac": 0.04816233286542003, "timer/agent.policy_avg": 0.010307239154511184, "timer/agent.policy_min": 0.008837699890136719, "timer/agent.policy_max": 0.0802464485168457, "timer/dataset_train_count": 2033.0, "timer/dataset_train_total": 0.20856332778930664, "timer/dataset_train_frac": 0.00020854862398919232, "timer/dataset_train_avg": 0.00010258894628101655, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.00046324729919433594, "timer/agent.train_count": 2033.0, "timer/agent.train_total": 902.3916544914246, "timer/agent.train_frac": 0.9023280355098273, "timer/agent.train_avg": 0.44387194023188614, "timer/agent.train_min": 0.4326188564300537, "timer/agent.train_max": 0.7654640674591064, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48517513275146484, "timer/agent.report_frac": 0.00048514092770569753, "timer/agent.report_avg": 0.24258756637573242, "timer/agent.report_min": 0.2371816635131836, "timer/agent.report_max": 0.24799346923828125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4080276489257812e-05, "timer/dataset_eval_frac": 2.4078578819893073e-08, "timer/dataset_eval_avg": 2.4080276489257812e-05, "timer/dataset_eval_min": 2.4080276489257812e-05, "timer/dataset_eval_max": 2.4080276489257812e-05, "fps": 32.5251298536988}
{"step": 839304, "time": 26218.554728984833, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 839496, "time": 26224.807124376297, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839504, "time": 26225.27554154396, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 839672, "time": 26230.252959012985, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 839760, "time": 26233.129977464676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 839880, "time": 26236.560834407806, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 26241.15659880638, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 840008, "time": 26241.452689647675, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 840008, "time": 26241.70648431778, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 840008, "time": 26242.055573940277, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 840008, "time": 26242.07988858223, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 840008, "time": 26242.29114317894, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 840008, "time": 26242.296221733093, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 840008, "time": 26242.458311080933, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 840016, "time": 26242.923790454865, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 840216, "time": 26248.77768778801, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 840520, "time": 26258.142998933792, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 841240, "time": 26279.942230463028, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 841376, "time": 26284.273462057114, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841392, "time": 26284.77983522415, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 841808, "time": 26297.43585038185, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 841816, "time": 26297.464881181717, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842000, "time": 26303.259041547775, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 842072, "time": 26305.239162683487, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842080, "time": 26305.705434560776, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 842192, "time": 26309.116504907608, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 842336, "time": 26313.470481157303, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 842616, "time": 26321.8305747509, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 842832, "time": 26328.636683940887, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843024, "time": 26334.45654273033, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 843400, "time": 26345.62857556343, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 843648, "time": 26353.498879909515, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 843688, "time": 26354.493520498276, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 843728, "time": 26355.92738866806, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 844120, "time": 26368.097391605377, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844392, "time": 26376.43992805481, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844408, "time": 26376.932781219482, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 844504, "time": 26379.865361213684, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 844552, "time": 26381.33167028427, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 844648, "time": 26384.25162410736, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 845176, "time": 26400.3135201931, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 845296, "time": 26404.205258846283, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 845328, "time": 26405.190805196762, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 845496, "time": 26410.123198986053, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 845600, "time": 26413.5054666996, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 845712, "time": 26416.907252311707, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 845832, "time": 26420.3085603714, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 845960, "time": 26424.209184408188, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846000, "time": 26425.648295879364, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 846008, "time": 26425.674809217453, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 846056, "time": 26427.15121126175, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 846216, "time": 26431.995710372925, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 846424, "time": 26438.373816013336, "episode/length": 52.0, "episode/score": 0.8374999761581421, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0}
{"step": 846512, "time": 26441.27424097061, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 846736, "time": 26448.061320066452, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 846760, "time": 26448.57458972931, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 846960, "time": 26454.866634368896, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 847112, "time": 26459.26011943817, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 847432, "time": 26469.146874427795, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 847480, "time": 26470.61733675003, "episode/length": 157.0, "episode/score": 0.5093749761581421, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.0}
{"step": 847536, "time": 26472.54000020027, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 847600, "time": 26474.470975875854, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 847696, "time": 26477.397124052048, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 847928, "time": 26484.186450958252, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 847984, "time": 26486.12286233902, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 847992, "time": 26486.149520158768, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 848024, "time": 26487.12328672409, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 848040, "time": 26487.60916852951, "episode/length": 13.0, "episode/score": 0.9593750238418579, "episode/reward_rate": 0.07142857142857142, "episode/intrinsic_return": 0.0}
{"step": 848112, "time": 26490.024041891098, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 848328, "time": 26496.429708719254, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 848336, "time": 26496.900758743286, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 848632, "time": 26505.68224310875, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 848904, "time": 26513.93725514412, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 849064, "time": 26518.76733493805, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 849128, "time": 26520.714962005615, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 849160, "time": 26521.689098119736, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 849168, "time": 26522.156287431717, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 849384, "time": 26528.593159914017, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 849496, "time": 26531.998366117477, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 849648, "time": 26536.83763241768, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 849736, "time": 26539.30487370491, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 849744, "time": 26539.777059555054, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 849912, "time": 26544.643023729324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 26551.26284456253, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 850096, "time": 26551.615715026855, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 850096, "time": 26552.484376192093, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 850096, "time": 26552.548410892487, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 850096, "time": 26553.086932182312, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 850096, "time": 26553.112898111343, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 850096, "time": 26554.32313799858, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 850096, "time": 26554.328508853912, "eval_episode/length": 173.0, "eval_episode/score": 0.4593749940395355, "eval_episode/reward_rate": 0.005747126436781609}
{"step": 850160, "time": 26556.356786966324, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 850320, "time": 26561.197865247726, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 850344, "time": 26561.70879983902, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 850352, "time": 26562.194684028625, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 850600, "time": 26569.46227622032, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 850664, "time": 26571.39541363716, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 850696, "time": 26572.382472515106, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 850896, "time": 26578.638332128525, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 850936, "time": 26579.622262239456, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 851152, "time": 26586.466341257095, "episode/length": 31.0, "episode/score": 0.903124988079071, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.0}
{"step": 851336, "time": 26591.818390369415, "episode/length": 198.0, "episode/score": 0.3812499940395355, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.0}
{"step": 851384, "time": 26593.269905805588, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 851472, "time": 26596.219710111618, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 851616, "time": 26600.581731557846, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 851904, "time": 26609.323852062225, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 852088, "time": 26615.169164657593, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 852128, "time": 26616.728498458862, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 852176, "time": 26618.200284957886, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 852496, "time": 26627.89287161827, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 852616, "time": 26631.316533088684, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 852664, "time": 26632.767399311066, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 852784, "time": 26636.636370182037, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 852872, "time": 26639.07415175438, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 853008, "time": 26643.415863752365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 853088, "time": 26645.866158485413, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 853096, "time": 26645.91636943817, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 853320, "time": 26652.76661300659, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 853376, "time": 26654.68574166298, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 853584, "time": 26661.07254242897, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 853656, "time": 26663.04906153679, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 853840, "time": 26668.852775096893, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 853928, "time": 26671.31842136383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 854328, "time": 26683.492936372757, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 854560, "time": 26690.74843597412, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 854680, "time": 26694.174710273743, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 854760, "time": 26696.5818567276, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 854928, "time": 26701.892932891846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855000, "time": 26703.86364841461, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 855096, "time": 26706.850892066956, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855376, "time": 26715.549465179443, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 855400, "time": 26716.063220739365, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855616, "time": 26722.833055734634, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 855632, "time": 26723.34175157547, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 855664, "time": 26724.314131975174, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 855808, "time": 26728.680762290955, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 855896, "time": 26731.124708890915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 855896, "time": 26731.131365537643, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 855912, "time": 26731.62279033661, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 856200, "time": 26740.443832159042, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 856296, "time": 26743.357139110565, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 856296, "time": 26743.363638162613, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 856304, "time": 26743.83342242241, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 856408, "time": 26746.76193213463, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 856960, "time": 26763.692948818207, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 857056, "time": 26766.69561433792, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 857144, "time": 26769.1559278965, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 857208, "time": 26771.081813097, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 857408, "time": 26777.373787641525, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 857552, "time": 26781.726674556732, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 857600, "time": 26783.17114186287, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 857888, "time": 26791.904911518097, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 857976, "time": 26794.349547863007, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 857984, "time": 26794.817200660706, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 858016, "time": 26795.806154966354, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 858208, "time": 26801.739372730255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858208, "time": 26801.746189832687, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 858232, "time": 26802.2531042099, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 858464, "time": 26809.5152759552, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 858752, "time": 26818.26928448677, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 859024, "time": 26826.64814066887, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 859464, "time": 26839.753893852234, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 859656, "time": 26845.59277653694, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 859864, "time": 26851.93690276146, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 859912, "time": 26853.385942935944, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 26859.98106598854, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 860080, "time": 26860.059940338135, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 860080, "time": 26860.602246761322, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 860080, "time": 26860.939460277557, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 860080, "time": 26861.272787094116, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 860080, "time": 26861.46373152733, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 860080, "time": 26861.616533517838, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 860080, "time": 26861.82430243492, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 860192, "time": 26865.684236764908, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 860200, "time": 26865.71213912964, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860256, "time": 26867.620725393295, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 860328, "time": 26869.599464178085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860520, "time": 26875.380774497986, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 860616, "time": 26878.293935775757, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 860776, "time": 26883.13728928566, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 861000, "time": 26890.03582715988, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 861016, "time": 26890.531785964966, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 861136, "time": 26894.406231880188, "episode/length": 14.0, "episode/score": 0.956250011920929, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.0}
{"step": 861216, "time": 26896.828392982483, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 861456, "time": 26904.115174770355, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 861616, "time": 26908.972756147385, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 861776, "time": 26913.828523635864, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862264, "time": 26928.46597647667, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 862288, "time": 26929.423023462296, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 862640, "time": 26940.048465251923, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 862816, "time": 26945.4047768116, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 862832, "time": 26945.986406326294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863312, "time": 26960.57476067543, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863400, "time": 26963.017255306244, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 863448, "time": 26964.460315465927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 863736, "time": 26973.161558151245, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 863736, "time": 26973.168038606644, "episode/length": 244.0, "episode/score": 0.23749999701976776, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.0}
{"step": 863744, "time": 26973.641534090042, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 863768, "time": 26974.158053398132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 864152, "time": 26985.93582177162, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 864168, "time": 26986.42897582054, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 864192, "time": 26987.378609895706, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 864208, "time": 26987.865991830826, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 864496, "time": 26996.585394382477, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 864728, "time": 27003.36820244789, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 864880, "time": 27008.303747177124, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 864952, "time": 27010.273800849915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865144, "time": 27016.103071689606, "episode/length": 171.0, "episode/score": 0.46562498807907104, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0}
{"step": 865200, "time": 27018.039445400238, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 865328, "time": 27021.93241596222, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 865344, "time": 27022.42619585991, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 865496, "time": 27026.820961236954, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 865616, "time": 27030.682557106018, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 865624, "time": 27030.71085882187, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 865784, "time": 27035.569887161255, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 865888, "time": 27039.0846619606, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 866008, "time": 27042.480969190598, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 866144, "time": 27046.829066991806, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 866184, "time": 27047.82185792923, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 866504, "time": 27057.52586197853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 866648, "time": 27061.908125162125, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 866776, "time": 27065.85199379921, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 866888, "time": 27069.30860185623, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 866904, "time": 27069.801874160767, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 866920, "time": 27070.291702508926, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 867616, "time": 27091.593568325043, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 867768, "time": 27096.055008649826, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 867808, "time": 27097.51304769516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 867936, "time": 27101.391161441803, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 868032, "time": 27104.309412002563, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 868072, "time": 27105.309519052505, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 868096, "time": 27106.264769792557, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 868736, "time": 27126.245287179947, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 868760, "time": 27126.771491527557, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 868768, "time": 27127.237899303436, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 868840, "time": 27129.195645332336, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 869088, "time": 27136.915606737137, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869216, "time": 27140.76948952675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 869256, "time": 27141.77417898178, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 869336, "time": 27144.20056080818, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 869488, "time": 27149.03145480156, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 869616, "time": 27152.920649051666, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 869928, "time": 27162.27301287651, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 869928, "time": 27162.279715538025, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 27167.08850312233, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 870064, "time": 27167.66540980339, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 870064, "time": 27168.26379084587, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 870064, "time": 27168.784210681915, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 870064, "time": 27169.102271318436, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 870064, "time": 27169.655434131622, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 870064, "time": 27169.752777338028, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 870064, "time": 27170.325417995453, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 870104, "time": 27171.319066762924, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 870120, "time": 27171.80708861351, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 870272, "time": 27176.64359974861, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 870368, "time": 27179.56814646721, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 870840, "time": 27193.75721359253, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 870904, "time": 27195.70242547989, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 870952, "time": 27197.1621029377, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 871040, "time": 27200.05689764023, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 871048, "time": 27200.084940433502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 871088, "time": 27201.516063451767, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 871400, "time": 27210.8061273098, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 871416, "time": 27211.294800519943, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 871625, "time": 27218.710794448853, "train_stats/mean_log_entropy": 0.08131114096412885, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2653273408636085, "train/action_min": 0.0, "train/action_std": 1.8689235237431643, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.013489200371166169, "train/actor_opt_grad_steps": 53370.0, "train/actor_opt_loss": -20.997252229399283, "train/adv_mag": 0.9611769391985362, "train/adv_max": 0.25913632973074324, "train/adv_mean": 0.00024132101135351352, "train/adv_min": -0.9142113841813186, "train/adv_std": 0.033013048150526185, "train/cont_avg": 0.9945399091748769, "train/cont_loss_mean": 0.019929775417658495, "train/cont_loss_std": 0.24955256507167675, "train/cont_neg_acc": 0.24840346276026054, "train/cont_neg_loss": 2.9482019388029728, "train/cont_pos_acc": 0.99987422421648, "train/cont_pos_loss": 0.004192102298466259, "train/cont_pred": 0.9945186068271769, "train/cont_rate": 0.9945399091748769, "train/dyn_loss_mean": 1.0000419058823233, "train/dyn_loss_std": 0.0013202733585032924, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1567934159134409, "train/extr_critic_critic_opt_grad_steps": 53370.0, "train/extr_critic_critic_opt_loss": 4874.8322164601295, "train/extr_critic_mag": 1.6779091358184814, "train/extr_critic_max": 1.6779091358184814, "train/extr_critic_mean": 1.5582147073275938, "train/extr_critic_min": 1.39985642409677, "train/extr_critic_std": 0.030596044510969974, "train/extr_return_normed_mag": 0.9719590389082584, "train/extr_return_normed_max": 0.3158460456162251, "train/extr_return_normed_mean": 0.05970624237885616, "train/extr_return_normed_min": -0.8692419294066029, "train/extr_return_normed_std": 0.046361658621230734, "train/extr_return_rate": 0.9995850342247874, "train/extr_return_raw_mag": 1.8145957697788482, "train/extr_return_raw_max": 1.8145957697788482, "train/extr_return_raw_mean": 1.5584560427172431, "train/extr_return_raw_min": 0.6295077947560203, "train/extr_return_raw_std": 0.046361658712986656, "train/extr_reward_mag": 0.2744859580335946, "train/extr_reward_max": 0.2744859580335946, "train/extr_reward_mean": 0.0022913379969735966, "train/extr_reward_min": 4.6979030364839904e-08, "train/extr_reward_std": 0.008797282795765865, "train/image_loss_mean": 0.08868226992526078, "train/image_loss_std": 0.10237733425177964, "train/model_loss_mean": 0.7258784245387674, "train/model_loss_std": 0.4963871797757783, "train/model_opt_grad_norm": 18.663131911179114, "train/model_opt_grad_steps": 53322.86699507389, "train/model_opt_loss": 3737.4534244631313, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5147.783251231527, "train/policy_entropy_mag": 1.3066881519233065, "train/policy_entropy_max": 1.3066881519233065, "train/policy_entropy_mean": 0.09923374311530532, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12617052555671465, "train/policy_logprob_mag": 6.551080250387709, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09903358609365125, "train/policy_logprob_min": -6.551080250387709, "train/policy_logprob_std": 0.635965021079397, "train/policy_randomness_mag": 0.6715049147605896, "train/policy_randomness_max": 0.6715049147605896, "train/policy_randomness_mean": 0.05099605834983253, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06483882777576376, "train/post_ent_mag": 23.554148744479775, "train/post_ent_max": 23.554148744479775, "train/post_ent_mean": 23.090394184507172, "train/post_ent_min": 22.730520783974033, "train/post_ent_std": 0.1752978679288197, "train/prior_ent_mag": 24.4927802156345, "train/prior_ent_max": 24.4927802156345, "train/prior_ent_mean": 22.21530234050281, "train/prior_ent_min": 21.106506451010116, "train/prior_ent_std": 0.4784603041087465, "train/rep_loss_mean": 1.0000419058823233, "train/rep_loss_std": 0.0013202733585032924, "train/reward_avg": 0.0023001534695131476, "train/reward_loss_mean": 0.017241211617227845, "train/reward_loss_std": 0.24551817550429422, "train/reward_max_data": 0.7683959386031616, "train/reward_max_pred": 0.2858047250456411, "train/reward_neg_acc": 0.9995365594995433, "train/reward_neg_loss": 0.003012637819938839, "train/reward_pos_acc": 0.16718114560572944, "train/reward_pos_loss": 4.193375503597547, "train/reward_pred": 0.0018074101799401671, "train/reward_rate": 0.00341556342364532, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.022165583446621895, "report/cont_loss_std": 0.2954355478286743, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 2.6543736457824707, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004048123024404049, "report/cont_pred": 0.9930680990219116, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08048923313617706, "report/image_loss_std": 0.0858934298157692, "report/model_loss_mean": 0.7196517586708069, "report/model_loss_std": 0.4974910318851471, "report/post_ent_mag": 22.960174560546875, "report/post_ent_max": 22.960174560546875, "report/post_ent_mean": 22.52548599243164, "report/post_ent_min": 22.15304183959961, "report/post_ent_std": 0.17145907878875732, "report/prior_ent_mag": 24.08837890625, "report/prior_ent_max": 24.08837890625, "report/prior_ent_mean": 22.181936264038086, "report/prior_ent_min": 21.18864631652832, "report/prior_ent_std": 0.43358972668647766, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002160644391551614, "report/reward_loss_mean": 0.016996901482343674, "report/reward_loss_std": 0.24803560972213745, "report/reward_max_data": 0.675000011920929, "report/reward_max_pred": 0.6205148696899414, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0027503673918545246, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.649862766265869, "report/reward_pred": 0.0020893621258437634, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.025108860805630684, "eval/cont_loss_std": 0.3337937891483307, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.945891380310059, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.005811672192066908, "eval/cont_pred": 0.9953340291976929, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.13274770975112915, "eval/image_loss_std": 0.1325158029794693, "eval/model_loss_mean": 0.7867217063903809, "eval/model_loss_std": 0.7866608500480652, "eval/post_ent_mag": 22.961997985839844, "eval/post_ent_max": 22.961997985839844, "eval/post_ent_mean": 22.514068603515625, "eval/post_ent_min": 22.109981536865234, "eval/post_ent_std": 0.17440345883369446, "eval/prior_ent_mag": 24.08837890625, "eval/prior_ent_max": 24.08837890625, "eval/prior_ent_mean": 22.16792869567871, "eval/prior_ent_min": 21.3164119720459, "eval/prior_ent_std": 0.4235728979110718, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.002572631696239114, "eval/reward_loss_mean": 0.028865160420536995, "eval/reward_loss_std": 0.4155639410018921, "eval/reward_max_data": 0.887499988079071, "eval/reward_max_pred": 0.5324628353118896, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.004315920174121857, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.288921356201172, "eval/reward_pred": 0.0018039505230262876, "eval/reward_rate": 0.00390625, "replay/size": 871121.0, "replay/inserts": 32336.0, "replay/samples": 32336.0, "replay/insert_wait_avg": 1.3496868684703557e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.682857227467004e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5032.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1341939480391898e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1919400691986, "timer/env.step_count": 4042.0, "timer/env.step_total": 37.956725120544434, "timer/env.step_frac": 0.03794944110219323, "timer/env.step_avg": 0.009390580188160424, "timer/env.step_min": 0.00766444206237793, "timer/env.step_max": 0.03803610801696777, "timer/replay._sample_count": 32336.0, "timer/replay._sample_total": 16.52564311027527, "timer/replay._sample_frac": 0.01652247178589735, "timer/replay._sample_avg": 0.0005110602149392402, "timer/replay._sample_min": 0.00040912628173828125, "timer/replay._sample_max": 0.02563929557800293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4671.0, "timer/agent.policy_total": 48.558791160583496, "timer/agent.policy_frac": 0.04854947257145857, "timer/agent.policy_avg": 0.010395802003978483, "timer/agent.policy_min": 0.00885915756225586, "timer/agent.policy_max": 0.08754825592041016, "timer/dataset_train_count": 2021.0, "timer/dataset_train_total": 0.20893168449401855, "timer/dataset_train_frac": 0.000208891589827812, "timer/dataset_train_avg": 0.00010338034858684738, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0004999637603759766, "timer/agent.train_count": 2021.0, "timer/agent.train_total": 901.419047832489, "timer/agent.train_frac": 0.9012460626008685, "timer/agent.train_avg": 0.446026248309, "timer/agent.train_min": 0.434114933013916, "timer/agent.train_max": 0.6782329082489014, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.482867956161499, "timer/agent.report_frac": 0.00048277529223849936, "timer/agent.report_avg": 0.2414339780807495, "timer/agent.report_min": 0.23712563514709473, "timer/agent.report_max": 0.2457423210144043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.1696090698242188e-05, "timer/dataset_eval_frac": 2.16919271482443e-08, "timer/dataset_eval_avg": 2.1696090698242188e-05, "timer/dataset_eval_min": 2.1696090698242188e-05, "timer/dataset_eval_max": 2.1696090698242188e-05, "fps": 32.32924613610408}
{"step": 871808, "time": 27224.259885787964, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 871856, "time": 27225.72388935089, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 872032, "time": 27231.100972175598, "episode/length": 238.0, "episode/score": 0.2562499940395355, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0}
{"step": 872040, "time": 27231.128046751022, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 872336, "time": 27240.39020204544, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 872344, "time": 27240.418347120285, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 872448, "time": 27243.823877096176, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 873000, "time": 27260.548817396164, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 873008, "time": 27261.02045559883, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 873352, "time": 27271.231466054916, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873360, "time": 27271.70200920105, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 873536, "time": 27277.195514202118, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 873688, "time": 27281.617862939835, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 873744, "time": 27283.55839586258, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 873992, "time": 27290.946761131287, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 874240, "time": 27298.735055208206, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 874336, "time": 27301.631560087204, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 874344, "time": 27301.658764362335, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874648, "time": 27311.023587465286, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874656, "time": 27311.492015361786, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 874792, "time": 27315.407736063004, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 874928, "time": 27319.783510684967, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 875136, "time": 27326.09649991989, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 875328, "time": 27331.964900255203, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 875792, "time": 27346.151558160782, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 875824, "time": 27347.12733221054, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 875928, "time": 27350.04542016983, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 876000, "time": 27352.464190244675, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876128, "time": 27356.346381902695, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 876368, "time": 27363.64158463478, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 876368, "time": 27363.648871421814, "episode/length": 213.0, "episode/score": 0.3343749940395355, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0}
{"step": 876544, "time": 27369.33655333519, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 876552, "time": 27369.47406744957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 876864, "time": 27379.46646142006, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 877040, "time": 27384.80353784561, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 877040, "time": 27384.809590816498, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 877080, "time": 27385.831075191498, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 877176, "time": 27388.73388195038, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 877240, "time": 27390.69681239128, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 877240, "time": 27390.702330112457, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 877328, "time": 27393.587867498398, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 877624, "time": 27402.52000617981, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 877744, "time": 27406.396134138107, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 878232, "time": 27420.97005200386, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 878232, "time": 27420.977650642395, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 879176, "time": 27449.655740737915, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879352, "time": 27455.012699365616, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879432, "time": 27457.523020982742, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 879488, "time": 27459.460627555847, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879552, "time": 27461.398235559464, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879552, "time": 27461.405108451843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 879936, "time": 27473.06201672554, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880032, "time": 27475.99734210968, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 880040, "time": 27476.02542614937, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 27477.230894088745, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 880048, "time": 27477.72648501396, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 880048, "time": 27477.911694049835, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 880048, "time": 27477.95694041252, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 880048, "time": 27478.406672477722, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 880048, "time": 27478.600603103638, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 880048, "time": 27479.25131559372, "eval_episode/length": 77.0, "eval_episode/score": 0.7593749761581421, "eval_episode/reward_rate": 0.01282051282051282}
{"step": 880048, "time": 27479.574336528778, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 880264, "time": 27485.97687935829, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 880368, "time": 27489.423880815506, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 880448, "time": 27491.85220861435, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 880544, "time": 27494.76163816452, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 880544, "time": 27494.76758956909, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 880720, "time": 27500.135570526123, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 880960, "time": 27507.431661605835, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 881056, "time": 27510.33317422867, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 881120, "time": 27512.28165268898, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 881136, "time": 27512.769882917404, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 881176, "time": 27513.768698453903, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 881264, "time": 27516.785736083984, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 881408, "time": 27521.162237405777, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 881616, "time": 27527.475702762604, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 881640, "time": 27527.986519813538, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 881664, "time": 27528.933284044266, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 881856, "time": 27534.745661973953, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 882048, "time": 27540.582448720932, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 882208, "time": 27545.432785987854, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 882216, "time": 27545.459008216858, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 882336, "time": 27549.389173030853, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 882488, "time": 27553.809923648834, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 882632, "time": 27558.19667696953, "episode/length": 152.0, "episode/score": 0.5249999761581421, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0}
{"step": 882648, "time": 27558.68769645691, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 882704, "time": 27560.608734607697, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 882792, "time": 27563.05301141739, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 882880, "time": 27565.945858478546, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 883032, "time": 27570.327177286148, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 883136, "time": 27573.699216604233, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 883432, "time": 27582.576036691666, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 883432, "time": 27582.581531763077, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 883680, "time": 27590.372245788574, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 884304, "time": 27609.384981155396, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 884320, "time": 27609.87574982643, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 884368, "time": 27611.345661640167, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 884848, "time": 27626.378405094147, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 884944, "time": 27629.312288999557, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 884960, "time": 27629.798510074615, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885008, "time": 27631.251101732254, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 885104, "time": 27634.186320781708, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885120, "time": 27634.677707910538, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 885192, "time": 27636.751163721085, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885344, "time": 27641.59833097458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 885824, "time": 27656.18817424774, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 885848, "time": 27656.699103355408, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 886136, "time": 27665.43912410736, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 886384, "time": 27673.3006567955, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 886480, "time": 27676.22673177719, "episode/length": 169.0, "episode/score": 0.47187501192092896, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.0}
{"step": 886728, "time": 27683.54435133934, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 886744, "time": 27684.037727594376, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 886880, "time": 27688.375742912292, "episode/length": 253.0, "episode/score": 0.20937499403953552, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0}
{"step": 887256, "time": 27699.792253017426, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887272, "time": 27700.2821290493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887280, "time": 27700.752492427826, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 887504, "time": 27707.574779510498, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 887584, "time": 27710.012402057648, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 887720, "time": 27713.936404705048, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 887904, "time": 27719.737278461456, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 887944, "time": 27720.727407693863, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 888208, "time": 27729.090181827545, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 888280, "time": 27731.061886310577, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 888448, "time": 27736.395468235016, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 888744, "time": 27745.15193748474, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 889056, "time": 27754.87673330307, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889288, "time": 27761.80400443077, "episode/length": 172.0, "episode/score": 0.4625000059604645, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.0}
{"step": 889392, "time": 27765.185771226883, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 889592, "time": 27771.04674386978, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889896, "time": 27780.256214141846, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 889992, "time": 27783.149722099304, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 889992, "time": 27783.156309366226, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 27785.67960834503, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 890032, "time": 27786.157746076584, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 890032, "time": 27786.351942777634, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 890032, "time": 27786.61069703102, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 890032, "time": 27787.187649965286, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 890032, "time": 27787.305387735367, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 890032, "time": 27787.349142313004, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 890032, "time": 27788.15053510666, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 890096, "time": 27790.076193094254, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 890224, "time": 27793.948792219162, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 890256, "time": 27794.934370279312, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890288, "time": 27795.909962892532, "episode/length": 23.0, "episode/score": 0.9281250238418579, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0}
{"step": 890584, "time": 27804.647275924683, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 890584, "time": 27804.65427184105, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 890592, "time": 27805.12472462654, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 890688, "time": 27808.051106214523, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 890776, "time": 27810.48811006546, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 890936, "time": 27815.349207162857, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 891040, "time": 27818.84057021141, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 891112, "time": 27820.805611371994, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 891192, "time": 27823.22802734375, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 891424, "time": 27830.469047307968, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 891512, "time": 27832.95907855034, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 891744, "time": 27840.233864307404, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 891760, "time": 27840.723212957382, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 891800, "time": 27841.734085083008, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 891920, "time": 27845.575518131256, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 892144, "time": 27852.5280649662, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 892256, "time": 27855.943696022034, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 892256, "time": 27855.951611042023, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 892320, "time": 27857.920870542526, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 892480, "time": 27862.800117969513, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 892488, "time": 27862.826334953308, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 892600, "time": 27866.24236059189, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 892832, "time": 27873.50068283081, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 893176, "time": 27884.296293258667, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 893192, "time": 27884.786824464798, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 893232, "time": 27886.257704019547, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 893576, "time": 27896.513508796692, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 893696, "time": 27900.381509304047, "episode/length": 179.0, "episode/score": 0.44062501192092896, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.0}
{"step": 893736, "time": 27901.397968769073, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 893920, "time": 27907.331104040146, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 894264, "time": 27917.579065322876, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 894328, "time": 27919.543382644653, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 894344, "time": 27920.044509410858, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 894512, "time": 27925.45973777771, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 894568, "time": 27926.941239118576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 894632, "time": 27928.876851320267, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 895312, "time": 27949.861419439316, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 895328, "time": 27950.35163450241, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 895472, "time": 27954.732818841934, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 895888, "time": 27967.45980167389, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896232, "time": 27977.664971113205, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896400, "time": 27982.988849639893, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 896576, "time": 27988.33119034767, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896624, "time": 27989.814883947372, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 896640, "time": 27990.30431842804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 896880, "time": 27997.72856736183, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897480, "time": 28015.708374023438, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 897496, "time": 28016.19982790947, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 897576, "time": 28018.650798797607, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 897624, "time": 28020.102415323257, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897640, "time": 28020.59367799759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 897672, "time": 28021.567302942276, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 897816, "time": 28025.99311065674, "episode/length": 21.0, "episode/score": 0.934374988079071, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.0}
{"step": 898256, "time": 28039.643670082092, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 898304, "time": 28041.095831155777, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 898304, "time": 28041.10112452507, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 898544, "time": 28048.39475250244, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898712, "time": 28053.275140285492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 898776, "time": 28055.213900327682, "episode/length": 137.0, "episode/score": 0.5718749761581421, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0}
{"step": 899072, "time": 28064.561994314194, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 899168, "time": 28067.4861536026, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 899240, "time": 28069.44027042389, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 899488, "time": 28077.206098794937, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 899576, "time": 28079.643088817596, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 899784, "time": 28086.049033880234, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 899792, "time": 28086.543531656265, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 899888, "time": 28089.460022449493, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 28094.049746513367, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 900016, "time": 28094.551032066345, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 900016, "time": 28095.389847755432, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 900016, "time": 28095.808296203613, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 900016, "time": 28096.350200653076, "eval_episode/length": 151.0, "eval_episode/score": 0.528124988079071, "eval_episode/reward_rate": 0.006578947368421052}
{"step": 900016, "time": 28096.565358877182, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 900016, "time": 28098.036754369736, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 900016, "time": 28099.071557998657, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 900208, "time": 28104.887388944626, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 900568, "time": 28115.57748222351, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 900712, "time": 28120.087128400803, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 900856, "time": 28124.472950220108, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901088, "time": 28131.81713938713, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901552, "time": 28146.54838371277, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901600, "time": 28148.002707719803, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 901800, "time": 28153.873838186264, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 901888, "time": 28156.78968334198, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902160, "time": 28165.04396557808, "episode/length": 44.0, "episode/score": 0.862500011920929, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.0}
{"step": 902232, "time": 28167.014004945755, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 902368, "time": 28171.37676715851, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 902520, "time": 28175.834879159927, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902672, "time": 28180.750388145447, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 902712, "time": 28181.736318826675, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 902880, "time": 28187.0837829113, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 902968, "time": 28189.533719539642, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 903168, "time": 28195.87050461769, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 903224, "time": 28197.350972890854, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 903392, "time": 28202.680128335953, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 903392, "time": 28202.685794591904, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 903528, "time": 28206.738636016846, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 903632, "time": 28210.121313095093, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 903808, "time": 28215.49074268341, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 903880, "time": 28217.46347641945, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 903897, "time": 28218.975400686264, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.225684322527985, "train/action_min": 0.0, "train/action_std": 1.8599008873327454, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011806681724404222, "train/actor_opt_grad_steps": 55390.0, "train/actor_opt_loss": -21.260843210552462, "train/adv_mag": 0.9088751925757869, "train/adv_max": 0.26634474417463466, "train/adv_mean": 0.00011961981148198531, "train/adv_min": -0.8619026076141282, "train/adv_std": 0.03036529747815571, "train/cont_avg": 0.9943835509950248, "train/cont_loss_mean": 0.02018034385762812, "train/cont_loss_std": 0.25321208731507633, "train/cont_neg_acc": 0.26323146699228095, "train/cont_neg_loss": 2.8732901424822854, "train/cont_pos_acc": 0.9998974224821252, "train/cont_pos_loss": 0.004289326647792326, "train/cont_pred": 0.994323402791474, "train/cont_rate": 0.9943835509950248, "train/dyn_loss_mean": 1.0000003771995432, "train/dyn_loss_std": 1.206361938879561e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.15317996078870486, "train/extr_critic_critic_opt_grad_steps": 55390.0, "train/extr_critic_critic_opt_loss": 5043.684041948461, "train/extr_critic_mag": 1.6730519491641676, "train/extr_critic_max": 1.6730519491641676, "train/extr_critic_mean": 1.5523183826190323, "train/extr_critic_min": 1.3807417160242945, "train/extr_critic_std": 0.0293916022006552, "train/extr_return_normed_mag": 0.9334016718081574, "train/extr_return_normed_max": 0.3180358481051317, "train/extr_return_normed_mean": 0.057111396570110794, "train/extr_return_normed_min": -0.8291253029410519, "train/extr_return_normed_std": 0.04350783690736068, "train/extr_return_rate": 0.9996515115102133, "train/extr_return_raw_mag": 1.8133623333119635, "train/extr_return_raw_max": 1.8133623333119635, "train/extr_return_raw_mean": 1.5524379572465052, "train/extr_return_raw_min": 0.6662011822657798, "train/extr_return_raw_std": 0.043507836814691773, "train/extr_reward_mag": 0.2878298700152345, "train/extr_reward_max": 0.2878298700152345, "train/extr_reward_mean": 0.0023528620205699137, "train/extr_reward_min": 1.7140042129440687e-07, "train/extr_reward_std": 0.008811466845299178, "train/image_loss_mean": 0.08888910951750789, "train/image_loss_std": 0.10313462087912346, "train/model_loss_mean": 0.7261838856621168, "train/model_loss_std": 0.4925857002091645, "train/model_opt_grad_norm": 18.34153799512493, "train/model_opt_grad_steps": 55341.119402985074, "train/model_opt_loss": 4084.365122629042, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5646.766169154229, "train/policy_entropy_mag": 1.2865293577535828, "train/policy_entropy_max": 1.2865293577535828, "train/policy_entropy_mean": 0.09719548300279314, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12191936395951171, "train/policy_logprob_mag": 6.551080257738407, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0971392244841922, "train/policy_logprob_min": -6.551080257738407, "train/policy_logprob_std": 0.6341013164069522, "train/policy_randomness_mag": 0.6611453416335642, "train/policy_randomness_max": 0.6611453416335642, "train/policy_randomness_mean": 0.04994859957872932, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06265416253932674, "train/post_ent_mag": 23.90848131322149, "train/post_ent_max": 23.90848131322149, "train/post_ent_mean": 23.462095782531435, "train/post_ent_min": 23.100305528783085, "train/post_ent_std": 0.17210733786744264, "train/prior_ent_mag": 24.729070957620344, "train/prior_ent_max": 24.729070957620344, "train/prior_ent_mean": 23.4406924081679, "train/prior_ent_min": 22.360389111646967, "train/prior_ent_std": 0.37142182048873523, "train/rep_loss_mean": 1.0000003771995432, "train/rep_loss_std": 1.206361938879561e-05, "train/reward_avg": 0.002375300016593876, "train/reward_loss_mean": 0.01711418240016039, "train/reward_loss_std": 0.2395020266902165, "train/reward_max_data": 0.7718905464407817, "train/reward_max_pred": 0.3214729793036162, "train/reward_neg_acc": 0.9995124455708176, "train/reward_neg_loss": 0.0031568121879746148, "train/reward_pos_acc": 0.1976919365020431, "train/reward_pos_loss": 4.052836006089133, "train/reward_pred": 0.001918936226475261, "train/reward_rate": 0.003468983208955224, "train_stats/mean_log_entropy": 0.0803280465982177, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.015122149139642715, "report/cont_loss_std": 0.21221283078193665, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 1.6748919486999512, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0036979722790420055, "report/cont_pred": 0.9925864934921265, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0926915854215622, "report/image_loss_std": 0.10344544053077698, "report/model_loss_mean": 0.7264388799667358, "report/model_loss_std": 0.5276047587394714, "report/post_ent_mag": 23.689804077148438, "report/post_ent_max": 23.689804077148438, "report/post_ent_mean": 23.244489669799805, "report/post_ent_min": 22.876567840576172, "report/post_ent_std": 0.16724546253681183, "report/prior_ent_mag": 23.820810317993164, "report/prior_ent_max": 23.820810317993164, "report/prior_ent_mean": 23.096195220947266, "report/prior_ent_min": 22.073627471923828, "report/prior_ent_std": 0.27854007482528687, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0024383547715842724, "report/reward_loss_mean": 0.01862516440451145, "report/reward_loss_std": 0.2876562476158142, "report/reward_max_data": 0.7250000238418579, "report/reward_max_pred": 0.558275580406189, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0024614029098302126, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 4.140384674072266, "report/reward_pred": 0.001815152121707797, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.04579875245690346, "eval/cont_loss_std": 0.5755281448364258, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.950404167175293, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.005103633739054203, "eval/cont_pred": 0.9951769113540649, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.16790497303009033, "eval/image_loss_std": 0.16730311512947083, "eval/model_loss_mean": 0.8552184104919434, "eval/model_loss_std": 1.097083568572998, "eval/post_ent_mag": 23.693876266479492, "eval/post_ent_max": 23.693876266479492, "eval/post_ent_mean": 23.27423858642578, "eval/post_ent_min": 22.9234561920166, "eval/post_ent_std": 0.1617628037929535, "eval/prior_ent_mag": 23.951915740966797, "eval/prior_ent_max": 23.951915740966797, "eval/prior_ent_mean": 23.113731384277344, "eval/prior_ent_min": 22.213272094726562, "eval/prior_ent_std": 0.2884202003479004, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0037689208984375, "eval/reward_loss_mean": 0.041514717042446136, "eval/reward_loss_std": 0.5670660138130188, "eval/reward_max_data": 0.846875011920929, "eval/reward_max_pred": 0.29796910285949707, "eval/reward_neg_acc": 0.9970559477806091, "eval/reward_neg_loss": 0.004369845613837242, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.611639499664307, "eval/reward_pred": 0.002087637782096863, "eval/reward_rate": 0.0048828125, "replay/size": 903393.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.3697617232474467e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.657734072320699e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1648951458329914e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2333369255066, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.21384143829346, "timer/env.step_frac": 0.03820492681813051, "timer/env.step_avg": 0.009472940366458467, "timer/env.step_min": 0.007587909698486328, "timer/env.step_max": 0.039087772369384766, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.464388608932495, "timer/replay._sample_frac": 0.016460547755327112, "timer/replay._sample_avg": 0.0005101756509956773, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.028009653091430664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4629.0, "timer/agent.policy_total": 48.477017402648926, "timer/agent.policy_frac": 0.048465708563220286, "timer/agent.policy_avg": 0.010472460013534008, "timer/agent.policy_min": 0.008981943130493164, "timer/agent.policy_max": 0.08521842956542969, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.21151304244995117, "timer/dataset_train_frac": 0.0002114637001602995, "timer/dataset_train_avg": 0.00010486516730290092, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0004780292510986328, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 901.6405885219574, "timer/agent.train_frac": 0.9014302515585001, "timer/agent.train_avg": 0.4470206189994831, "timer/agent.train_min": 0.43542003631591797, "timer/agent.train_max": 0.6837334632873535, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48872828483581543, "timer/agent.report_frac": 0.0004886142730835755, "timer/agent.report_avg": 0.24436414241790771, "timer/agent.report_min": 0.2397143840789795, "timer/agent.report_max": 0.24901390075683594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.3603439331054688e-05, "timer/dataset_eval_frac": 2.3597933061905713e-08, "timer/dataset_eval_avg": 2.3603439331054688e-05, "timer/dataset_eval_min": 2.3603439331054688e-05, "timer/dataset_eval_max": 2.3603439331054688e-05, "fps": 32.26382118336068}
{"step": 903968, "time": 28221.119190216064, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 904064, "time": 28224.04611492157, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 904176, "time": 28227.45996952057, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 904280, "time": 28230.40240263939, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 904312, "time": 28231.38051533699, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 904656, "time": 28242.136266231537, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 904680, "time": 28242.644105911255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 904800, "time": 28246.49059033394, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 904992, "time": 28252.27642083168, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 905176, "time": 28257.62140393257, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 905248, "time": 28260.041352510452, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 905280, "time": 28261.007932662964, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 905352, "time": 28262.971177339554, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 905528, "time": 28268.388965845108, "episode/length": 34.0, "episode/score": 0.893750011920929, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.0}
{"step": 905840, "time": 28278.0868871212, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906000, "time": 28282.94561266899, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 906216, "time": 28289.3091173172, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 906232, "time": 28289.80412387848, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 906280, "time": 28291.25397157669, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 906648, "time": 28302.538445711136, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 906712, "time": 28304.488454580307, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 906808, "time": 28307.408884763718, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 906840, "time": 28308.416347265244, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 907112, "time": 28316.674655675888, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907112, "time": 28316.680332183838, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 907152, "time": 28318.154309272766, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 907592, "time": 28331.441735506058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 907656, "time": 28333.40746641159, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 907704, "time": 28334.876787662506, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 907784, "time": 28337.31312417984, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 907920, "time": 28341.688943624496, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 908024, "time": 28344.64439058304, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 908192, "time": 28349.99484229088, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 908352, "time": 28354.886265039444, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 908672, "time": 28364.665058135986, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 908960, "time": 28373.40042948723, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 908960, "time": 28373.408661842346, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909152, "time": 28379.278223991394, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 909248, "time": 28382.203394651413, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 909376, "time": 28386.712426662445, "episode/length": 51.0, "episode/score": 0.840624988079071, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.0}
{"step": 909528, "time": 28391.126811742783, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 909616, "time": 28394.05411195755, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 909968, "time": 28404.71851158142, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 28407.033455610275, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 910000, "time": 28407.5248837471, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 910000, "time": 28407.928253412247, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 910000, "time": 28407.972044229507, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 910000, "time": 28408.22549700737, "eval_episode/length": 129.0, "eval_episode/score": 0.596875011920929, "eval_episode/reward_rate": 0.007692307692307693}
{"step": 910000, "time": 28408.78452563286, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 910000, "time": 28408.828395843506, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 910000, "time": 28410.016352653503, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 910080, "time": 28412.441668748856, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 910096, "time": 28412.932747364044, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910240, "time": 28417.42143511772, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 910312, "time": 28419.3883330822, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 910408, "time": 28422.32098555565, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 910504, "time": 28425.230413913727, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 910592, "time": 28428.13805603981, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 911216, "time": 28447.17432308197, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 911320, "time": 28450.09836125374, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 911376, "time": 28452.007058382034, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 911448, "time": 28453.95017838478, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 911560, "time": 28457.353846788406, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 911696, "time": 28461.690442085266, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 912072, "time": 28472.869133472443, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 912408, "time": 28483.127089500427, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912448, "time": 28484.57631587982, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 912624, "time": 28489.916814804077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 912872, "time": 28497.18965601921, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 912904, "time": 28498.162992239, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 913008, "time": 28501.548221111298, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 913264, "time": 28509.3891851902, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 913480, "time": 28515.73969769478, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 913480, "time": 28515.74494743347, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 913560, "time": 28518.174635648727, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 913632, "time": 28520.59596300125, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914184, "time": 28537.21683573723, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 914328, "time": 28541.586940288544, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 914384, "time": 28543.530154943466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 914752, "time": 28554.720901489258, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 914776, "time": 28555.23701262474, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 914936, "time": 28560.107926130295, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915184, "time": 28567.99151945114, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 915184, "time": 28567.999097824097, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915288, "time": 28570.935924053192, "episode/length": 112.0, "episode/score": 0.6499999761581421, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.0}
{"step": 915576, "time": 28579.71536374092, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915768, "time": 28585.53052997589, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 915792, "time": 28586.511311531067, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 915968, "time": 28591.86690235138, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 916008, "time": 28592.860521793365, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 916056, "time": 28594.31069779396, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 916232, "time": 28599.772825717926, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 916376, "time": 28604.136400461197, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 916432, "time": 28606.06418323517, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 917008, "time": 28623.53387093544, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 917096, "time": 28626.07453560829, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 917368, "time": 28634.369214057922, "episode/length": 141.0, "episode/score": 0.559374988079071, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0}
{"step": 917376, "time": 28634.84647345543, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 917496, "time": 28638.301166772842, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917536, "time": 28640.25438761711, "episode/length": 195.0, "episode/score": 0.390625, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0}
{"step": 917600, "time": 28642.233166217804, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 917792, "time": 28648.05965280533, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 917856, "time": 28649.993472337723, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 918144, "time": 28658.808814048767, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 918368, "time": 28665.617587327957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 918456, "time": 28668.06173968315, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 918552, "time": 28670.98985671997, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 918768, "time": 28677.84364962578, "episode/length": 153.0, "episode/score": 0.5218750238418579, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.0}
{"step": 918912, "time": 28682.315854787827, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 919216, "time": 28691.677433490753, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 919216, "time": 28691.68527531624, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 919752, "time": 28707.78704380989, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 919808, "time": 28709.728027820587, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 919872, "time": 28711.67266511917, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 28719.487761497498, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 920088, "time": 28719.906620025635, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 920088, "time": 28720.134710788727, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 920088, "time": 28720.46325802803, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 920088, "time": 28720.601987361908, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 920088, "time": 28720.93933916092, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 920088, "time": 28721.162904262543, "eval_episode/length": 156.0, "eval_episode/score": 0.512499988079071, "eval_episode/reward_rate": 0.006369426751592357}
{"step": 920088, "time": 28722.179247379303, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 920104, "time": 28722.6717543602, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920256, "time": 28727.526592731476, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 920376, "time": 28730.980288743973, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 920456, "time": 28733.43357014656, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 920496, "time": 28734.888909578323, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 920744, "time": 28742.20176911354, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 920928, "time": 28748.17351293564, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 921080, "time": 28752.5840985775, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921160, "time": 28755.037398815155, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 921208, "time": 28756.50161266327, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 921224, "time": 28757.000390529633, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 921360, "time": 28761.385553598404, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 921424, "time": 28763.34495973587, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 921624, "time": 28769.212752103806, "episode/length": 140.0, "episode/score": 0.5625, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0}
{"step": 921928, "time": 28778.621831178665, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 922144, "time": 28785.430633544922, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 922192, "time": 28786.91832947731, "episode/length": 32.0, "episode/score": 0.8999999761581421, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.0}
{"step": 922216, "time": 28787.43286705017, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 922288, "time": 28789.85266137123, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 922624, "time": 28800.10750937462, "episode/length": 50.0, "episode/score": 0.84375, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.0}
{"step": 922736, "time": 28803.53017473221, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 923240, "time": 28818.701289653778, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 923240, "time": 28818.708943128586, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923256, "time": 28819.19782280922, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 923472, "time": 28825.989026784897, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923736, "time": 28833.787623643875, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 923928, "time": 28839.716071367264, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 923936, "time": 28840.190217733383, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924120, "time": 28845.57365345955, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 924424, "time": 28854.78628396988, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 924504, "time": 28857.235445976257, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 924600, "time": 28860.195934057236, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 924600, "time": 28860.20240855217, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 924744, "time": 28864.58713245392, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 924824, "time": 28867.154942274094, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 924936, "time": 28870.569561719894, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 924936, "time": 28870.5782225132, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 925240, "time": 28879.88013100624, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 925296, "time": 28881.80174422264, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 925656, "time": 28892.511782169342, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 925752, "time": 28895.96707010269, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 926032, "time": 28904.714126825333, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 926080, "time": 28906.1683177948, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 926088, "time": 28906.19694542885, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 926216, "time": 28910.087259054184, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 926280, "time": 28912.033890485764, "episode/length": 167.0, "episode/score": 0.4781250059604645, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.0}
{"step": 926616, "time": 28922.191665410995, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 926976, "time": 28933.55818414688, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 927048, "time": 28935.5339615345, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 927160, "time": 28938.95421719551, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 927536, "time": 28950.51572537422, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 927552, "time": 28951.001374721527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 927600, "time": 28952.448596954346, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 928064, "time": 28966.618215322495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928344, "time": 28974.905321598053, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928392, "time": 28976.36925816536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928504, "time": 28979.762194871902, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 928592, "time": 28982.667362451553, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 928664, "time": 28984.62807917595, "episode/length": 33.0, "episode/score": 0.8968750238418579, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.0}
{"step": 928848, "time": 28990.56426525116, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 928968, "time": 28993.99445080757, "episode/length": 176.0, "episode/score": 0.44999998807907104, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.0}
{"step": 929008, "time": 28995.42651128769, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 929056, "time": 28996.881791591644, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 929272, "time": 29003.19492816925, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 929472, "time": 29009.48298382759, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 929472, "time": 29009.488829135895, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 929808, "time": 29019.781141519547, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 29028.124472141266, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 930072, "time": 29029.117905139923, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 930072, "time": 29029.422751903534, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 930072, "time": 29029.44805455208, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 930072, "time": 29029.734992980957, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 930072, "time": 29030.54908967018, "eval_episode/length": 159.0, "eval_episode/score": 0.503125011920929, "eval_episode/reward_rate": 0.00625}
{"step": 930072, "time": 29030.660024166107, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 930072, "time": 29031.244289159775, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 930272, "time": 29037.52320957184, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 930320, "time": 29038.975695371628, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 930376, "time": 29040.477937221527, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 930448, "time": 29042.873559951782, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 930616, "time": 29047.8597574234, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 930976, "time": 29059.018156051636, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931096, "time": 29062.463061094284, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 931160, "time": 29064.42102956772, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 931232, "time": 29066.832748174667, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 931384, "time": 29071.231039762497, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 931504, "time": 29075.123830795288, "episode/length": 65.0, "episode/score": 0.796875, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.0}
{"step": 931584, "time": 29077.678727388382, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931760, "time": 29083.02647471428, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 931784, "time": 29083.534184217453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 931792, "time": 29084.022045612335, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 931920, "time": 29088.006209373474, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 932120, "time": 29093.89601445198, "episode/length": 41.0, "episode/score": 0.871874988079071, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.0}
{"step": 932560, "time": 29107.616982221603, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 932688, "time": 29111.511870622635, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 932768, "time": 29113.953748226166, "episode/length": 147.0, "episode/score": 0.5406249761581421, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.0}
{"step": 932992, "time": 29120.776046037674, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 933152, "time": 29125.65523004532, "episode/length": 205.0, "episode/score": 0.359375, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.0}
{"step": 933408, "time": 29133.455515623093, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 933408, "time": 29133.464375257492, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934104, "time": 29155.043221473694, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934120, "time": 29155.531992673874, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 934232, "time": 29158.95045375824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 934416, "time": 29164.7731423378, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 934480, "time": 29166.82598543167, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 934720, "time": 29174.134172916412, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 935080, "time": 29184.83359527588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935216, "time": 29189.204088926315, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 935248, "time": 29190.18605518341, "episode/length": 229.0, "episode/score": 0.28437501192092896, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.0}
{"step": 935296, "time": 29191.646014213562, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 935304, "time": 29191.674127340317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 935552, "time": 29199.551543951035, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 935688, "time": 29203.474231243134, "episode/length": 120.0, "episode/score": 0.625, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0}
{"step": 935984, "time": 29212.719960689545, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 935992, "time": 29212.747240304947, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 936032, "time": 29214.17526602745, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 936064, "time": 29215.143946409225, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 936169, "time": 29219.08141374588, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2376385679339417, "train/action_min": 0.0, "train/action_std": 1.8552746926203814, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011307389687488574, "train/actor_opt_grad_steps": 57405.0, "train/actor_opt_loss": -21.61314586129519, "train/adv_mag": 0.8869540883172856, "train/adv_max": 0.26524441962194917, "train/adv_mean": -0.0001657457535540095, "train/adv_min": -0.8510540655933985, "train/adv_std": 0.029856679412434892, "train/cont_avg": 0.9943049969059405, "train/cont_loss_mean": 0.020767814104011892, "train/cont_loss_std": 0.2536728451729263, "train/cont_neg_acc": 0.2396714719805387, "train/cont_neg_loss": 2.8925099032792714, "train/cont_pos_acc": 0.9998590019669863, "train/cont_pos_loss": 0.004485354038407233, "train/cont_pred": 0.9942147194749058, "train/cont_rate": 0.9943049969059405, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.11234098885872282, "train/extr_critic_critic_opt_grad_steps": 57405.0, "train/extr_critic_critic_opt_loss": 7285.67364924969, "train/extr_critic_mag": 1.6662914009377507, "train/extr_critic_max": 1.6662914009377507, "train/extr_critic_mean": 1.5215349704912393, "train/extr_critic_min": 1.3185846351160861, "train/extr_critic_std": 0.031045943286528092, "train/extr_return_normed_mag": 0.9108258757260767, "train/extr_return_normed_max": 0.3138049002921227, "train/extr_return_normed_mean": 0.05859853380756213, "train/extr_return_normed_min": -0.8144377670665779, "train/extr_return_normed_std": 0.044646898367543625, "train/extr_return_rate": 0.9995923237045212, "train/extr_return_raw_mag": 1.7765755859932097, "train/extr_return_raw_max": 1.7765755859932097, "train/extr_return_raw_mean": 1.5213692837422437, "train/extr_return_raw_min": 0.6483329186345091, "train/extr_return_raw_std": 0.04464689834910159, "train/extr_reward_mag": 0.26461787861172514, "train/extr_reward_max": 0.26461787861172514, "train/extr_reward_mean": 0.0021745182085657804, "train/extr_reward_min": 1.3632349448628944e-07, "train/extr_reward_std": 0.008122214058524754, "train/image_loss_mean": 0.09005187444462634, "train/image_loss_std": 0.10410594184062269, "train/model_loss_mean": 0.729251755346166, "train/model_loss_std": 0.5089741356965929, "train/model_opt_grad_norm": 18.429315766291833, "train/model_opt_grad_steps": 57354.20297029703, "train/model_opt_loss": 3825.27172247254, "train/model_opt_model_opt_grad_overflow": 0.0049504950495049506, "train/model_opt_model_opt_grad_scale": 5222.772277227723, "train/policy_entropy_mag": 1.291654646396637, "train/policy_entropy_max": 1.291654646396637, "train/policy_entropy_mean": 0.09653822635069932, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12064633662305256, "train/policy_logprob_mag": 6.5510802646674735, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0968956508406318, "train/policy_logprob_min": -6.5510802646674735, "train/policy_logprob_std": 0.6355802800395701, "train/policy_randomness_mag": 0.6637792215488925, "train/policy_randomness_max": 0.6637792215488925, "train/policy_randomness_mean": 0.04961083622852174, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06199995577704198, "train/post_ent_mag": 23.728703073935932, "train/post_ent_max": 23.728703073935932, "train/post_ent_mean": 23.332516141457134, "train/post_ent_min": 22.99705693273261, "train/post_ent_std": 0.15667930924066223, "train/prior_ent_mag": 24.03254730866687, "train/prior_ent_max": 24.03254730866687, "train/prior_ent_mean": 23.185658804260857, "train/prior_ent_min": 22.31063474522959, "train/prior_ent_std": 0.29004590523124923, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.002513273634099503, "train/reward_loss_mean": 0.01843204193905291, "train/reward_loss_std": 0.25208396395889693, "train/reward_max_data": 0.7946782171136082, "train/reward_max_pred": 0.31686744359460206, "train/reward_neg_acc": 0.999480780693564, "train/reward_neg_loss": 0.0033196621311662516, "train/reward_pos_acc": 0.18818254221230746, "train/reward_pos_loss": 4.037493401765824, "train/reward_pred": 0.002009242477407218, "train/reward_rate": 0.0037370436262376236, "train_stats/mean_log_entropy": 0.07973950920260955, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.03068007156252861, "report/cont_loss_std": 0.29233506321907043, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.616039991378784, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.005183425731956959, "report/cont_pred": 0.9928737282752991, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11707772314548492, "report/image_loss_std": 0.11794121563434601, "report/model_loss_mean": 0.7823360562324524, "report/model_loss_std": 0.6750611662864685, "report/post_ent_mag": 23.518888473510742, "report/post_ent_max": 23.518888473510742, "report/post_ent_mean": 23.163379669189453, "report/post_ent_min": 22.759464263916016, "report/post_ent_std": 0.15789583325386047, "report/prior_ent_mag": 24.142261505126953, "report/prior_ent_max": 24.142261505126953, "report/prior_ent_mean": 23.213977813720703, "report/prior_ent_min": 22.222740173339844, "report/prior_ent_std": 0.29482293128967285, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00554504431784153, "report/reward_loss_mean": 0.03457826003432274, "report/reward_loss_std": 0.3570127785205841, "report/reward_max_data": 0.918749988079071, "report/reward_max_pred": 0.3856734037399292, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.004138453863561153, "report/reward_pos_acc": 0.25, "report/reward_pos_loss": 3.9004337787628174, "report/reward_pred": 0.0027034389786422253, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.03779083862900734, "eval/cont_loss_std": 0.5578804016113281, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.8948822021484375, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00414465693756938, "eval/cont_pred": 0.9959537982940674, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15985292196273804, "eval/image_loss_std": 0.1406857669353485, "eval/model_loss_mean": 0.8264025449752808, "eval/model_loss_std": 0.9515916705131531, "eval/post_ent_mag": 23.518451690673828, "eval/post_ent_max": 23.518451690673828, "eval/post_ent_mean": 23.114662170410156, "eval/post_ent_min": 22.811248779296875, "eval/post_ent_std": 0.16075143218040466, "eval/prior_ent_mag": 23.88993263244629, "eval/prior_ent_max": 23.88993263244629, "eval/prior_ent_mean": 23.176246643066406, "eval/prior_ent_min": 22.41377067565918, "eval/prior_ent_std": 0.27651137113571167, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0024139403831213713, "eval/reward_loss_mean": 0.02875877171754837, "eval/reward_loss_std": 0.4527364671230316, "eval/reward_max_data": 0.809374988079071, "eval/reward_max_pred": 0.1668548583984375, "eval/reward_neg_acc": 0.9990195631980896, "eval/reward_neg_loss": 0.002921729115769267, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.617204666137695, "eval/reward_pred": 0.001495018252171576, "eval/reward_rate": 0.00390625, "replay/size": 935665.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.360933320854463e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.722303308232562e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5016.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1440859647078566e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1002366542816, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.093353033065796, "timer/env.step_frac": 0.03808953506550769, "timer/env.step_avg": 0.009443072145033662, "timer/env.step_min": 0.007616519927978516, "timer/env.step_max": 0.03506326675415039, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.558637619018555, "timer/replay._sample_frac": 0.016556978002938524, "timer/replay._sample_avg": 0.0005130961086706295, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.011002302169799805, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4661.0, "timer/agent.policy_total": 48.271994829177856, "timer/agent.policy_frac": 0.04826715669087948, "timer/agent.policy_avg": 0.01035657473271355, "timer/agent.policy_min": 0.008496761322021484, "timer/agent.policy_max": 0.08329224586486816, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.25396084785461426, "timer/dataset_train_frac": 0.00025393539422029394, "timer/dataset_train_avg": 0.00012591018733495998, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.04408693313598633, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 901.8766803741455, "timer/agent.train_frac": 0.9017862883337259, "timer/agent.train_avg": 0.44713766999213955, "timer/agent.train_min": 0.4351623058319092, "timer/agent.train_max": 0.6894450187683105, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4812431335449219, "timer/agent.report_frac": 0.00048119490017807065, "timer/agent.report_avg": 0.24062156677246094, "timer/agent.report_min": 0.23543119430541992, "timer/agent.report_max": 0.24581193923950195, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7176993886637495e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 32.2682098449104}
{"step": 936312, "time": 29223.23371696472, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 936544, "time": 29230.618005514145, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937112, "time": 29247.681515455246, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 937240, "time": 29251.591840982437, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 937336, "time": 29254.5046312809, "episode/length": 254.0, "episode/score": 0.20624999701976776, "episode/reward_rate": 0.00392156862745098, "episode/intrinsic_return": 0.0}
{"step": 937344, "time": 29254.977521657944, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 937344, "time": 29254.983226776123, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 937392, "time": 29256.555346012115, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 937608, "time": 29262.91051530838, "episode/length": 239.0, "episode/score": 0.25312501192092896, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.0}
{"step": 937976, "time": 29274.087320804596, "episode/length": 107.0, "episode/score": 0.6656249761581421, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.0}
{"step": 938232, "time": 29281.84370470047, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 938296, "time": 29283.78504872322, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 938384, "time": 29286.783739328384, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 938688, "time": 29295.99099779129, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 939184, "time": 29311.01464676857, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 939552, "time": 29322.330622673035, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939648, "time": 29325.27303290367, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939656, "time": 29325.301863193512, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 939800, "time": 29329.678985357285, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 29338.697115659714, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 940056, "time": 29339.160583019257, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 940056, "time": 29339.319193840027, "eval_episode/length": 32.0, "eval_episode/score": 0.8999999761581421, "eval_episode/reward_rate": 0.030303030303030304}
{"step": 940056, "time": 29339.343369483948, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 940056, "time": 29339.458463430405, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 940056, "time": 29339.689931869507, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 940056, "time": 29340.478621721268, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 940056, "time": 29340.483911514282, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 940288, "time": 29347.82407450676, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940384, "time": 29350.726624011993, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 940536, "time": 29355.139789819717, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 940544, "time": 29355.617571353912, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940608, "time": 29357.59020638466, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 940872, "time": 29365.390013694763, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 941496, "time": 29384.51348376274, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941608, "time": 29387.92445039749, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 941648, "time": 29389.375855207443, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 941864, "time": 29395.702886104584, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 941968, "time": 29399.08774280548, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942008, "time": 29400.075791835785, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 942392, "time": 29412.325297355652, "episode/length": 47.0, "episode/score": 0.8531249761581421, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.0}
{"step": 942696, "time": 29421.6186068058, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942792, "time": 29424.541300296783, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 942848, "time": 29426.47637486458, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 942848, "time": 29426.482612371445, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 942856, "time": 29426.511737823486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943328, "time": 29441.241209983826, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 943496, "time": 29446.099554538727, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 943552, "time": 29448.008686065674, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 943920, "time": 29459.157727241516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 943936, "time": 29459.645626544952, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 943984, "time": 29461.12443304062, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 944080, "time": 29464.06568670273, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 944280, "time": 29470.06106901169, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 944328, "time": 29471.556522846222, "episode/length": 184.0, "episode/score": 0.42500001192092896, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.0}
{"step": 944424, "time": 29474.4637696743, "episode/length": 203.0, "episode/score": 0.3656249940395355, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.0}
{"step": 944528, "time": 29477.906101942062, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 944704, "time": 29483.2448554039, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 944944, "time": 29490.52627968788, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 945296, "time": 29501.283367872238, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 945376, "time": 29503.70273041725, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 945512, "time": 29507.62144470215, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 945664, "time": 29512.445039987564, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 945680, "time": 29512.932471513748, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 945768, "time": 29515.404116868973, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 946096, "time": 29525.61103129387, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 946296, "time": 29531.59499526024, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 946360, "time": 29533.572366714478, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 946448, "time": 29536.462115764618, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 946528, "time": 29538.91621375084, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 946752, "time": 29545.735190153122, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 946840, "time": 29548.206191539764, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 947168, "time": 29558.48064637184, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 947472, "time": 29567.749289751053, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 947488, "time": 29568.234234571457, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 947608, "time": 29571.634506225586, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 947960, "time": 29582.336711645126, "episode/length": 43.0, "episode/score": 0.8656250238418579, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.0}
{"step": 947976, "time": 29582.82782268524, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948208, "time": 29590.181317090988, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 948264, "time": 29591.670458078384, "episode/length": 216.0, "episode/score": 0.32499998807907104, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.0}
{"step": 948408, "time": 29596.04796051979, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948608, "time": 29604.527967453003, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 948744, "time": 29608.437145233154, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 948752, "time": 29608.924077510834, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 948760, "time": 29608.951691627502, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949128, "time": 29620.208352804184, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 949304, "time": 29625.53421330452, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 949352, "time": 29626.991750478745, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 949464, "time": 29630.399396181107, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 949768, "time": 29639.63951611519, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 949784, "time": 29640.128246307373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 949960, "time": 29645.473773002625, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 29649.961403369904, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 950040, "time": 29649.985994815826, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 950040, "time": 29650.085898160934, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 950040, "time": 29650.111574411392, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 950040, "time": 29650.253935337067, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 950040, "time": 29650.774035215378, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 950040, "time": 29650.98922395706, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 950040, "time": 29651.46332192421, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 950072, "time": 29652.446122407913, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 950320, "time": 29660.68751192093, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 950472, "time": 29665.089265584946, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 950576, "time": 29668.480628728867, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 950584, "time": 29668.507512569427, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 950888, "time": 29677.82816505432, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 951064, "time": 29683.170661449432, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951384, "time": 29692.90469813347, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 951392, "time": 29693.374952077866, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 951480, "time": 29695.815347909927, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 951560, "time": 29698.22879767418, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 951616, "time": 29700.13948583603, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 951864, "time": 29707.511840343475, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 951888, "time": 29708.462288856506, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 952096, "time": 29714.773780822754, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 952152, "time": 29716.279945135117, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 952208, "time": 29718.188171863556, "episode/length": 142.0, "episode/score": 0.5562499761581421, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.0}
{"step": 952224, "time": 29718.68044233322, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 952272, "time": 29720.160233974457, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 952960, "time": 29741.103487730026, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 953040, "time": 29743.52695083618, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 953384, "time": 29753.721575260162, "episode/length": 160.0, "episode/score": 0.5, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.0}
{"step": 953432, "time": 29755.201909065247, "episode/length": 144.0, "episode/score": 0.550000011920929, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.0}
{"step": 953720, "time": 29763.960141181946, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 953768, "time": 29765.412949085236, "episode/length": 192.0, "episode/score": 0.4000000059604645, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.0}
{"step": 953792, "time": 29766.483844041824, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 953848, "time": 29767.971262931824, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 954128, "time": 29776.716354370117, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 954176, "time": 29778.190499544144, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954184, "time": 29778.218898773193, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 954448, "time": 29786.453152179718, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 954520, "time": 29788.42369866371, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 954544, "time": 29789.37032675743, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 954552, "time": 29789.3968770504, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 954592, "time": 29790.83480668068, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 955152, "time": 29807.99980020523, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 955560, "time": 29820.16587805748, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 955760, "time": 29826.56267118454, "episode/length": 150.0, "episode/score": 0.53125, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.0}
{"step": 955824, "time": 29828.53765964508, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 956160, "time": 29838.775883197784, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956336, "time": 29844.13634634018, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 956384, "time": 29845.605193138123, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 956440, "time": 29847.104889154434, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 956488, "time": 29848.56604886055, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956496, "time": 29849.039345502853, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956832, "time": 29859.308569431305, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 956880, "time": 29860.768276691437, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 956904, "time": 29861.278520345688, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 957096, "time": 29867.10986852646, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 957160, "time": 29869.04704642296, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 957224, "time": 29870.990077972412, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 957488, "time": 29879.243104934692, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 957848, "time": 29890.085774183273, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 957920, "time": 29892.502506017685, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 957992, "time": 29894.46874189377, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 958120, "time": 29898.370319128036, "episode/length": 154.0, "episode/score": 0.518750011920929, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.0}
{"step": 958240, "time": 29902.250811338425, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 958272, "time": 29903.2312772274, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 958320, "time": 29904.694476127625, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 958416, "time": 29907.624269485474, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 958456, "time": 29908.61545610428, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 958696, "time": 29916.536722660065, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 958960, "time": 29924.787684202194, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 959032, "time": 29926.77479171753, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 959216, "time": 29932.56680703163, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 959296, "time": 29935.002222299576, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 959328, "time": 29935.994020700455, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 959448, "time": 29939.412393569946, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 959656, "time": 29945.7561712265, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 959784, "time": 29949.725486040115, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 959968, "time": 29955.56965327263, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 29958.697598695755, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 960024, "time": 29958.891008615494, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 960024, "time": 29959.047308683395, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 960024, "time": 29959.12827539444, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 960024, "time": 29959.1912920475, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 960024, "time": 29959.509793758392, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 960024, "time": 29960.33137011528, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 960024, "time": 29960.62087535858, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 960080, "time": 29962.5320622921, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 960096, "time": 29963.0202896595, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 960144, "time": 29964.500729322433, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 960304, "time": 29969.368641138077, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 960368, "time": 29971.30425095558, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 960576, "time": 29977.75236439705, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 960656, "time": 29980.219432592392, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 960728, "time": 29982.17729997635, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961128, "time": 29994.3962328434, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 961248, "time": 29998.2513422966, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 961272, "time": 29998.759923934937, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 961280, "time": 29999.227806329727, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 961480, "time": 30005.07541704178, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 961568, "time": 30008.111563682556, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 961800, "time": 30014.95463037491, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 961872, "time": 30017.390711784363, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 961888, "time": 30017.885461568832, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 962056, "time": 30022.780848026276, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 962232, "time": 30028.12940120697, "episode/length": 122.0, "episode/score": 0.6187499761581421, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.0}
{"step": 962392, "time": 30033.018033266068, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 962560, "time": 30038.436336517334, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 962744, "time": 30043.809623241425, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 962784, "time": 30045.251305103302, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 962960, "time": 30050.629007339478, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 963256, "time": 30059.389659404755, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 963312, "time": 30061.318574666977, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 963440, "time": 30065.208663225174, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 963544, "time": 30068.255898714066, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 963656, "time": 30071.697697877884, "episode/length": 177.0, "episode/score": 0.4468750059604645, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.0}
{"step": 963792, "time": 30076.054229736328, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964112, "time": 30085.77662563324, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 964200, "time": 30088.21663093567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 964432, "time": 30095.516738414764, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 964528, "time": 30098.524455070496, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 964728, "time": 30104.352720975876, "episode/length": 76.0, "episode/score": 0.762499988079071, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0}
{"step": 965056, "time": 30114.567755937576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965304, "time": 30121.940766572952, "episode/length": 96.0, "episode/score": 0.699999988079071, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.0}
{"step": 965456, "time": 30126.8947930336, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 965568, "time": 30130.307022809982, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965856, "time": 30139.056261777878, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 965968, "time": 30142.47378230095, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966176, "time": 30148.78159427643, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 966200, "time": 30149.311459302902, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 966232, "time": 30150.286128520966, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 966512, "time": 30159.15094780922, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966552, "time": 30160.14350247383, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 966744, "time": 30166.49128961563, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 966776, "time": 30167.463418245316, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 966992, "time": 30174.27045607567, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 967040, "time": 30175.722561120987, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 967144, "time": 30178.64342689514, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 967160, "time": 30179.15549492836, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 967624, "time": 30193.298382997513, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 967632, "time": 30193.78751397133, "episode/length": 106.0, "episode/score": 0.668749988079071, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0}
{"step": 967632, "time": 30193.793210744858, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 967648, "time": 30194.284512996674, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 967976, "time": 30204.084760427475, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 968088, "time": 30207.477762699127, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 968240, "time": 30212.308183670044, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 968288, "time": 30213.778773784637, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 968441, "time": 30219.2514898777, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.240515982750619, "train/action_min": 0.0, "train/action_std": 1.8355493150135078, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011549658154709135, "train/actor_opt_grad_steps": 59425.0, "train/actor_opt_loss": -21.023585423384564, "train/adv_mag": 0.9507704740113551, "train/adv_max": 0.2729676631417605, "train/adv_mean": -3.0688397299233505e-05, "train/adv_min": -0.9029905167546602, "train/adv_std": 0.030419914093384945, "train/cont_avg": 0.9941116181930693, "train/cont_loss_mean": 0.02109947191818737, "train/cont_loss_std": 0.25364626820964536, "train/cont_neg_acc": 0.251129279793495, "train/cont_neg_loss": 2.806903755662972, "train/cont_pos_acc": 0.9998492170678507, "train/cont_pos_loss": 0.004490359016062489, "train/cont_pred": 0.9940962413750073, "train/cont_rate": 0.9941116181930693, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12275528851527684, "train/extr_critic_critic_opt_grad_steps": 59425.0, "train/extr_critic_critic_opt_loss": 6428.430910620359, "train/extr_critic_mag": 1.6665483123005027, "train/extr_critic_max": 1.6665483123005027, "train/extr_critic_mean": 1.5316198279361914, "train/extr_critic_min": 1.333295234949282, "train/extr_critic_std": 0.030897540095640292, "train/extr_return_normed_mag": 0.9742796603995975, "train/extr_return_normed_max": 0.31224814617987906, "train/extr_return_normed_mean": 0.059564751480696815, "train/extr_return_normed_min": -0.8778815434710814, "train/extr_return_normed_std": 0.04459550631887252, "train/extr_return_rate": 0.9996329377783407, "train/extr_return_raw_mag": 1.7842724689162603, "train/extr_return_raw_max": 1.7842724689162603, "train/extr_return_raw_mean": 1.531589148658337, "train/extr_return_raw_min": 0.5941427792652999, "train/extr_return_raw_std": 0.044595506346535564, "train/extr_reward_mag": 0.2835978352197326, "train/extr_reward_max": 0.2835978352197326, "train/extr_reward_mean": 0.0022659147784141547, "train/extr_reward_min": 1.0445566460637763e-07, "train/extr_reward_std": 0.008401743770291162, "train/image_loss_mean": 0.0877039647928559, "train/image_loss_std": 0.10262961656150252, "train/model_loss_mean": 0.7276623060207555, "train/model_loss_std": 0.5127953700721264, "train/model_opt_grad_norm": 17.794854102748456, "train/model_opt_grad_steps": 59372.262376237624, "train/model_opt_loss": 3782.223903542698, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5198.019801980198, "train/policy_entropy_mag": 1.2722502628175338, "train/policy_entropy_max": 1.2722502628175338, "train/policy_entropy_mean": 0.0935575839980404, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.11467828221692897, "train/policy_logprob_mag": 6.551080262306893, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.09328212091090655, "train/policy_logprob_min": -6.551080262306893, "train/policy_logprob_std": 0.6295416535127281, "train/policy_randomness_mag": 0.6538073385115897, "train/policy_randomness_max": 0.6538073385115897, "train/policy_randomness_mean": 0.04807908963965307, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.05893298334414416, "train/post_ent_mag": 23.725653865549823, "train/post_ent_max": 23.725653865549823, "train/post_ent_mean": 23.32744798565855, "train/post_ent_min": 22.985890936143328, "train/post_ent_std": 0.16029408507712997, "train/prior_ent_mag": 24.06694800310796, "train/prior_ent_max": 24.06694800310796, "train/prior_ent_mean": 23.205485740510543, "train/prior_ent_min": 22.322644016530255, "train/prior_ent_std": 0.29505860687482477, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0025731454943975266, "train/reward_loss_mean": 0.01885884306232196, "train/reward_loss_std": 0.2566654675013137, "train/reward_max_data": 0.7919709139531201, "train/reward_max_pred": 0.3063909387824559, "train/reward_neg_acc": 0.999441806927766, "train/reward_neg_loss": 0.003368425083295949, "train/reward_pos_acc": 0.18092277019622907, "train/reward_pos_loss": 4.087723650742526, "train/reward_pred": 0.0020197122017760753, "train/reward_rate": 0.003799891707920792, "train_stats/mean_log_entropy": 0.07887361717419089, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.017989888787269592, "report/cont_loss_std": 0.23525552451610565, "report/cont_neg_acc": 0.4285714626312256, "report/cont_neg_loss": 2.1652560234069824, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032102803234010935, "report/cont_pred": 0.9939432144165039, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09971500188112259, "report/image_loss_std": 0.10759134590625763, "report/model_loss_mean": 0.7306181192398071, "report/model_loss_std": 0.43077895045280457, "report/post_ent_mag": 23.98426055908203, "report/post_ent_max": 23.98426055908203, "report/post_ent_mean": 23.568744659423828, "report/post_ent_min": 23.23952865600586, "report/post_ent_std": 0.16944922506809235, "report/prior_ent_mag": 23.924057006835938, "report/prior_ent_max": 23.924057006835938, "report/prior_ent_mean": 23.19884490966797, "report/prior_ent_min": 22.19988250732422, "report/prior_ent_std": 0.2833005487918854, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.003048705868422985, "report/reward_loss_mean": 0.012913264334201813, "report/reward_loss_std": 0.20161955058574677, "report/reward_max_data": 0.859375, "report/reward_max_pred": 0.6885679960250854, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.0024474572855979204, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.6816937923431396, "report/reward_pred": 0.002548069227486849, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02129627950489521, "eval/cont_loss_std": 0.35867512226104736, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.92371129989624, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.003953235689550638, "eval/cont_pred": 0.9965115785598755, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14331062138080597, "eval/image_loss_std": 0.14661051332950592, "eval/model_loss_mean": 0.7878884077072144, "eval/model_loss_std": 0.8186314702033997, "eval/post_ent_mag": 23.975982666015625, "eval/post_ent_max": 23.975982666015625, "eval/post_ent_mean": 23.553876876831055, "eval/post_ent_min": 23.238018035888672, "eval/post_ent_std": 0.1656714677810669, "eval/prior_ent_mag": 23.8837890625, "eval/prior_ent_max": 23.8837890625, "eval/prior_ent_mean": 23.17624282836914, "eval/prior_ent_min": 22.176204681396484, "eval/prior_ent_std": 0.2818584144115448, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0023956298828125, "eval/reward_loss_mean": 0.023281527683138847, "eval/reward_loss_std": 0.42831721901893616, "eval/reward_max_data": 0.8999999761581421, "eval/reward_max_pred": 0.030841350555419922, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002202069852501154, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 7.197324275970459, "eval/reward_pred": 0.0011554781813174486, "eval/reward_rate": 0.0029296875, "replay/size": 967937.0, "replay/inserts": 32272.0, "replay/samples": 32272.0, "replay/insert_wait_avg": 1.374172230551724e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.678198235189791e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3912.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.133402432400756e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1521680355072, "timer/env.step_count": 4034.0, "timer/env.step_total": 38.21577334403992, "timer/env.step_frac": 0.03820995900964061, "timer/env.step_avg": 0.009473419272196311, "timer/env.step_min": 0.007741451263427734, "timer/env.step_max": 0.035421133041381836, "timer/replay._sample_count": 32272.0, "timer/replay._sample_total": 16.631812572479248, "timer/replay._sample_frac": 0.016629282127286045, "timer/replay._sample_avg": 0.0005153635526920937, "timer/replay._sample_min": 0.0003368854522705078, "timer/replay._sample_max": 0.025820255279541016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4523.0, "timer/agent.policy_total": 47.411437034606934, "timer/agent.policy_frac": 0.047404223627022866, "timer/agent.policy_avg": 0.01048229870320737, "timer/agent.policy_min": 0.008774042129516602, "timer/agent.policy_max": 0.09370803833007812, "timer/dataset_train_count": 2017.0, "timer/dataset_train_total": 0.2105405330657959, "timer/dataset_train_frac": 0.00021050850040083233, "timer/dataset_train_avg": 0.00010438301093990872, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0003390312194824219, "timer/agent.train_count": 2017.0, "timer/agent.train_total": 903.8090994358063, "timer/agent.train_frac": 0.9036715895052876, "timer/agent.train_avg": 0.44809573596222424, "timer/agent.train_min": 0.43428730964660645, "timer/agent.train_max": 2.6130948066711426, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4826803207397461, "timer/agent.report_frac": 0.00048260688339837713, "timer/agent.report_avg": 0.24134016036987305, "timer/agent.report_min": 0.2363111972808838, "timer/agent.report_max": 0.2463691234588623, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.07513173365532e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 32.26659086811449}
{"step": 968544, "time": 30222.351283311844, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 968576, "time": 30223.322451353073, "episode/length": 74.0, "episode/score": 0.768750011920929, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0}
{"step": 968592, "time": 30223.832113981247, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 968672, "time": 30226.283141613007, "episode/length": 264.0, "episode/score": 0.17499999701976776, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.0}
{"step": 968896, "time": 30233.09610414505, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 968960, "time": 30235.064098596573, "episode/length": 108.0, "episode/score": 0.6625000238418579, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.0}
{"step": 969000, "time": 30236.05475783348, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 969232, "time": 30243.337523937225, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 969280, "time": 30244.788088798523, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 969456, "time": 30250.214921951294, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 969648, "time": 30256.0432741642, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 969792, "time": 30260.43839430809, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 969800, "time": 30260.465603113174, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 969912, "time": 30263.887696266174, "episode/length": 113.0, "episode/score": 0.6468750238418579, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 30267.86502957344, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 970008, "time": 30268.757801294327, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 970008, "time": 30268.88165807724, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 970008, "time": 30269.25003027916, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 970008, "time": 30270.082862615585, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 970008, "time": 30270.70379424095, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 970008, "time": 30270.84358239174, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 970008, "time": 30271.669108629227, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 970424, "time": 30284.470113039017, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 970472, "time": 30285.93577337265, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 970792, "time": 30295.68297290802, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 970984, "time": 30301.51282453537, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971136, "time": 30306.43090224266, "episode/length": 185.0, "episode/score": 0.421875, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.0}
{"step": 971152, "time": 30306.942974805832, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 971208, "time": 30308.43149614334, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 971536, "time": 30318.651270866394, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 971664, "time": 30322.5526471138, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 971872, "time": 30328.870676517487, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 972096, "time": 30335.675426483154, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 972112, "time": 30336.264934539795, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972136, "time": 30336.77244567871, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 972224, "time": 30339.66078233719, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 972552, "time": 30349.41149330139, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 972576, "time": 30350.362173318863, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 972856, "time": 30358.633602380753, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 972920, "time": 30360.594824314117, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 972928, "time": 30361.06263256073, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 973464, "time": 30377.256641864777, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 973568, "time": 30380.64668059349, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 973800, "time": 30387.440899848938, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 973832, "time": 30388.419053554535, "episode/length": 159.0, "episode/score": 0.503125011920929, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.0}
{"step": 973976, "time": 30392.788133859634, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974288, "time": 30402.596383094788, "episode/length": 102.0, "episode/score": 0.6812499761581421, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.0}
{"step": 974368, "time": 30405.040745973587, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 974424, "time": 30406.525790452957, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 974488, "time": 30408.4578499794, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 974888, "time": 30421.092406749725, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 974984, "time": 30424.001347780228, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 975128, "time": 30428.47775864601, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 975144, "time": 30428.97237277031, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 975192, "time": 30430.45234465599, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 975240, "time": 30431.90418958664, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 975320, "time": 30434.361972093582, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 975632, "time": 30444.094038009644, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 975664, "time": 30445.06796193123, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 975784, "time": 30448.47983765602, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 975840, "time": 30450.427613019943, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 975880, "time": 30451.418797969818, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 975888, "time": 30451.890424728394, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 976032, "time": 30456.379437685013, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 976232, "time": 30462.256114959717, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 976376, "time": 30466.64950799942, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 976504, "time": 30470.540231227875, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 976600, "time": 30473.475571155548, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 976600, "time": 30473.480889320374, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 976640, "time": 30474.925956726074, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 977048, "time": 30487.22151875496, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 977296, "time": 30494.98329091072, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 977368, "time": 30496.94759631157, "episode/length": 123.0, "episode/score": 0.6156250238418579, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0}
{"step": 977592, "time": 30503.767467975616, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 977768, "time": 30509.109732866287, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 978184, "time": 30521.822790384293, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 978344, "time": 30526.68774008751, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978728, "time": 30538.312728643417, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 978816, "time": 30541.1976211071, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978912, "time": 30544.136848449707, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 978952, "time": 30545.12886953354, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979200, "time": 30553.016563415527, "episode/length": 30.0, "episode/score": 0.90625, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.0}
{"step": 979360, "time": 30557.915791511536, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979384, "time": 30558.429694890976, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 979608, "time": 30565.233546495438, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 979616, "time": 30565.70461511612, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 979752, "time": 30569.62144947052, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 979848, "time": 30572.552199602127, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 30581.64809846878, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 980096, "time": 30582.233602523804, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 980096, "time": 30582.46233844757, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 980096, "time": 30582.814980745316, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 980096, "time": 30583.123049020767, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 980096, "time": 30583.245715379715, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 980096, "time": 30583.383444547653, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 980096, "time": 30584.59317445755, "eval_episode/length": 122.0, "eval_episode/score": 0.6187499761581421, "eval_episode/reward_rate": 0.008130081300813009}
{"step": 980320, "time": 30591.397356271744, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 980496, "time": 30596.76024246216, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980656, "time": 30601.62214756012, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 980688, "time": 30602.600868463516, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 981200, "time": 30618.23081636429, "episode/length": 180.0, "episode/score": 0.4375, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.0}
{"step": 981224, "time": 30618.74460864067, "episode/length": 200.0, "episode/score": 0.375, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.0}
{"step": 981240, "time": 30619.251606702805, "episode/length": 92.0, "episode/score": 0.7124999761581421, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0}
{"step": 981392, "time": 30624.089648723602, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 981448, "time": 30625.580638885498, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 981696, "time": 30633.322503328323, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981920, "time": 30640.228534698486, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 981952, "time": 30641.204880475998, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 982144, "time": 30647.05182147026, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 982176, "time": 30648.034430980682, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 982280, "time": 30650.981444597244, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 982632, "time": 30661.654009580612, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 982696, "time": 30663.630618095398, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 982800, "time": 30667.10382461548, "episode/length": 175.0, "episode/score": 0.453125, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.0}
{"step": 982960, "time": 30671.99400806427, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 982992, "time": 30672.984066963196, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 983392, "time": 30685.647759199142, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 983600, "time": 30692.00179028511, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 983760, "time": 30696.967274665833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 983840, "time": 30699.404637098312, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 984008, "time": 30704.272794008255, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984032, "time": 30705.226804971695, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 984264, "time": 30712.074413776398, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 984392, "time": 30715.998999118805, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 984448, "time": 30717.92787671089, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 984456, "time": 30717.955647468567, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 984592, "time": 30722.32371854782, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 984944, "time": 30733.105669021606, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985032, "time": 30735.557104349136, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 985040, "time": 30736.032149791718, "episode/length": 72.0, "episode/score": 0.7749999761581421, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0}
{"step": 985112, "time": 30738.04320168495, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 985344, "time": 30745.30416250229, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 985544, "time": 30751.137146234512, "episode/length": 62.0, "episode/score": 0.8062499761581421, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0}
{"step": 985888, "time": 30761.900849580765, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 985896, "time": 30761.927198171616, "episode/length": 68.0, "episode/score": 0.7875000238418579, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.0}
{"step": 985928, "time": 30762.903804779053, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 985976, "time": 30764.365911722183, "episode/length": 197.0, "episode/score": 0.3843750059604645, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.0}
{"step": 986232, "time": 30772.136157512665, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 986240, "time": 30772.600620746613, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 986344, "time": 30775.521296977997, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986576, "time": 30782.782202005386, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 986680, "time": 30785.737773895264, "episode/length": 93.0, "episode/score": 0.7093750238418579, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.0}
{"step": 986688, "time": 30786.294064760208, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 986696, "time": 30786.32174706459, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 986952, "time": 30794.08420276642, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 987000, "time": 30795.568731307983, "episode/length": 37.0, "episode/score": 0.8843749761581421, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.0}
{"step": 987000, "time": 30795.57412171364, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 987272, "time": 30803.83042240143, "episode/length": 129.0, "episode/score": 0.596875011920929, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.0}
{"step": 987368, "time": 30806.75572490692, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 987632, "time": 30815.010724067688, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 987712, "time": 30817.50647497177, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 987784, "time": 30819.462827444077, "episode/length": 97.0, "episode/score": 0.6968749761581421, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.0}
{"step": 987888, "time": 30822.85375213623, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 988208, "time": 30832.603090047836, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 988472, "time": 30840.42165207863, "episode/length": 85.0, "episode/score": 0.734375, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.0}
{"step": 988488, "time": 30840.912509918213, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 988640, "time": 30845.799345731735, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 988832, "time": 30851.73655986786, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 988880, "time": 30853.203942775726, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 988992, "time": 30856.626588582993, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989096, "time": 30859.589131355286, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 989104, "time": 30860.059543132782, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 989312, "time": 30866.378932237625, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 989400, "time": 30868.84225511551, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 989584, "time": 30874.65375351906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 989824, "time": 30882.048771619797, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 989936, "time": 30885.46835041046, "episode/length": 103.0, "episode/score": 0.6781250238418579, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0}
{"step": 990056, "time": 30889.014569044113, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 30891.401280403137, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 990080, "time": 30891.657390356064, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 990080, "time": 30891.76347231865, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 990080, "time": 30891.825872659683, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 990080, "time": 30892.29144525528, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 990080, "time": 30892.31639122963, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 990080, "time": 30892.6483566761, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 990080, "time": 30893.7880795002, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 990152, "time": 30895.749371767044, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 990168, "time": 30896.24183654785, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 990696, "time": 30912.356464147568, "episode/length": 79.0, "episode/score": 0.753125011920929, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.0}
{"step": 990832, "time": 30916.7462618351, "episode/length": 84.0, "episode/score": 0.737500011920929, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0}
{"step": 991040, "time": 30923.087164402008, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 991144, "time": 30926.028912305832, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 991192, "time": 30927.506587028503, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 991232, "time": 30929.08356165886, "episode/length": 161.0, "episode/score": 0.49687498807907104, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0}
{"step": 991248, "time": 30929.9177570343, "episode/length": 134.0, "episode/score": 0.581250011920929, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.0}
{"step": 991536, "time": 30938.71923971176, "episode/length": 277.0, "episode/score": 0.13437500596046448, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0}
{"step": 991584, "time": 30940.18159198761, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 991704, "time": 30943.60689854622, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 991752, "time": 30945.068620443344, "episode/length": 131.0, "episode/score": 0.590624988079071, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.0}
{"step": 991808, "time": 30947.008650302887, "episode/length": 27.0, "episode/score": 0.9156249761581421, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0}
{"step": 991896, "time": 30949.466388225555, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 991992, "time": 30952.386544704437, "episode/length": 94.0, "episode/score": 0.706250011920929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0}
{"step": 992128, "time": 30956.73950099945, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 992168, "time": 30957.733007907867, "episode/length": 57.0, "episode/score": 0.8218749761581421, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.0}
{"step": 992256, "time": 30960.607815504074, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 992288, "time": 30961.595396757126, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 992376, "time": 30964.025663375854, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 992464, "time": 30967.01155948639, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 992736, "time": 30975.248595237732, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 992744, "time": 30975.278074741364, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 992776, "time": 30976.276990413666, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 992864, "time": 30979.164222478867, "episode/length": 165.0, "episode/score": 0.484375, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.0}
{"step": 992896, "time": 30980.1435546875, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 992960, "time": 30982.106422185898, "episode/length": 61.0, "episode/score": 0.809374988079071, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0}
{"step": 993112, "time": 30986.51033639908, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 993168, "time": 30988.44063949585, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 993224, "time": 30989.913724422455, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 993304, "time": 30992.3631606102, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 993408, "time": 30995.76179432869, "episode/length": 36.0, "episode/score": 0.887499988079071, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0}
{"step": 993464, "time": 30997.339772939682, "episode/length": 89.0, "episode/score": 0.721875011920929, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.0}
{"step": 993824, "time": 31008.51848769188, "episode/length": 135.0, "episode/score": 0.578125, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0}
{"step": 993880, "time": 31010.007284641266, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 994016, "time": 31014.34693837166, "episode/length": 75.0, "episode/score": 0.765625, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0}
{"step": 994520, "time": 31029.55887389183, "episode/length": 168.0, "episode/score": 0.4749999940395355, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.0}
{"step": 994936, "time": 31042.21466445923, "episode/length": 183.0, "episode/score": 0.4281249940395355, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.0}
{"step": 994936, "time": 31042.22128009796, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 994960, "time": 31043.1865735054, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 995176, "time": 31049.576783180237, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995208, "time": 31050.554590940475, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995536, "time": 31060.849983930588, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 995776, "time": 31068.140789985657, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 995808, "time": 31069.12617278099, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 995840, "time": 31070.09607052803, "episode/length": 78.0, "episode/score": 0.7562500238418579, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.0}
{"step": 995888, "time": 31071.555366516113, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 996192, "time": 31080.828591823578, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 996208, "time": 31081.341167211533, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 996296, "time": 31083.818682909012, "episode/length": 60.0, "episode/score": 0.8125, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0}
{"step": 996680, "time": 31095.57509469986, "episode/length": 217.0, "episode/score": 0.3218750059604645, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.0}
{"step": 996872, "time": 31101.411260843277, "episode/length": 166.0, "episode/score": 0.48124998807907104, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.0}
{"step": 997144, "time": 31109.698680639267, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 997144, "time": 31109.70472550392, "episode/length": 156.0, "episode/score": 0.512499988079071, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.0}
{"step": 997264, "time": 31113.57829117775, "episode/length": 48.0, "episode/score": 0.8500000238418579, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.0}
{"step": 997448, "time": 31119.033680200577, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 997928, "time": 31133.618715286255, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 998072, "time": 31137.993142843246, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 998088, "time": 31138.486431360245, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998152, "time": 31140.418350696564, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998520, "time": 31151.663184404373, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 998576, "time": 31153.572973012924, "episode/length": 178.0, "episode/score": 0.4437499940395355, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.0}
{"step": 998992, "time": 31166.216337680817, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999136, "time": 31170.577449321747, "episode/length": 130.0, "episode/score": 0.59375, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.0}
{"step": 999288, "time": 31174.977667331696, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 999456, "time": 31180.848697185516, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 999760, "time": 31190.083174943924, "episode/length": 77.0, "episode/score": 0.7593749761581421, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.0}
{"step": 999768, "time": 31190.10995864868, "episode/length": 59.0, "episode/score": 0.815625011920929, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.0}
{"step": 999840, "time": 31192.531900644302, "episode/length": 105.0, "episode/score": 0.671875, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 31200.244230270386, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 1000064, "time": 31201.52754855156, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1000064, "time": 31201.629212141037, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1000064, "time": 31201.692440986633, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 1000064, "time": 31202.001179218292, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 1000064, "time": 31202.402620077133, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 1000064, "time": 31202.5628156662, "eval_episode/length": 168.0, "eval_episode/score": 0.4749999940395355, "eval_episode/reward_rate": 0.005917159763313609}
{"step": 1000064, "time": 31202.645320892334, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 1000240, "time": 31208.12914299965, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000304, "time": 31210.082212924957, "episode/length": 66.0, "episode/score": 0.793749988079071, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1000344, "time": 31211.076200962067, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1000384, "time": 31212.519183397293, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000464, "time": 31214.96099090576, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000585, "time": 31219.40607905388, "train_stats/mean_log_entropy": 0.08273426229995778, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2580202017257465, "train/action_min": 0.0, "train/action_std": 1.9073150994172736, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.011246038237076938, "train/actor_opt_grad_steps": 61440.0, "train/actor_opt_loss": -22.54225723304559, "train/adv_mag": 0.9528968992517955, "train/adv_max": 0.2550617106518342, "train/adv_mean": -0.0001537637255742129, "train/adv_min": -0.9150958517890665, "train/adv_std": 0.02850337364520896, "train/cont_avg": 0.994082322761194, "train/cont_loss_mean": 0.021886127962689125, "train/cont_loss_std": 0.26363794160867804, "train/cont_neg_acc": 0.24886516655855512, "train/cont_neg_loss": 2.9078115396461084, "train/cont_pos_acc": 0.9998142327835311, "train/cont_pos_loss": 0.004472049474438179, "train/cont_pred": 0.9941598043512943, "train/cont_rate": 0.994082322761194, "train/dyn_loss_mean": 1.0000002259638772, "train/dyn_loss_std": 7.222236866196293e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.10188660842009742, "train/extr_critic_critic_opt_grad_steps": 61440.0, "train/extr_critic_critic_opt_loss": 7997.677158640392, "train/extr_critic_mag": 1.6505024456859227, "train/extr_critic_max": 1.6505024456859227, "train/extr_critic_mean": 1.5126131209568006, "train/extr_critic_min": 1.3017687744169093, "train/extr_critic_std": 0.030968580422783967, "train/extr_return_normed_mag": 0.9712707800651664, "train/extr_return_normed_max": 0.2841897769946957, "train/extr_return_normed_mean": 0.05883621620894665, "train/extr_return_normed_min": -0.887138147852314, "train/extr_return_normed_std": 0.04293180037456662, "train/extr_return_rate": 0.9996719223942923, "train/extr_return_raw_mag": 1.737812918810109, "train/extr_return_raw_max": 1.737812918810109, "train/extr_return_raw_mean": 1.5124594323077605, "train/extr_return_raw_min": 0.5664849939630993, "train/extr_return_raw_std": 0.042931800198495684, "train/extr_reward_mag": 0.25368220355380233, "train/extr_reward_max": 0.25368220355380233, "train/extr_reward_mean": 0.0021048569432065927, "train/extr_reward_min": 8.836907533863883e-08, "train/extr_reward_std": 0.007802464711984888, "train/image_loss_mean": 0.0879962385738667, "train/image_loss_std": 0.10231013833290309, "train/model_loss_mean": 0.7286068755595838, "train/model_loss_std": 0.5173625741431962, "train/model_opt_grad_norm": 17.21458034992218, "train/model_opt_grad_steps": 61385.27860696518, "train/model_opt_loss": 3751.0702724172106, "train/model_opt_model_opt_grad_overflow": 0.004975124378109453, "train/model_opt_model_opt_grad_scale": 5124.378109452737, "train/policy_entropy_mag": 1.2789060767017193, "train/policy_entropy_max": 1.2789060767017193, "train/policy_entropy_mean": 0.096905524976811, "train/policy_entropy_min": 0.06468649208545685, "train/policy_entropy_std": 0.12160763163026886, "train/policy_logprob_mag": 6.5510802743446765, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.0969217919295107, "train/policy_logprob_min": -6.5510802743446765, "train/policy_logprob_std": 0.63449457065383, "train/policy_randomness_mag": 0.6572277528136524, "train/policy_randomness_max": 0.6572277528136524, "train/policy_randomness_mean": 0.04979959070979066, "train/policy_randomness_min": 0.03324228152632713, "train/policy_randomness_std": 0.06249396365821658, "train/post_ent_mag": 23.740236111541293, "train/post_ent_max": 23.740236111541293, "train/post_ent_mean": 23.325880582059792, "train/post_ent_min": 22.96896300624259, "train/post_ent_std": 0.16701864944168585, "train/prior_ent_mag": 23.99306437743837, "train/prior_ent_max": 23.99306437743837, "train/prior_ent_mean": 23.065373017420224, "train/prior_ent_min": 22.133849366980407, "train/prior_ent_std": 0.2984861767114098, "train/rep_loss_mean": 1.0000002259638772, "train/rep_loss_std": 7.222236866196293e-06, "train/reward_avg": 0.0024849355644465366, "train/reward_loss_mean": 0.01872435075912013, "train/reward_loss_std": 0.2555939805188879, "train/reward_max_data": 0.7774253738163716, "train/reward_max_pred": 0.31708668001848667, "train/reward_neg_acc": 0.9995319004082561, "train/reward_neg_loss": 0.0032755598149016795, "train/reward_pos_acc": 0.18725572541430968, "train/reward_pos_loss": 4.084666807747366, "train/reward_pred": 0.0019793161891854894, "train/reward_rate": 0.0037410603233830847, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.018040381371974945, "report/cont_loss_std": 0.2544447183609009, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 3.512791633605957, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004335473291575909, "report/cont_pred": 0.9950071573257446, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.08251336216926575, "report/image_loss_std": 0.0914800837635994, "report/model_loss_mean": 0.7141063213348389, "report/model_loss_std": 0.4484926164150238, "report/post_ent_mag": 23.52198600769043, "report/post_ent_max": 23.52198600769043, "report/post_ent_mean": 23.11922836303711, "report/post_ent_min": 22.797683715820312, "report/post_ent_std": 0.1672268956899643, "report/prior_ent_mag": 23.639541625976562, "report/prior_ent_max": 23.639541625976562, "report/prior_ent_mean": 22.933740615844727, "report/prior_ent_min": 22.16104507446289, "report/prior_ent_std": 0.23781819641590118, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.001828002859838307, "report/reward_loss_mean": 0.01355259120464325, "report/reward_loss_std": 0.21111221611499786, "report/reward_max_data": 0.6781250238418579, "report/reward_max_pred": 0.5614218711853027, "report/reward_neg_acc": 0.999020516872406, "report/reward_neg_loss": 0.0034848491195589304, "report/reward_pos_acc": 0.3333333432674408, "report/reward_pos_loss": 3.439940929412842, "report/reward_pred": 0.002331648487597704, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.051911234855651855, "eval/cont_loss_std": 0.5658869743347168, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.502628803253174, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003579751355573535, "eval/cont_pred": 0.9963528513908386, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.14127816259860992, "eval/image_loss_std": 0.129405677318573, "eval/model_loss_mean": 0.8458857536315918, "eval/model_loss_std": 1.193278193473816, "eval/post_ent_mag": 23.51702880859375, "eval/post_ent_max": 23.51702880859375, "eval/post_ent_mean": 23.144832611083984, "eval/post_ent_min": 22.735965728759766, "eval/post_ent_std": 0.17694008350372314, "eval/prior_ent_mag": 23.704296112060547, "eval/prior_ent_max": 23.704296112060547, "eval/prior_ent_mean": 22.935447692871094, "eval/prior_ent_min": 22.186946868896484, "eval/prior_ent_std": 0.2522445321083069, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.005703735630959272, "eval/reward_loss_mean": 0.0526963546872139, "eval/reward_loss_std": 0.6102604866027832, "eval/reward_max_data": 0.875, "eval/reward_max_pred": 0.06892859935760498, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0029010369908064604, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.376701354980469, "eval/reward_pred": 0.0015413484070450068, "eval/reward_rate": 0.0078125, "replay/size": 1000000.0, "replay/inserts": 32144.0, "replay/samples": 32144.0, "replay/insert_wait_avg": 1.3580379823121696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.648842437994783e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6736.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1871730346860908e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1387455463409, "timer/env.step_count": 4018.0, "timer/env.step_total": 38.08621025085449, "timer/env.step_frac": 0.03808092669187546, "timer/env.step_avg": 0.00947889752385627, "timer/env.step_min": 0.0076906681060791016, "timer/env.step_max": 0.04771900177001953, "timer/replay._sample_count": 32144.0, "timer/replay._sample_total": 16.571463584899902, "timer/replay._sample_frac": 0.016569164687092977, "timer/replay._sample_avg": 0.0005155383146123663, "timer/replay._sample_min": 0.0004076957702636719, "timer/replay._sample_max": 0.02877521514892578, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4860.0, "timer/agent.policy_total": 50.072591066360474, "timer/agent.policy_frac": 0.05006564468113628, "timer/agent.policy_avg": 0.010303002277028904, "timer/agent.policy_min": 0.008720874786376953, "timer/agent.policy_max": 0.07813835144042969, "timer/dataset_train_count": 2009.0, "timer/dataset_train_total": 0.2106921672821045, "timer/dataset_train_frac": 0.00021066293873757557, "timer/dataset_train_avg": 0.00010487414996620433, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0002796649932861328, "timer/agent.train_count": 2009.0, "timer/agent.train_total": 898.0990450382233, "timer/agent.train_frac": 0.8979744550818527, "timer/agent.train_avg": 0.4470378521842824, "timer/agent.train_min": 0.43753504753112793, "timer/agent.train_max": 0.7064566612243652, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4809751510620117, "timer/agent.report_frac": 0.0004809084271595455, "timer/agent.report_avg": 0.24048757553100586, "timer/agent.report_min": 0.2347245216369629, "timer/agent.report_max": 0.24625062942504883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.4318695068359375e-05, "timer/dataset_eval_frac": 2.4315321425803697e-08, "timer/dataset_eval_avg": 2.4318695068359375e-05, "timer/dataset_eval_min": 2.4318695068359375e-05, "timer/dataset_eval_max": 2.4318695068359375e-05, "fps": 32.13901906596742}
{"step": 1000760, "time": 31224.471252679825, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1000888, "time": 31228.34213733673, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1000904, "time": 31228.82848930359, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1001072, "time": 31234.16581439972, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1001264, "time": 31240.1070895195, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1001496, "time": 31246.910944223404, "episode/length": 128.0, "episode/score": 0.6000000238418579, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0}
{"step": 1001512, "time": 31247.402937173843, "episode/length": 145.0, "episode/score": 0.546875, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.0}
{"step": 1001624, "time": 31250.798001289368, "episode/length": 91.0, "episode/score": 0.715624988079071, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0}
{"step": 1001912, "time": 31259.62980055809, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1002152, "time": 31266.97477531433, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1002264, "time": 31270.386684179306, "episode/length": 124.0, "episode/score": 0.612500011920929, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.0}
{"step": 1002392, "time": 31274.261605978012, "episode/length": 109.0, "episode/score": 0.659375011920929, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0}
{"step": 1002392, "time": 31274.267066955566, "episode/length": 111.0, "episode/score": 0.653124988079071, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.0}
{"step": 1002720, "time": 31284.44281077385, "episode/length": 100.0, "episode/score": 0.6875, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0}
{"step": 1002920, "time": 31290.29659318924, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1003072, "time": 31295.17300915718, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003384, "time": 31304.53298854828, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1003480, "time": 31307.484327554703, "episode/length": 151.0, "episode/score": 0.528124988079071, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0}
{"step": 1003608, "time": 31311.350934267044, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1003856, "time": 31319.09339952469, "episode/length": 182.0, "episode/score": 0.4312500059604645, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.0}
{"step": 1003888, "time": 31320.060026407242, "episode/length": 101.0, "episode/score": 0.684374988079071, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.0}
{"step": 1003936, "time": 31321.509111881256, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1004096, "time": 31326.434572458267, "episode/length": 146.0, "episode/score": 0.543749988079071, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.0}
{"step": 1004184, "time": 31328.890924215317, "episode/length": 99.0, "episode/score": 0.690625011920929, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0}
{"step": 1004328, "time": 31333.26233649254, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1004336, "time": 31333.725651025772, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1004576, "time": 31340.99777841568, "episode/length": 136.0, "episode/score": 0.574999988079071, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0}
{"step": 1004704, "time": 31344.876816034317, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1005048, "time": 31355.073790550232, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1005144, "time": 31358.081053972244, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1005720, "time": 31375.53009915352, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1005848, "time": 31379.386033296585, "episode/length": 188.0, "episode/score": 0.4124999940395355, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.0}
{"step": 1006008, "time": 31384.231755018234, "episode/length": 162.0, "episode/score": 0.4937500059604645, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.0}
{"step": 1006024, "time": 31384.721140623093, "episode/length": 121.0, "episode/score": 0.621874988079071, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.0}
{"step": 1006200, "time": 31390.162708044052, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006224, "time": 31391.11550140381, "episode/length": 26.0, "episode/score": 0.918749988079071, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.0}
{"step": 1006248, "time": 31391.62991285324, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006360, "time": 31395.03343129158, "episode/length": 19.0, "episode/score": 0.940625011920929, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0}
{"step": 1006384, "time": 31395.989275932312, "episode/length": 82.0, "episode/score": 0.7437499761581421, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.0}
{"step": 1006552, "time": 31400.84636425972, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1006888, "time": 31411.042826890945, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1006952, "time": 31412.99254846573, "episode/length": 70.0, "episode/score": 0.78125, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.0}
{"step": 1007152, "time": 31419.397524118423, "episode/length": 98.0, "episode/score": 0.6937500238418579, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.0}
{"step": 1007168, "time": 31419.88877081871, "episode/length": 114.0, "episode/score": 0.643750011920929, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.0}
{"step": 1007456, "time": 31428.594779729843, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1007472, "time": 31429.099371910095, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1007512, "time": 31430.086404561996, "episode/length": 69.0, "episode/score": 0.784375011920929, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0}
{"step": 1007880, "time": 31441.65006685257, "episode/length": 90.0, "episode/score": 0.71875, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.0}
{"step": 1007888, "time": 31442.116651296616, "episode/length": 46.0, "episode/score": 0.856249988079071, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.0}
{"step": 1008288, "time": 31454.35077357292, "episode/length": 139.0, "episode/score": 0.565625011920929, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.0}
{"step": 1008312, "time": 31454.857964515686, "episode/length": 53.0, "episode/score": 0.8343750238418579, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0}
{"step": 1008336, "time": 31455.80870628357, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1008488, "time": 31460.213360786438, "episode/length": 126.0, "episode/score": 0.606249988079071, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0}
{"step": 1008488, "time": 31460.22038292885, "episode/length": 241.0, "episode/score": 0.24687500298023224, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.0}
{"step": 1008928, "time": 31473.784684419632, "episode/length": 54.0, "episode/score": 0.831250011920929, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0}
{"step": 1008992, "time": 31475.718599557877, "episode/length": 81.0, "episode/score": 0.746874988079071, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0}
{"step": 1008992, "time": 31475.723985910416, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1009032, "time": 31476.79819369316, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1009200, "time": 31482.086827516556, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009624, "time": 31494.73927974701, "episode/length": 163.0, "episode/score": 0.4906249940395355, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.0}
{"step": 1009728, "time": 31498.12895298004, "episode/length": 86.0, "episode/score": 0.731249988079071, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0}
{"step": 1009768, "time": 31499.121661901474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1009928, "time": 31503.9978659153, "episode/length": 116.0, "episode/score": 0.637499988079071, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 31508.78369307518, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 1010048, "time": 31510.139083385468, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 1010048, "time": 31510.328830242157, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 1010048, "time": 31510.6388733387, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 1010048, "time": 31510.684831142426, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 1010048, "time": 31510.825818538666, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 1010048, "time": 31510.92583179474, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 1010048, "time": 31511.079176664352, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 1010080, "time": 31512.049738407135, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1010200, "time": 31515.48442554474, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1010312, "time": 31518.89221596718, "episode/length": 164.0, "episode/score": 0.48750001192092896, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.0}
{"step": 1010376, "time": 31520.854490041733, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1010400, "time": 31521.80682682991, "episode/length": 58.0, "episode/score": 0.8187500238418579, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0}
{"step": 1010584, "time": 31527.17729997635, "episode/length": 119.0, "episode/score": 0.628125011920929, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.0}
{"step": 1010656, "time": 31529.578248739243, "episode/length": 110.0, "episode/score": 0.65625, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0}
{"step": 1011024, "time": 31540.836429834366, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1011176, "time": 31545.22700238228, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1011328, "time": 31550.06042575836, "episode/length": 83.0, "episode/score": 0.7406250238418579, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0}
{"step": 1011352, "time": 31550.571076393127, "episode/length": 158.0, "episode/score": 0.5062500238418579, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0}
{"step": 1011512, "time": 31555.441428422928, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012048, "time": 31572.021287202835, "episode/length": 127.0, "episode/score": 0.6031249761581421, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.0}
{"step": 1012096, "time": 31573.467559337616, "episode/length": 95.0, "episode/score": 0.703125, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.0}
{"step": 1012120, "time": 31573.99782848358, "episode/length": 117.0, "episode/score": 0.6343749761581421, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.0}
{"step": 1012504, "time": 31585.63736462593, "episode/length": 56.0, "episode/score": 0.824999988079071, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0}
{"step": 1012512, "time": 31586.10431265831, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012552, "time": 31587.100933790207, "episode/length": 149.0, "episode/score": 0.534375011920929, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1012624, "time": 31589.531994104385, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012712, "time": 31591.98201751709, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1012760, "time": 31593.466939926147, "episode/length": 155.0, "episode/score": 0.515625, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1012880, "time": 31597.41043114662, "episode/length": 40.0, "episode/score": 0.875, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.0}
{"step": 1013128, "time": 31604.712430238724, "episode/length": 125.0, "episode/score": 0.609375, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.0}
{"step": 1013160, "time": 31605.684683561325, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1013432, "time": 31613.933108329773, "episode/length": 115.0, "episode/score": 0.640625, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0}
{"step": 1013576, "time": 31618.30188202858, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1013592, "time": 31618.79031920433, "episode/length": 186.0, "episode/score": 0.41874998807907104, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.0}
{"step": 1013704, "time": 31622.172721147537, "episode/length": 67.0, "episode/score": 0.7906249761581421, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1014048, "time": 31633.01343894005, "episode/length": 42.0, "episode/score": 0.8687499761581421, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.0}
{"step": 1014544, "time": 31648.003565311432, "episode/length": 138.0, "episode/score": 0.5687500238418579, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.0}
{"step": 1014640, "time": 31650.89270377159, "episode/length": 132.0, "episode/score": 0.5874999761581421, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0}
{"step": 1014664, "time": 31651.40400671959, "episode/length": 133.0, "episode/score": 0.5843750238418579, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0}
{"step": 1014744, "time": 31653.838711500168, "episode/length": 9.0, "episode/score": 0.971875011920929, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.0}
{"step": 1014824, "time": 31656.363901376724, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1014848, "time": 31657.336807012558, "episode/length": 245.0, "episode/score": 0.234375, "episode/reward_rate": 0.0040650406504065045, "episode/intrinsic_return": 0.0}
{"step": 1014936, "time": 31659.77339553833, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015024, "time": 31662.657885551453, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1015064, "time": 31663.65363740921, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1015384, "time": 31673.33281826973, "episode/length": 55.0, "episode/score": 0.828125, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.0}
{"step": 1015544, "time": 31678.197777986526, "episode/length": 64.0, "episode/score": 0.800000011920929, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.0}
{"step": 1015584, "time": 31679.624302864075, "episode/length": 104.0, "episode/score": 0.675000011920929, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.0}
{"step": 1015752, "time": 31684.47680592537, "episode/length": 45.0, "episode/score": 0.859375, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0}
{"step": 1015776, "time": 31685.43128180504, "episode/length": 118.0, "episode/score": 0.6312500238418579, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.0}
{"step": 1015832, "time": 31687.483955860138, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1016152, "time": 31697.1875371933, "episode/length": 49.0, "episode/score": 0.846875011920929, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.0}
{"step": 1016240, "time": 31700.068613052368, "episode/length": 173.0, "episode/score": 0.4593749940395355, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.0}
{"step": 1016360, "time": 31703.471552848816, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1016368, "time": 31703.942901849747, "episode/length": 73.0, "episode/score": 0.7718750238418579, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0}
{"step": 1016432, "time": 31705.887635231018, "episode/length": 170.0, "episode/score": 0.46875, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0}
{"step": 1016800, "time": 31717.164286136627, "episode/length": 80.0, "episode/score": 0.75, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.0}
{"step": 1017512, "time": 31738.472135543823, "episode/length": 88.0, "episode/score": 0.7250000238418579, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0}
{"step": 1017552, "time": 31739.94276881218, "episode/length": 148.0, "episode/score": 0.5375000238418579, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0}
{"step": 1017856, "time": 31749.254569768906, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1017896, "time": 31750.254655599594, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018144, "time": 31757.978935480118, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018152, "time": 31758.00657224655, "episode/length": 214.0, "episode/score": 0.33125001192092896, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.0}
{"step": 1018256, "time": 31761.389937639236, "episode/length": 87.0, "episode/score": 0.7281249761581421, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.0}
{"step": 1018552, "time": 31770.163269519806, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018680, "time": 31774.07666707039, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
{"step": 1018728, "time": 31775.527367591858, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1019000, "time": 31783.857225179672, "episode/length": 39.0, "episode/score": 0.878125011920929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.0}
{"step": 1019048, "time": 31785.325484275818, "episode/length": 143.0, "episode/score": 0.5531250238418579, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0}
{"step": 1019128, "time": 31787.782564163208, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1019304, "time": 31793.11305475235, "episode/length": 71.0, "episode/score": 0.778124988079071, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.0}
{"step": 1019512, "time": 31799.41384243965, "episode/length": 63.0, "episode/score": 0.8031250238418579, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.0}
{"step": 1019824, "time": 31809.16162800789, "episode/length": 288.0, "episode/score": 0.0, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0}
