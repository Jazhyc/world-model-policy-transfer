{"step": 776, "time": 130.5229368209839, "episode/length": 96.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 928, "time": 132.4063379764557, "episode/length": 115.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.0}
{"step": 1200, "time": 134.7508683204651, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 1296, "time": 136.5311770439148, "episode/length": 161.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1424, "time": 138.62998795509338, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1496, "time": 140.61600017547607, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 1528, "time": 142.35197734832764, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 160.8152630329132, "eval_episode/length": 135.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 1560, "time": 162.23487830162048, "eval_episode/length": 139.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 1560, "time": 163.89427876472473, "eval_episode/length": 150.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 1560, "time": 165.21775460243225, "eval_episode/length": 151.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.993421052631579}
{"step": 1560, "time": 166.83296608924866, "eval_episode/length": 164.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 1560, "time": 168.46483612060547, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1560, "time": 170.12302684783936, "eval_episode/length": 189.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 1560, "time": 171.51604175567627, "eval_episode/length": 193.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 1560, "time": 173.00348496437073, "train_stats/sum_log_reward": 1.24285715924842, "train_stats/max_log_achievement_collect_sapling": 0.5714285714285714, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_place_plant": 0.4, "train_stats/max_log_achievement_collect_drink": 1.0, "train_stats/max_log_achievement_collect_wood": 0.5, "eval_stats/sum_log_reward": 1.5999999567866325, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.375, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.5}
{"step": 1560, "time": 227.26740741729736, "eval_episode/length": 76.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.948051948051948}
{"step": 1560, "time": 229.6501326560974, "eval_episode/length": 95.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9479166666666666}
{"step": 1560, "time": 231.3919117450714, "eval_episode/length": 98.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9494949494949495}
{"step": 1560, "time": 234.45761108398438, "eval_episode/length": 135.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 1560, "time": 236.18862080574036, "eval_episode/length": 140.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 1560, "time": 238.12239503860474, "eval_episode/length": 149.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 1560, "time": 243.36383724212646, "eval_episode/length": 154.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 1560, "time": 245.10081934928894, "eval_episode/length": 235.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 1561, "time": 364.006543636322, "eval_stats/sum_log_reward": 0.2249999949708581, "eval_stats/max_log_achievement_collect_drink": 0.25, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_place_plant": 0.125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.375, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.5848388671875, "train/action_min": 0.0, "train/action_std": 4.779718399047852, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.000112270048703067, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.5799692273139954, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9990234375, "train/cont_loss_mean": 1.261641263961792, "train/cont_loss_std": 0.4134446382522583, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.16610436141490936, "train/cont_pos_acc": 0.07624633610248566, "train/cont_pos_loss": 1.2627122402191162, "train/cont_pred": 0.3061295449733734, "train/cont_rate": 0.9990234375, "train/dyn_loss_mean": 10.898059844970703, "train/dyn_loss_std": 0.4435180425643921, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 2.0662684440612793, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 8335.099609375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3578.26806640625, "train/image_loss_std": 153.8756561279297, "train/model_loss_mean": 3591.60986328125, "train/model_loss_std": 153.89967346191406, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 35916100.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7842020988464355, "train/policy_entropy_max": 2.7842020988464355, "train/policy_entropy_mean": 2.5622341632843018, "train/policy_entropy_min": 1.639525055885315, "train/policy_entropy_std": 0.09758855402469635, "train/policy_logprob_mag": 5.417365550994873, "train/policy_logprob_max": -0.5878995060920715, "train/policy_logprob_mean": -2.566114664077759, "train/policy_logprob_min": -5.417365550994873, "train/policy_logprob_std": 0.7166030406951904, "train/policy_randomness_mag": 0.9827011823654175, "train/policy_randomness_max": 0.9827011823654175, "train/policy_randomness_mean": 0.9043563008308411, "train/policy_randomness_min": 0.5786803960800171, "train/policy_randomness_std": 0.034444477409124374, "train/post_ent_mag": 105.92745971679688, "train/post_ent_max": 105.92745971679688, "train/post_ent_mean": 105.377197265625, "train/post_ent_min": 104.79957580566406, "train/post_ent_std": 0.20620544254779816, "train/prior_ent_mag": 106.42483520507812, "train/prior_ent_max": 106.42483520507812, "train/prior_ent_mean": 105.54045104980469, "train/prior_ent_min": 104.65655517578125, "train/prior_ent_std": 0.28990864753723145, "train/rep_loss_mean": 10.898059844970703, "train/rep_loss_std": 0.4435180425643921, "train/reward_avg": 0.01650390587747097, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541264057159424, "train/reward_pred": 0.0, "train/reward_rate": 0.0185546875, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 1.3819102048873901, "report/cont_loss_std": 0.47351497411727905, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.13807116448879242, "report/cont_pos_acc": 0.06060606241226196, "report/cont_pos_loss": 1.383126139640808, "report/cont_pred": 0.2781972289085388, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 10.821523666381836, "report/dyn_loss_std": 0.4415181279182434, "report/image_loss_mean": 3580.519287109375, "report/image_loss_std": 157.06480407714844, "report/model_loss_mean": 3593.935546875, "report/model_loss_std": 157.1649627685547, "report/post_ent_mag": 105.91891479492188, "report/post_ent_max": 105.91891479492188, "report/post_ent_mean": 105.38055419921875, "report/post_ent_min": 104.86363983154297, "report/post_ent_std": 0.2086166888475418, "report/prior_ent_mag": 106.344482421875, "report/prior_ent_max": 106.344482421875, "report/prior_ent_mean": 105.61328887939453, "report/prior_ent_min": 104.52166748046875, "report/prior_ent_std": 0.28147193789482117, "report/rep_loss_mean": 10.821523666381836, "report/rep_loss_std": 0.4415181279182434, "report/reward_avg": 0.01650390587747097, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541264057159424, "report/reward_pred": 0.0, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.3639657497406006, "eval/cont_loss_std": 0.4606130123138428, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.6106092929840088, "eval/cont_pos_acc": 0.0519607812166214, "eval/cont_pos_loss": 1.366919994354248, "eval/cont_pred": 0.28197240829467773, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 10.87026596069336, "eval/dyn_loss_std": 0.4623805582523346, "eval/image_loss_mean": 3608.9619140625, "eval/image_loss_std": 163.33071899414062, "eval/model_loss_mean": 3622.389404296875, "eval/model_loss_std": 163.38644409179688, "eval/post_ent_mag": 106.0269775390625, "eval/post_ent_max": 106.0269775390625, "eval/post_ent_mean": 105.37808990478516, "eval/post_ent_min": 104.81742095947266, "eval/post_ent_std": 0.20239795744419098, "eval/prior_ent_mag": 106.50628662109375, "eval/prior_ent_max": 106.50628662109375, "eval/prior_ent_mean": 105.56330108642578, "eval/prior_ent_min": 104.60044860839844, "eval/prior_ent_std": 0.302333265542984, "eval/rep_loss_mean": 10.87026596069336, "eval/rep_loss_std": 0.4623805582523346, "eval/reward_avg": 0.01953125, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.559997806718457e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263103485107, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0244140625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.6968996883453687e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0068927492414202e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2944.0, "eval_replay/inserts": 2944.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 2.597094230029894e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.558030537196567e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 247.20291352272034, "timer/env.step_count": 196.0, "timer/env.step_total": 27.05772852897644, "timer/env.step_frac": 0.10945554056542127, "timer/env.step_avg": 0.1380496353519206, "timer/env.step_min": 0.02196335792541504, "timer/env.step_max": 11.308161497116089, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.12098407745361328, "timer/replay._sample_frac": 0.0004894120207951905, "timer/replay._sample_avg": 0.0010802149772644043, "timer/replay._sample_min": 0.0003705024719238281, "timer/replay._sample_max": 0.014536857604980469, "timer/agent.save_count": 1.0, "timer/agent.save_total": 12.636218070983887, "timer/agent.save_frac": 0.0511167845512569, "timer/agent.save_avg": 12.636218070983887, "timer/agent.save_min": 12.636218070983887, "timer/agent.save_max": 12.636218070983887, "timer/agent.policy_count": 237.0, "timer/agent.policy_total": 32.54871106147766, "timer/agent.policy_frac": 0.13166799127748194, "timer/agent.policy_avg": 0.13733633359273276, "timer/agent.policy_min": 0.008964300155639648, "timer/agent.policy_max": 25.49160385131836, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.719329833984375e-05, "timer/dataset_train_frac": 1.5045655332223796e-07, "timer/dataset_train_avg": 3.719329833984375e-05, "timer/dataset_train_min": 3.719329833984375e-05, "timer/dataset_train_max": 3.719329833984375e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.48050832748413, "timer/agent.train_frac": 0.37006241966916054, "timer/agent.train_avg": 91.48050832748413, "timer/agent.train_min": 91.48050832748413, "timer/agent.train_max": 91.48050832748413, "timer/agent.report_count": 2.0, "timer/agent.report_total": 24.069334030151367, "timer/agent.report_frac": 0.09736670853573562, "timer/agent.report_avg": 12.034667015075684, "timer/agent.report_min": 0.24855446815490723, "timer/agent.report_max": 23.82077956199646, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 1.224870658456681e-07, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05}
{"step": 1976, "time": 377.1920254230499, "episode/length": 149.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 2240, "time": 387.6679277420044, "episode/length": 279.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 2544, "time": 399.12632870674133, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 2712, "time": 405.8759515285492, "episode/length": 58.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 2728, "time": 407.9545166492462, "episode/length": 162.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 2752, "time": 410.41043162345886, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 2880, "time": 416.2282269001007, "episode/length": 209.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 3400, "time": 434.44872760772705, "episode/length": 233.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 3720, "time": 446.290807723999, "episode/length": 146.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 3904, "time": 454.0970735549927, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 4016, "time": 459.2926712036133, "episode/length": 254.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 4072, "time": 462.535462141037, "episode/length": 169.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 4096, "time": 465.06457114219666, "episode/length": 395.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 4368, "time": 475.4865915775299, "episode/length": 120.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 4592, "time": 484.36974000930786, "episode/length": 232.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 4696, "time": 489.0446443557739, "episode/length": 226.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 4864, "time": 496.14174032211304, "episode/length": 142.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 5272, "time": 510.7740433216095, "episode/length": 170.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 5544, "time": 521.1651766300201, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 5704, "time": 527.9215760231018, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 5792, "time": 532.5074048042297, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 5800, "time": 534.1171877384186, "episode/length": 212.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 5976, "time": 541.4568901062012, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 6200, "time": 550.4153258800507, "episode/length": 166.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 6208, "time": 552.47935962677, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 6304, "time": 557.6926875114441, "episode/length": 63.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 6392, "time": 562.4172866344452, "episode/length": 105.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 6800, "time": 578.2386860847473, "episode/length": 74.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 6816, "time": 580.3259966373444, "episode/length": 192.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 7240, "time": 595.4756155014038, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 7464, "time": 604.4474711418152, "episode/length": 219.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 7656, "time": 612.1276805400848, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 7696, "time": 615.1526758670807, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 7720, "time": 617.2250778675079, "episode/length": 59.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 7792, "time": 621.4823009967804, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 8088, "time": 632.5369925498962, "episode/length": 222.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 8200, "time": 637.7488794326782, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 8440, "time": 648.6536316871643, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 8712, "time": 659.0596516132355, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 9056, "time": 671.8490171432495, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 9160, "time": 676.5010616779327, "episode/length": 179.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 9312, "time": 683.0939433574677, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 9368, "time": 686.1901335716248, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 9856, "time": 703.933801651001, "episode/length": 176.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 10064, "time": 712.2236173152924, "episode/length": 232.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 729.8860898017883, "eval_episode/length": 61.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9354838709677419}
{"step": 10088, "time": 731.5083158016205, "eval_episode/length": 65.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9242424242424242}
{"step": 10088, "time": 735.9495573043823, "eval_episode/length": 137.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9637681159420289}
{"step": 10088, "time": 738.0666189193726, "eval_episode/length": 150.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 10088, "time": 738.0735745429993, "eval_episode/length": 150.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 10088, "time": 743.282240152359, "eval_episode/length": 199.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 10088, "time": 745.4379625320435, "eval_episode/length": 214.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 10088, "time": 747.3230752944946, "eval_episode/length": 224.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9822222222222222}
{"step": 10152, "time": 749.3830556869507, "episode/length": 179.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 10352, "time": 757.6877329349518, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 10408, "time": 760.8623106479645, "episode/length": 338.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 10520, "time": 766.0168182849884, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 10648, "time": 771.586368560791, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 10856, "time": 779.8351032733917, "episode/length": 62.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 10872, "time": 782.0993700027466, "episode/length": 194.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 10984, "time": 787.308837890625, "episode/length": 114.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 11080, "time": 791.9935441017151, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 11344, "time": 802.3581738471985, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 11512, "time": 809.0999093055725, "episode/length": 107.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 11792, "time": 820.0067193508148, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 12048, "time": 829.8303325176239, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 12304, "time": 839.67222905159, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 12456, "time": 846.1351528167725, "episode/length": 50.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 12592, "time": 852.1428227424622, "episode/length": 214.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 12808, "time": 860.3575556278229, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 12816, "time": 862.3276464939117, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 12936, "time": 867.4537472724915, "episode/length": 231.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9870689655172413, "episode/intrinsic_return": 0.0}
{"step": 12976, "time": 870.4790744781494, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 13032, "time": 873.7394971847534, "episode/length": 271.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 13856, "time": 902.0902543067932, "episode/length": 102.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 14088, "time": 911.0591585636139, "episode/length": 222.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 14112, "time": 913.631427526474, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 14112, "time": 913.6396706104279, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 14224, "time": 920.5669310092926, "episode/length": 176.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 14232, "time": 922.2039041519165, "episode/length": 176.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 14368, "time": 928.4097917079926, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 14896, "time": 947.1259858608246, "episode/length": 244.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 15280, "time": 961.027752161026, "episode/length": 130.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 15296, "time": 963.167072057724, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 15432, "time": 968.9170989990234, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 15576, "time": 975.1469180583954, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 15896, "time": 986.9368088245392, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 16064, "time": 994.1970181465149, "episode/length": 243.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9877049180327869, "episode/intrinsic_return": 0.0}
{"step": 16224, "time": 1001.0197038650513, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 16280, "time": 1004.1689820289612, "episode/length": 238.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.9874476987447699, "episode/intrinsic_return": 0.0}
{"step": 16376, "time": 1008.771327495575, "episode/length": 268.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 16520, "time": 1016.003256559372, "episode/length": 36.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 16656, "time": 1022.2636518478394, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 16664, "time": 1023.7740831375122, "episode/length": 172.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 16752, "time": 1028.45046377182, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 17192, "time": 1044.1408333778381, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 17568, "time": 1058.1609725952148, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 17600, "time": 1061.0430362224579, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 17928, "time": 1072.9850144386292, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 17968, "time": 1075.9745404720306, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 18056, "time": 1080.0792758464813, "episode/length": 191.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 18064, "time": 1082.199453830719, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 18104, "time": 1084.7977888584137, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 18456, "time": 1097.8420050144196, "episode/length": 65.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 18784, "time": 1110.177515745163, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 19160, "time": 1123.9915142059326, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 19176, "time": 1126.707734823227, "episode/length": 139.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 19352, "time": 1134.0379321575165, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 19592, "time": 1143.3766264915466, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 19656, "time": 1147.5903866291046, "episode/length": 307.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 19656, "time": 1147.5996198654175, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 19720, "time": 1153.4419481754303, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1182.3510749340057, "eval_episode/length": 77.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 20072, "time": 1186.2484517097473, "eval_episode/length": 133.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 20072, "time": 1188.808010339737, "eval_episode/length": 156.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 20072, "time": 1190.497153043747, "eval_episode/length": 158.0, "eval_episode/score": 0.09999997913837433, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 20072, "time": 1192.3154201507568, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 20072, "time": 1194.8676221370697, "eval_episode/length": 187.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 20072, "time": 1197.4224598407745, "eval_episode/length": 213.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 20072, "time": 1199.4224677085876, "eval_episode/length": 228.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 20176, "time": 1203.0424785614014, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 20600, "time": 1218.0557413101196, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 20784, "time": 1225.769600391388, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 20872, "time": 1229.9888362884521, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 20896, "time": 1232.5532357692719, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 20992, "time": 1237.1743354797363, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 21000, "time": 1238.7086544036865, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 21120, "time": 1244.3224232196808, "episode/length": 64.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 21304, "time": 1251.6027405261993, "episode/length": 243.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 21664, "time": 1265.0897464752197, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 22040, "time": 1278.4869079589844, "episode/length": 142.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 22200, "time": 1285.2023270130157, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 22208, "time": 1287.2356791496277, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 22304, "time": 1291.8354179859161, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 22464, "time": 1298.6388812065125, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 22512, "time": 1301.7510318756104, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 22536, "time": 1303.8576173782349, "episode/length": 41.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 22640, "time": 1309.0499563217163, "episode/length": 41.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 22744, "time": 1313.6214966773987, "episode/length": 34.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 23072, "time": 1325.9135994911194, "episode/length": 175.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 23320, "time": 1335.2531945705414, "episode/length": 251.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 23401, "time": 1340.475534439087, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.607929902918198, "train/action_min": 0.0, "train/action_std": 2.2066710416008446, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01932938774167697, "train/actor_opt_grad_steps": 685.0, "train/actor_opt_loss": 193.54124197188546, "train/adv_mag": 2.228511407478329, "train/adv_max": 2.224385352969608, "train/adv_mean": 0.04095066081144443, "train/adv_min": -0.3301847678222283, "train/adv_std": 0.18164520298673512, "train/cont_avg": 0.9944134880514706, "train/cont_loss_mean": 0.030328522636623615, "train/cont_loss_std": 0.23839951831135242, "train/cont_neg_acc": 0.13813317304148393, "train/cont_neg_loss": 2.9678076415815773, "train/cont_pos_acc": 0.9927692668348113, "train/cont_pos_loss": 0.014458656249831513, "train/cont_pred": 0.9891862632597194, "train/cont_rate": 0.9944134880514706, "train/dyn_loss_mean": 5.556253529646817, "train/dyn_loss_std": 7.099933791029103, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.300753706956611, "train/extr_critic_critic_opt_grad_steps": 685.0, "train/extr_critic_critic_opt_loss": 22413.306640625, "train/extr_critic_mag": 0.4043221158139846, "train/extr_critic_max": 0.4043221140609068, "train/extr_critic_mean": 0.1442537986715715, "train/extr_critic_min": -0.0561443286783555, "train/extr_critic_std": 0.13143647092268593, "train/extr_return_normed_mag": 2.5650427005859777, "train/extr_return_normed_max": 2.564941762420965, "train/extr_return_normed_mean": 0.23569695210608188, "train/extr_return_normed_min": -0.16686600076836305, "train/extr_return_normed_std": 0.245437950371792, "train/extr_return_rate": 0.13558374327626285, "train/extr_return_raw_mag": 2.8125023455085123, "train/extr_return_raw_max": 2.8125023455085123, "train/extr_return_raw_mean": 0.19123331353886683, "train/extr_return_raw_min": -0.30646555800579817, "train/extr_return_raw_std": 0.2968319536958006, "train/extr_reward_mag": 0.6722079673234154, "train/extr_reward_max": 0.6722079673234154, "train/extr_reward_mean": 0.00949942438838287, "train/extr_reward_min": -0.06518257628468906, "train/extr_reward_std": 0.056353360676082535, "train/image_loss_mean": 86.90678745157578, "train/image_loss_std": 46.77926701657913, "train/model_loss_mean": 90.58217616642223, "train/model_loss_std": 48.284867756506976, "train/model_opt_grad_norm": 368.8711853027344, "train/model_opt_grad_steps": 676.0, "train/model_opt_loss": 1899.506456038531, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 24.701286764705884, "train/policy_entropy_mag": 1.3717128326568533, "train/policy_entropy_max": 1.3717128326568533, "train/policy_entropy_mean": 0.8040859380408245, "train/policy_entropy_min": 0.6735498894225148, "train/policy_entropy_std": 0.09945796479758642, "train/policy_logprob_mag": 6.854660195462844, "train/policy_logprob_max": -0.33325747653896753, "train/policy_logprob_mean": -0.8049926041789791, "train/policy_logprob_min": -6.854660195462844, "train/policy_logprob_std": 0.7886747969862293, "train/policy_randomness_mag": 0.48415443440899253, "train/policy_randomness_max": 0.48415443440899253, "train/policy_randomness_mean": 0.2838070490397513, "train/policy_randomness_min": 0.2377335530541399, "train/policy_randomness_std": 0.035104296824155265, "train/post_ent_mag": 51.5816813917721, "train/post_ent_max": 51.5816813917721, "train/post_ent_mean": 33.47338015892927, "train/post_ent_min": 17.14640420324662, "train/post_ent_std": 6.0481987416963365, "train/prior_ent_mag": 58.17440981023452, "train/prior_ent_max": 58.17440981023452, "train/prior_ent_mean": 39.72428557452034, "train/prior_ent_min": 23.098519381354837, "train/prior_ent_std": 5.962034505408476, "train/rep_loss_mean": 5.556253529646817, "train/rep_loss_std": 7.099933791029103, "train/reward_avg": 0.0071145449456868366, "train/reward_loss_mean": 0.3113090447971926, "train/reward_loss_std": 0.6252172445263765, "train/reward_max_data": 1.0058823543436386, "train/reward_max_pred": 0.7345279937281328, "train/reward_neg_acc": 0.9969545975327492, "train/reward_neg_loss": 0.28067103135125604, "train/reward_pos_acc": 0.5264326611205059, "train/reward_pos_loss": 2.8242824090754284, "train/reward_pred": 0.005444599645938177, "train/reward_rate": 0.012041877297794117, "train_stats/sum_log_reward": 1.1239999640583993, "train_stats/max_log_achievement_collect_drink": 0.12, "train_stats/max_log_achievement_collect_sapling": 8.488, "train_stats/max_log_achievement_collect_wood": 0.088, "train_stats/max_log_achievement_place_plant": 0.608, "train_stats/max_log_achievement_place_table": 0.008, "train_stats/max_log_achievement_wake_up": 0.896, "train_stats/mean_log_entropy": 0.6501260203719139, "train_stats/max_log_achievement_eat_cow": 0.09174311926605505, "train_stats/max_log_achievement_defeat_zombie": 0.24742268041237114, "eval_stats/sum_log_reward": 0.912499968893826, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 6.4375, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 0.3125, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.0016375717241317034, "report/cont_loss_std": 0.017220577225089073, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.17474150657653809, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0011289409594610333, "report/cont_pred": 0.9964543581008911, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 6.311952590942383, "report/dyn_loss_std": 5.7389607429504395, "report/image_loss_mean": 19.9704647064209, "report/image_loss_std": 20.784465789794922, "report/model_loss_mean": 23.85076141357422, "report/model_loss_std": 22.678592681884766, "report/post_ent_mag": 42.71159362792969, "report/post_ent_max": 42.71159362792969, "report/post_ent_mean": 28.998390197753906, "report/post_ent_min": 11.328531265258789, "report/post_ent_std": 4.3566975593566895, "report/prior_ent_mag": 50.24908447265625, "report/prior_ent_max": 50.24908447265625, "report/prior_ent_mean": 36.17447280883789, "report/prior_ent_min": 17.899852752685547, "report/prior_ent_std": 5.343667984008789, "report/rep_loss_mean": 6.311952590942383, "report/rep_loss_std": 5.7389607429504395, "report/reward_avg": 0.01318359375, "report/reward_loss_mean": 0.09148544073104858, "report/reward_loss_std": 0.44135627150535583, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.99391770362854, "report/reward_neg_acc": 0.9960318207740784, "report/reward_neg_loss": 0.06964758038520813, "report/reward_pos_acc": 0.8125, "report/reward_pos_loss": 1.467270851135254, "report/reward_pred": 0.010509960353374481, "report/reward_rate": 0.015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.008061343804001808, "eval/cont_loss_std": 0.1999664455652237, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 4.097092628479004, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.932457133894786e-05, "eval/cont_pred": 0.9998268485069275, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.202336311340332, "eval/dyn_loss_std": 7.159063816070557, "eval/image_loss_mean": 81.79788970947266, "eval/image_loss_std": 95.31571197509766, "eval/model_loss_mean": 88.05815124511719, "eval/model_loss_std": 97.57062530517578, "eval/post_ent_mag": 47.68302917480469, "eval/post_ent_max": 47.68302917480469, "eval/post_ent_mean": 31.867063522338867, "eval/post_ent_min": 12.421887397766113, "eval/post_ent_std": 7.86650276184082, "eval/prior_ent_mag": 53.04341506958008, "eval/prior_ent_max": 53.04341506958008, "eval/prior_ent_mean": 37.71541976928711, "eval/prior_ent_min": 15.545154571533203, "eval/prior_ent_std": 7.252701759338379, "eval/rep_loss_mean": 10.202336311340332, "eval/rep_loss_std": 7.159063816070557, "eval/reward_avg": 0.010058593936264515, "eval/reward_loss_mean": 0.13080014288425446, "eval/reward_loss_std": 0.9165077805519104, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9904754161834717, "eval/reward_neg_acc": 0.9940652251243591, "eval/reward_neg_loss": 0.07358607649803162, "eval/reward_pos_acc": 0.38461539149284363, "eval/reward_pos_loss": 4.580295562744141, "eval/reward_pred": 0.005801696330308914, "eval/reward_rate": 0.0126953125, "replay/size": 22897.0, "replay/inserts": 21840.0, "replay/samples": 21840.0, "replay/insert_wait_avg": 1.3811575187431586e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.869044516986107e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6576.0, "eval_replay/inserts": 3632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1956376651310186e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 976.4554779529572, "timer/env.step_count": 2730.0, "timer/env.step_total": 269.60925698280334, "timer/env.step_frac": 0.276110138219525, "timer/env.step_avg": 0.09875796959077046, "timer/env.step_min": 0.022965431213378906, "timer/env.step_max": 3.8221209049224854, "timer/replay._sample_count": 21840.0, "timer/replay._sample_total": 11.350030660629272, "timer/replay._sample_frac": 0.011623705245039431, "timer/replay._sample_avg": 0.0005196900485636114, "timer/replay._sample_min": 0.0003514289855957031, "timer/replay._sample_max": 0.011199951171875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3184.0, "timer/agent.policy_total": 47.8749885559082, "timer/agent.policy_frac": 0.04902936143721925, "timer/agent.policy_avg": 0.015036114496202325, "timer/agent.policy_min": 0.0085296630859375, "timer/agent.policy_max": 0.08598566055297852, "timer/dataset_train_count": 1365.0, "timer/dataset_train_total": 0.14492249488830566, "timer/dataset_train_frac": 0.00014841689985919422, "timer/dataset_train_avg": 0.00010617032592549866, "timer/dataset_train_min": 8.606910705566406e-05, "timer/dataset_train_max": 0.0004761219024658203, "timer/agent.train_count": 1365.0, "timer/agent.train_total": 594.3482186794281, "timer/agent.train_frac": 0.6086792814408913, "timer/agent.train_avg": 0.43541994042448945, "timer/agent.train_min": 0.4254419803619385, "timer/agent.train_max": 1.2057781219482422, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48502206802368164, "timer/agent.report_frac": 0.0004967170331621086, "timer/agent.report_avg": 0.24251103401184082, "timer/agent.report_min": 0.23664307594299316, "timer/agent.report_max": 0.24837899208068848, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.47955322265625e-05, "timer/dataset_eval_frac": 2.539340787820034e-08, "timer/dataset_eval_avg": 2.47955322265625e-05, "timer/dataset_eval_min": 2.47955322265625e-05, "timer/dataset_eval_max": 2.47955322265625e-05, "fps": 22.366325121429675}
{"step": 23488, "time": 1343.2699818611145, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 23496, "time": 1344.9104301929474, "episode/length": 52.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.0}
{"step": 23504, "time": 1346.8997540473938, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 23920, "time": 1361.847841501236, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 23968, "time": 1365.0227704048157, "episode/length": 80.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 24128, "time": 1371.792810678482, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 24144, "time": 1373.8618404865265, "episode/length": 203.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 24144, "time": 1373.8708124160767, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 24880, "time": 1402.2427697181702, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 24992, "time": 1407.3422050476074, "episode/length": 105.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9528301886792453, "episode/intrinsic_return": 0.0}
{"step": 25056, "time": 1410.9000568389893, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 25144, "time": 1415.1659998893738, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 25304, "time": 1421.7798264026642, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 25304, "time": 1421.7880673408508, "episode/length": 226.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 25368, "time": 1427.1121017932892, "episode/length": 174.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 25672, "time": 1438.4303863048553, "episode/length": 190.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 26048, "time": 1452.3197031021118, "episode/length": 92.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 26192, "time": 1458.507066488266, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 26504, "time": 1469.9115109443665, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 26536, "time": 1472.63086271286, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 26600, "time": 1476.3172552585602, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 26664, "time": 1479.8508694171906, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 26728, "time": 1483.5661525726318, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 26960, "time": 1492.875606060028, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 27432, "time": 1509.515174627304, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 27488, "time": 1513.0788340568542, "episode/length": 94.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 27552, "time": 1516.7224717140198, "episode/length": 126.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 28080, "time": 1535.529543876648, "episode/length": 235.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 28088, "time": 1537.0858850479126, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 28088, "time": 1537.0938906669617, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 28272, "time": 1546.4297206401825, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 28480, "time": 1554.6578464508057, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 28536, "time": 1557.8093116283417, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 28776, "time": 1567.1843948364258, "episode/length": 263.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 29456, "time": 1590.9054162502289, "episode/length": 237.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 29520, "time": 1594.801005601883, "episode/length": 253.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 29656, "time": 1600.5339958667755, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 29656, "time": 1600.5424737930298, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 29664, "time": 1604.225399017334, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 29840, "time": 1611.4404127597809, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1639.8848593235016, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 30056, "time": 1641.5808198451996, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 30056, "time": 1643.1642816066742, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 30056, "time": 1646.3162276744843, "eval_episode/length": 191.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 30056, "time": 1648.091875076294, "eval_episode/length": 195.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 30056, "time": 1649.7871310710907, "eval_episode/length": 196.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 30056, "time": 1653.0193054676056, "eval_episode/length": 235.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 30056, "time": 1654.9552550315857, "eval_episode/length": 52.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9245283018867925}
{"step": 30072, "time": 1655.4766685962677, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 30408, "time": 1667.9796087741852, "episode/length": 93.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9468085106382979, "episode/intrinsic_return": 0.0}
{"step": 30496, "time": 1672.561226606369, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 30744, "time": 1682.0536088943481, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 30888, "time": 1688.1333191394806, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 31032, "time": 1694.289170742035, "episode/length": 171.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 31720, "time": 1717.9419424533844, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 31736, "time": 1719.9614956378937, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 31752, "time": 1722.1005396842957, "episode/length": 238.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 31920, "time": 1729.5903778076172, "episode/length": 110.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 32112, "time": 1737.3939716815948, "episode/length": 201.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 32536, "time": 1752.4248340129852, "episode/length": 99.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 32576, "time": 1755.4926075935364, "episode/length": 389.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 32688, "time": 1760.5500116348267, "episode/length": 71.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.0}
{"step": 32696, "time": 1762.1006801128387, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 32896, "time": 1771.4317214488983, "episode/length": 268.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 33024, "time": 1777.1948227882385, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 33048, "time": 1779.2777211666107, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 33064, "time": 1781.2647268772125, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 33360, "time": 1792.4630694389343, "episode/length": 97.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 33816, "time": 1808.4640171527863, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 33872, "time": 1811.9476454257965, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 34240, "time": 1825.4052016735077, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 34264, "time": 1827.6560566425323, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 34312, "time": 1830.7383406162262, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 34496, "time": 1838.6433715820312, "episode/length": 183.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 34512, "time": 1840.7913019657135, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 34616, "time": 1845.4044315814972, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 34696, "time": 1849.5187866687775, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 34776, "time": 1853.66845536232, "episode/length": 32.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 35056, "time": 1864.4159059524536, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 35480, "time": 1879.4025452136993, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 35672, "time": 1887.075055360794, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 36032, "time": 1900.6631164550781, "episode/length": 220.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 36072, "time": 1903.2369513511658, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 36152, "time": 1907.2762687206268, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 36184, "time": 1909.9601204395294, "episode/length": 210.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 36232, "time": 1913.0712015628815, "episode/length": 191.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 36504, "time": 1923.3265116214752, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 37000, "time": 1940.753749847412, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 37360, "time": 1954.1656818389893, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 37440, "time": 1958.2943835258484, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 37632, "time": 1966.0909156799316, "episode/length": 244.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 37728, "time": 1970.7336049079895, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 37840, "time": 1975.814521074295, "episode/length": 220.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 38224, "time": 1989.7489666938782, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 38272, "time": 1992.8344247341156, "episode/length": 220.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 38280, "time": 1994.4440939426422, "episode/length": 255.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 38816, "time": 2013.5115103721619, "episode/length": 181.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 38880, "time": 2017.1110789775848, "episode/length": 179.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 38912, "time": 2019.732503414154, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 38992, "time": 2023.965714931488, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 39008, "time": 2026.0391404628754, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 39512, "time": 2043.586233139038, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 39616, "time": 2048.608323574066, "episode/length": 167.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2083.1608192920685, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 40040, "time": 2084.7833733558655, "eval_episode/length": 167.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 40040, "time": 2086.41880941391, "eval_episode/length": 173.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 40040, "time": 2088.4233407974243, "eval_episode/length": 182.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 40040, "time": 2090.394421815872, "eval_episode/length": 192.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 40040, "time": 2092.1571023464203, "eval_episode/length": 197.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 40040, "time": 2095.0166528224945, "eval_episode/length": 228.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.982532751091703}
{"step": 40040, "time": 2098.1784625053406, "eval_episode/length": 266.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 40224, "time": 2104.3636877536774, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 40512, "time": 2115.24559879303, "episode/length": 278.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 40608, "time": 2119.8534746170044, "episode/length": 211.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 40648, "time": 2122.57417011261, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 40784, "time": 2128.6789920330048, "episode/length": 237.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 40824, "time": 2131.4767060279846, "episode/length": 226.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 40840, "time": 2133.4447944164276, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 41416, "time": 2154.6694045066833, "episode/length": 224.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 41568, "time": 2161.3576481342316, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 41736, "time": 2167.997305870056, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 41920, "time": 2175.539638519287, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 42056, "time": 2181.308221101761, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 42296, "time": 2190.745179414749, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 42328, "time": 2193.5322127342224, "episode/length": 192.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 42432, "time": 2198.627217769623, "episode/length": 200.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 43016, "time": 2218.590833425522, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 43144, "time": 2224.2080142498016, "episode/length": 196.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 43440, "time": 2235.423579931259, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 43496, "time": 2238.631110191345, "episode/length": 179.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 43680, "time": 2246.3521649837494, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 43784, "time": 2251.0124974250793, "episode/length": 232.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 43936, "time": 2257.7719678878784, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 44008, "time": 2261.3703877925873, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 44136, "time": 2266.992218017578, "episode/length": 43.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 44232, "time": 2271.5379152297974, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 44360, "time": 2277.201665878296, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 44464, "time": 2282.327687740326, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 44584, "time": 2287.5088727474213, "episode/length": 142.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 45160, "time": 2307.5420999526978, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 45320, "time": 2314.3762788772583, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 45360, "time": 2317.4087908267975, "episode/length": 232.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 45504, "time": 2323.6983346939087, "episode/length": 142.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 45560, "time": 2326.9548196792603, "episode/length": 165.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 45720, "time": 2333.526184797287, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 45865, "time": 2340.7925033569336, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.27245790738586, "train/action_min": 0.0, "train/action_std": 2.562506654583816, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03184315378625765, "train/actor_opt_grad_steps": 2070.0, "train/actor_opt_loss": 16.542387264628783, "train/adv_mag": 1.5934835332082518, "train/adv_max": 1.5894851200546778, "train/adv_mean": 0.011936223403918507, "train/adv_min": -0.5824084877967834, "train/adv_std": 0.11813627381591087, "train/cont_avg": 0.9941891068262412, "train/cont_loss_mean": 0.001438911954229549, "train/cont_loss_std": 0.03165514320310049, "train/cont_neg_acc": 0.9463185606696082, "train/cont_neg_loss": 0.15272929439934096, "train/cont_pos_acc": 0.9998466845945264, "train/cont_pos_loss": 0.0005659332425629216, "train/cont_pred": 0.994197262094376, "train/cont_rate": 0.9941891068262412, "train/dyn_loss_mean": 6.403604064427369, "train/dyn_loss_std": 5.967398257965737, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.5171190267759012, "train/extr_critic_critic_opt_grad_steps": 2070.0, "train/extr_critic_critic_opt_loss": 15930.772869570035, "train/extr_critic_mag": 1.660640851825687, "train/extr_critic_max": 1.660640851825687, "train/extr_critic_mean": 0.41622486277252224, "train/extr_critic_min": -0.31699770984920206, "train/extr_critic_std": 0.63857427662146, "train/extr_return_normed_mag": 2.424238091664957, "train/extr_return_normed_max": 2.424238091664957, "train/extr_return_normed_mean": 0.38036593329821916, "train/extr_return_normed_min": -0.31706692265174913, "train/extr_return_normed_std": 0.37058059374491376, "train/extr_return_rate": 0.3536449267086408, "train/extr_return_raw_mag": 4.360605736996265, "train/extr_return_raw_max": 4.360605736996265, "train/extr_return_raw_mean": 0.4392112376208001, "train/extr_return_raw_min": -0.8992117560924368, "train/extr_return_raw_std": 0.7101317840687772, "train/extr_reward_mag": 0.998418946638175, "train/extr_reward_max": 0.998418946638175, "train/extr_reward_mean": 0.011622526891284344, "train/extr_reward_min": -0.37911848988093383, "train/extr_reward_std": 0.08887107519710317, "train/image_loss_mean": 15.815481733768545, "train/image_loss_std": 16.952018379319643, "train/model_loss_mean": 19.728065544831836, "train/model_loss_std": 18.687280059706236, "train/model_opt_grad_norm": 146.13777753140064, "train/model_opt_grad_steps": 2061.0, "train/model_opt_loss": 1201.300208991301, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 60.117464539007095, "train/policy_entropy_mag": 1.6962425463588526, "train/policy_entropy_max": 1.6962425463588526, "train/policy_entropy_mean": 0.3195878742857182, "train/policy_entropy_min": 0.07960133983733807, "train/policy_entropy_std": 0.2999441457767013, "train/policy_logprob_mag": 7.437644292276802, "train/policy_logprob_max": -0.009487012962658777, "train/policy_logprob_mean": -0.31918809335705234, "train/policy_logprob_min": -7.437644292276802, "train/policy_logprob_std": 0.9314343434699038, "train/policy_randomness_mag": 0.5986991799469535, "train/policy_randomness_max": 0.5986991799469535, "train/policy_randomness_mean": 0.11280049526310981, "train/policy_randomness_min": 0.028095779715911717, "train/policy_randomness_std": 0.10586712113086214, "train/post_ent_mag": 42.27193946026741, "train/post_ent_max": 42.27193946026741, "train/post_ent_mean": 30.531788440460854, "train/post_ent_min": 12.605356236721606, "train/post_ent_std": 4.942255121596316, "train/prior_ent_mag": 52.45354361567937, "train/prior_ent_max": 52.45354361567937, "train/prior_ent_mean": 37.10458030430138, "train/prior_ent_min": 15.341855245279081, "train/prior_ent_std": 5.917099529969777, "train/rep_loss_mean": 6.403604064427369, "train/rep_loss_std": 5.967398257965737, "train/reward_avg": 0.008508560442364055, "train/reward_loss_mean": 0.06898250701632483, "train/reward_loss_std": 0.33957705799992205, "train/reward_max_data": 1.0078014202997194, "train/reward_max_pred": 0.9971335272417001, "train/reward_neg_acc": 0.9951982908215083, "train/reward_neg_loss": 0.052363231322391235, "train/reward_pos_acc": 0.8832356291459807, "train/reward_pos_loss": 1.2710543241061218, "train/reward_pred": 0.00799581382245301, "train/reward_rate": 0.013748060726950355, "train_stats/sum_log_reward": 2.2627906290482183, "train_stats/max_log_achievement_collect_drink": 6.1395348837209305, "train_stats/max_log_achievement_collect_sapling": 2.116279069767442, "train_stats/max_log_achievement_collect_wood": 0.20930232558139536, "train_stats/max_log_achievement_defeat_zombie": 0.12403100775193798, "train_stats/max_log_achievement_eat_cow": 0.10077519379844961, "train_stats/max_log_achievement_place_plant": 1.9689922480620154, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.62015503875969, "train_stats/mean_log_entropy": 0.1722440582144168, "eval_stats/sum_log_reward": 2.09999992698431, "eval_stats/max_log_achievement_collect_drink": 4.8125, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00034913700073957443, "report/cont_loss_std": 0.005876939743757248, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004841713234782219, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003137623716611415, "report/cont_pred": 0.9919302463531494, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 6.6306281089782715, "report/dyn_loss_std": 5.8467278480529785, "report/image_loss_mean": 16.445999145507812, "report/image_loss_std": 14.29007625579834, "report/model_loss_mean": 20.485692977905273, "report/model_loss_std": 15.674999237060547, "report/post_ent_mag": 44.858680725097656, "report/post_ent_max": 44.858680725097656, "report/post_ent_mean": 31.147212982177734, "report/post_ent_min": 12.901597023010254, "report/post_ent_std": 5.964056968688965, "report/prior_ent_mag": 53.651920318603516, "report/prior_ent_max": 53.651920318603516, "report/prior_ent_mean": 38.389678955078125, "report/prior_ent_min": 16.234012603759766, "report/prior_ent_std": 7.2082061767578125, "report/rep_loss_mean": 6.6306281089782715, "report/rep_loss_std": 5.8467278480529785, "report/reward_avg": 0.00996093824505806, "report/reward_loss_mean": 0.060968317091464996, "report/reward_loss_std": 0.28263601660728455, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006225109100342, "report/reward_neg_acc": 0.9930486679077148, "report/reward_neg_loss": 0.04149964824318886, "report/reward_pos_acc": 0.8235294222831726, "report/reward_pos_loss": 1.2142008543014526, "report/reward_pred": 0.007892368361353874, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00368536077439785, "eval/cont_loss_std": 0.05280185863375664, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007971235550940037, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.003668552963063121, "eval/cont_pred": 0.9934783577919006, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 12.16124153137207, "eval/dyn_loss_std": 8.00415325164795, "eval/image_loss_mean": 62.087642669677734, "eval/image_loss_std": 73.27752685546875, "eval/model_loss_mean": 69.52244567871094, "eval/model_loss_std": 75.33079528808594, "eval/post_ent_mag": 48.83613967895508, "eval/post_ent_max": 48.83613967895508, "eval/post_ent_mean": 30.62084197998047, "eval/post_ent_min": 14.023948669433594, "eval/post_ent_std": 7.279077053070068, "eval/prior_ent_mag": 53.23908996582031, "eval/prior_ent_max": 53.23908996582031, "eval/prior_ent_mean": 38.160057067871094, "eval/prior_ent_min": 15.419242858886719, "eval/prior_ent_std": 8.555603981018066, "eval/rep_loss_mean": 12.16124153137207, "eval/rep_loss_std": 8.00415325164795, "eval/reward_avg": 0.01376953162252903, "eval/reward_loss_mean": 0.13436180353164673, "eval/reward_loss_std": 0.8196169137954712, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9990838766098022, "eval/reward_neg_acc": 0.9990040063858032, "eval/reward_neg_loss": 0.07234816253185272, "eval/reward_pos_acc": 0.6500000357627869, "eval/reward_pos_loss": 3.2474465370178223, "eval/reward_pred": 0.004605982452630997, "eval/reward_rate": 0.01953125, "replay/size": 45361.0, "replay/inserts": 22464.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.4040629748265627e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.812159925444514e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10672.0, "eval_replay/inserts": 4096.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2304517440497875e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3047182559967, "timer/env.step_count": 2808.0, "timer/env.step_total": 273.01037216186523, "timer/env.step_frac": 0.2729272062595598, "timer/env.step_avg": 0.09722591601206027, "timer/env.step_min": 0.023029327392578125, "timer/env.step_max": 3.5199615955352783, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.499227046966553, "timer/replay._sample_frac": 0.011495724089970438, "timer/replay._sample_avg": 0.0005118957909084113, "timer/replay._sample_min": 0.0003609657287597656, "timer/replay._sample_max": 0.010839462280273438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3320.0, "timer/agent.policy_total": 50.32368040084839, "timer/agent.policy_frac": 0.05030835052801342, "timer/agent.policy_avg": 0.015157735060496502, "timer/agent.policy_min": 0.008377552032470703, "timer/agent.policy_max": 0.10517644882202148, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.15036869049072266, "timer/dataset_train_frac": 0.000150322884363563, "timer/dataset_train_avg": 0.00010710020690222411, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.001088857650756836, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 610.0733256340027, "timer/agent.train_frac": 0.6098874817841992, "timer/agent.train_avg": 0.43452516070797914, "timer/agent.train_min": 0.4234907627105713, "timer/agent.train_max": 1.2701354026794434, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48326563835144043, "timer/agent.report_frac": 0.00048311842334803793, "timer/agent.report_avg": 0.24163281917572021, "timer/agent.report_min": 0.23480844497680664, "timer/agent.report_max": 0.2484571933746338, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.288818359375e-05, "timer/dataset_eval_frac": 2.2881211270956423e-08, "timer/dataset_eval_avg": 2.288818359375e-05, "timer/dataset_eval_min": 2.288818359375e-05, "timer/dataset_eval_max": 2.288818359375e-05, "fps": 22.4568736397573}
{"step": 45928, "time": 2342.7620635032654, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 46104, "time": 2349.999442100525, "episode/length": 189.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 46264, "time": 2356.623955965042, "episode/length": 67.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 46344, "time": 2360.7832911014557, "episode/length": 51.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 46376, "time": 2363.3479437828064, "episode/length": 151.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 46424, "time": 2366.5394949913025, "episode/length": 114.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 46552, "time": 2372.3591895103455, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 46584, "time": 2375.0231103897095, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 46920, "time": 2387.780782222748, "episode/length": 67.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 46976, "time": 2391.47896027565, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 47040, "time": 2395.141386270523, "episode/length": 76.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 47272, "time": 2404.1193265914917, "episode/length": 125.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 47504, "time": 2413.3838782310486, "episode/length": 28.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 47736, "time": 2422.2955067157745, "episode/length": 28.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 47808, "time": 2426.473249435425, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 47896, "time": 2430.697782754898, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 48032, "time": 2437.0322580337524, "episode/length": 240.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 48128, "time": 2441.7852182388306, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 48280, "time": 2447.9945828914642, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 48544, "time": 2458.307470560074, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 48584, "time": 2461.0065145492554, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 48904, "time": 2473.1099948883057, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 49336, "time": 2489.9450764656067, "episode/length": 179.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 49512, "time": 2497.447102546692, "episode/length": 212.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 49696, "time": 2505.2267141342163, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 49944, "time": 2514.766760826111, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 50008, "time": 2518.464722633362, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2536.1439661979675, "eval_episode/length": 55.0, "eval_episode/score": -0.9000000283122063, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 50024, "time": 2542.2437608242035, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 50024, "time": 2542.2510817050934, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 50024, "time": 2545.6556403636932, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 50024, "time": 2547.5629210472107, "eval_episode/length": 177.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9550561797752809}
{"step": 50024, "time": 2550.1356461048126, "eval_episode/length": 200.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 50024, "time": 2552.5661981105804, "eval_episode/length": 161.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 50024, "time": 2554.498440027237, "eval_episode/length": 226.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 50272, "time": 2562.7505366802216, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 50328, "time": 2565.813277244568, "episode/length": 286.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 50440, "time": 2570.950796365738, "episode/length": 92.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 50448, "time": 2572.9260590076447, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 50792, "time": 2585.4843668937683, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 50912, "time": 2591.8943734169006, "episode/length": 58.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 51128, "time": 2600.97216963768, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 51184, "time": 2604.5549323558807, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 51320, "time": 2610.301560163498, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 51496, "time": 2617.6431879997253, "episode/length": 145.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 51656, "time": 2624.4425213336945, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 51840, "time": 2632.319346666336, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 51912, "time": 2636.376846075058, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 51976, "time": 2640.0225689411163, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 52440, "time": 2656.6286420822144, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 52544, "time": 2661.8157427310944, "episode/length": 78.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 52696, "time": 2668.0913157463074, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 52928, "time": 2677.447897672653, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 52992, "time": 2681.1327385902405, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 53368, "time": 2694.585072040558, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 53928, "time": 2714.492711544037, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 53976, "time": 2717.6167085170746, "episode/length": 178.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 54056, "time": 2721.7285182476044, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 54112, "time": 2725.2990362644196, "episode/length": 283.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 54280, "time": 2732.1771359443665, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 54360, "time": 2736.36172413826, "episode/length": 379.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9763157894736842, "episode/intrinsic_return": 0.0}
{"step": 54512, "time": 2743.6957008838654, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 54840, "time": 2756.404784679413, "episode/length": 40.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 54864, "time": 2759.0466017723083, "episode/length": 241.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 54944, "time": 2763.2837867736816, "episode/length": 126.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 55360, "time": 2778.364636659622, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 55416, "time": 2781.517849445343, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 55432, "time": 2783.573762655258, "episode/length": 164.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 55512, "time": 2787.7511489391327, "episode/length": 153.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 55576, "time": 2791.3566291332245, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 55672, "time": 2796.0101795196533, "episode/length": 38.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 56056, "time": 2810.007034301758, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 56584, "time": 2828.8446764945984, "episode/length": 214.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 56816, "time": 2838.502462387085, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 56928, "time": 2844.4939465522766, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 57072, "time": 2851.5410356521606, "episode/length": 265.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 57088, "time": 2854.052998304367, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 57248, "time": 2861.486675262451, "episode/length": 196.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 57640, "time": 2877.8486654758453, "episode/length": 197.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 57856, "time": 2886.9155747890472, "episode/length": 302.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 58152, "time": 2897.8244700431824, "episode/length": 195.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 58344, "time": 2905.595349550247, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 58400, "time": 2909.1178941726685, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 58712, "time": 2920.5643994808197, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 58968, "time": 2930.364798307419, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 59072, "time": 2935.527592897415, "episode/length": 227.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 59392, "time": 2947.511883020401, "episode/length": 84.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 59400, "time": 2948.9900166988373, "episode/length": 192.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 59560, "time": 2955.6710233688354, "episode/length": 175.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 59672, "time": 2960.9217727184296, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 59936, "time": 2971.2404363155365, "episode/length": 389.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 59968, "time": 2974.0121438503265, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 2995.092306613922, "eval_episode/length": 135.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 60008, "time": 2996.8250238895416, "eval_episode/length": 140.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 60008, "time": 2999.0639843940735, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 60008, "time": 3001.424259662628, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 60008, "time": 3003.431384563446, "eval_episode/length": 183.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 60008, "time": 3005.2206633090973, "eval_episode/length": 191.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 60008, "time": 3008.412833213806, "eval_episode/length": 227.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 60008, "time": 3010.594831466675, "eval_episode/length": 240.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.995850622406639}
{"step": 60200, "time": 3016.82634305954, "episode/length": 79.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 60704, "time": 3035.1358590126038, "episode/length": 203.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 60720, "time": 3037.206951856613, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 60872, "time": 3043.393624305725, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 60904, "time": 3045.9303801059723, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 61216, "time": 3057.9193012714386, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 61240, "time": 3060.0281987190247, "episode/length": 162.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 61264, "time": 3062.702727794647, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 61992, "time": 3087.6049304008484, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 62048, "time": 3091.268358230591, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 62184, "time": 3097.1233439445496, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 62680, "time": 3114.913464307785, "episode/length": 309.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 62776, "time": 3119.6372530460358, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 62944, "time": 3126.9465520381927, "episode/length": 209.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 63000, "time": 3130.0964205265045, "episode/length": 39.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 63016, "time": 3132.0950088500977, "episode/length": 221.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 63088, "time": 3136.243216276169, "episode/length": 295.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 63176, "time": 3140.4176259040833, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 63296, "time": 3146.1126749515533, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 63688, "time": 3160.115317583084, "episode/length": 85.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 64032, "time": 3172.9352707862854, "episode/length": 42.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.9302325581395349, "episode/intrinsic_return": 0.0}
{"step": 64184, "time": 3179.1598570346832, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 64272, "time": 3183.869043111801, "episode/length": 186.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 64344, "time": 3187.479430913925, "episode/length": 269.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 64480, "time": 3193.6888461112976, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 64680, "time": 3201.45299577713, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 64984, "time": 3212.959724187851, "episode/length": 225.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 65016, "time": 3215.4487578868866, "episode/length": 249.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 65312, "time": 3226.7626366615295, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 65384, "time": 3230.39791059494, "episode/length": 87.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 65688, "time": 3243.0716869831085, "episode/length": 206.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 65744, "time": 3246.68492102623, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 66032, "time": 3257.42675447464, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 66552, "time": 3275.8960156440735, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 66576, "time": 3278.3660345077515, "episode/length": 198.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 66616, "time": 3281.079913377762, "episode/length": 266.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 66640, "time": 3283.6411242485046, "episode/length": 75.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9210526315789473, "episode/intrinsic_return": 0.0}
{"step": 66736, "time": 3288.2697274684906, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 66744, "time": 3289.8383588790894, "episode/length": 178.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 66848, "time": 3295.027160167694, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 67200, "time": 3308.0342779159546, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 67720, "time": 3326.221465110779, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 67736, "time": 3328.33989238739, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 67984, "time": 3338.3261473178864, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 67993, "time": 3340.8975536823273, "train_stats/sum_log_reward": 2.6781249375781044, "train_stats/max_log_achievement_collect_drink": 5.546875, "train_stats/max_log_achievement_collect_sapling": 2.125, "train_stats/max_log_achievement_collect_wood": 1.078125, "train_stats/max_log_achievement_defeat_zombie": 0.140625, "train_stats/max_log_achievement_eat_cow": 0.046875, "train_stats/max_log_achievement_place_plant": 1.8671875, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 2.1015625, "train_stats/mean_log_entropy": 0.44195780652808025, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.923143027485281, "train/action_min": 0.0, "train/action_std": 3.7956743361293404, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04315636761864458, "train/actor_opt_grad_steps": 3465.0, "train/actor_opt_loss": 17.354728208071943, "train/adv_mag": 1.2157705430535302, "train/adv_max": 1.2143424948056538, "train/adv_mean": 0.006337012656153409, "train/adv_min": -0.5423042378995729, "train/adv_std": 0.0932570704785378, "train/cont_avg": 0.9942396965579711, "train/cont_loss_mean": 0.000661930792634321, "train/cont_loss_std": 0.016527621073112023, "train/cont_neg_acc": 0.9817690391471421, "train/cont_neg_loss": 0.05832742655292287, "train/cont_pos_acc": 0.9999146681764851, "train/cont_pos_loss": 0.0002736792517586527, "train/cont_pred": 0.9942447944827701, "train/cont_rate": 0.9942396965579711, "train/dyn_loss_mean": 7.294422208399013, "train/dyn_loss_std": 6.748441008553988, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2082299058851989, "train/extr_critic_critic_opt_grad_steps": 3465.0, "train/extr_critic_critic_opt_loss": 14171.015738224638, "train/extr_critic_mag": 1.8868848448214324, "train/extr_critic_max": 1.8868848448214324, "train/extr_critic_mean": 0.46683507574641186, "train/extr_critic_min": -0.30585743378901825, "train/extr_critic_std": 0.6609868733347326, "train/extr_return_normed_mag": 2.1222004510354306, "train/extr_return_normed_max": 2.1222004510354306, "train/extr_return_normed_mean": 0.3684019246611042, "train/extr_return_normed_min": -0.2508959908956203, "train/extr_return_normed_std": 0.3683551662210105, "train/extr_return_rate": 0.3432857951392298, "train/extr_return_raw_mag": 3.78585005670354, "train/extr_return_raw_max": 3.78585005670354, "train/extr_return_raw_mean": 0.4788215445435565, "train/extr_return_raw_min": -0.6937693482723789, "train/extr_return_raw_std": 0.6965233795884727, "train/extr_reward_mag": 1.0022379393162935, "train/extr_reward_max": 1.0022379393162935, "train/extr_reward_mean": 0.009610164827039547, "train/extr_reward_min": -0.3619994892590288, "train/extr_reward_std": 0.08664363290628661, "train/image_loss_mean": 17.962804483330768, "train/image_loss_std": 21.807003822879516, "train/model_loss_mean": 22.392759482065838, "train/model_loss_std": 24.186419231304225, "train/model_opt_grad_norm": 118.51058595076852, "train/model_opt_grad_steps": 3456.0, "train/model_opt_loss": 3552.741009256114, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 158.5144927536232, "train/policy_entropy_mag": 2.4411505521207615, "train/policy_entropy_max": 2.4411505521207615, "train/policy_entropy_mean": 0.881233692817066, "train/policy_entropy_min": 0.07997493624039319, "train/policy_entropy_std": 0.5375647009282872, "train/policy_logprob_mag": 7.435464855553447, "train/policy_logprob_max": -0.009538262407632841, "train/policy_logprob_mean": -0.8816591492597607, "train/policy_logprob_min": -7.435464855553447, "train/policy_logprob_std": 1.2547646605450173, "train/policy_randomness_mag": 0.8616190163985543, "train/policy_randomness_max": 0.8616190163985543, "train/policy_randomness_mean": 0.3110368225885474, "train/policy_randomness_min": 0.028227642961386322, "train/policy_randomness_std": 0.18973675084070882, "train/post_ent_mag": 44.72080866495768, "train/post_ent_max": 44.72080866495768, "train/post_ent_mean": 32.10032009732896, "train/post_ent_min": 13.00310819045357, "train/post_ent_std": 5.258314557697462, "train/prior_ent_mag": 56.605567323988765, "train/prior_ent_max": 56.605567323988765, "train/prior_ent_mean": 39.52789585832237, "train/prior_ent_min": 15.055942086205967, "train/prior_ent_std": 6.835232969643413, "train/rep_loss_mean": 7.294422208399013, "train/rep_loss_std": 6.748441008553988, "train/reward_avg": 0.01068203690363958, "train/reward_loss_mean": 0.05263997171668039, "train/reward_loss_std": 0.2761147915237192, "train/reward_max_data": 1.0072463785392651, "train/reward_max_pred": 1.000274029330931, "train/reward_neg_acc": 0.9941159944603408, "train/reward_neg_loss": 0.035598041867648346, "train/reward_pos_acc": 0.919472251681314, "train/reward_pos_loss": 1.10654368651086, "train/reward_pred": 0.010144519669415457, "train/reward_rate": 0.015879755434782608, "eval_stats/sum_log_reward": 2.5374999158084393, "eval_stats/max_log_achievement_collect_drink": 11.9375, "eval_stats/max_log_achievement_collect_sapling": 1.1875, "eval_stats/max_log_achievement_collect_wood": 0.4375, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.5359979443019256e-05, "report/cont_loss_std": 0.00019473400607239455, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0011272224364802241, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.904323633236345e-06, "report/cont_pred": 0.9951128959655762, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 8.172715187072754, "report/dyn_loss_std": 7.540972709655762, "report/image_loss_mean": 18.349946975708008, "report/image_loss_std": 23.525997161865234, "report/model_loss_mean": 23.307430267333984, "report/model_loss_std": 26.730554580688477, "report/post_ent_mag": 45.471336364746094, "report/post_ent_max": 45.471336364746094, "report/post_ent_mean": 32.258522033691406, "report/post_ent_min": 13.048530578613281, "report/post_ent_std": 5.460110187530518, "report/prior_ent_mag": 58.33919906616211, "report/prior_ent_max": 58.33919906616211, "report/prior_ent_mean": 40.52745819091797, "report/prior_ent_min": 15.663691520690918, "report/prior_ent_std": 7.6383585929870605, "report/rep_loss_mean": 8.172715187072754, "report/rep_loss_std": 7.540972709655762, "report/reward_avg": 0.01113281212747097, "report/reward_loss_mean": 0.053838327527046204, "report/reward_loss_std": 0.2670823633670807, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9983489513397217, "report/reward_neg_acc": 0.9920713901519775, "report/reward_neg_loss": 0.03389723598957062, "report/reward_pos_acc": 0.8666667342185974, "report/reward_pos_loss": 1.3952094316482544, "report/reward_pred": 0.009300921112298965, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0023276477586477995, "eval/cont_loss_std": 0.035059332847595215, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1573183834552765, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001107248361222446, "eval/cont_pred": 0.9922279119491577, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 13.741109848022461, "eval/dyn_loss_std": 8.835607528686523, "eval/image_loss_mean": 52.16553497314453, "eval/image_loss_std": 58.660640716552734, "eval/model_loss_mean": 60.53268814086914, "eval/model_loss_std": 61.919376373291016, "eval/post_ent_mag": 47.138755798339844, "eval/post_ent_max": 47.138755798339844, "eval/post_ent_mean": 33.21857833862305, "eval/post_ent_min": 15.873773574829102, "eval/post_ent_std": 5.509274959564209, "eval/prior_ent_mag": 56.621395111083984, "eval/prior_ent_max": 56.621395111083984, "eval/prior_ent_mean": 42.65880584716797, "eval/prior_ent_min": 13.713152885437012, "eval/prior_ent_std": 7.789792060852051, "eval/rep_loss_mean": 13.741109848022461, "eval/rep_loss_std": 8.835607528686523, "eval/reward_avg": 0.002148437313735485, "eval/reward_loss_mean": 0.12016130238771439, "eval/reward_loss_std": 0.8178293108940125, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000431537628174, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.06461618840694427, "eval/reward_pos_acc": 0.4545454680919647, "eval/reward_pos_loss": 5.2353620529174805, "eval/reward_pred": -0.0018957930151373148, "eval/reward_rate": 0.0107421875, "replay/size": 67489.0, "replay/inserts": 22128.0, "replay/samples": 22128.0, "replay/insert_wait_avg": 1.3948693623684147e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.041330733337181e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14416.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2177560064527724e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0946192741394, "timer/env.step_count": 2766.0, "timer/env.step_total": 277.9018449783325, "timer/env.step_frac": 0.2778755525952449, "timer/env.step_avg": 0.10047065978970807, "timer/env.step_min": 0.023539304733276367, "timer/env.step_max": 2.2010748386383057, "timer/replay._sample_count": 22128.0, "timer/replay._sample_total": 11.842465162277222, "timer/replay._sample_frac": 0.01184134474283282, "timer/replay._sample_avg": 0.0005351800959091297, "timer/replay._sample_min": 0.0003743171691894531, "timer/replay._sample_max": 0.010075569152832031, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3234.0, "timer/agent.policy_total": 49.83555722236633, "timer/agent.policy_frac": 0.04983084226424154, "timer/agent.policy_avg": 0.015409881639569058, "timer/agent.policy_min": 0.008794784545898438, "timer/agent.policy_max": 0.0969545841217041, "timer/dataset_train_count": 1383.0, "timer/dataset_train_total": 0.1527690887451172, "timer/dataset_train_frac": 0.00015275463521241195, "timer/dataset_train_avg": 0.00011046210321411221, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.00040841102600097656, "timer/agent.train_count": 1383.0, "timer/agent.train_total": 605.8441126346588, "timer/agent.train_frac": 0.6057867935279719, "timer/agent.train_avg": 0.43806515736417845, "timer/agent.train_min": 0.42615175247192383, "timer/agent.train_max": 1.3578550815582275, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47318029403686523, "timer/agent.report_frac": 0.00047313552629679745, "timer/agent.report_avg": 0.23659014701843262, "timer/agent.report_min": 0.22534537315368652, "timer/agent.report_max": 0.2478349208831787, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027629482485848e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 22.125641416154096}
{"step": 68128, "time": 3345.253842115402, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 68168, "time": 3347.8534836769104, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 68184, "time": 3349.8264453411102, "episode/length": 192.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 68232, "time": 3352.918612718582, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 68304, "time": 3357.0481798648834, "episode/length": 137.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 68344, "time": 3359.6309583187103, "episode/length": 77.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 68896, "time": 3379.395001888275, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 69368, "time": 3396.3026037216187, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 69392, "time": 3398.905880212784, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 69488, "time": 3403.494575023651, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 69696, "time": 3411.7518532276154, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 69848, "time": 3418.0034227371216, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 70088, "time": 3427.5773758888245, "episode/length": 217.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3449.0675826072693, "eval_episode/length": 154.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 70096, "time": 3451.7669405937195, "eval_episode/length": 176.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 70096, "time": 3453.855153799057, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 70096, "time": 3457.275106906891, "eval_episode/length": 189.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 70096, "time": 3459.33881855011, "eval_episode/length": 199.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 70096, "time": 3461.403121948242, "eval_episode/length": 210.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.976303317535545}
{"step": 70096, "time": 3464.7200174331665, "eval_episode/length": 39.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 70096, "time": 3466.6370017528534, "eval_episode/length": 261.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9809160305343512}
{"step": 70208, "time": 3470.2924468517303, "episode/length": 259.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 70240, "time": 3472.8536224365234, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 70888, "time": 3495.401863336563, "episode/length": 322.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938080495356038, "episode/intrinsic_return": 0.0}
{"step": 71056, "time": 3502.6595735549927, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 71168, "time": 3507.806923389435, "episode/length": 183.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 71432, "time": 3517.9429683685303, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 71456, "time": 3520.44673371315, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 71600, "time": 3526.6810669898987, "episode/length": 53.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 71848, "time": 3536.0470168590546, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 72208, "time": 3549.5473539829254, "episode/length": 245.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 72304, "time": 3554.262679576874, "episode/length": 306.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 72536, "time": 3563.05761885643, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 72624, "time": 3567.7072653770447, "episode/length": 216.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 72800, "time": 3575.1293568611145, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 73160, "time": 3588.1925160884857, "episode/length": 215.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 73456, "time": 3599.7336280345917, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 73472, "time": 3601.9605503082275, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 73696, "time": 3610.698667526245, "episode/length": 279.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 73856, "time": 3618.700880765915, "episode/length": 86.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9310344827586207, "episode/intrinsic_return": 0.0}
{"step": 73976, "time": 3623.8511624336243, "episode/length": 179.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 74280, "time": 3635.475375175476, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 74304, "time": 3637.985251903534, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 74568, "time": 3647.976533651352, "episode/length": 282.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 74728, "time": 3654.624660253525, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 74808, "time": 3658.794767141342, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 75048, "time": 3668.332048177719, "episode/length": 168.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 75168, "time": 3674.068436384201, "episode/length": 107.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 75176, "time": 3675.5170431137085, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 75208, "time": 3678.038815498352, "episode/length": 168.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 75920, "time": 3703.246755361557, "episode/length": 204.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 75928, "time": 3704.7963075637817, "episode/length": 109.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 76144, "time": 3713.66637301445, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 76208, "time": 3717.2738468647003, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 76376, "time": 3724.1613624095917, "episode/length": 150.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 76480, "time": 3729.2810497283936, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 76576, "time": 3734.021350622177, "episode/length": 53.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 76664, "time": 3738.1559445858, "episode/length": 91.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 76728, "time": 3741.7740590572357, "episode/length": 193.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 76800, "time": 3745.9495327472687, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 77056, "time": 3755.9066355228424, "episode/length": 84.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 77832, "time": 3782.555240869522, "episode/length": 145.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 77864, "time": 3785.1640889644623, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 77880, "time": 3787.2360751628876, "episode/length": 244.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 78088, "time": 3795.3768439292908, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 78112, "time": 3797.9119114875793, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 78408, "time": 3808.847890853882, "episode/length": 274.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672727272727273, "episode/intrinsic_return": 0.0}
{"step": 78552, "time": 3815.6230607032776, "episode/length": 218.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 78784, "time": 3824.885915994644, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 79384, "time": 3845.865092277527, "episode/length": 193.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 79464, "time": 3849.9500856399536, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 79504, "time": 3853.0031831264496, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 79672, "time": 3859.7446954250336, "episode/length": 197.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 79672, "time": 3859.7523036003113, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 79936, "time": 3871.8182530403137, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 79960, "time": 3874.0487444400787, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 3898.1997237205505, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 80080, "time": 3900.2969698905945, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 80080, "time": 3902.785585165024, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.994475138121547}
{"step": 80080, "time": 3904.7182052135468, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9685863874345549}
{"step": 80080, "time": 3906.514787197113, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9597989949748744}
{"step": 80080, "time": 3908.4133319854736, "eval_episode/length": 204.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9853658536585366}
{"step": 80080, "time": 3912.505231142044, "eval_episode/length": 267.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9738805970149254}
{"step": 80080, "time": 3914.1929829120636, "eval_episode/length": 271.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9816176470588235}
{"step": 80728, "time": 3935.0642342567444, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 80896, "time": 3942.212668657303, "episode/length": 263.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 81000, "time": 3946.9244287014008, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 81216, "time": 3955.71359872818, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 81496, "time": 3966.254288673401, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 81536, "time": 3969.3514330387115, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 81616, "time": 3973.423467874527, "episode/length": 263.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 81904, "time": 3984.196530342102, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 81992, "time": 3989.566910266876, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 82392, "time": 4004.2436661720276, "episode/length": 173.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 82704, "time": 4016.081337928772, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 82744, "time": 4018.6756904125214, "episode/length": 43.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 82920, "time": 4026.015444993973, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 82968, "time": 4029.0279099941254, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 83000, "time": 4031.579288005829, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 83224, "time": 4040.4791119098663, "episode/length": 410.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 83448, "time": 4049.2694613933563, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 83512, "time": 4053.0239222049713, "episode/length": 67.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9117647058823529, "episode/intrinsic_return": 0.0}
{"step": 83888, "time": 4066.8231744766235, "episode/length": 236.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 84208, "time": 4078.749298810959, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 84264, "time": 4082.0657057762146, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 84440, "time": 4089.346431016922, "episode/length": 216.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 84536, "time": 4093.9693942070007, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 84704, "time": 4101.182173252106, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 84760, "time": 4104.485015153885, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 85104, "time": 4117.453143596649, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 85136, "time": 4120.052669286728, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 85512, "time": 4133.688626766205, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 85840, "time": 4146.205549240112, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 85864, "time": 4148.321297168732, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 85936, "time": 4152.467871665955, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 85984, "time": 4155.4383680820465, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 85984, "time": 4155.4457013607025, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 86176, "time": 4164.910984039307, "episode/length": 29.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8666666666666667, "episode/intrinsic_return": 0.0}
{"step": 86184, "time": 4166.421612739563, "episode/length": 39.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 86480, "time": 4177.807356595993, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 86512, "time": 4180.4508373737335, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 86616, "time": 4185.087204217911, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 87016, "time": 4199.705347061157, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 87328, "time": 4211.962807416916, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 87712, "time": 4225.741902112961, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 87864, "time": 4232.042717933655, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 87888, "time": 4234.553397655487, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 87984, "time": 4239.218656301498, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 88056, "time": 4242.825573921204, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 88400, "time": 4255.735792398453, "episode/length": 239.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 88728, "time": 4267.764203071594, "episode/length": 40.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 88752, "time": 4270.358611345291, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 88920, "time": 4277.072957754135, "episode/length": 237.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 89032, "time": 4282.202908754349, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 89328, "time": 4293.637831926346, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 89472, "time": 4299.8503074646, "episode/length": 197.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 89544, "time": 4303.488218784332, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 89552, "time": 4305.542345762253, "episode/length": 195.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 89960, "time": 4320.05353307724, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4344.123951911926, "eval_episode/length": 143.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 90064, "time": 4346.322949409485, "eval_episode/length": 157.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 90064, "time": 4348.497977733612, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9881656804733728}
{"step": 90064, "time": 4350.142968893051, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 90064, "time": 4351.97789978981, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 90064, "time": 4354.017916679382, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 90064, "time": 4358.040670633316, "eval_episode/length": 246.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 90064, "time": 4359.947703123093, "eval_episode/length": 253.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9763779527559056}
{"step": 90065, "time": 4360.522493362427, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.629850525786911, "train/action_min": 0.0, "train/action_std": 3.3055954497793447, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048808951808166676, "train/actor_opt_grad_steps": 4845.0, "train/actor_opt_loss": 21.1516386927038, "train/adv_mag": 1.1202102268951526, "train/adv_max": 1.119892427454824, "train/adv_mean": 0.007320577421168033, "train/adv_min": -0.5219754028147545, "train/adv_std": 0.09220666756880457, "train/cont_avg": 0.9944095335144928, "train/cont_loss_mean": 0.0005020375406855771, "train/cont_loss_std": 0.012868462904034986, "train/cont_neg_acc": 0.9818461554637854, "train/cont_neg_loss": 0.04367936343667892, "train/cont_pos_acc": 0.9999359828838403, "train/cont_pos_loss": 0.0002313376879810165, "train/cont_pred": 0.9943973953309266, "train/cont_rate": 0.9944095335144928, "train/dyn_loss_mean": 9.497188105099443, "train/dyn_loss_std": 7.718552720719489, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1990435555361318, "train/extr_critic_critic_opt_grad_steps": 4845.0, "train/extr_critic_critic_opt_loss": 14636.470271456068, "train/extr_critic_mag": 2.236831595932228, "train/extr_critic_max": 2.236831595932228, "train/extr_critic_mean": 0.5305402738892514, "train/extr_critic_min": -0.29611461490824603, "train/extr_critic_std": 0.7075390366540439, "train/extr_return_normed_mag": 2.1166890004406804, "train/extr_return_normed_max": 2.1166890004406804, "train/extr_return_normed_mean": 0.36175205925668497, "train/extr_return_normed_min": -0.23779476757930673, "train/extr_return_normed_std": 0.36078484701937524, "train/extr_return_rate": 0.36409318403921265, "train/extr_return_raw_mag": 4.172717082327691, "train/extr_return_raw_max": 4.172717082327691, "train/extr_return_raw_mean": 0.5457297941480858, "train/extr_return_raw_min": -0.6922425465739291, "train/extr_return_raw_std": 0.7459195429000302, "train/extr_reward_mag": 1.003778092239214, "train/extr_reward_max": 1.003778092239214, "train/extr_reward_mean": 0.01169299058433946, "train/extr_reward_min": -0.34611342005107715, "train/extr_reward_std": 0.09517694513003032, "train/image_loss_mean": 18.06217470721922, "train/image_loss_std": 21.21515142744866, "train/model_loss_mean": 23.81395778103151, "train/model_loss_std": 24.40608757129614, "train/model_opt_grad_norm": 112.01762655506964, "train/model_opt_grad_steps": 4836.0, "train/model_opt_loss": 10240.839797752491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 430.2536231884058, "train/policy_entropy_mag": 2.540792779646058, "train/policy_entropy_max": 2.540792779646058, "train/policy_entropy_mean": 0.9561258087987485, "train/policy_entropy_min": 0.07944092559425728, "train/policy_entropy_std": 0.622036030974941, "train/policy_logprob_mag": 7.437667148700659, "train/policy_logprob_max": -0.009465235420435236, "train/policy_logprob_mean": -0.9575652333273403, "train/policy_logprob_min": -7.437667148700659, "train/policy_logprob_std": 1.2638223318086155, "train/policy_randomness_mag": 0.8967883509138356, "train/policy_randomness_max": 0.8967883509138356, "train/policy_randomness_mean": 0.33747045415035193, "train/policy_randomness_min": 0.02803916054899278, "train/policy_randomness_std": 0.2195514220258464, "train/post_ent_mag": 47.16424900552501, "train/post_ent_max": 47.16424900552501, "train/post_ent_mean": 33.67750488502392, "train/post_ent_min": 15.282679405765258, "train/post_ent_std": 5.1627577318661455, "train/prior_ent_mag": 60.09758979686792, "train/prior_ent_max": 60.09758979686792, "train/prior_ent_mean": 43.27290142446324, "train/prior_ent_min": 17.69766476534415, "train/prior_ent_std": 7.47744800042415, "train/rep_loss_mean": 9.497188105099443, "train/rep_loss_std": 7.718552720719489, "train/reward_avg": 0.012519106619815895, "train/reward_loss_mean": 0.05296825687738432, "train/reward_loss_std": 0.28686391745788464, "train/reward_max_data": 1.0065217406853386, "train/reward_max_pred": 1.0017036268676536, "train/reward_neg_acc": 0.9943430449651636, "train/reward_neg_loss": 0.03333782781239437, "train/reward_pos_acc": 0.9086255750794342, "train/reward_pos_loss": 1.1551394242307413, "train/reward_pred": 0.011318038580466764, "train/reward_rate": 0.017620584239130436, "train_stats/sum_log_reward": 3.51463408356275, "train_stats/max_log_achievement_collect_drink": 9.691056910569106, "train_stats/max_log_achievement_collect_sapling": 2.6504065040650406, "train_stats/max_log_achievement_collect_wood": 1.6016260162601625, "train_stats/max_log_achievement_defeat_zombie": 0.24390243902439024, "train_stats/max_log_achievement_eat_cow": 0.08943089430894309, "train_stats/max_log_achievement_place_plant": 2.4471544715447155, "train_stats/max_log_achievement_place_table": 0.14634146341463414, "train_stats/max_log_achievement_wake_up": 1.934959349593496, "train_stats/mean_log_entropy": 0.5097192768158951, "eval_stats/sum_log_reward": 3.8083332975705466, "eval_stats/max_log_achievement_collect_drink": 13.875, "eval_stats/max_log_achievement_collect_sapling": 2.7083333333333335, "eval_stats/max_log_achievement_collect_wood": 1.7083333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_table": 0.20833333333333334, "eval_stats/max_log_achievement_wake_up": 1.9583333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.018518518518518517, "train_stats/max_log_achievement_make_wood_sword": 0.08888888888888889, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0001549927837913856, "report/cont_loss_std": 0.003767056856304407, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.021483445540070534, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.18929220258724e-06, "report/cont_pred": 0.9932959675788879, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 10.688859939575195, "report/dyn_loss_std": 8.20586109161377, "report/image_loss_mean": 19.457012176513672, "report/image_loss_std": 27.66248893737793, "report/model_loss_mean": 25.95087242126465, "report/model_loss_std": 30.835128784179688, "report/post_ent_mag": 49.43751525878906, "report/post_ent_max": 49.43751525878906, "report/post_ent_mean": 35.271522521972656, "report/post_ent_min": 15.27918815612793, "report/post_ent_std": 5.843656539916992, "report/prior_ent_mag": 61.8839225769043, "report/prior_ent_max": 61.8839225769043, "report/prior_ent_mean": 46.18437194824219, "report/prior_ent_min": 19.882862091064453, "report/prior_ent_std": 8.156643867492676, "report/rep_loss_mean": 10.688859939575195, "report/rep_loss_std": 8.20586109161377, "report/reward_avg": 0.02304687350988388, "report/reward_loss_mean": 0.08038988709449768, "report/reward_loss_std": 0.37155669927597046, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0036289691925049, "report/reward_neg_acc": 0.9949596524238586, "report/reward_neg_loss": 0.04101312533020973, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.3010696172714233, "report/reward_pred": 0.018270235508680344, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00037027947837486863, "eval/cont_loss_std": 0.008218962699174881, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.07212070375680923, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.821653131628409e-05, "eval/cont_pred": 0.9954199194908142, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 13.674342155456543, "eval/dyn_loss_std": 8.401691436767578, "eval/image_loss_mean": 33.94171905517578, "eval/image_loss_std": 48.37701416015625, "eval/model_loss_mean": 42.21202850341797, "eval/model_loss_std": 51.58808898925781, "eval/post_ent_mag": 46.68109130859375, "eval/post_ent_max": 46.68109130859375, "eval/post_ent_mean": 33.32935333251953, "eval/post_ent_min": 18.23165512084961, "eval/post_ent_std": 4.720883846282959, "eval/prior_ent_mag": 61.19207763671875, "eval/prior_ent_max": 61.19207763671875, "eval/prior_ent_mean": 45.097633361816406, "eval/prior_ent_min": 16.878665924072266, "eval/prior_ent_std": 7.097743511199951, "eval/rep_loss_mean": 13.674342155456543, "eval/rep_loss_std": 8.401691436767578, "eval/reward_avg": 0.00732421875, "eval/reward_loss_mean": 0.06533278524875641, "eval/reward_loss_std": 0.5574467778205872, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030512809753418, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.025986453518271446, "eval/reward_pos_acc": 0.5833333730697632, "eval/reward_pos_loss": 3.383540630340576, "eval/reward_pred": 0.0022978007327765226, "eval/reward_rate": 0.01171875, "replay/size": 89561.0, "replay/inserts": 22072.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.300284291316133e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.963638706774362e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20720.0, "eval_replay/inserts": 6304.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2004889812566302e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1019.6102819442749, "timer/env.step_count": 2759.0, "timer/env.step_total": 262.8720922470093, "timer/env.step_frac": 0.2578162430313508, "timer/env.step_avg": 0.09527803271004323, "timer/env.step_min": 0.022786378860473633, "timer/env.step_max": 3.286130666732788, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.646005392074585, "timer/replay._sample_frac": 0.011422016429519566, "timer/replay._sample_avg": 0.0005278283807140403, "timer/replay._sample_min": 0.00038886070251464844, "timer/replay._sample_max": 0.011084318161010742, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3547.0, "timer/agent.policy_total": 53.427751779556274, "timer/agent.policy_frac": 0.05240016967823818, "timer/agent.policy_avg": 0.015062800050622011, "timer/agent.policy_min": 0.008656024932861328, "timer/agent.policy_max": 0.08532261848449707, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.1464529037475586, "timer/dataset_train_frac": 0.00014363615818809754, "timer/dataset_train_avg": 0.00010620225072339274, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.0007135868072509766, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 603.332291841507, "timer/agent.train_frac": 0.5917283324085595, "timer/agent.train_avg": 0.43751435231436325, "timer/agent.train_min": 0.42572712898254395, "timer/agent.train_max": 1.336491584777832, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756779670715332, "timer/agent.report_frac": 0.00046652919796421846, "timer/agent.report_avg": 0.2378389835357666, "timer/agent.report_min": 0.22925090789794922, "timer/agent.report_max": 0.24642705917358398, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 2.993063003131611e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.64722545655995}
{"step": 90168, "time": 4364.928535223007, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 90200, "time": 4367.4436111450195, "episode/length": 159.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 90608, "time": 4382.517810583115, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 90856, "time": 4391.969019651413, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 90880, "time": 4394.471623420715, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 91000, "time": 4399.649418354034, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 91248, "time": 4409.324377536774, "episode/length": 48.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 91328, "time": 4413.473762750626, "episode/length": 55.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 91392, "time": 4417.070918083191, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 91432, "time": 4419.738748550415, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 91808, "time": 4433.614195108414, "episode/length": 204.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 91840, "time": 4436.088151693344, "episode/length": 313.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 92176, "time": 4448.521643161774, "episode/length": 195.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 92488, "time": 4460.017283678055, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 92488, "time": 4460.0246322155, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 92584, "time": 4466.371233701706, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 92592, "time": 4468.377154350281, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 92840, "time": 4477.804479837418, "episode/length": 124.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 93216, "time": 4491.768303155899, "episode/length": 227.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 93432, "time": 4500.101099491119, "episode/length": 104.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 93464, "time": 4502.669917821884, "episode/length": 160.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 93600, "time": 4508.783462524414, "episode/length": 126.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 93808, "time": 4517.02649974823, "episode/length": 249.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 93896, "time": 4521.143886566162, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 93976, "time": 4525.307360649109, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 94288, "time": 4537.2239818573, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 94536, "time": 4546.5648102760315, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 94784, "time": 4556.313722372055, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 94992, "time": 4564.581141471863, "episode/length": 136.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 95224, "time": 4573.308916568756, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 95240, "time": 4575.473059415817, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 95344, "time": 4580.629701375961, "episode/length": 234.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 95704, "time": 4593.657417058945, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 95984, "time": 4604.371390104294, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 96008, "time": 4606.447061777115, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 96104, "time": 4611.101464033127, "episode/length": 164.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 96168, "time": 4614.686661720276, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 96848, "time": 4638.431957244873, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 96944, "time": 4643.168627738953, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 97048, "time": 4647.8409078121185, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 97112, "time": 4651.564812660217, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 97416, "time": 4663.120791912079, "episode/length": 213.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 97448, "time": 4665.713566064835, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 97568, "time": 4671.427733182907, "episode/length": 56.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 97608, "time": 4674.053950786591, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 98216, "time": 4695.299123287201, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 98304, "time": 4700.212680578232, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 98528, "time": 4710.399799585342, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 98696, "time": 4717.302216529846, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 98888, "time": 4725.022920846939, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 98912, "time": 4727.499738454819, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 98952, "time": 4730.087381601334, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 99536, "time": 4750.889977693558, "episode/length": 245.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 99624, "time": 4755.144735336304, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 99808, "time": 4763.004576444626, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 99840, "time": 4765.5078320503235, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 99936, "time": 4770.122946500778, "episode/length": 49.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 100040, "time": 4774.992519855499, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4792.273189544678, "eval_episode/length": 61.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9516129032258065}
{"step": 100048, "time": 4796.969606399536, "eval_episode/length": 136.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 100048, "time": 4798.983689546585, "eval_episode/length": 147.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 100048, "time": 4801.265949964523, "eval_episode/length": 164.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 100048, "time": 4802.89236664772, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 100048, "time": 4805.278447389603, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 100048, "time": 4807.075269937515, "eval_episode/length": 192.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 100048, "time": 4810.179439544678, "eval_episode/length": 228.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 100336, "time": 4819.471420764923, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 100496, "time": 4826.126433372498, "episode/length": 81.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 100544, "time": 4829.11577129364, "episode/length": 279.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 100616, "time": 4832.8415331840515, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 100904, "time": 4843.724291563034, "episode/length": 44.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 101080, "time": 4850.897899627686, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 101344, "time": 4861.1726450920105, "episode/length": 214.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 101656, "time": 4872.547516345978, "episode/length": 201.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 101928, "time": 4882.91384601593, "episode/length": 198.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 101936, "time": 4884.900188922882, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 102120, "time": 4892.2061586380005, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 102200, "time": 4896.367394447327, "episode/length": 33.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 102248, "time": 4899.442751407623, "episode/length": 304.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 102280, "time": 4901.994517564774, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 102576, "time": 4913.340319156647, "episode/length": 153.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 102832, "time": 4923.149206876755, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 103240, "time": 4937.674390792847, "episode/length": 197.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 103648, "time": 4952.68319773674, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 103648, "time": 4952.690720081329, "episode/length": 190.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 103712, "time": 4957.92024230957, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 103936, "time": 4966.668438196182, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 103992, "time": 4969.878673791885, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 104008, "time": 4971.852476835251, "episode/length": 225.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 104192, "time": 4979.514887332916, "episode/length": 242.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 104368, "time": 4986.986293077469, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 104632, "time": 4996.954460382462, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 104912, "time": 5007.8002943992615, "episode/length": 157.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 105008, "time": 5012.547545194626, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 105232, "time": 5021.366780042648, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 105328, "time": 5026.042191505432, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 105328, "time": 5026.053023576736, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 105896, "time": 5047.543323278427, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 106120, "time": 5056.277350902557, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 106392, "time": 5066.527170419693, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 106416, "time": 5069.012196779251, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 106520, "time": 5075.027373313904, "episode/length": 322.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 106672, "time": 5081.712954282761, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 106696, "time": 5083.864068746567, "episode/length": 37.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 106728, "time": 5086.387925386429, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 106728, "time": 5086.395908117294, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 107104, "time": 5102.135609388351, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 107288, "time": 5109.3953332901, "episode/length": 95.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 107624, "time": 5121.739448070526, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 107888, "time": 5132.078473567963, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 107888, "time": 5132.084979057312, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 108048, "time": 5140.444181680679, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 108072, "time": 5142.455463647842, "episode/length": 174.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 108632, "time": 5162.167150974274, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 108704, "time": 5166.249851703644, "episode/length": 250.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 108872, "time": 5172.850908994675, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 109080, "time": 5181.042137861252, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 109112, "time": 5183.556210279465, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 109144, "time": 5186.168786048889, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 109216, "time": 5190.241012573242, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 109672, "time": 5206.294516324997, "episode/length": 202.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 109696, "time": 5208.793691158295, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 109928, "time": 5217.445119857788, "episode/length": 28.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 109952, "time": 5219.937141895294, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5238.402844905853, "eval_episode/length": 38.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 110032, "time": 5240.939775466919, "eval_episode/length": 64.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9384615384615385}
{"step": 110032, "time": 5247.897559642792, "eval_episode/length": 190.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 110032, "time": 5251.512028217316, "eval_episode/length": 205.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 110032, "time": 5253.199452161789, "eval_episode/length": 207.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 110032, "time": 5255.064329385757, "eval_episode/length": 216.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 110032, "time": 5256.653743982315, "eval_episode/length": 219.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 110032, "time": 5258.779074668884, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 110232, "time": 5265.037090539932, "episode/length": 190.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 110368, "time": 5271.060748577118, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 110376, "time": 5272.678303480148, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 110408, "time": 5275.203755140305, "episode/length": 157.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 110992, "time": 5295.893967866898, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 111040, "time": 5298.951607465744, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 111384, "time": 5311.527400493622, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 111616, "time": 5320.8109612464905, "episode/length": 155.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 111848, "time": 5329.6437175273895, "episode/length": 183.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 112040, "time": 5337.505696773529, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 112656, "time": 5359.476243019104, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 112657, "time": 5361.559213399887, "train_stats/sum_log_reward": 3.8795274937246726, "train_stats/max_log_achievement_collect_drink": 9.291338582677165, "train_stats/max_log_achievement_collect_sapling": 2.661417322834646, "train_stats/max_log_achievement_collect_wood": 1.779527559055118, "train_stats/max_log_achievement_defeat_zombie": 0.2283464566929134, "train_stats/max_log_achievement_eat_cow": 0.14173228346456693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.007874015748031496, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5511811023622046, "train_stats/max_log_achievement_place_table": 0.47244094488188976, "train_stats/max_log_achievement_wake_up": 1.4173228346456692, "train_stats/mean_log_entropy": 0.41953326397993435, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.545531793689052, "train/action_min": 0.0, "train/action_std": 3.2152430774472283, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05062457583580457, "train/actor_opt_grad_steps": 6240.0, "train/actor_opt_loss": 13.757741631134182, "train/adv_mag": 1.0096823581567047, "train/adv_max": 1.0085486055265926, "train/adv_mean": 0.006668346399005423, "train/adv_min": -0.5137900395173554, "train/adv_std": 0.08895909791508465, "train/cont_avg": 0.9942029587765957, "train/cont_loss_mean": 0.0005453415256583673, "train/cont_loss_std": 0.01453565738921362, "train/cont_neg_acc": 0.9847939906390846, "train/cont_neg_loss": 0.05078967843298176, "train/cont_pos_acc": 0.9999233547677385, "train/cont_pos_loss": 0.00021224046321513515, "train/cont_pred": 0.9942029325674612, "train/cont_rate": 0.9942029587765957, "train/dyn_loss_mean": 11.316801125276173, "train/dyn_loss_std": 8.411827841549055, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1900860663001418, "train/extr_critic_critic_opt_grad_steps": 6240.0, "train/extr_critic_critic_opt_loss": 14753.747368129432, "train/extr_critic_mag": 2.801945481739991, "train/extr_critic_max": 2.801945481739991, "train/extr_critic_mean": 0.6810490059937145, "train/extr_critic_min": -0.2693679721642893, "train/extr_critic_std": 0.8013882594751128, "train/extr_return_normed_mag": 2.003591371766219, "train/extr_return_normed_max": 2.003591371766219, "train/extr_return_normed_mean": 0.3528236818651781, "train/extr_return_normed_min": -0.20691521724699236, "train/extr_return_normed_std": 0.35379404463666553, "train/extr_return_rate": 0.4151660590729815, "train/extr_return_raw_mag": 4.633482948262641, "train/extr_return_raw_max": 4.633482948262641, "train/extr_return_raw_mean": 0.6969074105962794, "train/extr_return_raw_min": -0.6369010799742759, "train/extr_return_raw_std": 0.8438979936829696, "train/extr_reward_mag": 1.0048207264419988, "train/extr_reward_max": 1.0048207264419988, "train/extr_reward_mean": 0.01385036501240857, "train/extr_reward_min": -0.34534175514329407, "train/extr_reward_std": 0.10454721542748999, "train/image_loss_mean": 16.318628683157847, "train/image_loss_std": 18.6602870386543, "train/model_loss_mean": 23.16372596794832, "train/model_loss_std": 22.259610493977863, "train/model_opt_grad_norm": 93.16757120984666, "train/model_opt_grad_steps": 6230.347517730496, "train/model_opt_loss": 14595.521996897163, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 629.4326241134752, "train/policy_entropy_mag": 2.46695994823537, "train/policy_entropy_max": 2.46695994823537, "train/policy_entropy_mean": 0.8575915558963803, "train/policy_entropy_min": 0.07938318752439309, "train/policy_entropy_std": 0.6039613464199904, "train/policy_logprob_mag": 7.438193656028585, "train/policy_logprob_max": -0.009457258897311721, "train/policy_logprob_mean": -0.8583997048384754, "train/policy_logprob_min": -7.438193656028585, "train/policy_logprob_std": 1.2349907514896798, "train/policy_randomness_mag": 0.8707286026460904, "train/policy_randomness_max": 0.8707286026460904, "train/policy_randomness_mean": 0.30269218547969845, "train/policy_randomness_min": 0.02801878165110206, "train/policy_randomness_std": 0.21317185355839155, "train/post_ent_mag": 49.417685163782, "train/post_ent_max": 49.417685163782, "train/post_ent_mean": 34.90292986064938, "train/post_ent_min": 16.671605806824164, "train/post_ent_std": 5.400793792508173, "train/prior_ent_mag": 61.75949023632293, "train/prior_ent_max": 61.75949023632293, "train/prior_ent_mean": 46.318509933796335, "train/prior_ent_min": 19.420200652264533, "train/prior_ent_std": 7.840069628776388, "train/rep_loss_mean": 11.316801125276173, "train/rep_loss_std": 8.411827841549055, "train/reward_avg": 0.014802194093122866, "train/reward_loss_mean": 0.05447134367646055, "train/reward_loss_std": 0.27466590158271453, "train/reward_max_data": 1.0042553201634834, "train/reward_max_pred": 1.0026569797637614, "train/reward_neg_acc": 0.9931624117472493, "train/reward_neg_loss": 0.03394942693676509, "train/reward_pos_acc": 0.9248411148152453, "train/reward_pos_loss": 1.0666163880774315, "train/reward_pred": 0.014006883265939376, "train/reward_rate": 0.020002216312056738, "eval_stats/sum_log_reward": 3.7249999046325684, "eval_stats/max_log_achievement_collect_drink": 6.3125, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_wood": 1.6875, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_table": 0.5625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.008994136936962605, "report/cont_loss_std": 0.28477880358695984, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002822771202772856, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.009045485407114029, "report/cont_pred": 0.9930784702301025, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.477294921875, "report/dyn_loss_std": 8.738517761230469, "report/image_loss_mean": 13.115143775939941, "report/image_loss_std": 12.854369163513184, "report/model_loss_mean": 20.071651458740234, "report/model_loss_std": 17.063373565673828, "report/post_ent_mag": 50.72209167480469, "report/post_ent_max": 50.72209167480469, "report/post_ent_mean": 36.608299255371094, "report/post_ent_min": 16.655780792236328, "report/post_ent_std": 6.4010772705078125, "report/prior_ent_mag": 63.13550567626953, "report/prior_ent_max": 63.13550567626953, "report/prior_ent_mean": 47.952613830566406, "report/prior_ent_min": 16.272544860839844, "report/prior_ent_std": 8.781266212463379, "report/rep_loss_mean": 11.477294921875, "report/rep_loss_std": 8.738517761230469, "report/reward_avg": 0.014355468563735485, "report/reward_loss_mean": 0.061136890202760696, "report/reward_loss_std": 0.20523692667484283, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9992965459823608, "report/reward_neg_acc": 0.9840478897094727, "report/reward_neg_loss": 0.04685302823781967, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7433611154556274, "report/reward_pred": 0.01565619744360447, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00016106010298244655, "eval/cont_loss_std": 0.0032775539439171553, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000128420622786507, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00016118808707688004, "eval/cont_pred": 0.9959390163421631, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.73516845703125, "eval/dyn_loss_std": 9.811553001403809, "eval/image_loss_mean": 43.37516784667969, "eval/image_loss_std": 46.59129333496094, "eval/model_loss_mean": 53.524017333984375, "eval/model_loss_std": 50.57709503173828, "eval/post_ent_mag": 49.56367492675781, "eval/post_ent_max": 49.56367492675781, "eval/post_ent_mean": 34.95610046386719, "eval/post_ent_min": 19.937660217285156, "eval/post_ent_std": 5.048187255859375, "eval/prior_ent_mag": 63.13550567626953, "eval/prior_ent_max": 63.13550567626953, "eval/prior_ent_mean": 47.85976791381836, "eval/prior_ent_min": 18.420269012451172, "eval/prior_ent_std": 9.490735054016113, "eval/rep_loss_mean": 16.73516845703125, "eval/rep_loss_std": 9.811553001403809, "eval/reward_avg": 0.01591796986758709, "eval/reward_loss_mean": 0.10758550465106964, "eval/reward_loss_std": 0.7683369517326355, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9983927011489868, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.024057740345597267, "eval/reward_pos_acc": 0.4761904776096344, "eval/reward_pos_loss": 4.097030162811279, "eval/reward_pred": 0.0038957404904067516, "eval/reward_rate": 0.0205078125, "replay/size": 112153.0, "replay/inserts": 22592.0, "replay/samples": 22592.0, "replay/insert_wait_avg": 1.2858055806362595e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.817727479313318e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24432.0, "eval_replay/inserts": 3712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1722460902970412e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.024689912796, "timer/env.step_count": 2824.0, "timer/env.step_total": 267.7358241081238, "timer/env.step_frac": 0.26746175874188227, "timer/env.step_avg": 0.09480730315443477, "timer/env.step_min": 0.022881031036376953, "timer/env.step_max": 3.3211326599121094, "timer/replay._sample_count": 22592.0, "timer/replay._sample_total": 11.969651937484741, "timer/replay._sample_frac": 0.011957399311027458, "timer/replay._sample_avg": 0.0005298181629552382, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.010473489761352539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3288.0, "timer/agent.policy_total": 49.285407304763794, "timer/agent.policy_frac": 0.049234956741234105, "timer/agent.policy_avg": 0.014989479107288258, "timer/agent.policy_min": 0.008470773696899414, "timer/agent.policy_max": 0.09230804443359375, "timer/dataset_train_count": 1412.0, "timer/dataset_train_total": 0.15042352676391602, "timer/dataset_train_frac": 0.000150269547074828, "timer/dataset_train_avg": 0.00010653224275064874, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0010797977447509766, "timer/agent.train_count": 1412.0, "timer/agent.train_total": 617.3782777786255, "timer/agent.train_frac": 0.6167463040620988, "timer/agent.train_avg": 0.4372367406364203, "timer/agent.train_min": 0.4263765811920166, "timer/agent.train_max": 1.3285865783691406, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46964168548583984, "timer/agent.report_frac": 0.0004691609410021171, "timer/agent.report_avg": 0.23482084274291992, "timer/agent.report_min": 0.22123384475708008, "timer/agent.report_max": 0.24840784072875977, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.024816455679649e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 22.568586713049402}
{"step": 112848, "time": 5367.917549133301, "episode/length": 231.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 113224, "time": 5381.5878212451935, "episode/length": 500.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9920159680638723, "episode/intrinsic_return": 0.0}
{"step": 113248, "time": 5384.130283117294, "episode/length": 232.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 113280, "time": 5386.688881158829, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 113680, "time": 5401.176264762878, "episode/length": 228.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9650655021834061, "episode/intrinsic_return": 0.0}
{"step": 113920, "time": 5410.604164123535, "episode/length": 133.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 114120, "time": 5418.33563542366, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 114160, "time": 5421.360991477966, "episode/length": 490.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816700610997964, "episode/intrinsic_return": 0.0}
{"step": 114536, "time": 5434.785075426102, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 114568, "time": 5437.338119983673, "episode/length": 315.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 114680, "time": 5442.557332992554, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 114824, "time": 5450.027494907379, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 115080, "time": 5459.7828249931335, "episode/length": 49.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 115352, "time": 5470.278698682785, "episode/length": 208.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 115360, "time": 5472.269115686417, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 115392, "time": 5474.789193868637, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 115856, "time": 5491.494247913361, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 116032, "time": 5498.748567819595, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 116296, "time": 5508.671125173569, "episode/length": 266.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 116416, "time": 5514.215711116791, "episode/length": 198.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 116616, "time": 5522.068002939224, "episode/length": 157.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 116896, "time": 5532.950752019882, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 117040, "time": 5539.01176738739, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 117064, "time": 5541.047980546951, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 117312, "time": 5550.798106908798, "episode/length": 181.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 117568, "time": 5560.742880105972, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 117720, "time": 5567.059918880463, "episode/length": 177.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 117800, "time": 5571.183007478714, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 117920, "time": 5576.768376350403, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 118056, "time": 5582.629900455475, "episode/length": 41.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 118296, "time": 5591.765280008316, "episode/length": 90.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 118528, "time": 5601.175418376923, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 118808, "time": 5611.764801502228, "episode/length": 110.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9369369369369369, "episode/intrinsic_return": 0.0}
{"step": 119016, "time": 5620.201882362366, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9660377358490566, "episode/intrinsic_return": 0.0}
{"step": 119272, "time": 5630.220793962479, "episode/length": 275.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 119456, "time": 5638.438992023468, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 119488, "time": 5640.9646418094635, "episode/length": 119.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 119992, "time": 5658.766622066498, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5674.983142852783, "eval_episode/length": 25.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.8846153846153846}
{"step": 120016, "time": 5681.339514017105, "eval_episode/length": 140.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 120016, "time": 5683.274407863617, "eval_episode/length": 149.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 120016, "time": 5685.136301279068, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 120016, "time": 5687.039977550507, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 120016, "time": 5690.317506551743, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 120016, "time": 5691.818567991257, "eval_episode/length": 200.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9800995024875622}
{"step": 120016, "time": 5693.52245426178, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 120088, "time": 5695.7279217243195, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 120208, "time": 5702.058505058289, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 120480, "time": 5713.140307188034, "episode/length": 429.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 120480, "time": 5713.150583744049, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 120624, "time": 5721.954459190369, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 120648, "time": 5724.507692813873, "episode/length": 293.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 121136, "time": 5743.06710767746, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.951048951048951, "episode/intrinsic_return": 0.0}
{"step": 121456, "time": 5754.896345615387, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 121464, "time": 5756.522011756897, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 121576, "time": 5761.7064661979675, "episode/length": 136.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 121792, "time": 5770.652284383774, "episode/length": 291.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 122128, "time": 5783.002138376236, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 122296, "time": 5789.846052408218, "episode/length": 89.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 122304, "time": 5791.992779970169, "episode/length": 227.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 122368, "time": 5795.641912698746, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 122528, "time": 5802.419509410858, "episode/length": 173.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 122880, "time": 5815.397885560989, "episode/length": 43.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 123296, "time": 5831.992272138596, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 123424, "time": 5837.691819667816, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 123440, "time": 5839.826986789703, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 123600, "time": 5846.482830524445, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 123800, "time": 5854.394886016846, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 123832, "time": 5856.888012886047, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 123888, "time": 5860.340047836304, "episode/length": 197.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 124224, "time": 5872.740264892578, "episode/length": 99.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.94, "episode/intrinsic_return": 0.0}
{"step": 124280, "time": 5875.890476703644, "episode/length": 55.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 124552, "time": 5886.219187736511, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 124832, "time": 5896.932534694672, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 124864, "time": 5899.404207229614, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 124880, "time": 5901.457766056061, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 124936, "time": 5904.637973308563, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 125072, "time": 5910.726171731949, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 125240, "time": 5917.511677980423, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 125696, "time": 5933.87181687355, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 125896, "time": 5941.633496046066, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 126048, "time": 5948.196900606155, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 126264, "time": 5956.53196310997, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 126464, "time": 5964.794705152512, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 126648, "time": 5972.075146436691, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 126904, "time": 5981.847491979599, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 126976, "time": 5985.916573524475, "episode/length": 88.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 127136, "time": 5992.520254135132, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 127272, "time": 5998.1727685928345, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 127400, "time": 6003.871057271957, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 127528, "time": 6009.568857908249, "episode/length": 336.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 127696, "time": 6017.014858484268, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 127760, "time": 6021.06741309166, "episode/length": 106.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 128736, "time": 6055.068652868271, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 128800, "time": 6058.759304761887, "episode/length": 207.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 128840, "time": 6061.487779378891, "episode/length": 273.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 129128, "time": 6072.8492867946625, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 129304, "time": 6080.090002536774, "episode/length": 290.0, "episode/score": 4.0999999567866325, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 129336, "time": 6082.690220117569, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 129368, "time": 6085.172278165817, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 129424, "time": 6088.759243965149, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 129936, "time": 6106.94872045517, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6125.56355214119, "eval_episode/length": 59.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 130000, "time": 6129.119605779648, "eval_episode/length": 108.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9541284403669725}
{"step": 130000, "time": 6131.905119419098, "eval_episode/length": 138.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 130000, "time": 6133.613313436508, "eval_episode/length": 141.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 130000, "time": 6135.967798948288, "eval_episode/length": 157.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9556962025316456}
{"step": 130000, "time": 6138.278941631317, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 130000, "time": 6141.482474088669, "eval_episode/length": 210.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 130000, "time": 6143.1913113594055, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 130048, "time": 6144.781064271927, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 130408, "time": 6157.796263456345, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 130952, "time": 6176.7964606285095, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 131040, "time": 6181.503660202026, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 131112, "time": 6186.445563077927, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 131232, "time": 6192.048043489456, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 131384, "time": 6198.2247722148895, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 131568, "time": 6205.814917087555, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 131592, "time": 6207.930042743683, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 131680, "time": 6212.776371479034, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 131816, "time": 6218.451317071915, "episode/length": 175.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 132152, "time": 6230.697982549667, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 132512, "time": 6244.0733478069305, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 132592, "time": 6248.276306629181, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 132848, "time": 6257.982531309128, "episode/length": 201.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 132896, "time": 6261.069829940796, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 132912, "time": 6263.154389619827, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 133040, "time": 6268.721753835678, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 133208, "time": 6275.540185689926, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 133312, "time": 6280.678858041763, "episode/length": 57.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.0}
{"step": 133704, "time": 6294.708215475082, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 134032, "time": 6307.14848279953, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 134352, "time": 6319.140931844711, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 134352, "time": 6319.14896273613, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 134416, "time": 6324.401832342148, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 134424, "time": 6325.869937181473, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 134448, "time": 6328.416380405426, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 135016, "time": 6348.171223402023, "episode/length": 122.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 135352, "time": 6360.546429872513, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 135353, "time": 6363.18757891655, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.821562001402949, "train/action_min": 0.0, "train/action_std": 3.364174935179697, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05208130797345034, "train/actor_opt_grad_steps": 7655.0, "train/actor_opt_loss": 5.871705977587213, "train/adv_mag": 0.948948106715377, "train/adv_max": 0.9471137487972286, "train/adv_mean": 0.006644477382124792, "train/adv_min": -0.5115293682041303, "train/adv_std": 0.09015633913517838, "train/cont_avg": 0.9944019586267606, "train/cont_loss_mean": 0.0004149189843097945, "train/cont_loss_std": 0.010620408081227734, "train/cont_neg_acc": 0.985560588013958, "train/cont_neg_loss": 0.03507876794625386, "train/cont_pos_acc": 0.9999375939369202, "train/cont_pos_loss": 0.00022192688404712799, "train/cont_pred": 0.994394301108911, "train/cont_rate": 0.9944019586267606, "train/dyn_loss_mean": 12.515626551399768, "train/dyn_loss_std": 8.727870507979057, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1998071720902348, "train/extr_critic_critic_opt_grad_steps": 7655.0, "train/extr_critic_critic_opt_loss": 15341.68622771787, "train/extr_critic_mag": 3.5001014118463223, "train/extr_critic_max": 3.5001014118463223, "train/extr_critic_mean": 0.7740536185217576, "train/extr_critic_min": -0.2567938582997927, "train/extr_critic_std": 0.8857696480314496, "train/extr_return_normed_mag": 2.055390645920391, "train/extr_return_normed_max": 2.055390645920391, "train/extr_return_normed_mean": 0.34923639809581597, "train/extr_return_normed_min": -0.20936923925305756, "train/extr_return_normed_std": 0.3602716803130969, "train/extr_return_rate": 0.4427115662207066, "train/extr_return_raw_mag": 5.202975538414969, "train/extr_return_raw_max": 5.202975538414969, "train/extr_return_raw_mean": 0.791372644229674, "train/extr_return_raw_min": -0.6556245978449432, "train/extr_return_raw_std": 0.9329579296246381, "train/extr_reward_mag": 1.006029061868157, "train/extr_reward_max": 1.006029061868157, "train/extr_reward_mean": 0.016143610435341234, "train/extr_reward_min": -0.3857232987041205, "train/extr_reward_std": 0.11188975952460732, "train/image_loss_mean": 14.058838293585978, "train/image_loss_std": 16.003784777412953, "train/model_loss_mean": 21.622039250924555, "train/model_loss_std": 19.803741522238287, "train/model_opt_grad_norm": 92.28026822587134, "train/model_opt_grad_steps": 7644.239436619719, "train/model_opt_loss": 16756.586659606073, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 774.6478873239437, "train/policy_entropy_mag": 2.4866368350848345, "train/policy_entropy_max": 2.4866368350848345, "train/policy_entropy_mean": 0.7734280111084522, "train/policy_entropy_min": 0.07938019422368264, "train/policy_entropy_std": 0.6043122146331089, "train/policy_logprob_mag": 7.4383264561774025, "train/policy_logprob_max": -0.009456788629136036, "train/policy_logprob_mean": -0.7732021388873248, "train/policy_logprob_min": -7.4383264561774025, "train/policy_logprob_std": 1.201183000920524, "train/policy_randomness_mag": 0.8776736775754204, "train/policy_randomness_max": 0.8776736775754204, "train/policy_randomness_mean": 0.2729861500187659, "train/policy_randomness_min": 0.02801772502159149, "train/policy_randomness_std": 0.2132956934436946, "train/post_ent_mag": 50.85985884867923, "train/post_ent_max": 50.85985884867923, "train/post_ent_mean": 36.08240957663093, "train/post_ent_min": 18.08053709755481, "train/post_ent_std": 5.4942817452927715, "train/prior_ent_mag": 62.88321269398004, "train/prior_ent_max": 62.88321269398004, "train/prior_ent_mean": 48.768683876789794, "train/prior_ent_min": 21.50616824459022, "train/prior_ent_std": 7.5436593411673964, "train/rep_loss_mean": 12.515626551399768, "train/rep_loss_std": 8.727870507979057, "train/reward_avg": 0.01614560396164577, "train/reward_loss_mean": 0.05341004717990126, "train/reward_loss_std": 0.27169296575683943, "train/reward_max_data": 1.0056338041601047, "train/reward_max_pred": 1.0028268275126604, "train/reward_neg_acc": 0.9934576560913677, "train/reward_neg_loss": 0.03246722492376264, "train/reward_pos_acc": 0.9322791372386503, "train/reward_pos_loss": 1.0362818702845507, "train/reward_pred": 0.015139385825023055, "train/reward_rate": 0.021195532570422535, "train_stats/sum_log_reward": 4.140650344088795, "train_stats/max_log_achievement_collect_drink": 9.861788617886178, "train_stats/max_log_achievement_collect_sapling": 2.7154471544715446, "train_stats/max_log_achievement_collect_wood": 1.6829268292682926, "train_stats/max_log_achievement_defeat_zombie": 0.3170731707317073, "train_stats/max_log_achievement_eat_cow": 0.0975609756097561, "train_stats/max_log_achievement_make_wood_pickaxe": 0.04065040650406504, "train_stats/max_log_achievement_make_wood_sword": 0.024390243902439025, "train_stats/max_log_achievement_place_plant": 2.6260162601626016, "train_stats/max_log_achievement_place_table": 0.5447154471544715, "train_stats/max_log_achievement_wake_up": 2.0813008130081303, "train_stats/mean_log_entropy": 0.3698794202106755, "train_stats/max_log_achievement_eat_plant": 0.00819672131147541, "eval_stats/sum_log_reward": 4.099999941885471, "eval_stats/max_log_achievement_collect_drink": 10.1875, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_wood": 2.125, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_table": 0.625, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 7.020895282039419e-06, "report/cont_loss_std": 0.00012396497186273336, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002623558393679559, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.270645826589316e-06, "report/cont_pred": 0.9970648288726807, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.298959732055664, "report/dyn_loss_std": 9.069186210632324, "report/image_loss_mean": 11.538719177246094, "report/image_loss_std": 17.02288818359375, "report/model_loss_mean": 17.780439376831055, "report/model_loss_std": 21.2867374420166, "report/post_ent_mag": 54.330780029296875, "report/post_ent_max": 54.330780029296875, "report/post_ent_mean": 37.52920913696289, "report/post_ent_min": 16.238826751708984, "report/post_ent_std": 5.534215927124023, "report/prior_ent_mag": 63.787113189697266, "report/prior_ent_max": 63.787113189697266, "report/prior_ent_mean": 48.52323913574219, "report/prior_ent_min": 20.02246856689453, "report/prior_ent_std": 7.491197109222412, "report/rep_loss_mean": 10.298959732055664, "report/rep_loss_std": 9.069186210632324, "report/reward_avg": 0.01230468787252903, "report/reward_loss_mean": 0.062336646020412445, "report/reward_loss_std": 0.43544062972068787, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021641254425049, "report/reward_neg_acc": 0.9970208406448364, "report/reward_neg_loss": 0.03491964563727379, "report/reward_pos_acc": 0.7647058963775635, "report/reward_pos_loss": 1.6863906383514404, "report/reward_pred": 0.008371157571673393, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.00044564998825080693, "eval/cont_loss_std": 0.0127857755869627, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.058748528361320496, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.435182927409187e-05, "eval/cont_pred": 0.9934512972831726, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 16.609928131103516, "eval/dyn_loss_std": 8.763636589050293, "eval/image_loss_mean": 32.86559295654297, "eval/image_loss_std": 36.652957916259766, "eval/model_loss_mean": 42.95185852050781, "eval/model_loss_std": 39.8924560546875, "eval/post_ent_mag": 50.94629669189453, "eval/post_ent_max": 50.94629669189453, "eval/post_ent_mean": 35.604515075683594, "eval/post_ent_min": 19.33039093017578, "eval/post_ent_std": 5.061100482940674, "eval/prior_ent_mag": 63.06081771850586, "eval/prior_ent_max": 63.06081771850586, "eval/prior_ent_mean": 49.976341247558594, "eval/prior_ent_min": 21.745376586914062, "eval/prior_ent_std": 7.081153869628906, "eval/rep_loss_mean": 16.609928131103516, "eval/rep_loss_std": 8.763636589050293, "eval/reward_avg": 0.01083984412252903, "eval/reward_loss_mean": 0.11986193060874939, "eval/reward_loss_std": 0.8632129430770874, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9985945224761963, "eval/reward_neg_acc": 0.9970208406448364, "eval/reward_neg_loss": 0.03697437420487404, "eval/reward_pos_acc": 0.4117647111415863, "eval/reward_pos_loss": 5.029730796813965, "eval/reward_pred": 0.0022852951660752296, "eval/reward_rate": 0.0166015625, "replay/size": 134849.0, "replay/inserts": 22696.0, "replay/samples": 22704.0, "replay/insert_wait_avg": 1.282655398611204e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.158044465584516e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27768.0, "eval_replay/inserts": 3336.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.196095125852443e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.6132166385651, "timer/env.step_count": 2837.0, "timer/env.step_total": 266.70024847984314, "timer/env.step_frac": 0.2662706961624316, "timer/env.step_avg": 0.09400784225584884, "timer/env.step_min": 0.022317171096801758, "timer/env.step_max": 4.020650148391724, "timer/replay._sample_count": 22704.0, "timer/replay._sample_total": 12.161616802215576, "timer/replay._sample_frac": 0.012142029078879587, "timer/replay._sample_avg": 0.0005356596547839842, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.011156082153320312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3254.0, "timer/agent.policy_total": 48.99697661399841, "timer/agent.policy_frac": 0.04891806118377041, "timer/agent.policy_avg": 0.015057460545174681, "timer/agent.policy_min": 0.008472919464111328, "timer/agent.policy_max": 0.0836031436920166, "timer/dataset_train_count": 1419.0, "timer/dataset_train_total": 0.1523759365081787, "timer/dataset_train_frac": 0.00015213051702687744, "timer/dataset_train_avg": 0.00010738261910372003, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0007207393646240234, "timer/agent.train_count": 1419.0, "timer/agent.train_total": 621.8265466690063, "timer/agent.train_frac": 0.6208250214148224, "timer/agent.train_avg": 0.438214620626502, "timer/agent.train_min": 0.42574214935302734, "timer/agent.train_max": 1.3338909149169922, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768073558807373, "timer/agent.report_frac": 0.00047603940119811194, "timer/agent.report_avg": 0.23840367794036865, "timer/agent.report_min": 0.22913575172424316, "timer/agent.report_max": 0.24767160415649414, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7135941864658922e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.65915162369151}
{"step": 135504, "time": 6368.038177728653, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 135552, "time": 6371.072335958481, "episode/length": 141.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 135632, "time": 6375.140478849411, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 135664, "time": 6377.786341190338, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 135984, "time": 6389.744075298309, "episode/length": 39.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 136016, "time": 6392.432379245758, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 136488, "time": 6409.079467058182, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 136880, "time": 6423.59109210968, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 137088, "time": 6431.915652990341, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 137208, "time": 6437.152522087097, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 137232, "time": 6439.690361261368, "episode/length": 489.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 137288, "time": 6442.797878503799, "episode/length": 216.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 137720, "time": 6458.352828264236, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 137872, "time": 6465.033169269562, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 137952, "time": 6469.237052202225, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 138448, "time": 6486.990536689758, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 138472, "time": 6489.1186356544495, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 138784, "time": 6500.950595378876, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 138880, "time": 6505.548308610916, "episode/length": 223.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 138888, "time": 6507.128016233444, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 139008, "time": 6512.786878585815, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 139688, "time": 6537.307252168655, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 139720, "time": 6539.926047325134, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6571.312523603439, "eval_episode/length": 133.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 140088, "time": 6573.622633695602, "eval_episode/length": 153.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 140088, "time": 6575.970625400543, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 140088, "time": 6577.441177845001, "eval_episode/length": 176.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 140088, "time": 6579.249857902527, "eval_episode/length": 184.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.972972972972973}
{"step": 140088, "time": 6581.199275255203, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 140088, "time": 6582.939673662186, "eval_episode/length": 197.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 140088, "time": 6585.924080371857, "eval_episode/length": 232.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 140160, "time": 6588.502409219742, "episode/length": 285.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 140368, "time": 6596.886253356934, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 140488, "time": 6602.290371179581, "episode/length": 40.0, "episode/score": 2.1000000163912773, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 140760, "time": 6612.595388174057, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 141032, "time": 6622.91069149971, "episode/length": 267.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 141080, "time": 6625.980665445328, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 141512, "time": 6641.339004278183, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 141568, "time": 6644.821775197983, "episode/length": 347.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 141968, "time": 6659.270187854767, "episode/length": 436.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 141992, "time": 6661.323839426041, "episode/length": 202.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 142320, "time": 6673.72093629837, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 142640, "time": 6685.569901943207, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 142736, "time": 6690.140619754791, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 142824, "time": 6694.4890904426575, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 143032, "time": 6702.840565443039, "episode/length": 317.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 143112, "time": 6707.044898748398, "episode/length": 192.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 143272, "time": 6713.663568019867, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 143400, "time": 6719.432562351227, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 143504, "time": 6724.57289147377, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 143648, "time": 6730.73864865303, "episode/length": 46.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 143872, "time": 6739.456025600433, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 144256, "time": 6753.535238027573, "episode/length": 142.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 144296, "time": 6756.068874835968, "episode/length": 287.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 144592, "time": 6767.396537780762, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 145048, "time": 6783.590116977692, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 145112, "time": 6787.18542098999, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 145632, "time": 6805.872134447098, "episode/length": 219.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 145640, "time": 6807.435190677643, "episode/length": 172.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 145888, "time": 6817.3973886966705, "episode/length": 161.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 145992, "time": 6822.202592372894, "episode/length": 211.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 146200, "time": 6830.544887065887, "episode/length": 432.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 146952, "time": 6856.535450935364, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 147016, "time": 6860.172960996628, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 147096, "time": 6864.238461732864, "episode/length": 255.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 147120, "time": 6866.879647016525, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 147296, "time": 6874.305586099625, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 147624, "time": 6887.702052593231, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 147680, "time": 6891.357880353928, "episode/length": 210.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 147912, "time": 6900.150099992752, "episode/length": 532.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962476547842402, "episode/intrinsic_return": 0.0}
{"step": 147992, "time": 6904.39569568634, "episode/length": 294.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 148192, "time": 6912.482773065567, "episode/length": 111.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 148296, "time": 6917.1188333034515, "episode/length": 47.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 148304, "time": 6919.199828386307, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 148384, "time": 6923.244091033936, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 148624, "time": 6932.551973819733, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 149296, "time": 6956.150088071823, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 149424, "time": 6961.840015172958, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 149536, "time": 6967.138633012772, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 149576, "time": 6969.72987818718, "episode/length": 243.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 149832, "time": 6979.603678226471, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 149960, "time": 6985.763995409012, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 149976, "time": 6988.257767915726, "episode/length": 247.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 150016, "time": 6991.964175224304, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7009.8823165893555, "eval_episode/length": 32.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 150072, "time": 7012.068429708481, "eval_episode/length": 48.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 150072, "time": 7014.90811753273, "eval_episode/length": 49.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.98}
{"step": 150072, "time": 7018.641236543655, "eval_episode/length": 136.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 150072, "time": 7020.636368513107, "eval_episode/length": 144.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 150072, "time": 7022.99091386795, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 150072, "time": 7025.258133888245, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 150072, "time": 7027.633380174637, "eval_episode/length": 151.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.993421052631579}
{"step": 150248, "time": 7033.297039747238, "episode/length": 118.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 150320, "time": 7037.372468471527, "episode/length": 44.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 151208, "time": 7067.396177530289, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 151264, "time": 7070.874582290649, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 151488, "time": 7079.705953121185, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 151592, "time": 7084.561789035797, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 151800, "time": 7092.783530950546, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 151872, "time": 7096.902475118637, "episode/length": 305.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 151944, "time": 7101.061743974686, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 152424, "time": 7118.1191465854645, "episode/length": 355.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 152512, "time": 7122.82341837883, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 152624, "time": 7127.875225543976, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 152656, "time": 7130.483525276184, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 153168, "time": 7148.729715585709, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 153464, "time": 7159.601464033127, "episode/length": 207.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 153480, "time": 7161.563938140869, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 153664, "time": 7169.207744836807, "episode/length": 214.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 153888, "time": 7178.049706220627, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 154000, "time": 7183.123445749283, "episode/length": 300.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 154088, "time": 7187.313905000687, "episode/length": 196.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 154368, "time": 7198.238574743271, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 154424, "time": 7201.519942045212, "episode/length": 117.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9491525423728814, "episode/intrinsic_return": 0.0}
{"step": 154576, "time": 7208.187313318253, "episode/length": 239.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 154824, "time": 7217.463329315186, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 154824, "time": 7217.470306634903, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 155352, "time": 7237.671288251877, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 155432, "time": 7241.772190570831, "episode/length": 178.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 155792, "time": 7256.513926267624, "episode/length": 170.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 155808, "time": 7258.56436252594, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 156368, "time": 7278.284854888916, "episode/length": 223.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 156480, "time": 7283.464282512665, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 156552, "time": 7287.112215280533, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 156752, "time": 7295.447288036346, "episode/length": 297.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 156920, "time": 7302.165275812149, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 157320, "time": 7316.701317548752, "episode/length": 311.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9967948717948718, "episode/intrinsic_return": 0.0}
{"step": 157336, "time": 7318.68910241127, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 157520, "time": 7326.313220500946, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 157904, "time": 7340.361312150955, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 157928, "time": 7342.476887702942, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 158024, "time": 7347.032574892044, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 158032, "time": 7348.946832418442, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 158409, "time": 7363.43186211586, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.409800211588542, "train/action_min": 0.0, "train/action_std": 3.1375758118099637, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050390762354557715, "train/actor_opt_grad_steps": 9085.0, "train/actor_opt_loss": 3.127246590641638, "train/adv_mag": 0.8833428530229462, "train/adv_max": 0.8815596542424626, "train/adv_mean": 0.005046249675514345, "train/adv_min": -0.5088039359284772, "train/adv_std": 0.08701565383105642, "train/cont_avg": 0.9943372938368056, "train/cont_loss_mean": 0.0004511761116009359, "train/cont_loss_std": 0.012512611903277262, "train/cont_neg_acc": 0.984636796431409, "train/cont_neg_loss": 0.04204603517169166, "train/cont_pos_acc": 0.9999521921078364, "train/cont_pos_loss": 0.0001842724088360923, "train/cont_pred": 0.9943384933802817, "train/cont_rate": 0.9943372938368056, "train/dyn_loss_mean": 13.277931736575233, "train/dyn_loss_std": 8.979469875494638, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1296851543916597, "train/extr_critic_critic_opt_grad_steps": 9085.0, "train/extr_critic_critic_opt_loss": 15581.344712999133, "train/extr_critic_mag": 3.9801761673556433, "train/extr_critic_max": 3.9801761673556433, "train/extr_critic_mean": 0.8609581101271842, "train/extr_critic_min": -0.24321265353096855, "train/extr_critic_std": 0.9584870955182446, "train/extr_return_normed_mag": 1.933203083773454, "train/extr_return_normed_max": 1.933203083773454, "train/extr_return_normed_mean": 0.3366951019399696, "train/extr_return_normed_min": -0.182683148007426, "train/extr_return_normed_std": 0.350210168502397, "train/extr_return_rate": 0.46237252838909626, "train/extr_return_raw_mag": 5.436497294240528, "train/extr_return_raw_max": 5.436497294240528, "train/extr_return_raw_mean": 0.8753650602367189, "train/extr_return_raw_min": -0.6077621059699191, "train/extr_return_raw_std": 1.0003629852500227, "train/extr_reward_mag": 1.0052344848712285, "train/extr_reward_max": 1.0052344848712285, "train/extr_reward_mean": 0.01728990555016531, "train/extr_reward_min": -0.36826375292407143, "train/extr_reward_std": 0.11724903719085786, "train/image_loss_mean": 12.205148624049293, "train/image_loss_std": 14.847546362214619, "train/model_loss_mean": 20.225401706165737, "train/model_loss_std": 18.72552290889952, "train/model_opt_grad_norm": 88.41596640740241, "train/model_opt_grad_steps": 9073.013888888889, "train/model_opt_loss": 16530.108690049914, "train/model_opt_model_opt_grad_overflow": 0.006944444444444444, "train/model_opt_model_opt_grad_scale": 811.6319444444445, "train/policy_entropy_mag": 2.4917120618952646, "train/policy_entropy_max": 2.4917120618952646, "train/policy_entropy_mean": 0.7368619553744793, "train/policy_entropy_min": 0.07937770611089137, "train/policy_entropy_std": 0.6390077856679758, "train/policy_logprob_mag": 7.438360426161024, "train/policy_logprob_max": -0.009456302116935452, "train/policy_logprob_mean": -0.7374248028629355, "train/policy_logprob_min": -7.438360426161024, "train/policy_logprob_std": 1.1816220076547728, "train/policy_randomness_mag": 0.8794650120867623, "train/policy_randomness_max": 0.8794650120867623, "train/policy_randomness_mean": 0.26007993353737724, "train/policy_randomness_min": 0.028016846898632746, "train/policy_randomness_std": 0.22554170723176664, "train/post_ent_mag": 52.80267463790046, "train/post_ent_max": 52.80267463790046, "train/post_ent_mean": 36.91437607341342, "train/post_ent_min": 19.587678584787582, "train/post_ent_std": 5.726882431242201, "train/prior_ent_mag": 64.15078481038411, "train/prior_ent_max": 64.15078481038411, "train/prior_ent_mean": 50.358743853039215, "train/prior_ent_min": 23.894165237744648, "train/prior_ent_std": 7.332533753580517, "train/rep_loss_mean": 13.277931736575233, "train/rep_loss_std": 8.979469875494638, "train/reward_avg": 0.017034233728837635, "train/reward_loss_mean": 0.05304293450899422, "train/reward_loss_std": 0.2662918304817544, "train/reward_max_data": 1.0069444461001291, "train/reward_max_pred": 1.0031859129667282, "train/reward_neg_acc": 0.9928906257781718, "train/reward_neg_loss": 0.032029325174840376, "train/reward_pos_acc": 0.9418133935994573, "train/reward_pos_loss": 0.9897179065479172, "train/reward_pred": 0.0163840002561402, "train/reward_rate": 0.021999782986111112, "train_stats/sum_log_reward": 4.544444386775677, "train_stats/max_log_achievement_collect_drink": 9.205128205128204, "train_stats/max_log_achievement_collect_sapling": 3.0683760683760686, "train_stats/max_log_achievement_collect_wood": 2.0085470085470085, "train_stats/max_log_achievement_defeat_zombie": 0.452991452991453, "train_stats/max_log_achievement_eat_cow": 0.1452991452991453, "train_stats/max_log_achievement_eat_plant": 0.017094017094017096, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.02564102564102564, "train_stats/max_log_achievement_place_plant": 2.4957264957264957, "train_stats/max_log_achievement_place_table": 0.6923076923076923, "train_stats/max_log_achievement_wake_up": 2.6153846153846154, "train_stats/mean_log_entropy": 0.38713372645215094, "eval_stats/sum_log_reward": 3.7874999810010195, "eval_stats/max_log_achievement_collect_drink": 7.3125, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_wood": 1.75, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_table": 0.625, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.9981049010530114e-05, "report/cont_loss_std": 0.0004050409479532391, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0027376837097108364, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4022093637322541e-05, "report/cont_pred": 0.9941426515579224, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.36824893951416, "report/dyn_loss_std": 8.15552043914795, "report/image_loss_mean": 9.455863952636719, "report/image_loss_std": 9.290191650390625, "report/model_loss_mean": 18.713943481445312, "report/model_loss_std": 12.582436561584473, "report/post_ent_mag": 53.290771484375, "report/post_ent_max": 53.290771484375, "report/post_ent_mean": 36.324432373046875, "report/post_ent_min": 21.60519027709961, "report/post_ent_std": 5.772461414337158, "report/prior_ent_mag": 64.64634704589844, "report/prior_ent_max": 64.64634704589844, "report/prior_ent_mean": 52.00646209716797, "report/prior_ent_min": 26.671667098999023, "report/prior_ent_std": 6.721017837524414, "report/rep_loss_mean": 15.36824893951416, "report/rep_loss_std": 8.15552043914795, "report/reward_avg": 0.014843749813735485, "report/reward_loss_mean": 0.037099771201610565, "report/reward_loss_std": 0.15987692773342133, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0032973289489746, "report/reward_neg_acc": 0.993027925491333, "report/reward_neg_loss": 0.023113591596484184, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7392061352729797, "report/reward_pred": 0.014740420505404472, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 2.2218730009626597e-05, "eval/cont_loss_std": 0.00022376059496309608, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001445759437046945, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1009747140633408e-05, "eval/cont_pred": 0.9921877980232239, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 10.568713188171387, "eval/dyn_loss_std": 9.003344535827637, "eval/image_loss_mean": 8.362850189208984, "eval/image_loss_std": 12.048494338989258, "eval/model_loss_mean": 14.749809265136719, "eval/model_loss_std": 15.919772148132324, "eval/post_ent_mag": 54.767974853515625, "eval/post_ent_max": 54.767974853515625, "eval/post_ent_mean": 37.531776428222656, "eval/post_ent_min": 17.524147033691406, "eval/post_ent_std": 5.682955265045166, "eval/prior_ent_mag": 64.64634704589844, "eval/prior_ent_max": 64.64634704589844, "eval/prior_ent_mean": 46.320186614990234, "eval/prior_ent_min": 21.278545379638672, "eval/prior_ent_std": 6.919112682342529, "eval/rep_loss_mean": 10.568713188171387, "eval/rep_loss_std": 9.003344535827637, "eval/reward_avg": 0.004687499720603228, "eval/reward_loss_mean": 0.04570857807993889, "eval/reward_loss_std": 0.3392942249774933, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020289421081543, "eval/reward_neg_acc": 0.9960552453994751, "eval/reward_neg_loss": 0.027416616678237915, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 1.9005135297775269, "eval/reward_pred": 0.0042408425360918045, "eval/reward_rate": 0.009765625, "replay/size": 157905.0, "replay/inserts": 23056.0, "replay/samples": 23056.0, "replay/insert_wait_avg": 1.2982520355605815e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.989338749734004e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31240.0, "eval_replay/inserts": 3472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.201981223673315e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2338373661041, "timer/env.step_count": 2882.0, "timer/env.step_total": 254.9805121421814, "timer/env.step_frac": 0.2549209021098671, "timer/env.step_avg": 0.08847346014648903, "timer/env.step_min": 0.02244734764099121, "timer/env.step_max": 3.1055450439453125, "timer/replay._sample_count": 23056.0, "timer/replay._sample_total": 12.275863409042358, "timer/replay._sample_frac": 0.012272993524562362, "timer/replay._sample_avg": 0.0005324368237787282, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.009722471237182617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3316.0, "timer/agent.policy_total": 49.58493137359619, "timer/agent.policy_frac": 0.049573339274511255, "timer/agent.policy_avg": 0.014953236240529612, "timer/agent.policy_min": 0.008466720581054688, "timer/agent.policy_max": 0.08548426628112793, "timer/dataset_train_count": 1441.0, "timer/dataset_train_total": 0.15314292907714844, "timer/dataset_train_frac": 0.00015310712690986007, "timer/dataset_train_avg": 0.00010627545390503015, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.00032067298889160156, "timer/agent.train_count": 1441.0, "timer/agent.train_total": 631.8759534358978, "timer/agent.train_frac": 0.6317282317700871, "timer/agent.train_avg": 0.438498232779943, "timer/agent.train_min": 0.428314208984375, "timer/agent.train_max": 1.4092824459075928, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48276805877685547, "timer/agent.report_frac": 0.0004826551959570964, "timer/agent.report_avg": 0.24138402938842773, "timer/agent.report_min": 0.2355036735534668, "timer/agent.report_max": 0.24726438522338867, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.0742416381835938e-05, "timer/dataset_eval_frac": 2.0737567163750958e-08, "timer/dataset_eval_avg": 2.0742416381835938e-05, "timer/dataset_eval_min": 2.0742416381835938e-05, "timer/dataset_eval_max": 2.0742416381835938e-05, "fps": 23.05031383268502}
{"step": 159056, "time": 7384.377728939056, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 159216, "time": 7391.050714731216, "episode/length": 234.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 159376, "time": 7397.708619356155, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 159400, "time": 7399.736834049225, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 159400, "time": 7399.745096206665, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 159504, "time": 7406.665832281113, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7439.774561166763, "eval_episode/length": 40.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.975609756097561}
{"step": 160056, "time": 7444.86355304718, "eval_episode/length": 124.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.944}
{"step": 160056, "time": 7448.75292301178, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 160056, "time": 7450.361268520355, "eval_episode/length": 151.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 160056, "time": 7452.444566965103, "eval_episode/length": 163.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.975609756097561}
{"step": 160056, "time": 7454.130180120468, "eval_episode/length": 167.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 160056, "time": 7457.605513811111, "eval_episode/length": 213.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 160056, "time": 7459.418479919434, "eval_episode/length": 217.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.963302752293578}
{"step": 160184, "time": 7463.547479629517, "episode/length": 120.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9504132231404959, "episode/intrinsic_return": 0.0}
{"step": 160408, "time": 7472.372160196304, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 160544, "time": 7478.52579832077, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 160696, "time": 7484.736012220383, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 160768, "time": 7488.790913820267, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 160960, "time": 7496.438281774521, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 161592, "time": 7518.056980133057, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 161760, "time": 7525.204943180084, "episode/length": 478.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937369519832986, "episode/intrinsic_return": 0.0}
{"step": 161944, "time": 7532.570425748825, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 162040, "time": 7537.166790962219, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 162064, "time": 7539.612718820572, "episode/length": 663.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.983433734939759, "episode/intrinsic_return": 0.0}
{"step": 162208, "time": 7545.867864608765, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 162224, "time": 7547.895521640778, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 162528, "time": 7559.249104976654, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 162704, "time": 7566.464917898178, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 163304, "time": 7587.026340961456, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 163328, "time": 7589.496833086014, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 163512, "time": 7596.725499391556, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 163640, "time": 7602.419980287552, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 164104, "time": 7620.028735876083, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 164144, "time": 7623.2179119586945, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 164296, "time": 7629.389011144638, "episode/length": 260.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 164640, "time": 7642.21124458313, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 164736, "time": 7646.865322351456, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 164808, "time": 7650.473170518875, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 164984, "time": 7657.942103624344, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 165200, "time": 7666.574266672134, "episode/length": 450.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.991130820399113, "episode/intrinsic_return": 0.0}
{"step": 165216, "time": 7668.685212135315, "episode/length": 138.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 165360, "time": 7674.8900763988495, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 165672, "time": 7686.378628730774, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 165728, "time": 7689.956352710724, "episode/length": 135.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 166488, "time": 7715.733996152878, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 166672, "time": 7723.44374871254, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 166792, "time": 7728.648299694061, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 166880, "time": 7733.295214176178, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 166928, "time": 7736.691154956818, "episode/length": 215.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 166992, "time": 7740.266539573669, "episode/length": 157.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 167176, "time": 7747.680098295212, "episode/length": 273.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 167576, "time": 7762.091740846634, "episode/length": 135.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 168040, "time": 7778.565243005753, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 168184, "time": 7784.730204820633, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 168344, "time": 7791.618188619614, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 168712, "time": 7805.152546405792, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9906976744186047, "episode/intrinsic_return": 0.0}
{"step": 168720, "time": 7807.0678861141205, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 168864, "time": 7813.330577373505, "episode/length": 210.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 169040, "time": 7820.50815486908, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 169416, "time": 7834.120761632919, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 169416, "time": 7834.126370191574, "episode/length": 46.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 169720, "time": 7847.250504732132, "episode/length": 125.0, "episode/score": 3.1000000163912773, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 169728, "time": 7849.29069519043, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 169904, "time": 7856.481059551239, "episode/length": 645.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9922600619195047, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 7876.46404671669, "eval_episode/length": 40.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 170040, "time": 7883.818290948868, "eval_episode/length": 177.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 170040, "time": 7885.797148227692, "eval_episode/length": 148.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 170040, "time": 7887.583567619324, "eval_episode/length": 195.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 170040, "time": 7889.3653652668, "eval_episode/length": 203.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 170040, "time": 7892.134113550186, "eval_episode/length": 230.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 170040, "time": 7894.3792016506195, "eval_episode/length": 246.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 170040, "time": 7896.363438844681, "eval_episode/length": 255.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.99609375}
{"step": 170288, "time": 7904.592483520508, "episode/length": 70.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 170336, "time": 7907.695325613022, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 170472, "time": 7913.377922534943, "episode/length": 285.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 170584, "time": 7918.604312181473, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 170672, "time": 7923.308223485947, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 170816, "time": 7929.451363563538, "episode/length": 174.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 171128, "time": 7940.8258056640625, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 171568, "time": 7956.710197925568, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 171952, "time": 7970.678529262543, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 171992, "time": 7973.372262716293, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 172008, "time": 7975.388731002808, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 172160, "time": 7983.464883327484, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 172208, "time": 7986.459276199341, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 172360, "time": 7992.692168474197, "episode/length": 252.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 172528, "time": 7999.751229047775, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 173296, "time": 8025.941768884659, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 173552, "time": 8035.852207899094, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 173768, "time": 8044.22025346756, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 173792, "time": 8046.728311300278, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 173816, "time": 8048.755261898041, "episode/length": 280.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 173912, "time": 8053.3112943172455, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 174064, "time": 8059.92911362648, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 174064, "time": 8059.937846422195, "episode/length": 212.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 175040, "time": 8095.819296598434, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 175048, "time": 8097.335834503174, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 175328, "time": 8108.152088165283, "episode/length": 157.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 175336, "time": 8109.676258563995, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 175360, "time": 8112.123775482178, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 175576, "time": 8120.430133342743, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 175752, "time": 8127.592044353485, "episode/length": 48.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 175872, "time": 8133.366540670395, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 175936, "time": 8136.906747102737, "episode/length": 252.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 176184, "time": 8146.399902582169, "episode/length": 298.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 176640, "time": 8162.782362937927, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 177144, "time": 8180.402710437775, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 177168, "time": 8182.991627693176, "episode/length": 228.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 177520, "time": 8196.012494325638, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 177816, "time": 8206.978870868683, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9670781893004116, "episode/intrinsic_return": 0.0}
{"step": 177944, "time": 8212.590685844421, "episode/length": 162.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 177984, "time": 8215.67993402481, "episode/length": 366.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.989100817438692, "episode/intrinsic_return": 0.0}
{"step": 178232, "time": 8224.952671051025, "episode/length": 35.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 178432, "time": 8233.056760549545, "episode/length": 311.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 178592, "time": 8239.815358400345, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 178752, "time": 8246.589006185532, "episode/length": 197.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 178960, "time": 8254.873540401459, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 179096, "time": 8260.575784683228, "episode/length": 82.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 179488, "time": 8274.983628511429, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 179528, "time": 8277.436711072922, "episode/length": 250.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 179720, "time": 8285.32214140892, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 179800, "time": 8289.388169765472, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8312.629068136215, "eval_episode/length": 41.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9047619047619048}
{"step": 180024, "time": 8317.969720602036, "eval_episode/length": 135.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9558823529411765}
{"step": 180024, "time": 8320.208427667618, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 180024, "time": 8322.434833526611, "eval_episode/length": 174.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 180024, "time": 8324.239426136017, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 180024, "time": 8326.314415931702, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 180024, "time": 8328.360586643219, "eval_episode/length": 206.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 180024, "time": 8330.35904455185, "eval_episode/length": 220.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 180120, "time": 8333.47471523285, "episode/length": 49.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 180280, "time": 8341.556196928024, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 180344, "time": 8345.093398332596, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 180448, "time": 8350.082320690155, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 180520, "time": 8353.59999871254, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 180761, "time": 8363.895955324173, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.763490513392857, "train/action_min": 0.0, "train/action_std": 3.5393880997385296, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05127434522977897, "train/actor_opt_grad_steps": 10505.0, "train/actor_opt_loss": 6.363703182479367, "train/adv_mag": 0.884683933854103, "train/adv_max": 0.8826943065438951, "train/adv_mean": 0.005751772426862901, "train/adv_min": -0.49275764184338705, "train/adv_std": 0.08761640180434499, "train/cont_avg": 0.9944196428571429, "train/cont_loss_mean": 0.0005602965879635998, "train/cont_loss_std": 0.015971526917941705, "train/cont_neg_acc": 0.9848974642962435, "train/cont_neg_loss": 0.05200740890124149, "train/cont_pos_acc": 0.9999227553606034, "train/cont_pos_loss": 0.0002698731204754422, "train/cont_pred": 0.9944290212222509, "train/cont_rate": 0.9944196428571429, "train/dyn_loss_mean": 13.871301555633545, "train/dyn_loss_std": 9.193027312414987, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.159907710977963, "train/extr_critic_critic_opt_grad_steps": 10505.0, "train/extr_critic_critic_opt_loss": 15543.49351283482, "train/extr_critic_mag": 3.809195831843785, "train/extr_critic_max": 3.809195831843785, "train/extr_critic_mean": 0.8737264505454472, "train/extr_critic_min": -0.23505686691829136, "train/extr_critic_std": 0.9320744889123099, "train/extr_return_normed_mag": 1.8882941833564213, "train/extr_return_normed_max": 1.8882941833564213, "train/extr_return_normed_mean": 0.34065169787832666, "train/extr_return_normed_min": -0.18316591240997826, "train/extr_return_normed_std": 0.3466570888246809, "train/extr_return_rate": 0.4806101437125887, "train/extr_return_raw_mag": 5.232004618644714, "train/extr_return_raw_max": 5.232004618644714, "train/extr_return_raw_mean": 0.8898637054221971, "train/extr_return_raw_min": -0.5793842570057937, "train/extr_return_raw_std": 0.9727927207946777, "train/extr_reward_mag": 1.005952823162079, "train/extr_reward_max": 1.005952823162079, "train/extr_reward_mean": 0.017469138459169437, "train/extr_reward_min": -0.3914863399096898, "train/extr_reward_std": 0.11821265167423657, "train/image_loss_mean": 11.462920192309788, "train/image_loss_std": 14.409254721232823, "train/model_loss_mean": 19.841303368977137, "train/model_loss_std": 18.33839112690517, "train/model_opt_grad_norm": 80.46866192136493, "train/model_opt_grad_steps": 10491.921428571428, "train/model_opt_loss": 14719.936418805804, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 745.5357142857143, "train/policy_entropy_mag": 2.457749618802752, "train/policy_entropy_max": 2.457749618802752, "train/policy_entropy_mean": 0.737365968312536, "train/policy_entropy_min": 0.07937675517584597, "train/policy_entropy_std": 0.6626100165503366, "train/policy_logprob_mag": 7.438370673997062, "train/policy_logprob_max": -0.00945611973958356, "train/policy_logprob_mean": -0.7387490170342582, "train/policy_logprob_min": -7.438370673997062, "train/policy_logprob_std": 1.1738895407744816, "train/policy_randomness_mag": 0.8674777618476323, "train/policy_randomness_max": 0.8674777618476323, "train/policy_randomness_mean": 0.2602578303643635, "train/policy_randomness_min": 0.028016511177910226, "train/policy_randomness_std": 0.23387225994041988, "train/post_ent_mag": 54.41544260297503, "train/post_ent_max": 54.41544260297503, "train/post_ent_mean": 37.71127035958426, "train/post_ent_min": 20.26582659312657, "train/post_ent_std": 5.965224061693464, "train/prior_ent_mag": 65.30284006936209, "train/prior_ent_max": 65.30284006936209, "train/prior_ent_mean": 51.7054931640625, "train/prior_ent_min": 26.709832981654575, "train/prior_ent_std": 6.982132032939366, "train/rep_loss_mean": 13.871301555633545, "train/rep_loss_std": 9.193027312414987, "train/reward_avg": 0.017956193975572077, "train/reward_loss_mean": 0.05504203845879861, "train/reward_loss_std": 0.2717986613512039, "train/reward_max_data": 1.0121428600379399, "train/reward_max_pred": 1.0030284336635045, "train/reward_neg_acc": 0.9926501993622099, "train/reward_neg_loss": 0.03278815032847758, "train/reward_pos_acc": 0.9399463559900011, "train/reward_pos_loss": 1.0053245791367122, "train/reward_pred": 0.01709422245289066, "train/reward_rate": 0.023039899553571427, "train_stats/sum_log_reward": 4.555357081549508, "train_stats/max_log_achievement_collect_drink": 10.223214285714286, "train_stats/max_log_achievement_collect_sapling": 3.0, "train_stats/max_log_achievement_collect_wood": 2.8392857142857144, "train_stats/max_log_achievement_defeat_zombie": 0.3482142857142857, "train_stats/max_log_achievement_eat_cow": 0.13392857142857142, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008928571428571428, "train_stats/max_log_achievement_make_wood_sword": 0.008928571428571428, "train_stats/max_log_achievement_place_plant": 2.75, "train_stats/max_log_achievement_place_table": 1.1071428571428572, "train_stats/max_log_achievement_wake_up": 2.5625, "train_stats/mean_log_entropy": 0.4001218946650624, "eval_stats/sum_log_reward": 4.391666596134503, "eval_stats/max_log_achievement_collect_drink": 8.541666666666666, "eval_stats/max_log_achievement_collect_sapling": 2.5416666666666665, "eval_stats/max_log_achievement_collect_wood": 2.0833333333333335, "eval_stats/max_log_achievement_defeat_zombie": 0.4166666666666667, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3333333333333335, "eval_stats/max_log_achievement_place_table": 0.7916666666666666, "eval_stats/max_log_achievement_wake_up": 2.1666666666666665, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0024438321124762297, "report/cont_loss_std": 0.07740761339664459, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002505366923287511, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.0024434085935354233, "report/cont_pred": 0.9922800064086914, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.735799789428711, "report/dyn_loss_std": 8.5667085647583, "report/image_loss_mean": 8.016561508178711, "report/image_loss_std": 10.186991691589355, "report/model_loss_mean": 15.116960525512695, "report/model_loss_std": 13.918815612792969, "report/post_ent_mag": 54.70679473876953, "report/post_ent_max": 54.70679473876953, "report/post_ent_mean": 39.0904541015625, "report/post_ent_min": 20.207969665527344, "report/post_ent_std": 6.037193298339844, "report/prior_ent_mag": 66.64676666259766, "report/prior_ent_max": 66.64676666259766, "report/prior_ent_mean": 51.59624099731445, "report/prior_ent_min": 27.270891189575195, "report/prior_ent_std": 6.390542030334473, "report/rep_loss_mean": 11.735799789428711, "report/rep_loss_std": 8.5667085647583, "report/reward_avg": 0.01533203199505806, "report/reward_loss_mean": 0.056475602090358734, "report/reward_loss_std": 0.24966304004192352, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014028549194336, "report/reward_neg_acc": 0.9920079708099365, "report/reward_neg_loss": 0.03417876735329628, "report/reward_pos_acc": 0.9130434989929199, "report/reward_pos_loss": 1.0268725156784058, "report/reward_pred": 0.01534429844468832, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0015849634073674679, "eval/cont_loss_std": 0.03529757261276245, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.10766672343015671, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.001064444426447153, "eval/cont_pred": 0.994823157787323, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 12.826189041137695, "eval/dyn_loss_std": 9.0581693649292, "eval/image_loss_mean": 14.683656692504883, "eval/image_loss_std": 23.68958854675293, "eval/model_loss_mean": 22.43912696838379, "eval/model_loss_std": 27.190933227539062, "eval/post_ent_mag": 54.274688720703125, "eval/post_ent_max": 54.274688720703125, "eval/post_ent_mean": 38.208580017089844, "eval/post_ent_min": 20.67936897277832, "eval/post_ent_std": 5.454818248748779, "eval/prior_ent_mag": 66.64676666259766, "eval/prior_ent_max": 66.64676666259766, "eval/prior_ent_mean": 48.92706298828125, "eval/prior_ent_min": 21.998973846435547, "eval/prior_ent_std": 7.713881969451904, "eval/rep_loss_mean": 12.826189041137695, "eval/rep_loss_std": 9.0581693649292, "eval/reward_avg": 0.01201171800494194, "eval/reward_loss_mean": 0.0581713542342186, "eval/reward_loss_std": 0.3309219181537628, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.011291265487671, "eval/reward_neg_acc": 0.9920555949211121, "eval/reward_neg_loss": 0.03994308039546013, "eval/reward_pos_acc": 0.9411764740943909, "eval/reward_pos_loss": 1.1379286050796509, "eval/reward_pred": 0.012648280709981918, "eval/reward_rate": 0.0166015625, "replay/size": 180257.0, "replay/inserts": 22352.0, "replay/samples": 22352.0, "replay/insert_wait_avg": 1.3426084900721534e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.237558172358388e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 36800.0, "eval_replay/inserts": 5560.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2167066121272904e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4484553337097, "timer/env.step_count": 2794.0, "timer/env.step_total": 243.71816039085388, "timer/env.step_frac": 0.24360891267462573, "timer/env.step_avg": 0.08722911968176589, "timer/env.step_min": 0.022443771362304688, "timer/env.step_max": 4.209484100341797, "timer/replay._sample_count": 22352.0, "timer/replay._sample_total": 12.016823053359985, "timer/replay._sample_frac": 0.012011436460613707, "timer/replay._sample_avg": 0.000537617352065139, "timer/replay._sample_min": 0.0004029273986816406, "timer/replay._sample_max": 0.011330842971801758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3489.0, "timer/agent.policy_total": 53.6864857673645, "timer/agent.policy_frac": 0.05366242056864072, "timer/agent.policy_avg": 0.015387356195862569, "timer/agent.policy_min": 0.008430957794189453, "timer/agent.policy_max": 0.10264730453491211, "timer/dataset_train_count": 1397.0, "timer/dataset_train_total": 0.14889955520629883, "timer/dataset_train_frac": 0.00014883281033867144, "timer/dataset_train_avg": 0.00010658522205175292, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0006668567657470703, "timer/agent.train_count": 1397.0, "timer/agent.train_total": 609.2359323501587, "timer/agent.train_frac": 0.6089628397166568, "timer/agent.train_avg": 0.4361030295992546, "timer/agent.train_min": 0.4236929416656494, "timer/agent.train_max": 1.3669781684875488, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4714851379394531, "timer/agent.report_frac": 0.0004712737926934821, "timer/agent.report_avg": 0.23574256896972656, "timer/agent.report_min": 0.22426557540893555, "timer/agent.report_max": 0.24721956253051758, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.859740483345968e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.341695812829702}
{"step": 180784, "time": 8364.53718829155, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 180992, "time": 8373.068809509277, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 180992, "time": 8373.076367139816, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 181472, "time": 8391.76902103424, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 181544, "time": 8395.401260852814, "episode/length": 157.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 181616, "time": 8399.493307113647, "episode/length": 158.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 182032, "time": 8414.46017742157, "episode/length": 197.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 182080, "time": 8417.423641443253, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 182192, "time": 8422.628887414932, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 182496, "time": 8433.985597372055, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 182704, "time": 8442.30841255188, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 182864, "time": 8448.923749923706, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 183040, "time": 8456.093405246735, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 183432, "time": 8470.050907611847, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 183656, "time": 8478.871860265732, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 183720, "time": 8482.52398633957, "episode/length": 84.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 183944, "time": 8491.26409626007, "episode/length": 154.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 184304, "time": 8504.66215133667, "episode/length": 283.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 184328, "time": 8506.745089769363, "episode/length": 228.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 184424, "time": 8511.284188985825, "episode/length": 359.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 184504, "time": 8515.337607860565, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 184608, "time": 8520.443916797638, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 185360, "time": 8546.199711084366, "episode/length": 204.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 185384, "time": 8548.297440052032, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 185960, "time": 8568.57721233368, "episode/length": 251.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 185960, "time": 8568.585355520248, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 186136, "time": 8577.991386651993, "episode/length": 213.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 186240, "time": 8583.2308447361, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 186344, "time": 8587.83907699585, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 186864, "time": 8606.311711072922, "episode/length": 316.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 187480, "time": 8627.692875862122, "episode/length": 189.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 187656, "time": 8634.88767170906, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 187776, "time": 8640.503894805908, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 187792, "time": 8642.659517288208, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 187816, "time": 8644.744993925095, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 187864, "time": 8647.74038720131, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 187936, "time": 8652.331431865692, "episode/length": 224.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 188456, "time": 8672.667667388916, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 188768, "time": 8684.490090608597, "episode/length": 425.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 189248, "time": 8701.60900259018, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 189320, "time": 8705.191111803055, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 189336, "time": 8707.237004518509, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 189512, "time": 8714.410556077957, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 189568, "time": 8718.005435943604, "episode/length": 138.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 189728, "time": 8724.75619006157, "episode/length": 258.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 8753.729906320572, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 190008, "time": 8755.401481628418, "eval_episode/length": 150.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 190008, "time": 8758.30496096611, "eval_episode/length": 180.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 190008, "time": 8760.920015096664, "eval_episode/length": 208.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 190008, "time": 8763.29618549347, "eval_episode/length": 226.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 190008, "time": 8766.039608478546, "eval_episode/length": 255.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.99609375}
{"step": 190008, "time": 8768.056302785873, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 190008, "time": 8769.712687015533, "eval_episode/length": 271.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9742647058823529}
{"step": 190040, "time": 8770.758206129074, "episode/length": 58.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 190112, "time": 8774.709031820297, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 190672, "time": 8794.268558740616, "episode/length": 177.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 190720, "time": 8797.195326566696, "episode/length": 174.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 190952, "time": 8805.928015708923, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 191320, "time": 8819.327684640884, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9749216300940439, "episode/intrinsic_return": 0.0}
{"step": 191400, "time": 8823.51986026764, "episode/length": 257.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 191440, "time": 8826.513086080551, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 191832, "time": 8840.326600551605, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 191968, "time": 8846.328826904297, "episode/length": 306.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 192080, "time": 8851.53331232071, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 192216, "time": 8857.184142112732, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 192320, "time": 8862.21780204773, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 192368, "time": 8865.133705854416, "episode/length": 49.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 192544, "time": 8872.325508356094, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 192552, "time": 8874.002603054047, "episode/length": 153.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 192800, "time": 8883.737755775452, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 193496, "time": 8907.349557638168, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 193696, "time": 8915.594396829605, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 193816, "time": 8920.667559146881, "episode/length": 301.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 194048, "time": 8929.892831802368, "episode/length": 421.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.990521327014218, "episode/intrinsic_return": 0.0}
{"step": 194176, "time": 8935.478052139282, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 194400, "time": 8944.483992815018, "episode/length": 253.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 194408, "time": 8946.06530213356, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 194720, "time": 8957.795809268951, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 194928, "time": 8965.86370587349, "episode/length": 297.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 194952, "time": 8967.885875463486, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 195152, "time": 8976.100189685822, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 195448, "time": 8986.972513914108, "episode/length": 158.0, "episode/score": 3.099999964237213, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 195952, "time": 9004.92192363739, "episode/length": 192.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 196040, "time": 9009.056916475296, "episode/length": 204.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 196304, "time": 9019.30874633789, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 196608, "time": 9030.76711320877, "episode/length": 209.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 196672, "time": 9036.069877624512, "episode/length": 327.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 196680, "time": 9037.664082288742, "episode/length": 153.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 196680, "time": 9037.672532558441, "episode/length": 215.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 197112, "time": 9054.778250694275, "episode/length": 100.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.0}
{"step": 197176, "time": 9058.333925247192, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 197536, "time": 9071.629154205322, "episode/length": 44.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 197736, "time": 9079.335600614548, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 197976, "time": 9088.725342273712, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 198192, "time": 9097.597828388214, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 198248, "time": 9100.779993057251, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 198392, "time": 9106.957449913025, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 198696, "time": 9118.196261167526, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 198880, "time": 9125.889256954193, "episode/length": 465.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 198944, "time": 9129.433274507523, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 199024, "time": 9133.64898109436, "episode/length": 78.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.0}
{"step": 199128, "time": 9138.401963233948, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 199232, "time": 9143.59528684616, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 199536, "time": 9154.923649072647, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 199768, "time": 9163.575952291489, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 200040, "time": 9173.746969223022, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9195.466021299362, "eval_episode/length": 37.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 200096, "time": 9201.071452140808, "eval_episode/length": 113.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9473684210526315}
{"step": 200096, "time": 9204.108040094376, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 200096, "time": 9206.206053256989, "eval_episode/length": 157.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 200096, "time": 9208.9438560009, "eval_episode/length": 133.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9552238805970149}
{"step": 200096, "time": 9211.167404174805, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 200096, "time": 9216.351155996323, "eval_episode/length": 205.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 200096, "time": 9218.585649490356, "eval_episode/length": 211.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 200360, "time": 9227.090833902359, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 200520, "time": 9233.722233057022, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 200584, "time": 9237.315605401993, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 200600, "time": 9239.455346345901, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 200680, "time": 9243.618776321411, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 201168, "time": 9261.029569625854, "episode/length": 285.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 201440, "time": 9271.493365764618, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 201712, "time": 9281.850138902664, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 201824, "time": 9287.11192536354, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 202016, "time": 9294.915594816208, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 202192, "time": 9302.248124361038, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 202200, "time": 9303.792950630188, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 202216, "time": 9305.833034992218, "episode/length": 62.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 202384, "time": 9313.079874753952, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 202440, "time": 9316.268565654755, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 202672, "time": 9325.354155302048, "episode/length": 58.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 202688, "time": 9327.319905757904, "episode/length": 61.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 203160, "time": 9343.891932964325, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 203184, "time": 9346.42603969574, "episode/length": 217.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 203464, "time": 9356.687602043152, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 203609, "time": 9363.98479104042, "train_stats/sum_log_reward": 4.718644029003078, "train_stats/max_log_achievement_collect_drink": 8.457627118644067, "train_stats/max_log_achievement_collect_sapling": 2.906779661016949, "train_stats/max_log_achievement_collect_wood": 3.1271186440677967, "train_stats/max_log_achievement_defeat_zombie": 0.3813559322033898, "train_stats/max_log_achievement_eat_cow": 0.1694915254237288, "train_stats/max_log_achievement_eat_plant": 0.00847457627118644, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00847457627118644, "train_stats/max_log_achievement_make_wood_sword": 0.00847457627118644, "train_stats/max_log_achievement_place_plant": 2.652542372881356, "train_stats/max_log_achievement_place_table": 1.2627118644067796, "train_stats/max_log_achievement_wake_up": 2.5254237288135593, "train_stats/mean_log_entropy": 0.39044152414899763, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.608412191901408, "train/action_min": 0.0, "train/action_std": 3.4382370962223536, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05048414684412345, "train/actor_opt_grad_steps": 11915.0, "train/actor_opt_loss": -2.610719309516356, "train/adv_mag": 0.7801878607608903, "train/adv_max": 0.7735747573241382, "train/adv_mean": 0.00403971430301668, "train/adv_min": -0.4792472650887261, "train/adv_std": 0.08250675780672423, "train/cont_avg": 0.9944569762323944, "train/cont_loss_mean": 0.0003711429720017174, "train/cont_loss_std": 0.010027588478841365, "train/cont_neg_acc": 0.9912111578692853, "train/cont_neg_loss": 0.028288213552427742, "train/cont_pos_acc": 0.9999170064086645, "train/cont_pos_loss": 0.0002002999800411922, "train/cont_pred": 0.9944313856917368, "train/cont_rate": 0.9944569762323944, "train/dyn_loss_mean": 14.064875810918673, "train/dyn_loss_std": 9.271227850040919, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0465318795660852, "train/extr_critic_critic_opt_grad_steps": 11915.0, "train/extr_critic_critic_opt_loss": 15351.12647172095, "train/extr_critic_mag": 3.982711231204825, "train/extr_critic_max": 3.982711231204825, "train/extr_critic_mean": 0.9222461153084124, "train/extr_critic_min": -0.23105930610441824, "train/extr_critic_std": 1.0008598847288481, "train/extr_return_normed_mag": 1.8046098074442904, "train/extr_return_normed_max": 1.8046098074442904, "train/extr_return_normed_mean": 0.32259214260208774, "train/extr_return_normed_min": -0.19032363782466297, "train/extr_return_normed_std": 0.3426311178736284, "train/extr_return_rate": 0.4782428523184548, "train/extr_return_raw_mag": 5.431303917522162, "train/extr_return_raw_max": 5.431303917522162, "train/extr_return_raw_mean": 0.9344858573356145, "train/extr_return_raw_min": -0.6216116568572084, "train/extr_return_raw_std": 1.0396965288780105, "train/extr_reward_mag": 1.007094060870963, "train/extr_reward_max": 1.007094060870963, "train/extr_reward_mean": 0.017740035928051238, "train/extr_reward_min": -0.4100169858462374, "train/extr_reward_std": 0.12009852946224348, "train/image_loss_mean": 10.50226176288766, "train/image_loss_std": 13.891305863017767, "train/model_loss_mean": 18.99311752722297, "train/model_loss_std": 17.825506237191213, "train/model_opt_grad_norm": 76.84311743185553, "train/model_opt_grad_steps": 11900.718309859154, "train/model_opt_loss": 13199.801840338909, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 691.0211267605633, "train/policy_entropy_mag": 2.44346976951814, "train/policy_entropy_max": 2.44346976951814, "train/policy_entropy_mean": 0.7350030654752758, "train/policy_entropy_min": 0.07937582865567275, "train/policy_entropy_std": 0.6641659186759465, "train/policy_logprob_mag": 7.438377256124792, "train/policy_logprob_max": -0.009455973597269662, "train/policy_logprob_mean": -0.7352706340836807, "train/policy_logprob_min": -7.438377256124792, "train/policy_logprob_std": 1.1655063948161166, "train/policy_randomness_mag": 0.862437602919592, "train/policy_randomness_max": 0.862437602919592, "train/policy_randomness_mean": 0.2594238287756141, "train/policy_randomness_min": 0.028016184168067615, "train/policy_randomness_std": 0.2344214222590688, "train/post_ent_mag": 55.179870471148426, "train/post_ent_max": 55.179870471148426, "train/post_ent_mean": 38.33200677683656, "train/post_ent_min": 20.557466896486954, "train/post_ent_std": 6.188316566843382, "train/prior_ent_mag": 65.9793593715614, "train/prior_ent_max": 65.9793593715614, "train/prior_ent_mean": 52.52330280357683, "train/prior_ent_min": 28.887082126778616, "train/prior_ent_std": 6.590899158531512, "train/rep_loss_mean": 14.064875810918673, "train/rep_loss_std": 9.271227850040919, "train/reward_avg": 0.017755556664705067, "train/reward_loss_mean": 0.051559202254972826, "train/reward_loss_std": 0.2547223003397525, "train/reward_max_data": 1.007746480720144, "train/reward_max_pred": 1.005084944442964, "train/reward_neg_acc": 0.9926715614930005, "train/reward_neg_loss": 0.03124369759256886, "train/reward_pos_acc": 0.955810547294751, "train/reward_pos_loss": 0.9333950587561433, "train/reward_pred": 0.01722989963944739, "train/reward_rate": 0.022660376320422535, "train_stats/max_log_achievement_defeat_skeleton": 0.020202020202020204, "eval_stats/sum_log_reward": 4.9125000312924385, "eval_stats/max_log_achievement_collect_drink": 6.4375, "eval_stats/max_log_achievement_collect_sapling": 2.875, "eval_stats/max_log_achievement_collect_wood": 3.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.182396853342652e-05, "report/cont_loss_std": 0.0015041283331811428, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007214055513031781, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.9198151828022674e-05, "report/cont_pred": 0.9960486888885498, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.90145492553711, "report/dyn_loss_std": 8.863001823425293, "report/image_loss_mean": 9.274773597717285, "report/image_loss_std": 11.209275245666504, "report/model_loss_mean": 17.666332244873047, "report/model_loss_std": 14.953483581542969, "report/post_ent_mag": 56.585018157958984, "report/post_ent_max": 56.585018157958984, "report/post_ent_mean": 39.21357727050781, "report/post_ent_min": 23.54413604736328, "report/post_ent_std": 6.575751781463623, "report/prior_ent_mag": 66.09832000732422, "report/prior_ent_max": 66.09832000732422, "report/prior_ent_mean": 53.4914436340332, "report/prior_ent_min": 29.217876434326172, "report/prior_ent_std": 6.312462329864502, "report/rep_loss_mean": 13.90145492553711, "report/rep_loss_std": 8.863001823425293, "report/reward_avg": 0.02617187425494194, "report/reward_loss_mean": 0.05063643679022789, "report/reward_loss_std": 0.20581750571727753, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0015835762023926, "report/reward_neg_acc": 0.9929506778717041, "report/reward_neg_loss": 0.025569261983036995, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.8535946011543274, "report/reward_pred": 0.0251284409314394, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.153472425765358e-05, "eval/cont_loss_std": 0.0006417114636860788, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003521593753248453, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.059263326576911e-05, "eval/cont_pred": 0.9970411062240601, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 13.20505428314209, "eval/dyn_loss_std": 9.658576011657715, "eval/image_loss_mean": 10.866439819335938, "eval/image_loss_std": 14.049274444580078, "eval/model_loss_mean": 18.861621856689453, "eval/model_loss_std": 18.048233032226562, "eval/post_ent_mag": 53.579776763916016, "eval/post_ent_max": 53.579776763916016, "eval/post_ent_mean": 38.06708526611328, "eval/post_ent_min": 19.248327255249023, "eval/post_ent_std": 6.1984968185424805, "eval/prior_ent_mag": 66.09832000732422, "eval/prior_ent_max": 66.09832000732422, "eval/prior_ent_mean": 48.98214340209961, "eval/prior_ent_min": 24.777368545532227, "eval/prior_ent_std": 7.8738908767700195, "eval/rep_loss_mean": 13.20505428314209, "eval/rep_loss_std": 9.658576011657715, "eval/reward_avg": 0.01777343638241291, "eval/reward_loss_mean": 0.07211706787347794, "eval/reward_loss_std": 0.5377611517906189, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000969409942627, "eval/reward_neg_acc": 0.9980040192604065, "eval/reward_neg_loss": 0.040204647928476334, "eval/reward_pos_acc": 0.8181818723678589, "eval/reward_pos_loss": 1.5255826711654663, "eval/reward_pred": 0.014148174785077572, "eval/reward_rate": 0.021484375, "replay/size": 203105.0, "replay/inserts": 22848.0, "replay/samples": 22848.0, "replay/insert_wait_avg": 1.2978514870341752e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.086697394106568e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40672.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.261734272822861e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0737283229828, "timer/env.step_count": 2856.0, "timer/env.step_total": 255.41546487808228, "timer/env.step_frac": 0.2553966349124947, "timer/env.step_avg": 0.08943118518140136, "timer/env.step_min": 0.022918224334716797, "timer/env.step_max": 3.2906644344329834, "timer/replay._sample_count": 22848.0, "timer/replay._sample_total": 12.15912652015686, "timer/replay._sample_frac": 0.012158230114240099, "timer/replay._sample_avg": 0.0005321746551189102, "timer/replay._sample_min": 0.0003781318664550781, "timer/replay._sample_max": 0.010022640228271484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3340.0, "timer/agent.policy_total": 51.06084990501404, "timer/agent.policy_frac": 0.05105708555171992, "timer/agent.policy_avg": 0.015287679612279653, "timer/agent.policy_min": 0.008245706558227539, "timer/agent.policy_max": 0.12343430519104004, "timer/dataset_train_count": 1428.0, "timer/dataset_train_total": 0.1519029140472412, "timer/dataset_train_frac": 0.00015189171532579526, "timer/dataset_train_avg": 0.00010637458966893642, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0008535385131835938, "timer/agent.train_count": 1428.0, "timer/agent.train_total": 620.9542484283447, "timer/agent.train_frac": 0.6209084698881341, "timer/agent.train_avg": 0.43484191066410693, "timer/agent.train_min": 0.42226552963256836, "timer/agent.train_max": 1.4816598892211914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4828519821166992, "timer/agent.report_frac": 0.0004828163848743338, "timer/agent.report_avg": 0.2414259910583496, "timer/agent.report_min": 0.23395705223083496, "timer/agent.report_max": 0.24889492988586426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075372928321604e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.84598469880135}
{"step": 203760, "time": 9368.875484466553, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 204080, "time": 9380.654635429382, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 204088, "time": 9382.274898052216, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 204408, "time": 9394.174666166306, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 204512, "time": 9399.215111255646, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 204672, "time": 9405.944557666779, "episode/length": 150.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 205024, "time": 9420.168723583221, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 205080, "time": 9423.418322563171, "episode/length": 336.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 205216, "time": 9429.425282239914, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 205384, "time": 9436.117428541183, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 205816, "time": 9451.369261026382, "episode/length": 175.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 205824, "time": 9453.357340812683, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 205992, "time": 9459.979917287827, "episode/length": 238.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 206000, "time": 9461.953525781631, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 206520, "time": 9479.970913887024, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 206688, "time": 9487.21468424797, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 206728, "time": 9489.791275024414, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 206992, "time": 9499.933178424835, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 207160, "time": 9506.540764570236, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 207272, "time": 9511.755764961243, "episode/length": 273.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 207656, "time": 9525.646003961563, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 207656, "time": 9525.65614771843, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 207968, "time": 9539.045100688934, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 208048, "time": 9543.266454935074, "episode/length": 131.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 208280, "time": 9552.047188997269, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 208456, "time": 9559.339532136917, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 209008, "time": 9578.940587997437, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 209016, "time": 9580.549003124237, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 209472, "time": 9596.93672132492, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 209544, "time": 9600.628321647644, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 209688, "time": 9606.937695503235, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 209720, "time": 9609.441199302673, "episode/length": 257.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 209768, "time": 9612.508335590363, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 209872, "time": 9617.53982758522, "episode/length": 397.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 210040, "time": 9624.28733587265, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 9641.79366517067, "eval_episode/length": 40.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9024390243902439}
{"step": 210080, "time": 9648.350423812866, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 210080, "time": 9649.989461421967, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 210080, "time": 9651.788645982742, "eval_episode/length": 171.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 210080, "time": 9653.464051485062, "eval_episode/length": 176.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 210080, "time": 9655.699604034424, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 210080, "time": 9657.697732448578, "eval_episode/length": 206.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 210080, "time": 9659.926741600037, "eval_episode/length": 53.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 210352, "time": 9668.684720516205, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 210592, "time": 9677.812355995178, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 210960, "time": 9691.430476427078, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 211296, "time": 9703.854653596878, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 211328, "time": 9706.442705631256, "episode/length": 204.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 211480, "time": 9712.655400753021, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 211608, "time": 9718.293266773224, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 211872, "time": 9728.65899181366, "episode/length": 189.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 211976, "time": 9733.207573413849, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 212192, "time": 9741.870933532715, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 212624, "time": 9757.374226808548, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 212840, "time": 9765.618779182434, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 213032, "time": 9774.620316267014, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 213208, "time": 9781.977280855179, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 213288, "time": 9786.117535591125, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 213288, "time": 9786.130593061447, "episode/length": 426.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 213528, "time": 9796.965860366821, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 213720, "time": 9804.545412540436, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 213976, "time": 9814.23192358017, "episode/length": 168.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 214080, "time": 9819.373673915863, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 214376, "time": 9830.209911584854, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 214520, "time": 9836.34199500084, "episode/length": 153.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 214760, "time": 9845.728852033615, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 214840, "time": 9849.747940063477, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 214960, "time": 9855.198906183243, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 215040, "time": 9859.354447364807, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 215376, "time": 9871.71800160408, "episode/length": 161.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 215400, "time": 9873.902809619904, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 215864, "time": 9890.410860300064, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 215912, "time": 9893.484919071198, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 216072, "time": 9900.076574325562, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 216184, "time": 9905.46597146988, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 216208, "time": 9907.865282535553, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 216376, "time": 9914.663281679153, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 216536, "time": 9921.378979444504, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 216584, "time": 9924.399944782257, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 217328, "time": 9949.993927240372, "episode/length": 182.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 217568, "time": 9959.20411992073, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 217600, "time": 9961.858595371246, "episode/length": 152.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 217664, "time": 9965.445137500763, "episode/length": 198.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 217760, "time": 9970.056762218475, "episode/length": 152.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 217800, "time": 9972.583756685257, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 217816, "time": 9974.59478020668, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 218160, "time": 9987.24235701561, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 218168, "time": 9988.754320383072, "episode/length": 74.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 218992, "time": 10017.151986837387, "episode/length": 207.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 219008, "time": 10019.195050239563, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 219056, "time": 10022.284767627716, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 219320, "time": 10032.132641077042, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 219328, "time": 10034.107674598694, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 219400, "time": 10037.718133687973, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 219528, "time": 10043.391251325607, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 219832, "time": 10054.83253455162, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10082.378643035889, "eval_episode/length": 147.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 220064, "time": 10084.86869263649, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 220064, "time": 10086.831571102142, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 220064, "time": 10088.676537513733, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 220064, "time": 10090.44235754013, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 220064, "time": 10092.578251838684, "eval_episode/length": 207.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 220064, "time": 10094.27237701416, "eval_episode/length": 212.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 220064, "time": 10096.691071033478, "eval_episode/length": 237.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 220272, "time": 10103.361290693283, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 220464, "time": 10110.961165189743, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 220800, "time": 10123.37755727768, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 220808, "time": 10124.923188447952, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 221144, "time": 10137.390226364136, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 221360, "time": 10147.297576189041, "episode/length": 287.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 221520, "time": 10154.0873067379, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 221568, "time": 10157.62894654274, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 221968, "time": 10172.523847341537, "episode/length": 145.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 222064, "time": 10177.163448095322, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 222152, "time": 10181.29716348648, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 222376, "time": 10190.08589220047, "episode/length": 355.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 222416, "time": 10193.153872966766, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 223032, "time": 10214.385394334793, "episode/length": 188.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 223088, "time": 10217.961571216583, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 223280, "time": 10225.647793531418, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 223280, "time": 10225.655019044876, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 223416, "time": 10233.320789337158, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 223512, "time": 10238.09442281723, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 223736, "time": 10246.831971883774, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 223736, "time": 10246.840458393097, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 224080, "time": 10261.194166183472, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 224560, "time": 10278.06670832634, "episode/length": 159.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 224784, "time": 10286.756591796875, "episode/length": 218.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 224936, "time": 10293.129587173462, "episode/length": 206.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 224992, "time": 10296.677518606186, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 225032, "time": 10299.265646457672, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 225040, "time": 10301.17768573761, "episode/length": 202.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 225712, "time": 10324.309769153595, "episode/length": 327.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847560975609756, "episode/intrinsic_return": 0.0}
{"step": 225880, "time": 10331.177919149399, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 226064, "time": 10338.849935770035, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 226200, "time": 10344.476091384888, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 226416, "time": 10353.204755783081, "episode/length": 171.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 226696, "time": 10363.398204803467, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 226697, "time": 10365.93840956688, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.4502736058728445, "train/action_min": 0.0, "train/action_std": 3.3511516850570153, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05049015078051337, "train/actor_opt_grad_steps": 13350.0, "train/actor_opt_loss": -3.112384001473928, "train/adv_mag": 0.7705216366669227, "train/adv_max": 0.7584726165080893, "train/adv_mean": 0.004329813419789044, "train/adv_min": -0.49827369800929366, "train/adv_std": 0.08206552655018609, "train/cont_avg": 0.9944436961206896, "train/cont_loss_mean": 0.0004398860368994441, "train/cont_loss_std": 0.012155637195622869, "train/cont_neg_acc": 0.9870413521240498, "train/cont_neg_loss": 0.032641293172015015, "train/cont_pos_acc": 0.9999255233797534, "train/cont_pos_loss": 0.00022344968545416247, "train/cont_pred": 0.9944215425129594, "train/cont_rate": 0.9944436961206896, "train/dyn_loss_mean": 14.331616145166857, "train/dyn_loss_std": 9.407833717609273, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0032698211998774, "train/extr_critic_critic_opt_grad_steps": 13350.0, "train/extr_critic_critic_opt_loss": 15554.617463631466, "train/extr_critic_mag": 4.359965182994974, "train/extr_critic_max": 4.359965182994974, "train/extr_critic_mean": 0.9174242414277175, "train/extr_critic_min": -0.2541040198556308, "train/extr_critic_std": 1.02919661382149, "train/extr_return_normed_mag": 1.8687012170923167, "train/extr_return_normed_max": 1.8687012170923167, "train/extr_return_normed_mean": 0.3071499197647489, "train/extr_return_normed_min": -0.19300040679758992, "train/extr_return_normed_std": 0.3394686956857813, "train/extr_return_rate": 0.4587185941893479, "train/extr_return_raw_mag": 5.865339289040401, "train/extr_return_raw_max": 5.865339289040401, "train/extr_return_raw_mean": 0.9311282975920315, "train/extr_return_raw_min": -0.6490958005189895, "train/extr_return_raw_std": 1.0727176041438662, "train/extr_reward_mag": 1.0078973490616372, "train/extr_reward_max": 1.0078973490616372, "train/extr_reward_mean": 0.019931873659892328, "train/extr_reward_min": -0.43621855933090736, "train/extr_reward_std": 0.12828662169390712, "train/image_loss_mean": 10.252600357450287, "train/image_loss_std": 13.777611337859055, "train/model_loss_mean": 18.90546460644952, "train/model_loss_std": 17.76678374060269, "train/model_opt_grad_norm": 78.76093896010826, "train/model_opt_grad_steps": 13334.510344827586, "train/model_opt_loss": 12976.774528556034, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 685.3448275862069, "train/policy_entropy_mag": 2.4947858514456915, "train/policy_entropy_max": 2.4947858514456915, "train/policy_entropy_mean": 0.7185324689437603, "train/policy_entropy_min": 0.07937558822590729, "train/policy_entropy_std": 0.6677248301177189, "train/policy_logprob_mag": 7.438379899386702, "train/policy_logprob_max": -0.00945590219364084, "train/policy_logprob_mean": -0.7189723360127416, "train/policy_logprob_min": -7.438379899386702, "train/policy_logprob_std": 1.1695713750247299, "train/policy_randomness_mag": 0.8805499228937873, "train/policy_randomness_max": 0.8805499228937873, "train/policy_randomness_mean": 0.25361043081201357, "train/policy_randomness_min": 0.02801609937230061, "train/policy_randomness_std": 0.23567756280816834, "train/post_ent_mag": 56.45314488904229, "train/post_ent_max": 56.45314488904229, "train/post_ent_mean": 38.80498707212251, "train/post_ent_min": 20.831997772742962, "train/post_ent_std": 6.4858660796592975, "train/prior_ent_mag": 66.5203598548626, "train/prior_ent_max": 66.5203598548626, "train/prior_ent_mean": 53.260046491951776, "train/prior_ent_min": 30.61488905281856, "train/prior_ent_std": 6.314986498602505, "train/rep_loss_mean": 14.331616145166857, "train/rep_loss_std": 9.407833717609273, "train/reward_avg": 0.018773571957416576, "train/reward_loss_mean": 0.05345475441166039, "train/reward_loss_std": 0.26430825041285877, "train/reward_max_data": 1.0062068980315635, "train/reward_max_pred": 1.0034338893561527, "train/reward_neg_acc": 0.9925623227810038, "train/reward_neg_loss": 0.03226591535554878, "train/reward_pos_acc": 0.9539839555477274, "train/reward_pos_loss": 0.9236411579724015, "train/reward_pred": 0.018262981928499608, "train/reward_rate": 0.023801185344827586, "train_stats/sum_log_reward": 4.927868762954336, "train_stats/max_log_achievement_collect_drink": 9.549180327868852, "train_stats/max_log_achievement_collect_sapling": 3.3442622950819674, "train_stats/max_log_achievement_collect_wood": 3.3934426229508197, "train_stats/max_log_achievement_defeat_skeleton": 0.00819672131147541, "train_stats/max_log_achievement_defeat_zombie": 0.4180327868852459, "train_stats/max_log_achievement_eat_cow": 0.10655737704918032, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.00819672131147541, "train_stats/max_log_achievement_make_wood_sword": 0.01639344262295082, "train_stats/max_log_achievement_place_plant": 2.9344262295081966, "train_stats/max_log_achievement_place_table": 1.319672131147541, "train_stats/max_log_achievement_wake_up": 2.377049180327869, "train_stats/mean_log_entropy": 0.35694326264936416, "eval_stats/sum_log_reward": 4.849999889731407, "eval_stats/max_log_achievement_collect_drink": 7.6875, "eval_stats/max_log_achievement_collect_sapling": 3.8125, "eval_stats/max_log_achievement_collect_wood": 4.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.5625, "eval_stats/max_log_achievement_place_table": 1.75, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0032907493878155947, "report/cont_loss_std": 0.10381761193275452, "report/cont_neg_acc": 0.800000011920929, "report/cont_neg_loss": 0.6681732535362244, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.8323189326329157e-05, "report/cont_pred": 0.9960469007492065, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.100744247436523, "report/dyn_loss_std": 9.931228637695312, "report/image_loss_mean": 9.992737770080566, "report/image_loss_std": 13.922001838684082, "report/model_loss_mean": 17.906713485717773, "report/model_loss_std": 18.146045684814453, "report/post_ent_mag": 56.460853576660156, "report/post_ent_max": 56.460853576660156, "report/post_ent_mean": 39.84501647949219, "report/post_ent_min": 22.69428253173828, "report/post_ent_std": 7.116275310516357, "report/prior_ent_mag": 67.46202850341797, "report/prior_ent_max": 67.46202850341797, "report/prior_ent_mean": 53.5642204284668, "report/prior_ent_min": 33.10183334350586, "report/prior_ent_std": 5.9452056884765625, "report/rep_loss_mean": 13.100744247436523, "report/rep_loss_std": 9.931228637695312, "report/reward_avg": 0.025390625, "report/reward_loss_mean": 0.05023878067731857, "report/reward_loss_std": 0.26878243684768677, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021519660949707, "report/reward_neg_acc": 0.9939637184143066, "report/reward_neg_loss": 0.025828836485743523, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8590216040611267, "report/reward_pred": 0.025013238191604614, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.998192940140143e-05, "eval/cont_loss_std": 0.00023269739176612347, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.1701041229534894e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.9896755222580396e-05, "eval/cont_pred": 0.9960641860961914, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.560705184936523, "eval/dyn_loss_std": 11.318750381469727, "eval/image_loss_mean": 17.331649780273438, "eval/image_loss_std": 23.336223602294922, "eval/model_loss_mean": 27.96525764465332, "eval/model_loss_std": 28.23038673400879, "eval/post_ent_mag": 53.02354431152344, "eval/post_ent_max": 53.02354431152344, "eval/post_ent_mean": 37.63954544067383, "eval/post_ent_min": 21.318695068359375, "eval/post_ent_std": 5.968347549438477, "eval/prior_ent_mag": 67.46202850341797, "eval/prior_ent_max": 67.46202850341797, "eval/prior_ent_mean": 52.80470275878906, "eval/prior_ent_min": 26.348886489868164, "eval/prior_ent_std": 6.6016035079956055, "eval/rep_loss_mean": 17.560705184936523, "eval/rep_loss_std": 11.318750381469727, "eval/reward_avg": 0.02539062313735485, "eval/reward_loss_mean": 0.09715704619884491, "eval/reward_loss_std": 0.5888856053352356, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024127960205078, "eval/reward_neg_acc": 0.9929577112197876, "eval/reward_neg_loss": 0.05065491795539856, "eval/reward_pos_acc": 0.8666667342185974, "eval/reward_pos_loss": 1.6379278898239136, "eval/reward_pred": 0.022422533482313156, "eval/reward_rate": 0.029296875, "replay/size": 226193.0, "replay/inserts": 23088.0, "replay/samples": 23088.0, "replay/insert_wait_avg": 1.332409581787786e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.22279739115524e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44384.0, "eval_replay/inserts": 3712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2364110042308938e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.9424011707306, "timer/env.step_count": 2886.0, "timer/env.step_total": 262.11703848838806, "timer/env.step_frac": 0.26160888907597335, "timer/env.step_avg": 0.09082364465987113, "timer/env.step_min": 0.02261042594909668, "timer/env.step_max": 3.436640501022339, "timer/replay._sample_count": 23088.0, "timer/replay._sample_total": 11.874754905700684, "timer/replay._sample_frac": 0.011851734083541624, "timer/replay._sample_avg": 0.0005143258361789971, "timer/replay._sample_min": 0.0003693103790283203, "timer/replay._sample_max": 0.01096343994140625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3350.0, "timer/agent.policy_total": 49.82480788230896, "timer/agent.policy_frac": 0.04972821573784143, "timer/agent.policy_avg": 0.014873076979793719, "timer/agent.policy_min": 0.008380889892578125, "timer/agent.policy_max": 0.10029006004333496, "timer/dataset_train_count": 1443.0, "timer/dataset_train_total": 0.15179109573364258, "timer/dataset_train_frac": 0.00015149682811734546, "timer/dataset_train_avg": 0.00010519133453474884, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0010676383972167969, "timer/agent.train_count": 1443.0, "timer/agent.train_total": 625.9684851169586, "timer/agent.train_frac": 0.624754960350554, "timer/agent.train_avg": 0.4337965939826463, "timer/agent.train_min": 0.4245295524597168, "timer/agent.train_max": 1.4245524406433105, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48175930976867676, "timer/agent.report_frac": 0.00048082535403807625, "timer/agent.report_avg": 0.24087965488433838, "timer/agent.report_min": 0.23212671279907227, "timer/agent.report_max": 0.2496325969696045, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.4503673992968116e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 23.042930185579344}
{"step": 226712, "time": 10366.037112474442, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 227032, "time": 10378.247773170471, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 227344, "time": 10389.972696304321, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 227360, "time": 10392.037408828735, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 227584, "time": 10400.744668722153, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 227720, "time": 10406.374002695084, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 227864, "time": 10412.578401565552, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 227936, "time": 10416.698872327805, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 228280, "time": 10429.041640996933, "episode/length": 51.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 228336, "time": 10432.619080781937, "episode/length": 162.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 228336, "time": 10432.62945151329, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 228784, "time": 10450.754883527756, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 228960, "time": 10457.85523056984, "episode/length": 84.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 229168, "time": 10466.09433555603, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 229232, "time": 10469.715681552887, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 229448, "time": 10479.248796224594, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 229752, "time": 10490.604763269424, "episode/length": 298.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 229888, "time": 10496.65291428566, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 230040, "time": 10502.837713718414, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9624413145539906, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10519.705530166626, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 230048, "time": 10524.157074213028, "eval_episode/length": 132.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 230048, "time": 10526.1572265625, "eval_episode/length": 146.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 230048, "time": 10528.435108423233, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 230048, "time": 10530.230719566345, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 230048, "time": 10532.458526849747, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 230048, "time": 10534.88100528717, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9625668449197861}
{"step": 230048, "time": 10536.550448179245, "eval_episode/length": 189.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 230224, "time": 10542.214771986008, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 230336, "time": 10547.27490234375, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 230696, "time": 10560.20603609085, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 230976, "time": 10571.057255029678, "episode/length": 217.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 231192, "time": 10579.452777147293, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 231264, "time": 10584.036937713623, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 231360, "time": 10588.660594940186, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 231672, "time": 10599.994292497635, "episode/length": 277.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 231776, "time": 10604.981457948685, "episode/length": 72.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9315068493150684, "episode/intrinsic_return": 0.0}
{"step": 232272, "time": 10622.29966878891, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 232584, "time": 10633.589808940887, "episode/length": 280.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 232800, "time": 10642.255803108215, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 232912, "time": 10647.413066625595, "episode/length": 335.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 233032, "time": 10652.780852794647, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 233224, "time": 10660.631093502045, "episode/length": 232.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 233472, "time": 10670.373475074768, "episode/length": 211.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 233744, "time": 10680.688750743866, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 233864, "time": 10685.890746116638, "episode/length": 132.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 233880, "time": 10687.908513784409, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 234024, "time": 10694.030356884003, "episode/length": 380.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9973753280839895, "episode/intrinsic_return": 0.0}
{"step": 234232, "time": 10702.259699821472, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 234928, "time": 10726.828245401382, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 235144, "time": 10735.086104869843, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 235296, "time": 10741.807361602783, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 235368, "time": 10745.418976068497, "episode/length": 267.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 235416, "time": 10748.637813091278, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 235616, "time": 10756.755673408508, "episode/length": 322.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 235632, "time": 10758.815514087677, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 235680, "time": 10761.831091165543, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 236440, "time": 10787.692349433899, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 236672, "time": 10796.829461574554, "episode/length": 162.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 236720, "time": 10799.814390182495, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 236816, "time": 10804.517023086548, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 236848, "time": 10807.103523254395, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 237216, "time": 10820.360651016235, "episode/length": 285.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 237264, "time": 10823.563605308533, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 237728, "time": 10841.337342739105, "episode/length": 131.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 238008, "time": 10851.730548381805, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 238152, "time": 10857.857845067978, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 238408, "time": 10867.762790203094, "episode/length": 148.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 238512, "time": 10872.820484161377, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 238800, "time": 10883.434517860413, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 238976, "time": 10890.609743356705, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 239024, "time": 10893.830720186234, "episode/length": 423.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 239440, "time": 10908.757735729218, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 239608, "time": 10915.467936515808, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 239624, "time": 10917.464349031448, "episode/length": 151.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 239832, "time": 10925.825904130936, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 239920, "time": 10930.339421510696, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 239920, "time": 10930.349915742874, "episode/length": 399.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 10955.93718791008, "eval_episode/length": 145.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 240032, "time": 10957.665656805038, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 240032, "time": 10959.814059495926, "eval_episode/length": 167.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 240032, "time": 10961.552787780762, "eval_episode/length": 172.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 240032, "time": 10963.93197107315, "eval_episode/length": 41.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 240032, "time": 10965.513258218765, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 240032, "time": 10967.219279766083, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 240032, "time": 10969.37620806694, "eval_episode/length": 213.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 240224, "time": 10975.51402425766, "episode/length": 155.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 240408, "time": 10982.935697078705, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 240952, "time": 11002.078417539597, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 241144, "time": 11010.35610961914, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 241160, "time": 11012.529220342636, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 241232, "time": 11016.637142181396, "episode/length": 202.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 241392, "time": 11023.39475274086, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 241832, "time": 11038.830134153366, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 241872, "time": 11041.830990314484, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 242192, "time": 11053.638847112656, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 242392, "time": 11061.324471712112, "episode/length": 155.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 242448, "time": 11064.851222515106, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 242584, "time": 11070.47720360756, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 242664, "time": 11074.726928949356, "episode/length": 178.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 243088, "time": 11090.102357625961, "episode/length": 266.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 243272, "time": 11097.377175092697, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 243560, "time": 11108.239646911621, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 243736, "time": 11115.505342960358, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 243808, "time": 11119.619445085526, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 243944, "time": 11125.274469614029, "episode/length": 263.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 243952, "time": 11127.221173524857, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 244712, "time": 11153.021664381027, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 244784, "time": 11157.059111595154, "episode/length": 104.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 244872, "time": 11161.227990627289, "episode/length": 222.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 244912, "time": 11164.319283008575, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 245312, "time": 11178.734411001205, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 245352, "time": 11181.347539186478, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 245648, "time": 11192.529388427734, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 246176, "time": 11212.232847929, "episode/length": 438.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 246264, "time": 11216.443745613098, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 246704, "time": 11232.360460996628, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 246896, "time": 11240.137809038162, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 246920, "time": 11242.307801008224, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 247088, "time": 11249.460000514984, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 247248, "time": 11256.144144535065, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 247872, "time": 11277.59682226181, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 248096, "time": 11286.398495912552, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 248232, "time": 11292.104450941086, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 248272, "time": 11295.133353948593, "episode/length": 424.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905882352941177, "episode/intrinsic_return": 0.0}
{"step": 248480, "time": 11303.256223201752, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 248520, "time": 11305.884055137634, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 248696, "time": 11313.279736995697, "episode/length": 221.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 248784, "time": 11317.82046675682, "episode/length": 211.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 249272, "time": 11334.678668260574, "episode/length": 146.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 249616, "time": 11347.61126947403, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 249672, "time": 11350.566493272781, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 249768, "time": 11355.165479660034, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 249808, "time": 11358.083831071854, "episode/length": 165.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 249824, "time": 11360.129091978073, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 249945, "time": 11366.282042503357, "train_stats/sum_log_reward": 4.981355877245887, "train_stats/max_log_achievement_collect_drink": 7.398305084745763, "train_stats/max_log_achievement_collect_sapling": 3.610169491525424, "train_stats/max_log_achievement_collect_wood": 4.711864406779661, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.2711864406779661, "train_stats/max_log_achievement_eat_cow": 0.16101694915254236, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01694915254237288, "train_stats/max_log_achievement_make_wood_sword": 0.01694915254237288, "train_stats/max_log_achievement_place_plant": 3.110169491525424, "train_stats/max_log_achievement_place_table": 1.9745762711864407, "train_stats/max_log_achievement_wake_up": 2.5847457627118646, "train_stats/mean_log_entropy": 0.36209987028170443, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.39454556169181, "train/action_min": 0.0, "train/action_std": 3.340592677017738, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049157769310063326, "train/actor_opt_grad_steps": 14800.0, "train/actor_opt_loss": -9.223025274482266, "train/adv_mag": 0.7563686831244107, "train/adv_max": 0.7438113270134762, "train/adv_mean": 0.0030923038394168293, "train/adv_min": -0.5039524088645804, "train/adv_std": 0.08032509661440192, "train/cont_avg": 0.9946120689655172, "train/cont_loss_mean": 0.00043617430056726867, "train/cont_loss_std": 0.012270963509431097, "train/cont_neg_acc": 0.9884209106708395, "train/cont_neg_loss": 0.03896022086198078, "train/cont_pos_acc": 0.9999390199266631, "train/cont_pos_loss": 0.00021685841385521662, "train/cont_pred": 0.9946052004551066, "train/cont_rate": 0.9946120689655172, "train/dyn_loss_mean": 14.215982858065901, "train/dyn_loss_std": 9.373988375170477, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0268053543978723, "train/extr_critic_critic_opt_grad_steps": 14800.0, "train/extr_critic_critic_opt_loss": 15672.569746767242, "train/extr_critic_mag": 4.602995520624622, "train/extr_critic_max": 4.602995520624622, "train/extr_critic_mean": 0.9297472988737041, "train/extr_critic_min": -0.26146145853502994, "train/extr_critic_std": 1.0862521467537716, "train/extr_return_normed_mag": 1.8665242433547973, "train/extr_return_normed_max": 1.8665242433547973, "train/extr_return_normed_mean": 0.30848145330774374, "train/extr_return_normed_min": -0.17262076961583106, "train/extr_return_normed_std": 0.34487800937274404, "train/extr_return_rate": 0.45354213796812914, "train/extr_return_raw_mag": 6.030149637419602, "train/extr_return_raw_max": 6.030149637419602, "train/extr_return_raw_mean": 0.9398534024583882, "train/extr_return_raw_min": -0.6317239695581897, "train/extr_return_raw_std": 1.1266595552707541, "train/extr_reward_mag": 1.010628864682954, "train/extr_reward_max": 1.010628864682954, "train/extr_reward_mean": 0.021321135354710037, "train/extr_reward_min": -0.42690706417478363, "train/extr_reward_std": 0.13362096825550343, "train/image_loss_mean": 9.459626079427785, "train/image_loss_std": 13.109407618950152, "train/model_loss_mean": 18.04466062085382, "train/model_loss_std": 17.079001064958245, "train/model_opt_grad_norm": 71.1447258653312, "train/model_opt_grad_steps": 14783.289655172413, "train/model_opt_loss": 12445.226121363146, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 693.9655172413793, "train/policy_entropy_mag": 2.543100386652453, "train/policy_entropy_max": 2.543100386652453, "train/policy_entropy_mean": 0.7237460124081578, "train/policy_entropy_min": 0.07937543715896278, "train/policy_entropy_std": 0.7150512892624428, "train/policy_logprob_mag": 7.438380938562854, "train/policy_logprob_max": -0.00945588920650811, "train/policy_logprob_mean": -0.722631614372648, "train/policy_logprob_min": -7.438380938562854, "train/policy_logprob_std": 1.1887258250137855, "train/policy_randomness_mag": 0.8976028351948179, "train/policy_randomness_max": 0.8976028351948179, "train/policy_randomness_mean": 0.25545058014064, "train/policy_randomness_min": 0.028016046023574367, "train/policy_randomness_std": 0.2523817247357862, "train/post_ent_mag": 57.18174593695279, "train/post_ent_max": 57.18174593695279, "train/post_ent_mean": 39.411544641955146, "train/post_ent_min": 20.89977595888335, "train/post_ent_std": 6.796207526634479, "train/prior_ent_mag": 67.16980369830954, "train/prior_ent_max": 67.16980369830954, "train/prior_ent_mean": 53.7650694748451, "train/prior_ent_min": 31.601328317050275, "train/prior_ent_std": 6.011627355115167, "train/rep_loss_mean": 14.215982858065901, "train/rep_loss_std": 9.373988375170477, "train/reward_avg": 0.020289601205751812, "train/reward_loss_mean": 0.055008664495986084, "train/reward_loss_std": 0.27166574854275277, "train/reward_max_data": 1.0124137960631272, "train/reward_max_pred": 1.0054037743601305, "train/reward_neg_acc": 0.9930667309925474, "train/reward_neg_loss": 0.031938110176345395, "train/reward_pos_acc": 0.9518826225708271, "train/reward_pos_loss": 0.9404620762529045, "train/reward_pred": 0.019384094186384104, "train/reward_rate": 0.025276131465517243, "eval_stats/sum_log_reward": 4.724999934434891, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_wood": 3.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_table": 1.5625, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00037660758243873715, "report/cont_loss_std": 0.012010577134788036, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.0647476048907265e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003776534867938608, "report/cont_pred": 0.9967576861381531, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.591594696044922, "report/dyn_loss_std": 9.950833320617676, "report/image_loss_mean": 11.617539405822754, "report/image_loss_std": 13.80040454864502, "report/model_loss_mean": 20.419750213623047, "report/model_loss_std": 18.092571258544922, "report/post_ent_mag": 58.678489685058594, "report/post_ent_max": 58.678489685058594, "report/post_ent_mean": 40.440528869628906, "report/post_ent_min": 22.014179229736328, "report/post_ent_std": 7.6892852783203125, "report/prior_ent_mag": 67.371337890625, "report/prior_ent_max": 67.371337890625, "report/prior_ent_mean": 54.690704345703125, "report/prior_ent_min": 31.54892921447754, "report/prior_ent_std": 6.80481481552124, "report/rep_loss_mean": 14.591594696044922, "report/rep_loss_std": 9.950833320617676, "report/reward_avg": 0.02001953125, "report/reward_loss_mean": 0.04687899723649025, "report/reward_loss_std": 0.18568383157253265, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0476696491241455, "report/reward_neg_acc": 0.9899899959564209, "report/reward_neg_loss": 0.028996754437685013, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.76145339012146, "report/reward_pred": 0.02051529847085476, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.0259111604682403e-06, "eval/cont_loss_std": 1.3248264622234274e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.9118278942187317e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.371360647492111e-07, "eval/cont_pred": 0.9951164722442627, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.586477279663086, "eval/dyn_loss_std": 10.470760345458984, "eval/image_loss_mean": 15.67689323425293, "eval/image_loss_std": 23.103891372680664, "eval/model_loss_mean": 25.76020622253418, "eval/model_loss_std": 27.03384780883789, "eval/post_ent_mag": 62.20030975341797, "eval/post_ent_max": 62.20030975341797, "eval/post_ent_mean": 40.514122009277344, "eval/post_ent_min": 20.745223999023438, "eval/post_ent_std": 7.165491104125977, "eval/prior_ent_mag": 66.98094177246094, "eval/prior_ent_max": 66.98094177246094, "eval/prior_ent_mean": 54.78955078125, "eval/prior_ent_min": 33.88876724243164, "eval/prior_ent_std": 6.013488292694092, "eval/rep_loss_mean": 16.586477279663086, "eval/rep_loss_std": 10.470760345458984, "eval/reward_avg": 0.02392578125, "eval/reward_loss_mean": 0.13142693042755127, "eval/reward_loss_std": 0.8230578303337097, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0034635066986084, "eval/reward_neg_acc": 0.9949697852134705, "eval/reward_neg_loss": 0.05212383717298508, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.759002923965454, "eval/reward_pred": 0.014637208543717861, "eval/reward_rate": 0.029296875, "replay/size": 249441.0, "replay/inserts": 23248.0, "replay/samples": 23248.0, "replay/insert_wait_avg": 1.3261007918051335e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.03924312447156e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47616.0, "eval_replay/inserts": 3232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.157421876888464e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3331334590912, "timer/env.step_count": 2906.0, "timer/env.step_total": 257.4977858066559, "timer/env.step_frac": 0.2574120332456091, "timer/env.step_avg": 0.0886090109451672, "timer/env.step_min": 0.022397994995117188, "timer/env.step_max": 3.3869142532348633, "timer/replay._sample_count": 23248.0, "timer/replay._sample_total": 11.91714882850647, "timer/replay._sample_frac": 0.011913180149594459, "timer/replay._sample_avg": 0.00051260963646363, "timer/replay._sample_min": 0.0003898143768310547, "timer/replay._sample_max": 0.011153221130371094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3310.0, "timer/agent.policy_total": 49.08269762992859, "timer/agent.policy_frac": 0.049066351986366386, "timer/agent.policy_avg": 0.014828609555869664, "timer/agent.policy_min": 0.008150339126586914, "timer/agent.policy_max": 0.08919715881347656, "timer/dataset_train_count": 1453.0, "timer/dataset_train_total": 0.1521754264831543, "timer/dataset_train_frac": 0.00015212474863942666, "timer/dataset_train_avg": 0.00010473188333321011, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0004124641418457031, "timer/agent.train_count": 1453.0, "timer/agent.train_total": 629.9616503715515, "timer/agent.train_frac": 0.6297518589564083, "timer/agent.train_avg": 0.4335592913775303, "timer/agent.train_min": 0.4250640869140625, "timer/agent.train_max": 1.3609998226165771, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47526001930236816, "timer/agent.report_frac": 0.00047510174701396513, "timer/agent.report_avg": 0.23763000965118408, "timer/agent.report_min": 0.23049354553222656, "timer/agent.report_max": 0.2447664737701416, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9315719182555157e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 23.239959645423614}
{"step": 250016, "time": 11389.02834558487, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 250016, "time": 11390.934319019318, "eval_episode/length": 165.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 250016, "time": 11393.419851064682, "eval_episode/length": 187.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 250016, "time": 11396.362717866898, "eval_episode/length": 218.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 250016, "time": 11397.997736215591, "eval_episode/length": 221.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9819819819819819}
{"step": 250016, "time": 11401.911159276962, "eval_episode/length": 254.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 250016, "time": 11405.060626029968, "eval_episode/length": 293.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 250016, "time": 11407.144971132278, "eval_episode/length": 145.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.958904109589041}
{"step": 250240, "time": 11414.290821313858, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 250272, "time": 11416.890306472778, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 250728, "time": 11432.753058195114, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 251288, "time": 11452.322445631027, "episode/length": 201.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 251304, "time": 11454.373589992523, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 251424, "time": 11459.951688289642, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 251472, "time": 11463.063034772873, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 251480, "time": 11464.560816526413, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 251640, "time": 11471.191075325012, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 251752, "time": 11476.260924339294, "episode/length": 33.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 252136, "time": 11490.300427675247, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 252472, "time": 11502.619506835938, "episode/length": 145.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 252696, "time": 11511.24753165245, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 252696, "time": 11511.254989147186, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 252808, "time": 11517.939808130264, "episode/length": 145.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 252840, "time": 11520.47159743309, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 253112, "time": 11530.71147942543, "episode/length": 51.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 253224, "time": 11535.840051174164, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 253512, "time": 11546.508466959, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 254096, "time": 11568.128369092941, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 254176, "time": 11572.181689977646, "episode/length": 491.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 254192, "time": 11574.250024080276, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 254304, "time": 11579.237321138382, "episode/length": 200.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 254544, "time": 11588.656097888947, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 254648, "time": 11593.2024269104, "episode/length": 56.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 254728, "time": 11597.25022649765, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 254800, "time": 11601.342004299164, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 255184, "time": 11615.062199354172, "episode/length": 135.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 255576, "time": 11628.967370986938, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 255792, "time": 11637.601608991623, "episode/length": 201.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 255896, "time": 11642.278553724289, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 255976, "time": 11646.343097686768, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 256088, "time": 11652.237479925156, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 256440, "time": 11665.892660140991, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 257032, "time": 11687.60348033905, "episode/length": 439.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 257176, "time": 11694.512258052826, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 257240, "time": 11698.50886797905, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 257264, "time": 11701.048030138016, "episode/length": 210.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 257504, "time": 11710.43046760559, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 257600, "time": 11715.105323076248, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 257808, "time": 11723.407126665115, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 258344, "time": 11742.141370534897, "episode/length": 137.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 258360, "time": 11744.284934043884, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 258520, "time": 11751.035196065903, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 258800, "time": 11761.787940979004, "episode/length": 202.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 259016, "time": 11770.014981031418, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 259232, "time": 11778.57318019867, "episode/length": 348.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.997134670487106, "episode/intrinsic_return": 0.0}
{"step": 259472, "time": 11787.95546913147, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 259592, "time": 11793.148430347443, "episode/length": 155.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 259736, "time": 11799.244398832321, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 11823.648269891739, "eval_episode/length": 39.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 260000, "time": 11829.122599840164, "eval_episode/length": 136.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 260000, "time": 11831.33830857277, "eval_episode/length": 154.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 260000, "time": 11833.675942659378, "eval_episode/length": 174.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 260000, "time": 11835.559091329575, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 260000, "time": 11838.252632856369, "eval_episode/length": 207.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 260000, "time": 11840.217740297318, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 260000, "time": 11843.492083072662, "eval_episode/length": 257.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9806201550387597}
{"step": 260104, "time": 11846.585840463638, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 260336, "time": 11855.824482440948, "episode/length": 164.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 260408, "time": 11859.393791675568, "episode/length": 324.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 260560, "time": 11866.084770917892, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 260752, "time": 11873.7498254776, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 260920, "time": 11880.470211982727, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 260936, "time": 11882.627536535263, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 261752, "time": 11910.352302312851, "episode/length": 314.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 261960, "time": 11918.789184093475, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 262304, "time": 11932.620173215866, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 262328, "time": 11934.69402885437, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 262680, "time": 11947.558337211609, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 262704, "time": 11950.058809995651, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 262808, "time": 11954.567997932434, "episode/length": 233.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 263368, "time": 11974.184671163559, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 263544, "time": 11981.358904361725, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 263688, "time": 11987.515058040619, "episode/length": 418.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 263808, "time": 11993.072637796402, "episode/length": 230.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 264272, "time": 12009.471277952194, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 264488, "time": 12017.677805662155, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 264648, "time": 12024.296977043152, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 264776, "time": 12029.931514978409, "episode/length": 258.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 264936, "time": 12036.657951593399, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 265200, "time": 12046.868863582611, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 265240, "time": 12049.462368011475, "episode/length": 435.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9977064220183486, "episode/intrinsic_return": 0.0}
{"step": 265728, "time": 12066.870859146118, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 265784, "time": 12070.01542019844, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 265992, "time": 12078.214263677597, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 266208, "time": 12086.724978208542, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 266368, "time": 12093.460643529892, "episode/length": 198.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 266400, "time": 12096.097000360489, "episode/length": 182.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 266400, "time": 12096.102952718735, "episode/length": 50.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 266696, "time": 12108.50042128563, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 266808, "time": 12113.70465040207, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 267480, "time": 12136.672525167465, "episode/length": 134.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 267576, "time": 12141.172774791718, "episode/length": 146.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 267616, "time": 12144.211742639542, "episode/length": 155.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 267720, "time": 12148.926063537598, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 267792, "time": 12153.039009571075, "episode/length": 318.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 267952, "time": 12159.69652557373, "episode/length": 156.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 267984, "time": 12162.213684797287, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 268096, "time": 12167.277809143066, "episode/length": 288.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 268840, "time": 12192.591912031174, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 268880, "time": 12195.605100870132, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 269136, "time": 12205.466792583466, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 269160, "time": 12207.961064338684, "episode/length": 150.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 269464, "time": 12219.856809616089, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 269480, "time": 12221.975180387497, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 269504, "time": 12224.550167798996, "episode/length": 175.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 269568, "time": 12228.129930734634, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 269896, "time": 12239.972628355026, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 270048, "time": 12246.6292989254, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12263.083441019058, "eval_episode/length": 38.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8974358974358975}
{"step": 270088, "time": 12264.888439655304, "eval_episode/length": 43.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 270088, "time": 12270.069167613983, "eval_episode/length": 135.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 270088, "time": 12271.998580217361, "eval_episode/length": 139.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 270088, "time": 12274.15472483635, "eval_episode/length": 155.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 270088, "time": 12276.065066576004, "eval_episode/length": 163.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 270088, "time": 12277.71973991394, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 270088, "time": 12280.022278308868, "eval_episode/length": 184.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 270200, "time": 12283.593371391296, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 270232, "time": 12286.260957241058, "episode/length": 313.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9904458598726115, "episode/intrinsic_return": 0.0}
{"step": 270712, "time": 12304.442085266113, "episode/length": 193.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 270952, "time": 12313.527891874313, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 271296, "time": 12326.23040318489, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 271328, "time": 12328.767771720886, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 271344, "time": 12330.672137498856, "episode/length": 142.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 271576, "time": 12339.641483783722, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 271584, "time": 12341.611087560654, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 272281, "time": 12366.340556383133, "eval_stats/sum_log_reward": 4.39166659116745, "eval_stats/max_log_achievement_collect_drink": 6.25, "eval_stats/max_log_achievement_collect_sapling": 2.4166666666666665, "eval_stats/max_log_achievement_collect_wood": 4.833333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.2916666666666665, "eval_stats/max_log_achievement_place_table": 1.875, "eval_stats/max_log_achievement_wake_up": 1.7083333333333333, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6483389718191965, "train/action_min": 0.0, "train/action_std": 3.508302472318922, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04880987307322877, "train/actor_opt_grad_steps": 16225.0, "train/actor_opt_loss": -8.559616378162588, "train/adv_mag": 0.7198567032814026, "train/adv_max": 0.7102333322167397, "train/adv_mean": 0.00288692779421191, "train/adv_min": -0.4957441398075649, "train/adv_std": 0.07843486052006483, "train/cont_avg": 0.9946916852678571, "train/cont_loss_mean": 0.00027994188385451125, "train/cont_loss_std": 0.008071883186963598, "train/cont_neg_acc": 0.992264740381922, "train/cont_neg_loss": 0.021345894508236336, "train/cont_pos_acc": 0.9999579063483647, "train/cont_pos_loss": 0.00013665427588652586, "train/cont_pred": 0.994691914319992, "train/cont_rate": 0.9946916852678571, "train/dyn_loss_mean": 14.354898296083723, "train/dyn_loss_std": 9.360295227595739, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9773761842932019, "train/extr_critic_critic_opt_grad_steps": 16225.0, "train/extr_critic_critic_opt_loss": 15735.048081752233, "train/extr_critic_mag": 4.688628898348127, "train/extr_critic_max": 4.688628898348127, "train/extr_critic_mean": 0.8772631402526583, "train/extr_critic_min": -0.25333653262683326, "train/extr_critic_std": 1.0813568796430315, "train/extr_return_normed_mag": 1.859178571190153, "train/extr_return_normed_max": 1.859178571190153, "train/extr_return_normed_mean": 0.2942272406603609, "train/extr_return_normed_min": -0.16250730508140154, "train/extr_return_normed_std": 0.3364440710416862, "train/extr_return_rate": 0.43138767172183307, "train/extr_return_raw_mag": 6.098116156033107, "train/extr_return_raw_max": 6.098116156033107, "train/extr_return_raw_mean": 0.8868668441261564, "train/extr_return_raw_min": -0.6333959424069949, "train/extr_return_raw_std": 1.120098967211587, "train/extr_reward_mag": 1.009097957611084, "train/extr_reward_max": 1.009097957611084, "train/extr_reward_mean": 0.02188193826004863, "train/extr_reward_min": -0.44523619753973825, "train/extr_reward_std": 0.1362018900790385, "train/image_loss_mean": 9.19750338622502, "train/image_loss_std": 13.21513945034572, "train/model_loss_mean": 17.86377579144069, "train/model_loss_std": 17.159677260262626, "train/model_opt_grad_norm": 70.06197689601353, "train/model_opt_grad_steps": 16207.078571428572, "train/model_opt_loss": 13133.890171595982, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 741.0714285714286, "train/policy_entropy_mag": 2.5353733045714244, "train/policy_entropy_max": 2.5353733045714244, "train/policy_entropy_mean": 0.7559761762619018, "train/policy_entropy_min": 0.07937537421073232, "train/policy_entropy_std": 0.7324778475931712, "train/policy_logprob_mag": 7.438382135118757, "train/policy_logprob_max": -0.009455875533499887, "train/policy_logprob_mean": -0.7551523715257644, "train/policy_logprob_min": -7.438382135118757, "train/policy_logprob_std": 1.2016451239585877, "train/policy_randomness_mag": 0.8948755145072937, "train/policy_randomness_max": 0.8948755145072937, "train/policy_randomness_mean": 0.2668264115495341, "train/policy_randomness_min": 0.028016023763588496, "train/policy_randomness_std": 0.2585325344332627, "train/post_ent_mag": 57.65153557913644, "train/post_ent_max": 57.65153557913644, "train/post_ent_mean": 39.74984495980399, "train/post_ent_min": 21.13085572378976, "train/post_ent_std": 6.886694724219186, "train/prior_ent_mag": 67.59192036220006, "train/prior_ent_max": 67.59192036220006, "train/prior_ent_mean": 54.21357569013323, "train/prior_ent_min": 32.796297781808036, "train/prior_ent_std": 5.7846873044967655, "train/rep_loss_mean": 14.354898296083723, "train/rep_loss_std": 9.360295227595739, "train/reward_avg": 0.02029087592381984, "train/reward_loss_mean": 0.053053497483155555, "train/reward_loss_std": 0.2641346762222903, "train/reward_max_data": 1.0107142882687705, "train/reward_max_pred": 1.0056216640131814, "train/reward_neg_acc": 0.9929300027234214, "train/reward_neg_loss": 0.030735607179147858, "train/reward_pos_acc": 0.9558782296521323, "train/reward_pos_loss": 0.9236705575670515, "train/reward_pred": 0.01967275669532163, "train/reward_rate": 0.025027901785714287, "train_stats/sum_log_reward": 5.027927887332332, "train_stats/max_log_achievement_collect_drink": 7.468468468468468, "train_stats/max_log_achievement_collect_sapling": 2.855855855855856, "train_stats/max_log_achievement_collect_wood": 4.837837837837838, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3783783783783784, "train_stats/max_log_achievement_eat_cow": 0.12612612612612611, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.009009009009009009, "train_stats/max_log_achievement_make_wood_sword": 0.018018018018018018, "train_stats/max_log_achievement_place_plant": 2.5855855855855854, "train_stats/max_log_achievement_place_table": 2.09009009009009, "train_stats/max_log_achievement_wake_up": 2.3783783783783785, "train_stats/mean_log_entropy": 0.40350220426245853, "train_stats/max_log_achievement_collect_stone": 0.011904761904761904, "eval_stats/max_log_achievement_collect_stone": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.6648351195035502e-05, "report/cont_loss_std": 0.00042219346505589783, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0031651079189032316, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.150558642228134e-06, "report/cont_pred": 0.9941511154174805, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.976701736450195, "report/dyn_loss_std": 8.59368896484375, "report/image_loss_mean": 8.359346389770508, "report/image_loss_std": 10.456480026245117, "report/model_loss_mean": 16.797121047973633, "report/model_loss_std": 14.145110130310059, "report/post_ent_mag": 56.23076248168945, "report/post_ent_max": 56.23076248168945, "report/post_ent_mean": 40.343955993652344, "report/post_ent_min": 21.79368782043457, "report/post_ent_std": 6.9485764503479, "report/prior_ent_mag": 67.67869567871094, "report/prior_ent_max": 67.67869567871094, "report/prior_ent_mean": 54.680030822753906, "report/prior_ent_min": 34.40513610839844, "report/prior_ent_std": 5.48252010345459, "report/rep_loss_mean": 13.976701736450195, "report/rep_loss_std": 8.59368896484375, "report/reward_avg": 0.02812500111758709, "report/reward_loss_mean": 0.051728568971157074, "report/reward_loss_std": 0.19002129137516022, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006282329559326, "report/reward_neg_acc": 0.9909090399742126, "report/reward_neg_loss": 0.028297949582338333, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7339730858802795, "report/reward_pred": 0.028536980971693993, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.784689058898948e-05, "eval/cont_loss_std": 0.0005051228799857199, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.007057107053697109, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.8116372163822234e-07, "eval/cont_pred": 0.9961209297180176, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.496780395507812, "eval/dyn_loss_std": 10.512540817260742, "eval/image_loss_mean": 17.477327346801758, "eval/image_loss_std": 26.5017147064209, "eval/model_loss_mean": 27.42535400390625, "eval/model_loss_std": 30.443286895751953, "eval/post_ent_mag": 58.15625762939453, "eval/post_ent_max": 58.15625762939453, "eval/post_ent_mean": 40.61580276489258, "eval/post_ent_min": 20.485219955444336, "eval/post_ent_std": 7.015028476715088, "eval/prior_ent_mag": 67.67869567871094, "eval/prior_ent_max": 67.67869567871094, "eval/prior_ent_mean": 54.77967071533203, "eval/prior_ent_min": 30.38785171508789, "eval/prior_ent_std": 5.284911632537842, "eval/rep_loss_mean": 16.496780395507812, "eval/rep_loss_std": 10.512540817260742, "eval/reward_avg": 0.01875000074505806, "eval/reward_loss_mean": 0.04993182048201561, "eval/reward_loss_std": 0.3551797568798065, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000159740447998, "eval/reward_neg_acc": 0.9930209517478943, "eval/reward_neg_loss": 0.017238564789295197, "eval/reward_pos_acc": 0.761904776096344, "eval/reward_pos_loss": 1.611424207687378, "eval/reward_pred": 0.013779276981949806, "eval/reward_rate": 0.0205078125, "replay/size": 271777.0, "replay/inserts": 22336.0, "replay/samples": 22336.0, "replay/insert_wait_avg": 1.3209836701609002e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.050256267318069e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 53600.0, "eval_replay/inserts": 5984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2042050693124373e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0455989837646, "timer/env.step_count": 2792.0, "timer/env.step_total": 244.95535683631897, "timer/env.step_frac": 0.24494418763028397, "timer/env.step_avg": 0.08773472666057269, "timer/env.step_min": 0.022856950759887695, "timer/env.step_max": 3.1700940132141113, "timer/replay._sample_count": 22336.0, "timer/replay._sample_total": 11.566951513290405, "timer/replay._sample_frac": 0.011566424096105832, "timer/replay._sample_avg": 0.0005178613678944486, "timer/replay._sample_min": 0.0004012584686279297, "timer/replay._sample_max": 0.014232158660888672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3540.0, "timer/agent.policy_total": 55.11966848373413, "timer/agent.policy_frac": 0.055117155197469125, "timer/agent.policy_avg": 0.015570527820263878, "timer/agent.policy_min": 0.008246421813964844, "timer/agent.policy_max": 0.9832847118377686, "timer/dataset_train_count": 1396.0, "timer/dataset_train_total": 0.1466679573059082, "timer/dataset_train_frac": 0.0001466612697010522, "timer/dataset_train_avg": 0.00010506300666612335, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.000278472900390625, "timer/agent.train_count": 1396.0, "timer/agent.train_total": 604.6383018493652, "timer/agent.train_frac": 0.6046107322144031, "timer/agent.train_avg": 0.43312199272877167, "timer/agent.train_min": 0.4189412593841553, "timer/agent.train_max": 1.3563132286071777, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47057342529296875, "timer/agent.report_frac": 0.00047055196860139206, "timer/agent.report_avg": 0.23528671264648438, "timer/agent.report_min": 0.2236804962158203, "timer/agent.report_max": 0.24689292907714844, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.409230223718723e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 22.33471218352351}
{"step": 272536, "time": 12374.310562133789, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 272592, "time": 12377.910450935364, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 272800, "time": 12386.196419477463, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 272856, "time": 12389.231048345566, "episode/length": 158.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 272936, "time": 12393.385605096817, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 273064, "time": 12399.061180830002, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 273640, "time": 12419.02532196045, "episode/length": 288.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792387543252595, "episode/intrinsic_return": 0.0}
{"step": 273944, "time": 12430.26138305664, "episode/length": 373.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9919786096256684, "episode/intrinsic_return": 0.0}
{"step": 274080, "time": 12436.422428131104, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 274120, "time": 12438.992164373398, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 274120, "time": 12439.000039815903, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 274136, "time": 12442.686794996262, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 274200, "time": 12446.306875228882, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 274296, "time": 12450.93108177185, "episode/length": 153.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 274784, "time": 12468.335225582123, "episode/length": 142.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 275480, "time": 12492.063086509705, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 275560, "time": 12496.185669898987, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 275656, "time": 12500.750730514526, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 275696, "time": 12503.710223913193, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 275968, "time": 12514.064260959625, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 276080, "time": 12519.203523159027, "episode/length": 249.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 276432, "time": 12532.007225513458, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 276440, "time": 12533.598821163177, "episode/length": 311.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 276768, "time": 12545.852152824402, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 276928, "time": 12552.546569824219, "episode/length": 158.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 277096, "time": 12559.234996795654, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 277216, "time": 12564.923638820648, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 277280, "time": 12568.441415786743, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 277328, "time": 12571.538397312164, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 277872, "time": 12590.520963430405, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 277936, "time": 12594.207480192184, "episode/length": 75.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 278032, "time": 12598.86862897873, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 278144, "time": 12604.157215595245, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 278160, "time": 12606.211408138275, "episode/length": 215.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 278624, "time": 12623.868450403214, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 278656, "time": 12626.424937725067, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 278904, "time": 12635.79665350914, "episode/length": 34.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9142857142857143, "episode/intrinsic_return": 0.0}
{"step": 279144, "time": 12644.98101902008, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 279264, "time": 12650.594465255737, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 279592, "time": 12662.593654870987, "episode/length": 296.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 279992, "time": 12677.761064767838, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 12700.594747781754, "eval_episode/length": 143.0, "eval_episode/score": 3.099999964237213, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 280072, "time": 12702.601657629013, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 280072, "time": 12704.773635149002, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 280072, "time": 12706.470796585083, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 280072, "time": 12708.531092882156, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 280072, "time": 12710.426259040833, "eval_episode/length": 192.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 280072, "time": 12712.372030735016, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 280072, "time": 12714.0674700737, "eval_episode/length": 40.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 280392, "time": 12724.460883378983, "episode/length": 155.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 280456, "time": 12727.984338998795, "episode/length": 286.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 280728, "time": 12738.216204881668, "episode/length": 322.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 280872, "time": 12744.373554944992, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 281112, "time": 12753.573300361633, "episode/length": 275.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 281216, "time": 12758.553796291351, "episode/length": 152.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 281360, "time": 12764.60384774208, "episode/length": 78.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 281416, "time": 12767.721274614334, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 281528, "time": 12772.874969005585, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 281760, "time": 12782.235942363739, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 282048, "time": 12793.190306663513, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 283096, "time": 12828.896356582642, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 283208, "time": 12833.99688076973, "episode/length": 230.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 283208, "time": 12834.004591703415, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9558011049723757, "episode/intrinsic_return": 0.0}
{"step": 283688, "time": 12852.6364133358, "episode/length": 411.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 284496, "time": 12880.347507238388, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 284512, "time": 12882.319567203522, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 284840, "time": 12894.139659643173, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 284864, "time": 12896.58666586876, "episode/length": 455.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9978070175438597, "episode/intrinsic_return": 0.0}
{"step": 284912, "time": 12899.594294786453, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 285176, "time": 12909.548377990723, "episode/length": 455.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9978070175438597, "episode/intrinsic_return": 0.0}
{"step": 285256, "time": 12913.577674388885, "episode/length": 400.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9900249376558603, "episode/intrinsic_return": 0.0}
{"step": 285264, "time": 12915.632435321808, "episode/length": 43.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 285648, "time": 12929.553825378418, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 285752, "time": 12934.287090539932, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 286064, "time": 12945.95044541359, "episode/length": 38.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 286088, "time": 12948.048600912094, "episode/length": 152.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 286440, "time": 12960.941752910614, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 286624, "time": 12968.76007771492, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 287064, "time": 12985.704241275787, "episode/length": 421.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 287248, "time": 12993.614803552628, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 287272, "time": 12995.789027929306, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 287352, "time": 12999.920218706131, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 287592, "time": 13009.213008403778, "episode/length": 291.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 287616, "time": 13011.62684583664, "episode/length": 146.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 287656, "time": 13014.31266117096, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 287752, "time": 13018.856177330017, "episode/length": 140.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 288264, "time": 13036.786884784698, "episode/length": 385.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9974093264248705, "episode/intrinsic_return": 0.0}
{"step": 288336, "time": 13040.809228658676, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 288864, "time": 13059.309636354446, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 288944, "time": 13063.38454914093, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 289056, "time": 13068.637528657913, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 289160, "time": 13073.341578006744, "episode/length": 238.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 289192, "time": 13075.91789484024, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 289496, "time": 13087.218821287155, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 289568, "time": 13091.434307813644, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 289816, "time": 13100.795209646225, "episode/length": 30.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13124.52386522293, "eval_episode/length": 48.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 290056, "time": 13130.307903289795, "eval_episode/length": 101.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9509803921568627}
{"step": 290056, "time": 13132.48315668106, "eval_episode/length": 163.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 290056, "time": 13134.090773105621, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 290056, "time": 13135.732694625854, "eval_episode/length": 167.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 290056, "time": 13137.74403142929, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 290056, "time": 13139.377081871033, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 290056, "time": 13145.28939795494, "eval_episode/length": 250.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9760956175298805}
{"step": 290072, "time": 13145.820762395859, "episode/length": 301.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 290440, "time": 13159.604983568192, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 290504, "time": 13163.717972517014, "episode/length": 125.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 290600, "time": 13169.003377914429, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 290664, "time": 13173.33746933937, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 290816, "time": 13180.621329545975, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 291048, "time": 13189.994329929352, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 291544, "time": 13207.5002617836, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 291592, "time": 13210.594673156738, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 291672, "time": 13214.66470503807, "episode/length": 133.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 291792, "time": 13220.22367143631, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 291904, "time": 13225.33826994896, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 291992, "time": 13229.429970502853, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 292016, "time": 13231.992159605026, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 292792, "time": 13258.237342119217, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 293000, "time": 13266.561727046967, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 293128, "time": 13272.145500659943, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 293240, "time": 13277.274208307266, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 293280, "time": 13280.212014436722, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 293352, "time": 13283.839878082275, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 293536, "time": 13291.520178556442, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 293680, "time": 13297.647205352783, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 294008, "time": 13309.564969301224, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 294136, "time": 13315.196143627167, "episode/length": 292.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 294544, "time": 13330.156146526337, "episode/length": 176.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 294720, "time": 13337.563789129257, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 294784, "time": 13341.681162118912, "episode/length": 248.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 294856, "time": 13345.572709321976, "episode/length": 146.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 294896, "time": 13348.647052288055, "episode/length": 201.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 294944, "time": 13352.996507167816, "episode/length": 49.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 295297, "time": 13366.378636837006, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.573428707522946, "train/action_min": 0.0, "train/action_std": 3.4620040630127167, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04816102603828157, "train/actor_opt_grad_steps": 17640.0, "train/actor_opt_loss": -7.35644309587412, "train/adv_mag": 0.705071386132207, "train/adv_max": 0.6938261821136608, "train/adv_mean": 0.003683818423014854, "train/adv_min": -0.4931331370677148, "train/adv_std": 0.07668370823864337, "train/cont_avg": 0.9945162259615384, "train/cont_loss_mean": 0.0003621901803788498, "train/cont_loss_std": 0.0108477395585994, "train/cont_neg_acc": 0.9896270403495202, "train/cont_neg_loss": 0.04546581367867475, "train/cont_pos_acc": 0.9999587656734706, "train/cont_pos_loss": 0.00010473336360387993, "train/cont_pred": 0.9945337080455326, "train/cont_rate": 0.9945162259615384, "train/dyn_loss_mean": 14.342117502972796, "train/dyn_loss_std": 9.363387394618321, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.950981644483713, "train/extr_critic_critic_opt_grad_steps": 17640.0, "train/extr_critic_critic_opt_loss": 15817.74928294362, "train/extr_critic_mag": 4.8099612689518425, "train/extr_critic_max": 4.8099612689518425, "train/extr_critic_mean": 0.9120718313680662, "train/extr_critic_min": -0.28771652375067863, "train/extr_critic_std": 1.1575940597307433, "train/extr_return_normed_mag": 1.8380029801722173, "train/extr_return_normed_max": 1.8380029801722173, "train/extr_return_normed_mean": 0.29600156124655186, "train/extr_return_normed_min": -0.16199825777040494, "train/extr_return_normed_std": 0.34506618455573396, "train/extr_return_rate": 0.42734012976809815, "train/extr_return_raw_mag": 6.280933030001767, "train/extr_return_raw_max": 6.280933030001767, "train/extr_return_raw_mean": 0.9249284221575811, "train/extr_return_raw_min": -0.6661544817310947, "train/extr_return_raw_std": 1.1998491812419225, "train/extr_reward_mag": 1.0125690723632599, "train/extr_reward_max": 1.0125690723632599, "train/extr_reward_mean": 0.024365622641427533, "train/extr_reward_min": -0.4321844444408283, "train/extr_reward_std": 0.1447282813333131, "train/image_loss_mean": 8.686541704031137, "train/image_loss_std": 12.381357072950243, "train/model_loss_mean": 17.34481613452618, "train/model_loss_std": 16.310126764790994, "train/model_opt_grad_norm": 69.8599767484865, "train/model_opt_grad_steps": 17620.664335664336, "train/model_opt_loss": 11525.164994673296, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 664.3356643356643, "train/policy_entropy_mag": 2.553341758834732, "train/policy_entropy_max": 2.553341758834732, "train/policy_entropy_mean": 0.7737986628825848, "train/policy_entropy_min": 0.07937532861332794, "train/policy_entropy_std": 0.763514496646561, "train/policy_logprob_mag": 7.438382315468955, "train/policy_logprob_max": -0.009455856072579647, "train/policy_logprob_mean": -0.7751132387381333, "train/policy_logprob_min": -7.438382315468955, "train/policy_logprob_std": 1.2149575206783267, "train/policy_randomness_mag": 0.901217591929269, "train/policy_randomness_max": 0.901217591929269, "train/policy_randomness_mean": 0.2731169688326496, "train/policy_randomness_min": 0.028016007785405313, "train/policy_randomness_std": 0.2694871093218143, "train/post_ent_mag": 57.73982270780977, "train/post_ent_max": 57.73982270780977, "train/post_ent_mean": 40.09116769003701, "train/post_ent_min": 20.83354893931142, "train/post_ent_std": 7.076132537601711, "train/prior_ent_mag": 67.9509683889109, "train/prior_ent_max": 67.9509683889109, "train/prior_ent_mean": 54.570887532267534, "train/prior_ent_min": 33.61895594563518, "train/prior_ent_std": 5.547285560127738, "train/rep_loss_mean": 14.342117502972796, "train/rep_loss_std": 9.363387394618321, "train/reward_avg": 0.021593640573482335, "train/reward_loss_mean": 0.05264186655933207, "train/reward_loss_std": 0.24864962749131075, "train/reward_max_data": 1.005594406928216, "train/reward_max_pred": 1.0047273319084327, "train/reward_neg_acc": 0.9930868132131083, "train/reward_neg_loss": 0.029810029967733614, "train/reward_pos_acc": 0.9574364215343982, "train/reward_pos_loss": 0.8907931501215155, "train/reward_pred": 0.020755234047431837, "train/reward_rate": 0.0265310861013986, "train_stats/sum_log_reward": 4.930508408632319, "train_stats/max_log_achievement_collect_drink": 7.983050847457627, "train_stats/max_log_achievement_collect_sapling": 2.957627118644068, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.059322033898305, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.3644067796610169, "train_stats/max_log_achievement_eat_cow": 0.1440677966101695, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01694915254237288, "train_stats/max_log_achievement_make_wood_sword": 0.025423728813559324, "train_stats/max_log_achievement_place_plant": 2.788135593220339, "train_stats/max_log_achievement_place_table": 2.152542372881356, "train_stats/max_log_achievement_wake_up": 2.4491525423728815, "train_stats/mean_log_entropy": 0.42612445947982497, "eval_stats/sum_log_reward": 4.287499904632568, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_table": 1.8125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.935878910648171e-06, "report/cont_loss_std": 4.6710483729839325e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001883507939055562, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.208761543442961e-06, "report/cont_pred": 0.9960923194885254, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.520485877990723, "report/dyn_loss_std": 9.805924415588379, "report/image_loss_mean": 11.85018539428711, "report/image_loss_std": 18.514053344726562, "report/model_loss_mean": 21.20122718811035, "report/model_loss_std": 22.38795280456543, "report/post_ent_mag": 59.684661865234375, "report/post_ent_max": 59.684661865234375, "report/post_ent_mean": 39.59162139892578, "report/post_ent_min": 22.762622833251953, "report/post_ent_std": 6.681545257568359, "report/prior_ent_mag": 67.32572937011719, "report/prior_ent_max": 67.32572937011719, "report/prior_ent_mean": 55.001129150390625, "report/prior_ent_min": 34.330753326416016, "report/prior_ent_std": 6.205960273742676, "report/rep_loss_mean": 15.520485877990723, "report/rep_loss_std": 9.805924415588379, "report/reward_avg": 0.011328124441206455, "report/reward_loss_mean": 0.03874661773443222, "report/reward_loss_std": 0.22582541406154633, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9994242191314697, "report/reward_neg_acc": 0.9940535426139832, "report/reward_neg_loss": 0.02433265931904316, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.0083258152008057, "report/reward_pred": 0.01058404240757227, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.7885184888655203e-06, "eval/cont_loss_std": 2.7357766157365404e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002558804990258068, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0419209957035491e-06, "eval/cont_pred": 0.9970700740814209, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.471858978271484, "eval/dyn_loss_std": 11.59847640991211, "eval/image_loss_mean": 16.31926918029785, "eval/image_loss_std": 22.44577407836914, "eval/model_loss_mean": 26.255359649658203, "eval/model_loss_std": 27.806461334228516, "eval/post_ent_mag": 55.61361312866211, "eval/post_ent_max": 55.61361312866211, "eval/post_ent_mean": 39.97632598876953, "eval/post_ent_min": 21.89267349243164, "eval/post_ent_std": 6.331608295440674, "eval/prior_ent_mag": 67.32572937011719, "eval/prior_ent_max": 67.32572937011719, "eval/prior_ent_mean": 53.88493347167969, "eval/prior_ent_min": 28.011672973632812, "eval/prior_ent_std": 6.298341274261475, "eval/rep_loss_mean": 16.471858978271484, "eval/rep_loss_std": 11.59847640991211, "eval/reward_avg": 0.02001953125, "eval/reward_loss_mean": 0.05297292768955231, "eval/reward_loss_std": 0.36469605565071106, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0013537406921387, "eval/reward_neg_acc": 0.9950049519538879, "eval/reward_neg_loss": 0.02633860521018505, "eval/reward_pos_acc": 0.9130434989929199, "eval/reward_pos_loss": 1.2121450901031494, "eval/reward_pred": 0.016341067850589752, "eval/reward_rate": 0.0224609375, "replay/size": 294793.0, "replay/inserts": 23016.0, "replay/samples": 23008.0, "replay/insert_wait_avg": 1.3542602076313335e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.996369303516287e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57288.0, "eval_replay/inserts": 3688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1957777813561827e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0240910053253, "timer/env.step_count": 2877.0, "timer/env.step_total": 258.81459975242615, "timer/env.step_frac": 0.25880836479873154, "timer/env.step_avg": 0.08995988868697467, "timer/env.step_min": 0.022466659545898438, "timer/env.step_max": 3.201185703277588, "timer/replay._sample_count": 23008.0, "timer/replay._sample_total": 11.93294644355774, "timer/replay._sample_frac": 0.011932658973806857, "timer/replay._sample_avg": 0.000518643360724867, "timer/replay._sample_min": 0.0003635883331298828, "timer/replay._sample_max": 0.025248050689697266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3338.0, "timer/agent.policy_total": 51.58139395713806, "timer/agent.policy_frac": 0.05158015133943746, "timer/agent.policy_avg": 0.015452784289136627, "timer/agent.policy_min": 0.008433341979980469, "timer/agent.policy_max": 0.12358236312866211, "timer/dataset_train_count": 1438.0, "timer/dataset_train_total": 0.15534567832946777, "timer/dataset_train_frac": 0.00015534193598606069, "timer/dataset_train_avg": 0.00010802898353926827, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0010914802551269531, "timer/agent.train_count": 1438.0, "timer/agent.train_total": 625.2326226234436, "timer/agent.train_frac": 0.625217560503864, "timer/agent.train_avg": 0.43479320071171323, "timer/agent.train_min": 0.4221835136413574, "timer/agent.train_max": 1.322972059249878, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46914076805114746, "timer/agent.report_frac": 0.00046912946625067776, "timer/agent.report_avg": 0.23457038402557373, "timer/agent.report_min": 0.22360658645629883, "timer/agent.report_max": 0.24553418159484863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00012445449829101562, "timer/dataset_eval_frac": 1.2445150012926326e-07, "timer/dataset_eval_avg": 0.00012445449829101562, "timer/dataset_eval_min": 0.00012445449829101562, "timer/dataset_eval_max": 0.00012445449829101562, "fps": 23.015130372073262}
{"step": 295344, "time": 13368.075071573257, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 295872, "time": 13386.895197868347, "episode/length": 216.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 296064, "time": 13394.614511013031, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 296256, "time": 13402.244141340256, "episode/length": 339.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 296352, "time": 13406.953784942627, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 296448, "time": 13411.75272321701, "episode/length": 198.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 296712, "time": 13421.550979852676, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 296832, "time": 13427.190098285675, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 296968, "time": 13432.881664514542, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 297504, "time": 13452.020340681076, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 297536, "time": 13454.561716794968, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 297904, "time": 13467.943974733353, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 298168, "time": 13477.860945940018, "episode/length": 149.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 298176, "time": 13479.889879703522, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 298232, "time": 13483.013322114944, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 298384, "time": 13489.769058465958, "episode/length": 313.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 298496, "time": 13494.84350991249, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 298792, "time": 13505.732332706451, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 299288, "time": 13523.188952922821, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 299448, "time": 13529.782907009125, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 299560, "time": 13535.04822731018, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 299744, "time": 13542.740271806717, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 299864, "time": 13547.892285108566, "episode/length": 203.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 299864, "time": 13547.89975142479, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 13571.428770542145, "eval_episode/length": 56.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 300040, "time": 13573.737893819809, "eval_episode/length": 76.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.987012987012987}
{"step": 300040, "time": 13578.582292556763, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 300040, "time": 13580.18343758583, "eval_episode/length": 161.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 300040, "time": 13582.11854314804, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 300040, "time": 13584.39119720459, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 300040, "time": 13586.619770765305, "eval_episode/length": 46.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 300040, "time": 13589.148119211197, "eval_episode/length": 233.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 300488, "time": 13603.579125642776, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 300560, "time": 13607.622328519821, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 300728, "time": 13614.300265550613, "episode/length": 292.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 301016, "time": 13625.164157629013, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 301064, "time": 13628.241946697235, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 301176, "time": 13633.36698794365, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 301664, "time": 13650.777345180511, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 301816, "time": 13657.191879272461, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 301944, "time": 13662.941425800323, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 302040, "time": 13667.57718038559, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 302248, "time": 13675.720634698868, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 302440, "time": 13683.494351387024, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 302472, "time": 13686.082520723343, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 302832, "time": 13699.43780207634, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 303672, "time": 13728.98815536499, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 303744, "time": 13732.972280740738, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 303976, "time": 13741.793210029602, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 304224, "time": 13751.451223134995, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 304488, "time": 13761.072250366211, "episode/length": 251.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 304512, "time": 13763.50630569458, "episode/length": 355.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 305032, "time": 13781.514110565186, "episode/length": 401.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 305224, "time": 13789.264751911163, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 305432, "time": 13797.477462291718, "episode/length": 531.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 305448, "time": 13799.604330539703, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 305472, "time": 13802.10107922554, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 305808, "time": 13814.36472272873, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 305944, "time": 13820.100632190704, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 306488, "time": 13839.284439086914, "episode/length": 246.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 306528, "time": 13842.380469322205, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 306712, "time": 13849.624514579773, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 306840, "time": 13855.201318979263, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 307176, "time": 13867.490962982178, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 307680, "time": 13885.360256671906, "episode/length": 233.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 307792, "time": 13890.479233264923, "episode/length": 320.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 308032, "time": 13899.888205766678, "episode/length": 164.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 308104, "time": 13903.541553735733, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 308112, "time": 13905.572297096252, "episode/length": 197.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 308288, "time": 13912.688908100128, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 308480, "time": 13920.354427576065, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 308584, "time": 13925.02594923973, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 308912, "time": 13937.189797878265, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 309032, "time": 13942.39351606369, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 309384, "time": 13955.232458591461, "episode/length": 168.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 309408, "time": 13957.814536809921, "episode/length": 432.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 309464, "time": 13960.826740980148, "episode/length": 53.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 309488, "time": 13963.268380403519, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 309552, "time": 13966.848866939545, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 309744, "time": 13974.58151626587, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14003.553109884262, "eval_episode/length": 139.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 310024, "time": 14005.284570932388, "eval_episode/length": 144.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 310024, "time": 14006.902364969254, "eval_episode/length": 146.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 310024, "time": 14008.42106127739, "eval_episode/length": 149.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 310024, "time": 14010.211755037308, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 310024, "time": 14012.805946350098, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 310024, "time": 14015.530000448227, "eval_episode/length": 212.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 310024, "time": 14017.820409536362, "eval_episode/length": 228.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 310272, "time": 14026.006059408188, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 310296, "time": 14028.14398241043, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 310608, "time": 14039.899803638458, "episode/length": 149.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 310656, "time": 14043.014610052109, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 310744, "time": 14047.090797901154, "episode/length": 159.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 310904, "time": 14053.696943998337, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 311008, "time": 14058.710865020752, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 311176, "time": 14065.484006881714, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 311416, "time": 14076.15102481842, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 311624, "time": 14084.361591100693, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 312072, "time": 14100.257332324982, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 312200, "time": 14106.039853334427, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 312328, "time": 14111.55824971199, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 312448, "time": 14117.2091422081, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 312528, "time": 14121.389537334442, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 312904, "time": 14134.941831827164, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 312952, "time": 14137.977862596512, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 313312, "time": 14151.319202184677, "episode/length": 210.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 313512, "time": 14159.121167898178, "episode/length": 179.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 313616, "time": 14164.230050325394, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 313640, "time": 14166.433501720428, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 313680, "time": 14169.36605143547, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 314232, "time": 14188.357897281647, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 314384, "time": 14194.935423612595, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 314504, "time": 14200.128859519958, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 314976, "time": 14217.15467453003, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 315032, "time": 14220.284056186676, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 315144, "time": 14225.592772245407, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 315168, "time": 14227.967809438705, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 315472, "time": 14239.337664604187, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 315696, "time": 14248.20532155037, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 316064, "time": 14261.767667531967, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 316152, "time": 14265.840537071228, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 316248, "time": 14270.59543466568, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 316544, "time": 14281.990074396133, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 316888, "time": 14294.473877429962, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 316928, "time": 14297.543171167374, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 317336, "time": 14312.06957936287, "episode/length": 135.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 317416, "time": 14316.237661838531, "episode/length": 280.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 318312, "time": 14346.681884765625, "episode/length": 269.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 318424, "time": 14351.905520439148, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 318680, "time": 14362.245308637619, "episode/length": 441.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 318729, "time": 14366.477687358856, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.552777556335034, "train/action_min": 0.0, "train/action_std": 3.377711758321645, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046694187713520866, "train/actor_opt_grad_steps": 19090.0, "train/actor_opt_loss": -1.9596366669450487, "train/adv_mag": 0.6828500733894556, "train/adv_max": 0.6755652312113314, "train/adv_mean": 0.00437976077792344, "train/adv_min": -0.4714188960944714, "train/adv_std": 0.07473094994519032, "train/cont_avg": 0.9947850233843537, "train/cont_loss_mean": 0.00033272055676132704, "train/cont_loss_std": 0.009102781381938456, "train/cont_neg_acc": 0.9905922704813431, "train/cont_neg_loss": 0.031521586892557046, "train/cont_pos_acc": 0.9999532034607972, "train/cont_pos_loss": 0.0001216612368667564, "train/cont_pred": 0.9948064380762528, "train/cont_rate": 0.9947850233843537, "train/dyn_loss_mean": 14.2248068504593, "train/dyn_loss_std": 9.312311756367587, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9279846265202477, "train/extr_critic_critic_opt_grad_steps": 19090.0, "train/extr_critic_critic_opt_loss": 15791.118941326531, "train/extr_critic_mag": 4.975742048146773, "train/extr_critic_max": 4.975742048146773, "train/extr_critic_mean": 0.8994353117585994, "train/extr_critic_min": -0.29381513109012525, "train/extr_critic_std": 1.1651877935240869, "train/extr_return_normed_mag": 1.8391187604592771, "train/extr_return_normed_max": 1.8391187604592771, "train/extr_return_normed_mean": 0.287623875856805, "train/extr_return_normed_min": -0.1392474919050729, "train/extr_return_normed_std": 0.3370604085273483, "train/extr_return_rate": 0.42751605504629564, "train/extr_return_raw_mag": 6.460487125682182, "train/extr_return_raw_max": 6.460487125682182, "train/extr_return_raw_mean": 0.9150895387137017, "train/extr_return_raw_min": -0.6108155222166152, "train/extr_return_raw_std": 1.2048045850935436, "train/extr_reward_mag": 1.0121069846510076, "train/extr_reward_max": 1.0121069846510076, "train/extr_reward_mean": 0.024855228774502976, "train/extr_reward_min": -0.41283740478308023, "train/extr_reward_std": 0.1453496149810804, "train/image_loss_mean": 8.533241534719663, "train/image_loss_std": 12.281932727009261, "train/model_loss_mean": 17.121584347316197, "train/model_loss_std": 16.165734900909218, "train/model_opt_grad_norm": 65.37021688863534, "train/model_opt_grad_steps": 19069.353741496598, "train/model_opt_loss": 10700.990247661564, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 625.0, "train/policy_entropy_mag": 2.5569314664723923, "train/policy_entropy_max": 2.5569314664723923, "train/policy_entropy_mean": 0.782387354341494, "train/policy_entropy_min": 0.07937531730755656, "train/policy_entropy_std": 0.759641791282057, "train/policy_logprob_mag": 7.438382456902744, "train/policy_logprob_max": -0.009455828946463915, "train/policy_logprob_mean": -0.7810804478976191, "train/policy_logprob_min": -7.438382456902744, "train/policy_logprob_std": 1.21711211139653, "train/policy_randomness_mag": 0.9024846018577108, "train/policy_randomness_max": 0.9024846018577108, "train/policy_randomness_mean": 0.276148403177456, "train/policy_randomness_min": 0.028016003761060383, "train/policy_randomness_std": 0.268120213430755, "train/post_ent_mag": 58.8150070865138, "train/post_ent_max": 58.8150070865138, "train/post_ent_mean": 40.48958662902417, "train/post_ent_min": 21.04866410599274, "train/post_ent_std": 7.290445502923459, "train/prior_ent_mag": 68.17168296762064, "train/prior_ent_max": 68.17168296762064, "train/prior_ent_mean": 54.8219516001591, "train/prior_ent_min": 34.30519826720361, "train/prior_ent_std": 5.565078443410445, "train/rep_loss_mean": 14.2248068504593, "train/rep_loss_std": 9.312311756367587, "train/reward_avg": 0.02142857131706614, "train/reward_loss_mean": 0.0531259361198362, "train/reward_loss_std": 0.259580002552798, "train/reward_max_data": 1.0122449008785948, "train/reward_max_pred": 1.005123987489817, "train/reward_neg_acc": 0.992749133888556, "train/reward_neg_loss": 0.029401736343469546, "train/reward_pos_acc": 0.9512657182557243, "train/reward_pos_loss": 0.9366758790145926, "train/reward_pred": 0.020343465911110446, "train/reward_rate": 0.02618781887755102, "train_stats/sum_log_reward": 5.222806962958553, "train_stats/max_log_achievement_collect_drink": 7.37719298245614, "train_stats/max_log_achievement_collect_sapling": 3.0526315789473686, "train_stats/max_log_achievement_collect_stone": 0.09649122807017543, "train_stats/max_log_achievement_collect_wood": 5.447368421052632, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4298245614035088, "train_stats/max_log_achievement_eat_cow": 0.10526315789473684, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07894736842105263, "train_stats/max_log_achievement_make_wood_sword": 0.03508771929824561, "train_stats/max_log_achievement_place_plant": 2.780701754385965, "train_stats/max_log_achievement_place_table": 2.245614035087719, "train_stats/max_log_achievement_wake_up": 2.5526315789473686, "train_stats/mean_log_entropy": 0.4403240459791401, "eval_stats/sum_log_reward": 4.474999910220504, "eval_stats/max_log_achievement_collect_drink": 6.0625, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.034482758620689655, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.0074729036423378e-05, "report/cont_loss_std": 0.0004063440428581089, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003358860034495592, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.98145186106558e-06, "report/cont_pred": 0.9960998296737671, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.118558883666992, "report/dyn_loss_std": 8.844886779785156, "report/image_loss_mean": 5.763309478759766, "report/image_loss_std": 7.968684196472168, "report/model_loss_mean": 13.065034866333008, "report/model_loss_std": 11.91085147857666, "report/post_ent_mag": 59.0966911315918, "report/post_ent_max": 59.0966911315918, "report/post_ent_mean": 41.58582305908203, "report/post_ent_min": 15.438392639160156, "report/post_ent_std": 7.255588054656982, "report/prior_ent_mag": 67.3511962890625, "report/prior_ent_max": 67.3511962890625, "report/prior_ent_mean": 53.81891632080078, "report/prior_ent_min": 32.101993560791016, "report/prior_ent_std": 5.980905532836914, "report/rep_loss_mean": 12.118558883666992, "report/rep_loss_std": 8.844886779785156, "report/reward_avg": 0.00966796837747097, "report/reward_loss_mean": 0.030569709837436676, "report/reward_loss_std": 0.1624506562948227, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022790431976318, "report/reward_neg_acc": 0.9891196489334106, "report/reward_neg_loss": 0.021107982844114304, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.766400933265686, "report/reward_pred": 0.01103468332439661, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 9.056952876562718e-06, "eval/cont_loss_std": 4.310639269533567e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003334256471134722, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.145153176679742e-06, "eval/cont_pred": 0.9941354990005493, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 19.01695442199707, "eval/dyn_loss_std": 10.363247871398926, "eval/image_loss_mean": 24.382858276367188, "eval/image_loss_std": 29.762361526489258, "eval/model_loss_mean": 35.88459777832031, "eval/model_loss_std": 33.89573669433594, "eval/post_ent_mag": 59.283302307128906, "eval/post_ent_max": 59.283302307128906, "eval/post_ent_mean": 39.814849853515625, "eval/post_ent_min": 21.280332565307617, "eval/post_ent_std": 6.5852837562561035, "eval/prior_ent_mag": 67.40451049804688, "eval/prior_ent_max": 67.40451049804688, "eval/prior_ent_mean": 55.271854400634766, "eval/prior_ent_min": 30.158916473388672, "eval/prior_ent_std": 6.06583833694458, "eval/rep_loss_mean": 19.01695442199707, "eval/rep_loss_std": 10.363247871398926, "eval/reward_avg": 0.02138671837747097, "eval/reward_loss_mean": 0.09155742824077606, "eval/reward_loss_std": 0.6545647978782654, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024240016937256, "eval/reward_neg_acc": 0.9909729361534119, "eval/reward_neg_loss": 0.02183045819401741, "eval/reward_pos_acc": 0.7037037014961243, "eval/reward_pos_loss": 2.666290283203125, "eval/reward_pred": 0.011894134804606438, "eval/reward_rate": 0.0263671875, "replay/size": 318225.0, "replay/inserts": 23432.0, "replay/samples": 23440.0, "replay/insert_wait_avg": 1.3194421160624027e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.00624642355857e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 60992.0, "eval_replay/inserts": 3704.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.184046912141804e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0752470493317, "timer/env.step_count": 2929.0, "timer/env.step_total": 250.73463582992554, "timer/env.step_frac": 0.25071577020799646, "timer/env.step_avg": 0.08560417747692917, "timer/env.step_min": 0.022595882415771484, "timer/env.step_max": 3.3150980472564697, "timer/replay._sample_count": 23440.0, "timer/replay._sample_total": 12.119772672653198, "timer/replay._sample_frac": 0.012118860764139436, "timer/replay._sample_avg": 0.0005170551481507337, "timer/replay._sample_min": 0.0003833770751953125, "timer/replay._sample_max": 0.009820699691772461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3392.0, "timer/agent.policy_total": 50.368316650390625, "timer/agent.policy_frac": 0.0503645268683528, "timer/agent.policy_avg": 0.014849149955893462, "timer/agent.policy_min": 0.008171796798706055, "timer/agent.policy_max": 0.09456419944763184, "timer/dataset_train_count": 1465.0, "timer/dataset_train_total": 0.15511417388916016, "timer/dataset_train_frac": 0.0001551025028834742, "timer/dataset_train_avg": 0.00010587998217690114, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0006561279296875, "timer/agent.train_count": 1465.0, "timer/agent.train_total": 635.4135353565216, "timer/agent.train_frac": 0.6353657259603966, "timer/agent.train_avg": 0.4337293756699806, "timer/agent.train_min": 0.4241600036621094, "timer/agent.train_max": 1.3695173263549805, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4819788932800293, "timer/agent.report_frac": 0.00048194262851928606, "timer/agent.report_avg": 0.24098944664001465, "timer/agent.report_min": 0.23300886154174805, "timer/agent.report_max": 0.24897003173828125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0276881299917656e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 23.42971680160801}
{"step": 318736, "time": 14366.503114938736, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 318944, "time": 14375.36215519905, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 319072, "time": 14380.939333438873, "episode/length": 216.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 319344, "time": 14391.285895586014, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 319400, "time": 14394.402791261673, "episode/length": 135.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 319512, "time": 14400.828938484192, "episode/length": 430.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 319552, "time": 14404.08171248436, "episode/length": 140.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 319960, "time": 14418.507824420929, "episode/length": 159.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 14436.79968214035, "eval_episode/length": 50.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9215686274509803}
{"step": 320008, "time": 14439.818928718567, "eval_episode/length": 87.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9431818181818182}
{"step": 320008, "time": 14444.87056684494, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 320008, "time": 14446.353182315826, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 320008, "time": 14448.380200386047, "eval_episode/length": 183.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 320008, "time": 14450.43604850769, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9639175257731959}
{"step": 320008, "time": 14450.445104837418, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9639175257731959}
{"step": 320008, "time": 14454.811034917831, "eval_episode/length": 224.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 320040, "time": 14455.8674325943, "episode/length": 436.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 320616, "time": 14475.888523340225, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 320632, "time": 14477.903124332428, "episode/length": 236.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 320648, "time": 14479.851973056793, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 320664, "time": 14481.89673256874, "episode/length": 138.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 320976, "time": 14494.164604902267, "episode/length": 182.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 320992, "time": 14496.582104682922, "episode/length": 44.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 321032, "time": 14499.749098062515, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 321208, "time": 14506.854529619217, "episode/length": 155.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 321280, "time": 14510.883723974228, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 322016, "time": 14536.029639005661, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 322248, "time": 14544.838600873947, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 322264, "time": 14546.95203447342, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 322328, "time": 14550.469870567322, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 322336, "time": 14552.51825594902, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 322344, "time": 14554.11889743805, "episode/length": 163.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 322712, "time": 14567.411977052689, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 323080, "time": 14580.758016586304, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 323152, "time": 14585.969095230103, "episode/length": 100.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 323176, "time": 14588.065029621124, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 323312, "time": 14594.188393592834, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 323480, "time": 14600.862197875977, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 323640, "time": 14607.573632001877, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 323712, "time": 14611.658930301666, "episode/length": 78.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 323904, "time": 14619.435882091522, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 324456, "time": 14638.473937511444, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 324720, "time": 14648.684783697128, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 324832, "time": 14653.721041440964, "episode/length": 322.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 324968, "time": 14659.299816608429, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 324976, "time": 14661.29098534584, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 325048, "time": 14664.908579587936, "episode/length": 142.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 326040, "time": 14698.444867372513, "episode/length": 197.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 326136, "time": 14703.057214260101, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 326184, "time": 14706.129712104797, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9935275080906149, "episode/intrinsic_return": 0.0}
{"step": 326432, "time": 14715.778834104538, "episode/length": 213.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 326480, "time": 14718.792831659317, "episode/length": 205.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 326544, "time": 14722.390314102173, "episode/length": 362.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9889807162534435, "episode/intrinsic_return": 0.0}
{"step": 327040, "time": 14740.008698701859, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 327064, "time": 14742.12920331955, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 327480, "time": 14757.028433084488, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 327688, "time": 14765.596171855927, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 327936, "time": 14776.761473417282, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 328048, "time": 14781.864082813263, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 328064, "time": 14783.925791978836, "episode/length": 252.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 328368, "time": 14795.361356019974, "episode/length": 272.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 328384, "time": 14797.267075061798, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 328416, "time": 14799.758612632751, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 329256, "time": 14828.234463214874, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 329472, "time": 14836.983703136444, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 329504, "time": 14839.604122877121, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 329600, "time": 14844.26517367363, "episode/length": 238.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 329680, "time": 14848.53285574913, "episode/length": 52.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 329824, "time": 14855.48331952095, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 14880.200637102127, "eval_episode/length": 32.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 330096, "time": 14887.102802753448, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 330096, "time": 14888.710459470749, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 330096, "time": 14891.066591739655, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 330096, "time": 14892.567596673965, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 330096, "time": 14894.356034994125, "eval_episode/length": 190.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9842931937172775}
{"step": 330096, "time": 14896.849734306335, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 330096, "time": 14898.4692466259, "eval_episode/length": 49.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.98}
{"step": 330200, "time": 14901.621631622314, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 330688, "time": 14919.10234117508, "episode/length": 125.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 330848, "time": 14925.793563842773, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 331032, "time": 14932.984816551208, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 331336, "time": 14944.432531118393, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 331504, "time": 14951.582396030426, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 331520, "time": 14953.67758154869, "episode/length": 391.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 331528, "time": 14955.32146692276, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 331976, "time": 14971.104247570038, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 332328, "time": 14983.98208475113, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 332520, "time": 14991.747718334198, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 332616, "time": 14996.405421257019, "episode/length": 135.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.0}
{"step": 332680, "time": 14999.881563425064, "episode/length": 146.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 332792, "time": 15005.1853120327, "episode/length": 181.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 332824, "time": 15007.724579572678, "episode/length": 596.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 333144, "time": 15019.55723452568, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 333464, "time": 15031.502019643784, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 333712, "time": 15041.297153949738, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 333808, "time": 15045.926903009415, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 333944, "time": 15051.7359085083, "episode/length": 201.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 334264, "time": 15063.688353538513, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 334464, "time": 15071.901014089584, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 334608, "time": 15078.157900333405, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 334728, "time": 15083.508810043335, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 335008, "time": 15094.410737991333, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 335016, "time": 15096.039025783539, "episode/length": 277.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 335176, "time": 15102.657384634018, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 335392, "time": 15111.30759525299, "episode/length": 97.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 335568, "time": 15118.435443878174, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 335816, "time": 15127.862752199173, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 336048, "time": 15138.403301000595, "episode/length": 279.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 336264, "time": 15146.801458597183, "episode/length": 135.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 336296, "time": 15149.367223978043, "episode/length": 195.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 336680, "time": 15163.157457351685, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 336832, "time": 15169.751950740814, "episode/length": 157.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 336968, "time": 15175.52514386177, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 337144, "time": 15182.832907438278, "episode/length": 266.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 337584, "time": 15198.838591337204, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 337888, "time": 15210.096398353577, "episode/length": 258.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 337952, "time": 15213.948108434677, "episode/length": 237.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9873949579831933, "episode/intrinsic_return": 0.0}
{"step": 338216, "time": 15223.90184211731, "episode/length": 243.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 338504, "time": 15234.647840738297, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 338544, "time": 15237.616698265076, "episode/length": 232.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 339112, "time": 15257.610513210297, "episode/length": 284.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 339128, "time": 15260.029509782791, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 339176, "time": 15263.095254421234, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 339544, "time": 15276.43034863472, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 339840, "time": 15287.632460594177, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 339840, "time": 15287.638118743896, "episode/length": 36.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 15318.408569335938, "eval_episode/length": 142.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 340080, "time": 15320.351306915283, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 340080, "time": 15322.877799272537, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.994413407821229}
{"step": 340080, "time": 15324.6128180027, "eval_episode/length": 183.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 340080, "time": 15326.2538459301, "eval_episode/length": 186.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 340080, "time": 15328.96007180214, "eval_episode/length": 215.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 340080, "time": 15330.59934258461, "eval_episode/length": 217.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9908256880733946}
{"step": 340080, "time": 15334.790617227554, "eval_episode/length": 131.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 340216, "time": 15338.966559648514, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 340384, "time": 15346.097910404205, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 340432, "time": 15349.1437458992, "episode/length": 432.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 340472, "time": 15351.643773555756, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 340544, "time": 15355.749351978302, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 340793, "time": 15366.626618385315, "train_stats/sum_log_reward": 5.099999948169874, "train_stats/max_log_achievement_collect_coal": 0.008695652173913044, "train_stats/max_log_achievement_collect_drink": 6.921739130434783, "train_stats/max_log_achievement_collect_sapling": 2.8260869565217392, "train_stats/max_log_achievement_collect_stone": 0.02608695652173913, "train_stats/max_log_achievement_collect_wood": 5.460869565217391, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3217391304347826, "train_stats/max_log_achievement_eat_cow": 0.12173913043478261, "train_stats/max_log_achievement_eat_plant": 0.008695652173913044, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06086956521739131, "train_stats/max_log_achievement_make_wood_sword": 0.017391304347826087, "train_stats/max_log_achievement_place_plant": 2.6695652173913045, "train_stats/max_log_achievement_place_table": 2.2695652173913046, "train_stats/max_log_achievement_wake_up": 2.4608695652173913, "train_stats/mean_log_entropy": 0.43419582740120266, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.677903769672781, "train/action_min": 0.0, "train/action_std": 3.5451528628667197, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046497694783560604, "train/actor_opt_grad_steps": 20515.0, "train/actor_opt_loss": -0.859755737774506, "train/adv_mag": 0.6845644595830337, "train/adv_max": 0.6583114745824233, "train/adv_mean": 0.004252063944569681, "train/adv_min": -0.5054119058709213, "train/adv_std": 0.0749695292957451, "train/cont_avg": 0.9947845901268116, "train/cont_loss_mean": 0.0003925283749047271, "train/cont_loss_std": 0.011031379532009916, "train/cont_neg_acc": 0.9905710850936779, "train/cont_neg_loss": 0.0284322777570328, "train/cont_pos_acc": 0.9999359392601511, "train/cont_pos_loss": 0.00023543137932351314, "train/cont_pred": 0.9947662975477136, "train/cont_rate": 0.9947845901268116, "train/dyn_loss_mean": 14.081836645153986, "train/dyn_loss_std": 9.330046605372775, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.962345469257106, "train/extr_critic_critic_opt_grad_steps": 20515.0, "train/extr_critic_critic_opt_loss": 15902.365029155344, "train/extr_critic_mag": 5.11911067755326, "train/extr_critic_max": 5.11911067755326, "train/extr_critic_mean": 0.9360604705154032, "train/extr_critic_min": -0.2881750291672306, "train/extr_critic_std": 1.1832015078136886, "train/extr_return_normed_mag": 1.8342475156853164, "train/extr_return_normed_max": 1.8342475156853164, "train/extr_return_normed_mean": 0.29459969364646554, "train/extr_return_normed_min": -0.1421845369040966, "train/extr_return_normed_std": 0.33983758199906006, "train/extr_return_rate": 0.44121096067238547, "train/extr_return_raw_mag": 6.500313700109288, "train/extr_return_raw_max": 6.500313700109288, "train/extr_return_raw_mean": 0.9513956096725188, "train/extr_return_raw_min": -0.6230055807509284, "train/extr_return_raw_std": 1.2247670862985693, "train/extr_reward_mag": 1.0132304395454517, "train/extr_reward_max": 1.0132304395454517, "train/extr_reward_mean": 0.02593364088755587, "train/extr_reward_min": -0.4223680401193923, "train/extr_reward_std": 0.14967957133616228, "train/image_loss_mean": 8.162783878436986, "train/image_loss_std": 11.975741545359293, "train/model_loss_mean": 16.664360924043518, "train/model_loss_std": 15.877016813858695, "train/model_opt_grad_norm": 63.74451518404311, "train/model_opt_grad_steps": 20493.797101449276, "train/model_opt_loss": 21242.783875396286, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1272.644927536232, "train/policy_entropy_mag": 2.5581491511801016, "train/policy_entropy_max": 2.5581491511801016, "train/policy_entropy_mean": 0.789487620194753, "train/policy_entropy_min": 0.07937528857070467, "train/policy_entropy_std": 0.768582653740178, "train/policy_logprob_mag": 7.43838283635568, "train/policy_logprob_max": -0.009455816982233006, "train/policy_logprob_mean": -0.7890052087065103, "train/policy_logprob_min": -7.43838283635568, "train/policy_logprob_std": 1.2257204755492832, "train/policy_randomness_mag": 0.902914387592371, "train/policy_randomness_max": 0.902914387592371, "train/policy_randomness_mean": 0.2786544879925424, "train/policy_randomness_min": 0.028015993643498074, "train/policy_randomness_std": 0.2712759455476982, "train/post_ent_mag": 58.73268218662428, "train/post_ent_max": 58.73268218662428, "train/post_ent_mean": 40.86272350255994, "train/post_ent_min": 21.30091835795969, "train/post_ent_std": 7.363057350766832, "train/prior_ent_mag": 68.46824745509936, "train/prior_ent_max": 68.46824745509936, "train/prior_ent_mean": 55.01760452381079, "train/prior_ent_min": 35.051984925200976, "train/prior_ent_std": 5.377911436385003, "train/rep_loss_mean": 14.081836645153986, "train/rep_loss_std": 9.330046605372775, "train/reward_avg": 0.02184386312475671, "train/reward_loss_mean": 0.052082515672605106, "train/reward_loss_std": 0.2497724818362706, "train/reward_max_data": 1.0115942056628242, "train/reward_max_pred": 1.0053258676459824, "train/reward_neg_acc": 0.9929976411487745, "train/reward_neg_loss": 0.02964541620399425, "train/reward_pos_acc": 0.9617438692113628, "train/reward_pos_loss": 0.8835741652958635, "train/reward_pred": 0.021197263903888888, "train/reward_rate": 0.026600713315217392, "eval_stats/sum_log_reward": 5.058333287636439, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.958333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.4166666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.083333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4583333333333333, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.08333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 9.17409488465637e-06, "report/cont_loss_std": 4.1720464651007205e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.388082253281027e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.091292668017559e-06, "report/cont_pred": 0.9990144968032837, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 14.288293838500977, "report/dyn_loss_std": 9.366522789001465, "report/image_loss_mean": 8.858192443847656, "report/image_loss_std": 11.90670108795166, "report/model_loss_mean": 17.488502502441406, "report/model_loss_std": 16.175518035888672, "report/post_ent_mag": 59.441280364990234, "report/post_ent_max": 59.441280364990234, "report/post_ent_mean": 40.88744354248047, "report/post_ent_min": 21.92837142944336, "report/post_ent_std": 7.1199631690979, "report/prior_ent_mag": 68.87024688720703, "report/prior_ent_max": 68.87024688720703, "report/prior_ent_mean": 55.388519287109375, "report/prior_ent_min": 38.454689025878906, "report/prior_ent_std": 5.427160739898682, "report/rep_loss_mean": 14.288293838500977, "report/rep_loss_std": 9.366522789001465, "report/reward_avg": 0.01865234225988388, "report/reward_loss_mean": 0.05732513219118118, "report/reward_loss_std": 0.32938647270202637, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0028495788574219, "report/reward_neg_acc": 0.9950099587440491, "report/reward_neg_loss": 0.025101006031036377, "report/reward_pos_acc": 0.7727273106575012, "report/reward_pos_loss": 1.5249876976013184, "report/reward_pred": 0.013549348339438438, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0029994312208145857, "eval/cont_loss_std": 0.09447277337312698, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.7656272053718567, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 8.734409675525967e-06, "eval/cont_pred": 0.9970506429672241, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.759260177612305, "eval/dyn_loss_std": 11.106535911560059, "eval/image_loss_mean": 15.328428268432617, "eval/image_loss_std": 21.624494552612305, "eval/model_loss_mean": 25.49697494506836, "eval/model_loss_std": 26.155691146850586, "eval/post_ent_mag": 56.286720275878906, "eval/post_ent_max": 56.286720275878906, "eval/post_ent_mean": 40.25153350830078, "eval/post_ent_min": 21.50172996520996, "eval/post_ent_std": 6.527402400970459, "eval/prior_ent_mag": 68.87024688720703, "eval/prior_ent_max": 68.87024688720703, "eval/prior_ent_mean": 54.88359451293945, "eval/prior_ent_min": 30.298049926757812, "eval/prior_ent_std": 5.330307483673096, "eval/rep_loss_mean": 16.759260177612305, "eval/rep_loss_std": 11.106535911560059, "eval/reward_avg": 0.03505859524011612, "eval/reward_loss_mean": 0.1099931001663208, "eval/reward_loss_std": 0.7584447860717773, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0158207416534424, "eval/reward_neg_acc": 0.9959431886672974, "eval/reward_neg_loss": 0.024252373725175858, "eval/reward_pos_acc": 0.7894737124443054, "eval/reward_pos_loss": 2.3347394466400146, "eval/reward_pred": 0.02636377513408661, "eval/reward_rate": 0.037109375, "replay/size": 340289.0, "replay/inserts": 22064.0, "replay/samples": 22064.0, "replay/insert_wait_avg": 1.3319844348954498e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.077531555928209e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66704.0, "eval_replay/inserts": 5712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1937207534533588e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1371936798096, "timer/env.step_count": 2758.0, "timer/env.step_total": 251.21955037117004, "timer/env.step_frac": 0.25118508936444683, "timer/env.step_avg": 0.09108758171543511, "timer/env.step_min": 0.022825956344604492, "timer/env.step_max": 3.078861951828003, "timer/replay._sample_count": 22064.0, "timer/replay._sample_total": 11.53736162185669, "timer/replay._sample_frac": 0.011535778985888145, "timer/replay._sample_avg": 0.0005229043519695744, "timer/replay._sample_min": 0.0003581047058105469, "timer/replay._sample_max": 0.015552997589111328, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3472.0, "timer/agent.policy_total": 53.24900937080383, "timer/agent.policy_frac": 0.053241704945383043, "timer/agent.policy_avg": 0.015336696247351334, "timer/agent.policy_min": 0.008317947387695312, "timer/agent.policy_max": 0.13415932655334473, "timer/dataset_train_count": 1379.0, "timer/dataset_train_total": 0.14736580848693848, "timer/dataset_train_frac": 0.0001473455936027484, "timer/dataset_train_avg": 0.00010686425561054277, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0005552768707275391, "timer/agent.train_count": 1379.0, "timer/agent.train_total": 599.7311320304871, "timer/agent.train_frac": 0.5996488639962417, "timer/agent.train_avg": 0.4349029238799761, "timer/agent.train_min": 0.4230189323425293, "timer/agent.train_max": 1.4666860103607178, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47081613540649414, "timer/agent.report_frac": 0.0004707515512688995, "timer/agent.report_avg": 0.23540806770324707, "timer/agent.report_min": 0.22432637214660645, "timer/agent.report_max": 0.2464897632598877, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7652761391689028e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.06069035259636}
{"step": 340984, "time": 15372.4912815094, "episode/length": 225.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 341048, "time": 15376.145897626877, "episode/length": 71.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.0}
{"step": 341224, "time": 15383.461460351944, "episode/length": 84.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 341240, "time": 15385.392308712006, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 341480, "time": 15394.804986476898, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 341920, "time": 15410.766536951065, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 342032, "time": 15415.851364850998, "episode/length": 273.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 342936, "time": 15446.247564315796, "episode/length": 181.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 343008, "time": 15450.249239206314, "episode/length": 220.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 343120, "time": 15455.469441652298, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 343176, "time": 15458.611133813858, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 343600, "time": 15473.922446966171, "episode/length": 296.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 343968, "time": 15487.345279455185, "episode/length": 441.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 344232, "time": 15498.615590810776, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 344272, "time": 15501.556926727295, "episode/length": 279.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 344360, "time": 15505.638684272766, "episode/length": 421.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 344416, "time": 15509.200600147247, "episode/length": 154.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 344448, "time": 15511.782143592834, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 344768, "time": 15523.577817440033, "episode/length": 228.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 344952, "time": 15530.917220115662, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 345504, "time": 15550.546777009964, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 345664, "time": 15557.198726415634, "episode/length": 162.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 345952, "time": 15568.139193058014, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 345984, "time": 15570.628663301468, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 346008, "time": 15572.85998749733, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 346264, "time": 15582.660377025604, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 346464, "time": 15590.726953029633, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 346824, "time": 15603.795158624649, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 347072, "time": 15613.56062078476, "episode/length": 287.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 347184, "time": 15618.720616579056, "episode/length": 146.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 347352, "time": 15625.3568649292, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 347424, "time": 15629.310534238815, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 347448, "time": 15631.447164773941, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 347456, "time": 15633.39845252037, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 347952, "time": 15650.854910373688, "episode/length": 185.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 348488, "time": 15669.228530168533, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 348528, "time": 15672.285269498825, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 348808, "time": 15682.523985862732, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 348888, "time": 15686.637660980225, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 349024, "time": 15692.821221351624, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 349928, "time": 15723.089604139328, "episode/length": 308.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 349968, "time": 15726.076179027557, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 350008, "time": 15728.720329523087, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 15747.023997545242, "eval_episode/length": 50.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 350064, "time": 15752.979934692383, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 350064, "time": 15755.592692613602, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9890710382513661}
{"step": 350064, "time": 15757.589255571365, "eval_episode/length": 192.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 350064, "time": 15759.193287611008, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 350064, "time": 15761.004799365997, "eval_episode/length": 198.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 350064, "time": 15764.421545505524, "eval_episode/length": 243.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 350064, "time": 15766.114870548248, "eval_episode/length": 195.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 350112, "time": 15767.651692390442, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 350368, "time": 15777.387249231339, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 350440, "time": 15780.991105794907, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 351048, "time": 15802.14137840271, "episode/length": 449.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 351104, "time": 15805.683082580566, "episode/length": 393.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9974619289340102, "episode/intrinsic_return": 0.0}
{"step": 351392, "time": 15816.437257766724, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 351472, "time": 15820.500673532486, "episode/length": 192.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 351664, "time": 15828.273621559143, "episode/length": 193.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 351696, "time": 15831.421479701996, "episode/length": 215.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 351816, "time": 15836.557433843613, "episode/length": 180.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 351832, "time": 15838.647611618042, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 351920, "time": 15843.27994799614, "episode/length": 101.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 352696, "time": 15870.583499193192, "episode/length": 205.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 352776, "time": 15874.721078395844, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 352984, "time": 15882.838027000427, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 353176, "time": 15890.855522155762, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 353192, "time": 15892.970781087875, "episode/length": 190.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 353424, "time": 15902.293523311615, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 353904, "time": 15919.147829055786, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 354584, "time": 15942.335151433945, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 354944, "time": 15955.566902637482, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 355120, "time": 15962.781956911087, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 355232, "time": 15967.935097455978, "episode/length": 306.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 355296, "time": 15971.508672952652, "episode/length": 432.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 355400, "time": 15976.001570224762, "episode/length": 434.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954022988505747, "episode/intrinsic_return": 0.0}
{"step": 355520, "time": 15981.426824331284, "episode/length": 292.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9931740614334471, "episode/intrinsic_return": 0.0}
{"step": 356048, "time": 15999.943825483322, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 356408, "time": 16012.934271812439, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 356416, "time": 16015.410089731216, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 356720, "time": 16027.34216594696, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 357192, "time": 16043.784203767776, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 357320, "time": 16049.502375364304, "episode/length": 426.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 357576, "time": 16059.283310174942, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 357736, "time": 16066.012374639511, "episode/length": 291.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 357984, "time": 16075.58799815178, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 358016, "time": 16078.080279111862, "episode/length": 339.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 358072, "time": 16081.234149217606, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 358136, "time": 16084.785771846771, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 358288, "time": 16091.419388532639, "episode/length": 136.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 358584, "time": 16102.35429430008, "episode/length": 36.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 358904, "time": 16114.400295734406, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 359056, "time": 16120.894602298737, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 359504, "time": 16136.831606388092, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 359528, "time": 16138.929270267487, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 359600, "time": 16143.005422115326, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 359616, "time": 16145.12591600418, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 359728, "time": 16150.18123960495, "episode/length": 198.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9899497487437185, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16181.549644470215, "eval_episode/length": 168.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9822485207100592}
{"step": 360048, "time": 16183.61016368866, "eval_episode/length": 179.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 360048, "time": 16185.418607473373, "eval_episode/length": 181.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 360048, "time": 16187.115844011307, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 360048, "time": 16189.54826259613, "eval_episode/length": 202.0, "eval_episode/score": 6.099999949336052, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 360048, "time": 16193.0171585083, "eval_episode/length": 246.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 360048, "time": 16196.252858638763, "eval_episode/length": 287.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 360048, "time": 16198.369187355042, "eval_episode/length": 304.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9967213114754099}
{"step": 360136, "time": 16200.989918708801, "episode/length": 50.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 360264, "time": 16206.757264614105, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 360432, "time": 16213.833532333374, "episode/length": 190.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 360552, "time": 16220.180734872818, "episode/length": 127.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 360832, "time": 16230.899914503098, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 360888, "time": 16234.139862298965, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 360944, "time": 16237.594029188156, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 361424, "time": 16254.498987197876, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 361712, "time": 16265.276184797287, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 361768, "time": 16268.314176797867, "episode/length": 397.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.992462311557789, "episode/intrinsic_return": 0.0}
{"step": 362000, "time": 16277.485361337662, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9558011049723757, "episode/intrinsic_return": 0.0}
{"step": 362080, "time": 16281.670741558075, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 362168, "time": 16285.805046796799, "episode/length": 56.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 362504, "time": 16298.273377418518, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 362552, "time": 16301.371612071991, "episode/length": 207.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 362648, "time": 16305.925610303879, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 363392, "time": 16331.431643009186, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 363432, "time": 16334.028872013092, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 363432, "time": 16334.036373853683, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 363800, "time": 16348.875118255615, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968503937007874, "episode/intrinsic_return": 0.0}
{"step": 364000, "time": 16357.078136205673, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 364008, "time": 16358.775791406631, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 364128, "time": 16364.275151491165, "episode/length": 265.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 364137, "time": 16366.86344218254, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.692037085964255, "train/action_min": 0.0, "train/action_std": 3.4950489785573255, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04607605145708339, "train/actor_opt_grad_steps": 21935.0, "train/actor_opt_loss": -5.467783733717587, "train/adv_mag": 0.6761984167850181, "train/adv_max": 0.6654831554791699, "train/adv_mean": 0.0036722976054154232, "train/adv_min": -0.47843313584588976, "train/adv_std": 0.07369986276001964, "train/cont_avg": 0.9946623501712328, "train/cont_loss_mean": 0.00015442211699905005, "train/cont_loss_std": 0.0041955990771490575, "train/cont_neg_acc": 0.994273212266295, "train/cont_neg_loss": 0.010303310113678816, "train/cont_pos_acc": 0.9999932524276106, "train/cont_pos_loss": 8.47414963829675e-05, "train/cont_pred": 0.9946401743856195, "train/cont_rate": 0.9946623501712328, "train/dyn_loss_mean": 13.975200933952854, "train/dyn_loss_std": 9.287745136104219, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8783332489124717, "train/extr_critic_critic_opt_grad_steps": 21935.0, "train/extr_critic_critic_opt_loss": 15755.726201305652, "train/extr_critic_mag": 5.287430172097193, "train/extr_critic_max": 5.287430172097193, "train/extr_critic_mean": 0.9300551898267171, "train/extr_critic_min": -0.26090214023851366, "train/extr_critic_std": 1.2087428867816925, "train/extr_return_normed_mag": 1.8456463944422055, "train/extr_return_normed_max": 1.8456463944422055, "train/extr_return_normed_mean": 0.2886428563562158, "train/extr_return_normed_min": -0.1355086582878681, "train/extr_return_normed_std": 0.3426985946828372, "train/extr_return_rate": 0.42819369318958833, "train/extr_return_raw_mag": 6.605486363580782, "train/extr_return_raw_max": 6.605486363580782, "train/extr_return_raw_mean": 0.9434081769152863, "train/extr_return_raw_min": -0.5987850205130774, "train/extr_return_raw_std": 1.2464951909568212, "train/extr_reward_mag": 1.0111610448523745, "train/extr_reward_max": 1.0111610448523745, "train/extr_reward_mean": 0.026354537951466563, "train/extr_reward_min": -0.37883103873631724, "train/extr_reward_std": 0.1506212059765646, "train/image_loss_mean": 7.850028390753759, "train/image_loss_std": 11.7413952579237, "train/model_loss_mean": 16.28596584111044, "train/model_loss_std": 15.613215407280073, "train/model_opt_grad_norm": 63.38905585302066, "train/model_opt_grad_steps": 21912.41095890411, "train/model_opt_loss": 14480.553894879067, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 881.8493150684932, "train/policy_entropy_mag": 2.553306902924629, "train/policy_entropy_max": 2.553306902924629, "train/policy_entropy_mean": 0.7636563537055499, "train/policy_entropy_min": 0.07937525029051794, "train/policy_entropy_std": 0.755577707943851, "train/policy_logprob_mag": 7.438383063224897, "train/policy_logprob_max": -0.00945577584207058, "train/policy_logprob_mean": -0.7644003911377633, "train/policy_logprob_min": -7.438383063224897, "train/policy_logprob_std": 1.2150315168785721, "train/policy_randomness_mag": 0.9012052878125073, "train/policy_randomness_max": 0.9012052878125073, "train/policy_randomness_mean": 0.26953718219309636, "train/policy_randomness_min": 0.028015980101509453, "train/policy_randomness_std": 0.2666857723299771, "train/post_ent_mag": 59.01624880751518, "train/post_ent_max": 59.01624880751518, "train/post_ent_mean": 41.15421107043959, "train/post_ent_min": 21.318684813094464, "train/post_ent_std": 7.362123606956168, "train/prior_ent_mag": 68.7182586356385, "train/prior_ent_max": 68.7182586356385, "train/prior_ent_mean": 55.19129721759117, "train/prior_ent_min": 35.87931310314022, "train/prior_ent_std": 5.314831230738392, "train/rep_loss_mean": 13.975200933952854, "train/rep_loss_std": 9.287745136104219, "train/reward_avg": 0.02140611606611781, "train/reward_loss_mean": 0.0506624538221792, "train/reward_loss_std": 0.2360823018706008, "train/reward_max_data": 1.0109589067223954, "train/reward_max_pred": 1.0047025909162548, "train/reward_neg_acc": 0.9932130334311968, "train/reward_neg_loss": 0.029253171367749367, "train/reward_pos_acc": 0.9686530318162213, "train/reward_pos_loss": 0.8478680938890536, "train/reward_pred": 0.02089464325738484, "train/reward_rate": 0.026206656678082193, "train_stats/sum_log_reward": 5.091150403022766, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 8.654867256637168, "train_stats/max_log_achievement_collect_sapling": 3.2831858407079646, "train_stats/max_log_achievement_collect_stone": 0.02654867256637168, "train_stats/max_log_achievement_collect_wood": 6.132743362831858, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4424778761061947, "train_stats/max_log_achievement_eat_cow": 0.08849557522123894, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.04424778761061947, "train_stats/max_log_achievement_make_wood_sword": 0.008849557522123894, "train_stats/max_log_achievement_place_plant": 3.1150442477876106, "train_stats/max_log_achievement_place_table": 2.4867256637168142, "train_stats/max_log_achievement_wake_up": 2.1150442477876106, "train_stats/mean_log_entropy": 0.41352774954475136, "eval_stats/sum_log_reward": 5.537499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 10.3125, "eval_stats/max_log_achievement_collect_sapling": 3.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.875, "eval_stats/max_log_achievement_place_table": 2.5, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.59808153816266e-06, "report/cont_loss_std": 0.00015392203931696713, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001004959223791957, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.704258804442361e-06, "report/cont_pred": 0.9951193332672119, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.511731147766113, "report/dyn_loss_std": 9.371888160705566, "report/image_loss_mean": 6.717167854309082, "report/image_loss_std": 11.110310554504395, "report/model_loss_mean": 14.262962341308594, "report/model_loss_std": 14.9771089553833, "report/post_ent_mag": 64.4599380493164, "report/post_ent_max": 64.4599380493164, "report/post_ent_mean": 43.32530975341797, "report/post_ent_min": 21.361976623535156, "report/post_ent_std": 7.730328559875488, "report/prior_ent_mag": 68.07757568359375, "report/prior_ent_max": 68.07757568359375, "report/prior_ent_mean": 55.94926071166992, "report/prior_ent_min": 38.89307403564453, "report/prior_ent_std": 4.853128433227539, "report/rep_loss_mean": 12.511731147766113, "report/rep_loss_std": 9.371888160705566, "report/reward_avg": 0.01875000074505806, "report/reward_loss_mean": 0.03874758258461952, "report/reward_loss_std": 0.1924215704202652, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0122969150543213, "report/reward_neg_acc": 0.9950000643730164, "report/reward_neg_loss": 0.01745745725929737, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 0.9258362054824829, "report/reward_pred": 0.017064303159713745, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.28945170622319e-05, "eval/cont_loss_std": 0.00040179595816880465, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00014610434300266206, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.256187119404785e-05, "eval/cont_pred": 0.9970383644104004, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.02224349975586, "eval/dyn_loss_std": 10.640678405761719, "eval/image_loss_mean": 12.705480575561523, "eval/image_loss_std": 18.024667739868164, "eval/model_loss_mean": 22.987485885620117, "eval/model_loss_std": 21.938037872314453, "eval/post_ent_mag": 57.79164123535156, "eval/post_ent_max": 57.79164123535156, "eval/post_ent_mean": 41.00578308105469, "eval/post_ent_min": 21.99848175048828, "eval/post_ent_std": 6.894176959991455, "eval/prior_ent_mag": 68.07757568359375, "eval/prior_ent_max": 68.07757568359375, "eval/prior_ent_mean": 55.970367431640625, "eval/prior_ent_min": 35.3099250793457, "eval/prior_ent_std": 5.2171831130981445, "eval/rep_loss_mean": 17.02224349975586, "eval/rep_loss_std": 10.640678405761719, "eval/reward_avg": 0.02558593824505806, "eval/reward_loss_mean": 0.06862770766019821, "eval/reward_loss_std": 0.49739742279052734, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0033049583435059, "eval/reward_neg_acc": 0.991959810256958, "eval/reward_neg_loss": 0.025028778240084648, "eval/reward_pos_acc": 0.8620689511299133, "eval/reward_pos_loss": 1.5645219087600708, "eval/reward_pred": 0.023294085636734962, "eval/reward_rate": 0.0283203125, "replay/size": 363633.0, "replay/inserts": 23344.0, "replay/samples": 23344.0, "replay/insert_wait_avg": 1.306706213477215e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.093097424000563e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 71120.0, "eval_replay/inserts": 4416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.192848751510399e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2003486156464, "timer/env.step_count": 2918.0, "timer/env.step_total": 250.20015811920166, "timer/env.step_frac": 0.25015004090480253, "timer/env.step_avg": 0.08574371422865033, "timer/env.step_min": 0.022645235061645508, "timer/env.step_max": 3.1755211353302, "timer/replay._sample_count": 23344.0, "timer/replay._sample_total": 12.149538278579712, "timer/replay._sample_frac": 0.012147104622984385, "timer/replay._sample_avg": 0.0005204565746478629, "timer/replay._sample_min": 0.0003757476806640625, "timer/replay._sample_max": 0.010802268981933594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3470.0, "timer/agent.policy_total": 51.90306830406189, "timer/agent.policy_frac": 0.05189267167912878, "timer/agent.policy_avg": 0.01495765657177576, "timer/agent.policy_min": 0.008380413055419922, "timer/agent.policy_max": 0.0916740894317627, "timer/dataset_train_count": 1459.0, "timer/dataset_train_total": 0.152618408203125, "timer/dataset_train_frac": 0.0001525878374411292, "timer/dataset_train_avg": 0.00010460480342914667, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0008885860443115234, "timer/agent.train_count": 1459.0, "timer/agent.train_total": 630.4970586299896, "timer/agent.train_frac": 0.630370764719934, "timer/agent.train_avg": 0.43214328898559945, "timer/agent.train_min": 0.42229795455932617, "timer/agent.train_max": 1.3520710468292236, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48232007026672363, "timer/agent.report_frac": 0.0004822234574645884, "timer/agent.report_avg": 0.24116003513336182, "timer/agent.report_min": 0.23236942291259766, "timer/agent.report_max": 0.24995064735412598, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6697532045788452e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 23.338668847270043}
{"step": 364576, "time": 16380.859667539597, "episode/length": 142.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 365096, "time": 16398.929770231247, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 365512, "time": 16414.0557076931, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 365664, "time": 16420.764332532883, "episode/length": 135.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 365728, "time": 16424.4343521595, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9721254355400697, "episode/intrinsic_return": 0.0}
{"step": 365824, "time": 16429.010461091995, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 365864, "time": 16431.647348165512, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 366640, "time": 16458.30895256996, "episode/length": 329.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 366736, "time": 16462.832931041718, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 366848, "time": 16468.040936231613, "episode/length": 542.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996316758747698, "episode/intrinsic_return": 0.0}
{"step": 366968, "time": 16473.283502578735, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 367048, "time": 16477.3756005764, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 367424, "time": 16491.855261325836, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 367568, "time": 16498.08868074417, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 367640, "time": 16501.803787708282, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 367840, "time": 16509.873610973358, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 368304, "time": 16526.31230378151, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 368384, "time": 16530.39084005356, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 368560, "time": 16537.574007987976, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 368856, "time": 16549.62698674202, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 369048, "time": 16557.26542186737, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 369096, "time": 16560.249750852585, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 369168, "time": 16564.35356926918, "episode/length": 264.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 369472, "time": 16575.632714271545, "episode/length": 237.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 369576, "time": 16580.41471028328, "episode/length": 50.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 369584, "time": 16582.4935567379, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 369648, "time": 16586.07566332817, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 369768, "time": 16591.293905973434, "episode/length": 172.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 16620.97902727127, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96045197740113}
{"step": 370032, "time": 16623.488578557968, "eval_episode/length": 183.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 370032, "time": 16627.099235773087, "eval_episode/length": 217.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 370032, "time": 16629.41432285309, "eval_episode/length": 234.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9829787234042553}
{"step": 370032, "time": 16632.63962984085, "eval_episode/length": 47.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8958333333333334}
{"step": 370032, "time": 16638.269463062286, "eval_episode/length": 329.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.990909090909091}
{"step": 370032, "time": 16640.327770233154, "eval_episode/length": 343.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9854651162790697}
{"step": 370032, "time": 16642.627323389053, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 370288, "time": 16650.796262979507, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 370368, "time": 16655.030997753143, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 370488, "time": 16660.034293174744, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 370760, "time": 16670.23165488243, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 370928, "time": 16677.354552030563, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 370976, "time": 16680.487243413925, "episode/length": 165.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 371160, "time": 16688.30704975128, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 371288, "time": 16693.941754102707, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 371720, "time": 16709.399087190628, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 372088, "time": 16722.820179224014, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 372376, "time": 16733.653235435486, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 372496, "time": 16739.186888217926, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 372536, "time": 16741.84118294716, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 372624, "time": 16746.502557992935, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 373352, "time": 16771.805477380753, "episode/length": 203.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 373392, "time": 16775.29878616333, "episode/length": 387.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 373760, "time": 16789.557131052017, "episode/length": 45.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 373792, "time": 16792.590947389603, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 373904, "time": 16798.21564936638, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 373912, "time": 16800.198147058487, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 373976, "time": 16804.44452738762, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 374248, "time": 16815.49531531334, "episode/length": 385.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 374352, "time": 16821.128214597702, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 374800, "time": 16837.99679660797, "episode/length": 110.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9459459459459459, "episode/intrinsic_return": 0.0}
{"step": 375176, "time": 16852.02246236801, "episode/length": 158.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 375368, "time": 16859.781002759933, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 375368, "time": 16859.788425207138, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 375464, "time": 16865.985728740692, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 375464, "time": 16865.993827819824, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 375944, "time": 16884.588777542114, "episode/length": 142.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 376000, "time": 16888.120604991913, "episode/length": 78.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 376224, "time": 16896.876557826996, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 376368, "time": 16903.66382098198, "episode/length": 148.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 376616, "time": 16913.424795150757, "episode/length": 155.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 377368, "time": 16940.295611143112, "episode/length": 501.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9820717131474104, "episode/intrinsic_return": 0.0}
{"step": 377432, "time": 16943.98882293701, "episode/length": 245.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 377480, "time": 16947.130820035934, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 377568, "time": 16951.829516887665, "episode/length": 195.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 377688, "time": 16957.077341794968, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 378368, "time": 16980.67453455925, "episode/length": 218.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 378696, "time": 16993.06359767914, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 379008, "time": 17004.841875076294, "episode/length": 442.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 379016, "time": 17006.46480035782, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 379104, "time": 17011.19456934929, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 379144, "time": 17013.932574510574, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 379416, "time": 17024.222600460052, "episode/length": 433.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 379608, "time": 17031.99069595337, "episode/length": 154.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 380008, "time": 17046.40976381302, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17065.117473363876, "eval_episode/length": 102.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.941747572815534}
{"step": 380016, "time": 17069.048604249954, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 380016, "time": 17071.763811826706, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 380016, "time": 17073.312887191772, "eval_episode/length": 184.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 380016, "time": 17074.913888692856, "eval_episode/length": 187.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9680851063829787}
{"step": 380016, "time": 17076.477880716324, "eval_episode/length": 188.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 380016, "time": 17078.286961078644, "eval_episode/length": 194.0, "eval_episode/score": 5.1000000461936, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 380016, "time": 17081.424403190613, "eval_episode/length": 233.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 380240, "time": 17088.650986909866, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 380560, "time": 17100.424920082092, "episode/length": 192.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 380720, "time": 17107.31923723221, "episode/length": 418.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 380744, "time": 17109.32502913475, "episode/length": 199.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 380992, "time": 17119.032915353775, "episode/length": 196.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 381040, "time": 17122.068908452988, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 381224, "time": 17129.137629508972, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 381328, "time": 17134.330758571625, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 381968, "time": 17156.494301319122, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 382224, "time": 17166.230984687805, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 382408, "time": 17173.38230252266, "episode/length": 230.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 382720, "time": 17185.348168373108, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 383616, "time": 17215.796418190002, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 383688, "time": 17219.46144604683, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 383848, "time": 17226.163901805878, "episode/length": 314.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 383880, "time": 17228.797882556915, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 384040, "time": 17235.384272813797, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 384128, "time": 17240.02687883377, "episode/length": 63.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 384184, "time": 17243.246290445328, "episode/length": 432.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 384320, "time": 17249.367931365967, "episode/length": 54.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 384512, "time": 17257.27470779419, "episode/length": 317.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 384624, "time": 17262.540452718735, "episode/length": 424.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 384704, "time": 17266.682172060013, "episode/length": 64.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 385368, "time": 17291.62528538704, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 385512, "time": 17297.829270362854, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 385672, "time": 17304.475677490234, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 385760, "time": 17309.027208566666, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 385952, "time": 17316.79954123497, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 386424, "time": 17333.242571353912, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 386512, "time": 17337.722143650055, "episode/length": 249.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 386624, "time": 17343.018763065338, "episode/length": 249.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 386640, "time": 17345.04844546318, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 387048, "time": 17359.516607046127, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 387080, "time": 17362.09490084648, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 387161, "time": 17367.249079704285, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.027435302734375, "train/action_min": 0.0, "train/action_std": 3.8459134797255197, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04673319309949875, "train/actor_opt_grad_steps": 23385.0, "train/actor_opt_loss": -2.8407934876417533, "train/adv_mag": 0.6908274996611807, "train/adv_max": 0.675029987262355, "train/adv_mean": 0.003965035346280072, "train/adv_min": -0.4885564607878526, "train/adv_std": 0.07407526206225157, "train/cont_avg": 0.99462890625, "train/cont_loss_mean": 0.0002546757467393314, "train/cont_loss_std": 0.006973469907317546, "train/cont_neg_acc": 0.9899718931151761, "train/cont_neg_loss": 0.02643635342128113, "train/cont_pos_acc": 0.9999795423613654, "train/cont_pos_loss": 0.00011514243078735042, "train/cont_pred": 0.9946410929163297, "train/cont_rate": 0.99462890625, "train/dyn_loss_mean": 13.749063544803196, "train/dyn_loss_std": 9.332503431373173, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8966806274321344, "train/extr_critic_critic_opt_grad_steps": 23385.0, "train/extr_critic_critic_opt_loss": 15906.503580729166, "train/extr_critic_mag": 5.362494717041652, "train/extr_critic_max": 5.362494717041652, "train/extr_critic_mean": 0.9366262381275495, "train/extr_critic_min": -0.2691025725669331, "train/extr_critic_std": 1.2185411722295814, "train/extr_return_normed_mag": 1.8455115689171686, "train/extr_return_normed_max": 1.8455115689171686, "train/extr_return_normed_mean": 0.2828069156449702, "train/extr_return_normed_min": -0.1402692126058456, "train/extr_return_normed_std": 0.3414214922943049, "train/extr_return_rate": 0.4290735547741254, "train/extr_return_raw_mag": 6.708534204297596, "train/extr_return_raw_max": 6.708534204297596, "train/extr_return_raw_mean": 0.9512416356139712, "train/extr_return_raw_min": -0.6081441595322556, "train/extr_return_raw_std": 1.2582030635741022, "train/extr_reward_mag": 1.011971256799168, "train/extr_reward_max": 1.011971256799168, "train/extr_reward_mean": 0.02661154981211035, "train/extr_reward_min": -0.39913101411528057, "train/extr_reward_std": 0.15193380151564875, "train/image_loss_mean": 7.779549390077591, "train/image_loss_std": 11.738893512222502, "train/model_loss_mean": 16.080735557609135, "train/model_loss_std": 15.638225078582764, "train/model_opt_grad_norm": 63.65144650141398, "train/model_opt_grad_steps": 23361.104166666668, "train/model_opt_loss": 12084.00782945421, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 755.2083333333334, "train/policy_entropy_mag": 2.55392943488227, "train/policy_entropy_max": 2.55392943488227, "train/policy_entropy_mean": 0.8600530843767855, "train/policy_entropy_min": 0.07937524152091807, "train/policy_entropy_std": 0.8136459452410539, "train/policy_logprob_mag": 7.438382827573353, "train/policy_logprob_max": -0.009455781591693975, "train/policy_logprob_mean": -0.8596894852817059, "train/policy_logprob_min": -7.438382827573353, "train/policy_logprob_std": 1.2526758056547906, "train/policy_randomness_mag": 0.9014250139395396, "train/policy_randomness_max": 0.9014250139395396, "train/policy_randomness_mean": 0.30356099735945463, "train/policy_randomness_min": 0.02801597681051741, "train/policy_randomness_std": 0.28718131232178873, "train/post_ent_mag": 59.300094578001236, "train/post_ent_max": 59.300094578001236, "train/post_ent_mean": 41.49661413828532, "train/post_ent_min": 21.310542517238193, "train/post_ent_std": 7.478262328439289, "train/prior_ent_mag": 68.76782602734036, "train/prior_ent_max": 68.76782602734036, "train/prior_ent_mean": 55.2807031472524, "train/prior_ent_min": 36.537416007783676, "train/prior_ent_std": 5.139826622274187, "train/rep_loss_mean": 13.749063544803196, "train/rep_loss_std": 9.332503431373173, "train/reward_avg": 0.02157253667893302, "train/reward_loss_mean": 0.05149343997860948, "train/reward_loss_std": 0.24646919831219646, "train/reward_max_data": 1.0111111137602065, "train/reward_max_pred": 1.00663533144527, "train/reward_neg_acc": 0.9937025109926859, "train/reward_neg_loss": 0.029110800934075896, "train/reward_pos_acc": 0.9598194439378049, "train/reward_pos_loss": 0.8861154872510169, "train/reward_pred": 0.020901901854409113, "train/reward_rate": 0.026435004340277776, "train_stats/sum_log_reward": 5.254545404694297, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.8090909090909095, "train_stats/max_log_achievement_collect_sapling": 2.709090909090909, "train_stats/max_log_achievement_collect_stone": 0.00909090909090909, "train_stats/max_log_achievement_collect_wood": 5.872727272727273, "train_stats/max_log_achievement_defeat_skeleton": 0.00909090909090909, "train_stats/max_log_achievement_defeat_zombie": 0.38181818181818183, "train_stats/max_log_achievement_eat_cow": 0.09090909090909091, "train_stats/max_log_achievement_eat_plant": 0.00909090909090909, "train_stats/max_log_achievement_make_wood_pickaxe": 0.21818181818181817, "train_stats/max_log_achievement_make_wood_sword": 0.01818181818181818, "train_stats/max_log_achievement_place_plant": 2.609090909090909, "train_stats/max_log_achievement_place_table": 2.2545454545454544, "train_stats/max_log_achievement_wake_up": 2.018181818181818, "train_stats/mean_log_entropy": 0.5234812840819358, "eval_stats/sum_log_reward": 5.3499999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.1875, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 3.125, "eval_stats/max_log_achievement_wake_up": 2.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00010740871221059933, "report/cont_loss_std": 0.002828763797879219, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.01543575618416071, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.9038677692151396e-06, "report/cont_pred": 0.993263840675354, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.643651962280273, "report/dyn_loss_std": 9.365903854370117, "report/image_loss_mean": 6.928182601928711, "report/image_loss_std": 9.500580787658691, "report/model_loss_mean": 15.787040710449219, "report/model_loss_std": 13.892420768737793, "report/post_ent_mag": 58.179725646972656, "report/post_ent_max": 58.179725646972656, "report/post_ent_mean": 40.7421875, "report/post_ent_min": 21.12512969970703, "report/post_ent_std": 7.5712971687316895, "report/prior_ent_mag": 68.13284301757812, "report/prior_ent_max": 68.13284301757812, "report/prior_ent_mean": 55.48406982421875, "report/prior_ent_min": 39.169189453125, "report/prior_ent_std": 4.857763290405273, "report/rep_loss_mean": 14.643651962280273, "report/rep_loss_std": 9.365903854370117, "report/reward_avg": 0.03339843451976776, "report/reward_loss_mean": 0.07255981862545013, "report/reward_loss_std": 0.3141675591468811, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0028350353240967, "report/reward_neg_acc": 0.9908537268638611, "report/reward_neg_loss": 0.04030405357480049, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8660516738891602, "report/reward_pred": 0.03287241607904434, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.013224379159510136, "eval/cont_loss_std": 0.4197215139865875, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 2.2562108039855957, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.4193102439749055e-06, "eval/cont_pred": 0.9952070116996765, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.249706268310547, "eval/dyn_loss_std": 10.556966781616211, "eval/image_loss_mean": 13.573620796203613, "eval/image_loss_std": 20.696216583251953, "eval/model_loss_mean": 24.06772232055664, "eval/model_loss_std": 24.822240829467773, "eval/post_ent_mag": 56.669410705566406, "eval/post_ent_max": 56.669410705566406, "eval/post_ent_mean": 40.005828857421875, "eval/post_ent_min": 21.554231643676758, "eval/post_ent_std": 6.847671031951904, "eval/prior_ent_mag": 68.13284301757812, "eval/prior_ent_max": 68.13284301757812, "eval/prior_ent_mean": 55.447269439697266, "eval/prior_ent_min": 43.98659133911133, "eval/prior_ent_std": 4.572258949279785, "eval/rep_loss_mean": 17.249706268310547, "eval/rep_loss_std": 10.556966781616211, "eval/reward_avg": 0.03994140774011612, "eval/reward_loss_mean": 0.13105280697345734, "eval/reward_loss_std": 0.7207649350166321, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0028464794158936, "eval/reward_neg_acc": 0.9908162951469421, "eval/reward_neg_loss": 0.04192672297358513, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.11613392829895, "eval/reward_pred": 0.030003782361745834, "eval/reward_rate": 0.04296875, "replay/size": 386657.0, "replay/inserts": 23024.0, "replay/samples": 23024.0, "replay/insert_wait_avg": 1.3424610412311355e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.063195396248378e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 75888.0, "eval_replay/inserts": 4768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.200743569623704e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3711643218994, "timer/env.step_count": 2878.0, "timer/env.step_total": 252.9763147830963, "timer/env.step_frac": 0.25288245383859703, "timer/env.step_avg": 0.08790003988293826, "timer/env.step_min": 0.02267599105834961, "timer/env.step_max": 3.259202718734741, "timer/replay._sample_count": 23024.0, "timer/replay._sample_total": 12.026648759841919, "timer/replay._sample_frac": 0.01202218655312218, "timer/replay._sample_avg": 0.0005223527084712439, "timer/replay._sample_min": 0.00036835670471191406, "timer/replay._sample_max": 0.00997471809387207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3474.0, "timer/agent.policy_total": 52.816662073135376, "timer/agent.policy_frac": 0.05279706568605173, "timer/agent.policy_avg": 0.015203414528824231, "timer/agent.policy_min": 0.008380413055419922, "timer/agent.policy_max": 0.10744357109069824, "timer/dataset_train_count": 1439.0, "timer/dataset_train_total": 0.15997052192687988, "timer/dataset_train_frac": 0.00015991116860641994, "timer/dataset_train_avg": 0.00011116784011596935, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.005875349044799805, "timer/agent.train_count": 1439.0, "timer/agent.train_total": 624.255642414093, "timer/agent.train_frac": 0.6240240269592777, "timer/agent.train_avg": 0.4338121212050681, "timer/agent.train_min": 0.4184737205505371, "timer/agent.train_max": 1.3191354274749756, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4710385799407959, "timer/agent.report_frac": 0.00047086381209327335, "timer/agent.report_avg": 0.23551928997039795, "timer/agent.report_min": 0.22385549545288086, "timer/agent.report_max": 0.24718308448791504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.883794445519038e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 23.015128535985937}
{"step": 387208, "time": 17368.53018450737, "episode/length": 156.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 387336, "time": 17374.103102207184, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 387672, "time": 17386.471348762512, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 387992, "time": 17398.26168680191, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 388184, "time": 17406.146277189255, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 388608, "time": 17421.535799980164, "episode/length": 190.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 388688, "time": 17425.679338932037, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 388840, "time": 17432.040424585342, "episode/length": 274.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 388880, "time": 17434.99032020569, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 389192, "time": 17446.37033700943, "episode/length": 267.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 389320, "time": 17451.93749523163, "episode/length": 165.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 389552, "time": 17461.297263383865, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 389936, "time": 17475.19616508484, "episode/length": 165.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 17496.1893119812, "eval_episode/length": 99.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 390000, "time": 17500.009734392166, "eval_episode/length": 154.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 390000, "time": 17501.705285310745, "eval_episode/length": 57.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 390000, "time": 17503.67881321907, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 390000, "time": 17506.20908856392, "eval_episode/length": 189.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 390000, "time": 17507.816453933716, "eval_episode/length": 191.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 390000, "time": 17509.652777671814, "eval_episode/length": 196.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 390000, "time": 17511.361105442047, "eval_episode/length": 202.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 390168, "time": 17516.53713774681, "episode/length": 165.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 390224, "time": 17520.105967521667, "episode/length": 318.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780564263322884, "episode/intrinsic_return": 0.0}
{"step": 390288, "time": 17523.903205871582, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 390536, "time": 17533.224727392197, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 390584, "time": 17536.348463773727, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 390680, "time": 17541.217418432236, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 390904, "time": 17550.02095603943, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 390944, "time": 17553.095947265625, "episode/length": 50.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 391400, "time": 17569.045286893845, "episode/length": 182.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 391696, "time": 17581.165460586548, "episode/length": 190.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 391880, "time": 17589.07388806343, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 391960, "time": 17593.115446567535, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 392416, "time": 17609.547564983368, "episode/length": 273.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 392856, "time": 17625.348427534103, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 392992, "time": 17631.51780486107, "episode/length": 138.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 393016, "time": 17633.56396007538, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 393368, "time": 17647.821001291275, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 393752, "time": 17661.774101257324, "episode/length": 432.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 394088, "time": 17674.214684009552, "episode/length": 392.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989821882951654, "episode/intrinsic_return": 0.0}
{"step": 394216, "time": 17679.83395242691, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 394232, "time": 17681.830753326416, "episode/length": 226.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 394392, "time": 17688.41607117653, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 394400, "time": 17690.372854471207, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 394408, "time": 17691.980454683304, "episode/length": 437.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 394648, "time": 17701.41093635559, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 394720, "time": 17705.95915722847, "episode/length": 40.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 395064, "time": 17719.135081768036, "episode/length": 163.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 395480, "time": 17735.21001982689, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 395640, "time": 17742.43550515175, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 396072, "time": 17757.92662835121, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 396080, "time": 17759.85712981224, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 396328, "time": 17769.335654973984, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 396496, "time": 17776.5358543396, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 396568, "time": 17780.177729845047, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 396856, "time": 17791.210567712784, "episode/length": 306.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 396872, "time": 17793.252514600754, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 397272, "time": 17807.677158117294, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 397400, "time": 17813.334101438522, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 397512, "time": 17818.43198823929, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 397784, "time": 17828.86913537979, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 397816, "time": 17831.40925860405, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 397896, "time": 17835.524394512177, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 398088, "time": 17843.288801670074, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 398128, "time": 17846.30921769142, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 398384, "time": 17856.12362885475, "episode/length": 188.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 398624, "time": 17865.361180067062, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 399208, "time": 17885.866622447968, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 399376, "time": 17893.14494585991, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 399592, "time": 17901.452009916306, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 399632, "time": 17904.553230047226, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 399688, "time": 17907.70375728607, "episode/length": 132.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 399808, "time": 17913.530701875687, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 399824, "time": 17915.59115576744, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 399936, "time": 17920.697519302368, "episode/length": 225.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 17945.96067237854, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 400088, "time": 17947.869126558304, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9640718562874252}
{"step": 400088, "time": 17947.87734937668, "eval_episode/length": 166.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 400088, "time": 17952.01556968689, "eval_episode/length": 186.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 400088, "time": 17954.06299829483, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 400088, "time": 17956.447674512863, "eval_episode/length": 217.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 400088, "time": 17959.68830370903, "eval_episode/length": 258.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 400088, "time": 17964.828939199448, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 400616, "time": 17981.976628303528, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 400744, "time": 17987.68061184883, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 400760, "time": 17989.63378214836, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 400856, "time": 17994.278352975845, "episode/length": 130.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 401104, "time": 18004.131543397903, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 401184, "time": 18008.259870290756, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 401256, "time": 18011.771067619324, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 401416, "time": 18018.643000602722, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 402200, "time": 18047.048801898956, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 402216, "time": 18049.113476991653, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 402272, "time": 18052.585372924805, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 402512, "time": 18062.035141706467, "episode/length": 156.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 402616, "time": 18066.82981944084, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 402656, "time": 18069.94285750389, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 402888, "time": 18078.754417657852, "episode/length": 283.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 403088, "time": 18087.037166833878, "episode/length": 247.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 403728, "time": 18110.334256887436, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 403760, "time": 18113.00582551956, "episode/length": 185.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 403928, "time": 18119.722323656082, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 404120, "time": 18127.5767929554, "episode/length": 200.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 404232, "time": 18132.742104053497, "episode/length": 201.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 404720, "time": 18150.251967906952, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 404936, "time": 18158.593774080276, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 405160, "time": 18167.230670928955, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 405208, "time": 18170.284598350525, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 405480, "time": 18180.47150683403, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 405568, "time": 18185.21139383316, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 405688, "time": 18191.052210330963, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 405920, "time": 18200.731740951538, "episode/length": 378.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9920844327176781, "episode/intrinsic_return": 0.0}
{"step": 406072, "time": 18206.9055891037, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 406416, "time": 18219.71542739868, "episode/length": 184.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 406560, "time": 18225.720899820328, "episode/length": 174.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 406744, "time": 18232.908712387085, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 407080, "time": 18245.369959831238, "episode/length": 199.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 407144, "time": 18248.91355252266, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 407640, "time": 18266.436626672745, "episode/length": 195.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 407760, "time": 18272.22669816017, "episode/length": 258.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 407776, "time": 18274.355682849884, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 407856, "time": 18278.431030273438, "episode/length": 285.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 408176, "time": 18290.293268680573, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 408464, "time": 18301.025588989258, "episode/length": 214.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 408480, "time": 18303.188504457474, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 408832, "time": 18316.098534584045, "episode/length": 210.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 408840, "time": 18317.60369348526, "episode/length": 149.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 409120, "time": 18328.28419160843, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 409528, "time": 18342.69538640976, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 409536, "time": 18344.708559036255, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 409688, "time": 18352.24085879326, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 409728, "time": 18355.393450737, "episode/length": 413.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 410025, "time": 18367.33020544052, "train_stats/sum_log_reward": 5.462068911256461, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.017241379310345, "train_stats/max_log_achievement_collect_sapling": 2.5775862068965516, "train_stats/max_log_achievement_collect_stone": 0.008620689655172414, "train_stats/max_log_achievement_collect_wood": 6.362068965517241, "train_stats/max_log_achievement_defeat_skeleton": 0.017241379310344827, "train_stats/max_log_achievement_defeat_zombie": 0.3017241379310345, "train_stats/max_log_achievement_eat_cow": 0.05172413793103448, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4396551724137931, "train_stats/max_log_achievement_make_wood_sword": 0.017241379310344827, "train_stats/max_log_achievement_place_plant": 2.456896551724138, "train_stats/max_log_achievement_place_table": 2.3706896551724137, "train_stats/max_log_achievement_wake_up": 1.8275862068965518, "train_stats/mean_log_entropy": 0.520863823721121, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.192225316187718, "train/action_min": 0.0, "train/action_std": 3.930139511615246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045092697952177144, "train/actor_opt_grad_steps": 24820.0, "train/actor_opt_loss": -4.420730094549122, "train/adv_mag": 0.6639308627251979, "train/adv_max": 0.6474712213853022, "train/adv_mean": 0.0033773438567900136, "train/adv_min": -0.47882230194298536, "train/adv_std": 0.07206693289059025, "train/cont_avg": 0.9947074409965035, "train/cont_loss_mean": 0.00021858679999965902, "train/cont_loss_std": 0.006514585971529102, "train/cont_neg_acc": 0.9934648692191064, "train/cont_neg_loss": 0.01958145371301115, "train/cont_pos_acc": 0.9999587648398393, "train/cont_pos_loss": 0.00011068545347169535, "train/cont_pred": 0.99469558675806, "train/cont_rate": 0.9947074409965035, "train/dyn_loss_mean": 13.77374651715472, "train/dyn_loss_std": 9.31867527461552, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8666124377217326, "train/extr_critic_critic_opt_grad_steps": 24820.0, "train/extr_critic_critic_opt_loss": 15689.32660210883, "train/extr_critic_mag": 5.443692577468766, "train/extr_critic_max": 5.443692577468766, "train/extr_critic_mean": 0.9284054736991029, "train/extr_critic_min": -0.30895251994366413, "train/extr_critic_std": 1.2194371394344143, "train/extr_return_normed_mag": 1.840498932591685, "train/extr_return_normed_max": 1.840498932591685, "train/extr_return_normed_mean": 0.2815055135455165, "train/extr_return_normed_min": -0.14902795679294145, "train/extr_return_normed_std": 0.3397932783081815, "train/extr_return_rate": 0.4270869983242942, "train/extr_return_raw_mag": 6.7068548769384, "train/extr_return_raw_max": 6.7068548769384, "train/extr_return_raw_mean": 0.9408907102538155, "train/extr_return_raw_min": -0.6513650484018393, "train/extr_return_raw_std": 1.2568051706660877, "train/extr_reward_mag": 1.0127123202477302, "train/extr_reward_max": 1.0127123202477302, "train/extr_reward_mean": 0.026633901488999804, "train/extr_reward_min": -0.4115386826175076, "train/extr_reward_std": 0.15196129466061825, "train/image_loss_mean": 7.40740786399041, "train/image_loss_std": 11.536942331940978, "train/model_loss_mean": 15.723297979448224, "train/model_loss_std": 15.427688245173101, "train/model_opt_grad_norm": 59.079188313517534, "train/model_opt_grad_steps": 24795.503496503497, "train/model_opt_loss": 19654.12240493881, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.5472497639956173, "train/policy_entropy_max": 2.5472497639956173, "train/policy_entropy_mean": 0.9066000789195507, "train/policy_entropy_min": 0.07937523957107451, "train/policy_entropy_std": 0.8128157874920985, "train/policy_logprob_mag": 7.4383830924134156, "train/policy_logprob_max": -0.009455779977663831, "train/policy_logprob_mean": -0.9076880029031447, "train/policy_logprob_min": -7.4383830924134156, "train/policy_logprob_std": 1.2730375119856188, "train/policy_randomness_mag": 0.8990673847965427, "train/policy_randomness_max": 0.8990673847965427, "train/policy_randomness_mean": 0.31999004272731035, "train/policy_randomness_min": 0.028015976107412285, "train/policy_randomness_std": 0.28688830314399477, "train/post_ent_mag": 59.49763910253565, "train/post_ent_max": 59.49763910253565, "train/post_ent_mean": 41.690905724372065, "train/post_ent_min": 21.324162396517668, "train/post_ent_std": 7.4898512746904276, "train/prior_ent_mag": 68.99996718826827, "train/prior_ent_max": 68.99996718826827, "train/prior_ent_mean": 55.5001564559403, "train/prior_ent_min": 36.700243142934944, "train/prior_ent_std": 5.160698000367705, "train/rep_loss_mean": 13.77374651715472, "train/rep_loss_std": 9.31867527461552, "train/reward_avg": 0.02204914219755601, "train/reward_loss_mean": 0.05142373256906346, "train/reward_loss_std": 0.24524118850281187, "train/reward_max_data": 1.002797203464108, "train/reward_max_pred": 1.0040421752662925, "train/reward_neg_acc": 0.9935698559234193, "train/reward_neg_loss": 0.02871675517123479, "train/reward_pos_acc": 0.9650097997872146, "train/reward_pos_loss": 0.8692915852253253, "train/reward_pred": 0.021329240658535406, "train/reward_rate": 0.02683839597902098, "eval_stats/sum_log_reward": 5.287499964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.0625, "eval_stats/max_log_achievement_collect_sapling": 3.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 3.0625, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.443368642474525e-06, "report/cont_loss_std": 9.603847865946591e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009180080960504711, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.9803430809115525e-06, "report/cont_pred": 0.9951177835464478, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.32432746887207, "report/dyn_loss_std": 8.977049827575684, "report/image_loss_mean": 7.520623207092285, "report/image_loss_std": 12.442585945129395, "report/model_loss_mean": 16.158130645751953, "report/model_loss_std": 15.9865083694458, "report/post_ent_mag": 57.75025177001953, "report/post_ent_max": 57.75025177001953, "report/post_ent_mean": 41.23363494873047, "report/post_ent_min": 23.063159942626953, "report/post_ent_std": 7.236001014709473, "report/prior_ent_mag": 68.75517272949219, "report/prior_ent_max": 68.75517272949219, "report/prior_ent_mean": 55.92595672607422, "report/prior_ent_min": 35.315547943115234, "report/prior_ent_std": 5.133889675140381, "report/rep_loss_mean": 14.32432746887207, "report/rep_loss_std": 8.977049827575684, "report/reward_avg": 0.01542968675494194, "report/reward_loss_mean": 0.04290385916829109, "report/reward_loss_std": 0.22969791293144226, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002716302871704, "report/reward_neg_acc": 0.9950199723243713, "report/reward_neg_loss": 0.025838997215032578, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.8995599746704102, "report/reward_pred": 0.015065805986523628, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.00012272624007891864, "eval/cont_loss_std": 0.002828943310305476, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.011987739242613316, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.930093432951253e-05, "eval/cont_pred": 0.9922486543655396, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 17.0330810546875, "eval/dyn_loss_std": 10.393193244934082, "eval/image_loss_mean": 10.716058731079102, "eval/image_loss_std": 16.420997619628906, "eval/model_loss_mean": 21.027164459228516, "eval/model_loss_std": 20.48352813720703, "eval/post_ent_mag": 55.730628967285156, "eval/post_ent_max": 55.730628967285156, "eval/post_ent_mean": 41.02953338623047, "eval/post_ent_min": 20.157909393310547, "eval/post_ent_std": 6.8645477294921875, "eval/prior_ent_mag": 68.75517272949219, "eval/prior_ent_max": 68.75517272949219, "eval/prior_ent_mean": 56.472999572753906, "eval/prior_ent_min": 37.788490295410156, "eval/prior_ent_std": 4.585531711578369, "eval/rep_loss_mean": 17.0330810546875, "eval/rep_loss_std": 10.393193244934082, "eval/reward_avg": 0.02666015550494194, "eval/reward_loss_mean": 0.09113521873950958, "eval/reward_loss_std": 0.534423291683197, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0010688304901123, "eval/reward_neg_acc": 0.9939454793930054, "eval/reward_neg_loss": 0.03943276032805443, "eval/reward_pos_acc": 0.8484848141670227, "eval/reward_pos_loss": 1.6437758207321167, "eval/reward_pred": 0.020862428471446037, "eval/reward_rate": 0.0322265625, "replay/size": 409521.0, "replay/inserts": 22864.0, "replay/samples": 22864.0, "replay/insert_wait_avg": 1.319946735534241e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.081351234163748e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 80312.0, "eval_replay/inserts": 4424.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1877815287971152e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0777173042297, "timer/env.step_count": 2858.0, "timer/env.step_total": 257.0900673866272, "timer/env.step_frac": 0.2570700885923437, "timer/env.step_avg": 0.08995453722415227, "timer/env.step_min": 0.022586584091186523, "timer/env.step_max": 2.946898937225342, "timer/replay._sample_count": 22864.0, "timer/replay._sample_total": 11.938025712966919, "timer/replay._sample_frac": 0.011937097993890507, "timer/replay._sample_avg": 0.0005221319853466987, "timer/replay._sample_min": 0.0003783702850341797, "timer/replay._sample_max": 0.011737585067749023, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3411.0, "timer/agent.policy_total": 50.95068645477295, "timer/agent.policy_frac": 0.05094672701249021, "timer/agent.policy_avg": 0.014937169878268234, "timer/agent.policy_min": 0.00841665267944336, "timer/agent.policy_max": 0.10049653053283691, "timer/dataset_train_count": 1429.0, "timer/dataset_train_total": 0.15471434593200684, "timer/dataset_train_frac": 0.00015470232288451418, "timer/dataset_train_avg": 0.00010826756188383964, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.001092672348022461, "timer/agent.train_count": 1429.0, "timer/agent.train_total": 624.4746437072754, "timer/agent.train_frac": 0.6244261149929274, "timer/agent.train_avg": 0.4370011502500178, "timer/agent.train_min": 0.4235992431640625, "timer/agent.train_max": 1.6373209953308105, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4709935188293457, "timer/agent.report_frac": 0.0004709569173273227, "timer/agent.report_avg": 0.23549675941467285, "timer/agent.report_min": 0.22405576705932617, "timer/agent.report_max": 0.24693775177001953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.646240569343951e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 22.861922321295083}
{"step": 410056, "time": 18368.019679307938, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 18388.64208483696, "eval_episode/length": 133.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9552238805970149}
{"step": 410072, "time": 18393.85621190071, "eval_episode/length": 182.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 410072, "time": 18396.15211033821, "eval_episode/length": 200.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 410072, "time": 18397.79923772812, "eval_episode/length": 201.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 410072, "time": 18399.635115146637, "eval_episode/length": 210.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.995260663507109}
{"step": 410072, "time": 18402.067368507385, "eval_episode/length": 231.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 410072, "time": 18404.08859562874, "eval_episode/length": 242.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 410072, "time": 18407.906069517136, "eval_episode/length": 298.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732441471571907}
{"step": 410400, "time": 18418.62821006775, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 410432, "time": 18421.172372817993, "episode/length": 199.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 410968, "time": 18439.895119190216, "episode/length": 178.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 411224, "time": 18449.55071425438, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 411280, "time": 18453.108669281006, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 411432, "time": 18459.308320999146, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 411744, "time": 18471.014018058777, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 412088, "time": 18483.32841515541, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 412456, "time": 18496.767447948456, "episode/length": 416.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976019184652278, "episode/intrinsic_return": 0.0}
{"step": 412592, "time": 18502.94604730606, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 412608, "time": 18505.05924630165, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 412712, "time": 18509.72492980957, "episode/length": 288.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 412944, "time": 18518.976166963577, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 413016, "time": 18522.684332847595, "episode/length": 197.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 413256, "time": 18532.073912382126, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 413360, "time": 18537.882816791534, "episode/length": 42.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 413440, "time": 18542.59733915329, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 413792, "time": 18556.251614570618, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 413968, "time": 18563.406100273132, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 414048, "time": 18567.634226322174, "episode/length": 166.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 414288, "time": 18576.906965255737, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 414568, "time": 18587.27168059349, "episode/length": 246.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9878542510121457, "episode/intrinsic_return": 0.0}
{"step": 414584, "time": 18589.3524787426, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 414984, "time": 18603.919226408005, "episode/length": 192.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 415032, "time": 18607.005431175232, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 415416, "time": 18620.91260457039, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 415440, "time": 18623.41891145706, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 415672, "time": 18632.316843032837, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 415912, "time": 18641.569475650787, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 416504, "time": 18662.273822307587, "episode/length": 276.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 416632, "time": 18667.98220562935, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 416648, "time": 18669.949251890182, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 416720, "time": 18673.988673210144, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 417344, "time": 18695.90324831009, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9663865546218487, "episode/intrinsic_return": 0.0}
{"step": 417360, "time": 18697.922386169434, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 417424, "time": 18701.486901283264, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 417464, "time": 18704.005390644073, "episode/length": 223.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 417840, "time": 18719.14651799202, "episode/length": 46.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 417920, "time": 18723.281046152115, "episode/length": 160.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 417992, "time": 18726.79412817955, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 418016, "time": 18729.173248291016, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 418136, "time": 18734.509669303894, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 418408, "time": 18744.837643146515, "episode/length": 48.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 418544, "time": 18750.97734618187, "episode/length": 50.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 418864, "time": 18763.03393316269, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 419056, "time": 18771.41007041931, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 419200, "time": 18778.387736320496, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 419376, "time": 18786.368941545486, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 419664, "time": 18797.865324258804, "episode/length": 208.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 419664, "time": 18797.873995780945, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 18835.289719104767, "eval_episode/length": 110.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9459459459459459}
{"step": 420056, "time": 18838.905836820602, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 420056, "time": 18841.66309595108, "eval_episode/length": 187.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 420056, "time": 18843.34397673607, "eval_episode/length": 190.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9633507853403142}
{"step": 420056, "time": 18845.382056713104, "eval_episode/length": 202.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 420056, "time": 18845.38954758644, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 420056, "time": 18849.606048583984, "eval_episode/length": 228.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.982532751091703}
{"step": 420056, "time": 18854.19323325157, "eval_episode/length": 100.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 420104, "time": 18855.739794015884, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 420112, "time": 18857.678911685944, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 420264, "time": 18863.83455133438, "episode/length": 231.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 420424, "time": 18870.570204019547, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 420760, "time": 18883.047794818878, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 420832, "time": 18887.02099967003, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 421056, "time": 18895.747678279877, "episode/length": 173.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 421232, "time": 18903.023015022278, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 421552, "time": 18914.79718184471, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 421648, "time": 18919.429139375687, "episode/length": 191.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 421664, "time": 18921.45849585533, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 421952, "time": 18932.32483625412, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 422112, "time": 18939.093457698822, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 422360, "time": 18948.61747932434, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 422440, "time": 18952.711455106735, "episode/length": 200.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 422496, "time": 18956.254190683365, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 423040, "time": 18975.489215373993, "episode/length": 171.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 423288, "time": 18984.811571121216, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 423336, "time": 18987.92769241333, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 423416, "time": 18992.223746538162, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 423872, "time": 19008.65815973282, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 423968, "time": 19013.283012628555, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 424024, "time": 19016.369374752045, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 424176, "time": 19023.024628400803, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 424688, "time": 19040.982308149338, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 424912, "time": 19049.762498140335, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 425360, "time": 19065.934541225433, "episode/length": 55.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 425520, "time": 19072.65054154396, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 425640, "time": 19077.84737610817, "episode/length": 277.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 425656, "time": 19079.896285057068, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 425696, "time": 19083.049333810806, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 426184, "time": 19102.077887296677, "episode/length": 276.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 426264, "time": 19106.15895962715, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 426360, "time": 19110.760322332382, "episode/length": 482.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9917184265010351, "episode/intrinsic_return": 0.0}
{"step": 426840, "time": 19127.89137840271, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 426848, "time": 19129.85794210434, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 427168, "time": 19142.046058416367, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 427488, "time": 19154.002849578857, "episode/length": 230.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 427520, "time": 19156.912897109985, "episode/length": 232.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 427704, "time": 19164.583118915558, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 428120, "time": 19179.50686979294, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 428392, "time": 19189.898394823074, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 428552, "time": 19196.590943574905, "episode/length": 295.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 428704, "time": 19203.308506011963, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 428704, "time": 19203.31597828865, "episode/length": 191.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 428752, "time": 19208.05729007721, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 428880, "time": 19213.590857982635, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 429352, "time": 19230.054046154022, "episode/length": 153.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 429640, "time": 19240.89664697647, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9628099173553719, "episode/intrinsic_return": 0.0}
{"step": 429720, "time": 19244.953817605972, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 429760, "time": 19247.914022922516, "episode/length": 150.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 19273.943422079086, "eval_episode/length": 82.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.927710843373494}
{"step": 430040, "time": 19278.19844698906, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 430040, "time": 19280.08840227127, "eval_episode/length": 158.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 430040, "time": 19282.192592144012, "eval_episode/length": 173.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 430040, "time": 19285.037989377975, "eval_episode/length": 204.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 430040, "time": 19286.951080322266, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 430040, "time": 19289.295346021652, "eval_episode/length": 233.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 430040, "time": 19290.825105428696, "eval_episode/length": 236.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9831223628691983}
{"step": 430088, "time": 19292.478390216827, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 430104, "time": 19294.561740875244, "episode/length": 42.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 430296, "time": 19302.226311683655, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 430320, "time": 19304.679208040237, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 430464, "time": 19310.749539375305, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 430784, "time": 19322.71586203575, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 431072, "time": 19333.33187007904, "episode/length": 295.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 431152, "time": 19337.33830142021, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 431448, "time": 19348.144870996475, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 431544, "time": 19352.85352897644, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 431608, "time": 19356.46797657013, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 431840, "time": 19365.632869005203, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 431841, "time": 19367.77333664894, "train_stats/sum_log_reward": 5.424561328009555, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.543859649122807, "train_stats/max_log_achievement_collect_sapling": 2.412280701754386, "train_stats/max_log_achievement_collect_stone": 0.07017543859649122, "train_stats/max_log_achievement_collect_wood": 6.315789473684211, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.40350877192982454, "train_stats/max_log_achievement_eat_cow": 0.05263157894736842, "train_stats/max_log_achievement_eat_plant": 0.008771929824561403, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5263157894736842, "train_stats/max_log_achievement_make_wood_sword": 0.008771929824561403, "train_stats/max_log_achievement_place_plant": 2.289473684210526, "train_stats/max_log_achievement_place_table": 2.219298245614035, "train_stats/max_log_achievement_wake_up": 1.4035087719298245, "train_stats/mean_log_entropy": 0.4123688538869222, "eval_stats/sum_log_reward": 5.1833332777023315, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.208333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.4583333333333335, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.083333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4583333333333333, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.20833333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 1.9583333333333333, "eval_stats/max_log_achievement_wake_up": 1.4583333333333333, "eval_stats/mean_log_entropy": 0.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.132952521829044, "train/action_min": 0.0, "train/action_std": 3.8415009291733013, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.046324204023489184, "train/actor_opt_grad_steps": 26215.0, "train/actor_opt_loss": -2.4902846177711204, "train/adv_mag": 0.7031966561780256, "train/adv_max": 0.6850116117035642, "train/adv_mean": 0.003979459785435157, "train/adv_min": -0.5031346652437659, "train/adv_std": 0.07361899535445605, "train/cont_avg": 0.9945714613970589, "train/cont_loss_mean": 0.0002354954507306756, "train/cont_loss_std": 0.007155690432358262, "train/cont_neg_acc": 0.9895833340637824, "train/cont_neg_loss": 0.03293459551023529, "train/cont_pos_acc": 0.9999855542007614, "train/cont_pos_loss": 8.236667139345102e-05, "train/cont_pred": 0.9945855302845731, "train/cont_rate": 0.9945714613970589, "train/dyn_loss_mean": 13.555987806881175, "train/dyn_loss_std": 9.305733358158784, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8392236758680904, "train/extr_critic_critic_opt_grad_steps": 26215.0, "train/extr_critic_critic_opt_loss": 15629.98186896829, "train/extr_critic_mag": 5.479506282245412, "train/extr_critic_max": 5.479506282245412, "train/extr_critic_mean": 0.9333639960078632, "train/extr_critic_min": -0.30510903631939607, "train/extr_critic_std": 1.2291692236767096, "train/extr_return_normed_mag": 1.8771001012886273, "train/extr_return_normed_max": 1.8771001012886273, "train/extr_return_normed_mean": 0.286134450312923, "train/extr_return_normed_min": -0.15055754610939936, "train/extr_return_normed_std": 0.34589975579258275, "train/extr_return_rate": 0.4272039896425079, "train/extr_return_raw_mag": 6.7873040963621705, "train/extr_return_raw_max": 6.7873040963621705, "train/extr_return_raw_mean": 0.9479544263552216, "train/extr_return_raw_min": -0.6546754425062853, "train/extr_return_raw_std": 1.2697241748957073, "train/extr_reward_mag": 1.016200181315927, "train/extr_reward_max": 1.016200181315927, "train/extr_reward_mean": 0.027594657375148553, "train/extr_reward_min": -0.43222707948263955, "train/extr_reward_std": 0.1551523657844347, "train/image_loss_mean": 7.259086591355941, "train/image_loss_std": 11.564243958276862, "train/model_loss_mean": 15.445249326088849, "train/model_loss_std": 15.434499572305118, "train/model_opt_grad_norm": 61.954894318300134, "train/model_opt_grad_steps": 26189.198529411766, "train/model_opt_loss": 19892.824017693016, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1286.764705882353, "train/policy_entropy_mag": 2.5578402613892273, "train/policy_entropy_max": 2.5578402613892273, "train/policy_entropy_mean": 0.8451033799963839, "train/policy_entropy_min": 0.0793752017814447, "train/policy_entropy_std": 0.7881753523560131, "train/policy_logprob_mag": 7.438383256687837, "train/policy_logprob_max": -0.009455750621033503, "train/policy_logprob_mean": -0.8455898016691208, "train/policy_logprob_min": -7.438383256687837, "train/policy_logprob_std": 1.255970613044851, "train/policy_randomness_mag": 0.902805362992427, "train/policy_randomness_max": 0.902805362992427, "train/policy_randomness_mean": 0.29828440606155815, "train/policy_randomness_min": 0.028015962870353284, "train/policy_randomness_std": 0.27819131051792817, "train/post_ent_mag": 59.4856868351207, "train/post_ent_max": 59.4856868351207, "train/post_ent_mean": 42.0169046345879, "train/post_ent_min": 21.25416459756739, "train/post_ent_std": 7.603064887663898, "train/prior_ent_mag": 69.00899572933422, "train/prior_ent_max": 69.00899572933422, "train/prior_ent_mean": 55.602056222803455, "train/prior_ent_min": 36.92302106408512, "train/prior_ent_std": 5.087851166725159, "train/rep_loss_mean": 13.555987806881175, "train/rep_loss_std": 9.305733358158784, "train/reward_avg": 0.022189510321956787, "train/reward_loss_mean": 0.052334512063466454, "train/reward_loss_std": 0.2461767538505442, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.0087046649526148, "train/reward_neg_acc": 0.9929658384884105, "train/reward_neg_loss": 0.029435101465102944, "train/reward_pos_acc": 0.9594656413092333, "train/reward_pos_loss": 0.8807408165405778, "train/reward_pred": 0.021558240251204765, "train/reward_rate": 0.027106789981617647, "train_stats/max_log_achievement_place_stone": 0.010869565217391304, "eval_stats/max_log_achievement_place_stone": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 2.8109665436204523e-05, "report/cont_loss_std": 0.0008476348593831062, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.011311001610011e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.780316208372824e-05, "report/cont_pred": 0.9941139221191406, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.07344913482666, "report/dyn_loss_std": 10.024739265441895, "report/image_loss_mean": 6.907909393310547, "report/image_loss_std": 9.293434143066406, "report/model_loss_mean": 15.413043975830078, "report/model_loss_std": 13.8372802734375, "report/post_ent_mag": 62.4134521484375, "report/post_ent_max": 62.4134521484375, "report/post_ent_mean": 41.63471221923828, "report/post_ent_min": 21.929641723632812, "report/post_ent_std": 7.60317325592041, "report/prior_ent_mag": 68.59208679199219, "report/prior_ent_max": 68.59208679199219, "report/prior_ent_mean": 55.87710952758789, "report/prior_ent_min": 32.60014343261719, "report/prior_ent_std": 6.0561323165893555, "report/rep_loss_mean": 14.07344913482666, "report/rep_loss_std": 10.024739265441895, "report/reward_avg": 0.02216796949505806, "report/reward_loss_mean": 0.06103663146495819, "report/reward_loss_std": 0.31291064620018005, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006115436553955, "report/reward_neg_acc": 0.9909729361534119, "report/reward_neg_loss": 0.032038576900959015, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 1.1318166255950928, "report/reward_pred": 0.021026896312832832, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 3.0861377808832913e-07, "eval/cont_loss_std": 3.688609012897359e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.481463737552986e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2600771387715213e-07, "eval/cont_pred": 0.9990233182907104, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.619983673095703, "eval/dyn_loss_std": 10.628508567810059, "eval/image_loss_mean": 10.61785888671875, "eval/image_loss_std": 16.194072723388672, "eval/model_loss_mean": 20.655628204345703, "eval/model_loss_std": 20.78995704650879, "eval/post_ent_mag": 55.28826904296875, "eval/post_ent_max": 55.28826904296875, "eval/post_ent_mean": 40.55759811401367, "eval/post_ent_min": 22.913105010986328, "eval/post_ent_std": 6.453989505767822, "eval/prior_ent_mag": 68.59208679199219, "eval/prior_ent_max": 68.59208679199219, "eval/prior_ent_mean": 54.988067626953125, "eval/prior_ent_min": 33.17427062988281, "eval/prior_ent_std": 5.569594860076904, "eval/rep_loss_mean": 16.619983673095703, "eval/rep_loss_std": 10.628508567810059, "eval/reward_avg": 0.02226562425494194, "eval/reward_loss_mean": 0.06578022986650467, "eval/reward_loss_std": 0.5685139298439026, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.999902606010437, "eval/reward_neg_acc": 0.9939939975738525, "eval/reward_neg_loss": 0.017718469724059105, "eval/reward_pos_acc": 0.8799999952316284, "eval/reward_pos_loss": 1.9863284826278687, "eval/reward_pred": 0.01760226860642433, "eval/reward_rate": 0.0244140625, "replay/size": 431337.0, "replay/inserts": 21816.0, "replay/samples": 21808.0, "replay/insert_wait_avg": 1.2816747204480173e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.610087524156578e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 87032.0, "eval_replay/inserts": 6720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2010690711793446e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4293529987335, "timer/env.step_count": 2727.0, "timer/env.step_total": 249.76337432861328, "timer/env.step_frac": 0.2496561836974904, "timer/env.step_avg": 0.09158906282677422, "timer/env.step_min": 0.023125410079956055, "timer/env.step_max": 3.202998399734497, "timer/replay._sample_count": 21808.0, "timer/replay._sample_total": 11.089637994766235, "timer/replay._sample_frac": 0.011084878668869159, "timer/replay._sample_avg": 0.0005085123805377034, "timer/replay._sample_min": 0.0003924369812011719, "timer/replay._sample_max": 0.010254621505737305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3567.0, "timer/agent.policy_total": 54.36587572097778, "timer/agent.policy_frac": 0.05434254358692993, "timer/agent.policy_avg": 0.015241344469015358, "timer/agent.policy_min": 0.008383989334106445, "timer/agent.policy_max": 0.16891098022460938, "timer/dataset_train_count": 1363.0, "timer/dataset_train_total": 0.1533186435699463, "timer/dataset_train_frac": 0.00015325284400180967, "timer/dataset_train_avg": 0.0001124861654951917, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.009160995483398438, "timer/agent.train_count": 1363.0, "timer/agent.train_total": 594.2059581279755, "timer/agent.train_frac": 0.5939509435092791, "timer/agent.train_avg": 0.43595448138516174, "timer/agent.train_min": 0.4241981506347656, "timer/agent.train_max": 1.3730747699737549, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47718024253845215, "timer/agent.report_frac": 0.00047697545169794335, "timer/agent.report_avg": 0.23859012126922607, "timer/agent.report_min": 0.2323598861694336, "timer/agent.report_max": 0.24482035636901855, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8836267133523005e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.806396538255115}
{"step": 431936, "time": 19370.9759619236, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 431976, "time": 19373.537594795227, "episode/length": 45.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 432160, "time": 19381.22102189064, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 432936, "time": 19407.54018354416, "episode/length": 232.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 432968, "time": 19410.16751933098, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 432968, "time": 19410.175239801407, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 433208, "time": 19421.227026224136, "episode/length": 256.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9883268482490273, "episode/intrinsic_return": 0.0}
{"step": 433424, "time": 19429.834615945816, "episode/length": 197.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 433456, "time": 19432.39843583107, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 433488, "time": 19434.935855150223, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 433776, "time": 19446.02415728569, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 434240, "time": 19464.55047774315, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 434320, "time": 19468.68651986122, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 434408, "time": 19472.88118314743, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 434440, "time": 19475.52535200119, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 434600, "time": 19482.213042974472, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 434784, "time": 19489.852565288544, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 435024, "time": 19499.086658477783, "episode/length": 195.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 435464, "time": 19514.565811872482, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 435560, "time": 19519.15919137001, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 435864, "time": 19530.668067216873, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 435976, "time": 19535.880552768707, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 436192, "time": 19544.705641508102, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 436248, "time": 19547.8065700531, "episode/length": 229.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 436264, "time": 19549.87970805168, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 436680, "time": 19564.740267038345, "episode/length": 51.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 436760, "time": 19568.840723991394, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 436952, "time": 19576.406814336777, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 437144, "time": 19584.097616910934, "episode/length": 197.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 437256, "time": 19589.384986639023, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 437448, "time": 19597.12917494774, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 437504, "time": 19600.618664741516, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 437512, "time": 19602.265603780746, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 437784, "time": 19612.55051088333, "episode/length": 33.0, "episode/score": 1.1000000163912773, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 438456, "time": 19635.72681760788, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 438456, "time": 19635.7346200943, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 438464, "time": 19639.27343773842, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 438808, "time": 19651.692773103714, "episode/length": 43.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 438872, "time": 19655.31896185875, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 438912, "time": 19658.276187181473, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 438984, "time": 19661.822036266327, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 438992, "time": 19663.861669540405, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 439056, "time": 19667.553646326065, "episode/length": 296.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 439104, "time": 19671.11385679245, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 439992, "time": 19701.87913942337, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 19719.697813272476, "eval_episode/length": 49.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.98}
{"step": 440024, "time": 19725.983650684357, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 440024, "time": 19728.39079761505, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 440024, "time": 19730.088099479675, "eval_episode/length": 192.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 440024, "time": 19731.617717027664, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 440024, "time": 19733.473952054977, "eval_episode/length": 203.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 440024, "time": 19735.697586536407, "eval_episode/length": 220.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 440024, "time": 19737.351536035538, "eval_episode/length": 224.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 440360, "time": 19748.300980567932, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 440400, "time": 19751.390782117844, "episode/length": 167.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 440416, "time": 19753.353635311127, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 440592, "time": 19760.4742705822, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 440600, "time": 19762.15387225151, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 440664, "time": 19765.697409152985, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 441280, "time": 19787.23728299141, "episode/length": 160.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 441496, "time": 19795.405719041824, "episode/length": 379.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 441696, "time": 19803.787588357925, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 441768, "time": 19807.324427843094, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 441904, "time": 19813.37695980072, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 442056, "time": 19819.651858329773, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 442112, "time": 19823.164321660995, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 442776, "time": 19847.27306485176, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 442888, "time": 19852.441286802292, "episode/length": 277.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 443344, "time": 19869.0441365242, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 443520, "time": 19876.164609909058, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 443536, "time": 19878.300792217255, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 443552, "time": 19880.35238623619, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 443768, "time": 19888.59634590149, "episode/length": 30.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 444160, "time": 19903.122643232346, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 444192, "time": 19905.841064214706, "episode/length": 266.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 444512, "time": 19917.553900957108, "episode/length": 216.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 444720, "time": 19925.84064269066, "episode/length": 429.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 444856, "time": 19931.513691425323, "episode/length": 86.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 444864, "time": 19933.479603290558, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 445144, "time": 19943.801131248474, "episode/length": 224.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 445400, "time": 19953.604418039322, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 445712, "time": 19965.28932404518, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 445888, "time": 19972.48263311386, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 446112, "time": 19981.311091423035, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 446152, "time": 19983.875828027725, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 446784, "time": 20005.87453007698, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 446920, "time": 20011.55178618431, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 446976, "time": 20015.026852846146, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 446984, "time": 20016.638890504837, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 447560, "time": 20036.691281080246, "episode/length": 180.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 447640, "time": 20040.842625141144, "episode/length": 311.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 447656, "time": 20042.982587575912, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 447896, "time": 20052.2665913105, "episode/length": 515.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 448000, "time": 20057.41247701645, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 448280, "time": 20067.749943971634, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 448696, "time": 20082.90126132965, "episode/length": 214.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 448792, "time": 20087.622037410736, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 448824, "time": 20090.143860816956, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 449040, "time": 20098.795029878616, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 449256, "time": 20107.23287463188, "episode/length": 156.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 449344, "time": 20111.7646586895, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 449432, "time": 20115.96882557869, "episode/length": 223.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 449608, "time": 20123.07498025894, "episode/length": 165.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 20152.51466012001, "eval_episode/length": 60.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 450008, "time": 20159.240988254547, "eval_episode/length": 145.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.958904109589041}
{"step": 450008, "time": 20161.35928416252, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 450008, "time": 20162.9551718235, "eval_episode/length": 154.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 450008, "time": 20164.937858104706, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 450008, "time": 20167.131499290466, "eval_episode/length": 179.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 450008, "time": 20169.195393562317, "eval_episode/length": 192.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 450008, "time": 20172.2798807621, "eval_episode/length": 227.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 450064, "time": 20174.31068444252, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 450096, "time": 20176.815013170242, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 450264, "time": 20183.532212734222, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.0}
{"step": 450696, "time": 20200.335175037384, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 451128, "time": 20215.8212788105, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 451288, "time": 20222.582460403442, "episode/length": 323.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 451376, "time": 20227.285711050034, "episode/length": 318.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 451416, "time": 20229.901195287704, "episode/length": 258.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 451472, "time": 20233.56165456772, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 451504, "time": 20236.096380472183, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 451512, "time": 20237.71507692337, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 451664, "time": 20244.39155101776, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 452256, "time": 20264.910383462906, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 452888, "time": 20286.628086328506, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 452960, "time": 20290.625749349594, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 453160, "time": 20298.427431344986, "episode/length": 217.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 453160, "time": 20298.434735298157, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 453168, "time": 20302.08219242096, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 453872, "time": 20326.39665412903, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 453912, "time": 20328.981710910797, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 454232, "time": 20340.74258208275, "episode/length": 339.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 454440, "time": 20349.15492963791, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 454464, "time": 20351.535865545273, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 454528, "time": 20354.987939357758, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 454704, "time": 20362.177596092224, "episode/length": 192.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 454817, "time": 20367.789500951767, "train_stats/sum_log_reward": 5.7666666269302365, "train_stats/max_log_achievement_collect_coal": 0.025, "train_stats/max_log_achievement_collect_drink": 5.783333333333333, "train_stats/max_log_achievement_collect_sapling": 2.783333333333333, "train_stats/max_log_achievement_collect_stone": 0.09166666666666666, "train_stats/max_log_achievement_collect_wood": 6.583333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.008333333333333333, "train_stats/max_log_achievement_defeat_zombie": 0.4583333333333333, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.6583333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.025, "train_stats/max_log_achievement_place_plant": 2.683333333333333, "train_stats/max_log_achievement_place_stone": 0.041666666666666664, "train_stats/max_log_achievement_place_table": 2.408333333333333, "train_stats/max_log_achievement_wake_up": 1.7083333333333333, "train_stats/mean_log_entropy": 0.504518432294329, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.207660381610577, "train/action_min": 0.0, "train/action_std": 3.991354843953273, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045205501005887154, "train/actor_opt_grad_steps": 27610.0, "train/actor_opt_loss": -3.123782564840325, "train/adv_mag": 0.6710738800205551, "train/adv_max": 0.6610582283326796, "train/adv_mean": 0.0034255492636303814, "train/adv_min": -0.477512749341818, "train/adv_std": 0.07130442330470452, "train/cont_avg": 0.9950010926573427, "train/cont_loss_mean": 0.00024289996353793746, "train/cont_loss_std": 0.007421156805882795, "train/cont_neg_acc": 0.9892191149138071, "train/cont_neg_loss": 0.02006250773884203, "train/cont_pos_acc": 0.9999725372641237, "train/cont_pos_loss": 0.00014923730603809404, "train/cont_pred": 0.9950113917564178, "train/cont_rate": 0.9950010926573427, "train/dyn_loss_mean": 13.510516680203951, "train/dyn_loss_std": 9.303538862641874, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8391057190361556, "train/extr_critic_critic_opt_grad_steps": 27610.0, "train/extr_critic_critic_opt_loss": 15446.670365767046, "train/extr_critic_mag": 5.524223944523952, "train/extr_critic_max": 5.524223944523952, "train/extr_critic_mean": 0.9230593659661033, "train/extr_critic_min": -0.2800736018827745, "train/extr_critic_std": 1.221180218916673, "train/extr_return_normed_mag": 1.8311062601062802, "train/extr_return_normed_max": 1.8311062601062802, "train/extr_return_normed_mean": 0.2750965225529837, "train/extr_return_normed_min": -0.13854609719002164, "train/extr_return_normed_std": 0.3378057701812757, "train/extr_return_rate": 0.424316657277254, "train/extr_return_raw_mag": 6.725598438636406, "train/extr_return_raw_max": 6.725598438636406, "train/extr_return_raw_mean": 0.9358009862733054, "train/extr_return_raw_min": -0.6032796254108003, "train/extr_return_raw_std": 1.2570793049318807, "train/extr_reward_mag": 1.0135272732981435, "train/extr_reward_max": 1.0135272732981435, "train/extr_reward_mean": 0.027025322325631873, "train/extr_reward_min": -0.40833539812714903, "train/extr_reward_std": 0.15352174113472025, "train/image_loss_mean": 7.159882625499805, "train/image_loss_std": 11.563627223034839, "train/model_loss_mean": 15.317235173045338, "train/model_loss_std": 15.393831059649274, "train/model_opt_grad_norm": 63.95890262577083, "train/model_opt_grad_steps": 27582.11888111888, "train/model_opt_loss": 12438.27744960118, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 812.9370629370629, "train/policy_entropy_mag": 2.562466156232607, "train/policy_entropy_max": 2.562466156232607, "train/policy_entropy_mean": 0.9038537749043711, "train/policy_entropy_min": 0.07937519590963017, "train/policy_entropy_std": 0.8317754443708834, "train/policy_logprob_mag": 7.438383159103927, "train/policy_logprob_max": -0.009455751028511074, "train/policy_logprob_mean": -0.9043822442734992, "train/policy_logprob_min": -7.438383159103927, "train/policy_logprob_std": 1.271386555024794, "train/policy_randomness_mag": 0.904438102995599, "train/policy_randomness_max": 0.904438102995599, "train/policy_randomness_mean": 0.3190207181276975, "train/policy_randomness_min": 0.02801596069825696, "train/policy_randomness_std": 0.29358022936157413, "train/post_ent_mag": 59.89625591998334, "train/post_ent_max": 59.89625591998334, "train/post_ent_mean": 42.247749862137375, "train/post_ent_min": 21.19388610999901, "train/post_ent_std": 7.6027747634407525, "train/prior_ent_mag": 69.11569619345498, "train/prior_ent_max": 69.11569619345498, "train/prior_ent_mean": 55.81537550812835, "train/prior_ent_min": 37.57600604237376, "train/prior_ent_std": 5.031871288806409, "train/rep_loss_mean": 13.510516680203951, "train/rep_loss_std": 9.303538862641874, "train/reward_avg": 0.02182856180145034, "train/reward_loss_mean": 0.05079966644150811, "train/reward_loss_std": 0.24134320562536066, "train/reward_max_data": 1.0111888138564316, "train/reward_max_pred": 1.0076387862225513, "train/reward_neg_acc": 0.9929888006690499, "train/reward_neg_loss": 0.02827742669106155, "train/reward_pos_acc": 0.9627325551493184, "train/reward_pos_loss": 0.8848971120127431, "train/reward_pred": 0.02111389192954435, "train/reward_rate": 0.02640133304195804, "eval_stats/sum_log_reward": 5.412500008940697, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 3.125, "eval_stats/max_log_achievement_collect_stone": 0.1875, "eval_stats/max_log_achievement_collect_wood": 5.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.0625, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.415762072720099e-07, "report/cont_loss_std": 7.861207450332586e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010010415280703455, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5353613491697615e-07, "report/cont_pred": 0.9951175451278687, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.386578559875488, "report/dyn_loss_std": 9.51465892791748, "report/image_loss_mean": 6.14007568359375, "report/image_loss_std": 11.420612335205078, "report/model_loss_mean": 13.607030868530273, "report/model_loss_std": 15.53505802154541, "report/post_ent_mag": 60.72430419921875, "report/post_ent_max": 60.72430419921875, "report/post_ent_mean": 42.46293640136719, "report/post_ent_min": 20.30510139465332, "report/post_ent_std": 7.730433464050293, "report/prior_ent_mag": 69.16680145263672, "report/prior_ent_max": 69.16680145263672, "report/prior_ent_mean": 54.956573486328125, "report/prior_ent_min": 33.495880126953125, "report/prior_ent_std": 5.30511474609375, "report/rep_loss_mean": 12.386578559875488, "report/rep_loss_std": 9.51465892791748, "report/reward_avg": 0.010449218563735485, "report/reward_loss_mean": 0.03500779718160629, "report/reward_loss_std": 0.14859265089035034, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029995441436768, "report/reward_neg_acc": 0.9940477013587952, "report/reward_neg_loss": 0.02463800087571144, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6883050203323364, "report/reward_pred": 0.012581245973706245, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0001609776954865083, "eval/cont_loss_std": 0.004170554690063, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010707966051995754, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00012998752936255187, "eval/cont_pred": 0.9969794750213623, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.0633602142334, "eval/dyn_loss_std": 10.446961402893066, "eval/image_loss_mean": 13.921163558959961, "eval/image_loss_std": 22.221385955810547, "eval/model_loss_mean": 24.250202178955078, "eval/model_loss_std": 26.099748611450195, "eval/post_ent_mag": 57.99427795410156, "eval/post_ent_max": 57.99427795410156, "eval/post_ent_mean": 41.5035400390625, "eval/post_ent_min": 22.88723373413086, "eval/post_ent_std": 7.595664978027344, "eval/prior_ent_mag": 69.16680145263672, "eval/prior_ent_max": 69.16680145263672, "eval/prior_ent_mean": 56.2635612487793, "eval/prior_ent_min": 33.49922180175781, "eval/prior_ent_std": 5.304272651672363, "eval/rep_loss_mean": 17.0633602142334, "eval/rep_loss_std": 10.446961402893066, "eval/reward_avg": 0.02851562574505806, "eval/reward_loss_mean": 0.09086272120475769, "eval/reward_loss_std": 0.6362727880477905, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0003693103790283, "eval/reward_neg_acc": 0.9939576983451843, "eval/reward_neg_loss": 0.03130248188972473, "eval/reward_pos_acc": 0.8064515590667725, "eval/reward_pos_loss": 1.9987114667892456, "eval/reward_pred": 0.02405492216348648, "eval/reward_rate": 0.0302734375, "replay/size": 454313.0, "replay/inserts": 22976.0, "replay/samples": 22976.0, "replay/insert_wait_avg": 1.312754944506462e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.55237752680659e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90656.0, "eval_replay/inserts": 3624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2095927139518014e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0068526268005, "timer/env.step_count": 2872.0, "timer/env.step_total": 259.3168361186981, "timer/env.step_frac": 0.25931505912937414, "timer/env.step_avg": 0.09029137747865533, "timer/env.step_min": 0.02248358726501465, "timer/env.step_max": 3.3798961639404297, "timer/replay._sample_count": 22976.0, "timer/replay._sample_total": 11.34953784942627, "timer/replay._sample_frac": 0.011349460075811982, "timer/replay._sample_avg": 0.0004939736180982882, "timer/replay._sample_min": 0.00037550926208496094, "timer/replay._sample_max": 0.009646415710449219, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3325.0, "timer/agent.policy_total": 51.13260221481323, "timer/agent.policy_frac": 0.05113225182457401, "timer/agent.policy_avg": 0.015378226230019018, "timer/agent.policy_min": 0.007955312728881836, "timer/agent.policy_max": 0.1537177562713623, "timer/dataset_train_count": 1436.0, "timer/dataset_train_total": 0.15053367614746094, "timer/dataset_train_frac": 0.00015053264460342618, "timer/dataset_train_avg": 0.00010482846528374717, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0010704994201660156, "timer/agent.train_count": 1436.0, "timer/agent.train_total": 624.9065861701965, "timer/agent.train_frac": 0.6249023039479208, "timer/agent.train_avg": 0.43517171738871624, "timer/agent.train_min": 0.4248924255371094, "timer/agent.train_max": 1.37109375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4756336212158203, "timer/agent.report_frac": 0.0004756303618984552, "timer/agent.report_avg": 0.23781681060791016, "timer/agent.report_min": 0.23073220252990723, "timer/agent.report_max": 0.24490141868591309, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6941114821071102e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 22.97557291209859}
{"step": 454880, "time": 20370.01656770706, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 455448, "time": 20389.71283698082, "episode/length": 70.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9154929577464789, "episode/intrinsic_return": 0.0}
{"step": 455560, "time": 20394.95260977745, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 455712, "time": 20401.78400325775, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 455744, "time": 20404.289041280746, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 455752, "time": 20405.835416316986, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702127659574468, "episode/intrinsic_return": 0.0}
{"step": 455888, "time": 20411.913192272186, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 456008, "time": 20417.05860185623, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 456504, "time": 20434.588090896606, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 456680, "time": 20441.798708200455, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9884393063583815, "episode/intrinsic_return": 0.0}
{"step": 457168, "time": 20459.1895840168, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 457192, "time": 20461.366822481155, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 457424, "time": 20470.68801188469, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 457496, "time": 20474.24978685379, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 457656, "time": 20480.881447076797, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 457792, "time": 20487.18094444275, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 457968, "time": 20495.244790554047, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 458224, "time": 20505.498949050903, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 458520, "time": 20516.58598256111, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 458880, "time": 20531.936073303223, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 458992, "time": 20537.100009202957, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 459048, "time": 20540.206078529358, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 459664, "time": 20561.762821674347, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 459816, "time": 20567.911192178726, "episode/length": 230.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 20597.704810619354, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 460096, "time": 20599.369005441666, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 460096, "time": 20601.189516305923, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 460096, "time": 20602.766583681107, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 460096, "time": 20604.433259248734, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 460096, "time": 20606.33965754509, "eval_episode/length": 182.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 460096, "time": 20607.820423841476, "eval_episode/length": 185.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 460096, "time": 20610.324782848358, "eval_episode/length": 208.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 460120, "time": 20610.89873814583, "episode/length": 37.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 460208, "time": 20615.650982379913, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 460216, "time": 20617.1695830822, "episode/length": 319.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 460216, "time": 20617.17720103264, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 460240, "time": 20621.176479816437, "episode/length": 169.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 460520, "time": 20631.492218494415, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 460712, "time": 20639.15908741951, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 460728, "time": 20641.261829853058, "episode/length": 444.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9977528089887641, "episode/intrinsic_return": 0.0}
{"step": 461152, "time": 20656.545456171036, "episode/length": 185.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 461368, "time": 20664.72480249405, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 461768, "time": 20679.057648181915, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 461864, "time": 20683.640630960464, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 461976, "time": 20688.8323264122, "episode/length": 157.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 461984, "time": 20690.809236764908, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 462024, "time": 20693.455771446228, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 462912, "time": 20723.813700199127, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 463224, "time": 20735.296438694, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 463256, "time": 20737.771060466766, "episode/length": 379.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9973684210526316, "episode/intrinsic_return": 0.0}
{"step": 463344, "time": 20742.413845300674, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 463400, "time": 20745.573543787003, "episode/length": 280.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 463472, "time": 20749.610215187073, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 463480, "time": 20751.213353395462, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 463560, "time": 20755.221359968185, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 464560, "time": 20789.401214838028, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 464648, "time": 20793.695871829987, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 464664, "time": 20795.64830350876, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 464728, "time": 20799.269476890564, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 464920, "time": 20806.971029043198, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 465048, "time": 20812.54019522667, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 465344, "time": 20823.773250102997, "episode/length": 303.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 465968, "time": 20845.456513404846, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 466208, "time": 20854.76633286476, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 466248, "time": 20857.257702112198, "episode/length": 149.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 466288, "time": 20860.31116080284, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 466336, "time": 20863.335108041763, "episode/length": 357.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 466408, "time": 20866.966677188873, "episode/length": 209.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 467504, "time": 20905.705727100372, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 467544, "time": 20908.80991101265, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 467640, "time": 20914.02337884903, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 467648, "time": 20916.391298294067, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 467736, "time": 20921.118106365204, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 468072, "time": 20933.528841733932, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 468408, "time": 20945.924477100372, "episode/length": 382.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9973890339425587, "episode/intrinsic_return": 0.0}
{"step": 468568, "time": 20952.567101478577, "episode/length": 455.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9978070175438597, "episode/intrinsic_return": 0.0}
{"step": 468872, "time": 20963.888384580612, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 469160, "time": 20974.7178003788, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 469168, "time": 20976.731521844864, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 469168, "time": 20976.74001288414, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 469192, "time": 20980.443061828613, "episode/length": 192.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 469504, "time": 20992.259671211243, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 469616, "time": 20997.390238046646, "episode/length": 55.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 469784, "time": 21004.291355848312, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21030.51964521408, "eval_episode/length": 55.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 470080, "time": 21036.62865638733, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 470080, "time": 21038.25256061554, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 470080, "time": 21039.856040239334, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 470080, "time": 21042.281111955643, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 470080, "time": 21043.835389852524, "eval_episode/length": 189.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 470080, "time": 21045.984944820404, "eval_episode/length": 206.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 470080, "time": 21048.198360204697, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 470096, "time": 21048.719794988632, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 470280, "time": 21056.059165239334, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 470440, "time": 21062.845468997955, "episode/length": 159.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 470568, "time": 21068.5485162735, "episode/length": 174.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 470752, "time": 21076.312355041504, "episode/length": 155.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 471016, "time": 21086.250443935394, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 471144, "time": 21092.045713424683, "episode/length": 169.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 471472, "time": 21104.317145824432, "episode/length": 148.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 471720, "time": 21113.641865968704, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 471896, "time": 21120.796678066254, "episode/length": 377.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 472304, "time": 21135.87303185463, "episode/length": 275.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 472368, "time": 21139.497454881668, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 472464, "time": 21144.161898851395, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 472616, "time": 21150.589433670044, "episode/length": 199.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 472848, "time": 21160.838339805603, "episode/length": 212.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 472872, "time": 21163.40212726593, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 473080, "time": 21172.244988918304, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 473136, "time": 21175.787932395935, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 473624, "time": 21192.85209608078, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 473712, "time": 21197.46829366684, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 473832, "time": 21202.531361103058, "episode/length": 170.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 473880, "time": 21205.702298402786, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 474104, "time": 21214.37225008011, "episode/length": 33.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 474224, "time": 21220.006910800934, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 474384, "time": 21226.70489168167, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 474568, "time": 21234.035121917725, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 474944, "time": 21247.9650182724, "episode/length": 225.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 475120, "time": 21255.108236074448, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 475232, "time": 21261.471445560455, "episode/length": 168.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 475336, "time": 21266.217105150223, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 475920, "time": 21286.874398946762, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 476224, "time": 21298.301953077316, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 476504, "time": 21308.603298187256, "episode/length": 284.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754385964912281, "episode/intrinsic_return": 0.0}
{"step": 476672, "time": 21315.807416200638, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 477040, "time": 21329.086526870728, "episode/length": 366.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9863760217983651, "episode/intrinsic_return": 0.0}
{"step": 477120, "time": 21333.296459674835, "episode/length": 55.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 477136, "time": 21335.402903795242, "episode/length": 237.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 477464, "time": 21347.410398960114, "episode/length": 314.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 477488, "time": 21349.95216035843, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 477488, "time": 21349.960058927536, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 477913, "time": 21367.91122841835, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.74319058122306, "train/action_min": 0.0, "train/action_std": 3.6370300128542143, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0444893728941679, "train/actor_opt_grad_steps": 29050.0, "train/actor_opt_loss": -5.703609649503026, "train/adv_mag": 0.6641027181312955, "train/adv_max": 0.6471325415989448, "train/adv_mean": 0.003434174160165953, "train/adv_min": -0.4781150665776483, "train/adv_std": 0.0704040016079771, "train/cont_avg": 0.9947198275862069, "train/cont_loss_mean": 0.00020410774460005683, "train/cont_loss_std": 0.005758523516404803, "train/cont_neg_acc": 0.9848002203579607, "train/cont_neg_loss": 0.023654058497539092, "train/cont_pos_acc": 0.9999660911231205, "train/cont_pos_loss": 9.490921617837416e-05, "train/cont_pred": 0.994727257613478, "train/cont_rate": 0.9947198275862069, "train/dyn_loss_mean": 13.611760830057078, "train/dyn_loss_std": 9.261338148445919, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.845725091161399, "train/extr_critic_critic_opt_grad_steps": 29050.0, "train/extr_critic_critic_opt_loss": 15674.427262931034, "train/extr_critic_mag": 5.595664455150736, "train/extr_critic_max": 5.595664455150736, "train/extr_critic_mean": 0.9631674404801993, "train/extr_critic_min": -0.28975089418477024, "train/extr_critic_std": 1.2454082715100256, "train/extr_return_normed_mag": 1.839689329574848, "train/extr_return_normed_max": 1.839689329574848, "train/extr_return_normed_mean": 0.2829362807602718, "train/extr_return_normed_min": -0.14095280630321338, "train/extr_return_normed_std": 0.3395804254145458, "train/extr_return_rate": 0.4414233350548251, "train/extr_return_raw_mag": 6.848069019975333, "train/extr_return_raw_max": 6.848069019975333, "train/extr_return_raw_mean": 0.9761119912410604, "train/extr_return_raw_min": -0.6228192501027009, "train/extr_return_raw_std": 1.280964730525839, "train/extr_reward_mag": 1.0144651445849189, "train/extr_reward_max": 1.0144651445849189, "train/extr_reward_mean": 0.028497871563866222, "train/extr_reward_min": -0.41153770150809454, "train/extr_reward_std": 0.1571504924317886, "train/image_loss_mean": 6.948437154704127, "train/image_loss_std": 11.501675401884935, "train/model_loss_mean": 15.16709213256836, "train/model_loss_std": 15.332900915474728, "train/model_opt_grad_norm": 57.761393790409485, "train/model_opt_grad_steps": 29021.51724137931, "train/model_opt_loss": 19089.27118130388, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.6206896551723, "train/policy_entropy_mag": 2.5627053770525703, "train/policy_entropy_max": 2.5627053770525703, "train/policy_entropy_mean": 0.7977315401208812, "train/policy_entropy_min": 0.07937515917523154, "train/policy_entropy_std": 0.7799217561195637, "train/policy_logprob_mag": 7.438383296440388, "train/policy_logprob_max": -0.009455740766535546, "train/policy_logprob_mean": -0.7973904338376275, "train/policy_logprob_min": -7.438383296440388, "train/policy_logprob_std": 1.2373947398415928, "train/policy_randomness_mag": 0.9045225377740531, "train/policy_randomness_max": 0.9045225377740531, "train/policy_randomness_mean": 0.28156422643825924, "train/policy_randomness_min": 0.02801594795851872, "train/policy_randomness_std": 0.2752781526795749, "train/post_ent_mag": 59.57514006516029, "train/post_ent_max": 59.57514006516029, "train/post_ent_mean": 42.081526052540745, "train/post_ent_min": 21.236419322572907, "train/post_ent_std": 7.554044427542851, "train/prior_ent_mag": 69.16753350619612, "train/prior_ent_max": 69.16753350619612, "train/prior_ent_mean": 55.75872434418777, "train/prior_ent_min": 37.39903774919181, "train/prior_ent_std": 4.977236711567846, "train/rep_loss_mean": 13.611760830057078, "train/rep_loss_std": 9.261338148445919, "train/reward_avg": 0.023663119502879422, "train/reward_loss_mean": 0.05139446929097176, "train/reward_loss_std": 0.24298436456713182, "train/reward_max_data": 1.008965519378925, "train/reward_max_pred": 1.0067017686778101, "train/reward_neg_acc": 0.9932837293065827, "train/reward_neg_loss": 0.027796180160908863, "train/reward_pos_acc": 0.966068971979207, "train/reward_pos_loss": 0.8629739189970083, "train/reward_pred": 0.023062231237518376, "train/reward_rate": 0.02841460129310345, "train_stats/sum_log_reward": 6.031034482450321, "train_stats/max_log_achievement_collect_coal": 0.06896551724137931, "train_stats/max_log_achievement_collect_drink": 4.870689655172414, "train_stats/max_log_achievement_collect_sapling": 2.6982758620689653, "train_stats/max_log_achievement_collect_stone": 0.46551724137931033, "train_stats/max_log_achievement_collect_wood": 7.9655172413793105, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.3620689655172414, "train_stats/max_log_achievement_eat_cow": 0.08620689655172414, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3620689655172413, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.6206896551724137, "train_stats/max_log_achievement_place_stone": 0.017241379310344827, "train_stats/max_log_achievement_place_table": 2.6724137931034484, "train_stats/max_log_achievement_wake_up": 1.4224137931034482, "train_stats/mean_log_entropy": 0.4238668571001497, "eval_stats/sum_log_reward": 5.599999938160181, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.6875, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 2.668676188477548e-06, "report/cont_loss_std": 2.9124084903742187e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001926214317791164, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.4829939775372623e-06, "report/cont_pred": 0.9990212321281433, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 14.011000633239746, "report/dyn_loss_std": 9.426201820373535, "report/image_loss_mean": 7.722413063049316, "report/image_loss_std": 13.453458786010742, "report/model_loss_mean": 16.175750732421875, "report/model_loss_std": 17.70479393005371, "report/post_ent_mag": 63.64719009399414, "report/post_ent_max": 63.64719009399414, "report/post_ent_mean": 41.05366897583008, "report/post_ent_min": 21.606657028198242, "report/post_ent_std": 7.624881744384766, "report/prior_ent_mag": 69.54129791259766, "report/prior_ent_max": 69.54129791259766, "report/prior_ent_mean": 55.55949401855469, "report/prior_ent_min": 33.992122650146484, "report/prior_ent_std": 6.0177788734436035, "report/rep_loss_mean": 14.011000633239746, "report/rep_loss_std": 9.426201820373535, "report/reward_avg": 0.02031249925494194, "report/reward_loss_mean": 0.0467352420091629, "report/reward_loss_std": 0.19251097738742828, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034966468811035, "report/reward_neg_acc": 0.9930069446563721, "report/reward_neg_loss": 0.029093315824866295, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8145425915718079, "report/reward_pred": 0.018997764214873314, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00023760745534673333, "eval/cont_loss_std": 0.005401317961513996, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.025637976825237274, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00013799815496895462, "eval/cont_pred": 0.996060848236084, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.757362365722656, "eval/dyn_loss_std": 10.997918128967285, "eval/image_loss_mean": 12.171432495117188, "eval/image_loss_std": 16.47551918029785, "eval/model_loss_mean": 22.325695037841797, "eval/model_loss_std": 21.046340942382812, "eval/post_ent_mag": 62.10102081298828, "eval/post_ent_max": 62.10102081298828, "eval/post_ent_mean": 42.12043762207031, "eval/post_ent_min": 20.554668426513672, "eval/post_ent_std": 8.375657081604004, "eval/prior_ent_mag": 69.54129791259766, "eval/prior_ent_max": 69.54129791259766, "eval/prior_ent_mean": 56.71824645996094, "eval/prior_ent_min": 38.77032470703125, "eval/prior_ent_std": 4.977749824523926, "eval/rep_loss_mean": 16.757362365722656, "eval/rep_loss_std": 10.997918128967285, "eval/reward_avg": 0.02187499962747097, "eval/reward_loss_mean": 0.09960676729679108, "eval/reward_loss_std": 0.6498512625694275, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006136894226074, "eval/reward_neg_acc": 0.9949849843978882, "eval/reward_neg_loss": 0.041052110493183136, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 2.261791706085205, "eval/reward_pred": 0.01812583953142166, "eval/reward_rate": 0.0263671875, "replay/size": 477409.0, "replay/inserts": 23096.0, "replay/samples": 23104.0, "replay/insert_wait_avg": 1.3013818415135383e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.722495830620425e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 94120.0, "eval_replay/inserts": 3464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1769508379436256e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1069688796997, "timer/env.step_count": 2887.0, "timer/env.step_total": 257.62222504615784, "timer/env.step_frac": 0.257594670432845, "timer/env.step_avg": 0.08923527019264213, "timer/env.step_min": 0.022814512252807617, "timer/env.step_max": 3.452354907989502, "timer/replay._sample_count": 23104.0, "timer/replay._sample_total": 11.540873527526855, "timer/replay._sample_frac": 0.011539639145255349, "timer/replay._sample_avg": 0.0004995184179158092, "timer/replay._sample_min": 0.0004134178161621094, "timer/replay._sample_max": 0.01097559928894043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3320.0, "timer/agent.policy_total": 49.953205585479736, "timer/agent.policy_frac": 0.04994786271856134, "timer/agent.policy_avg": 0.015046146260686668, "timer/agent.policy_min": 0.008318662643432617, "timer/agent.policy_max": 0.10868024826049805, "timer/dataset_train_count": 1444.0, "timer/dataset_train_total": 0.15282988548278809, "timer/dataset_train_frac": 0.000152813539189698, "timer/dataset_train_avg": 0.00010583787083295574, "timer/dataset_train_min": 8.869171142578125e-05, "timer/dataset_train_max": 0.0010716915130615234, "timer/agent.train_count": 1444.0, "timer/agent.train_total": 629.1053159236908, "timer/agent.train_frac": 0.629038028430501, "timer/agent.train_avg": 0.43566850133219587, "timer/agent.train_min": 0.42495012283325195, "timer/agent.train_max": 1.3610219955444336, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47973108291625977, "timer/agent.report_frac": 0.0004796797721084227, "timer/agent.report_avg": 0.23986554145812988, "timer/agent.report_min": 0.23374223709106445, "timer/agent.report_max": 0.2459888458251953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.956074172916789e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 23.093239990734578}
{"step": 477968, "time": 21369.637401103973, "episode/length": 328.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 478456, "time": 21386.651893377304, "episode/length": 60.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 478648, "time": 21394.515456199646, "episode/length": 147.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 478704, "time": 21398.067460775375, "episode/length": 207.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 478712, "time": 21399.559621810913, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 478720, "time": 21401.544443130493, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 478720, "time": 21401.55303955078, "episode/length": 276.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 479176, "time": 21419.167956590652, "episode/length": 210.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 479312, "time": 21425.370274543762, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 479888, "time": 21445.653967380524, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 479912, "time": 21447.642251491547, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 479944, "time": 21450.08271598816, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 21475.053681850433, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 480064, "time": 21477.289294719696, "eval_episode/length": 173.0, "eval_episode/score": 5.100000016391277, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 480064, "time": 21479.176966905594, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 480064, "time": 21481.679684638977, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 480064, "time": 21483.448496103287, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 480064, "time": 21485.726108312607, "eval_episode/length": 221.0, "eval_episode/score": 4.1000000312924385, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 480064, "time": 21487.60910487175, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 480064, "time": 21490.361338615417, "eval_episode/length": 261.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9809160305343512}
{"step": 480128, "time": 21492.439213752747, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 480416, "time": 21503.263476848602, "episode/length": 154.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 480568, "time": 21509.536019563675, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 481056, "time": 21526.874312877655, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 481528, "time": 21543.454275131226, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 481544, "time": 21545.550566911697, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 481560, "time": 21547.611855506897, "episode/length": 354.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9915492957746479, "episode/intrinsic_return": 0.0}
{"step": 481568, "time": 21549.571171045303, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 481960, "time": 21563.606947660446, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 482056, "time": 21568.221353292465, "episode/length": 63.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 482176, "time": 21573.782130479813, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 482176, "time": 21573.79119372368, "episode/length": 219.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 482664, "time": 21592.59869503975, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 483096, "time": 21608.191508054733, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 483176, "time": 21612.34494805336, "episode/length": 205.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 483208, "time": 21614.9704310894, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 483440, "time": 21625.474799394608, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 483616, "time": 21632.80020403862, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 483704, "time": 21636.97341156006, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 483792, "time": 21641.604105234146, "episode/length": 341.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9853801169590644, "episode/intrinsic_return": 0.0}
{"step": 483840, "time": 21644.622438669205, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 484672, "time": 21672.881042718887, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 484680, "time": 21674.485113620758, "episode/length": 110.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 484680, "time": 21674.49330163002, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 484816, "time": 21682.187834739685, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 484848, "time": 21684.797108888626, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 484896, "time": 21687.831557750702, "episode/length": 159.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 484976, "time": 21692.02432489395, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 485256, "time": 21702.348628282547, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 486032, "time": 21729.17090678215, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 486048, "time": 21731.730622053146, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 486304, "time": 21742.06145811081, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 486312, "time": 21743.554239988327, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 486320, "time": 21745.5255484581, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 486456, "time": 21751.337439775467, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 486496, "time": 21754.36125946045, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 487176, "time": 21777.47213935852, "episode/length": 239.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 487272, "time": 21782.248150110245, "episode/length": 96.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9381443298969072, "episode/intrinsic_return": 0.0}
{"step": 487416, "time": 21788.334864377975, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 487512, "time": 21792.97735476494, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 487880, "time": 21806.386104106903, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 488040, "time": 21813.092736005783, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 488416, "time": 21827.011066913605, "episode/length": 297.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 488536, "time": 21832.09942007065, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 488664, "time": 21837.7785923481, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 488720, "time": 21841.489597797394, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 488736, "time": 21843.428610801697, "episode/length": 106.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9345794392523364, "episode/intrinsic_return": 0.0}
{"step": 488880, "time": 21849.612436056137, "episode/length": 170.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 489088, "time": 21857.785299539566, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 489336, "time": 21867.212371587753, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 489448, "time": 21872.350833177567, "episode/length": 70.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 489656, "time": 21880.439752817154, "episode/length": 39.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 21908.840962171555, "eval_episode/length": 32.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8484848484848485}
{"step": 490048, "time": 21911.249648094177, "eval_episode/length": 54.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 490048, "time": 21911.25529193878, "eval_episode/length": 54.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 490048, "time": 21917.633506536484, "eval_episode/length": 138.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 490048, "time": 21919.68688416481, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 490048, "time": 21922.858216047287, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 490048, "time": 21925.808468341827, "eval_episode/length": 204.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 490048, "time": 21928.613924503326, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 490072, "time": 21929.18601512909, "episode/length": 51.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 490160, "time": 21933.850620746613, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 490200, "time": 21936.572334766388, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 490232, "time": 21939.08594083786, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 490368, "time": 21945.17297744751, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 490400, "time": 21947.717479228973, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 491080, "time": 21970.780343055725, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 491472, "time": 21985.123765468597, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 491688, "time": 21994.867941617966, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 491712, "time": 21997.40910601616, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 491896, "time": 22004.630665063858, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 491936, "time": 22007.651861190796, "episode/length": 355.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 492072, "time": 22013.39783191681, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 492176, "time": 22018.515262126923, "episode/length": 57.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 492200, "time": 22020.65574479103, "episode/length": 245.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 492528, "time": 22032.953505516052, "episode/length": 40.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 492712, "time": 22040.123762369156, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 493328, "time": 22061.816451072693, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 493344, "time": 22063.97237277031, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 493344, "time": 22063.980624437332, "episode/length": 206.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 493440, "time": 22070.177611112595, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 493816, "time": 22083.543437480927, "episode/length": 292.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 494008, "time": 22091.216178178787, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 494088, "time": 22095.366132497787, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 494088, "time": 22095.373797893524, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 494552, "time": 22113.37020921707, "episode/length": 152.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 494808, "time": 22123.15918469429, "episode/length": 182.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 495064, "time": 22132.999176979065, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 495144, "time": 22137.379703998566, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 495432, "time": 22148.243666887283, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 495496, "time": 22151.817266464233, "episode/length": 43.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 495624, "time": 22157.429631471634, "episode/length": 69.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 495656, "time": 22160.02880215645, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819494584837545, "episode/intrinsic_return": 0.0}
{"step": 495688, "time": 22162.59715628624, "episode/length": 199.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 495944, "time": 22172.354446172714, "episode/length": 231.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 496040, "time": 22176.925144195557, "episode/length": 185.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 496464, "time": 22192.28259086609, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 496896, "time": 22208.938577651978, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 497064, "time": 22215.595254659653, "episode/length": 175.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 497096, "time": 22218.141731977463, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 497176, "time": 22222.209427833557, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 497680, "time": 22240.49294757843, "episode/length": 216.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 497864, "time": 22247.73383831978, "episode/length": 271.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 498040, "time": 22254.916009902954, "episode/length": 117.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 498232, "time": 22262.780861854553, "episode/length": 220.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 498240, "time": 22264.696199417114, "episode/length": 274.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 498576, "time": 22277.139540195465, "episode/length": 41.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 498592, "time": 22279.229865074158, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 498600, "time": 22280.771309137344, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 498608, "time": 22282.84052824974, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 498720, "time": 22288.02912569046, "episode/length": 129.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 499112, "time": 22302.04887151718, "episode/length": 48.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 499400, "time": 22312.7638027668, "episode/length": 191.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 499688, "time": 22323.618652820587, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 499704, "time": 22325.66854763031, "episode/length": 137.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 499792, "time": 22331.57404947281, "episode/length": 84.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 499800, "time": 22333.13594865799, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 499992, "time": 22340.80681180954, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 22358.65083551407, "eval_episode/length": 56.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 500032, "time": 22363.3868663311, "eval_episode/length": 139.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 500032, "time": 22366.71359062195, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 500032, "time": 22368.329091072083, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9835164835164835}
{"step": 500032, "time": 22369.933385849, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 500032, "time": 22371.607818365097, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 500032, "time": 22373.51556634903, "eval_episode/length": 194.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 500032, "time": 22376.6612637043, "eval_episode/length": 234.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 500033, "time": 22377.2448220253, "train_stats/sum_log_reward": 6.018032750145334, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.19672131147541, "train_stats/max_log_achievement_collect_sapling": 2.3360655737704916, "train_stats/max_log_achievement_collect_stone": 0.7540983606557377, "train_stats/max_log_achievement_collect_wood": 8.401639344262295, "train_stats/max_log_achievement_defeat_skeleton": 0.01639344262295082, "train_stats/max_log_achievement_defeat_zombie": 0.5163934426229508, "train_stats/max_log_achievement_eat_cow": 0.07377049180327869, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4344262295081966, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.2295081967213113, "train_stats/max_log_achievement_place_stone": 0.00819672131147541, "train_stats/max_log_achievement_place_table": 2.6557377049180326, "train_stats/max_log_achievement_wake_up": 1.4098360655737705, "train_stats/mean_log_entropy": 0.3832525340382193, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.564037378283515, "train/action_min": 0.0, "train/action_std": 3.655575532844101, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045691052559709205, "train/actor_opt_grad_steps": 30465.0, "train/actor_opt_loss": -1.6872943526714284, "train/adv_mag": 0.6467602697835453, "train/adv_max": 0.6324002226625663, "train/adv_mean": 0.0038624237657896247, "train/adv_min": -0.46703471524128015, "train/adv_std": 0.07090608818807463, "train/cont_avg": 0.9948058197463768, "train/cont_loss_mean": 0.0003092380784729865, "train/cont_loss_std": 0.009224218474934747, "train/cont_neg_acc": 0.9943064200705376, "train/cont_neg_loss": 0.02546508755583183, "train/cont_pos_acc": 0.9999572889528413, "train/cont_pos_loss": 0.00016084614960579506, "train/cont_pred": 0.9947888496993245, "train/cont_rate": 0.9948058197463768, "train/dyn_loss_mean": 13.213898078255031, "train/dyn_loss_std": 9.333380256873975, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8641907101955967, "train/extr_critic_critic_opt_grad_steps": 30465.0, "train/extr_critic_critic_opt_loss": 15740.71095872962, "train/extr_critic_mag": 5.587603562120078, "train/extr_critic_max": 5.587603562120078, "train/extr_critic_mean": 0.9965804875760839, "train/extr_critic_min": -0.2667347374169723, "train/extr_critic_std": 1.2445501702419226, "train/extr_return_normed_mag": 1.8136244925899783, "train/extr_return_normed_max": 1.8136244925899783, "train/extr_return_normed_mean": 0.28799389205549075, "train/extr_return_normed_min": -0.14041616589478825, "train/extr_return_normed_std": 0.3375458199044932, "train/extr_return_rate": 0.4575431430037471, "train/extr_return_raw_mag": 6.800206526466038, "train/extr_return_raw_max": 6.800206526466038, "train/extr_return_raw_mean": 1.0112155416737432, "train/extr_return_raw_min": -0.6144128834855729, "train/extr_return_raw_std": 1.2809078792730968, "train/extr_reward_mag": 1.0183148245880569, "train/extr_reward_max": 1.0183148245880569, "train/extr_reward_mean": 0.029061338823774586, "train/extr_reward_min": -0.41311531395151996, "train/extr_reward_std": 0.15880495914514514, "train/image_loss_mean": 6.9026821281598965, "train/image_loss_std": 11.587331775305927, "train/model_loss_mean": 14.882666663847107, "train/model_loss_std": 15.392967120460842, "train/model_opt_grad_norm": 61.77346946882165, "train/model_opt_grad_steps": 30435.181159420288, "train/model_opt_loss": 18876.597351958786, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1268.1159420289855, "train/policy_entropy_mag": 2.5775841163552324, "train/policy_entropy_max": 2.5775841163552324, "train/policy_entropy_mean": 0.7956870008206022, "train/policy_entropy_min": 0.0793751457679099, "train/policy_entropy_std": 0.782621294260025, "train/policy_logprob_mag": 7.4383834237637725, "train/policy_logprob_max": -0.009455724416867546, "train/policy_logprob_mean": -0.7951591731845469, "train/policy_logprob_min": -7.4383834237637725, "train/policy_logprob_std": 1.2366174295328665, "train/policy_randomness_mag": 0.9097740792709849, "train/policy_randomness_max": 0.9097740792709849, "train/policy_randomness_mean": 0.2808425951263179, "train/policy_randomness_min": 0.0280159431901099, "train/policy_randomness_std": 0.2762309717743293, "train/post_ent_mag": 59.9352930870609, "train/post_ent_max": 59.9352930870609, "train/post_ent_mean": 42.507806308027625, "train/post_ent_min": 21.088379749353383, "train/post_ent_std": 7.623528888260108, "train/prior_ent_mag": 69.32453741543534, "train/prior_ent_max": 69.32453741543534, "train/prior_ent_mean": 55.79931098827417, "train/prior_ent_min": 37.52803550941357, "train/prior_ent_std": 5.030323660891989, "train/rep_loss_mean": 13.213898078255031, "train/rep_loss_std": 9.333380256873975, "train/reward_avg": 0.02341202424461211, "train/reward_loss_mean": 0.05133653410534928, "train/reward_loss_std": 0.24268234132424646, "train/reward_max_data": 1.0108695678088977, "train/reward_max_pred": 1.0072535535563594, "train/reward_neg_acc": 0.9937651140102441, "train/reward_neg_loss": 0.028191364781958037, "train/reward_pos_acc": 0.9655737958956456, "train/reward_pos_loss": 0.8553216288919034, "train/reward_pred": 0.02243906473133551, "train/reward_rate": 0.028136322463768116, "eval_stats/sum_log_reward": 5.183333257834117, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.083333333333333, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_stone": 0.041666666666666664, "eval_stats/max_log_achievement_collect_wood": 6.791666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8333333333333334, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9166666666666667, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.2083333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.44769648311194e-06, "report/cont_loss_std": 2.3052609321894124e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00020709563978016376, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.4533497910160804e-06, "report/cont_pred": 0.995114803314209, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.501862525939941, "report/dyn_loss_std": 9.302190780639648, "report/image_loss_mean": 5.183989524841309, "report/image_loss_std": 11.151604652404785, "report/model_loss_mean": 12.122990608215332, "report/model_loss_std": 14.98556900024414, "report/post_ent_mag": 61.57710266113281, "report/post_ent_max": 61.57710266113281, "report/post_ent_mean": 43.96058654785156, "report/post_ent_min": 20.068531036376953, "report/post_ent_std": 7.562723159790039, "report/prior_ent_mag": 69.07760620117188, "report/prior_ent_max": 69.07760620117188, "report/prior_ent_mean": 55.64351272583008, "report/prior_ent_min": 38.22984313964844, "report/prior_ent_std": 5.159104347229004, "report/rep_loss_mean": 11.501862525939941, "report/rep_loss_std": 9.302190780639648, "report/reward_avg": 0.01484375074505806, "report/reward_loss_mean": 0.0378791019320488, "report/reward_loss_std": 0.19399316608905792, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003462553024292, "report/reward_neg_acc": 0.9950249195098877, "report/reward_neg_loss": 0.020719794556498528, "report/reward_pos_acc": 0.9473684430122375, "report/reward_pos_loss": 0.9455161094665527, "report/reward_pred": 0.013057909905910492, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.727790681296028e-05, "eval/cont_loss_std": 0.001035159220919013, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.008919192478060722, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.446867483740789e-06, "eval/cont_pred": 0.9961255788803101, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.873497009277344, "eval/dyn_loss_std": 10.229493141174316, "eval/image_loss_mean": 10.611261367797852, "eval/image_loss_std": 14.74360466003418, "eval/model_loss_mean": 20.845874786376953, "eval/model_loss_std": 18.929895401000977, "eval/post_ent_mag": 59.44197082519531, "eval/post_ent_max": 59.44197082519531, "eval/post_ent_mean": 41.306297302246094, "eval/post_ent_min": 20.621986389160156, "eval/post_ent_std": 7.445488929748535, "eval/prior_ent_mag": 69.07760620117188, "eval/prior_ent_max": 69.07760620117188, "eval/prior_ent_mean": 56.458641052246094, "eval/prior_ent_min": 41.338531494140625, "eval/prior_ent_std": 4.763403415679932, "eval/rep_loss_mean": 16.873497009277344, "eval/rep_loss_std": 10.229493141174316, "eval/reward_avg": 0.03554687649011612, "eval/reward_loss_mean": 0.11047861725091934, "eval/reward_loss_std": 0.6750892996788025, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0102343559265137, "eval/reward_neg_acc": 0.9918699860572815, "eval/reward_neg_loss": 0.03973984718322754, "eval/reward_pos_acc": 0.7750000357627869, "eval/reward_pos_loss": 1.8506523370742798, "eval/reward_pred": 0.02645295485854149, "eval/reward_rate": 0.0390625, "replay/size": 499529.0, "replay/inserts": 22120.0, "replay/samples": 22112.0, "replay/insert_wait_avg": 1.3013213711233293e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.670432027272999e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 99808.0, "eval_replay/inserts": 5688.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2059251970379663e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1009.3187212944031, "timer/env.step_count": 2765.0, "timer/env.step_total": 258.9119107723236, "timer/env.step_frac": 0.25652145879180904, "timer/env.step_avg": 0.09363902740409534, "timer/env.step_min": 0.022963762283325195, "timer/env.step_max": 3.251692295074463, "timer/replay._sample_count": 22112.0, "timer/replay._sample_total": 11.00664472579956, "timer/replay._sample_frac": 0.010905023847852604, "timer/replay._sample_avg": 0.000497767941651572, "timer/replay._sample_min": 0.0004062652587890625, "timer/replay._sample_max": 0.008384227752685547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3476.0, "timer/agent.policy_total": 52.22230529785156, "timer/agent.policy_frac": 0.0517401532301699, "timer/agent.policy_avg": 0.015023678163938884, "timer/agent.policy_min": 0.008550405502319336, "timer/agent.policy_max": 0.11048007011413574, "timer/dataset_train_count": 1382.0, "timer/dataset_train_total": 0.14396333694458008, "timer/dataset_train_frac": 0.0001426341688777495, "timer/dataset_train_avg": 0.00010417028722473233, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0008325576782226562, "timer/agent.train_count": 1382.0, "timer/agent.train_total": 602.8837428092957, "timer/agent.train_frac": 0.5973175074332576, "timer/agent.train_avg": 0.4362400454481155, "timer/agent.train_min": 0.42222142219543457, "timer/agent.train_max": 1.7815027236938477, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47721409797668457, "timer/agent.report_frac": 0.00047280813078021605, "timer/agent.report_avg": 0.23860704898834229, "timer/agent.report_min": 0.2309408187866211, "timer/agent.report_max": 0.24627327919006348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.425151366001742e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 21.91550186772752}
{"step": 500440, "time": 22390.333859443665, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 501128, "time": 22414.091829061508, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 501192, "time": 22417.73348069191, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 501248, "time": 22421.242986679077, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 501448, "time": 22428.954356193542, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 501560, "time": 22434.148804187775, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 501648, "time": 22438.803903102875, "episode/length": 150.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 502000, "time": 22451.849198818207, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 502056, "time": 22455.07682466507, "episode/length": 50.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 502128, "time": 22459.13893675804, "episode/length": 441.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 502368, "time": 22468.554035425186, "episode/length": 370.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 502496, "time": 22474.21818614006, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 502504, "time": 22475.77222251892, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 502600, "time": 22480.271661758423, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 502624, "time": 22482.73203444481, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 503352, "time": 22507.57578778267, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 503856, "time": 22525.75705218315, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 503888, "time": 22528.28755044937, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 504016, "time": 22534.1008579731, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 504160, "time": 22540.29938840866, "episode/length": 223.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 504208, "time": 22543.38011288643, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 504496, "time": 22554.241920232773, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 504528, "time": 22556.87497997284, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 504872, "time": 22569.28413581848, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 505152, "time": 22580.054477214813, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 505216, "time": 22583.5284781456, "episode/length": 338.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 505376, "time": 22590.29341983795, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 505440, "time": 22594.121308088303, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 505464, "time": 22596.226824760437, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 505576, "time": 22601.285848855972, "episode/length": 430.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 505640, "time": 22604.811060667038, "episode/length": 52.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 505880, "time": 22614.002228975296, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 506008, "time": 22619.729254722595, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 506192, "time": 22627.449763774872, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 506232, "time": 22629.94734787941, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 506920, "time": 22653.692892551422, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 506960, "time": 22656.689388990402, "episode/length": 90.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 507328, "time": 22670.13203215599, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 507472, "time": 22676.374866485596, "episode/length": 236.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 507488, "time": 22678.391351938248, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 507808, "time": 22690.254825353622, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 507824, "time": 22692.244574546814, "episode/length": 297.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 507912, "time": 22696.653580904007, "episode/length": 305.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 508160, "time": 22707.783383131027, "episode/length": 43.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 508208, "time": 22710.822393894196, "episode/length": 155.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 508952, "time": 22736.222372293472, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 509024, "time": 22740.34702849388, "episode/length": 262.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 509064, "time": 22743.105058670044, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 509096, "time": 22745.73087787628, "episode/length": 202.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 509272, "time": 22752.882957696915, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 509424, "time": 22759.507709264755, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 509848, "time": 22774.427290201187, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 22781.435343503952, "episode/length": 225.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 22800.304244995117, "eval_episode/length": 157.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9810126582278481}
{"step": 510016, "time": 22802.614131450653, "eval_episode/length": 171.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 510016, "time": 22802.62102818489, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 510016, "time": 22806.415838241577, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 510016, "time": 22808.24702334404, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 510016, "time": 22811.3913333416, "eval_episode/length": 229.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 510016, "time": 22815.63527560234, "eval_episode/length": 294.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9864406779661017}
{"step": 510016, "time": 22818.945271492004, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 510304, "time": 22829.72569179535, "episode/length": 150.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 510480, "time": 22837.04213619232, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 510488, "time": 22838.548667669296, "episode/length": 182.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 510536, "time": 22841.585987329483, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 510760, "time": 22850.363127946854, "episode/length": 166.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 511248, "time": 22867.853773117065, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 511520, "time": 22878.135424137115, "episode/length": 187.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 511720, "time": 22885.856411218643, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 512000, "time": 22896.836161136627, "episode/length": 189.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 512112, "time": 22901.928333759308, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 512112, "time": 22901.94100379944, "episode/length": 394.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9898734177215189, "episode/intrinsic_return": 0.0}
{"step": 512512, "time": 22918.190690279007, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 512552, "time": 22920.858817100525, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 512704, "time": 22927.497906684875, "episode/length": 147.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 512912, "time": 22935.7260389328, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 512936, "time": 22937.90456199646, "episode/length": 151.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 513416, "time": 22954.92409992218, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 513656, "time": 22964.12638258934, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 513688, "time": 22966.655116796494, "episode/length": 96.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 513696, "time": 22968.645133256912, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 514200, "time": 22986.648504257202, "episode/length": 205.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 514248, "time": 22989.701851129532, "episode/length": 266.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 514352, "time": 22994.96222615242, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 514432, "time": 22998.973342180252, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 514544, "time": 23004.06405901909, "episode/length": 106.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 514888, "time": 23016.494215011597, "episode/length": 66.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 514904, "time": 23018.531622171402, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 514952, "time": 23021.541401863098, "episode/length": 64.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 515232, "time": 23032.29884815216, "episode/length": 40.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 515248, "time": 23034.234607219696, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 515256, "time": 23035.881145715714, "episode/length": 131.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 515648, "time": 23050.463251829147, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 515720, "time": 23054.175343751907, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 516400, "time": 23078.992645025253, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 516432, "time": 23081.735647201538, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 516528, "time": 23086.34592270851, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 516640, "time": 23091.470005512238, "episode/length": 218.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 516672, "time": 23094.00729393959, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 516760, "time": 23098.115395784378, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 517016, "time": 23107.979154586792, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 517192, "time": 23115.71506381035, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 517912, "time": 23140.638373613358, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 518168, "time": 23150.56105017662, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 518192, "time": 23153.11545777321, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 518224, "time": 23155.59301996231, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 518384, "time": 23162.254898786545, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 518520, "time": 23167.92243218422, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 518600, "time": 23171.967101335526, "episode/length": 270.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 518648, "time": 23175.00816464424, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 519432, "time": 23201.764800071716, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 519536, "time": 23206.88897252083, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 519824, "time": 23217.718646526337, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 519840, "time": 23219.76589369774, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 519960, "time": 23225.03941011429, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 23242.633540391922, "eval_episode/length": 48.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 520000, "time": 23242.6409406662, "eval_episode/length": 48.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 520000, "time": 23246.119020938873, "eval_episode/length": 55.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 520000, "time": 23253.000086307526, "eval_episode/length": 187.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 520000, "time": 23254.80951976776, "eval_episode/length": 196.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 520000, "time": 23254.816920757294, "eval_episode/length": 196.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 520000, "time": 23262.298133850098, "eval_episode/length": 244.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 520000, "time": 23264.1446955204, "eval_episode/length": 256.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.980544747081712}
{"step": 520040, "time": 23265.24003791809, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 520080, "time": 23268.303914308548, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 520312, "time": 23277.03905439377, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 520680, "time": 23290.514976263046, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 521344, "time": 23313.619881868362, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 521360, "time": 23315.632685661316, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 521600, "time": 23324.977766275406, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 23327.10711979866, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 521960, "time": 23339.519245624542, "episode/length": 234.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 522624, "time": 23362.74173617363, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 522624, "time": 23362.7499191761, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 522736, "time": 23369.66689348221, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 522864, "time": 23375.460859775543, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 522865, "time": 23377.605088233948, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.491667634123689, "train/action_min": 0.0, "train/action_std": 3.5941236936129055, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045075533794356394, "train/actor_opt_grad_steps": 31870.0, "train/actor_opt_loss": -1.5565170829112713, "train/adv_mag": 0.6617241380931614, "train/adv_max": 0.650076306783236, "train/adv_mean": 0.004073704028640706, "train/adv_min": -0.45808560385570657, "train/adv_std": 0.07031042993693919, "train/cont_avg": 0.9951718203671329, "train/cont_loss_mean": 0.0002167552213917178, "train/cont_loss_std": 0.0064298547110611505, "train/cont_neg_acc": 0.9909590420189437, "train/cont_neg_loss": 0.02872039071005204, "train/cont_pos_acc": 0.9999793797106176, "train/cont_pos_loss": 7.965588767885637e-05, "train/cont_pred": 0.9951832711279809, "train/cont_rate": 0.9951718203671329, "train/dyn_loss_mean": 13.183318291510735, "train/dyn_loss_std": 9.310110979146891, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.899542098278766, "train/extr_critic_critic_opt_grad_steps": 31870.0, "train/extr_critic_critic_opt_loss": 15932.191228693182, "train/extr_critic_mag": 5.601249704827795, "train/extr_critic_max": 5.601249704827795, "train/extr_critic_mean": 1.0095574276430623, "train/extr_critic_min": -0.25076822300890944, "train/extr_critic_std": 1.2251992930065503, "train/extr_return_normed_mag": 1.8220434463941133, "train/extr_return_normed_max": 1.8220434463941133, "train/extr_return_normed_mean": 0.2851525381520078, "train/extr_return_normed_min": -0.13598056145377094, "train/extr_return_normed_std": 0.33236812075951716, "train/extr_return_rate": 0.4795873644468668, "train/extr_return_raw_mag": 6.8545089968434585, "train/extr_return_raw_max": 6.8545089968434585, "train/extr_return_raw_mean": 1.024987189086167, "train/extr_return_raw_min": -0.5724616786399921, "train/extr_return_raw_std": 1.2610483565530577, "train/extr_reward_mag": 1.0169056345532823, "train/extr_reward_max": 1.0169056345532823, "train/extr_reward_mean": 0.028695175841033874, "train/extr_reward_min": -0.39826336523869654, "train/extr_reward_std": 0.1573397654753465, "train/image_loss_mean": 6.605954710420195, "train/image_loss_std": 11.065670163481386, "train/model_loss_mean": 14.567265350501854, "train/model_loss_std": 14.908651872114701, "train/model_opt_grad_norm": 58.52638994230257, "train/model_opt_grad_steps": 31838.664335664336, "train/model_opt_loss": 18318.974889368445, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.7412587412587, "train/policy_entropy_mag": 2.5831568391173034, "train/policy_entropy_max": 2.5831568391173034, "train/policy_entropy_mean": 0.7311048632735139, "train/policy_entropy_min": 0.07937513031325974, "train/policy_entropy_std": 0.7548215781058465, "train/policy_logprob_mag": 7.438383472549332, "train/policy_logprob_max": -0.009455717116646417, "train/policy_logprob_mean": -0.7316114256432006, "train/policy_logprob_min": -7.438383472549332, "train/policy_logprob_std": 1.2088614935641522, "train/policy_randomness_mag": 0.9117410066244486, "train/policy_randomness_max": 0.9117410066244486, "train/policy_randomness_mean": 0.2580479341787058, "train/policy_randomness_min": 0.028015937994826923, "train/policy_randomness_std": 0.26641889145741093, "train/post_ent_mag": 59.79452976146778, "train/post_ent_max": 59.79452976146778, "train/post_ent_mean": 42.66345977783203, "train/post_ent_min": 20.96711008031885, "train/post_ent_std": 7.6467792337591, "train/prior_ent_mag": 69.39154853020514, "train/prior_ent_max": 69.39154853020514, "train/prior_ent_mean": 55.885740320165674, "train/prior_ent_min": 37.826277406065614, "train/prior_ent_std": 4.910045098591517, "train/rep_loss_mean": 13.183318291510735, "train/rep_loss_std": 9.310110979146891, "train/reward_avg": 0.02351330298200979, "train/reward_loss_mean": 0.05110296949587919, "train/reward_loss_std": 0.24359149996425722, "train/reward_max_data": 1.0104895129904046, "train/reward_max_pred": 1.007482181895863, "train/reward_neg_acc": 0.9934845654280869, "train/reward_neg_loss": 0.027571800542617594, "train/reward_pos_acc": 0.9610437925878939, "train/reward_pos_loss": 0.8755980267391338, "train/reward_pred": 0.022620373014751432, "train/reward_rate": 0.027972027972027972, "train_stats/sum_log_reward": 6.250000009934108, "train_stats/max_log_achievement_collect_coal": 0.058333333333333334, "train_stats/max_log_achievement_collect_drink": 5.241666666666666, "train_stats/max_log_achievement_collect_sapling": 2.066666666666667, "train_stats/max_log_achievement_collect_stone": 0.7916666666666666, "train_stats/max_log_achievement_collect_wood": 8.141666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.05, "train_stats/max_log_achievement_defeat_zombie": 0.5166666666666667, "train_stats/max_log_achievement_eat_cow": 0.058333333333333334, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.275, "train_stats/max_log_achievement_make_wood_sword": 0.008333333333333333, "train_stats/max_log_achievement_place_plant": 2.0166666666666666, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.7916666666666665, "train_stats/max_log_achievement_wake_up": 1.4416666666666667, "train_stats/mean_log_entropy": 0.34588236833612124, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01098901098901099, "eval_stats/sum_log_reward": 5.97500005364418, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 1.6875, "eval_stats/max_log_achievement_collect_wood": 7.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.1, "train_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 9.865638276096433e-06, "report/cont_loss_std": 0.00026639754651114345, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0024705093819648027, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.1605434596949635e-07, "report/cont_pred": 0.9961031675338745, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.334329605102539, "report/dyn_loss_std": 9.33913803100586, "report/image_loss_mean": 7.706716537475586, "report/image_loss_std": 9.981221199035645, "report/model_loss_mean": 15.144989013671875, "report/model_loss_std": 13.893330574035645, "report/post_ent_mag": 61.0648307800293, "report/post_ent_max": 61.0648307800293, "report/post_ent_mean": 43.970245361328125, "report/post_ent_min": 22.121570587158203, "report/post_ent_std": 7.6725592613220215, "report/prior_ent_mag": 69.32550048828125, "report/prior_ent_max": 69.32550048828125, "report/prior_ent_mean": 56.314266204833984, "report/prior_ent_min": 36.82060241699219, "report/prior_ent_std": 5.4932169914245605, "report/rep_loss_mean": 12.334329605102539, "report/rep_loss_std": 9.33913803100586, "report/reward_avg": 0.01835937425494194, "report/reward_loss_mean": 0.03766456991434097, "report/reward_loss_std": 0.17089886963367462, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.050689697265625, "report/reward_neg_acc": 0.9950099587440491, "report/reward_neg_loss": 0.023670140653848648, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6750472187995911, "report/reward_pred": 0.01899719424545765, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 5.267587039270438e-05, "eval/cont_loss_std": 0.0012987806694582105, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02345362864434719, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.881448825879488e-06, "eval/cont_pred": 0.9980850219726562, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.429100036621094, "eval/dyn_loss_std": 10.384008407592773, "eval/image_loss_mean": 10.198772430419922, "eval/image_loss_std": 14.106091499328613, "eval/model_loss_mean": 20.735637664794922, "eval/model_loss_std": 18.305858612060547, "eval/post_ent_mag": 57.04307556152344, "eval/post_ent_max": 57.04307556152344, "eval/post_ent_mean": 40.3311767578125, "eval/post_ent_min": 22.332115173339844, "eval/post_ent_std": 6.942665100097656, "eval/prior_ent_mag": 69.32550048828125, "eval/prior_ent_max": 69.32550048828125, "eval/prior_ent_mean": 55.8076171875, "eval/prior_ent_min": 41.117767333984375, "eval/prior_ent_std": 4.511762619018555, "eval/rep_loss_mean": 17.429100036621094, "eval/rep_loss_std": 10.384008407592773, "eval/reward_avg": 0.03046874888241291, "eval/reward_loss_mean": 0.07935214042663574, "eval/reward_loss_std": 0.42449212074279785, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0041768550872803, "eval/reward_neg_acc": 0.9838219285011292, "eval/reward_neg_loss": 0.03666425496339798, "eval/reward_pos_acc": 0.8571428656578064, "eval/reward_pos_loss": 1.2855898141860962, "eval/reward_pred": 0.03099871426820755, "eval/reward_rate": 0.0341796875, "replay/size": 522361.0, "replay/inserts": 22832.0, "replay/samples": 22832.0, "replay/insert_wait_avg": 1.3077935724719555e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.882578521653665e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5160.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.15660733954851e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.296401023864746e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3440847396851, "timer/env.step_count": 2854.0, "timer/env.step_total": 260.08237075805664, "timer/env.step_frac": 0.25999291116489853, "timer/env.step_avg": 0.09112907174423848, "timer/env.step_min": 0.022681236267089844, "timer/env.step_max": 3.349977731704712, "timer/replay._sample_count": 22832.0, "timer/replay._sample_total": 11.479446411132812, "timer/replay._sample_frac": 0.01147549786743634, "timer/replay._sample_avg": 0.0005027788372079893, "timer/replay._sample_min": 0.00039458274841308594, "timer/replay._sample_max": 0.010947465896606445, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3499.0, "timer/agent.policy_total": 52.052043437957764, "timer/agent.policy_frac": 0.05203413928468725, "timer/agent.policy_avg": 0.01487626277163697, "timer/agent.policy_min": 0.008430957794189453, "timer/agent.policy_max": 0.08957266807556152, "timer/dataset_train_count": 1427.0, "timer/dataset_train_total": 0.14798331260681152, "timer/dataset_train_frac": 0.00014793241132157097, "timer/dataset_train_avg": 0.00010370239145536898, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0003180503845214844, "timer/agent.train_count": 1427.0, "timer/agent.train_total": 619.1229362487793, "timer/agent.train_frac": 0.6189099787698458, "timer/agent.train_avg": 0.43386330500965614, "timer/agent.train_min": 0.4258871078491211, "timer/agent.train_max": 1.3051567077636719, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47745633125305176, "timer/agent.report_frac": 0.00047729210232426975, "timer/agent.report_avg": 0.23872816562652588, "timer/agent.report_min": 0.23236608505249023, "timer/agent.report_max": 0.24509024620056152, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.291534423828125e-05, "timer/dataset_eval_frac": 4.290058280241534e-08, "timer/dataset_eval_avg": 4.291534423828125e-05, "timer/dataset_eval_min": 4.291534423828125e-05, "timer/dataset_eval_max": 4.291534423828125e-05, "fps": 22.82374528667419}
{"step": 523040, "time": 23383.3589322567, "episode/length": 437.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 523240, "time": 23391.033398389816, "episode/length": 201.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 523592, "time": 23403.867875814438, "episode/length": 248.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 523712, "time": 23409.505311727524, "episode/length": 58.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 524256, "time": 23428.55951333046, "episode/length": 203.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 524312, "time": 23433.102949380875, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 524328, "time": 23435.25983786583, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 524488, "time": 23441.84060907364, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 525128, "time": 23463.850692033768, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 525168, "time": 23466.825906276703, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 525224, "time": 23469.89616894722, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 525704, "time": 23486.68300151825, "episode/length": 151.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 525888, "time": 23494.446632623672, "episode/length": 203.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 525952, "time": 23497.950984716415, "episode/length": 401.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 526000, "time": 23501.0608420372, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 526000, "time": 23501.069620370865, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 526520, "time": 23520.899987459183, "episode/length": 173.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 526632, "time": 23526.0530834198, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 526816, "time": 23533.566224575043, "episode/length": 205.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 527128, "time": 23544.877824544907, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 527168, "time": 23547.97472691536, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 527176, "time": 23549.509645700455, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 527264, "time": 23554.06309390068, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 527296, "time": 23556.554268836975, "episode/length": 198.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 527792, "time": 23574.359305143356, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 527976, "time": 23582.102032661438, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 528056, "time": 23586.16487979889, "episode/length": 115.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 528280, "time": 23594.87854576111, "episode/length": 205.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 528504, "time": 23603.643807649612, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 528768, "time": 23613.871485471725, "episode/length": 88.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 529000, "time": 23622.53697323799, "episode/length": 216.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 529016, "time": 23624.5116045475, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 529016, "time": 23624.51944541931, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 529312, "time": 23637.28947520256, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 23683.49777650833, "eval_episode/length": 142.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.951048951048951}
{"step": 530088, "time": 23686.2085852623, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9631901840490797}
{"step": 530088, "time": 23687.94345855713, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 530088, "time": 23689.811292409897, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 530088, "time": 23691.6844496727, "eval_episode/length": 175.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 530088, "time": 23693.169367313385, "eval_episode/length": 176.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 530088, "time": 23693.177290439606, "eval_episode/length": 176.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9887005649717514}
{"step": 530088, "time": 23697.09300637245, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 530360, "time": 23705.926994085312, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 530424, "time": 23709.50684070587, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 530424, "time": 23709.51528096199, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 530432, "time": 23713.060439109802, "episode/length": 406.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 530608, "time": 23720.1947183609, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 530648, "time": 23722.820288181305, "episode/length": 267.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9664179104477612, "episode/intrinsic_return": 0.0}
{"step": 530848, "time": 23730.944899082184, "episode/length": 52.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 531144, "time": 23741.951365470886, "episode/length": 357.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 531224, "time": 23745.980535030365, "episode/length": 238.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 531648, "time": 23761.495795965195, "episode/length": 129.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 531752, "time": 23766.166611909866, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 532048, "time": 23777.365790605545, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 532400, "time": 23790.161039352417, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.0}
{"step": 532504, "time": 23796.211601018906, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 532672, "time": 23803.436504125595, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 532784, "time": 23808.5809237957, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 532824, "time": 23811.088561058044, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 532944, "time": 23816.645164489746, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 533016, "time": 23820.35709810257, "episode/length": 42.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 533248, "time": 23829.65469288826, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 533768, "time": 23847.76503109932, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 534008, "time": 23857.22516131401, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 534216, "time": 23865.400026082993, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 534240, "time": 23868.010022878647, "episode/length": 181.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 534464, "time": 23876.742973804474, "episode/length": 244.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 534632, "time": 23883.60692000389, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 535456, "time": 23911.784855127335, "episode/length": 210.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 535536, "time": 23915.82146215439, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 535832, "time": 23926.58037996292, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 535832, "time": 23926.58813548088, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 535952, "time": 23933.877047538757, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 535968, "time": 23935.989725351334, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 536128, "time": 23942.750453948975, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 536168, "time": 23945.22360086441, "episode/length": 417.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 536792, "time": 23966.802715063095, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 537104, "time": 23978.674956560135, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 537184, "time": 23982.82622909546, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 537560, "time": 23996.22084593773, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 537568, "time": 23998.316112041473, "episode/length": 201.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 537840, "time": 24008.657818078995, "episode/length": 287.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 538200, "time": 24021.461057424545, "episode/length": 175.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 538240, "time": 24024.51273727417, "episode/length": 258.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 538584, "time": 24036.934019327164, "episode/length": 343.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 539096, "time": 24054.962749004364, "episode/length": 238.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 539096, "time": 24054.97089076042, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 539104, "time": 24058.620409727097, "episode/length": 249.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 24091.226304531097, "episode/length": 233.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 24106.327286958694, "eval_episode/length": 64.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 540072, "time": 24111.330721855164, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 540072, "time": 24113.150269269943, "eval_episode/length": 154.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 540072, "time": 24115.549384832382, "eval_episode/length": 174.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 540072, "time": 24115.55626988411, "eval_episode/length": 174.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 540072, "time": 24122.755296707153, "eval_episode/length": 270.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.996309963099631}
{"step": 540072, "time": 24125.199836969376, "eval_episode/length": 295.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9763513513513513}
{"step": 540072, "time": 24126.952031850815, "eval_episode/length": 153.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 540104, "time": 24129.425288677216, "episode/length": 189.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 540528, "time": 24144.69914674759, "episode/length": 285.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 540768, "time": 24155.443536281586, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 540976, "time": 24163.55990767479, "episode/length": 426.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 541272, "time": 24174.278739452362, "episode/length": 428.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 541568, "time": 24185.57129406929, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 541744, "time": 24192.712176322937, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 541896, "time": 24198.865545749664, "episode/length": 140.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 542160, "time": 24209.08140230179, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 542208, "time": 24212.233261823654, "episode/length": 388.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768637532133676, "episode/intrinsic_return": 0.0}
{"step": 542536, "time": 24224.15871334076, "episode/length": 46.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 542736, "time": 24232.39588212967, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 542904, "time": 24239.080969572067, "episode/length": 475.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9978991596638656, "episode/intrinsic_return": 0.0}
{"step": 542944, "time": 24242.232222557068, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 542984, "time": 24244.825557231903, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 543080, "time": 24249.49825668335, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 543528, "time": 24265.54896378517, "episode/length": 123.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 543800, "time": 24275.834351301193, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 543904, "time": 24280.8572101593, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 544432, "time": 24299.375375032425, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 544504, "time": 24303.045315504074, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 544512, "time": 24304.945101499557, "episode/length": 178.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 545232, "time": 24329.438657045364, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 545648, "time": 24344.352014303207, "episode/length": 342.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 545800, "time": 24350.563503026962, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 545864, "time": 24354.27472305298, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 546152, "time": 24365.10210800171, "episode/length": 426.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 546336, "time": 24372.770623922348, "episode/length": 303.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 546425, "time": 24377.929941654205, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.492680763711735, "train/action_min": 0.0, "train/action_std": 3.4794396137704653, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04579919926366027, "train/actor_opt_grad_steps": 33320.0, "train/actor_opt_loss": -2.6994871947230124, "train/adv_mag": 0.6499018689402106, "train/adv_max": 0.6301609754156904, "train/adv_mean": 0.004013482366298419, "train/adv_min": -0.46350230469184667, "train/adv_std": 0.07022649736530116, "train/cont_avg": 0.9947119472789115, "train/cont_loss_mean": 0.00022935918557508633, "train/cont_loss_std": 0.006859168563829483, "train/cont_neg_acc": 0.9950599297374284, "train/cont_neg_loss": 0.025132573648376393, "train/cont_pos_acc": 0.9999799408069273, "train/cont_pos_loss": 7.659257316643424e-05, "train/cont_pred": 0.9947239610613609, "train/cont_rate": 0.9947119472789115, "train/dyn_loss_mean": 13.343373052116965, "train/dyn_loss_std": 9.370589502814676, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8521500258218675, "train/extr_critic_critic_opt_grad_steps": 33320.0, "train/extr_critic_critic_opt_loss": 16013.629836309523, "train/extr_critic_mag": 5.6697037755226605, "train/extr_critic_max": 5.6697037755226605, "train/extr_critic_mean": 1.102724283325429, "train/extr_critic_min": -0.24754521798114387, "train/extr_critic_std": 1.2560898641339775, "train/extr_return_normed_mag": 1.7959665757458225, "train/extr_return_normed_max": 1.7959665757458225, "train/extr_return_normed_mean": 0.2979853811109958, "train/extr_return_normed_min": -0.13200326927867875, "train/extr_return_normed_std": 0.33403030524448474, "train/extr_return_rate": 0.5053899429079627, "train/extr_return_raw_mag": 6.907656838293789, "train/extr_return_raw_max": 6.907656838293789, "train/extr_return_raw_mean": 1.1182522025643562, "train/extr_return_raw_min": -0.5435363914893598, "train/extr_return_raw_std": 1.2910202863265057, "train/extr_reward_mag": 1.0189375455687646, "train/extr_reward_max": 1.0189375455687646, "train/extr_reward_mean": 0.03000750861504451, "train/extr_reward_min": -0.42222345361904223, "train/extr_reward_std": 0.1608827124748911, "train/image_loss_mean": 6.641321621784548, "train/image_loss_std": 11.126990960568797, "train/model_loss_mean": 14.700776982469623, "train/model_loss_std": 15.035090971966179, "train/model_opt_grad_norm": 60.66720053267805, "train/model_opt_grad_steps": 33287.360544217685, "train/model_opt_loss": 18605.387024340987, "train/model_opt_model_opt_grad_overflow": 0.006802721088435374, "train/model_opt_model_opt_grad_scale": 1258.5034013605443, "train/policy_entropy_mag": 2.5734028816223145, "train/policy_entropy_max": 2.5734028816223145, "train/policy_entropy_mean": 0.6741812364990208, "train/policy_entropy_min": 0.07937512551846147, "train/policy_entropy_std": 0.730353832244873, "train/policy_logprob_mag": 7.438383455990123, "train/policy_logprob_max": -0.009455709059272899, "train/policy_logprob_mean": -0.6729401520320347, "train/policy_logprob_min": -7.438383455990123, "train/policy_logprob_std": 1.1798204248454296, "train/policy_randomness_mag": 0.9082982864509634, "train/policy_randomness_max": 0.9082982864509634, "train/policy_randomness_mean": 0.2379563905957605, "train/policy_randomness_min": 0.028015936135637517, "train/policy_randomness_std": 0.257782849831646, "train/post_ent_mag": 60.10545660524952, "train/post_ent_max": 60.10545660524952, "train/post_ent_mean": 42.67028538710406, "train/post_ent_min": 20.83354090995529, "train/post_ent_std": 7.656651402817292, "train/prior_ent_mag": 69.33688136509487, "train/prior_ent_max": 69.33688136509487, "train/prior_ent_mean": 56.026511808641914, "train/prior_ent_min": 38.14645560906858, "train/prior_ent_std": 4.870073788831023, "train/rep_loss_mean": 13.343373052116965, "train/rep_loss_std": 9.370589502814676, "train/reward_avg": 0.024050674768684267, "train/reward_loss_mean": 0.053202365772152434, "train/reward_loss_std": 0.2518420136299263, "train/reward_max_data": 1.0163265345047932, "train/reward_max_pred": 1.006724374634879, "train/reward_neg_acc": 0.9928586381633265, "train/reward_neg_loss": 0.029081813515905216, "train/reward_pos_acc": 0.9617594298051328, "train/reward_pos_loss": 0.8742930585024308, "train/reward_pred": 0.023299863815408984, "train/reward_rate": 0.02878534226190476, "train_stats/sum_log_reward": 6.56788991569379, "train_stats/max_log_achievement_collect_coal": 0.09174311926605505, "train_stats/max_log_achievement_collect_drink": 6.174311926605505, "train_stats/max_log_achievement_collect_sapling": 2.2477064220183487, "train_stats/max_log_achievement_collect_stone": 1.4770642201834863, "train_stats/max_log_achievement_collect_wood": 9.495412844036696, "train_stats/max_log_achievement_defeat_skeleton": 0.03669724770642202, "train_stats/max_log_achievement_defeat_zombie": 0.5045871559633027, "train_stats/max_log_achievement_eat_cow": 0.08256880733944955, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8990825688073394, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.01834862385321101, "train_stats/max_log_achievement_place_plant": 2.128440366972477, "train_stats/max_log_achievement_place_stone": 0.01834862385321101, "train_stats/max_log_achievement_place_table": 3.1192660550458715, "train_stats/max_log_achievement_wake_up": 1.385321100917431, "train_stats/mean_log_entropy": 0.36009502014435757, "eval_stats/sum_log_reward": 5.912499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.125, "eval_stats/max_log_achievement_collect_sapling": 2.6875, "eval_stats/max_log_achievement_collect_stone": 0.4375, "eval_stats/max_log_achievement_collect_wood": 5.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 2.7220445190323517e-05, "report/cont_loss_std": 0.0005333711160346866, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.3951382647501305e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.7160762329003774e-05, "report/cont_pred": 0.9911845326423645, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 13.08340835571289, "report/dyn_loss_std": 9.540257453918457, "report/image_loss_mean": 8.096223831176758, "report/image_loss_std": 17.2597599029541, "report/model_loss_mean": 16.004371643066406, "report/model_loss_std": 21.02460479736328, "report/post_ent_mag": 62.056640625, "report/post_ent_max": 62.056640625, "report/post_ent_mean": 43.352691650390625, "report/post_ent_min": 20.79315185546875, "report/post_ent_std": 8.546131134033203, "report/prior_ent_mag": 69.72195434570312, "report/prior_ent_max": 69.72195434570312, "report/prior_ent_mean": 56.70277786254883, "report/prior_ent_min": 39.77824401855469, "report/prior_ent_std": 5.16083288192749, "report/rep_loss_mean": 13.08340835571289, "report/rep_loss_std": 9.540257453918457, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.05807541310787201, "report/reward_loss_std": 0.2366114854812622, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001631736755371, "report/reward_neg_acc": 0.9899396300315857, "report/reward_neg_loss": 0.03457566350698471, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8367007374763489, "report/reward_pred": 0.021796371787786484, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00023909927404019982, "eval/cont_loss_std": 0.004650916904211044, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.027887864038348198, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00010343315079808235, "eval/cont_pred": 0.995144248008728, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.273609161376953, "eval/dyn_loss_std": 10.920716285705566, "eval/image_loss_mean": 14.267461776733398, "eval/image_loss_std": 20.861934661865234, "eval/model_loss_mean": 24.72745132446289, "eval/model_loss_std": 25.26025390625, "eval/post_ent_mag": 59.29167938232422, "eval/post_ent_max": 59.29167938232422, "eval/post_ent_mean": 42.160240173339844, "eval/post_ent_min": 22.655256271362305, "eval/post_ent_std": 7.598443984985352, "eval/prior_ent_mag": 69.72195434570312, "eval/prior_ent_max": 69.72195434570312, "eval/prior_ent_mean": 57.328285217285156, "eval/prior_ent_min": 42.1419677734375, "eval/prior_ent_std": 4.690546989440918, "eval/rep_loss_mean": 17.273609161376953, "eval/rep_loss_std": 10.920716285705566, "eval/reward_avg": 0.01416015625, "eval/reward_loss_mean": 0.09558475017547607, "eval/reward_loss_std": 0.7239255905151367, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011186599731445, "eval/reward_neg_acc": 0.9950199723243713, "eval/reward_neg_loss": 0.04143276438117027, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.8140146732330322, "eval/reward_pred": 0.009144308976829052, "eval/reward_rate": 0.01953125, "replay/size": 545921.0, "replay/inserts": 23560.0, "replay/samples": 23568.0, "replay/insert_wait_avg": 1.3207033251258837e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.856745988595915e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1407732963562011e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3106362819672, "timer/env.step_count": 2945.0, "timer/env.step_total": 242.17162442207336, "timer/env.step_frac": 0.24209642049013474, "timer/env.step_avg": 0.08223145141666328, "timer/env.step_min": 0.02208542823791504, "timer/env.step_max": 3.3566930294036865, "timer/replay._sample_count": 23568.0, "timer/replay._sample_total": 11.880624532699585, "timer/replay._sample_frac": 0.011876935125730962, "timer/replay._sample_avg": 0.0005040998189366762, "timer/replay._sample_min": 0.0003986358642578125, "timer/replay._sample_max": 0.01092386245727539, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3445.0, "timer/agent.policy_total": 52.66010355949402, "timer/agent.policy_frac": 0.052643750500569714, "timer/agent.policy_avg": 0.015285951686355303, "timer/agent.policy_min": 0.008333921432495117, "timer/agent.policy_max": 0.20125317573547363, "timer/dataset_train_count": 1473.0, "timer/dataset_train_total": 0.1511526107788086, "timer/dataset_train_frac": 0.0001511056718747133, "timer/dataset_train_avg": 0.00010261548593266029, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.0002300739288330078, "timer/agent.train_count": 1473.0, "timer/agent.train_total": 639.3183131217957, "timer/agent.train_frac": 0.639119779329813, "timer/agent.train_avg": 0.434024652492733, "timer/agent.train_min": 0.422696590423584, "timer/agent.train_max": 1.4023265838623047, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4786531925201416, "timer/agent.report_frac": 0.00047850455164531416, "timer/agent.report_avg": 0.2393265962600708, "timer/agent.report_min": 0.23347043991088867, "timer/agent.report_max": 0.24518275260925293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0508101201872773e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 23.552326956470093}
{"step": 546608, "time": 24383.800098896027, "episode/length": 384.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9974025974025974, "episode/intrinsic_return": 0.0}
{"step": 546656, "time": 24386.98300409317, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 546856, "time": 24394.876289606094, "episode/length": 131.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 547256, "time": 24409.523123264313, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 547280, "time": 24412.09423470497, "episode/length": 203.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 547408, "time": 24417.77535390854, "episode/length": 99.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 547456, "time": 24420.676202058792, "episode/length": 377.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9867724867724867, "episode/intrinsic_return": 0.0}
{"step": 547712, "time": 24430.44304084778, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 547936, "time": 24439.05376648903, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 548208, "time": 24449.313556194305, "episode/length": 115.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 548232, "time": 24451.350541830063, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 548256, "time": 24453.752049684525, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 548936, "time": 24478.03101992607, "episode/length": 87.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 548944, "time": 24480.029503583908, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 548960, "time": 24482.18295955658, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 549160, "time": 24489.815227985382, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 549456, "time": 24501.163898944855, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 549576, "time": 24506.28325033188, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 549624, "time": 24509.30844926834, "episode/length": 238.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 549832, "time": 24517.690056562424, "episode/length": 110.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 24541.19626379013, "eval_episode/length": 50.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 550056, "time": 24547.572206020355, "eval_episode/length": 164.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 550056, "time": 24549.764455080032, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 550056, "time": 24549.770956277847, "eval_episode/length": 184.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 550056, "time": 24554.52788710594, "eval_episode/length": 222.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 550056, "time": 24556.383584022522, "eval_episode/length": 232.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 550056, "time": 24558.818001270294, "eval_episode/length": 205.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 550056, "time": 24563.957585573196, "eval_episode/length": 182.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 550168, "time": 24567.537121772766, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 550568, "time": 24581.878304243088, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 550624, "time": 24585.394748449326, "episode/length": 130.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 550656, "time": 24587.917050123215, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 551096, "time": 24603.401077508926, "episode/length": 204.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 551336, "time": 24612.581299304962, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 551408, "time": 24616.589965343475, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 551456, "time": 24619.86658525467, "episode/length": 228.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 551944, "time": 24636.903282165527, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 552096, "time": 24643.591381072998, "episode/length": 190.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 552688, "time": 24664.137938261032, "episode/length": 159.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 553152, "time": 24680.37200665474, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 553160, "time": 24681.98769569397, "episode/length": 312.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 553264, "time": 24687.1193087101, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 553312, "time": 24690.218604326248, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 553320, "time": 24692.010617017746, "episode/length": 336.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 553368, "time": 24694.990800619125, "episode/length": 158.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 554440, "time": 24730.93302178383, "episode/length": 218.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 554456, "time": 24732.93025660515, "episode/length": 419.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 554752, "time": 24744.42298436165, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 554752, "time": 24744.431610107422, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 554800, "time": 24749.09126353264, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 555592, "time": 24775.851009130478, "episode/length": 304.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 555696, "time": 24780.903675556183, "episode/length": 154.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 556024, "time": 24792.818637371063, "episode/length": 357.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 556184, "time": 24799.496328115463, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 556224, "time": 24802.434926509857, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 556608, "time": 24816.399506807327, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 556864, "time": 24826.21379494667, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 557328, "time": 24844.73785829544, "episode/length": 203.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 557328, "time": 24844.747708559036, "episode/length": 315.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 557584, "time": 24857.25194311142, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 557688, "time": 24862.531549453735, "episode/length": 187.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 557960, "time": 24873.683718442917, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 558360, "time": 24888.875256299973, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 558464, "time": 24893.92956495285, "episode/length": 358.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9972144846796658, "episode/intrinsic_return": 0.0}
{"step": 558480, "time": 24895.960301876068, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 559216, "time": 24921.7915225029, "episode/length": 235.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 559320, "time": 24926.41148352623, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 559432, "time": 24931.60532927513, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 559648, "time": 24940.329948425293, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 559688, "time": 24942.890606164932, "episode/length": 294.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.976271186440678, "episode/intrinsic_return": 0.0}
{"step": 559696, "time": 24944.89385676384, "episode/length": 59.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 24976.04983997345, "eval_episode/length": 148.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 560040, "time": 24978.247775793076, "eval_episode/length": 163.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 560040, "time": 24981.388018369675, "eval_episode/length": 200.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9651741293532339}
{"step": 560040, "time": 24983.383822202682, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 560040, "time": 24985.87061738968, "eval_episode/length": 233.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 560040, "time": 24987.80981707573, "eval_episode/length": 244.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 560040, "time": 24995.899583101273, "eval_episode/length": 355.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9915730337078652}
{"step": 560040, "time": 24997.739597558975, "eval_episode/length": 360.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9861495844875346}
{"step": 560312, "time": 25006.52096414566, "episode/length": 327.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 560440, "time": 25012.128942489624, "episode/length": 139.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 560592, "time": 25018.708660125732, "episode/length": 265.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 560920, "time": 25030.52218770981, "episode/length": 40.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 561056, "time": 25036.65696501732, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 561384, "time": 25048.466324329376, "episode/length": 362.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9972451790633609, "episode/intrinsic_return": 0.0}
{"step": 561464, "time": 25052.63728952408, "episode/length": 253.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 561528, "time": 25056.290984869003, "episode/length": 229.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 561568, "time": 25059.351553678513, "episode/length": 239.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 561856, "time": 25070.228786230087, "episode/length": 176.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 562264, "time": 25084.67299580574, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 562584, "time": 25096.560428142548, "episode/length": 190.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 562632, "time": 25099.705171108246, "episode/length": 289.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 562720, "time": 25104.252353429794, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 562776, "time": 25107.370128154755, "episode/length": 155.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 563136, "time": 25120.75434780121, "episode/length": 195.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 563160, "time": 25122.850056886673, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 563744, "time": 25143.28147172928, "episode/length": 235.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 563904, "time": 25149.86900115013, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 563912, "time": 25151.38379740715, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 564016, "time": 25156.44470834732, "episode/length": 328.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9848024316109423, "episode/intrinsic_return": 0.0}
{"step": 564320, "time": 25167.678946971893, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 564520, "time": 25175.416421175003, "episode/length": 217.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 564640, "time": 25181.082686662674, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 564832, "time": 25188.84684586525, "episode/length": 115.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 565032, "time": 25196.60502576828, "episode/length": 139.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 565352, "time": 25209.887883663177, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 565408, "time": 25213.335690259933, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 565480, "time": 25216.863926649094, "episode/length": 289.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 565488, "time": 25218.932147741318, "episode/length": 56.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 565848, "time": 25231.810959339142, "episode/length": 61.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 565920, "time": 25235.970983028412, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 566192, "time": 25246.327845096588, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 566240, "time": 25249.38180565834, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 566528, "time": 25260.22828435898, "episode/length": 250.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 567064, "time": 25278.82968235016, "episode/length": 196.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 567248, "time": 25286.501204013824, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 567360, "time": 25291.771245718002, "episode/length": 188.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 567784, "time": 25306.721759319305, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 567888, "time": 25311.80809044838, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 568272, "time": 25325.615105628967, "episode/length": 253.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 568472, "time": 25333.276273965836, "episode/length": 382.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9895561357702349, "episode/intrinsic_return": 0.0}
{"step": 568592, "time": 25338.762887716293, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 568592, "time": 25338.77304983139, "episode/length": 388.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948586118251928, "episode/intrinsic_return": 0.0}
{"step": 568816, "time": 25349.150285959244, "episode/length": 181.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 569320, "time": 25366.719895601273, "episode/length": 281.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 569593, "time": 25378.098066329956, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.433342874461207, "train/action_min": 0.0, "train/action_std": 3.3674178945607154, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04489898363064075, "train/actor_opt_grad_steps": 34780.0, "train/actor_opt_loss": -3.874117438649309, "train/adv_mag": 0.6085807004879261, "train/adv_max": 0.5788590203071463, "train/adv_mean": 0.0038414216439534733, "train/adv_min": -0.4578718300523429, "train/adv_std": 0.06852531700298704, "train/cont_avg": 0.9947265625, "train/cont_loss_mean": 0.00020360220597342112, "train/cont_loss_std": 0.006244905452271707, "train/cont_neg_acc": 0.9915845665438422, "train/cont_neg_loss": 0.02716696846651632, "train/cont_pos_acc": 0.9999796698833334, "train/cont_pos_loss": 7.897998236947207e-05, "train/cont_pred": 0.9947512429336022, "train/cont_rate": 0.9947265625, "train/dyn_loss_mean": 13.060134453609072, "train/dyn_loss_std": 9.315359996927196, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8189775413480298, "train/extr_critic_critic_opt_grad_steps": 34780.0, "train/extr_critic_critic_opt_loss": 15935.709273976294, "train/extr_critic_mag": 5.7788390093836295, "train/extr_critic_max": 5.7788390093836295, "train/extr_critic_mean": 1.2091308770508602, "train/extr_critic_min": -0.270792974274734, "train/extr_critic_std": 1.328885803140443, "train/extr_return_normed_mag": 1.7669521159139172, "train/extr_return_normed_max": 1.7669521159139172, "train/extr_return_normed_mean": 0.3145090479275276, "train/extr_return_normed_min": -0.1468125776997928, "train/extr_return_normed_std": 0.3386813422729229, "train/extr_return_rate": 0.5446493654415525, "train/extr_return_raw_mag": 7.0830673316429404, "train/extr_return_raw_max": 7.0830673316429404, "train/extr_return_raw_mean": 1.2246411475641974, "train/extr_return_raw_min": -0.6364167645059783, "train/extr_return_raw_std": 1.3667108457663963, "train/extr_reward_mag": 1.0156890129220897, "train/extr_reward_max": 1.0156890129220897, "train/extr_reward_mean": 0.030813461208137972, "train/extr_reward_min": -0.44673650840233115, "train/extr_reward_std": 0.16477867549863354, "train/image_loss_mean": 6.395447701421277, "train/image_loss_std": 10.817800936205634, "train/model_loss_mean": 14.283926792802482, "train/model_loss_std": 14.694485052700701, "train/model_opt_grad_norm": 57.32654017744393, "train/model_opt_grad_steps": 34745.87586206896, "train/model_opt_loss": 19001.362351831896, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1327.5862068965516, "train/policy_entropy_mag": 2.5870951027705753, "train/policy_entropy_max": 2.5870951027705753, "train/policy_entropy_mean": 0.6514583784958412, "train/policy_entropy_min": 0.07937511406068144, "train/policy_entropy_std": 0.728917070092826, "train/policy_logprob_mag": 7.438383572677086, "train/policy_logprob_max": -0.00945570569100051, "train/policy_logprob_mean": -0.6511420038239709, "train/policy_logprob_min": -7.438383572677086, "train/policy_logprob_std": 1.1690744490459049, "train/policy_randomness_mag": 0.9131310409513013, "train/policy_randomness_max": 0.9131310409513013, "train/policy_randomness_mean": 0.22993621857001864, "train/policy_randomness_min": 0.02801593191407878, "train/policy_randomness_std": 0.25727573653747293, "train/post_ent_mag": 60.466635394918505, "train/post_ent_max": 60.466635394918505, "train/post_ent_mean": 42.98609253455852, "train/post_ent_min": 21.08183118885961, "train/post_ent_std": 7.739442818740319, "train/prior_ent_mag": 69.44604081778691, "train/prior_ent_max": 69.44604081778691, "train/prior_ent_mean": 56.121038713126346, "train/prior_ent_min": 38.50629359278186, "train/prior_ent_std": 4.8206459111180795, "train/rep_loss_mean": 13.060134453609072, "train/rep_loss_std": 9.315359996927196, "train/reward_avg": 0.02532125523249651, "train/reward_loss_mean": 0.052194993942976, "train/reward_loss_std": 0.244474141042808, "train/reward_max_data": 1.0131034513999675, "train/reward_max_pred": 1.0068686172879975, "train/reward_neg_acc": 0.9935546488597475, "train/reward_neg_loss": 0.027611116236396904, "train/reward_pos_acc": 0.9674273375807138, "train/reward_pos_loss": 0.849443635447272, "train/reward_pred": 0.024550090954992276, "train/reward_rate": 0.029990571120689657, "train_stats/sum_log_reward": 6.687156013392527, "train_stats/max_log_achievement_collect_coal": 0.28440366972477066, "train_stats/max_log_achievement_collect_drink": 5.990825688073395, "train_stats/max_log_achievement_collect_sapling": 1.889908256880734, "train_stats/max_log_achievement_collect_stone": 2.1376146788990824, "train_stats/max_log_achievement_collect_wood": 9.36697247706422, "train_stats/max_log_achievement_defeat_skeleton": 0.045871559633027525, "train_stats/max_log_achievement_defeat_zombie": 0.5412844036697247, "train_stats/max_log_achievement_eat_cow": 0.06422018348623854, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7889908256880733, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.8073394495412844, "train_stats/max_log_achievement_place_stone": 0.01834862385321101, "train_stats/max_log_achievement_place_table": 2.6605504587155964, "train_stats/max_log_achievement_wake_up": 1.2568807339449541, "train_stats/mean_log_entropy": 0.3486805385269156, "eval_stats/sum_log_reward": 6.725000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 8.0625, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 4.125, "eval_stats/max_log_achievement_collect_wood": 8.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.363177362800343e-06, "report/cont_loss_std": 9.555049473419785e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0012569039827212691, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.2705974345171853e-07, "report/cont_pred": 0.9951231479644775, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.899120330810547, "report/dyn_loss_std": 10.146503448486328, "report/image_loss_mean": 6.7627129554748535, "report/image_loss_std": 12.782881736755371, "report/model_loss_mean": 15.159364700317383, "report/model_loss_std": 17.229747772216797, "report/post_ent_mag": 61.200016021728516, "report/post_ent_max": 61.200016021728516, "report/post_ent_mean": 42.598060607910156, "report/post_ent_min": 21.40688133239746, "report/post_ent_std": 8.343377113342285, "report/prior_ent_mag": 69.20753479003906, "report/prior_ent_max": 69.20753479003906, "report/prior_ent_mean": 56.31785202026367, "report/prior_ent_min": 35.946258544921875, "report/prior_ent_std": 4.908543109893799, "report/rep_loss_mean": 13.899120330810547, "report/rep_loss_std": 10.146503448486328, "report/reward_avg": 0.03408202901482582, "report/reward_loss_mean": 0.05717436224222183, "report/reward_loss_std": 0.22690925002098083, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001823902130127, "report/reward_neg_acc": 0.9918699860572815, "report/reward_neg_loss": 0.029435740783810616, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7395445108413696, "report/reward_pred": 0.03359987959265709, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.4135875921492698e-06, "eval/cont_loss_std": 6.187926192069426e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010989960283041, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.94442435486053e-07, "eval/cont_pred": 0.9970733523368835, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.753345489501953, "eval/dyn_loss_std": 10.472648620605469, "eval/image_loss_mean": 12.394916534423828, "eval/image_loss_std": 19.283220291137695, "eval/model_loss_mean": 22.521995544433594, "eval/model_loss_std": 23.195600509643555, "eval/post_ent_mag": 58.072750091552734, "eval/post_ent_max": 58.072750091552734, "eval/post_ent_mean": 41.7996940612793, "eval/post_ent_min": 20.188135147094727, "eval/post_ent_std": 7.478433609008789, "eval/prior_ent_mag": 69.20753479003906, "eval/prior_ent_max": 69.20753479003906, "eval/prior_ent_mean": 56.72087860107422, "eval/prior_ent_min": 38.777130126953125, "eval/prior_ent_std": 4.620134353637695, "eval/rep_loss_mean": 16.753345489501953, "eval/rep_loss_std": 10.472648620605469, "eval/reward_avg": 0.02812499925494194, "eval/reward_loss_mean": 0.07506629824638367, "eval/reward_loss_std": 0.5288695693016052, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0016405582427979, "eval/reward_neg_acc": 0.9899193048477173, "eval/reward_neg_loss": 0.022652922198176384, "eval/reward_pos_acc": 0.84375, "eval/reward_pos_loss": 1.6998810768127441, "eval/reward_pred": 0.02478570118546486, "eval/reward_rate": 0.03125, "replay/size": 569089.0, "replay/inserts": 23168.0, "replay/samples": 23168.0, "replay/insert_wait_avg": 1.3233733605284717e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.850689124007251e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1299241581151448e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.155312538147, "timer/env.step_count": 2896.0, "timer/env.step_total": 244.0015664100647, "timer/env.step_frac": 0.24396367579236172, "timer/env.step_avg": 0.08425468453386212, "timer/env.step_min": 0.022312164306640625, "timer/env.step_max": 3.963623523712158, "timer/replay._sample_count": 23168.0, "timer/replay._sample_total": 11.75143027305603, "timer/replay._sample_frac": 0.011749605412017264, "timer/replay._sample_avg": 0.0005072267901008301, "timer/replay._sample_min": 0.00037217140197753906, "timer/replay._sample_max": 0.028361797332763672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3605.0, "timer/agent.policy_total": 55.23803353309631, "timer/agent.policy_frac": 0.055229455706150114, "timer/agent.policy_avg": 0.01532261679142755, "timer/agent.policy_min": 0.008385658264160156, "timer/agent.policy_max": 0.1160590648651123, "timer/dataset_train_count": 1448.0, "timer/dataset_train_total": 0.1526777744293213, "timer/dataset_train_frac": 0.00015265406533897504, "timer/dataset_train_avg": 0.00010544045195395117, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0009303092956542969, "timer/agent.train_count": 1448.0, "timer/agent.train_total": 629.4971392154694, "timer/agent.train_frac": 0.6293993855993838, "timer/agent.train_avg": 0.434735593380849, "timer/agent.train_min": 0.4222753047943115, "timer/agent.train_max": 1.5436768531799316, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48152732849121094, "timer/agent.report_frac": 0.00048145255287322685, "timer/agent.report_avg": 0.24076366424560547, "timer/agent.report_min": 0.23471832275390625, "timer/agent.report_max": 0.2468090057373047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.814697265625e-05, "timer/dataset_eval_frac": 3.814104887314192e-08, "timer/dataset_eval_avg": 3.814697265625e-05, "timer/dataset_eval_min": 3.814697265625e-05, "timer/dataset_eval_max": 3.814697265625e-05, "fps": 23.16408772335181}
{"step": 569632, "time": 25379.301498413086, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 569792, "time": 25386.054100751877, "episode/length": 149.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 569928, "time": 25391.75701570511, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 569984, "time": 25395.365844249725, "episode/length": 274.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 25418.612174272537, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 570024, "time": 25420.38288617134, "eval_episode/length": 189.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.968421052631579}
{"step": 570024, "time": 25423.495339632034, "eval_episode/length": 225.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 570024, "time": 25423.50321006775, "eval_episode/length": 225.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 570024, "time": 25427.817997694016, "eval_episode/length": 58.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 570024, "time": 25430.097016334534, "eval_episode/length": 267.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9738805970149254}
{"step": 570024, "time": 25431.67890715599, "eval_episode/length": 268.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9814126394052045}
{"step": 570024, "time": 25435.818821668625, "eval_episode/length": 62.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 570032, "time": 25436.323184728622, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 570336, "time": 25447.78538918495, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 570672, "time": 25460.154598236084, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 570920, "time": 25469.500853061676, "episode/length": 199.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 571264, "time": 25482.793531179428, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 571288, "time": 25485.42938566208, "episode/length": 351.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 571336, "time": 25489.061354398727, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 571408, "time": 25493.110768795013, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 571672, "time": 25503.09783768654, "episode/length": 234.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 572208, "time": 25522.11115169525, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 572272, "time": 25525.710968732834, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 572496, "time": 25534.513463020325, "episode/length": 150.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 572848, "time": 25547.45454645157, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 573072, "time": 25556.115958452225, "episode/length": 341.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 573080, "time": 25557.72755408287, "episode/length": 217.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 573480, "time": 25573.721659898758, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 573664, "time": 25581.41481900215, "episode/length": 248.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 574240, "time": 25601.488210439682, "episode/length": 353.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 574272, "time": 25604.06007862091, "episode/length": 177.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 574312, "time": 25606.591905593872, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 574456, "time": 25612.742422819138, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 574624, "time": 25619.920587062836, "episode/length": 265.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 574728, "time": 25624.679295301437, "episode/length": 306.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990228013029316, "episode/intrinsic_return": 0.0}
{"step": 574768, "time": 25627.740139484406, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 575096, "time": 25639.689157247543, "episode/length": 58.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 575776, "time": 25663.542789936066, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 576056, "time": 25673.77237844467, "episode/length": 226.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 576096, "time": 25676.742667913437, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 576392, "time": 25687.66472387314, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 576496, "time": 25692.713840007782, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 576632, "time": 25698.40438556671, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 576808, "time": 25705.55260014534, "episode/length": 415.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 577192, "time": 25719.476588010788, "episode/length": 47.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 577520, "time": 25731.738978147507, "episode/length": 217.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 577552, "time": 25734.277082443237, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 577832, "time": 25744.720321416855, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 578184, "time": 25757.63642334938, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 578296, "time": 25762.796441078186, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 578848, "time": 25782.3101708889, "episode/length": 509.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 579000, "time": 25788.599677801132, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 579248, "time": 25798.161966085434, "episode/length": 398.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 579328, "time": 25802.34483885765, "episode/length": 40.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 579520, "time": 25809.959033727646, "episode/length": 245.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 579624, "time": 25814.673252105713, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 579840, "time": 25824.060217380524, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 579840, "time": 25824.070380687714, "episode/length": 430.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 25851.964111328125, "eval_episode/length": 161.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 580008, "time": 25853.69975590706, "eval_episode/length": 164.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 580008, "time": 25856.057096481323, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 580008, "time": 25858.3911755085, "eval_episode/length": 203.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 580008, "time": 25860.54084467888, "eval_episode/length": 218.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 580008, "time": 25862.4121427536, "eval_episode/length": 224.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 580008, "time": 25864.08779144287, "eval_episode/length": 228.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 580008, "time": 25870.258614063263, "eval_episode/length": 144.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.993103448275862}
{"step": 580104, "time": 25873.340772151947, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 580192, "time": 25877.923857212067, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 580496, "time": 25889.19654417038, "episode/length": 332.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.987987987987988, "episode/intrinsic_return": 0.0}
{"step": 580760, "time": 25899.051481962204, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 580872, "time": 25904.26527905464, "episode/length": 202.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 581208, "time": 25916.587861299515, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 581504, "time": 25928.12834262848, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 581600, "time": 25932.72507739067, "episode/length": 283.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 581744, "time": 25940.24574303627, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 581768, "time": 25942.249081134796, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 582344, "time": 25962.398737430573, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 582632, "time": 25973.127284288406, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 582808, "time": 25981.03054523468, "episode/length": 288.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 583216, "time": 25996.024361133575, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 583424, "time": 26004.207064390182, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 583472, "time": 26007.233846902847, "episode/length": 140.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 584176, "time": 26031.49568772316, "episode/length": 192.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 584192, "time": 26033.547998189926, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9906759906759907, "episode/intrinsic_return": 0.0}
{"step": 584560, "time": 26047.159238815308, "episode/length": 135.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 584608, "time": 26050.164455652237, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 584712, "time": 26054.78928589821, "episode/length": 400.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 584808, "time": 26059.43448615074, "episode/length": 400.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 585112, "time": 26070.773312091827, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 585152, "time": 26073.861505031586, "episode/length": 121.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 585688, "time": 26092.433404684067, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 585720, "time": 26095.04324030876, "episode/length": 286.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 586288, "time": 26115.210518836975, "episode/length": 196.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 586320, "time": 26117.674322605133, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 586448, "time": 26123.394451379776, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 586488, "time": 26125.98471546173, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 586632, "time": 26132.150001764297, "episode/length": 117.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 586736, "time": 26137.27651166916, "episode/length": 126.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 586992, "time": 26147.05806660652, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 587008, "time": 26149.074858665466, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 587616, "time": 26170.181361436844, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 587712, "time": 26174.850602149963, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 587832, "time": 26180.008123636246, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 587936, "time": 26184.975739717484, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 588288, "time": 26197.907839536667, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 588960, "time": 26221.47822380066, "episode/length": 167.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 589080, "time": 26226.641704797745, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 589248, "time": 26233.754408359528, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 589336, "time": 26237.872395277023, "episode/length": 174.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 589392, "time": 26241.46346974373, "episode/length": 299.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 589456, "time": 26244.998183250427, "episode/length": 352.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 589488, "time": 26247.498609542847, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 589720, "time": 26256.37375807762, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 26285.630588769913, "eval_episode/length": 32.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 590096, "time": 26288.299892663956, "eval_episode/length": 60.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 590096, "time": 26294.078359603882, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 590096, "time": 26296.827803373337, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 590096, "time": 26296.835426330566, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 590096, "time": 26300.470169067383, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 590096, "time": 26302.61155438423, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9671361502347418}
{"step": 590096, "time": 26305.96649479866, "eval_episode/length": 194.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 590152, "time": 26307.54376888275, "episode/length": 82.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 590448, "time": 26318.88668203354, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 590552, "time": 26323.499554634094, "episode/length": 144.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 590688, "time": 26329.52432656288, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 591136, "time": 26345.5738093853, "episode/length": 256.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 591256, "time": 26350.74244427681, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 591336, "time": 26354.84417939186, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 591384, "time": 26358.016540050507, "episode/length": 153.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 591920, "time": 26376.94466972351, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 591921, "time": 26378.999382019043, "train_stats/sum_log_reward": 6.901886836537775, "train_stats/max_log_achievement_collect_coal": 0.2830188679245283, "train_stats/max_log_achievement_collect_drink": 5.613207547169812, "train_stats/max_log_achievement_collect_sapling": 1.9811320754716981, "train_stats/max_log_achievement_collect_stone": 4.30188679245283, "train_stats/max_log_achievement_collect_wood": 8.877358490566039, "train_stats/max_log_achievement_defeat_skeleton": 0.02830188679245283, "train_stats/max_log_achievement_defeat_zombie": 0.5849056603773585, "train_stats/max_log_achievement_eat_cow": 0.07547169811320754, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.849056603773585, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.018867924528301886, "train_stats/max_log_achievement_place_plant": 1.8018867924528301, "train_stats/max_log_achievement_place_stone": 0.09433962264150944, "train_stats/max_log_achievement_place_table": 2.4245283018867925, "train_stats/max_log_achievement_wake_up": 1.330188679245283, "train_stats/mean_log_entropy": 0.34315337198522855, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.24149503639276, "train/action_min": 0.0, "train/action_std": 3.2378832710732657, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0435218362660288, "train/actor_opt_grad_steps": 36200.0, "train/actor_opt_loss": -6.207673840653554, "train/adv_mag": 0.5900315633780665, "train/adv_max": 0.5677153564614358, "train/adv_mean": 0.0032678111661527064, "train/adv_min": -0.4511190299078715, "train/adv_std": 0.06590625892976205, "train/cont_avg": 0.9946183678057554, "train/cont_loss_mean": 0.0001515163087137055, "train/cont_loss_std": 0.003974335250198584, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.004205325555807798, "train/cont_pos_acc": 0.9999504801180723, "train/cont_pos_loss": 0.00012890913246401935, "train/cont_pred": 0.9945704945557409, "train/cont_rate": 0.9946183678057554, "train/dyn_loss_mean": 13.226008902350776, "train/dyn_loss_std": 9.404041084454214, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8190159544670325, "train/extr_critic_critic_opt_grad_steps": 36200.0, "train/extr_critic_critic_opt_loss": 15939.61314073741, "train/extr_critic_mag": 5.91849025204885, "train/extr_critic_max": 5.91849025204885, "train/extr_critic_mean": 1.2381628558790083, "train/extr_critic_min": -0.26118651997271203, "train/extr_critic_std": 1.365640980734242, "train/extr_return_normed_mag": 1.7587156261471535, "train/extr_return_normed_max": 1.7587156261471535, "train/extr_return_normed_mean": 0.31177430626728553, "train/extr_return_normed_min": -0.12887776015902594, "train/extr_return_normed_std": 0.33597272580904924, "train/extr_return_rate": 0.5520074852078939, "train/extr_return_raw_mag": 7.269332470653726, "train/extr_return_raw_max": 7.269332470653726, "train/extr_return_raw_mean": 1.2518059053866983, "train/extr_return_raw_min": -0.5816271052086096, "train/extr_return_raw_std": 1.3976983852523694, "train/extr_reward_mag": 1.0203634234641095, "train/extr_reward_max": 1.0203634234641095, "train/extr_reward_mean": 0.030463079834799116, "train/extr_reward_min": -0.4172059331866477, "train/extr_reward_std": 0.1636335337869555, "train/image_loss_mean": 6.663493626409298, "train/image_loss_std": 11.198793099080916, "train/model_loss_mean": 14.652809197954136, "train/model_loss_std": 15.093165836745886, "train/model_opt_grad_norm": 60.81994941766313, "train/model_opt_grad_steps": 36164.525179856115, "train/model_opt_loss": 18607.85545469874, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.9856115107914, "train/policy_entropy_mag": 2.587560804627782, "train/policy_entropy_max": 2.587560804627782, "train/policy_entropy_mean": 0.6344693577546867, "train/policy_entropy_min": 0.079375092824586, "train/policy_entropy_std": 0.7107408222534674, "train/policy_logprob_mag": 7.438383620419948, "train/policy_logprob_max": -0.009455690750008006, "train/policy_logprob_mean": -0.6352126557621167, "train/policy_logprob_min": -7.438383620419948, "train/policy_logprob_std": 1.1642657329710266, "train/policy_randomness_mag": 0.9132954105198812, "train/policy_randomness_max": 0.9132954105198812, "train/policy_randomness_mean": 0.223939839241316, "train/policy_randomness_min": 0.028015924416643252, "train/policy_randomness_std": 0.250860319827958, "train/post_ent_mag": 60.25530621645262, "train/post_ent_max": 60.25530621645262, "train/post_ent_mean": 42.83095059291922, "train/post_ent_min": 20.91443340383845, "train/post_ent_std": 7.6899114649930445, "train/prior_ent_mag": 69.45437144547057, "train/prior_ent_max": 69.45437144547057, "train/prior_ent_mean": 56.09419524926933, "train/prior_ent_min": 37.890782280791576, "train/prior_ent_std": 4.918878786855465, "train/rep_loss_mean": 13.226008902350776, "train/rep_loss_std": 9.404041084454214, "train/reward_avg": 0.025496711773570064, "train/reward_loss_mean": 0.05355874060405244, "train/reward_loss_std": 0.24479349815159393, "train/reward_max_data": 1.015107917271072, "train/reward_max_pred": 1.0100985268037097, "train/reward_neg_acc": 0.9933484423932412, "train/reward_neg_loss": 0.028522561351172357, "train/reward_pos_acc": 0.9638539166759243, "train/reward_pos_loss": 0.8625746986848845, "train/reward_pred": 0.02454267613080551, "train/reward_rate": 0.03022425809352518, "eval_stats/sum_log_reward": 6.516666670640309, "eval_stats/max_log_achievement_collect_coal": 0.2916666666666667, "eval_stats/max_log_achievement_collect_drink": 3.9583333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.7916666666666667, "eval_stats/max_log_achievement_collect_stone": 5.208333333333333, "eval_stats/max_log_achievement_collect_wood": 8.833333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5833333333333334, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.7083333333333333, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5416666666666665, "eval_stats/max_log_achievement_wake_up": 1.0833333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 3.993264544988051e-05, "report/cont_loss_std": 0.0008325460366904736, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0028158193454146385, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.721916800714098e-05, "report/cont_pred": 0.9989893436431885, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 11.315376281738281, "report/dyn_loss_std": 9.259430885314941, "report/image_loss_mean": 7.774888038635254, "report/image_loss_std": 11.727409362792969, "report/model_loss_mean": 14.5975341796875, "report/model_loss_std": 15.485718727111816, "report/post_ent_mag": 59.90156936645508, "report/post_ent_max": 59.90156936645508, "report/post_ent_mean": 44.77574157714844, "report/post_ent_min": 20.70972442626953, "report/post_ent_std": 8.225729942321777, "report/prior_ent_mag": 69.57506561279297, "report/prior_ent_max": 69.57506561279297, "report/prior_ent_mean": 56.32683563232422, "report/prior_ent_min": 38.051788330078125, "report/prior_ent_std": 5.660365581512451, "report/rep_loss_mean": 11.315376281738281, "report/rep_loss_std": 9.259430885314941, "report/reward_avg": 0.00996093638241291, "report/reward_loss_mean": 0.03338076174259186, "report/reward_loss_std": 0.16997243463993073, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035536289215088, "report/reward_neg_acc": 0.9940652251243591, "report/reward_neg_loss": 0.024877432733774185, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6946778893470764, "report/reward_pred": 0.010627230629324913, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.00014470763562712818, "eval/cont_loss_std": 0.003774402430281043, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001713228557491675, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00014468161680269986, "eval/cont_pred": 0.998885989189148, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.74383544921875, "eval/dyn_loss_std": 11.46928596496582, "eval/image_loss_mean": 15.152886390686035, "eval/image_loss_std": 22.650575637817383, "eval/model_loss_mean": 25.275930404663086, "eval/model_loss_std": 27.26799201965332, "eval/post_ent_mag": 60.67900848388672, "eval/post_ent_max": 60.67900848388672, "eval/post_ent_mean": 42.12639617919922, "eval/post_ent_min": 21.138835906982422, "eval/post_ent_std": 8.256732940673828, "eval/prior_ent_mag": 69.57506561279297, "eval/prior_ent_max": 69.57506561279297, "eval/prior_ent_mean": 56.84796142578125, "eval/prior_ent_min": 35.38475036621094, "eval/prior_ent_std": 5.0937018394470215, "eval/rep_loss_mean": 16.74383544921875, "eval/rep_loss_std": 11.46928596496582, "eval/reward_avg": 0.02949218824505806, "eval/reward_loss_mean": 0.07659944891929626, "eval/reward_loss_std": 0.5247373580932617, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0059802532196045, "eval/reward_neg_acc": 0.9889112710952759, "eval/reward_neg_loss": 0.022425496950745583, "eval/reward_pos_acc": 0.8125, "eval/reward_pos_loss": 1.7559919357299805, "eval/reward_pred": 0.023198604583740234, "eval/reward_rate": 0.03125, "replay/size": 591417.0, "replay/inserts": 22328.0, "replay/samples": 22320.0, "replay/insert_wait_avg": 1.3262513972917623e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.821026668753675e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1376726461958097e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.8714027404785, "timer/env.step_count": 2791.0, "timer/env.step_total": 236.34108781814575, "timer/env.step_frac": 0.23613531885417247, "timer/env.step_avg": 0.08467971616558428, "timer/env.step_min": 0.022516489028930664, "timer/env.step_max": 3.3482344150543213, "timer/replay._sample_count": 22320.0, "timer/replay._sample_total": 11.372047424316406, "timer/replay._sample_frac": 0.011362146418789356, "timer/replay._sample_avg": 0.0005095003326306633, "timer/replay._sample_min": 0.00037026405334472656, "timer/replay._sample_max": 0.02807927131652832, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3728.0, "timer/agent.policy_total": 56.04833936691284, "timer/agent.policy_frac": 0.05599954121323409, "timer/agent.policy_avg": 0.01503442579584572, "timer/agent.policy_min": 0.00818777084350586, "timer/agent.policy_max": 0.10689926147460938, "timer/dataset_train_count": 1395.0, "timer/dataset_train_total": 0.1461036205291748, "timer/dataset_train_frac": 0.0001459764162799832, "timer/dataset_train_avg": 0.00010473377815711455, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0005071163177490234, "timer/agent.train_count": 1395.0, "timer/agent.train_total": 607.1317870616913, "timer/agent.train_frac": 0.6066031913783412, "timer/agent.train_avg": 0.4352199190406389, "timer/agent.train_min": 0.42441248893737793, "timer/agent.train_max": 1.3838987350463867, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4818141460418701, "timer/agent.report_frac": 0.00048139465741814423, "timer/agent.report_avg": 0.24090707302093506, "timer/agent.report_min": 0.2319958209991455, "timer/agent.report_max": 0.2498183250427246, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00013113021850585938, "timer/dataset_eval_frac": 1.310160507601803e-07, "timer/dataset_eval_avg": 0.00013113021850585938, "timer/dataset_eval_min": 0.00013113021850585938, "timer/dataset_eval_max": 0.00013113021850585938, "fps": 22.30825769211332}
{"step": 592192, "time": 26387.906135082245, "episode/length": 367.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9864130434782609, "episode/intrinsic_return": 0.0}
{"step": 592504, "time": 26399.176622390747, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 592696, "time": 26406.90977692604, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 592728, "time": 26409.348048210144, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 592744, "time": 26411.35101866722, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 592816, "time": 26415.376222372055, "episode/length": 184.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 593240, "time": 26430.317596435547, "episode/length": 52.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 593768, "time": 26449.177706480026, "episode/length": 384.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766233766233766, "episode/intrinsic_return": 0.0}
{"step": 593968, "time": 26457.49009037018, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 594240, "time": 26467.803636550903, "episode/length": 255.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 594376, "time": 26473.42825770378, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 594464, "time": 26478.01432132721, "episode/length": 214.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 594472, "time": 26479.60419034958, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 594528, "time": 26483.116173505783, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 594848, "time": 26495.120530843735, "episode/length": 200.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 595336, "time": 26512.265464305878, "episode/length": 107.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 595336, "time": 26512.27385878563, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 595648, "time": 26525.728706598282, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 595864, "time": 26533.880543231964, "episode/length": 185.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 596448, "time": 26554.566825389862, "episode/length": 247.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 596800, "time": 26567.33923149109, "episode/length": 319.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 597192, "time": 26581.2769882679, "episode/length": 332.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 597360, "time": 26588.445038080215, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683794466403162, "episode/intrinsic_return": 0.0}
{"step": 597712, "time": 26601.494530916214, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9653679653679653, "episode/intrinsic_return": 0.0}
{"step": 597744, "time": 26604.128268957138, "episode/length": 68.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 597832, "time": 26608.257944107056, "episode/length": 272.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 597920, "time": 26612.980075120926, "episode/length": 322.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 598000, "time": 26617.13650894165, "episode/length": 193.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 598640, "time": 26640.797593593597, "episode/length": 111.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 598912, "time": 26651.212651252747, "episode/length": 507.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9822834645669292, "episode/intrinsic_return": 0.0}
{"step": 599256, "time": 26663.84457707405, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 599280, "time": 26666.772506952286, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 599544, "time": 26676.654062747955, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 599568, "time": 26679.19938993454, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 599744, "time": 26686.473163843155, "episode/length": 297.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 599944, "time": 26694.304460525513, "episode/length": 278.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 26720.995663166046, "eval_episode/length": 146.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 600080, "time": 26722.670026779175, "eval_episode/length": 150.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 600080, "time": 26725.195051193237, "eval_episode/length": 174.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 600080, "time": 26726.76160311699, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 600080, "time": 26728.60182929039, "eval_episode/length": 183.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 600080, "time": 26731.396177768707, "eval_episode/length": 213.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 600080, "time": 26731.404399871826, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9626168224299065}
{"step": 600080, "time": 26735.106729745865, "eval_episode/length": 40.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.975609756097561}
{"step": 600232, "time": 26739.83543896675, "episode/length": 118.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 600896, "time": 26764.570506334305, "episode/length": 168.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 600984, "time": 26768.70007610321, "episode/length": 176.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 601008, "time": 26771.144957065582, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 601304, "time": 26781.9156768322, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 601496, "time": 26789.682401657104, "episode/length": 60.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 602048, "time": 26809.09261250496, "episode/length": 425.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 602112, "time": 26812.62142944336, "episode/length": 399.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9925, "episode/intrinsic_return": 0.0}
{"step": 602152, "time": 26815.157850027084, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 602304, "time": 26821.742629766464, "episode/length": 294.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 602440, "time": 26827.429579496384, "episode/length": 275.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 602624, "time": 26834.9743847847, "episode/length": 164.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 603032, "time": 26849.41107392311, "episode/length": 191.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 603056, "time": 26852.02273464203, "episode/length": 258.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 603120, "time": 26855.63306093216, "episode/length": 61.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 603680, "time": 26875.290821790695, "episode/length": 190.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 603776, "time": 26879.829894304276, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 604296, "time": 26898.283764362335, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 604352, "time": 26902.437049865723, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 604472, "time": 26908.28877043724, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 604512, "time": 26911.795002937317, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 604584, "time": 26916.004372119904, "episode/length": 308.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773462783171522, "episode/intrinsic_return": 0.0}
{"step": 605040, "time": 26933.40705394745, "episode/length": 373.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9866310160427807, "episode/intrinsic_return": 0.0}
{"step": 605432, "time": 26948.289966583252, "episode/length": 119.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 605448, "time": 26950.719152212143, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 605552, "time": 26956.344375371933, "episode/length": 221.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 605824, "time": 26966.652053117752, "episode/length": 267.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 606368, "time": 26987.25309586525, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 606400, "time": 26989.84930729866, "episode/length": 120.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 606408, "time": 26991.307579040527, "episode/length": 256.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 606472, "time": 26994.986360549927, "episode/length": 244.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 606816, "time": 27008.051210165024, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 606904, "time": 27012.241020441055, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 607200, "time": 27023.522735118866, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 607248, "time": 27026.507253170013, "episode/length": 42.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 607488, "time": 27035.848216056824, "episode/length": 254.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 607528, "time": 27038.27760910988, "episode/length": 140.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 607576, "time": 27041.36530995369, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 607840, "time": 27051.516632080078, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 607848, "time": 27053.143035650253, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 608680, "time": 27081.372476816177, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 608848, "time": 27088.5571475029, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 609056, "time": 27096.868640184402, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 609080, "time": 27098.87350487709, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 609152, "time": 27102.966148853302, "episode/length": 163.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 609488, "time": 27115.21453523636, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 609992, "time": 27132.817562818527, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 27155.525894641876, "eval_episode/length": 149.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 610064, "time": 27157.239723682404, "eval_episode/length": 154.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 610064, "time": 27159.294597625732, "eval_episode/length": 166.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 610064, "time": 27160.82520890236, "eval_episode/length": 168.0, "eval_episode/score": 8.099999964237213, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 610064, "time": 27163.243848085403, "eval_episode/length": 189.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 610064, "time": 27165.745569705963, "eval_episode/length": 211.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 610064, "time": 27171.53698205948, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 610064, "time": 27173.93581390381, "eval_episode/length": 180.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 610088, "time": 27174.503192186356, "episode/length": 408.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779951100244498, "episode/intrinsic_return": 0.0}
{"step": 610320, "time": 27183.794939994812, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 610440, "time": 27189.023125886917, "episode/length": 198.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 610520, "time": 27193.140030384064, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 611136, "time": 27214.76163673401, "episode/length": 256.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 611328, "time": 27222.39588022232, "episode/length": 271.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 611936, "time": 27243.762655496597, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 612056, "time": 27248.881539821625, "episode/length": 257.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 612144, "time": 27253.448306560516, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 612608, "time": 27270.00107550621, "episode/length": 159.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 612840, "time": 27278.903319358826, "episode/length": 343.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 612872, "time": 27281.574610710144, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 612944, "time": 27285.661417484283, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 613112, "time": 27292.351659297943, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 613352, "time": 27301.54632139206, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 613432, "time": 27305.56615304947, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 613448, "time": 27307.65191078186, "episode/length": 71.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 613520, "time": 27311.709980487823, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 613976, "time": 27327.552392721176, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 614432, "time": 27345.253237485886, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 614536, "time": 27349.9365131855, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 614664, "time": 27355.529170513153, "episode/length": 153.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 614776, "time": 27360.761655569077, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 614976, "time": 27369.008415222168, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 615032, "time": 27372.101004362106, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 615177, "time": 27379.154665708542, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.220761233813142, "train/action_min": 0.0, "train/action_std": 3.277668774944462, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04273627840033541, "train/actor_opt_grad_steps": 37625.0, "train/actor_opt_loss": -0.31615111721705086, "train/adv_mag": 0.5779294269542171, "train/adv_max": 0.5532454244078022, "train/adv_mean": 0.004426043181398474, "train/adv_min": -0.45188686986492105, "train/adv_std": 0.06454703982358109, "train/cont_avg": 0.9949499678938356, "train/cont_loss_mean": 0.00010734314562559781, "train/cont_loss_std": 0.002824730561986156, "train/cont_neg_acc": 0.9970319638513538, "train/cont_neg_loss": 0.010519773888941703, "train/cont_pos_acc": 0.9999932691659013, "train/cont_pos_loss": 4.3334449469774844e-05, "train/cont_pred": 0.9949572784443425, "train/cont_rate": 0.9949499678938356, "train/dyn_loss_mean": 13.179053241259432, "train/dyn_loss_std": 9.421881995788992, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8384785517437817, "train/extr_critic_critic_opt_grad_steps": 37625.0, "train/extr_critic_critic_opt_loss": 16189.665513966182, "train/extr_critic_mag": 6.238232331733181, "train/extr_critic_max": 6.238232331733181, "train/extr_critic_mean": 1.3626877983955488, "train/extr_critic_min": -0.24996129127397929, "train/extr_critic_std": 1.4130077749898988, "train/extr_return_normed_mag": 1.7224612350333226, "train/extr_return_normed_max": 1.7224612350333226, "train/extr_return_normed_mean": 0.3250900903997356, "train/extr_return_normed_min": -0.12398570852532778, "train/extr_return_normed_std": 0.333173384507225, "train/extr_return_rate": 0.5937009784456801, "train/extr_return_raw_mag": 7.452220560753182, "train/extr_return_raw_max": 7.452220560753182, "train/extr_return_raw_mean": 1.3818954037476892, "train/extr_return_raw_min": -0.568929414328647, "train/extr_return_raw_std": 1.4476619750669557, "train/extr_reward_mag": 1.0210589627697044, "train/extr_reward_max": 1.0210589627697044, "train/extr_reward_mean": 0.03156553313442289, "train/extr_reward_min": -0.4024421115444131, "train/extr_reward_std": 0.1662560151252028, "train/image_loss_mean": 6.705878587618266, "train/image_loss_std": 11.49971004054971, "train/model_loss_mean": 14.665393809749656, "train/model_loss_std": 15.38782168087894, "train/model_opt_grad_norm": 63.363718111221104, "train/model_opt_grad_steps": 37588.17123287671, "train/model_opt_loss": 18452.868545323203, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.123287671233, "train/policy_entropy_mag": 2.5772495041154837, "train/policy_entropy_max": 2.5772495041154837, "train/policy_entropy_mean": 0.5989713636163163, "train/policy_entropy_min": 0.07937508459164672, "train/policy_entropy_std": 0.6942456832079038, "train/policy_logprob_mag": 7.438383651106325, "train/policy_logprob_max": -0.00945567700705708, "train/policy_logprob_mean": -0.5980109923506436, "train/policy_logprob_min": -7.438383651106325, "train/policy_logprob_std": 1.138152837753296, "train/policy_randomness_mag": 0.9096559751523684, "train/policy_randomness_max": 0.9096559751523684, "train/policy_randomness_mean": 0.2114106078874575, "train/policy_randomness_min": 0.028015921504734313, "train/policy_randomness_std": 0.24503825809041116, "train/post_ent_mag": 60.315620056570395, "train/post_ent_max": 60.315620056570395, "train/post_ent_mean": 43.002460218455695, "train/post_ent_min": 20.76926395991077, "train/post_ent_std": 7.725001446188313, "train/prior_ent_mag": 69.62711386484642, "train/prior_ent_max": 69.62711386484642, "train/prior_ent_mean": 56.242718500633764, "train/prior_ent_min": 38.98450281848646, "train/prior_ent_std": 4.843969869287046, "train/rep_loss_mean": 13.179053241259432, "train/rep_loss_std": 9.421881995788992, "train/reward_avg": 0.024961204574226518, "train/reward_loss_mean": 0.05197605900211285, "train/reward_loss_std": 0.2390947158205999, "train/reward_max_data": 1.0123287700626948, "train/reward_max_pred": 1.0114509332669925, "train/reward_neg_acc": 0.9930541168336999, "train/reward_neg_loss": 0.028211409736373653, "train/reward_pos_acc": 0.9709726951710166, "train/reward_pos_loss": 0.8354652385189109, "train/reward_pred": 0.02452107175725372, "train/reward_rate": 0.029564426369863013, "train_stats/sum_log_reward": 7.257407479816013, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_collect_drink": 5.157407407407407, "train_stats/max_log_achievement_collect_sapling": 1.9722222222222223, "train_stats/max_log_achievement_collect_stone": 4.37037037037037, "train_stats/max_log_achievement_collect_wood": 11.49074074074074, "train_stats/max_log_achievement_defeat_skeleton": 0.046296296296296294, "train_stats/max_log_achievement_defeat_zombie": 0.6481481481481481, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.240740740740741, "train_stats/max_log_achievement_make_wood_sword": 0.009259259259259259, "train_stats/max_log_achievement_place_furnace": 0.037037037037037035, "train_stats/max_log_achievement_place_plant": 1.8055555555555556, "train_stats/max_log_achievement_place_stone": 0.05555555555555555, "train_stats/max_log_achievement_place_table": 3.25, "train_stats/max_log_achievement_wake_up": 1.287037037037037, "train_stats/mean_log_entropy": 0.3294845406241991, "eval_stats/sum_log_reward": 6.975000023841858, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 2.4375, "eval_stats/max_log_achievement_collect_wood": 13.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.7613677957560867e-06, "report/cont_loss_std": 1.988022995647043e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.993114170152694e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.419525117147714e-06, "report/cont_pred": 0.9960916638374329, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.288961410522461, "report/dyn_loss_std": 8.820155143737793, "report/image_loss_mean": 4.751656532287598, "report/image_loss_std": 8.208687782287598, "report/model_loss_mean": 12.163477897644043, "report/model_loss_std": 11.821189880371094, "report/post_ent_mag": 60.30421447753906, "report/post_ent_max": 60.30421447753906, "report/post_ent_mean": 43.24213790893555, "report/post_ent_min": 21.77639389038086, "report/post_ent_std": 7.721453666687012, "report/prior_ent_mag": 69.87709045410156, "report/prior_ent_max": 69.87709045410156, "report/prior_ent_mean": 56.04518127441406, "report/prior_ent_min": 40.46474075317383, "report/prior_ent_std": 4.65523624420166, "report/rep_loss_mean": 12.288961410522461, "report/rep_loss_std": 8.820155143737793, "report/reward_avg": 0.01904296875, "report/reward_loss_mean": 0.0384417288005352, "report/reward_loss_std": 0.15090984106063843, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0035953521728516, "report/reward_neg_acc": 0.9909909963607788, "report/reward_neg_loss": 0.02174188382923603, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7057675719261169, "report/reward_pred": 0.019957037642598152, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0009827271569520235, "eval/cont_loss_std": 0.029063643887639046, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.18585015833377838, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.562487735413015e-05, "eval/cont_pred": 0.995634913444519, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.346709251403809, "eval/dyn_loss_std": 10.722177505493164, "eval/image_loss_mean": 9.15517807006836, "eval/image_loss_std": 15.268669128417969, "eval/model_loss_mean": 18.413496017456055, "eval/model_loss_std": 19.332645416259766, "eval/post_ent_mag": 60.31551742553711, "eval/post_ent_max": 60.31551742553711, "eval/post_ent_mean": 42.935699462890625, "eval/post_ent_min": 19.962854385375977, "eval/post_ent_std": 7.726407051086426, "eval/prior_ent_mag": 69.87709045410156, "eval/prior_ent_max": 69.87709045410156, "eval/prior_ent_mean": 56.58445358276367, "eval/prior_ent_min": 40.12445068359375, "eval/prior_ent_std": 4.664629936218262, "eval/rep_loss_mean": 15.346709251403809, "eval/rep_loss_std": 10.722177505493164, "eval/reward_avg": 0.0234375, "eval/reward_loss_mean": 0.049309901893138885, "eval/reward_loss_std": 0.25698184967041016, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0028502941131592, "eval/reward_neg_acc": 0.9929719567298889, "eval/reward_neg_loss": 0.02440616302192211, "eval/reward_pos_acc": 0.9285714626312256, "eval/reward_pos_loss": 0.9351716637611389, "eval/reward_pred": 0.023685738444328308, "eval/reward_rate": 0.02734375, "replay/size": 614673.0, "replay/inserts": 23256.0, "replay/samples": 23264.0, "replay/insert_wait_avg": 1.3129424917603589e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.148021675697547e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1382771910523339e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1579658985138, "timer/env.step_count": 2907.0, "timer/env.step_total": 245.30971717834473, "timer/env.step_frac": 0.24527097272875828, "timer/env.step_avg": 0.08438586762240961, "timer/env.step_min": 0.022829532623291016, "timer/env.step_max": 3.1763405799865723, "timer/replay._sample_count": 23264.0, "timer/replay._sample_total": 11.82321047782898, "timer/replay._sample_frac": 0.011821343108743167, "timer/replay._sample_avg": 0.0005082191574032401, "timer/replay._sample_min": 0.0004222393035888672, "timer/replay._sample_max": 0.028141260147094727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3463.0, "timer/agent.policy_total": 53.55657649040222, "timer/agent.policy_frac": 0.05354811771387383, "timer/agent.policy_avg": 0.015465370052094201, "timer/agent.policy_min": 0.008487939834594727, "timer/agent.policy_max": 0.10151267051696777, "timer/dataset_train_count": 1454.0, "timer/dataset_train_total": 0.1542339324951172, "timer/dataset_train_frac": 0.00015420957264141545, "timer/dataset_train_avg": 0.00010607560694299669, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.00107574462890625, "timer/agent.train_count": 1454.0, "timer/agent.train_total": 634.1724812984467, "timer/agent.train_frac": 0.6340723194947749, "timer/agent.train_avg": 0.4361571398201146, "timer/agent.train_min": 0.4232141971588135, "timer/agent.train_max": 1.9904563426971436, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795691967010498, "timer/agent.report_frac": 0.00047949345308690144, "timer/agent.report_avg": 0.2397845983505249, "timer/agent.report_min": 0.23272442817687988, "timer/agent.report_max": 0.24684476852416992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.506111145019531e-05, "timer/dataset_eval_frac": 4.505399445547952e-08, "timer/dataset_eval_avg": 4.506111145019531e-05, "timer/dataset_eval_min": 4.506111145019531e-05, "timer/dataset_eval_max": 4.506111145019531e-05, "fps": 23.252019192473018}
{"step": 615288, "time": 27382.445869922638, "episode/length": 163.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 615888, "time": 27403.70387196541, "episode/length": 367.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 615936, "time": 27406.931438207626, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 616120, "time": 27414.32151699066, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 616280, "time": 27421.034902334213, "episode/length": 123.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 616304, "time": 27423.6983397007, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 616384, "time": 27427.825740098953, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 616472, "time": 27431.930317878723, "episode/length": 241.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 616752, "time": 27442.69341158867, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 616808, "time": 27445.807024240494, "episode/length": 228.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 617056, "time": 27455.479954481125, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 617632, "time": 27475.574553251266, "episode/length": 165.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 617776, "time": 27481.738881111145, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 617824, "time": 27484.814831018448, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 617824, "time": 27484.822993516922, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 617920, "time": 27491.11683034897, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 618336, "time": 27505.93436026573, "episode/length": 63.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 618488, "time": 27512.247797250748, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 618632, "time": 27518.462327957153, "episode/length": 100.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 618832, "time": 27526.558932304382, "episode/length": 259.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 619224, "time": 27540.70809197426, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 619416, "time": 27548.597125530243, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 619592, "time": 27555.800263881683, "episode/length": 226.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 619792, "time": 27563.955205202103, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 619960, "time": 27570.543853998184, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 620016, "time": 27574.167579889297, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 27576.72443342209, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 27591.711373806, "eval_episode/length": 58.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 620048, "time": 27593.42723250389, "eval_episode/length": 61.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 620048, "time": 27597.367990255356, "eval_episode/length": 122.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.991869918699187}
{"step": 620048, "time": 27600.779088974, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 620048, "time": 27603.73175740242, "eval_episode/length": 200.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 620048, "time": 27605.545796871185, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 620048, "time": 27608.866349220276, "eval_episode/length": 187.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 620048, "time": 27610.378727674484, "eval_episode/length": 50.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 621016, "time": 27642.892322301865, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 621040, "time": 27645.474402427673, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 621056, "time": 27647.488369226456, "episode/length": 277.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 621112, "time": 27650.611901283264, "episode/length": 434.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 621248, "time": 27656.712520837784, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 621560, "time": 27668.010898828506, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 621568, "time": 27670.030195474625, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 622304, "time": 27695.303334712982, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 622648, "time": 27709.119579076767, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 622744, "time": 27713.698211669922, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 622752, "time": 27715.720843315125, "episode/length": 216.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 623232, "time": 27732.823436260223, "episode/length": 60.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 623752, "time": 27750.963195323944, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 623856, "time": 27756.058444023132, "episode/length": 351.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 623880, "time": 27758.08317875862, "episode/length": 352.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 624064, "time": 27765.625693798065, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 624376, "time": 27776.768174409866, "episode/length": 350.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 624696, "time": 27788.660005569458, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 625016, "time": 27800.368081092834, "episode/length": 431.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 625128, "time": 27805.462964773178, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 625608, "time": 27822.46750354767, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 625904, "time": 27833.812741994858, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 626160, "time": 27843.57083439827, "episode/length": 287.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 626296, "time": 27849.30593395233, "episode/length": 301.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 626328, "time": 27851.96609401703, "episode/length": 446.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 626520, "time": 27859.687843322754, "episode/length": 267.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 626808, "time": 27870.453377723694, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 626960, "time": 27877.097053050995, "episode/length": 54.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 627120, "time": 27883.677219867706, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 627288, "time": 27890.27480983734, "episode/length": 140.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 627320, "time": 27892.89685177803, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 627768, "time": 27908.745794534683, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 627800, "time": 27911.275752067566, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 628000, "time": 27919.398918390274, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 628008, "time": 27920.939071655273, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 628200, "time": 27928.683361291885, "episode/length": 397.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 628384, "time": 27936.33068537712, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 628608, "time": 27945.0787422657, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 629192, "time": 27965.209508419037, "episode/length": 147.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 629288, "time": 27969.756732225418, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 629328, "time": 27972.737781763077, "episode/length": 140.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 629328, "time": 27972.745297908783, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 629432, "time": 27979.078291893005, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 629560, "time": 27984.747676610947, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770491803278688, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 28016.60539674759, "eval_episode/length": 64.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 630032, "time": 28021.900628328323, "eval_episode/length": 155.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.967948717948718}
{"step": 630032, "time": 28023.473997831345, "eval_episode/length": 156.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9808917197452229}
{"step": 630032, "time": 28025.583076238632, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 630032, "time": 28028.133505821228, "eval_episode/length": 191.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 630032, "time": 28029.761820554733, "eval_episode/length": 194.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 630032, "time": 28032.112770795822, "eval_episode/length": 211.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 630032, "time": 28037.421574115753, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 630720, "time": 28059.766721010208, "episode/length": 291.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 630776, "time": 28062.8522336483, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 630952, "time": 28071.38966870308, "episode/length": 219.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 630976, "time": 28073.804771900177, "episode/length": 295.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 631248, "time": 28084.254674196243, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 631552, "time": 28095.74171757698, "episode/length": 264.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 631704, "time": 28101.792779684067, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 631752, "time": 28104.79087781906, "episode/length": 273.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 632064, "time": 28116.50670194626, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 632232, "time": 28123.135948181152, "episode/length": 156.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 632440, "time": 28131.39106106758, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 632520, "time": 28135.425426721573, "episode/length": 101.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 632800, "time": 28146.199291229248, "episode/length": 230.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 633064, "time": 28155.92844390869, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 633264, "time": 28163.959761857986, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 633768, "time": 28181.543860673904, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 633920, "time": 28188.12607884407, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 634216, "time": 28198.916137695312, "episode/length": 370.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9892183288409704, "episode/intrinsic_return": 0.0}
{"step": 634552, "time": 28211.182982444763, "episode/length": 218.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 634552, "time": 28211.19264650345, "episode/length": 289.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 634592, "time": 28215.946826934814, "episode/length": 190.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 634928, "time": 28228.240790605545, "episode/length": 421.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 635272, "time": 28240.516478300095, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 635504, "time": 28249.644804000854, "episode/length": 197.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 635992, "time": 28266.669367313385, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 636128, "time": 28272.743265390396, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 636200, "time": 28276.274242162704, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 636536, "time": 28288.520664691925, "episode/length": 289.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 636552, "time": 28290.503286600113, "episode/length": 130.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 636688, "time": 28296.713402986526, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 636928, "time": 28305.998473882675, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 637072, "time": 28312.666850090027, "episode/length": 134.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 637136, "time": 28316.7217566967, "episode/length": 275.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 637368, "time": 28326.275476932526, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 637648, "time": 28337.0463244915, "episode/length": 63.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 638016, "time": 28350.315370321274, "episode/length": 226.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 638288, "time": 28360.622400283813, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 638809, "time": 28379.5089366436, "train_stats/sum_log_reward": 7.127777859016701, "train_stats/max_log_achievement_collect_coal": 0.2777777777777778, "train_stats/max_log_achievement_collect_drink": 5.916666666666667, "train_stats/max_log_achievement_collect_sapling": 1.8888888888888888, "train_stats/max_log_achievement_collect_stone": 3.2777777777777777, "train_stats/max_log_achievement_collect_wood": 12.37962962962963, "train_stats/max_log_achievement_defeat_skeleton": 0.027777777777777776, "train_stats/max_log_achievement_defeat_zombie": 0.7129629629629629, "train_stats/max_log_achievement_eat_cow": 0.05555555555555555, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.6944444444444446, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.027777777777777776, "train_stats/max_log_achievement_place_plant": 1.7962962962962963, "train_stats/max_log_achievement_place_stone": 0.06481481481481481, "train_stats/max_log_achievement_place_table": 3.462962962962963, "train_stats/max_log_achievement_wake_up": 1.2592592592592593, "train_stats/mean_log_entropy": 0.3451008377251802, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.226577447385204, "train/action_min": 0.0, "train/action_std": 3.2353867884395884, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04092535299255329, "train/actor_opt_grad_steps": 39090.0, "train/actor_opt_loss": 1.15008975499544, "train/adv_mag": 0.5479382213686599, "train/adv_max": 0.5124610609748737, "train/adv_mean": 0.004285556629603431, "train/adv_min": -0.4381947890430892, "train/adv_std": 0.06210929320073452, "train/cont_avg": 0.994758450255102, "train/cont_loss_mean": 0.00025676777666215573, "train/cont_loss_std": 0.007729925139443788, "train/cont_neg_acc": 0.9901765483577235, "train/cont_neg_loss": 0.03654485445141061, "train/cont_pos_acc": 0.9999732492732353, "train/cont_pos_loss": 0.00010874561834684693, "train/cont_pred": 0.9947613287134235, "train/cont_rate": 0.994758450255102, "train/dyn_loss_mean": 13.030222263465934, "train/dyn_loss_std": 9.393698595008072, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8629574114773549, "train/extr_critic_critic_opt_grad_steps": 39090.0, "train/extr_critic_critic_opt_loss": 15944.400158110118, "train/extr_critic_mag": 6.446338322697853, "train/extr_critic_max": 6.446338322697853, "train/extr_critic_mean": 1.4580407296719193, "train/extr_critic_min": -0.23312546282398458, "train/extr_critic_std": 1.45568014894213, "train/extr_return_normed_mag": 1.6721218175628558, "train/extr_return_normed_max": 1.6721218175628558, "train/extr_return_normed_mean": 0.32669808436818676, "train/extr_return_normed_min": -0.12462540812232867, "train/extr_return_normed_std": 0.33012693532470133, "train/extr_return_rate": 0.6118095748278559, "train/extr_return_raw_mag": 7.546020611613786, "train/extr_return_raw_max": 7.546020611613786, "train/extr_return_raw_mean": 1.4774061700924723, "train/extr_return_raw_min": -0.5592017934030417, "train/extr_return_raw_std": 1.4895001329532287, "train/extr_reward_mag": 1.0221594709928343, "train/extr_reward_max": 1.0221594709928343, "train/extr_reward_mean": 0.0320158143001957, "train/extr_reward_min": -0.42468424313733366, "train/extr_reward_std": 0.16779757889152383, "train/image_loss_mean": 6.460065909794399, "train/image_loss_std": 11.239342631125936, "train/model_loss_mean": 14.331823310073542, "train/model_loss_std": 15.101866611818068, "train/model_opt_grad_norm": 60.754461210601185, "train/model_opt_grad_steps": 39051.62585034013, "train/model_opt_loss": 18171.750478316328, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.0068027210884, "train/policy_entropy_mag": 2.566101298040273, "train/policy_entropy_max": 2.566101298040273, "train/policy_entropy_mean": 0.5998552585540174, "train/policy_entropy_min": 0.0793750861875054, "train/policy_entropy_std": 0.7003927117302304, "train/policy_logprob_mag": 7.438383592229311, "train/policy_logprob_max": -0.009455670437895927, "train/policy_logprob_mean": -0.6004785345930631, "train/policy_logprob_min": -7.438383592229311, "train/policy_logprob_std": 1.139994665068023, "train/policy_randomness_mag": 0.9057211486660705, "train/policy_randomness_max": 0.9057211486660705, "train/policy_randomness_mean": 0.21172258470739638, "train/policy_randomness_min": 0.028015922096108092, "train/policy_randomness_std": 0.2472078909679335, "train/post_ent_mag": 60.44802340033914, "train/post_ent_max": 60.44802340033914, "train/post_ent_mean": 43.257829497460605, "train/post_ent_min": 20.6104800165916, "train/post_ent_std": 7.758246798093627, "train/prior_ent_mag": 69.54406769421635, "train/prior_ent_max": 69.54406769421635, "train/prior_ent_mean": 56.336030402151096, "train/prior_ent_min": 38.99897563700773, "train/prior_ent_std": 4.8442909052582825, "train/rep_loss_mean": 13.030222263465934, "train/rep_loss_std": 9.393698595008072, "train/reward_avg": 0.025147480649404787, "train/reward_loss_mean": 0.053367317026975204, "train/reward_loss_std": 0.23931039271711493, "train/reward_max_data": 1.0163265345047932, "train/reward_max_pred": 1.0094479160243963, "train/reward_neg_acc": 0.9928553051689044, "train/reward_neg_loss": 0.02946034814452841, "train/reward_pos_acc": 0.9712610601567898, "train/reward_pos_loss": 0.8280871210455083, "train/reward_pred": 0.02458475317273821, "train/reward_rate": 0.03001434948979592, "eval_stats/sum_log_reward": 6.10000005364418, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 1.5625, "eval_stats/max_log_achievement_collect_wood": 10.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.188600547015085e-06, "report/cont_loss_std": 1.3397690054262057e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00010513620509300381, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.7848842617240734e-06, "report/cont_pred": 0.9960923194885254, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.554930686950684, "report/dyn_loss_std": 9.581939697265625, "report/image_loss_mean": 8.7378568649292, "report/image_loss_std": 12.673415184020996, "report/model_loss_mean": 16.923294067382812, "report/model_loss_std": 16.706377029418945, "report/post_ent_mag": 60.712364196777344, "report/post_ent_max": 60.712364196777344, "report/post_ent_mean": 43.80591583251953, "report/post_ent_min": 18.96879005432129, "report/post_ent_std": 7.7827067375183105, "report/prior_ent_mag": 70.17462921142578, "report/prior_ent_max": 70.17462921142578, "report/prior_ent_mean": 57.17156982421875, "report/prior_ent_min": 38.61258316040039, "report/prior_ent_std": 5.20707893371582, "report/rep_loss_mean": 13.554930686950684, "report/rep_loss_std": 9.581939697265625, "report/reward_avg": 0.02460937574505806, "report/reward_loss_mean": 0.05247735604643822, "report/reward_loss_std": 0.25453364849090576, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004199504852295, "report/reward_neg_acc": 0.9939759969711304, "report/reward_neg_loss": 0.02777506224811077, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 0.9311733841896057, "report/reward_pred": 0.02351536974310875, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0005368207348510623, "eval/cont_loss_std": 0.010205031372606754, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.717166201677173e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0005377006018534303, "eval/cont_pred": 0.9975584745407104, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.19705581665039, "eval/dyn_loss_std": 9.805078506469727, "eval/image_loss_mean": 11.562882423400879, "eval/image_loss_std": 13.981107711791992, "eval/model_loss_mean": 20.77304458618164, "eval/model_loss_std": 17.480445861816406, "eval/post_ent_mag": 59.08232116699219, "eval/post_ent_max": 59.08232116699219, "eval/post_ent_mean": 43.13927459716797, "eval/post_ent_min": 19.346904754638672, "eval/post_ent_std": 7.291593074798584, "eval/prior_ent_mag": 70.17462921142578, "eval/prior_ent_max": 70.17462921142578, "eval/prior_ent_mean": 56.331871032714844, "eval/prior_ent_min": 36.29697036743164, "eval/prior_ent_std": 5.284170150756836, "eval/rep_loss_mean": 15.19705581665039, "eval/rep_loss_std": 9.805078506469727, "eval/reward_avg": 0.04384765774011612, "eval/reward_loss_mean": 0.09139455109834671, "eval/reward_loss_std": 0.5446428060531616, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023736953735352, "eval/reward_neg_acc": 0.9907787442207336, "eval/reward_neg_loss": 0.03688279166817665, "eval/reward_pos_acc": 0.9166666865348816, "eval/reward_pos_loss": 1.1998003721237183, "eval/reward_pred": 0.039962902665138245, "eval/reward_rate": 0.046875, "replay/size": 638305.0, "replay/inserts": 23632.0, "replay/samples": 23632.0, "replay/insert_wait_avg": 1.3276864002101228e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.708147723043619e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4144.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.178630070336537e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3427183628082, "timer/env.step_count": 2954.0, "timer/env.step_total": 241.6768922805786, "timer/env.step_frac": 0.24159409354837358, "timer/env.step_avg": 0.08181343679098801, "timer/env.step_min": 0.02213263511657715, "timer/env.step_max": 3.3010523319244385, "timer/replay._sample_count": 23632.0, "timer/replay._sample_total": 11.827633380889893, "timer/replay._sample_frac": 0.011823581222490791, "timer/replay._sample_avg": 0.0005004922723802426, "timer/replay._sample_min": 0.00037550926208496094, "timer/replay._sample_max": 0.009390592575073242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3472.0, "timer/agent.policy_total": 52.89137315750122, "timer/agent.policy_frac": 0.052873252522960205, "timer/agent.policy_avg": 0.015233690425547586, "timer/agent.policy_min": 0.008405208587646484, "timer/agent.policy_max": 0.10248208045959473, "timer/dataset_train_count": 1477.0, "timer/dataset_train_total": 0.19153642654418945, "timer/dataset_train_frac": 0.00019147080598303737, "timer/dataset_train_avg": 0.00012967936800554466, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.03801441192626953, "timer/agent.train_count": 1477.0, "timer/agent.train_total": 640.3212339878082, "timer/agent.train_frac": 0.6401018593265493, "timer/agent.train_avg": 0.4335282559159162, "timer/agent.train_min": 0.42255473136901855, "timer/agent.train_max": 1.3443832397460938, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4768195152282715, "timer/agent.report_frac": 0.00047665615641072394, "timer/agent.report_avg": 0.23840975761413574, "timer/agent.report_min": 0.23136043548583984, "timer/agent.report_max": 0.24545907974243164, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2413817947193276e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 23.623599158089196}
{"step": 638840, "time": 28380.229786396027, "episode/length": 220.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 638984, "time": 28386.987817287445, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 639112, "time": 28394.382553577423, "episode/length": 321.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 639352, "time": 28403.776875972748, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 639680, "time": 28416.126708745956, "episode/length": 373.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 639736, "time": 28419.21839594841, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 28444.614234685898, "eval_episode/length": 42.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 640016, "time": 28446.37746477127, "eval_episode/length": 47.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 640016, "time": 28451.166888952255, "eval_episode/length": 128.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9612403100775194}
{"step": 640016, "time": 28454.157781600952, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 640016, "time": 28456.673557281494, "eval_episode/length": 186.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 640016, "time": 28460.78993153572, "eval_episode/length": 246.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9757085020242915}
{"step": 640016, "time": 28464.086035728455, "eval_episode/length": 288.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.986159169550173}
{"step": 640016, "time": 28465.714327335358, "eval_episode/length": 247.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 640232, "time": 28472.548685073853, "episode/length": 357.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 640392, "time": 28479.188692331314, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 640480, "time": 28483.803519010544, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 640640, "time": 28490.51079583168, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 640920, "time": 28500.766195058823, "episode/length": 241.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 641160, "time": 28510.077917575836, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 641240, "time": 28514.128289461136, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 641552, "time": 28525.813866853714, "episode/length": 274.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 641872, "time": 28537.6818087101, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 641992, "time": 28542.894995450974, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 642040, "time": 28545.89696264267, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 642112, "time": 28549.95197868347, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 642432, "time": 28561.75899887085, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 642696, "time": 28571.681271791458, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 642728, "time": 28574.146286010742, "episode/length": 280.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 642960, "time": 28583.311485528946, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 643072, "time": 28588.31612586975, "episode/length": 119.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 643280, "time": 28596.589392900467, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 643592, "time": 28607.80916571617, "episode/length": 193.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 643856, "time": 28617.981961250305, "episode/length": 247.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 643976, "time": 28623.324055671692, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 644184, "time": 28631.605776786804, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 644320, "time": 28637.80183506012, "episode/length": 155.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 644680, "time": 28650.726861715317, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 644776, "time": 28655.513545513153, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 645024, "time": 28665.22858452797, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 645160, "time": 28670.914180994034, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 645240, "time": 28675.020647764206, "episode/length": 131.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 645504, "time": 28685.30878162384, "episode/length": 205.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 645632, "time": 28690.925433158875, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 645832, "time": 28698.67272567749, "episode/length": 231.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 646032, "time": 28706.8450255394, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 646448, "time": 28721.81218266487, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 646456, "time": 28723.514003276825, "episode/length": 209.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 646496, "time": 28726.550173282623, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 646720, "time": 28735.259219169617, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 646856, "time": 28740.900429725647, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 647272, "time": 28757.192348718643, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 647528, "time": 28766.999239206314, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 647720, "time": 28774.721736192703, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 647728, "time": 28776.704244613647, "episode/length": 159.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 647944, "time": 28784.93354344368, "episode/length": 51.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 648360, "time": 28799.6503033638, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 648416, "time": 28803.277796030045, "episode/length": 58.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 648752, "time": 28815.55786561966, "episode/length": 184.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 648824, "time": 28819.182321071625, "episode/length": 290.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 649088, "time": 28829.34408068657, "episode/length": 83.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 649216, "time": 28835.07837152481, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 649360, "time": 28841.293635845184, "episode/length": 465.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9978540772532188, "episode/intrinsic_return": 0.0}
{"step": 649488, "time": 28846.927397727966, "episode/length": 328.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9969604863221885, "episode/intrinsic_return": 0.0}
{"step": 649544, "time": 28850.022367477417, "episode/length": 98.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 649600, "time": 28853.58873772621, "episode/length": 47.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 649904, "time": 28864.896555662155, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 28887.265974760056, "eval_episode/length": 126.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9921259842519685}
{"step": 650000, "time": 28892.375960588455, "eval_episode/length": 206.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 650000, "time": 28894.36300587654, "eval_episode/length": 215.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 650000, "time": 28896.533158302307, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 650000, "time": 28899.204194307327, "eval_episode/length": 258.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9961389961389961}
{"step": 650000, "time": 28902.052377939224, "eval_episode/length": 288.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9757785467128027}
{"step": 650000, "time": 28904.273994207382, "eval_episode/length": 180.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 650000, "time": 28906.488990306854, "eval_episode/length": 90.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9340659340659341}
{"step": 650592, "time": 28925.576588392258, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 650696, "time": 28930.132972717285, "episode/length": 143.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 650704, "time": 28932.120334386826, "episode/length": 372.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946380697050938, "episode/intrinsic_return": 0.0}
{"step": 650744, "time": 28934.700354337692, "episode/length": 156.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 651264, "time": 28953.257311582565, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 651560, "time": 28964.127746105194, "episode/length": 341.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 651704, "time": 28970.31319832802, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 651936, "time": 28979.56557059288, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 652176, "time": 28989.09062576294, "episode/length": 321.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 652384, "time": 28997.383705854416, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 652424, "time": 29000.02725672722, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 652632, "time": 29008.382845640182, "episode/length": 241.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 652960, "time": 29020.907618284225, "episode/length": 381.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 653008, "time": 29024.008193969727, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 653128, "time": 29029.185565948486, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 653320, "time": 29036.888986825943, "episode/length": 142.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 653696, "time": 29050.84294462204, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 653792, "time": 29055.36771941185, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 654056, "time": 29065.282237768173, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 654280, "time": 29074.091578245163, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 654288, "time": 29076.014125585556, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 654544, "time": 29085.837588071823, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 655104, "time": 29105.425841093063, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 655568, "time": 29123.24027991295, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 655672, "time": 29127.89999985695, "episode/length": 293.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 655728, "time": 29131.43799996376, "episode/length": 253.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 655776, "time": 29134.506680965424, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 656240, "time": 29151.075830459595, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 656280, "time": 29153.738855838776, "episode/length": 88.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 656392, "time": 29158.77218604088, "episode/length": 230.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 656464, "time": 29162.808305740356, "episode/length": 437.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 656896, "time": 29178.325744390488, "episode/length": 62.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 657064, "time": 29185.095353126526, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 657216, "time": 29191.89241194725, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 657680, "time": 29208.369955062866, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 657984, "time": 29219.713039636612, "episode/length": 135.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 658272, "time": 29230.772558927536, "episode/length": 498.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9939879759519038, "episode/intrinsic_return": 0.0}
{"step": 658584, "time": 29242.814208507538, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726962457337884, "episode/intrinsic_return": 0.0}
{"step": 658896, "time": 29255.50609588623, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 659056, "time": 29262.83375597, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 659104, "time": 29266.329930067062, "episode/length": 139.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 659216, "time": 29271.423835992813, "episode/length": 366.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 659472, "time": 29281.197940826416, "episode/length": 300.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 29321.676552295685, "eval_episode/length": 162.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 660088, "time": 29323.357855796814, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 660088, "time": 29325.076444864273, "eval_episode/length": 173.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 660088, "time": 29327.53809952736, "eval_episode/length": 194.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 660088, "time": 29329.181876897812, "eval_episode/length": 198.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 660088, "time": 29331.2960190773, "eval_episode/length": 210.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 660088, "time": 29337.647537708282, "eval_episode/length": 162.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 660088, "time": 29339.48514175415, "eval_episode/length": 335.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 660136, "time": 29341.054086208344, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 660600, "time": 29357.612182617188, "episode/length": 516.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9922630560928434, "episode/intrinsic_return": 0.0}
{"step": 660704, "time": 29362.668711423874, "episode/length": 303.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 660768, "time": 29366.22776532173, "episode/length": 193.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 661113, "time": 29379.773788928986, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.298642839704241, "train/action_min": 0.0, "train/action_std": 3.2937900985990254, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03924284719728998, "train/actor_opt_grad_steps": 40525.0, "train/actor_opt_loss": -3.479529132161822, "train/adv_mag": 0.5285126096435956, "train/adv_max": 0.49560974410602027, "train/adv_mean": 0.0029687936404765684, "train/adv_min": -0.4170149694596018, "train/adv_std": 0.05961396364229066, "train/cont_avg": 0.9947265625, "train/cont_loss_mean": 0.00023488336208004056, "train/cont_loss_std": 0.0072193418324543145, "train/cont_neg_acc": 0.9891496620007924, "train/cont_neg_loss": 0.029464041649537517, "train/cont_pos_acc": 0.999978945510728, "train/cont_pos_loss": 8.203661863570894e-05, "train/cont_pred": 0.9947428945984159, "train/cont_rate": 0.9947265625, "train/dyn_loss_mean": 13.134114381245205, "train/dyn_loss_std": 9.413178825378418, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8694984878812517, "train/extr_critic_critic_opt_grad_steps": 40525.0, "train/extr_critic_critic_opt_loss": 15876.370717075893, "train/extr_critic_mag": 6.704369034085955, "train/extr_critic_max": 6.704369034085955, "train/extr_critic_mean": 1.627931740454265, "train/extr_critic_min": -0.2345833224909646, "train/extr_critic_std": 1.5473229825496673, "train/extr_return_normed_mag": 1.6472317848886762, "train/extr_return_normed_max": 1.6472317848886762, "train/extr_return_normed_mean": 0.34519234352878164, "train/extr_return_normed_min": -0.11362795249692031, "train/extr_return_normed_std": 0.33140197438853125, "train/extr_return_rate": 0.6574316723006112, "train/extr_return_raw_mag": 7.83746382849557, "train/extr_return_raw_max": 7.83746382849557, "train/extr_return_raw_mean": 1.6420060294015066, "train/extr_return_raw_min": -0.5414708652666637, "train/extr_return_raw_std": 1.5772524126938412, "train/extr_reward_mag": 1.026069826739175, "train/extr_reward_max": 1.026069826739175, "train/extr_reward_mean": 0.03337246592688773, "train/extr_reward_min": -0.40293917315346856, "train/extr_reward_std": 0.17236539274454116, "train/image_loss_mean": 6.386801624298096, "train/image_loss_std": 11.370866104534693, "train/model_loss_mean": 14.321794605255127, "train/model_loss_std": 15.266026891980852, "train/model_opt_grad_norm": 60.12668170928955, "train/model_opt_grad_steps": 40485.328571428574, "train/model_opt_loss": 18028.105964006696, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9285714285713, "train/policy_entropy_mag": 2.5500329341207233, "train/policy_entropy_max": 2.5500329341207233, "train/policy_entropy_mean": 0.6163446583918163, "train/policy_entropy_min": 0.07937508358487061, "train/policy_entropy_std": 0.7228387074811118, "train/policy_logprob_mag": 7.438383660997663, "train/policy_logprob_max": -0.009455671926428164, "train/policy_logprob_mean": -0.6174581191369466, "train/policy_logprob_min": -7.438383660997663, "train/policy_logprob_std": 1.1511818383421217, "train/policy_randomness_mag": 0.9000497238976615, "train/policy_randomness_max": 0.9000497238976615, "train/policy_randomness_mean": 0.21754261808735983, "train/policy_randomness_min": 0.028015921224973032, "train/policy_randomness_std": 0.25513034090399744, "train/post_ent_mag": 60.09336506979806, "train/post_ent_max": 60.09336506979806, "train/post_ent_mean": 43.16515064239502, "train/post_ent_min": 20.498708016531808, "train/post_ent_std": 7.75362263747624, "train/prior_ent_mag": 69.51246550423758, "train/prior_ent_max": 69.51246550423758, "train/prior_ent_mean": 56.36558535439627, "train/prior_ent_min": 38.989282853262765, "train/prior_ent_std": 4.747716384274619, "train/rep_loss_mean": 13.134114381245205, "train/rep_loss_std": 9.413178825378418, "train/reward_avg": 0.026732003003624934, "train/reward_loss_mean": 0.05428955436551145, "train/reward_loss_std": 0.24752671771815846, "train/reward_max_data": 1.0128571459225246, "train/reward_max_pred": 1.0091020950249263, "train/reward_neg_acc": 0.9934171621288572, "train/reward_neg_loss": 0.028670700772532396, "train/reward_pos_acc": 0.9682015082665852, "train/reward_pos_loss": 0.8454241480146135, "train/reward_pred": 0.026006888072671635, "train/reward_rate": 0.031431361607142855, "train_stats/sum_log_reward": 7.373585040558059, "train_stats/max_log_achievement_collect_coal": 0.32075471698113206, "train_stats/max_log_achievement_collect_drink": 5.047169811320755, "train_stats/max_log_achievement_collect_sapling": 2.292452830188679, "train_stats/max_log_achievement_collect_stone": 3.5660377358490565, "train_stats/max_log_achievement_collect_wood": 12.754716981132075, "train_stats/max_log_achievement_defeat_skeleton": 0.018867924528301886, "train_stats/max_log_achievement_defeat_zombie": 0.6886792452830188, "train_stats/max_log_achievement_eat_cow": 0.1320754716981132, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.707547169811321, "train_stats/max_log_achievement_make_wood_sword": 0.02830188679245283, "train_stats/max_log_achievement_place_furnace": 0.1320754716981132, "train_stats/max_log_achievement_place_plant": 2.188679245283019, "train_stats/max_log_achievement_place_stone": 0.09433962264150944, "train_stats/max_log_achievement_place_table": 3.6132075471698113, "train_stats/max_log_achievement_wake_up": 1.330188679245283, "train_stats/mean_log_entropy": 0.3652298890475957, "eval_stats/sum_log_reward": 7.183333436648051, "eval_stats/max_log_achievement_collect_coal": 0.20833333333333334, "eval_stats/max_log_achievement_collect_drink": 4.958333333333333, "eval_stats/max_log_achievement_collect_sapling": 1.9583333333333333, "eval_stats/max_log_achievement_collect_stone": 2.9166666666666665, "eval_stats/max_log_achievement_collect_wood": 12.708333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.16666666666666666, "eval_stats/max_log_achievement_place_table": 3.6666666666666665, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.045454545454545456, "train_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 1.2494803058871184e-07, "report/cont_loss_std": 2.0933266569045372e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.569304292090237e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.5773663142890655e-08, "report/cont_pred": 0.9980469346046448, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.135148048400879, "report/dyn_loss_std": 9.181200981140137, "report/image_loss_mean": 6.5583930015563965, "report/image_loss_std": 12.836499214172363, "report/model_loss_mean": 13.889137268066406, "report/model_loss_std": 16.958974838256836, "report/post_ent_mag": 62.587493896484375, "report/post_ent_max": 62.587493896484375, "report/post_ent_mean": 43.223793029785156, "report/post_ent_min": 19.92163848876953, "report/post_ent_std": 7.6003265380859375, "report/prior_ent_mag": 69.72478485107422, "report/prior_ent_max": 69.72478485107422, "report/prior_ent_mean": 55.73600769042969, "report/prior_ent_min": 39.24559020996094, "report/prior_ent_std": 5.109976768493652, "report/rep_loss_mean": 12.135148048400879, "report/rep_loss_std": 9.181200981140137, "report/reward_avg": 0.02480468712747097, "report/reward_loss_mean": 0.049656227231025696, "report/reward_loss_std": 0.2196698784828186, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0036695003509521, "report/reward_neg_acc": 0.9949849843978882, "report/reward_neg_loss": 0.025283511728048325, "report/reward_pos_acc": 0.9259259104728699, "report/reward_pos_loss": 0.9496414661407471, "report/reward_pred": 0.02123946137726307, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.3169134945201222e-05, "eval/cont_loss_std": 0.0003459436702542007, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003770074399653822, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1383864148228895e-05, "eval/cont_pred": 0.9951077699661255, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.212053298950195, "eval/dyn_loss_std": 10.72771167755127, "eval/image_loss_mean": 11.020612716674805, "eval/image_loss_std": 13.076081275939941, "eval/model_loss_mean": 20.87417984008789, "eval/model_loss_std": 17.80634117126465, "eval/post_ent_mag": 61.40037536621094, "eval/post_ent_max": 61.40037536621094, "eval/post_ent_mean": 42.80626678466797, "eval/post_ent_min": 19.8123722076416, "eval/post_ent_std": 7.511220455169678, "eval/prior_ent_mag": 69.72478485107422, "eval/prior_ent_max": 69.72478485107422, "eval/prior_ent_mean": 57.11311340332031, "eval/prior_ent_min": 41.20484924316406, "eval/prior_ent_std": 4.533175468444824, "eval/rep_loss_mean": 16.212053298950195, "eval/rep_loss_std": 10.72771167755127, "eval/reward_avg": 0.03789062798023224, "eval/reward_loss_mean": 0.1263224184513092, "eval/reward_loss_std": 0.7582860589027405, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000274896621704, "eval/reward_neg_acc": 0.9918534159660339, "eval/reward_neg_loss": 0.040746983140707016, "eval/reward_pos_acc": 0.761904776096344, "eval/reward_pos_loss": 2.1271581649780273, "eval/reward_pred": 0.03171980753540993, "eval/reward_rate": 0.041015625, "replay/size": 660609.0, "replay/inserts": 22304.0, "replay/samples": 22304.0, "replay/insert_wait_avg": 1.322055820755158e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.087356638532116e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.146103206433748e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2399623394012, "timer/env.step_count": 2788.0, "timer/env.step_total": 237.77091693878174, "timer/env.step_frac": 0.23771387456133386, "timer/env.step_avg": 0.08528368613299202, "timer/env.step_min": 0.02278447151184082, "timer/env.step_max": 3.3148505687713623, "timer/replay._sample_count": 22304.0, "timer/replay._sample_total": 11.19888687133789, "timer/replay._sample_frac": 0.011196200204944308, "timer/replay._sample_avg": 0.000502102173212782, "timer/replay._sample_min": 0.00042057037353515625, "timer/replay._sample_max": 0.022313594818115234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3738.0, "timer/agent.policy_total": 55.87260890007019, "timer/agent.policy_frac": 0.05585920479461058, "timer/agent.policy_avg": 0.014947193392207113, "timer/agent.policy_min": 0.008441448211669922, "timer/agent.policy_max": 0.08383774757385254, "timer/dataset_train_count": 1394.0, "timer/dataset_train_total": 0.14789772033691406, "timer/dataset_train_frac": 0.00014786223896814216, "timer/dataset_train_avg": 0.00010609592563623677, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0003387928009033203, "timer/agent.train_count": 1394.0, "timer/agent.train_total": 605.1180219650269, "timer/agent.train_frac": 0.6049728512643632, "timer/agent.train_avg": 0.4340875336908371, "timer/agent.train_min": 0.4159562587738037, "timer/agent.train_max": 1.340372085571289, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48157525062561035, "timer/agent.report_frac": 0.0004814597184252496, "timer/agent.report_avg": 0.24078762531280518, "timer/agent.report_min": 0.2325437068939209, "timer/agent.report_max": 0.24903154373168945, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7888281617583976e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.298335904848244}
{"step": 661128, "time": 29379.85335302353, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974910394265233, "episode/intrinsic_return": 0.0}
{"step": 661176, "time": 29383.264872312546, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 661336, "time": 29389.946447610855, "episode/length": 232.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 662128, "time": 29417.188819885254, "episode/length": 377.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 662248, "time": 29422.295795679092, "episode/length": 205.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 662480, "time": 29431.51452755928, "episode/length": 162.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 662488, "time": 29432.99874138832, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 662560, "time": 29437.018849611282, "episode/length": 302.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 662968, "time": 29451.549833536148, "episode/length": 274.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 663032, "time": 29455.129311800003, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 663800, "time": 29482.832753658295, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 664064, "time": 29493.120582580566, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 664088, "time": 29495.249903440475, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 664192, "time": 29500.370975732803, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 664240, "time": 29503.4901804924, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 664272, "time": 29506.104957580566, "episode/length": 392.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 664544, "time": 29516.296279668808, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 664752, "time": 29524.555378437042, "episode/length": 118.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 665024, "time": 29534.767151117325, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 665488, "time": 29551.877620220184, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 665776, "time": 29562.53721189499, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 666032, "time": 29572.395663499832, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 666104, "time": 29575.964356422424, "episode/length": 76.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 666112, "time": 29577.97930431366, "episode/length": 252.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 666168, "time": 29581.049771547318, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 666360, "time": 29588.931346178055, "episode/length": 200.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 666568, "time": 29597.189908981323, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 667264, "time": 29621.20231962204, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 667472, "time": 29629.48367166519, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 667704, "time": 29638.344415426254, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 667776, "time": 29642.39611339569, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 667888, "time": 29647.564590215683, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 668520, "time": 29669.11139535904, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9713114754098361, "episode/intrinsic_return": 0.0}
{"step": 668680, "time": 29675.901873350143, "episode/length": 330.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 668872, "time": 29683.57494854927, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 668984, "time": 29688.685685396194, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 669528, "time": 29707.682459115982, "episode/length": 395.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 669544, "time": 29709.63081073761, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 669688, "time": 29715.81098842621, "episode/length": 224.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 29748.985003709793, "eval_episode/length": 125.0, "eval_episode/score": 7.1000000461936, "eval_episode/reward_rate": 0.9920634920634921}
{"step": 670072, "time": 29751.734145641327, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 670072, "time": 29755.37412428856, "eval_episode/length": 204.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9804878048780488}
{"step": 670072, "time": 29756.940848350525, "eval_episode/length": 206.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 670072, "time": 29758.83385872841, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 670072, "time": 29760.71729874611, "eval_episode/length": 221.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 670072, "time": 29764.31881761551, "eval_episode/length": 56.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 670072, "time": 29767.027109861374, "eval_episode/length": 300.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9833887043189369}
{"step": 670176, "time": 29770.583173274994, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 670288, "time": 29775.724985599518, "episode/length": 162.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 670472, "time": 29782.983340024948, "episode/length": 400.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 670936, "time": 29799.581329345703, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 671040, "time": 29804.71199631691, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 671792, "time": 29832.022421360016, "episode/length": 388.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 672000, "time": 29840.262946605682, "episode/length": 132.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 672136, "time": 29846.03291296959, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 672184, "time": 29849.054822206497, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 672200, "time": 29851.220583677292, "episode/length": 50.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 672464, "time": 29861.482033014297, "episode/length": 57.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 672480, "time": 29863.58334493637, "episode/length": 366.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 672760, "time": 29874.078348636627, "episode/length": 285.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 673488, "time": 29899.398957252502, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 673512, "time": 29901.428633213043, "episode/length": 128.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 673768, "time": 29911.33645582199, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 674216, "time": 29927.294698238373, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 674248, "time": 29929.889303445816, "episode/length": 400.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 674304, "time": 29933.351558446884, "episode/length": 264.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 674320, "time": 29935.332572221756, "episode/length": 680.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9897209985315712, "episode/intrinsic_return": 0.0}
{"step": 674824, "time": 29953.1094622612, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 675328, "time": 29971.095635652542, "episode/length": 390.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769820971867008, "episode/intrinsic_return": 0.0}
{"step": 675368, "time": 29973.798129081726, "episode/length": 132.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 675480, "time": 29979.02786898613, "episode/length": 245.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 675536, "time": 29982.60612821579, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 675584, "time": 29985.818479776382, "episode/length": 170.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 675696, "time": 29991.147364616394, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 676528, "time": 30019.48836874962, "episode/length": 275.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 676552, "time": 30021.551714897156, "episode/length": 126.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 676752, "time": 30029.835392713547, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 676824, "time": 30033.63953113556, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 676896, "time": 30037.64099097252, "episode/length": 163.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 676904, "time": 30039.248743772507, "episode/length": 177.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 677328, "time": 30054.46444439888, "episode/length": 62.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 677592, "time": 30064.292952775955, "episode/length": 345.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 677768, "time": 30071.431906700134, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 677816, "time": 30074.605347156525, "episode/length": 60.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 677928, "time": 30079.755074977875, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 678280, "time": 30092.61255121231, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 678368, "time": 30097.31207871437, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 678392, "time": 30099.37760734558, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 678656, "time": 30109.54956150055, "episode/length": 104.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 678952, "time": 30120.270303726196, "episode/length": 127.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 679040, "time": 30124.927742004395, "episode/length": 267.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 679784, "time": 30151.57630944252, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 680032, "time": 30163.33229112625, "episode/length": 304.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 30188.998834848404, "eval_episode/length": 139.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 680056, "time": 30191.21490573883, "eval_episode/length": 145.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 680056, "time": 30195.548639535904, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 680056, "time": 30197.638741016388, "eval_episode/length": 57.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 680056, "time": 30200.128905773163, "eval_episode/length": 205.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 680056, "time": 30202.589732408524, "eval_episode/length": 216.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 680056, "time": 30204.741426229477, "eval_episode/length": 35.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 680056, "time": 30207.121774435043, "eval_episode/length": 106.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9906542056074766}
{"step": 680248, "time": 30213.360771417618, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 680304, "time": 30216.98172354698, "episode/length": 157.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 680440, "time": 30222.636915445328, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 680664, "time": 30231.293187618256, "episode/length": 361.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751381215469613, "episode/intrinsic_return": 0.0}
{"step": 680840, "time": 30238.521854400635, "episode/length": 131.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 681368, "time": 30257.044291734695, "episode/length": 87.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 681368, "time": 30257.05339360237, "episode/length": 301.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 681616, "time": 30268.50507736206, "episode/length": 369.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972972972972973, "episode/intrinsic_return": 0.0}
{"step": 681776, "time": 30275.241354465485, "episode/length": 166.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 682640, "time": 30304.57874941826, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 682680, "time": 30307.174920082092, "episode/length": 330.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 682880, "time": 30315.235570192337, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 683112, "time": 30323.914063692093, "episode/length": 283.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 683136, "time": 30326.42164158821, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 683152, "time": 30328.406143426895, "episode/length": 355.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 683304, "time": 30334.671942472458, "episode/length": 82.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 683568, "time": 30344.933866500854, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 683576, "time": 30346.523824214935, "episode/length": 57.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 683840, "time": 30356.798018693924, "episode/length": 257.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 684032, "time": 30364.58770751953, "episode/length": 56.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 684328, "time": 30375.443556785583, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 684393, "time": 30380.091756105423, "train_stats/sum_log_reward": 7.411320877525042, "train_stats/max_log_achievement_collect_coal": 0.330188679245283, "train_stats/max_log_achievement_collect_drink": 4.830188679245283, "train_stats/max_log_achievement_collect_sapling": 1.8679245283018868, "train_stats/max_log_achievement_collect_stone": 4.226415094339623, "train_stats/max_log_achievement_collect_wood": 11.641509433962264, "train_stats/max_log_achievement_defeat_skeleton": 0.03773584905660377, "train_stats/max_log_achievement_defeat_zombie": 0.6415094339622641, "train_stats/max_log_achievement_eat_cow": 0.0660377358490566, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009433962264150943, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.481132075471698, "train_stats/max_log_achievement_make_wood_sword": 0.03773584905660377, "train_stats/max_log_achievement_place_furnace": 0.24528301886792453, "train_stats/max_log_achievement_place_plant": 1.830188679245283, "train_stats/max_log_achievement_place_stone": 0.20754716981132076, "train_stats/max_log_achievement_place_table": 3.481132075471698, "train_stats/max_log_achievement_wake_up": 1.2641509433962264, "train_stats/mean_log_entropy": 0.432996983657468, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.328950447871767, "train/action_min": 0.0, "train/action_std": 3.406211333439268, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03820074399740531, "train/actor_opt_grad_steps": 41950.0, "train/actor_opt_loss": -5.805658125158014, "train/adv_mag": 0.5368875871444571, "train/adv_max": 0.5083184599876404, "train/adv_mean": 0.0025070697501711225, "train/adv_min": -0.41110635358711767, "train/adv_std": 0.058092931555262926, "train/cont_avg": 0.9948410560344828, "train/cont_loss_mean": 0.000352005448978969, "train/cont_loss_std": 0.00946913846220829, "train/cont_neg_acc": 0.9910563773122327, "train/cont_neg_loss": 0.04141002574971684, "train/cont_pos_acc": 0.9999593340117355, "train/cont_pos_loss": 0.00011639722516176001, "train/cont_pred": 0.9948554104772107, "train/cont_rate": 0.9948410560344828, "train/dyn_loss_mean": 13.193007186363483, "train/dyn_loss_std": 9.412950851177348, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8999098695557693, "train/extr_critic_critic_opt_grad_steps": 41950.0, "train/extr_critic_critic_opt_loss": 15713.260647898707, "train/extr_critic_mag": 6.7580627145438354, "train/extr_critic_max": 6.7580627145438354, "train/extr_critic_mean": 1.6146532724643576, "train/extr_critic_min": -0.21966848291199784, "train/extr_critic_std": 1.57073589768903, "train/extr_return_normed_mag": 1.6430739016368472, "train/extr_return_normed_max": 1.6430739016368472, "train/extr_return_normed_mean": 0.33664323862256673, "train/extr_return_normed_min": -0.10721717299572353, "train/extr_return_normed_std": 0.3293785099325509, "train/extr_return_rate": 0.6520739401208944, "train/extr_return_raw_mag": 7.970345921351992, "train/extr_return_raw_max": 7.970345921351992, "train/extr_return_raw_mean": 1.6268110106731284, "train/extr_return_raw_min": -0.5287078364142056, "train/extr_return_raw_std": 1.5995523312996174, "train/extr_reward_mag": 1.0243650650155955, "train/extr_reward_max": 1.0243650650155955, "train/extr_reward_mean": 0.033517334128505195, "train/extr_reward_min": -0.40304880224425216, "train/extr_reward_std": 0.1719873348700589, "train/image_loss_mean": 6.47962440622264, "train/image_loss_std": 11.079151077928215, "train/model_loss_mean": 14.449016748625656, "train/model_loss_std": 14.976916471020928, "train/model_opt_grad_norm": 58.42551141936204, "train/model_opt_grad_steps": 41908.82068965517, "train/model_opt_loss": 18660.76519396552, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1293.103448275862, "train/policy_entropy_mag": 2.548181984342378, "train/policy_entropy_max": 2.548181984342378, "train/policy_entropy_mean": 0.6305825642470656, "train/policy_entropy_min": 0.07937508189472658, "train/policy_entropy_std": 0.7257660360171877, "train/policy_logprob_mag": 7.438383681198646, "train/policy_logprob_max": -0.009455671431175594, "train/policy_logprob_mean": -0.6305203378200531, "train/policy_logprob_min": -7.438383681198646, "train/policy_logprob_std": 1.155216765814814, "train/policy_randomness_mag": 0.8993964150034148, "train/policy_randomness_max": 0.8993964150034148, "train/policy_randomness_mean": 0.22256797182148902, "train/policy_randomness_min": 0.028015920571212112, "train/policy_randomness_std": 0.2561635600081806, "train/post_ent_mag": 59.983884482548156, "train/post_ent_max": 59.983884482548156, "train/post_ent_mean": 43.04845236416521, "train/post_ent_min": 20.596552769891147, "train/post_ent_std": 7.670157047797893, "train/prior_ent_mag": 69.68499598009834, "train/prior_ent_max": 69.68499598009834, "train/prior_ent_mean": 56.314831884976094, "train/prior_ent_min": 39.03788675768622, "train/prior_ent_std": 4.809292013891812, "train/rep_loss_mean": 13.193007186363483, "train/rep_loss_std": 9.412950851177348, "train/reward_avg": 0.026516702552807744, "train/reward_loss_mean": 0.05323611328314091, "train/reward_loss_std": 0.2400183433088763, "train/reward_max_data": 1.0062068980315635, "train/reward_max_pred": 1.0054311234375526, "train/reward_neg_acc": 0.992853715090916, "train/reward_neg_loss": 0.02869040875470844, "train/reward_pos_acc": 0.9742868739983132, "train/reward_pos_loss": 0.8194398440163712, "train/reward_pred": 0.026070919498030483, "train/reward_rate": 0.03093345905172414, "eval_stats/sum_log_reward": 6.975000202655792, "eval_stats/max_log_achievement_collect_coal": 0.625, "eval_stats/max_log_achievement_collect_drink": 2.625, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 3.6875, "eval_stats/max_log_achievement_collect_wood": 9.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.0721850887639448e-05, "report/cont_loss_std": 0.00030684215016663074, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003165649832226336, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.9561681256163865e-05, "report/cont_pred": 0.9960756301879883, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.682626724243164, "report/dyn_loss_std": 9.824275970458984, "report/image_loss_mean": 5.994149208068848, "report/image_loss_std": 10.491443634033203, "report/model_loss_mean": 13.650309562683105, "report/model_loss_std": 14.611329078674316, "report/post_ent_mag": 59.862464904785156, "report/post_ent_max": 59.862464904785156, "report/post_ent_mean": 43.82333755493164, "report/post_ent_min": 19.144969940185547, "report/post_ent_std": 8.611502647399902, "report/prior_ent_mag": 69.85929870605469, "report/prior_ent_max": 69.85929870605469, "report/prior_ent_mean": 56.77259063720703, "report/prior_ent_min": 40.65978240966797, "report/prior_ent_std": 4.4128241539001465, "report/rep_loss_mean": 12.682626724243164, "report/rep_loss_std": 9.824275970458984, "report/reward_avg": 0.02656250074505806, "report/reward_loss_mean": 0.04656410217285156, "report/reward_loss_std": 0.21164391934871674, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016891956329346, "report/reward_neg_acc": 0.9959757924079895, "report/reward_neg_loss": 0.023986170068383217, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.7946463823318481, "report/reward_pred": 0.026092685759067535, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.5576637224512524e-06, "eval/cont_loss_std": 3.0174765925039537e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00025296889361925423, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.717373028346628e-07, "eval/cont_pred": 0.9960942268371582, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.34592056274414, "eval/dyn_loss_std": 10.874094009399414, "eval/image_loss_mean": 8.578287124633789, "eval/image_loss_std": 14.622160911560059, "eval/model_loss_mean": 18.499467849731445, "eval/model_loss_std": 18.982114791870117, "eval/post_ent_mag": 57.876197814941406, "eval/post_ent_max": 57.876197814941406, "eval/post_ent_mean": 42.09660339355469, "eval/post_ent_min": 18.41547966003418, "eval/post_ent_std": 7.869000434875488, "eval/prior_ent_mag": 69.85929870605469, "eval/prior_ent_max": 69.85929870605469, "eval/prior_ent_mean": 56.93880081176758, "eval/prior_ent_min": 41.04990768432617, "eval/prior_ent_std": 4.072874069213867, "eval/rep_loss_mean": 16.34592056274414, "eval/rep_loss_std": 10.874094009399414, "eval/reward_avg": 0.04306640475988388, "eval/reward_loss_mean": 0.11362749338150024, "eval/reward_loss_std": 0.6409521102905273, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.005378007888794, "eval/reward_neg_acc": 0.9887410402297974, "eval/reward_neg_loss": 0.03451748192310333, "eval/reward_pos_acc": 0.7872340083122253, "eval/reward_pos_loss": 1.7581056356430054, "eval/reward_pred": 0.03401121497154236, "eval/reward_rate": 0.0458984375, "replay/size": 683889.0, "replay/inserts": 23280.0, "replay/samples": 23280.0, "replay/insert_wait_avg": 1.3522880593525994e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.677528866377893e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4432.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2607350676498688e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3094635009766, "timer/env.step_count": 2910.0, "timer/env.step_total": 240.00004625320435, "timer/env.step_frac": 0.23992579797578817, "timer/env.step_avg": 0.08247424269869565, "timer/env.step_min": 0.022513389587402344, "timer/env.step_max": 3.3050601482391357, "timer/replay._sample_count": 23280.0, "timer/replay._sample_total": 11.695461511611938, "timer/replay._sample_frac": 0.011691843312847476, "timer/replay._sample_avg": 0.0005023823673372826, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.010744333267211914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3464.0, "timer/agent.policy_total": 53.69391202926636, "timer/agent.policy_frac": 0.05367730086381807, "timer/agent.policy_avg": 0.015500551971497216, "timer/agent.policy_min": 0.008427143096923828, "timer/agent.policy_max": 0.10803031921386719, "timer/dataset_train_count": 1455.0, "timer/dataset_train_total": 0.15282654762268066, "timer/dataset_train_frac": 0.00015277926801552394, "timer/dataset_train_avg": 0.00010503542791936815, "timer/dataset_train_min": 8.797645568847656e-05, "timer/dataset_train_max": 0.0002586841583251953, "timer/agent.train_count": 1455.0, "timer/agent.train_total": 632.1428897380829, "timer/agent.train_frac": 0.6319473251064227, "timer/agent.train_avg": 0.4344624671739401, "timer/agent.train_min": 0.4195117950439453, "timer/agent.train_max": 1.4371614456176758, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47865986824035645, "timer/agent.report_frac": 0.00047851178630770714, "timer/agent.report_avg": 0.23932993412017822, "timer/agent.report_min": 0.23249554634094238, "timer/agent.report_max": 0.24616432189941406, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.4345855712890625e-05, "timer/dataset_eval_frac": 4.433213653471282e-08, "timer/dataset_eval_avg": 4.4345855712890625e-05, "timer/dataset_eval_min": 4.4345855712890625e-05, "timer/dataset_eval_max": 4.4345855712890625e-05, "fps": 23.272473892310256}
{"step": 684416, "time": 30380.75509095192, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 684776, "time": 30393.885890245438, "episode/length": 92.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 684872, "time": 30398.43465590477, "episode/length": 214.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 684928, "time": 30402.01132750511, "episode/length": 135.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 684936, "time": 30403.583411455154, "episode/length": 203.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 685272, "time": 30415.73435473442, "episode/length": 266.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 685776, "time": 30433.77362394333, "episode/length": 124.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 686568, "time": 30460.711733341217, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 686768, "time": 30469.61630296707, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 687032, "time": 30479.919967889786, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 687032, "time": 30479.93321299553, "episode/length": 432.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953810623556582, "episode/intrinsic_return": 0.0}
{"step": 687080, "time": 30484.876566171646, "episode/length": 275.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 687144, "time": 30488.482478618622, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 687448, "time": 30499.71098923683, "episode/length": 208.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 687856, "time": 30514.610641002655, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 688440, "time": 30536.05567240715, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 688608, "time": 30543.33670926094, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 688648, "time": 30545.944274425507, "episode/length": 201.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 689008, "time": 30559.17127084732, "episode/length": 194.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 689320, "time": 30570.400349855423, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 689536, "time": 30579.167692422867, "episode/length": 370.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 689624, "time": 30583.405742406845, "episode/length": 220.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 689696, "time": 30587.369401454926, "episode/length": 326.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 30618.108050584793, "eval_episode/length": 142.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9790209790209791}
{"step": 690040, "time": 30621.678617239, "eval_episode/length": 190.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9790575916230366}
{"step": 690040, "time": 30623.829058647156, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 690040, "time": 30626.124750375748, "eval_episode/length": 221.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 690040, "time": 30628.847698926926, "eval_episode/length": 250.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9760956175298805}
{"step": 690040, "time": 30631.022920370102, "eval_episode/length": 262.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9771863117870723}
{"step": 690040, "time": 30635.44355726242, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 690040, "time": 30638.704980373383, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 690184, "time": 30643.359413146973, "episode/length": 191.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 690600, "time": 30658.36866092682, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 690912, "time": 30670.62286901474, "episode/length": 287.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 690968, "time": 30673.674747943878, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 691200, "time": 30682.83809709549, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 691392, "time": 30690.53457427025, "episode/length": 297.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 691512, "time": 30696.034768104553, "episode/length": 165.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 691664, "time": 30702.66953086853, "episode/length": 402.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9975186104218362, "episode/intrinsic_return": 0.0}
{"step": 691752, "time": 30706.823337078094, "episode/length": 256.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 691944, "time": 30714.522018671036, "episode/length": 289.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 691976, "time": 30717.111166238785, "episode/length": 57.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 692264, "time": 30727.912316799164, "episode/length": 168.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 692264, "time": 30727.919355392456, "episode/length": 108.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 692536, "time": 30739.89858198166, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 692712, "time": 30747.003112077713, "episode/length": 55.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 692920, "time": 30755.271295309067, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 693288, "time": 30768.663205385208, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 693312, "time": 30771.11804842949, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 693424, "time": 30776.240074396133, "episode/length": 277.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 693560, "time": 30781.891285181046, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 694040, "time": 30798.905067682266, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 694104, "time": 30802.451246738434, "episode/length": 98.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 694416, "time": 30814.32457971573, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 694656, "time": 30823.6128115654, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 694896, "time": 30832.937156438828, "episode/length": 392.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 695016, "time": 30838.226704120636, "episode/length": 198.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 695040, "time": 30840.7515335083, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 695144, "time": 30845.491909503937, "episode/length": 231.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 695568, "time": 30860.82845234871, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 695712, "time": 30866.98108434677, "episode/length": 200.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 695992, "time": 30877.47154211998, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 696128, "time": 30883.598553419113, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 696728, "time": 30905.69930458069, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 697304, "time": 30925.690675258636, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 697312, "time": 30927.66352248192, "episode/length": 301.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 697456, "time": 30934.059741020203, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 697576, "time": 30939.231015443802, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 698272, "time": 30963.438957452774, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 698464, "time": 30971.197296380997, "episode/length": 143.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 698760, "time": 30982.001115322113, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 698824, "time": 30985.54136276245, "episode/length": 406.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 699176, "time": 30998.451758623123, "episode/length": 51.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 699344, "time": 31005.653681755066, "episode/length": 133.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 699432, "time": 31009.74645972252, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 699496, "time": 31013.26378917694, "episode/length": 437.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9908675799086758, "episode/intrinsic_return": 0.0}
{"step": 700000, "time": 31031.233903169632, "episode/length": 336.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 31049.867092847824, "eval_episode/length": 94.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 700024, "time": 31053.563463449478, "eval_episode/length": 147.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 700024, "time": 31059.065337896347, "eval_episode/length": 201.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 700024, "time": 31060.605003356934, "eval_episode/length": 202.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 700024, "time": 31063.218663215637, "eval_episode/length": 228.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9694323144104804}
{"step": 700024, "time": 31066.376302480698, "eval_episode/length": 270.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.977859778597786}
{"step": 700024, "time": 31068.56553030014, "eval_episode/length": 283.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 700024, "time": 31070.41834449768, "eval_episode/length": 196.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 700088, "time": 31072.48185276985, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 700224, "time": 31078.608929395676, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 700688, "time": 31095.1747674942, "episode/length": 232.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 700984, "time": 31106.001827955246, "episode/length": 204.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 701000, "time": 31108.055864572525, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 701072, "time": 31112.197270154953, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 702032, "time": 31144.661478996277, "episode/length": 253.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 702448, "time": 31159.57258462906, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 702552, "time": 31164.199029684067, "episode/length": 421.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 702904, "time": 31177.0959649086, "episode/length": 43.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 703032, "time": 31182.749606370926, "episode/length": 350.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9971509971509972, "episode/intrinsic_return": 0.0}
{"step": 703264, "time": 31191.860376119614, "episode/length": 396.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 703400, "time": 31197.41307616234, "episode/length": 290.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 703856, "time": 31213.731373548508, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 703896, "time": 31216.28483915329, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 703936, "time": 31219.252556324005, "episode/length": 366.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 704816, "time": 31250.64720606804, "episode/length": 347.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.0}
{"step": 704832, "time": 31252.62087535858, "episode/length": 240.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 705264, "time": 31268.20896935463, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 705368, "time": 31272.831219434738, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 706088, "time": 31297.434333086014, "episode/length": 156.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 706128, "time": 31300.388965129852, "episode/length": 273.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 706368, "time": 31309.44174671173, "episode/length": 313.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 706456, "time": 31313.531600236893, "episode/length": 381.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 706480, "time": 31316.0014231205, "episode/length": 401.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 706536, "time": 31319.094316482544, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 706752, "time": 31327.862146139145, "episode/length": 172.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 707336, "time": 31347.692249774933, "episode/length": 109.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 707608, "time": 31357.888167858124, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 707720, "time": 31363.031136989594, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 707984, "time": 31373.55979657173, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9558011049723757, "episode/intrinsic_return": 0.0}
{"step": 708056, "time": 31377.64036154747, "episode/length": 55.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 708057, "time": 31380.1499979496, "train_stats/sum_log_reward": 8.030693209997498, "train_stats/max_log_achievement_collect_coal": 0.4752475247524752, "train_stats/max_log_achievement_collect_drink": 4.99009900990099, "train_stats/max_log_achievement_collect_sapling": 1.7128712871287128, "train_stats/max_log_achievement_collect_stone": 5.287128712871287, "train_stats/max_log_achievement_collect_wood": 11.217821782178218, "train_stats/max_log_achievement_defeat_skeleton": 0.009900990099009901, "train_stats/max_log_achievement_defeat_zombie": 0.7821782178217822, "train_stats/max_log_achievement_eat_cow": 0.04950495049504951, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.04950495049504951, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.1881188118811883, "train_stats/max_log_achievement_make_wood_sword": 0.0297029702970297, "train_stats/max_log_achievement_place_furnace": 0.36633663366336633, "train_stats/max_log_achievement_place_plant": 1.683168316831683, "train_stats/max_log_achievement_place_stone": 0.33663366336633666, "train_stats/max_log_achievement_place_table": 3.396039603960396, "train_stats/max_log_achievement_wake_up": 1.108910891089109, "train_stats/mean_log_entropy": 0.4700933593039465, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.518247449720228, "train/action_min": 0.0, "train/action_std": 3.5463940775072254, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037868618751196445, "train/actor_opt_grad_steps": 43415.0, "train/actor_opt_loss": -0.2357305374902648, "train/adv_mag": 0.5240329214044519, "train/adv_max": 0.49125406045365977, "train/adv_mean": 0.0035313090468514783, "train/adv_min": -0.4067131216461594, "train/adv_std": 0.05783732630614493, "train/cont_avg": 0.9948598500844594, "train/cont_loss_mean": 0.00013802150480926215, "train/cont_loss_std": 0.004051348879940135, "train/cont_neg_acc": 0.9949083018141824, "train/cont_neg_loss": 0.014655256324886068, "train/cont_pos_acc": 0.999980040901416, "train/cont_pos_loss": 5.098844318858749e-05, "train/cont_pred": 0.994873690846804, "train/cont_rate": 0.9948598500844594, "train/dyn_loss_mean": 13.128098681166366, "train/dyn_loss_std": 9.468325730916616, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8484788162482751, "train/extr_critic_critic_opt_grad_steps": 43415.0, "train/extr_critic_critic_opt_loss": 15517.219449429898, "train/extr_critic_mag": 6.825322647352476, "train/extr_critic_max": 6.825322647352476, "train/extr_critic_mean": 1.6659576997563645, "train/extr_critic_min": -0.2157423021020116, "train/extr_critic_std": 1.5440915323592521, "train/extr_return_normed_mag": 1.667598390901411, "train/extr_return_normed_max": 1.667598390901411, "train/extr_return_normed_mean": 0.3421958006314329, "train/extr_return_normed_min": -0.12150354451827101, "train/extr_return_normed_std": 0.3283476233482361, "train/extr_return_rate": 0.696212117937771, "train/extr_return_raw_mag": 8.043680886964541, "train/extr_return_raw_max": 8.043680886964541, "train/extr_return_raw_mean": 1.682886171985317, "train/extr_return_raw_min": -0.5421577291311445, "train/extr_return_raw_std": 1.5759062557607084, "train/extr_reward_mag": 1.0259695133647404, "train/extr_reward_max": 1.0259695133647404, "train/extr_reward_mean": 0.03448392070099913, "train/extr_reward_min": -0.4328959697001689, "train/extr_reward_std": 0.17512836745260535, "train/image_loss_mean": 6.521083383946805, "train/image_loss_std": 11.286042310096121, "train/model_loss_mean": 14.451528046582196, "train/model_loss_std": 15.193466463604489, "train/model_opt_grad_norm": 62.91662245827752, "train/model_opt_grad_steps": 43372.45945945946, "train/model_opt_loss": 18327.694006017737, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1266.8918918918919, "train/policy_entropy_mag": 2.5556587834615967, "train/policy_entropy_max": 2.5556587834615967, "train/policy_entropy_mean": 0.6474610603338963, "train/policy_entropy_min": 0.07937505941938709, "train/policy_entropy_std": 0.7513395112914008, "train/policy_logprob_mag": 7.4383837016853125, "train/policy_logprob_max": -0.009455660760805413, "train/policy_logprob_mean": -0.6482605324000925, "train/policy_logprob_min": -7.4383837016853125, "train/policy_logprob_std": 1.1658344703751642, "train/policy_randomness_mag": 0.9020353994659476, "train/policy_randomness_max": 0.9020353994659476, "train/policy_randomness_mean": 0.2285253428728194, "train/policy_randomness_min": 0.028015912573381856, "train/policy_randomness_std": 0.265189873608383, "train/post_ent_mag": 60.423954010009766, "train/post_ent_max": 60.423954010009766, "train/post_ent_mean": 43.11454644074311, "train/post_ent_min": 20.39206595678587, "train/post_ent_std": 7.745035026524518, "train/prior_ent_mag": 69.69711824365564, "train/prior_ent_max": 69.69711824365564, "train/prior_ent_mean": 56.3314175476899, "train/prior_ent_min": 39.23878210944098, "train/prior_ent_std": 4.830084264278412, "train/rep_loss_mean": 13.128098681166366, "train/rep_loss_std": 9.468325730916616, "train/reward_avg": 0.02682709544771225, "train/reward_loss_mean": 0.053447394858340956, "train/reward_loss_std": 0.2467063526446755, "train/reward_max_data": 1.012837840898617, "train/reward_max_pred": 1.0070918105744027, "train/reward_neg_acc": 0.99353047842915, "train/reward_neg_loss": 0.028020192107588455, "train/reward_pos_acc": 0.9684865039748114, "train/reward_pos_loss": 0.8392206321696978, "train/reward_pred": 0.026077703339979053, "train/reward_rate": 0.031408361486486486, "eval_stats/sum_log_reward": 7.912500083446503, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 4.5625, "eval_stats/max_log_achievement_collect_wood": 11.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.75, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_iron": 0.2222222222222222, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.690928446711041e-06, "report/cont_loss_std": 0.00010636030492605641, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008218404254876077, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.337987995015283e-08, "report/cont_pred": 0.9931696653366089, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.04692268371582, "report/dyn_loss_std": 9.183612823486328, "report/image_loss_mean": 5.501546859741211, "report/image_loss_std": 10.549712181091309, "report/model_loss_mean": 13.379432678222656, "report/model_loss_std": 14.397046089172363, "report/post_ent_mag": 59.91738510131836, "report/post_ent_max": 59.91738510131836, "report/post_ent_mean": 42.75115966796875, "report/post_ent_min": 19.839542388916016, "report/post_ent_std": 7.265021324157715, "report/prior_ent_mag": 69.73908996582031, "report/prior_ent_max": 69.73908996582031, "report/prior_ent_mean": 55.58460998535156, "report/prior_ent_min": 39.57929992675781, "report/prior_ent_std": 4.797987937927246, "report/rep_loss_mean": 13.04692268371582, "report/rep_loss_std": 9.183612823486328, "report/reward_avg": 0.02128906175494194, "report/reward_loss_mean": 0.0497264638543129, "report/reward_loss_std": 0.21393395960330963, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0867550373077393, "report/reward_neg_acc": 0.9929719567298889, "report/reward_neg_loss": 0.028646206483244896, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.7995814085006714, "report/reward_pred": 0.020442528650164604, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.48290494811954e-06, "eval/cont_loss_std": 0.00014162229490466416, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.1042814448010176e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.354913122981088e-06, "eval/cont_pred": 0.997063159942627, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.658748626708984, "eval/dyn_loss_std": 10.489784240722656, "eval/image_loss_mean": 10.69303035736084, "eval/image_loss_std": 13.204450607299805, "eval/model_loss_mean": 20.82756996154785, "eval/model_loss_std": 17.553119659423828, "eval/post_ent_mag": 57.85627746582031, "eval/post_ent_max": 57.85627746582031, "eval/post_ent_mean": 42.37623596191406, "eval/post_ent_min": 20.74932098388672, "eval/post_ent_std": 7.373456001281738, "eval/prior_ent_mag": 69.73908996582031, "eval/prior_ent_max": 69.73908996582031, "eval/prior_ent_mean": 56.743717193603516, "eval/prior_ent_min": 36.96887969970703, "eval/prior_ent_std": 5.127249717712402, "eval/rep_loss_mean": 16.658748626708984, "eval/rep_loss_std": 10.489784240722656, "eval/reward_avg": 0.03037109225988388, "eval/reward_loss_mean": 0.1392819583415985, "eval/reward_loss_std": 0.9146431684494019, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9996891021728516, "eval/reward_neg_acc": 0.9919191002845764, "eval/reward_neg_loss": 0.030538272112607956, "eval/reward_pos_acc": 0.6176470518112183, "eval/reward_pos_loss": 3.3056418895721436, "eval/reward_pred": 0.01950896345078945, "eval/reward_rate": 0.033203125, "replay/size": 707553.0, "replay/inserts": 23664.0, "replay/samples": 23664.0, "replay/insert_wait_avg": 1.3001892839113226e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.693089690862917e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5288.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1759969362152145e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0505475997925, "timer/env.step_count": 2958.0, "timer/env.step_total": 232.72891306877136, "timer/env.step_frac": 0.23271714977541966, "timer/env.step_avg": 0.07867779346476382, "timer/env.step_min": 0.02258443832397461, "timer/env.step_max": 3.4432849884033203, "timer/replay._sample_count": 23664.0, "timer/replay._sample_total": 11.895171880722046, "timer/replay._sample_frac": 0.011894570638725696, "timer/replay._sample_avg": 0.0005026695351894036, "timer/replay._sample_min": 0.00041866302490234375, "timer/replay._sample_max": 0.028041839599609375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3619.0, "timer/agent.policy_total": 55.46534323692322, "timer/agent.policy_frac": 0.05546253973866103, "timer/agent.policy_avg": 0.015326151764830953, "timer/agent.policy_min": 0.008425474166870117, "timer/agent.policy_max": 0.104644775390625, "timer/dataset_train_count": 1479.0, "timer/dataset_train_total": 0.1548147201538086, "timer/dataset_train_frac": 0.00015480689503683315, "timer/dataset_train_avg": 0.00010467526717634117, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 1479.0, "timer/agent.train_total": 641.6587913036346, "timer/agent.train_frac": 0.6416263586312423, "timer/agent.train_avg": 0.433846376811112, "timer/agent.train_min": 0.42237329483032227, "timer/agent.train_max": 1.3687653541564941, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4832425117492676, "timer/agent.report_frac": 0.0004832180862348321, "timer/agent.report_avg": 0.2416212558746338, "timer/agent.report_min": 0.23456668853759766, "timer/agent.report_max": 0.24867582321166992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.980081602797324e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 23.662487019439023}
{"step": 708424, "time": 31391.716865301132, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 708512, "time": 31396.60555410385, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975369458128078, "episode/intrinsic_return": 0.0}
{"step": 708896, "time": 31410.436150312424, "episode/length": 345.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 708904, "time": 31412.040316820145, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 709000, "time": 31416.593761205673, "episode/length": 159.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 709208, "time": 31424.84498476982, "episode/length": 340.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9824046920821115, "episode/intrinsic_return": 0.0}
{"step": 709456, "time": 31435.361006975174, "episode/length": 30.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 709528, "time": 31439.582673311234, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 31481.615418195724, "eval_episode/length": 153.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 710008, "time": 31483.77894616127, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 710008, "time": 31486.20029950142, "eval_episode/length": 166.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 710008, "time": 31491.095103025436, "eval_episode/length": 225.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 710008, "time": 31494.242569446564, "eval_episode/length": 249.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.996}
{"step": 710008, "time": 31497.787477493286, "eval_episode/length": 299.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 710008, "time": 31499.42636704445, "eval_episode/length": 148.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.959731543624161}
{"step": 710008, "time": 31501.05571269989, "eval_episode/length": 149.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 710552, "time": 31518.524659872055, "episode/length": 311.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 710680, "time": 31524.192631721497, "episode/length": 281.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 710720, "time": 31527.170019865036, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 711080, "time": 31540.157808065414, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 711232, "time": 31546.761709213257, "episode/length": 84.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 711304, "time": 31550.411748170853, "episode/length": 287.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 711480, "time": 31557.55052447319, "episode/length": 370.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9865229110512129, "episode/intrinsic_return": 0.0}
{"step": 711504, "time": 31560.083938121796, "episode/length": 324.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 711992, "time": 31577.05092191696, "episode/length": 307.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 712184, "time": 31584.79515695572, "episode/length": 182.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 712584, "time": 31599.260001897812, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 712952, "time": 31614.226294755936, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 713040, "time": 31618.650371074677, "episode/length": 191.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 713144, "time": 31623.397552013397, "episode/length": 69.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 713336, "time": 31631.127982378006, "episode/length": 331.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 713848, "time": 31649.255399227142, "episode/length": 345.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 713920, "time": 31653.42146921158, "episode/length": 304.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 713944, "time": 31655.515762090683, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 714632, "time": 31679.039304494858, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 714776, "time": 31685.162666082382, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 714784, "time": 31687.16004395485, "episode/length": 217.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 715200, "time": 31702.312268972397, "episode/length": 168.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 715392, "time": 31710.420037984848, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 715640, "time": 31719.779413223267, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 715752, "time": 31724.89453935623, "episode/length": 139.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 716224, "time": 31741.724411964417, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 716248, "time": 31743.731733322144, "episode/length": 290.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 716296, "time": 31746.797201395035, "episode/length": 393.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771573604060914, "episode/intrinsic_return": 0.0}
{"step": 717016, "time": 31773.098752737045, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 717368, "time": 31785.725739002228, "episode/length": 322.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 717496, "time": 31791.27935242653, "episode/length": 262.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 717608, "time": 31796.420743465424, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 717696, "time": 31800.930797100067, "episode/length": 256.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 718072, "time": 31814.29102373123, "episode/length": 358.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 718408, "time": 31826.426626443863, "episode/length": 113.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 718424, "time": 31828.394331932068, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 718496, "time": 31832.49608397484, "episode/length": 283.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 718936, "time": 31847.80497598648, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 719152, "time": 31856.461079120636, "episode/length": 192.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 719192, "time": 31859.081444978714, "episode/length": 139.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 719200, "time": 31861.01182961464, "episode/length": 362.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 719776, "time": 31881.034306049347, "episode/length": 104.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 31911.384689807892, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 720096, "time": 31914.10679769516, "eval_episode/length": 191.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 720096, "time": 31916.731845140457, "eval_episode/length": 219.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 720096, "time": 31916.73993372917, "eval_episode/length": 219.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9727272727272728}
{"step": 720096, "time": 31920.176408290863, "eval_episode/length": 227.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9692982456140351}
{"step": 720096, "time": 31922.072464704514, "eval_episode/length": 233.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 720096, "time": 31924.30530023575, "eval_episode/length": 250.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9840637450199203}
{"step": 720096, "time": 31927.76983141899, "eval_episode/length": 71.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 720304, "time": 31934.386352062225, "episode/length": 366.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989100817438692, "episode/intrinsic_return": 0.0}
{"step": 720312, "time": 31935.892682552338, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 720488, "time": 31943.004960775375, "episode/length": 160.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 721408, "time": 31975.50323653221, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 721464, "time": 31978.570530176163, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 721472, "time": 31980.617747306824, "episode/length": 382.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9921671018276762, "episode/intrinsic_return": 0.0}
{"step": 721704, "time": 31989.497960567474, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 721928, "time": 31998.091429948807, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 722088, "time": 32004.68454837799, "episode/length": 366.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 722488, "time": 32018.93815422058, "episode/length": 134.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 722552, "time": 32022.508009195328, "episode/length": 257.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 723048, "time": 32039.843705892563, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 723248, "time": 32048.07552266121, "episode/length": 367.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 723360, "time": 32053.1522667408, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 723368, "time": 32054.672064065933, "episode/length": 101.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 723408, "time": 32057.607166051865, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 723608, "time": 32065.313722372055, "episode/length": 139.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 723904, "time": 32076.467355012894, "episode/length": 304.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 724248, "time": 32088.867146730423, "episode/length": 317.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 724264, "time": 32090.908891916275, "episode/length": 106.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 724744, "time": 32108.56728053093, "episode/length": 172.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 725152, "time": 32123.20831489563, "episode/length": 382.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765013054830287, "episode/intrinsic_return": 0.0}
{"step": 725392, "time": 32132.519961833954, "episode/length": 267.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 725536, "time": 32138.6014316082, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 725584, "time": 32141.70523071289, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.97165991902834, "episode/intrinsic_return": 0.0}
{"step": 726000, "time": 32156.62127971649, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 726216, "time": 32164.838033914566, "episode/length": 78.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 726344, "time": 32170.40024113655, "episode/length": 304.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 726416, "time": 32174.413098812103, "episode/length": 268.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 726792, "time": 32187.708775043488, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 726952, "time": 32194.382289886475, "episode/length": 275.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 727568, "time": 32215.79154920578, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 727696, "time": 32221.471324682236, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 727888, "time": 32229.223131418228, "episode/length": 293.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 728104, "time": 32237.428893327713, "episode/length": 143.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 728456, "time": 32250.297913312912, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 728560, "time": 32255.496042490005, "episode/length": 319.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 728568, "time": 32257.118054151535, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 728936, "time": 32270.635929346085, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 729040, "time": 32275.708602905273, "episode/length": 336.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 729144, "time": 32282.013093709946, "episode/length": 129.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 729208, "time": 32285.65213727951, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 729568, "time": 32299.01700234413, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 729704, "time": 32304.735077619553, "episode/length": 226.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 729968, "time": 32315.062638044357, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 32334.724180221558, "eval_episode/length": 46.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 730080, "time": 32338.696449279785, "eval_episode/length": 57.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 730080, "time": 32342.010921001434, "eval_episode/length": 142.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.993006993006993}
{"step": 730080, "time": 32344.214238405228, "eval_episode/length": 158.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 730080, "time": 32347.311043977737, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 730080, "time": 32349.451176166534, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 730080, "time": 32353.29642724991, "eval_episode/length": 121.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9918032786885246}
{"step": 730080, "time": 32356.684459924698, "eval_episode/length": 288.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9965397923875432}
{"step": 730096, "time": 32358.05963420868, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 730240, "time": 32364.10533976555, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 730681, "time": 32380.513278722763, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.502412178147007, "train/action_min": 0.0, "train/action_std": 3.438782169785298, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03710795902240444, "train/actor_opt_grad_steps": 44865.0, "train/actor_opt_loss": 0.6968722356037355, "train/adv_mag": 0.5179927095141209, "train/adv_max": 0.49317386557518594, "train/adv_mean": 0.0037044181075108215, "train/adv_min": -0.3924622521014281, "train/adv_std": 0.05667212542513726, "train/cont_avg": 0.9948145906690141, "train/cont_loss_mean": 0.00033775784037404845, "train/cont_loss_std": 0.009542983814896334, "train/cont_neg_acc": 0.9929996661736932, "train/cont_neg_loss": 0.031322107635550704, "train/cont_pos_acc": 0.9999585000561996, "train/cont_pos_loss": 0.00014960527727268314, "train/cont_pred": 0.9948019775706278, "train/cont_rate": 0.9948145906690141, "train/dyn_loss_mean": 13.004183325968997, "train/dyn_loss_std": 9.413367533347976, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9173058749924243, "train/extr_critic_critic_opt_grad_steps": 44865.0, "train/extr_critic_critic_opt_loss": 15577.310753191021, "train/extr_critic_mag": 6.931368209946323, "train/extr_critic_max": 6.931368209946323, "train/extr_critic_mean": 1.78039473379162, "train/extr_critic_min": -0.20640827736384432, "train/extr_critic_std": 1.5865994960489407, "train/extr_return_normed_mag": 1.6371178215658162, "train/extr_return_normed_max": 1.6371178215658162, "train/extr_return_normed_mean": 0.3539815987919418, "train/extr_return_normed_min": -0.11266189538152285, "train/extr_return_normed_std": 0.32500330809976014, "train/extr_return_rate": 0.7312546233895799, "train/extr_return_raw_mag": 8.18324925194324, "train/extr_return_raw_max": 8.18324925194324, "train/extr_return_raw_mean": 1.7988277220390212, "train/extr_return_raw_min": -0.5232444348889338, "train/extr_return_raw_std": 1.6172695546083047, "train/extr_reward_mag": 1.0322924231139707, "train/extr_reward_max": 1.0322924231139707, "train/extr_reward_mean": 0.035507903368750086, "train/extr_reward_min": -0.4343976101405184, "train/extr_reward_std": 0.17687410410021392, "train/image_loss_mean": 6.490542274125865, "train/image_loss_std": 11.540616401484314, "train/model_loss_mean": 14.34753604002402, "train/model_loss_std": 15.416887236313082, "train/model_opt_grad_norm": 58.31771504039496, "train/model_opt_grad_steps": 44821.204225352114, "train/model_opt_loss": 20098.081948723593, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1399.6478873239437, "train/policy_entropy_mag": 2.557613151174196, "train/policy_entropy_max": 2.557613151174196, "train/policy_entropy_mean": 0.6634741385637875, "train/policy_entropy_min": 0.0793750700081738, "train/policy_entropy_std": 0.760132608699127, "train/policy_logprob_mag": 7.438383716932485, "train/policy_logprob_max": -0.009455660895877321, "train/policy_logprob_mean": -0.6631132070447358, "train/policy_logprob_min": -7.438383716932485, "train/policy_logprob_std": 1.1674477558740428, "train/policy_randomness_mag": 0.9027252071340319, "train/policy_randomness_max": 0.9027252071340319, "train/policy_randomness_mean": 0.23417725581938112, "train/policy_randomness_min": 0.02801591628821383, "train/policy_randomness_std": 0.26829345335423105, "train/post_ent_mag": 60.53886443124691, "train/post_ent_max": 60.53886443124691, "train/post_ent_mean": 43.28597133260378, "train/post_ent_min": 20.508493356301752, "train/post_ent_std": 7.7578613254385935, "train/prior_ent_mag": 69.76912318484884, "train/prior_ent_max": 69.76912318484884, "train/prior_ent_mean": 56.373512429250795, "train/prior_ent_min": 38.57638262359189, "train/prior_ent_std": 4.972658251372861, "train/rep_loss_mean": 13.004183325968997, "train/rep_loss_std": 9.413367533347976, "train/reward_avg": 0.02735200239686479, "train/reward_loss_mean": 0.054146040099817265, "train/reward_loss_std": 0.24621400478440272, "train/reward_max_data": 1.0147887359202747, "train/reward_max_pred": 1.0105624014223125, "train/reward_neg_acc": 0.9934886471486427, "train/reward_neg_loss": 0.02860733503344613, "train/reward_pos_acc": 0.9698294069565517, "train/reward_pos_loss": 0.831388168771502, "train/reward_pred": 0.026667356064779237, "train/reward_rate": 0.03180705325704225, "train_stats/sum_log_reward": 7.677319701184931, "train_stats/max_log_achievement_collect_coal": 0.3917525773195876, "train_stats/max_log_achievement_collect_drink": 4.206185567010309, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7938144329896908, "train_stats/max_log_achievement_collect_stone": 4.350515463917525, "train_stats/max_log_achievement_collect_wood": 11.206185567010309, "train_stats/max_log_achievement_defeat_skeleton": 0.020618556701030927, "train_stats/max_log_achievement_defeat_zombie": 0.6804123711340206, "train_stats/max_log_achievement_eat_cow": 0.05154639175257732, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.061855670103092786, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.1030927835051547, "train_stats/max_log_achievement_make_wood_sword": 0.030927835051546393, "train_stats/max_log_achievement_place_furnace": 0.5051546391752577, "train_stats/max_log_achievement_place_plant": 1.731958762886598, "train_stats/max_log_achievement_place_stone": 0.36082474226804123, "train_stats/max_log_achievement_place_table": 3.185567010309278, "train_stats/max_log_achievement_wake_up": 1.1030927835051547, "train_stats/mean_log_entropy": 0.4866798372612786, "eval_stats/sum_log_reward": 7.6416667103767395, "eval_stats/max_log_achievement_collect_coal": 0.2916666666666667, "eval_stats/max_log_achievement_collect_drink": 3.6666666666666665, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 2.0833333333333335, "eval_stats/max_log_achievement_collect_stone": 4.625, "eval_stats/max_log_achievement_collect_wood": 10.666666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.5416666666666666, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.4166666666666667, "eval_stats/max_log_achievement_place_plant": 2.0833333333333335, "eval_stats/max_log_achievement_place_stone": 0.16666666666666666, "eval_stats/max_log_achievement_place_table": 3.2083333333333335, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.98828125, "report/cont_loss_mean": 0.0001852949644671753, "report/cont_loss_std": 0.0030728362035006285, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004633821547031403, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00013254563964437693, "report/cont_pred": 0.9882063865661621, "report/cont_rate": 0.98828125, "report/dyn_loss_mean": 12.502264976501465, "report/dyn_loss_std": 8.966438293457031, "report/image_loss_mean": 6.289154052734375, "report/image_loss_std": 10.15658950805664, "report/model_loss_mean": 13.860835075378418, "report/model_loss_std": 13.481293678283691, "report/post_ent_mag": 64.30818939208984, "report/post_ent_max": 64.30818939208984, "report/post_ent_mean": 44.35139465332031, "report/post_ent_min": 23.075679779052734, "report/post_ent_std": 8.167243003845215, "report/prior_ent_mag": 70.05613708496094, "report/prior_ent_max": 70.05613708496094, "report/prior_ent_mean": 56.572696685791016, "report/prior_ent_min": 39.373565673828125, "report/prior_ent_std": 5.585977554321289, "report/rep_loss_mean": 12.502264976501465, "report/rep_loss_std": 8.966438293457031, "report/reward_avg": 0.03750000149011612, "report/reward_loss_mean": 0.0701356828212738, "report/reward_loss_std": 0.25908055901527405, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035302639007568, "report/reward_neg_acc": 0.9918200373649597, "report/reward_neg_loss": 0.040167175233364105, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7072923183441162, "report/reward_pred": 0.03737984597682953, "report/reward_rate": 0.044921875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0029627783223986626, "eval/cont_loss_std": 0.08697260916233063, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00037598834023810923, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.002972922520712018, "eval/cont_pred": 0.9949469566345215, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.2542724609375, "eval/dyn_loss_std": 10.510002136230469, "eval/image_loss_mean": 12.28773021697998, "eval/image_loss_std": 14.165118217468262, "eval/model_loss_mean": 22.746286392211914, "eval/model_loss_std": 18.515365600585938, "eval/post_ent_mag": 61.02597427368164, "eval/post_ent_max": 61.02597427368164, "eval/post_ent_mean": 42.369720458984375, "eval/post_ent_min": 21.241485595703125, "eval/post_ent_std": 8.212462425231934, "eval/prior_ent_mag": 70.05613708496094, "eval/prior_ent_max": 70.05613708496094, "eval/prior_ent_mean": 56.868019104003906, "eval/prior_ent_min": 41.63933563232422, "eval/prior_ent_std": 4.949542999267578, "eval/rep_loss_mean": 17.2542724609375, "eval/rep_loss_std": 10.510002136230469, "eval/reward_avg": 0.03291015326976776, "eval/reward_loss_mean": 0.10302920639514923, "eval/reward_loss_std": 0.5799463987350464, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0040764808654785, "eval/reward_neg_acc": 0.9837728142738342, "eval/reward_neg_loss": 0.044675473123788834, "eval/reward_pos_acc": 0.8157894611358643, "eval/reward_pos_loss": 1.6171551942825317, "eval/reward_pred": 0.027506396174430847, "eval/reward_rate": 0.037109375, "replay/size": 730177.0, "replay/inserts": 22624.0, "replay/samples": 22624.0, "replay/insert_wait_avg": 1.3015331776846922e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.617296558795589e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7168.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1749299509184702e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3407506942749, "timer/env.step_count": 2828.0, "timer/env.step_total": 223.85701179504395, "timer/env.step_frac": 0.2237807583462721, "timer/env.step_avg": 0.07915735919202403, "timer/env.step_min": 0.022562265396118164, "timer/env.step_max": 2.2189507484436035, "timer/replay._sample_count": 22624.0, "timer/replay._sample_total": 11.353710889816284, "timer/replay._sample_frac": 0.011349843422790057, "timer/replay._sample_avg": 0.000501843656728089, "timer/replay._sample_min": 0.00040531158447265625, "timer/replay._sample_max": 0.008890867233276367, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3724.0, "timer/agent.policy_total": 56.42636251449585, "timer/agent.policy_frac": 0.05640714174178527, "timer/agent.policy_avg": 0.015152084456094481, "timer/agent.policy_min": 0.008485555648803711, "timer/agent.policy_max": 0.10030269622802734, "timer/dataset_train_count": 1414.0, "timer/dataset_train_total": 0.14687275886535645, "timer/dataset_train_frac": 0.00014682272891854213, "timer/dataset_train_avg": 0.0001038704093814402, "timer/dataset_train_min": 8.7738037109375e-05, "timer/dataset_train_max": 0.001081705093383789, "timer/agent.train_count": 1414.0, "timer/agent.train_total": 614.3526203632355, "timer/agent.train_frac": 0.6141433505901376, "timer/agent.train_avg": 0.4344785151083702, "timer/agent.train_min": 0.4198610782623291, "timer/agent.train_max": 2.1865732669830322, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4798924922943115, "timer/agent.report_frac": 0.00047972902429621876, "timer/agent.report_avg": 0.23994624614715576, "timer/agent.report_min": 0.2341630458831787, "timer/agent.report_max": 0.2457294464111328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00010156631469726562, "timer/dataset_eval_frac": 1.0153171769397049e-07, "timer/dataset_eval_avg": 0.00010156631469726562, "timer/dataset_eval_min": 0.00010156631469726562, "timer/dataset_eval_max": 0.00010156631469726562, "fps": 22.61598288624318}
{"step": 731032, "time": 32391.64983344078, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 731272, "time": 32400.86442065239, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 731336, "time": 32404.424945116043, "episode/length": 154.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 731400, "time": 32408.07634139061, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 731992, "time": 32428.605532169342, "episode/length": 368.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 732080, "time": 32433.2732796669, "episode/length": 392.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 732456, "time": 32446.78467154503, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778325123152709, "episode/intrinsic_return": 0.0}
{"step": 732512, "time": 32450.385814666748, "episode/length": 283.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 733072, "time": 32469.88573694229, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 733176, "time": 32474.51345872879, "episode/length": 229.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 733936, "time": 32500.83250617981, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9670781893004116, "episode/intrinsic_return": 0.0}
{"step": 734032, "time": 32505.443688869476, "episode/length": 374.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946666666666667, "episode/intrinsic_return": 0.0}
{"step": 734272, "time": 32514.657416582108, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 734440, "time": 32521.52317881584, "episode/length": 395.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 734536, "time": 32526.204343557358, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 734832, "time": 32537.48891544342, "episode/length": 343.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 735168, "time": 32549.803045511246, "episode/length": 338.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 735456, "time": 32560.84239602089, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 735800, "time": 32573.20405936241, "episode/length": 410.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 736192, "time": 32587.725120782852, "episode/length": 281.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 736192, "time": 32587.732461214066, "episode/length": 127.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 736200, "time": 32590.89140033722, "episode/length": 170.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 736376, "time": 32598.08753013611, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 736504, "time": 32604.157705545425, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 736856, "time": 32616.947809934616, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 737472, "time": 32639.842075824738, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 737648, "time": 32647.220072746277, "episode/length": 142.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 737656, "time": 32648.722940206528, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 737736, "time": 32652.860035181046, "episode/length": 241.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 737896, "time": 32659.401467323303, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 738064, "time": 32666.534170389175, "episode/length": 233.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 738736, "time": 32689.565032720566, "episode/length": 135.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 739120, "time": 32703.845405101776, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 739128, "time": 32705.376078367233, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 739440, "time": 32717.14426112175, "episode/length": 404.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 739688, "time": 32726.4046626091, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 739896, "time": 32734.720425605774, "episode/length": 249.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 739936, "time": 32737.732612371445, "episode/length": 149.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 740008, "time": 32741.349627017975, "episode/length": 39.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 32759.345851659775, "eval_episode/length": 42.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 740064, "time": 32765.767666339874, "eval_episode/length": 161.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 740064, "time": 32770.39468669891, "eval_episode/length": 236.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 740064, "time": 32773.4365234375, "eval_episode/length": 271.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 740064, "time": 32775.567152023315, "eval_episode/length": 243.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959016393442623}
{"step": 740064, "time": 32777.27454376221, "eval_episode/length": 292.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9795221843003413}
{"step": 740064, "time": 32782.309579610825, "eval_episode/length": 216.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 740064, "time": 32784.72578883171, "eval_episode/length": 399.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9775}
{"step": 740096, "time": 32785.762848854065, "episode/length": 294.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9932203389830508, "episode/intrinsic_return": 0.0}
{"step": 740384, "time": 32796.680149555206, "episode/length": 157.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 740448, "time": 32800.301676273346, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 740672, "time": 32808.9423995018, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 741064, "time": 32822.953818798065, "episode/length": 140.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 741120, "time": 32826.51979494095, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 741696, "time": 32846.67711138725, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 742288, "time": 32867.430434942245, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 742376, "time": 32871.57089757919, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 742488, "time": 32876.68199682236, "episode/length": 380.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 742752, "time": 32886.926218271255, "episode/length": 32.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 742968, "time": 32895.144901037216, "episode/length": 358.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9749303621169917, "episode/intrinsic_return": 0.0}
{"step": 743064, "time": 32899.744218587875, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 743224, "time": 32906.42503142357, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 743368, "time": 32912.91146636009, "episode/length": 372.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9973190348525469, "episode/intrinsic_return": 0.0}
{"step": 743448, "time": 32917.59170818329, "episode/length": 144.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 744144, "time": 32943.37854361534, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 744248, "time": 32948.739572286606, "episode/length": 397.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 744280, "time": 32951.998680353165, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 744360, "time": 32956.488233327866, "episode/length": 123.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 744368, "time": 32958.460523843765, "episode/length": 333.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 744600, "time": 32967.335896253586, "episode/length": 39.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 744688, "time": 32972.002007484436, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 744704, "time": 32974.14372110367, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 744744, "time": 32976.68728160858, "episode/length": 46.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 744904, "time": 32983.34736204147, "episode/length": 94.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 745336, "time": 32998.70060300827, "episode/length": 235.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 745824, "time": 33017.68467903137, "episode/length": 139.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 746160, "time": 33029.95242071152, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 746920, "time": 33055.91558265686, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 747216, "time": 33067.21261572838, "episode/length": 370.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946091644204852, "episode/intrinsic_return": 0.0}
{"step": 747224, "time": 33068.78864192963, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 747360, "time": 33074.85669159889, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 747608, "time": 33084.0120985508, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 747936, "time": 33096.58409643173, "episode/length": 398.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 748192, "time": 33107.0692718029, "episode/length": 437.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 748576, "time": 33121.97716546059, "episode/length": 301.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 749056, "time": 33138.91284489632, "episode/length": 139.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 749496, "time": 33154.61019444466, "episode/length": 283.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 749712, "time": 33163.4799182415, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 749792, "time": 33168.269654512405, "episode/length": 303.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 749824, "time": 33171.36595749855, "episode/length": 362.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9889807162534435, "episode/intrinsic_return": 0.0}
{"step": 749848, "time": 33174.06316566467, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 33197.58700489998, "eval_episode/length": 59.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 750048, "time": 33204.81468629837, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 750048, "time": 33206.73374056816, "eval_episode/length": 204.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 750048, "time": 33208.56303691864, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 750048, "time": 33210.51995635033, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 750048, "time": 33212.665714263916, "eval_episode/length": 237.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 750048, "time": 33218.35398721695, "eval_episode/length": 98.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.98989898989899}
{"step": 750048, "time": 33222.10589170456, "eval_episode/length": 184.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 750200, "time": 33226.751349925995, "episode/length": 372.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946380697050938, "episode/intrinsic_return": 0.0}
{"step": 750264, "time": 33230.27135229111, "episode/length": 51.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 750880, "time": 33252.01108503342, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 751160, "time": 33262.34423613548, "episode/length": 262.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 751312, "time": 33268.91927909851, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 751392, "time": 33273.06447434425, "episode/length": 472.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9788583509513742, "episode/intrinsic_return": 0.0}
{"step": 751928, "time": 33291.59090566635, "episode/length": 276.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 751976, "time": 33294.78263235092, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 752168, "time": 33302.55510902405, "episode/length": 160.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 752664, "time": 33319.95643091202, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 752672, "time": 33321.90703868866, "episode/length": 300.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 753008, "time": 33334.14469695091, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 753288, "time": 33344.47967290878, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 753640, "time": 33357.220755815506, "episode/length": 429.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 753944, "time": 33370.06259560585, "episode/length": 251.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 754193, "time": 33380.52995181084, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.543378142272534, "train/action_min": 0.0, "train/action_std": 3.544192463362298, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.036746494662092656, "train/actor_opt_grad_steps": 46310.0, "train/actor_opt_loss": 0.4658392875829116, "train/adv_mag": 0.49837612152910554, "train/adv_max": 0.4595671405597609, "train/adv_mean": 0.003803262784031733, "train/adv_min": -0.3727752680883927, "train/adv_std": 0.055644433945417404, "train/cont_avg": 0.9948315263605442, "train/cont_loss_mean": 0.00022422930275564992, "train/cont_loss_std": 0.006588868969479367, "train/cont_neg_acc": 0.9921722122251171, "train/cont_neg_loss": 0.01924638467956867, "train/cont_pos_acc": 0.9999732180517547, "train/cont_pos_loss": 0.00013077363790114246, "train/cont_pred": 0.994818755153085, "train/cont_rate": 0.9948315263605442, "train/dyn_loss_mean": 12.992594037737165, "train/dyn_loss_std": 9.406024082988298, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9496208713168189, "train/extr_critic_critic_opt_grad_steps": 46310.0, "train/extr_critic_critic_opt_loss": 15842.362570418793, "train/extr_critic_mag": 7.122944523688076, "train/extr_critic_max": 7.122944523688076, "train/extr_critic_mean": 1.9077051804990184, "train/extr_critic_min": -0.2240936772352984, "train/extr_critic_std": 1.6717032202247049, "train/extr_return_normed_mag": 1.5986502081358513, "train/extr_return_normed_max": 1.5986502081358513, "train/extr_return_normed_mean": 0.3659616039723766, "train/extr_return_normed_min": -0.1089843097237908, "train/extr_return_normed_std": 0.3254162895233453, "train/extr_return_rate": 0.7405776490970534, "train/extr_return_raw_mag": 8.380691019045253, "train/extr_return_raw_max": 8.380691019045253, "train/extr_return_raw_mean": 1.927644985873683, "train/extr_return_raw_min": -0.5587235441824205, "train/extr_return_raw_std": 1.7035468670786644, "train/extr_reward_mag": 1.0297800991810908, "train/extr_reward_max": 1.0297800991810908, "train/extr_reward_mean": 0.03637787988599466, "train/extr_reward_min": -0.4390433377960101, "train/extr_reward_std": 0.1797484183798031, "train/image_loss_mean": 6.441888215590496, "train/image_loss_std": 11.43838440966444, "train/model_loss_mean": 14.292137561201239, "train/model_loss_std": 15.277076915818817, "train/model_opt_grad_norm": 56.462944134563, "train/model_opt_grad_steps": 46264.68707482993, "train/model_opt_loss": 18588.166593590562, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1301.0204081632653, "train/policy_entropy_mag": 2.5291555446832357, "train/policy_entropy_max": 2.5291555446832357, "train/policy_entropy_mean": 0.6456314246265256, "train/policy_entropy_min": 0.07937506596450092, "train/policy_entropy_std": 0.7447689159386823, "train/policy_logprob_mag": 7.438383754418821, "train/policy_logprob_max": -0.009455661587163705, "train/policy_logprob_mean": -0.6450595796919193, "train/policy_logprob_min": -7.438383754418821, "train/policy_logprob_std": 1.1572351974694908, "train/policy_randomness_mag": 0.8926809178728635, "train/policy_randomness_max": 0.8926809178728635, "train/policy_randomness_mean": 0.22787956112907046, "train/policy_randomness_min": 0.028015914898948606, "train/policy_randomness_std": 0.2628707427556823, "train/post_ent_mag": 60.388157098471716, "train/post_ent_max": 60.388157098471716, "train/post_ent_mean": 43.382873379454324, "train/post_ent_min": 20.359780369972697, "train/post_ent_std": 7.776435449820798, "train/prior_ent_mag": 69.85698663620721, "train/prior_ent_max": 69.85698663620721, "train/prior_ent_mean": 56.467987423851376, "train/prior_ent_min": 39.15639572403058, "train/prior_ent_std": 4.88028284968162, "train/rep_loss_mean": 12.992594037737165, "train/rep_loss_std": 9.406024082988298, "train/reward_avg": 0.027198926197225543, "train/reward_loss_mean": 0.054468689980555554, "train/reward_loss_std": 0.24224783956599075, "train/reward_max_data": 1.0176870790468593, "train/reward_max_pred": 1.0124743925470885, "train/reward_neg_acc": 0.9930511615714248, "train/reward_neg_loss": 0.028795730595027103, "train/reward_pos_acc": 0.9680887716157096, "train/reward_pos_loss": 0.8415233610438652, "train/reward_pred": 0.026598768986660203, "train/reward_rate": 0.03188775510204082, "train_stats/sum_log_reward": 8.089690880062653, "train_stats/max_log_achievement_collect_coal": 0.3917525773195876, "train_stats/max_log_achievement_collect_drink": 5.484536082474227, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7216494845360826, "train_stats/max_log_achievement_collect_stone": 6.154639175257732, "train_stats/max_log_achievement_collect_wood": 9.639175257731958, "train_stats/max_log_achievement_defeat_skeleton": 0.07216494845360824, "train_stats/max_log_achievement_defeat_zombie": 0.5876288659793815, "train_stats/max_log_achievement_eat_cow": 0.061855670103092786, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010309278350515464, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7731958762886597, "train_stats/max_log_achievement_make_wood_sword": 0.07216494845360824, "train_stats/max_log_achievement_place_furnace": 0.7525773195876289, "train_stats/max_log_achievement_place_plant": 1.597938144329897, "train_stats/max_log_achievement_place_stone": 0.9484536082474226, "train_stats/max_log_achievement_place_table": 2.7216494845360826, "train_stats/max_log_achievement_wake_up": 1.0721649484536082, "train_stats/mean_log_entropy": 0.5463382001851023, "eval_stats/sum_log_reward": 7.53750017285347, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 4.9375, "eval_stats/max_log_achievement_collect_wood": 8.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.5625, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_stone": 0.6875, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.9051409253734164e-05, "report/cont_loss_std": 0.0005780834471806884, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00012186858657514676, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.8546910723671317e-05, "report/cont_pred": 0.9950995445251465, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.005304336547852, "report/dyn_loss_std": 9.364096641540527, "report/image_loss_mean": 5.30185604095459, "report/image_loss_std": 10.73104190826416, "report/model_loss_mean": 13.157339096069336, "report/model_loss_std": 14.890374183654785, "report/post_ent_mag": 57.555633544921875, "report/post_ent_max": 57.555633544921875, "report/post_ent_mean": 42.273521423339844, "report/post_ent_min": 20.414180755615234, "report/post_ent_std": 7.378188133239746, "report/prior_ent_mag": 69.76891326904297, "report/prior_ent_max": 69.76891326904297, "report/prior_ent_mean": 55.8536491394043, "report/prior_ent_min": 43.00654983520508, "report/prior_ent_std": 4.007312297821045, "report/rep_loss_mean": 13.005304336547852, "report/rep_loss_std": 9.364096641540527, "report/reward_avg": 0.03632812201976776, "report/reward_loss_mean": 0.052281491458415985, "report/reward_loss_std": 0.22993113100528717, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0031285285949707, "report/reward_neg_acc": 0.997965395450592, "report/reward_neg_loss": 0.02433698996901512, "report/reward_pos_acc": 0.9756097197532654, "report/reward_pos_loss": 0.7222679257392883, "report/reward_pred": 0.036617740988731384, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.4123893379291985e-05, "eval/cont_loss_std": 0.00030369494925253093, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.854982348158956e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.3910458619648125e-05, "eval/cont_pred": 0.9960802793502808, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.709110260009766, "eval/dyn_loss_std": 11.443533897399902, "eval/image_loss_mean": 12.85744571685791, "eval/image_loss_std": 23.497276306152344, "eval/model_loss_mean": 23.553173065185547, "eval/model_loss_std": 27.978271484375, "eval/post_ent_mag": 58.0811653137207, "eval/post_ent_max": 58.0811653137207, "eval/post_ent_mean": 41.36798095703125, "eval/post_ent_min": 20.760419845581055, "eval/post_ent_std": 7.618982791900635, "eval/prior_ent_mag": 69.76891326904297, "eval/prior_ent_max": 69.76891326904297, "eval/prior_ent_mean": 56.65458679199219, "eval/prior_ent_min": 39.02886199951172, "eval/prior_ent_std": 4.717309951782227, "eval/rep_loss_mean": 17.709110260009766, "eval/rep_loss_std": 11.443533897399902, "eval/reward_avg": 0.02783203125, "eval/reward_loss_mean": 0.07024762034416199, "eval/reward_loss_std": 0.4266696572303772, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.1180436611175537, "eval/reward_neg_acc": 0.9959636330604553, "eval/reward_neg_loss": 0.03139796853065491, "eval/reward_pos_acc": 0.9090908765792847, "eval/reward_pos_loss": 1.2369143962860107, "eval/reward_pred": 0.02494790405035019, "eval/reward_rate": 0.0322265625, "replay/size": 753689.0, "replay/inserts": 23512.0, "replay/samples": 23504.0, "replay/insert_wait_avg": 1.3355374863537934e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.855316016688649e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1296966407872454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0069308280945, "timer/env.step_count": 2939.0, "timer/env.step_total": 231.472416639328, "timer/env.step_frac": 0.23147081235491868, "timer/env.step_avg": 0.07875890324577339, "timer/env.step_min": 0.02246570587158203, "timer/env.step_max": 3.143267869949341, "timer/replay._sample_count": 23504.0, "timer/replay._sample_total": 11.966211557388306, "timer/replay._sample_frac": 0.011966128622207868, "timer/replay._sample_avg": 0.0005091138341298632, "timer/replay._sample_min": 0.0003867149353027344, "timer/replay._sample_max": 0.010404348373413086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3729.0, "timer/agent.policy_total": 56.36245131492615, "timer/agent.policy_frac": 0.05636206067917253, "timer/agent.policy_avg": 0.015114628939374134, "timer/agent.policy_min": 0.008405923843383789, "timer/agent.policy_max": 0.11886429786682129, "timer/dataset_train_count": 1469.0, "timer/dataset_train_total": 0.15695762634277344, "timer/dataset_train_frac": 0.00015695653850398677, "timer/dataset_train_avg": 0.00010684658021972323, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0006172657012939453, "timer/agent.train_count": 1469.0, "timer/agent.train_total": 639.3549761772156, "timer/agent.train_frac": 0.6393505449484964, "timer/agent.train_avg": 0.43523143374895545, "timer/agent.train_min": 0.4194185733795166, "timer/agent.train_max": 1.4567267894744873, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4814934730529785, "timer/agent.report_frac": 0.0004814901359276172, "timer/agent.report_avg": 0.24074673652648926, "timer/agent.report_min": 0.23287606239318848, "timer/agent.report_max": 0.24861741065979004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.963180541992188e-05, "timer/dataset_eval_frac": 7.963125350939285e-08, "timer/dataset_eval_avg": 7.963180541992188e-05, "timer/dataset_eval_min": 7.963180541992188e-05, "timer/dataset_eval_max": 7.963180541992188e-05, "fps": 23.5114799092728}
{"step": 754424, "time": 33387.913813114166, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 754456, "time": 33390.47833609581, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 754512, "time": 33394.13304233551, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 754688, "time": 33401.288299798965, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 754736, "time": 33404.38667011261, "episode/length": 344.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 755216, "time": 33421.43776488304, "episode/length": 196.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 756032, "time": 33449.379006147385, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 756144, "time": 33454.62580823898, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 756152, "time": 33456.209983587265, "episode/length": 434.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9908045977011494, "episode/intrinsic_return": 0.0}
{"step": 756336, "time": 33463.92746782303, "episode/length": 298.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9933110367892977, "episode/intrinsic_return": 0.0}
{"step": 756384, "time": 33466.98588967323, "episode/length": 240.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 756392, "time": 33468.54562711716, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 757312, "time": 33499.96006441116, "episode/length": 145.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 757400, "time": 33504.10918712616, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 758040, "time": 33526.10092806816, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 758808, "time": 33552.2608089447, "episode/length": 302.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 758856, "time": 33555.30877304077, "episode/length": 454.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 759024, "time": 33562.39486026764, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 759168, "time": 33568.45065331459, "episode/length": 38.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 759200, "time": 33570.97916126251, "episode/length": 395.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 759200, "time": 33570.98773097992, "episode/length": 224.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 759360, "time": 33579.435306310654, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 759584, "time": 33588.08510375023, "episode/length": 398.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 33620.05912399292, "eval_episode/length": 93.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9468085106382979}
{"step": 760032, "time": 33625.545057058334, "eval_episode/length": 191.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9895833333333334}
{"step": 760032, "time": 33628.00005149841, "eval_episode/length": 213.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 760032, "time": 33629.732873916626, "eval_episode/length": 217.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 760032, "time": 33632.5295753479, "eval_episode/length": 230.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 760032, "time": 33635.52702498436, "eval_episode/length": 234.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9744680851063829}
{"step": 760032, "time": 33640.568553209305, "eval_episode/length": 228.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 760032, "time": 33643.270015478134, "eval_episode/length": 121.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9918032786885246}
{"step": 760096, "time": 33645.32729554176, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 760280, "time": 33652.5382232666, "episode/length": 138.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 760440, "time": 33659.18504691124, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 760520, "time": 33663.21060395241, "episode/length": 116.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9487179487179487, "episode/intrinsic_return": 0.0}
{"step": 760648, "time": 33668.9191672802, "episode/length": 160.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 760992, "time": 33681.73436784744, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 761464, "time": 33698.81997513771, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 761888, "time": 33715.71901464462, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 761944, "time": 33718.830709695816, "episode/length": 177.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 762032, "time": 33723.468952417374, "episode/length": 70.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 762520, "time": 33740.9111096859, "episode/length": 414.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9951807228915662, "episode/intrinsic_return": 0.0}
{"step": 762568, "time": 33743.96805047989, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 762664, "time": 33748.50740432739, "episode/length": 277.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 763152, "time": 33765.92737865448, "episode/length": 358.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 763848, "time": 33789.6850104332, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 763864, "time": 33791.68963217735, "episode/length": 246.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 764008, "time": 33797.79051399231, "episode/length": 246.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 764112, "time": 33802.80546140671, "episode/length": 119.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 764144, "time": 33805.21620178223, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 764296, "time": 33811.37931442261, "episode/length": 203.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 764384, "time": 33815.99002122879, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 764752, "time": 33829.24947452545, "episode/length": 110.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 765016, "time": 33839.07745361328, "episode/length": 383.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 765368, "time": 33852.04618573189, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 765544, "time": 33859.29997229576, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 765560, "time": 33861.28069496155, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 765800, "time": 33870.450392484665, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 765936, "time": 33876.62167143822, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 766280, "time": 33889.019881010056, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 766464, "time": 33896.73565363884, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 766592, "time": 33902.386952638626, "episode/length": 322.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 766760, "time": 33909.183982133865, "episode/length": 149.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 767016, "time": 33918.99196147919, "episode/length": 151.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 767112, "time": 33923.608613967896, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 767128, "time": 33925.67962932587, "episode/length": 219.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 767816, "time": 33949.41699266434, "episode/length": 131.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 768024, "time": 33957.596458911896, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 768384, "time": 33971.001326560974, "episode/length": 158.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 768736, "time": 33983.71773791313, "episode/length": 267.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 768744, "time": 33985.30232810974, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 768752, "time": 33987.21677899361, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 769104, "time": 33999.998943805695, "episode/length": 352.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9886685552407932, "episode/intrinsic_return": 0.0}
{"step": 769176, "time": 34003.5120716095, "episode/length": 169.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 769488, "time": 34015.1539273262, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 769712, "time": 34023.937195301056, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 34052.808191776276, "eval_episode/length": 127.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.953125}
{"step": 770016, "time": 34055.45858716965, "eval_episode/length": 154.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 770016, "time": 34059.162452459335, "eval_episode/length": 207.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 770016, "time": 34061.65500164032, "eval_episode/length": 231.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 770016, "time": 34064.422569036484, "eval_episode/length": 261.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9847328244274809}
{"step": 770016, "time": 34066.139564991, "eval_episode/length": 263.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 770016, "time": 34070.49931001663, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9605911330049262}
{"step": 770016, "time": 34072.252205610275, "eval_episode/length": 181.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.989010989010989}
{"step": 770120, "time": 34076.717183589935, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 770336, "time": 34085.39202618599, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 770376, "time": 34087.9251844883, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 770600, "time": 34096.6404633522, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 770680, "time": 34100.8197145462, "episode/length": 187.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 770960, "time": 34111.549669742584, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 771384, "time": 34126.582126140594, "episode/length": 236.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 771424, "time": 34129.58476138115, "episode/length": 135.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 771688, "time": 34139.53086519241, "episode/length": 246.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 771800, "time": 34144.67777299881, "episode/length": 381.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9869109947643979, "episode/intrinsic_return": 0.0}
{"step": 772120, "time": 34156.73520851135, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 772384, "time": 34167.61392450333, "episode/length": 250.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 772408, "time": 34169.80996012688, "episode/length": 285.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.986013986013986, "episode/intrinsic_return": 0.0}
{"step": 772456, "time": 34173.03416609764, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 772872, "time": 34188.08433842659, "episode/length": 180.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 772984, "time": 34193.303629636765, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 773432, "time": 34209.34454154968, "episode/length": 203.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 773456, "time": 34211.80765604973, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 773624, "time": 34218.45984363556, "episode/length": 145.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 773744, "time": 34224.02221608162, "episode/length": 108.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 773976, "time": 34232.84441232681, "episode/length": 43.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 774088, "time": 34237.94268774986, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 774304, "time": 34246.61285638809, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 774800, "time": 34264.19495654106, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 774888, "time": 34268.280397892, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 775128, "time": 34277.45524549484, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 775328, "time": 34285.52053618431, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 775464, "time": 34291.21826553345, "episode/length": 214.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 775768, "time": 34302.647443294525, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 775888, "time": 34308.19459557533, "episode/length": 135.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 776080, "time": 34315.967681884766, "episode/length": 248.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9718875502008032, "episode/intrinsic_return": 0.0}
{"step": 776176, "time": 34321.24047756195, "episode/length": 274.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 776672, "time": 34339.803099155426, "episode/length": 150.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 776816, "time": 34346.076919317245, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 777184, "time": 34359.47568202019, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 777248, "time": 34363.00816369057, "episode/length": 145.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 777721, "time": 34380.58031916618, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.500935041985544, "train/action_min": 0.0, "train/action_std": 3.35070801105629, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03551654819221724, "train/actor_opt_grad_steps": 47780.0, "train/actor_opt_loss": -1.7611514722206154, "train/adv_mag": 0.4983821274066458, "train/adv_max": 0.4544922916256652, "train/adv_mean": 0.0030865224627607667, "train/adv_min": -0.39861961773463656, "train/adv_std": 0.05415434838861835, "train/cont_avg": 0.9951238307823129, "train/cont_loss_mean": 0.00015271210837774598, "train/cont_loss_std": 0.004612108418252294, "train/cont_neg_acc": 0.9971655331501345, "train/cont_neg_loss": 0.010186120623922736, "train/cont_pos_acc": 0.9999666112620814, "train/cont_pos_loss": 9.595268525879496e-05, "train/cont_pred": 0.9951116706238312, "train/cont_rate": 0.9951238307823129, "train/dyn_loss_mean": 12.772729490889985, "train/dyn_loss_std": 9.338059159363208, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.951678374186665, "train/extr_critic_critic_opt_grad_steps": 47780.0, "train/extr_critic_critic_opt_loss": 15883.549452593537, "train/extr_critic_mag": 7.436113883037956, "train/extr_critic_max": 7.436113883037956, "train/extr_critic_mean": 1.9522623586005905, "train/extr_critic_min": -0.22047982329414004, "train/extr_critic_std": 1.7333219732557024, "train/extr_return_normed_mag": 1.5695452755000316, "train/extr_return_normed_max": 1.5695452755000316, "train/extr_return_normed_mean": 0.35842806617824396, "train/extr_return_normed_min": -0.10615973245529901, "train/extr_return_normed_std": 0.32140013088985364, "train/extr_return_rate": 0.7436579169870234, "train/extr_return_raw_mag": 8.608363699750836, "train/extr_return_raw_max": 8.608363699750836, "train/extr_return_raw_mean": 1.9691750005799897, "train/extr_return_raw_min": -0.5777898702491708, "train/extr_return_raw_std": 1.7619191473033153, "train/extr_reward_mag": 1.0311072132214396, "train/extr_reward_max": 1.0311072132214396, "train/extr_reward_mean": 0.03703455958946222, "train/extr_reward_min": -0.4508188687214235, "train/extr_reward_std": 0.18095359490031288, "train/image_loss_mean": 6.378440808276741, "train/image_loss_std": 11.083065405994857, "train/model_loss_mean": 14.094966862477413, "train/model_loss_std": 14.913209882723232, "train/model_opt_grad_norm": 56.01621389064659, "train/model_opt_grad_steps": 47733.37414965987, "train/model_opt_loss": 17766.415205144556, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.5034013605443, "train/policy_entropy_mag": 2.5344365567577127, "train/policy_entropy_max": 2.5344365567577127, "train/policy_entropy_mean": 0.64064486659303, "train/policy_entropy_min": 0.07937505248249793, "train/policy_entropy_std": 0.7253446209998358, "train/policy_logprob_mag": 7.4383837479312405, "train/policy_logprob_max": -0.009455661587163705, "train/policy_logprob_mean": -0.6406408637559333, "train/policy_logprob_min": -7.4383837479312405, "train/policy_logprob_std": 1.1560803432853854, "train/policy_randomness_mag": 0.8945448860830191, "train/policy_randomness_max": 0.8945448860830191, "train/policy_randomness_mean": 0.22611952578129413, "train/policy_randomness_min": 0.028015910185315983, "train/policy_randomness_std": 0.25601481843967827, "train/post_ent_mag": 60.49891299293155, "train/post_ent_max": 60.49891299293155, "train/post_ent_mean": 43.6623521921586, "train/post_ent_min": 20.439825920831588, "train/post_ent_std": 7.792418567501769, "train/prior_ent_mag": 69.82454162390054, "train/prior_ent_max": 69.82454162390054, "train/prior_ent_mean": 56.556109992825256, "train/prior_ent_min": 38.75447620988703, "train/prior_ent_std": 4.894979472063025, "train/rep_loss_mean": 12.772729490889985, "train/rep_loss_std": 9.338059159363208, "train/reward_avg": 0.026359215511807373, "train/reward_loss_mean": 0.05273568968535686, "train/reward_loss_std": 0.23806239786196728, "train/reward_max_data": 1.0102040840654958, "train/reward_max_pred": 1.0076511692838603, "train/reward_neg_acc": 0.9930042875867312, "train/reward_neg_loss": 0.027898394230271684, "train/reward_pos_acc": 0.9709871991151044, "train/reward_pos_loss": 0.8376548411894817, "train/reward_pred": 0.02577153010433223, "train/reward_rate": 0.030765040391156462, "train_stats/sum_log_reward": 8.532692455328428, "train_stats/max_log_achievement_collect_coal": 0.5096153846153846, "train_stats/max_log_achievement_collect_drink": 4.759615384615385, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.625, "train_stats/max_log_achievement_collect_stone": 7.0673076923076925, "train_stats/max_log_achievement_collect_wood": 9.75, "train_stats/max_log_achievement_defeat_skeleton": 0.009615384615384616, "train_stats/max_log_achievement_defeat_zombie": 0.5673076923076923, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8076923076923077, "train_stats/max_log_achievement_make_wood_sword": 0.0673076923076923, "train_stats/max_log_achievement_place_furnace": 0.8076923076923077, "train_stats/max_log_achievement_place_plant": 1.5384615384615385, "train_stats/max_log_achievement_place_stone": 2.0961538461538463, "train_stats/max_log_achievement_place_table": 2.6634615384615383, "train_stats/max_log_achievement_wake_up": 1.125, "train_stats/mean_log_entropy": 0.4269191056776505, "eval_stats/sum_log_reward": 8.287500143051147, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.4375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 6.375, "eval_stats/max_log_achievement_collect_wood": 9.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_furnace": 0.75, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 1.6875, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.6336009442457e-06, "report/cont_loss_std": 0.0001760017912602052, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.1823647886049e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.381874638667796e-06, "report/cont_pred": 0.9960867166519165, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.54893684387207, "report/dyn_loss_std": 9.497905731201172, "report/image_loss_mean": 6.698003768920898, "report/image_loss_std": 10.544257164001465, "report/model_loss_mean": 14.274614334106445, "report/model_loss_std": 15.022665977478027, "report/post_ent_mag": 57.796424865722656, "report/post_ent_max": 57.796424865722656, "report/post_ent_mean": 43.57936096191406, "report/post_ent_min": 19.36698341369629, "report/post_ent_std": 7.2413835525512695, "report/prior_ent_mag": 70.042236328125, "report/prior_ent_max": 70.042236328125, "report/prior_ent_mean": 56.42079162597656, "report/prior_ent_min": 38.747798919677734, "report/prior_ent_std": 4.9899773597717285, "report/rep_loss_mean": 12.54893684387207, "report/rep_loss_std": 9.497905731201172, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.04724157974123955, "report/reward_loss_std": 0.23669452965259552, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0050764083862305, "report/reward_neg_acc": 0.9969940185546875, "report/reward_neg_loss": 0.026068059727549553, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.8599791526794434, "report/reward_pred": 0.02144034206867218, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.990234375, "eval/cont_loss_mean": 7.485699825338088e-06, "eval/cont_loss_std": 0.00018244794046040624, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000706672843080014, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.903630153625272e-07, "eval/cont_pred": 0.990240752696991, "eval/cont_rate": 0.990234375, "eval/dyn_loss_mean": 17.923908233642578, "eval/dyn_loss_std": 10.36430835723877, "eval/image_loss_mean": 11.283623695373535, "eval/image_loss_std": 16.246891021728516, "eval/model_loss_mean": 22.14065170288086, "eval/model_loss_std": 20.115224838256836, "eval/post_ent_mag": 58.2066650390625, "eval/post_ent_max": 58.2066650390625, "eval/post_ent_mean": 40.8580322265625, "eval/post_ent_min": 20.608917236328125, "eval/post_ent_std": 7.7598724365234375, "eval/prior_ent_mag": 69.612060546875, "eval/prior_ent_max": 69.612060546875, "eval/prior_ent_mean": 56.966064453125, "eval/prior_ent_min": 41.639251708984375, "eval/prior_ent_std": 4.300125598907471, "eval/rep_loss_mean": 17.923908233642578, "eval/rep_loss_std": 10.36430835723877, "eval/reward_avg": 0.03691406175494194, "eval/reward_loss_mean": 0.10267724841833115, "eval/reward_loss_std": 0.5351862907409668, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016584396362305, "eval/reward_neg_acc": 0.991828441619873, "eval/reward_neg_loss": 0.05140075087547302, "eval/reward_pos_acc": 0.9111111164093018, "eval/reward_pos_loss": 1.2182258367538452, "eval/reward_pred": 0.0366520993411541, "eval/reward_rate": 0.0439453125, "replay/size": 777217.0, "replay/inserts": 23528.0, "replay/samples": 23536.0, "replay/insert_wait_avg": 1.308535767509515e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.750123313784518e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5520.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1425951252812925e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0312054157257, "timer/env.step_count": 2941.0, "timer/env.step_total": 236.38534450531006, "timer/env.step_frac": 0.23637796823254295, "timer/env.step_avg": 0.08037583968218635, "timer/env.step_min": 0.022032499313354492, "timer/env.step_max": 3.356036901473999, "timer/replay._sample_count": 23536.0, "timer/replay._sample_total": 11.90450406074524, "timer/replay._sample_frac": 0.011904132587338998, "timer/replay._sample_avg": 0.000505799798638054, "timer/replay._sample_min": 0.0004112720489501953, "timer/replay._sample_max": 0.025482654571533203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3631.0, "timer/agent.policy_total": 54.82738184928894, "timer/agent.policy_frac": 0.05482567099143321, "timer/agent.policy_avg": 0.015099802216824275, "timer/agent.policy_min": 0.008470296859741211, "timer/agent.policy_max": 0.12786006927490234, "timer/dataset_train_count": 1471.0, "timer/dataset_train_total": 0.15967249870300293, "timer/dataset_train_frac": 0.00015966751621178165, "timer/dataset_train_avg": 0.00010854690598436637, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.004589080810546875, "timer/agent.train_count": 1471.0, "timer/agent.train_total": 638.0893654823303, "timer/agent.train_frac": 0.6380694542597483, "timer/agent.train_avg": 0.43377931032109474, "timer/agent.train_min": 0.41962718963623047, "timer/agent.train_max": 1.3755898475646973, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4818413257598877, "timer/agent.report_frac": 0.00048182629017019536, "timer/agent.report_avg": 0.24092066287994385, "timer/agent.report_min": 0.23365378379821777, "timer/agent.report_max": 0.24818754196166992, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6702047610878575e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 23.52690478809195}
{"step": 777736, "time": 34380.66108965874, "episode/length": 230.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 777800, "time": 34384.90157151222, "episode/length": 363.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 778448, "time": 34409.15689635277, "episode/length": 283.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 778544, "time": 34414.51932668686, "episode/length": 233.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9700854700854701, "episode/intrinsic_return": 0.0}
{"step": 778776, "time": 34423.68489432335, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 778856, "time": 34427.80879998207, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 778960, "time": 34432.776300907135, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 778968, "time": 34434.36750769615, "episode/length": 153.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 778976, "time": 34436.384944200516, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 779232, "time": 34446.351801157, "episode/length": 56.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 779256, "time": 34448.4452290535, "episode/length": 49.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 34488.91561985016, "eval_episode/length": 55.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 780000, "time": 34492.52090215683, "eval_episode/length": 51.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 780000, "time": 34494.55656313896, "eval_episode/length": 120.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9586776859504132}
{"step": 780000, "time": 34497.85094189644, "eval_episode/length": 164.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 780000, "time": 34500.79023694992, "eval_episode/length": 197.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 780000, "time": 34506.48798775673, "eval_episode/length": 271.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 780000, "time": 34510.08363342285, "eval_episode/length": 184.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.972972972972973}
{"step": 780000, "time": 34512.25280404091, "eval_episode/length": 307.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.987012987012987}
{"step": 780024, "time": 34512.84667086601, "episode/length": 277.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 780512, "time": 34531.43956184387, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 780528, "time": 34533.40182495117, "episode/length": 161.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 780672, "time": 34539.52422499657, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 781032, "time": 34552.433399915695, "episode/length": 221.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 781184, "time": 34559.01477766037, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 781248, "time": 34562.637350320816, "episode/length": 284.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9719298245614035, "episode/intrinsic_return": 0.0}
{"step": 781808, "time": 34582.080406188965, "episode/length": 407.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 781904, "time": 34586.74721264839, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 781928, "time": 34588.75567674637, "episode/length": 368.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 782368, "time": 34604.80467367172, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 782504, "time": 34610.5706615448, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 782632, "time": 34616.17942357063, "episode/length": 172.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 782808, "time": 34623.39470458031, "episode/length": 221.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 783104, "time": 34634.62866687775, "episode/length": 58.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 783208, "time": 34639.327368974686, "episode/length": 334.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 783752, "time": 34658.515823841095, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 784152, "time": 34673.10866975784, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 784208, "time": 34676.73139166832, "episode/length": 212.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 784224, "time": 34678.75434613228, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 784656, "time": 34694.350044727325, "episode/length": 343.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.997093023255814, "episode/intrinsic_return": 0.0}
{"step": 784800, "time": 34700.560690164566, "episode/length": 130.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9541984732824428, "episode/intrinsic_return": 0.0}
{"step": 784816, "time": 34702.65335226059, "episode/length": 375.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9867021276595744, "episode/intrinsic_return": 0.0}
{"step": 784920, "time": 34707.29588007927, "episode/length": 213.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 784944, "time": 34709.69329237938, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 785568, "time": 34731.436437129974, "episode/length": 176.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 785824, "time": 34741.239755392075, "episode/length": 127.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 786040, "time": 34749.46445918083, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 786080, "time": 34752.488750219345, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 786992, "time": 34784.97824263573, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 787456, "time": 34801.51603913307, "episode/length": 57.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 787528, "time": 34805.18117213249, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 787536, "time": 34807.178741931915, "episode/length": 359.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 787720, "time": 34814.43286418915, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 787896, "time": 34821.67898488045, "episode/length": 258.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 787912, "time": 34823.71633434296, "episode/length": 373.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 788768, "time": 34853.083149433136, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 788976, "time": 34861.23313212395, "episode/length": 132.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 789040, "time": 34864.94426679611, "episode/length": 369.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9756756756756757, "episode/intrinsic_return": 0.0}
{"step": 789064, "time": 34866.99556326866, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 789184, "time": 34872.62714147568, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 789264, "time": 34876.704122543335, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 789592, "time": 34888.55440878868, "episode/length": 76.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 789648, "time": 34892.17056107521, "episode/length": 47.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 34927.94487452507, "eval_episode/length": 62.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9365079365079365}
{"step": 790088, "time": 34932.900213479996, "eval_episode/length": 146.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 790088, "time": 34936.79674720764, "eval_episode/length": 203.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 790088, "time": 34938.88948225975, "eval_episode/length": 216.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 790088, "time": 34941.056339263916, "eval_episode/length": 227.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 790088, "time": 34946.87448477745, "eval_episode/length": 137.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 790088, "time": 34949.298867464066, "eval_episode/length": 243.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9877049180327869}
{"step": 790088, "time": 34950.953981637955, "eval_episode/length": 309.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9806451612903225}
{"step": 790224, "time": 34955.61500644684, "episode/length": 345.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9971098265895953, "episode/intrinsic_return": 0.0}
{"step": 790536, "time": 34967.024815797806, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 790624, "time": 34971.70620083809, "episode/length": 385.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9974093264248705, "episode/intrinsic_return": 0.0}
{"step": 790864, "time": 34981.04350447655, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 790960, "time": 34985.75069832802, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 791152, "time": 34993.39781665802, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 791272, "time": 34998.5124168396, "episode/length": 209.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 791360, "time": 35003.112401008606, "episode/length": 49.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 791520, "time": 35009.781952142715, "episode/length": 111.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 791800, "time": 35020.23739337921, "episode/length": 54.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 792384, "time": 35040.83823800087, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 792392, "time": 35042.52282524109, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 792528, "time": 35048.63160896301, "episode/length": 287.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 792768, "time": 35057.85930991173, "episode/length": 186.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 793552, "time": 35084.622082710266, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 793664, "time": 35089.753155231476, "episode/length": 390.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 793872, "time": 35098.04872941971, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 794040, "time": 35104.857855796814, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 794536, "time": 35122.392614126205, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 794664, "time": 35129.547031879425, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 794728, "time": 35133.331859111786, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897260273972602, "episode/intrinsic_return": 0.0}
{"step": 795008, "time": 35144.20436811447, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 795208, "time": 35152.051142930984, "episode/length": 206.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 795296, "time": 35156.60950374603, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 795864, "time": 35176.20256447792, "episode/length": 274.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 795904, "time": 35179.28215885162, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 795976, "time": 35183.03056716919, "episode/length": 120.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 796176, "time": 35191.33387827873, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 796456, "time": 35201.66585659981, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 796624, "time": 35208.7163207531, "episode/length": 176.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 796640, "time": 35210.78675222397, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 796768, "time": 35216.33606052399, "episode/length": 183.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 796792, "time": 35218.453483343124, "episode/length": 110.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 797464, "time": 35241.610530376434, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 797544, "time": 35245.95167708397, "episode/length": 96.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 797768, "time": 35254.768263339996, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 797912, "time": 35260.882941007614, "episode/length": 139.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 798024, "time": 35266.13255691528, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 798152, "time": 35271.78535819054, "episode/length": 85.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 798336, "time": 35279.49043917656, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 798512, "time": 35286.78994035721, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 798560, "time": 35289.91471219063, "episode/length": 336.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 798776, "time": 35298.209641456604, "episode/length": 93.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 799168, "time": 35312.651029109955, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 799440, "time": 35322.908750772476, "episode/length": 109.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 799592, "time": 35329.06362700462, "episode/length": 179.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 799824, "time": 35338.22640347481, "episode/length": 256.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 35366.78534054756, "eval_episode/length": 151.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.993421052631579}
{"step": 800072, "time": 35370.85192203522, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 800072, "time": 35376.47819018364, "eval_episode/length": 299.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9866666666666667}
{"step": 800072, "time": 35378.81139302254, "eval_episode/length": 107.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 800072, "time": 35380.58877706528, "eval_episode/length": 323.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 800072, "time": 35382.28824567795, "eval_episode/length": 327.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9969512195121951}
{"step": 800072, "time": 35385.454931497574, "eval_episode/length": 367.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9972826086956522}
{"step": 800072, "time": 35385.46260881424, "eval_episode/length": 215.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 800073, "time": 35386.495431661606, "train_stats/sum_log_reward": 8.158823695837283, "train_stats/max_log_achievement_collect_coal": 0.3627450980392157, "train_stats/max_log_achievement_collect_drink": 3.715686274509804, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.6176470588235294, "train_stats/max_log_achievement_collect_stone": 12.382352941176471, "train_stats/max_log_achievement_collect_wood": 9.745098039215685, "train_stats/max_log_achievement_defeat_skeleton": 0.0392156862745098, "train_stats/max_log_achievement_defeat_zombie": 0.696078431372549, "train_stats/max_log_achievement_eat_cow": 0.06862745098039216, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.8529411764705883, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.20588235294117646, "train_stats/max_log_achievement_place_plant": 1.5686274509803921, "train_stats/max_log_achievement_place_stone": 9.843137254901961, "train_stats/max_log_achievement_place_table": 2.6666666666666665, "train_stats/max_log_achievement_wake_up": 1.0490196078431373, "train_stats/mean_log_entropy": 0.3485777730158731, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.215198544289568, "train/action_min": 0.0, "train/action_std": 3.066906635709804, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.035535107628047034, "train/actor_opt_grad_steps": 49210.0, "train/actor_opt_loss": 0.2086243582286423, "train/adv_mag": 0.509966526314509, "train/adv_max": 0.45859862467367873, "train/adv_mean": 0.003791085954911742, "train/adv_min": -0.42132015933664585, "train/adv_std": 0.0539831487234119, "train/cont_avg": 0.995082059352518, "train/cont_loss_mean": 0.00021242391932268948, "train/cont_loss_std": 0.006157273571459995, "train/cont_neg_acc": 0.9944243158983148, "train/cont_neg_loss": 0.02666868578068017, "train/cont_pos_acc": 0.9999717263866672, "train/cont_pos_loss": 8.961462751023567e-05, "train/cont_pred": 0.9950830031641953, "train/cont_rate": 0.995082059352518, "train/dyn_loss_mean": 13.020932924833229, "train/dyn_loss_std": 9.468977434172047, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9442603202174893, "train/extr_critic_critic_opt_grad_steps": 49210.0, "train/extr_critic_critic_opt_loss": 15873.880016299461, "train/extr_critic_mag": 7.672454346855767, "train/extr_critic_max": 7.672454346855767, "train/extr_critic_mean": 2.1040383131383993, "train/extr_critic_min": -0.21952922224140853, "train/extr_critic_std": 1.7805017936143943, "train/extr_return_normed_mag": 1.5674497523753763, "train/extr_return_normed_max": 1.5674497523753763, "train/extr_return_normed_mean": 0.3735741818551537, "train/extr_return_normed_min": -0.09506216240550974, "train/extr_return_normed_std": 0.322265005797791, "train/extr_return_rate": 0.7775316105472098, "train/extr_return_raw_mag": 8.84253743741152, "train/extr_return_raw_max": 8.84253743741152, "train/extr_return_raw_mean": 2.1253675694088283, "train/extr_return_raw_min": -0.5124053227172481, "train/extr_return_raw_std": 1.813521980381698, "train/extr_reward_mag": 1.0352151205213806, "train/extr_reward_max": 1.0352151205213806, "train/extr_reward_mean": 0.03941915824794941, "train/extr_reward_min": -0.4351221005693614, "train/extr_reward_std": 0.18612910657049084, "train/image_loss_mean": 6.451910379121629, "train/image_loss_std": 11.811930738764701, "train/model_loss_mean": 14.319092064452686, "train/model_loss_std": 15.664398303134837, "train/model_opt_grad_norm": 55.989708303547594, "train/model_opt_grad_steps": 49161.97122302158, "train/model_opt_loss": 19207.04298982689, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1339.928057553957, "train/policy_entropy_mag": 2.5479565129863273, "train/policy_entropy_max": 2.5479565129863273, "train/policy_entropy_mean": 0.5919516845572766, "train/policy_entropy_min": 0.07937503632881658, "train/policy_entropy_std": 0.6867030164320692, "train/policy_logprob_mag": 7.438383750778308, "train/policy_logprob_max": -0.009455659265944855, "train/policy_logprob_mean": -0.5914727783889222, "train/policy_logprob_min": -7.438383750778308, "train/policy_logprob_std": 1.1318006163878407, "train/policy_randomness_mag": 0.8993168340312491, "train/policy_randomness_max": 0.8993168340312491, "train/policy_randomness_mean": 0.2089329683523384, "train/policy_randomness_min": 0.028015904517160902, "train/policy_randomness_std": 0.24237603131386873, "train/post_ent_mag": 60.209079275885934, "train/post_ent_max": 60.209079275885934, "train/post_ent_mean": 43.36998153247421, "train/post_ent_min": 20.29986739673203, "train/post_ent_std": 7.779235150316636, "train/prior_ent_mag": 69.89491529944989, "train/prior_ent_max": 69.89491529944989, "train/prior_ent_mean": 56.46873174982963, "train/prior_ent_min": 38.83609593343392, "train/prior_ent_std": 4.959235815693148, "train/rep_loss_mean": 13.020932924833229, "train/rep_loss_std": 9.468977434172047, "train/reward_avg": 0.02800907699806656, "train/reward_loss_mean": 0.054409504713986416, "train/reward_loss_std": 0.23993430077600822, "train/reward_max_data": 1.0136690680071605, "train/reward_max_pred": 1.0107114383642621, "train/reward_neg_acc": 0.9929230037353022, "train/reward_neg_loss": 0.028216902468112304, "train/reward_pos_acc": 0.9729318948958418, "train/reward_pos_loss": 0.8371381369426096, "train/reward_pred": 0.027236988372671946, "train/reward_rate": 0.03250758767985611, "eval_stats/sum_log_reward": 8.225000162919363, "eval_stats/max_log_achievement_collect_coal": 0.5833333333333334, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5416666666666667, "eval_stats/max_log_achievement_collect_stone": 11.958333333333334, "eval_stats/max_log_achievement_collect_wood": 7.916666666666667, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.16666666666666666, "eval_stats/max_log_achievement_place_furnace": 0.16666666666666666, "eval_stats/max_log_achievement_place_plant": 1.4583333333333333, "eval_stats/max_log_achievement_place_stone": 9.75, "eval_stats/max_log_achievement_place_table": 2.3333333333333335, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.7690092590783024e-06, "report/cont_loss_std": 5.2989005780545995e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004485626413952559, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.687745765366344e-08, "report/cont_pred": 0.9960955381393433, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.014408111572266, "report/dyn_loss_std": 9.474481582641602, "report/image_loss_mean": 6.1424880027771, "report/image_loss_std": 10.34273910522461, "report/model_loss_mean": 14.599461555480957, "report/model_loss_std": 14.426621437072754, "report/post_ent_mag": 57.58827209472656, "report/post_ent_max": 57.58827209472656, "report/post_ent_mean": 43.41572570800781, "report/post_ent_min": 22.269350051879883, "report/post_ent_std": 7.730456352233887, "report/prior_ent_mag": 69.52339935302734, "report/prior_ent_max": 69.52339935302734, "report/prior_ent_mean": 56.69047546386719, "report/prior_ent_min": 38.76964569091797, "report/prior_ent_std": 4.711831569671631, "report/rep_loss_mean": 14.014408111572266, "report/rep_loss_std": 9.474481582641602, "report/reward_avg": 0.02529296837747097, "report/reward_loss_mean": 0.04832687973976135, "report/reward_loss_std": 0.2226351946592331, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0033557415008545, "report/reward_neg_acc": 0.9899396300315857, "report/reward_neg_loss": 0.02774464339017868, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7302849292755127, "report/reward_pred": 0.024830862879753113, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.3925828170613386e-06, "eval/cont_loss_std": 3.188114715158008e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00012269783474039286, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0361520708102034e-06, "eval/cont_pred": 0.9970696568489075, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.998563766479492, "eval/dyn_loss_std": 10.779468536376953, "eval/image_loss_mean": 13.216365814208984, "eval/image_loss_std": 17.234800338745117, "eval/model_loss_mean": 24.739871978759766, "eval/model_loss_std": 21.413497924804688, "eval/post_ent_mag": 59.58943176269531, "eval/post_ent_max": 59.58943176269531, "eval/post_ent_mean": 40.544776916503906, "eval/post_ent_min": 20.347251892089844, "eval/post_ent_std": 7.2931742668151855, "eval/prior_ent_mag": 69.52339935302734, "eval/prior_ent_max": 69.52339935302734, "eval/prior_ent_mean": 56.75640106201172, "eval/prior_ent_min": 37.87803649902344, "eval/prior_ent_std": 4.977325916290283, "eval/rep_loss_mean": 18.998563766479492, "eval/rep_loss_std": 10.779468536376953, "eval/reward_avg": 0.04179687425494194, "eval/reward_loss_mean": 0.12436705827713013, "eval/reward_loss_std": 0.6988136768341064, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0058703422546387, "eval/reward_neg_acc": 0.9836400747299194, "eval/reward_neg_loss": 0.034534841775894165, "eval/reward_pos_acc": 0.717391312122345, "eval/reward_pos_loss": 2.03427791595459, "eval/reward_pred": 0.030827343463897705, "eval/reward_rate": 0.044921875, "replay/size": 799569.0, "replay/inserts": 22352.0, "replay/samples": 22352.0, "replay/insert_wait_avg": 1.3198034201849335e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.777723484407942e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2639388593166886e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1005.8961753845215, "timer/env.step_count": 2794.0, "timer/env.step_total": 231.58911037445068, "timer/env.step_frac": 0.23023162433828886, "timer/env.step_avg": 0.08288801373459223, "timer/env.step_min": 0.022691965103149414, "timer/env.step_max": 2.1700496673583984, "timer/replay._sample_count": 22352.0, "timer/replay._sample_total": 11.434940814971924, "timer/replay._sample_frac": 0.01136791360261482, "timer/replay._sample_avg": 0.0005115846821300968, "timer/replay._sample_min": 0.00041174888610839844, "timer/replay._sample_max": 0.010729551315307617, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3780.0, "timer/agent.policy_total": 58.825387477874756, "timer/agent.policy_frac": 0.05848057574668451, "timer/agent.policy_avg": 0.015562271819543587, "timer/agent.policy_min": 0.008543968200683594, "timer/agent.policy_max": 0.10664153099060059, "timer/dataset_train_count": 1397.0, "timer/dataset_train_total": 0.14958667755126953, "timer/dataset_train_frac": 0.00014870985814623204, "timer/dataset_train_avg": 0.00010707707770312779, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0010848045349121094, "timer/agent.train_count": 1397.0, "timer/agent.train_total": 607.8666050434113, "timer/agent.train_frac": 0.6043035254717452, "timer/agent.train_avg": 0.43512283825584197, "timer/agent.train_min": 0.4243736267089844, "timer/agent.train_max": 1.3691294193267822, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48046875, "timer/agent.report_frac": 0.0004776524275145319, "timer/agent.report_avg": 0.240234375, "timer/agent.report_min": 0.2343909740447998, "timer/agent.report_max": 0.2460777759552002, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7020400994355308e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 22.220646289566663}
{"step": 800104, "time": 35387.20920038223, "episode/length": 319.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 800312, "time": 35395.68925642967, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 800336, "time": 35398.188220739365, "episode/length": 63.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 800416, "time": 35402.30200481415, "episode/length": 121.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 800744, "time": 35414.10668134689, "episode/length": 300.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 800912, "time": 35421.28916478157, "episode/length": 100.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 801240, "time": 35433.11569356918, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 801296, "time": 35436.704463005066, "episode/length": 347.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 801720, "time": 35451.684175252914, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 801888, "time": 35458.76531767845, "episode/length": 80.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 802048, "time": 35465.53860068321, "episode/length": 162.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 802216, "time": 35472.19952058792, "episode/length": 380.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973753280839895, "episode/intrinsic_return": 0.0}
{"step": 802352, "time": 35478.30286216736, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 802360, "time": 35479.86097049713, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 802624, "time": 35490.11140418053, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 802784, "time": 35496.883848428726, "episode/length": 52.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 803384, "time": 35518.7808778286, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 803400, "time": 35520.894275426865, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 803424, "time": 35523.46417927742, "episode/length": 171.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 803520, "time": 35528.05941820145, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 803528, "time": 35529.75540113449, "episode/length": 146.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 803808, "time": 35540.48280954361, "episode/length": 35.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 804368, "time": 35559.9546046257, "episode/length": 122.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 804416, "time": 35562.93775320053, "episode/length": 223.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9598214285714286, "episode/intrinsic_return": 0.0}
{"step": 804728, "time": 35574.14060521126, "episode/length": 165.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 804808, "time": 35578.29467964172, "episode/length": 48.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 805088, "time": 35589.04410862923, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 805296, "time": 35597.16657042503, "episode/length": 384.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948051948051948, "episode/intrinsic_return": 0.0}
{"step": 805432, "time": 35602.80894136429, "episode/length": 330.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939577039274925, "episode/intrinsic_return": 0.0}
{"step": 805664, "time": 35612.13526582718, "episode/length": 106.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 805696, "time": 35614.6504304409, "episode/length": 165.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 806264, "time": 35634.11225247383, "episode/length": 146.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 806472, "time": 35642.31505513191, "episode/length": 146.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 806520, "time": 35645.34201812744, "episode/length": 135.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 806728, "time": 35653.55744457245, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 806880, "time": 35660.14311647415, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 806888, "time": 35661.705676317215, "episode/length": 384.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9844155844155844, "episode/intrinsic_return": 0.0}
{"step": 807568, "time": 35685.38582897186, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 807592, "time": 35687.478295087814, "episode/length": 87.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 807632, "time": 35690.52925848961, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 807640, "time": 35691.987127780914, "episode/length": 145.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 807904, "time": 35702.27453184128, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 808312, "time": 35716.78650999069, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 808392, "time": 35720.82903790474, "episode/length": 93.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 808560, "time": 35727.95317316055, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 809224, "time": 35750.70713472366, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 809280, "time": 35754.30716943741, "episode/length": 110.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 809336, "time": 35757.433738946915, "episode/length": 351.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 809560, "time": 35766.218200445175, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 35798.864713191986, "eval_episode/length": 60.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9344262295081968}
{"step": 810056, "time": 35802.093432188034, "eval_episode/length": 101.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9901960784313726}
{"step": 810056, "time": 35804.77865600586, "eval_episode/length": 130.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9618320610687023}
{"step": 810056, "time": 35807.891317367554, "eval_episode/length": 167.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 810056, "time": 35810.14420127869, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 810056, "time": 35812.88399887085, "eval_episode/length": 216.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 810056, "time": 35817.85583734512, "eval_episode/length": 300.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9966777408637874}
{"step": 810056, "time": 35820.66339969635, "eval_episode/length": 165.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9578313253012049}
{"step": 810632, "time": 35839.24033880234, "episode/length": 258.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 810752, "time": 35844.912590265274, "episode/length": 304.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 810808, "time": 35848.091104745865, "episode/length": 401.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 811128, "time": 35861.463953495026, "episode/length": 237.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 811312, "time": 35869.090072870255, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 811656, "time": 35881.56878089905, "episode/length": 510.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9882583170254403, "episode/intrinsic_return": 0.0}
{"step": 811792, "time": 35887.67536568642, "episode/length": 82.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 812168, "time": 35901.04172348976, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 812176, "time": 35903.05728173256, "episode/length": 326.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9877675840978594, "episode/intrinsic_return": 0.0}
{"step": 812656, "time": 35920.04596209526, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 812800, "time": 35926.2617726326, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 812928, "time": 35931.86712050438, "episode/length": 271.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 813136, "time": 35940.155594587326, "episode/length": 312.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 813392, "time": 35950.04240441322, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 813440, "time": 35953.07701587677, "episode/length": 328.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 813688, "time": 35962.394045352936, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 814032, "time": 35975.36629772186, "episode/length": 153.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 814536, "time": 35992.92800068855, "episode/length": 174.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 814544, "time": 35994.87715435028, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 814688, "time": 36001.013316869736, "episode/length": 253.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 814856, "time": 36007.92060422897, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 815160, "time": 36019.126784324646, "episode/length": 140.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 815376, "time": 36027.750217199326, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 815952, "time": 36047.934876680374, "episode/length": 313.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 815992, "time": 36050.53094935417, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 816144, "time": 36057.176299095154, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 816184, "time": 36059.77651000023, "episode/length": 205.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 816344, "time": 36066.49301195145, "episode/length": 147.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 816352, "time": 36068.463665008545, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 816552, "time": 36076.14360713959, "episode/length": 357.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 817048, "time": 36093.84062957764, "episode/length": 87.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 817264, "time": 36102.54866552353, "episode/length": 163.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 817728, "time": 36119.05728268623, "episode/length": 192.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 817760, "time": 36121.49796128273, "episode/length": 220.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 817792, "time": 36124.217854976654, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 818088, "time": 36134.96290230751, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 818152, "time": 36138.54104137421, "episode/length": 250.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 818416, "time": 36148.81794548035, "episode/length": 170.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 818592, "time": 36156.07714366913, "episode/length": 165.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 818664, "time": 36159.758746385574, "episode/length": 410.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 819448, "time": 36188.52364015579, "episode/length": 214.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 819592, "time": 36194.73536658287, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 819608, "time": 36196.87133073807, "episode/length": 148.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 820000, "time": 36211.227847099304, "episode/length": 238.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 36229.14195227623, "eval_episode/length": 56.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 820040, "time": 36231.92599987984, "eval_episode/length": 85.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 820040, "time": 36234.6324596405, "eval_episode/length": 114.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.991304347826087}
{"step": 820040, "time": 36237.31092095375, "eval_episode/length": 141.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 820040, "time": 36241.51126027107, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 820040, "time": 36243.228236436844, "eval_episode/length": 96.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9484536082474226}
{"step": 820040, "time": 36245.26355099678, "eval_episode/length": 223.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 820040, "time": 36247.02643561363, "eval_episode/length": 230.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 820416, "time": 36259.342118024826, "episode/length": 120.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 820520, "time": 36263.97770309448, "episode/length": 231.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 820528, "time": 36265.922454595566, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831649831649831, "episode/intrinsic_return": 0.0}
{"step": 820936, "time": 36280.38272643089, "episode/length": 116.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 820968, "time": 36282.92282605171, "episode/length": 400.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 821200, "time": 36292.14820075035, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 821696, "time": 36309.59269833565, "episode/length": 90.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 821776, "time": 36313.721554756165, "episode/length": 397.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9773869346733668, "episode/intrinsic_return": 0.0}
{"step": 821816, "time": 36316.29301691055, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 821824, "time": 36318.29489898682, "episode/length": 110.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 822032, "time": 36326.413773059845, "episode/length": 187.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 822640, "time": 36347.7889816761, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 823064, "time": 36362.81474137306, "episode/length": 155.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 823336, "time": 36373.06439495087, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 823689, "time": 36386.861552000046, "train_stats/sum_log_reward": 8.660747857851403, "train_stats/max_log_achievement_collect_coal": 0.7757009345794392, "train_stats/max_log_achievement_collect_drink": 4.158878504672897, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.7009345794392523, "train_stats/max_log_achievement_collect_stone": 16.57943925233645, "train_stats/max_log_achievement_collect_wood": 8.850467289719626, "train_stats/max_log_achievement_defeat_skeleton": 0.08411214953271028, "train_stats/max_log_achievement_defeat_zombie": 0.616822429906542, "train_stats/max_log_achievement_eat_cow": 0.09345794392523364, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.691588785046729, "train_stats/max_log_achievement_make_wood_sword": 0.009345794392523364, "train_stats/max_log_achievement_place_furnace": 0.11214953271028037, "train_stats/max_log_achievement_place_plant": 1.6261682242990654, "train_stats/max_log_achievement_place_stone": 11.485981308411215, "train_stats/max_log_achievement_place_table": 2.439252336448598, "train_stats/max_log_achievement_wake_up": 1.0841121495327102, "train_stats/mean_log_entropy": 0.3423150404591427, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.204810065192145, "train/action_min": 0.0, "train/action_std": 3.178469928535255, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03387712936445668, "train/actor_opt_grad_steps": 50645.0, "train/actor_opt_loss": -5.288469134955792, "train/adv_mag": 0.4762749027561497, "train/adv_max": 0.4178551775780884, "train/adv_mean": 0.0028108267650512405, "train/adv_min": -0.39512937566315803, "train/adv_std": 0.0517560190244301, "train/cont_avg": 0.9950841955236487, "train/cont_loss_mean": 0.00022707393242719058, "train/cont_loss_std": 0.006767334903553073, "train/cont_neg_acc": 0.9929536685750291, "train/cont_neg_loss": 0.024424330316071212, "train/cont_pos_acc": 0.9999667559121106, "train/cont_pos_loss": 0.00011812765487155278, "train/cont_pred": 0.9950737143690521, "train/cont_rate": 0.9950841955236487, "train/dyn_loss_mean": 13.039181535308426, "train/dyn_loss_std": 9.437263269682187, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9442972323379001, "train/extr_critic_critic_opt_grad_steps": 50645.0, "train/extr_critic_critic_opt_loss": 15608.449522276182, "train/extr_critic_mag": 7.829525870245856, "train/extr_critic_max": 7.829525870245856, "train/extr_critic_mean": 2.1532498686700254, "train/extr_critic_min": -0.21913564044076042, "train/extr_critic_std": 1.7958951624664101, "train/extr_return_normed_mag": 1.5443430107993048, "train/extr_return_normed_max": 1.5443430107993048, "train/extr_return_normed_mean": 0.37348110057614947, "train/extr_return_normed_min": -0.09922545702775588, "train/extr_return_normed_std": 0.3188619405232571, "train/extr_return_rate": 0.799151487044386, "train/extr_return_raw_mag": 8.872731788738355, "train/extr_return_raw_max": 8.872731788738355, "train/extr_return_raw_mean": 2.1693532080263704, "train/extr_return_raw_min": -0.5367806606196068, "train/extr_return_raw_std": 1.8253737526970941, "train/extr_reward_mag": 1.035368734114879, "train/extr_reward_max": 1.035368734114879, "train/extr_reward_mean": 0.03852473989103895, "train/extr_reward_min": -0.4591574765540458, "train/extr_reward_std": 0.1841480548720102, "train/image_loss_mean": 6.37974117575465, "train/image_loss_std": 11.49822847263233, "train/model_loss_mean": 14.258596214088234, "train/model_loss_std": 15.388924798449954, "train/model_opt_grad_norm": 59.51469875026394, "train/model_opt_grad_steps": 50595.37837837838, "train/model_opt_loss": 12287.129354940878, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 861.4864864864865, "train/policy_entropy_mag": 2.539680107219799, "train/policy_entropy_max": 2.539680107219799, "train/policy_entropy_mean": 0.5688776287275392, "train/policy_entropy_min": 0.0793750330906462, "train/policy_entropy_std": 0.6860860988900468, "train/policy_logprob_mag": 7.438383772566512, "train/policy_logprob_max": -0.009455658363279057, "train/policy_logprob_mean": -0.5684227250717782, "train/policy_logprob_min": -7.438383772566512, "train/policy_logprob_std": 1.1198037613082577, "train/policy_randomness_mag": 0.8963956281140044, "train/policy_randomness_max": 0.8963956281140044, "train/policy_randomness_mean": 0.2007888395439934, "train/policy_randomness_min": 0.02801590336083963, "train/policy_randomness_std": 0.2421582873809982, "train/post_ent_mag": 60.41908019297832, "train/post_ent_max": 60.41908019297832, "train/post_ent_mean": 43.44917008683488, "train/post_ent_min": 20.51451929195507, "train/post_ent_std": 7.799504747261873, "train/prior_ent_mag": 69.89076732944798, "train/prior_ent_max": 69.89076732944798, "train/prior_ent_mean": 56.54194971033045, "train/prior_ent_min": 39.07691509659226, "train/prior_ent_std": 4.887109244191969, "train/rep_loss_mean": 13.039181535308426, "train/rep_loss_std": 9.437263269682187, "train/reward_avg": 0.0278313711940034, "train/reward_loss_mean": 0.055119103752076626, "train/reward_loss_std": 0.25216377909119064, "train/reward_max_data": 1.0114864892250783, "train/reward_max_pred": 1.0087566601263511, "train/reward_neg_acc": 0.9928286136002153, "train/reward_neg_loss": 0.028601932672884415, "train/reward_pos_acc": 0.9677113842319798, "train/reward_pos_loss": 0.853112047588503, "train/reward_pred": 0.0269967627623496, "train/reward_rate": 0.032246357685810814, "eval_stats/sum_log_reward": 7.600000217556953, "eval_stats/max_log_achievement_collect_coal": 0.5625, "eval_stats/max_log_achievement_collect_drink": 4.625, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 10.5625, "eval_stats/max_log_achievement_collect_wood": 5.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.9375, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 5.375, "eval_stats/max_log_achievement_place_table": 1.625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 7.35506273485953e-06, "report/cont_loss_std": 0.00020362192299216986, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001649334211833775, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.159284672932699e-07, "report/cont_pred": 0.9960993528366089, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.654394149780273, "report/dyn_loss_std": 9.003142356872559, "report/image_loss_mean": 5.226243495941162, "report/image_loss_std": 8.88656997680664, "report/model_loss_mean": 12.252557754516602, "report/model_loss_std": 12.692448616027832, "report/post_ent_mag": 63.903202056884766, "report/post_ent_max": 63.903202056884766, "report/post_ent_mean": 44.39012145996094, "report/post_ent_min": 20.29595184326172, "report/post_ent_std": 7.797312259674072, "report/prior_ent_mag": 69.90278625488281, "report/prior_ent_max": 69.90278625488281, "report/prior_ent_mean": 56.08567810058594, "report/prior_ent_min": 39.967769622802734, "report/prior_ent_std": 5.151584148406982, "report/rep_loss_mean": 11.654394149780273, "report/rep_loss_std": 9.003142356872559, "report/reward_avg": 0.014843749813735485, "report/reward_loss_mean": 0.033670902252197266, "report/reward_loss_std": 0.14133508503437042, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029520988464355, "report/reward_neg_acc": 0.9970149993896484, "report/reward_neg_loss": 0.02080792933702469, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.71405428647995, "report/reward_pred": 0.015023112297058105, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0001281740260310471, "eval/cont_loss_std": 0.0033390657044947147, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0003955643333029002, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0001268619962502271, "eval/cont_pred": 0.9949983358383179, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.183055877685547, "eval/dyn_loss_std": 11.0565185546875, "eval/image_loss_mean": 9.957704544067383, "eval/image_loss_std": 14.132444381713867, "eval/model_loss_mean": 20.382247924804688, "eval/model_loss_std": 18.660825729370117, "eval/post_ent_mag": 62.51205825805664, "eval/post_ent_max": 62.51205825805664, "eval/post_ent_mean": 42.173118591308594, "eval/post_ent_min": 20.567852020263672, "eval/post_ent_std": 8.731756210327148, "eval/prior_ent_mag": 69.90278625488281, "eval/prior_ent_max": 69.90278625488281, "eval/prior_ent_mean": 56.9686279296875, "eval/prior_ent_min": 33.34571075439453, "eval/prior_ent_std": 5.069615840911865, "eval/rep_loss_mean": 17.183055877685547, "eval/rep_loss_std": 11.0565185546875, "eval/reward_avg": 0.04169921576976776, "eval/reward_loss_mean": 0.11458291858434677, "eval/reward_loss_std": 0.6027895212173462, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023527145385742, "eval/reward_neg_acc": 0.9907881021499634, "eval/reward_neg_loss": 0.04833696410059929, "eval/reward_pos_acc": 0.8723403811454773, "eval/reward_pos_loss": 1.4916530847549438, "eval/reward_pred": 0.036577582359313965, "eval/reward_rate": 0.0458984375, "replay/size": 823185.0, "replay/inserts": 23616.0, "replay/samples": 23616.0, "replay/insert_wait_avg": 1.324487087849356e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.863896002937461e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4520.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1284794427652274e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3571989536285, "timer/env.step_count": 2952.0, "timer/env.step_total": 239.707777261734, "timer/env.step_frac": 0.2396221844681758, "timer/env.step_avg": 0.08120182156562805, "timer/env.step_min": 0.022830724716186523, "timer/env.step_max": 1.7365062236785889, "timer/replay._sample_count": 23616.0, "timer/replay._sample_total": 11.949397325515747, "timer/replay._sample_frac": 0.011945130537386836, "timer/replay._sample_avg": 0.0005059873528758361, "timer/replay._sample_min": 0.0004038810729980469, "timer/replay._sample_max": 0.01109457015991211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3517.0, "timer/agent.policy_total": 52.544968605041504, "timer/agent.policy_frac": 0.052526206299113386, "timer/agent.policy_avg": 0.014940281093273102, "timer/agent.policy_min": 0.008519172668457031, "timer/agent.policy_max": 0.1694490909576416, "timer/dataset_train_count": 1476.0, "timer/dataset_train_total": 0.15505051612854004, "timer/dataset_train_frac": 0.00015499515202242013, "timer/dataset_train_avg": 0.00010504777515483743, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0010807514190673828, "timer/agent.train_count": 1476.0, "timer/agent.train_total": 640.8846101760864, "timer/agent.train_frac": 0.6406557686059043, "timer/agent.train_avg": 0.43420366543095285, "timer/agent.train_min": 0.42467546463012695, "timer/agent.train_max": 1.412578821182251, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48863720893859863, "timer/agent.report_frac": 0.0004884627305623552, "timer/agent.report_avg": 0.24431860446929932, "timer/agent.report_min": 0.23802447319030762, "timer/agent.report_max": 0.250612735748291, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5978345684174925e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 23.607198237632563}
{"step": 823728, "time": 36388.15926837921, "episode/length": 413.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 823824, "time": 36393.4211127758, "episode/length": 412.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9927360774818402, "episode/intrinsic_return": 0.0}
{"step": 823872, "time": 36396.72435927391, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 823944, "time": 36400.47202396393, "episode/length": 109.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 824112, "time": 36407.5279443264, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 824144, "time": 36410.00794553757, "episode/length": 305.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 824648, "time": 36427.41840338707, "episode/length": 114.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 825192, "time": 36446.39301228523, "episode/length": 426.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 825224, "time": 36448.89763259888, "episode/length": 235.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 825392, "time": 36456.14884400368, "episode/length": 155.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 825480, "time": 36460.268518686295, "episode/length": 191.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 826008, "time": 36478.75740337372, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 826088, "time": 36482.894179821014, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681978798586572, "episode/intrinsic_return": 0.0}
{"step": 826720, "time": 36504.96867418289, "episode/length": 78.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 826768, "time": 36508.167484760284, "episode/length": 160.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 826920, "time": 36515.02011036873, "episode/length": 350.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 827200, "time": 36526.44825911522, "episode/length": 318.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 827248, "time": 36529.50832366943, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 827656, "time": 36545.575370550156, "episode/length": 307.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9967532467532467, "episode/intrinsic_return": 0.0}
{"step": 827688, "time": 36548.066660404205, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 827712, "time": 36550.5679795742, "episode/length": 117.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 828072, "time": 36563.40287280083, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 828136, "time": 36566.91150474548, "episode/length": 363.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9972527472527473, "episode/intrinsic_return": 0.0}
{"step": 828184, "time": 36569.94204425812, "episode/length": 61.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 828536, "time": 36582.77995824814, "episode/length": 43.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 828552, "time": 36584.84402966499, "episode/length": 51.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 828736, "time": 36592.54697871208, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 828800, "time": 36596.16223311424, "episode/length": 259.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 828848, "time": 36599.158989191055, "episode/length": 141.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 829424, "time": 36619.03597283363, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 829840, "time": 36633.97962808609, "episode/length": 272.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 829968, "time": 36639.49583005905, "episode/length": 178.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 830000, "time": 36642.00085878372, "episode/length": 149.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 36662.98441696167, "eval_episode/length": 113.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9912280701754386}
{"step": 830024, "time": 36669.67178750038, "eval_episode/length": 227.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 830024, "time": 36672.073414325714, "eval_episode/length": 233.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 830024, "time": 36675.187748909, "eval_episode/length": 268.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9776951672862454}
{"step": 830024, "time": 36679.07674431801, "eval_episode/length": 326.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9847094801223242}
{"step": 830024, "time": 36680.92509269714, "eval_episode/length": 336.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9940652818991098}
{"step": 830024, "time": 36683.653415203094, "eval_episode/length": 365.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9972677595628415}
{"step": 830024, "time": 36685.30947184563, "eval_episode/length": 368.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.991869918699187}
{"step": 830096, "time": 36687.86234879494, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 830368, "time": 36698.18646121025, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 830432, "time": 36701.72132086754, "episode/length": 197.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 830536, "time": 36706.33739209175, "episode/length": 307.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 831232, "time": 36730.571264743805, "episode/length": 86.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 831328, "time": 36735.22031569481, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 831360, "time": 36737.66725945473, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 831504, "time": 36743.84151721001, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 831696, "time": 36751.58612036705, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 832384, "time": 36775.40538048744, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 832640, "time": 36785.39509725571, "episode/length": 275.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 832712, "time": 36789.01834535599, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 832800, "time": 36793.665046453476, "episode/length": 303.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 832960, "time": 36800.24584031105, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 833168, "time": 36808.47013783455, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 833192, "time": 36810.65332221985, "episode/length": 244.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 833640, "time": 36826.55035996437, "episode/length": 156.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 834088, "time": 36842.56360292435, "episode/length": 140.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 834120, "time": 36845.118148326874, "episode/length": 175.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 834584, "time": 36861.49915385246, "episode/length": 173.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 834640, "time": 36865.0037355423, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 834736, "time": 36869.64002251625, "episode/length": 261.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 834792, "time": 36872.8709859848, "episode/length": 83.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 834840, "time": 36875.85783410072, "episode/length": 434.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 835624, "time": 36904.227955818176, "episode/length": 352.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9943342776203966, "episode/intrinsic_return": 0.0}
{"step": 835664, "time": 36907.24664735794, "episode/length": 252.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 835736, "time": 36910.78612446785, "episode/length": 205.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 835816, "time": 36914.94611096382, "episode/length": 121.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 835912, "time": 36919.55161142349, "episode/length": 158.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 836048, "time": 36925.685177087784, "episode/length": 182.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 836960, "time": 36956.93903589249, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 837120, "time": 36964.265132665634, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 837496, "time": 36977.65321612358, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 837496, "time": 36977.661274433136, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 837496, "time": 36977.670238256454, "episode/length": 344.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 838032, "time": 37000.25677609444, "episode/length": 66.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 838064, "time": 37002.852889060974, "episode/length": 290.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 838272, "time": 37010.939571380615, "episode/length": 325.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99079754601227, "episode/intrinsic_return": 0.0}
{"step": 838536, "time": 37020.76349949837, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 838688, "time": 37027.517825603485, "episode/length": 148.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 839040, "time": 37040.46417760849, "episode/length": 95.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 839104, "time": 37044.1343729496, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 839752, "time": 37066.4844186306, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 37095.78104138374, "eval_episode/length": 162.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 840008, "time": 37098.74635696411, "eval_episode/length": 195.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 840008, "time": 37100.755269527435, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 840008, "time": 37102.70562005043, "eval_episode/length": 216.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 840008, "time": 37105.421386003494, "eval_episode/length": 243.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9754098360655737}
{"step": 840008, "time": 37109.05668902397, "eval_episode/length": 296.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9865319865319865}
{"step": 840008, "time": 37111.783125162125, "eval_episode/length": 324.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9969230769230769}
{"step": 840008, "time": 37113.519713163376, "eval_episode/length": 124.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.992}
{"step": 840104, "time": 37116.60094165802, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 840248, "time": 37122.820293188095, "episode/length": 410.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9902676399026764, "episode/intrinsic_return": 0.0}
{"step": 840328, "time": 37126.98236465454, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 840640, "time": 37138.77583479881, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 840656, "time": 37140.867722034454, "episode/length": 327.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 841192, "time": 37161.568012952805, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 841232, "time": 37164.61202406883, "episode/length": 122.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967479674796748, "episode/intrinsic_return": 0.0}
{"step": 841408, "time": 37171.928661346436, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 841472, "time": 37175.5773897171, "episode/length": 295.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 841720, "time": 37184.91006708145, "episode/length": 173.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 841752, "time": 37187.47111201286, "episode/length": 138.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 841768, "time": 37189.57316851616, "episode/length": 44.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 841824, "time": 37193.02452945709, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 842008, "time": 37200.28487229347, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 842552, "time": 37219.47317862511, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 842928, "time": 37233.40351319313, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 843040, "time": 37238.47083115578, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 843216, "time": 37245.65106630325, "episode/length": 252.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 843224, "time": 37247.167563676834, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 843224, "time": 37247.17540335655, "episode/length": 151.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 843464, "time": 37258.03737592697, "episode/length": 52.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 843576, "time": 37263.36912274361, "episode/length": 218.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 843944, "time": 37278.20527100563, "episode/length": 271.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 844272, "time": 37290.44942688942, "episode/length": 314.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 844648, "time": 37304.169573783875, "episode/length": 178.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 844752, "time": 37309.2108836174, "episode/length": 227.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 845008, "time": 37318.89814591408, "episode/length": 132.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 845368, "time": 37331.804661512375, "episode/length": 237.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 845528, "time": 37338.515952825546, "episode/length": 287.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 845680, "time": 37345.13154840469, "episode/length": 306.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9804560260586319, "episode/intrinsic_return": 0.0}
{"step": 845768, "time": 37349.212464571, "episode/length": 273.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 846104, "time": 37361.59134936333, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 846104, "time": 37361.60018777847, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 846232, "time": 37368.88841128349, "episode/length": 152.0, "episode/score": 9.099999949336052, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 846312, "time": 37372.95971035957, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 846560, "time": 37382.759803533554, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 846625, "time": 37386.88168621063, "train_stats/sum_log_reward": 8.421428763440677, "train_stats/max_log_achievement_collect_coal": 0.8660714285714286, "train_stats/max_log_achievement_collect_drink": 4.107142857142857, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.4107142857142858, "train_stats/max_log_achievement_collect_stone": 18.669642857142858, "train_stats/max_log_achievement_collect_wood": 7.75, "train_stats/max_log_achievement_defeat_skeleton": 0.08928571428571429, "train_stats/max_log_achievement_defeat_zombie": 0.5446428571428571, "train_stats/max_log_achievement_eat_cow": 0.05357142857142857, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.24107142857142858, "train_stats/max_log_achievement_place_plant": 1.3303571428571428, "train_stats/max_log_achievement_place_stone": 12.473214285714286, "train_stats/max_log_achievement_place_table": 2.125, "train_stats/max_log_achievement_wake_up": 1.2678571428571428, "train_stats/mean_log_entropy": 0.3831425632483193, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.323928939712631, "train/action_min": 0.0, "train/action_std": 3.2624874565151187, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0338503202175969, "train/actor_opt_grad_steps": 52100.0, "train/actor_opt_loss": -1.975266452331643, "train/adv_mag": 0.44976726403603184, "train/adv_max": 0.40796195564570126, "train/adv_mean": 0.003270125843994026, "train/adv_min": -0.3740444910693002, "train/adv_std": 0.051647698259228596, "train/cont_avg": 0.9948098776223776, "train/cont_loss_mean": 0.00027261084528518707, "train/cont_loss_std": 0.008234382496435832, "train/cont_neg_acc": 0.9900932403711172, "train/cont_neg_loss": 0.051861524984440084, "train/cont_pos_acc": 0.9999793567857542, "train/cont_pos_loss": 0.00010746867441059093, "train/cont_pred": 0.9948085208872816, "train/cont_rate": 0.9948098776223776, "train/dyn_loss_mean": 12.867991480793986, "train/dyn_loss_std": 9.525779737459196, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9323264543826764, "train/extr_critic_critic_opt_grad_steps": 52100.0, "train/extr_critic_critic_opt_loss": 15554.74261773383, "train/extr_critic_mag": 7.9561576443118645, "train/extr_critic_max": 7.9561576443118645, "train/extr_critic_mean": 2.3390976332284352, "train/extr_critic_min": -0.21250708620031397, "train/extr_critic_std": 1.898345241179833, "train/extr_return_normed_mag": 1.5266321989206166, "train/extr_return_normed_max": 1.5266321989206166, "train/extr_return_normed_mean": 0.3889042720511243, "train/extr_return_normed_min": -0.10245770369688947, "train/extr_return_normed_std": 0.32590539628392334, "train/extr_return_rate": 0.8027148396818788, "train/extr_return_raw_mag": 9.088476654532906, "train/extr_return_raw_max": 9.088476654532906, "train/extr_return_raw_mean": 2.358445216725756, "train/extr_return_raw_min": -0.5503372722989196, "train/extr_return_raw_std": 1.9288217963038625, "train/extr_reward_mag": 1.0374435094686656, "train/extr_reward_max": 1.0374435094686656, "train/extr_reward_mean": 0.04020012981564432, "train/extr_reward_min": -0.4703749885092248, "train/extr_reward_std": 0.1877946037720967, "train/image_loss_mean": 6.541585908903109, "train/image_loss_std": 12.025947397405451, "train/model_loss_mean": 14.31917730077997, "train/model_loss_std": 15.94519082983057, "train/model_opt_grad_norm": 55.268695244422325, "train/model_opt_grad_steps": 52049.56643356643, "train/model_opt_loss": 13553.841253960883, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 944.0559440559441, "train/policy_entropy_mag": 2.548820593973973, "train/policy_entropy_max": 2.548820593973973, "train/policy_entropy_mean": 0.5803866638587072, "train/policy_entropy_min": 0.07937503382042571, "train/policy_entropy_std": 0.7063363540422666, "train/policy_logprob_mag": 7.438383789329262, "train/policy_logprob_max": -0.009455658391222253, "train/policy_logprob_mean": -0.5804934768409996, "train/policy_logprob_min": -7.438383789329262, "train/policy_logprob_std": 1.1255498586834727, "train/policy_randomness_mag": 0.8996218171986666, "train/policy_randomness_max": 0.8996218171986666, "train/policy_randomness_mean": 0.20485102192505256, "train/policy_randomness_min": 0.02801590356845539, "train/policy_randomness_std": 0.2493057346844173, "train/post_ent_mag": 60.58238649701739, "train/post_ent_max": 60.58238649701739, "train/post_ent_mean": 43.61404760400732, "train/post_ent_min": 20.407635255293414, "train/post_ent_std": 7.894227811506578, "train/prior_ent_mag": 69.97543655075394, "train/prior_ent_max": 69.97543655075394, "train/prior_ent_mean": 56.57422656612796, "train/prior_ent_min": 38.74514155621295, "train/prior_ent_std": 4.957030729814009, "train/rep_loss_mean": 12.867991480793986, "train/rep_loss_std": 9.525779737459196, "train/reward_avg": 0.02898546744632971, "train/reward_loss_mean": 0.056523955837413146, "train/reward_loss_std": 0.25312279664969944, "train/reward_max_data": 1.0237762294449173, "train/reward_max_pred": 1.0130523885046685, "train/reward_neg_acc": 0.993094727292761, "train/reward_neg_loss": 0.029050068441335553, "train/reward_pos_acc": 0.9696033747046144, "train/reward_pos_loss": 0.8494478026470105, "train/reward_pred": 0.028158410296000382, "train/reward_rate": 0.033640187937062936, "eval_stats/sum_log_reward": 8.975000202655792, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 31.25, "eval_stats/max_log_achievement_collect_wood": 8.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.25, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_stone": 23.5625, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.9272896426846273e-06, "report/cont_loss_std": 8.112150680972263e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0009560384787619114, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.267668210402917e-07, "report/cont_pred": 0.9970730543136597, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 10.477799415588379, "report/dyn_loss_std": 8.325662612915039, "report/image_loss_mean": 5.244050025939941, "report/image_loss_std": 8.322958946228027, "report/model_loss_mean": 11.589517593383789, "report/model_loss_std": 11.678556442260742, "report/post_ent_mag": 64.30517578125, "report/post_ent_max": 64.30517578125, "report/post_ent_mean": 45.351951599121094, "report/post_ent_min": 20.79547882080078, "report/post_ent_std": 7.6609930992126465, "report/prior_ent_mag": 70.72747802734375, "report/prior_ent_max": 70.72747802734375, "report/prior_ent_mean": 56.240150451660156, "report/prior_ent_min": 39.165706634521484, "report/prior_ent_std": 5.104736328125, "report/rep_loss_mean": 10.477799415588379, "report/rep_loss_std": 8.325662612915039, "report/reward_avg": 0.0234375, "report/reward_loss_mean": 0.05878431722521782, "report/reward_loss_std": 0.2804153263568878, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016741752624512, "report/reward_neg_acc": 0.9889559149742126, "report/reward_neg_loss": 0.03786599636077881, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.8028790950775146, "report/reward_pred": 0.02458251640200615, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00016010548279155046, "eval/cont_loss_std": 0.004780786577612162, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0035531199537217617, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00015013580559752882, "eval/cont_pred": 0.996941864490509, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.10824966430664, "eval/dyn_loss_std": 10.811877250671387, "eval/image_loss_mean": 10.496170043945312, "eval/image_loss_std": 15.791284561157227, "eval/model_loss_mean": 20.25182342529297, "eval/model_loss_std": 20.006099700927734, "eval/post_ent_mag": 59.877288818359375, "eval/post_ent_max": 59.877288818359375, "eval/post_ent_mean": 42.52837371826172, "eval/post_ent_min": 21.922771453857422, "eval/post_ent_std": 8.070998191833496, "eval/prior_ent_mag": 70.05907440185547, "eval/prior_ent_max": 70.05907440185547, "eval/prior_ent_mean": 56.67481231689453, "eval/prior_ent_min": 37.730594635009766, "eval/prior_ent_std": 5.202624797821045, "eval/rep_loss_mean": 16.10824966430664, "eval/rep_loss_std": 10.811877250671387, "eval/reward_avg": 0.03164062649011612, "eval/reward_loss_mean": 0.09054426848888397, "eval/reward_loss_std": 0.4838148057460785, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0032374858856201, "eval/reward_neg_acc": 0.9838057160377502, "eval/reward_neg_loss": 0.04927502200007439, "eval/reward_pos_acc": 0.8611111044883728, "eval/reward_pos_loss": 1.2231559753417969, "eval/reward_pred": 0.03147505223751068, "eval/reward_rate": 0.03515625, "replay/size": 846121.0, "replay/inserts": 22936.0, "replay/samples": 22928.0, "replay/insert_wait_avg": 1.3016244863690421e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.919764402273727e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5608.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.139758146778493e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.008141040802, "timer/env.step_count": 2867.0, "timer/env.step_total": 248.5475697517395, "timer/env.step_frac": 0.24854554633230566, "timer/env.step_avg": 0.08669256008082996, "timer/env.step_min": 0.022736787796020508, "timer/env.step_max": 5.1239707469940186, "timer/replay._sample_count": 22928.0, "timer/replay._sample_total": 11.692572593688965, "timer/replay._sample_frac": 0.011692477404753336, "timer/replay._sample_avg": 0.0005099691466193721, "timer/replay._sample_min": 0.00038051605224609375, "timer/replay._sample_max": 0.010833978652954102, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3568.0, "timer/agent.policy_total": 55.06072664260864, "timer/agent.policy_frac": 0.05506027839463566, "timer/agent.policy_avg": 0.015431818005215427, "timer/agent.policy_min": 0.008353233337402344, "timer/agent.policy_max": 0.11468052864074707, "timer/dataset_train_count": 1433.0, "timer/dataset_train_total": 0.14920544624328613, "timer/dataset_train_frac": 0.00014920423156554913, "timer/dataset_train_avg": 0.00010412103715511942, "timer/dataset_train_min": 8.726119995117188e-05, "timer/dataset_train_max": 0.00044417381286621094, "timer/agent.train_count": 1433.0, "timer/agent.train_total": 624.5531599521637, "timer/agent.train_frac": 0.6245480754807984, "timer/agent.train_avg": 0.43583611999453153, "timer/agent.train_min": 0.4216325283050537, "timer/agent.train_max": 2.455704689025879, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4751138687133789, "timer/agent.report_frac": 0.00047511000082347675, "timer/agent.report_avg": 0.23755693435668945, "timer/agent.report_min": 0.22950148582458496, "timer/agent.report_max": 0.24561238288879395, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337832933987769e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 22.935496915661876}
{"step": 846632, "time": 37386.89460682869, "episode/length": 118.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 847664, "time": 37422.33155751228, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 847928, "time": 37432.166898489, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 848024, "time": 37436.83776688576, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 848168, "time": 37443.00352907181, "episode/length": 299.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 848192, "time": 37445.52418923378, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 848232, "time": 37448.07656145096, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 848504, "time": 37458.27904677391, "episode/length": 371.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 849088, "time": 37478.815329790115, "episode/length": 177.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 849400, "time": 37490.23614859581, "episode/length": 171.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 849616, "time": 37499.04790210724, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 849776, "time": 37505.84279298782, "episode/length": 401.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 850056, "time": 37516.278044223785, "episode/length": 193.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 37538.261050224304, "eval_episode/length": 143.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 850096, "time": 37542.37626624107, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 850096, "time": 37544.61350464821, "eval_episode/length": 222.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 850096, "time": 37548.72026872635, "eval_episode/length": 56.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 850096, "time": 37551.25174474716, "eval_episode/length": 304.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 850096, "time": 37554.16316843033, "eval_episode/length": 193.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 850096, "time": 37557.12383747101, "eval_episode/length": 358.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9832869080779945}
{"step": 850096, "time": 37561.938952445984, "eval_episode/length": 396.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9974811083123426}
{"step": 850520, "time": 37575.42669296265, "episode/length": 290.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 850616, "time": 37580.01350235939, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 850992, "time": 37593.88975858688, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 851448, "time": 37609.83373951912, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 851640, "time": 37617.50897049904, "episode/length": 232.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 852056, "time": 37634.2668530941, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968, "episode/intrinsic_return": 0.0}
{"step": 852080, "time": 37636.722195863724, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 852856, "time": 37663.10184788704, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 853024, "time": 37670.25358462334, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712460063897763, "episode/intrinsic_return": 0.0}
{"step": 853032, "time": 37671.791545152664, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 853176, "time": 37677.87352180481, "episode/length": 510.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9882583170254403, "episode/intrinsic_return": 0.0}
{"step": 853328, "time": 37684.60974621773, "episode/length": 490.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9938900203665988, "episode/intrinsic_return": 0.0}
{"step": 853664, "time": 37696.895258426666, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 853896, "time": 37705.753136873245, "episode/length": 305.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 854064, "time": 37713.00526094437, "episode/length": 247.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 854496, "time": 37728.327912807465, "episode/length": 53.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 854648, "time": 37734.58933711052, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 854848, "time": 37742.78955101967, "episode/length": 248.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 855184, "time": 37755.07667350769, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 855544, "time": 37767.95893764496, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 855576, "time": 37770.39107847214, "episode/length": 299.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766666666666667, "episode/intrinsic_return": 0.0}
{"step": 855584, "time": 37772.55479955673, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 856264, "time": 37795.708485364914, "episode/length": 176.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 856264, "time": 37795.717015981674, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 856312, "time": 37800.47437334061, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 856448, "time": 37806.71667265892, "episode/length": 108.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 857280, "time": 37835.029024124146, "episode/length": 261.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9656488549618321, "episode/intrinsic_return": 0.0}
{"step": 857584, "time": 37846.478018045425, "episode/length": 249.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 857736, "time": 37852.69337892532, "episode/length": 273.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 857960, "time": 37861.52596592903, "episode/length": 205.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 857960, "time": 37861.53632736206, "episode/length": 432.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 858256, "time": 37874.54552078247, "episode/length": 248.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 858584, "time": 37886.35876727104, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 858640, "time": 37889.939665317535, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 858904, "time": 37899.85812520981, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 859104, "time": 37907.972608566284, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 859392, "time": 37918.94170022011, "episode/length": 367.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9972826086956522, "episode/intrinsic_return": 0.0}
{"step": 859688, "time": 37929.807787418365, "episode/length": 137.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 859920, "time": 37939.1635017395, "episode/length": 207.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 859936, "time": 37941.308940172195, "episode/length": 103.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 37962.410651922226, "eval_episode/length": 54.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 860080, "time": 37965.70249199867, "eval_episode/length": 99.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.99}
{"step": 860080, "time": 37969.64798069, "eval_episode/length": 160.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9813664596273292}
{"step": 860080, "time": 37972.44937372208, "eval_episode/length": 139.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 860080, "time": 37974.28068900108, "eval_episode/length": 200.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 860080, "time": 37976.90028786659, "eval_episode/length": 227.0, "eval_episode/score": 10.100000031292439, "eval_episode/reward_rate": 0.9649122807017544}
{"step": 860080, "time": 37980.47377324104, "eval_episode/length": 275.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 860080, "time": 37982.756534576416, "eval_episode/length": 287.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 860480, "time": 37997.302701473236, "episode/length": 342.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9970845481049563, "episode/intrinsic_return": 0.0}
{"step": 860712, "time": 38006.2160012722, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 860864, "time": 38013.02670121193, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 860888, "time": 38015.14727091789, "episode/length": 280.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 861376, "time": 38032.578048706055, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 862176, "time": 38060.17819070816, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 862320, "time": 38066.370361328125, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929742388758782, "episode/intrinsic_return": 0.0}
{"step": 862352, "time": 38069.013305425644, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 862488, "time": 38074.68237400055, "episode/length": 221.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 863144, "time": 38097.231998205185, "episode/length": 431.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 863192, "time": 38100.24133634567, "episode/length": 406.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 863696, "time": 38118.375993967056, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 863920, "time": 38127.038773059845, "episode/length": 378.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9894459102902374, "episode/intrinsic_return": 0.0}
{"step": 864064, "time": 38133.284031391144, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 864544, "time": 38150.32944607735, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 864568, "time": 38152.36977124214, "episode/length": 280.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 864672, "time": 38157.535460710526, "episode/length": 190.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 864736, "time": 38161.012721300125, "episode/length": 419.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 865200, "time": 38177.49796915054, "episode/length": 377.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 865208, "time": 38179.01632452011, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 865288, "time": 38183.16081595421, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 866096, "time": 38210.965552568436, "episode/length": 177.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 866584, "time": 38228.40553808212, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 866656, "time": 38232.50200557709, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 867104, "time": 38248.58641433716, "episode/length": 316.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 867232, "time": 38254.30724143982, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 867528, "time": 38265.1916782856, "episode/length": 432.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 867584, "time": 38268.800594091415, "episode/length": 124.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.944, "episode/intrinsic_return": 0.0}
{"step": 867984, "time": 38283.18648147583, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 868040, "time": 38286.28231096268, "episode/length": 242.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 868432, "time": 38302.00736570358, "episode/length": 402.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776674937965261, "episode/intrinsic_return": 0.0}
{"step": 868528, "time": 38306.67808556557, "episode/length": 233.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 868600, "time": 38310.34886956215, "episode/length": 133.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 868696, "time": 38315.048558950424, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 868904, "time": 38323.31792974472, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 868912, "time": 38325.32494688034, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 869224, "time": 38336.60102105141, "episode/length": 264.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 869304, "time": 38340.74743270874, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 869768, "time": 38357.21897649765, "episode/length": 154.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 870008, "time": 38366.46491885185, "episode/length": 245.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 38390.18211603165, "eval_episode/length": 178.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 870064, "time": 38392.3248128891, "eval_episode/length": 192.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 870064, "time": 38392.332283973694, "eval_episode/length": 192.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 870064, "time": 38396.39539027214, "eval_episode/length": 214.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 870064, "time": 38398.664811611176, "eval_episode/length": 233.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 870064, "time": 38400.84119319916, "eval_episode/length": 250.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 870064, "time": 38402.617199897766, "eval_episode/length": 251.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.996031746031746}
{"step": 870064, "time": 38406.76343488693, "eval_episode/length": 98.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.98989898989899}
{"step": 870065, "time": 38407.35455727577, "train_stats/sum_log_reward": 8.917204544108401, "train_stats/max_log_achievement_collect_coal": 1.075268817204301, "train_stats/max_log_achievement_collect_drink": 5.56989247311828, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.2473118279569892, "train_stats/max_log_achievement_collect_stone": 23.870967741935484, "train_stats/max_log_achievement_collect_wood": 8.172043010752688, "train_stats/max_log_achievement_defeat_skeleton": 0.06451612903225806, "train_stats/max_log_achievement_defeat_zombie": 0.5376344086021505, "train_stats/max_log_achievement_eat_cow": 0.03225806451612903, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010752688172043012, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5161290322580645, "train_stats/max_log_achievement_make_wood_sword": 0.010752688172043012, "train_stats/max_log_achievement_place_furnace": 0.40860215053763443, "train_stats/max_log_achievement_place_plant": 1.2258064516129032, "train_stats/max_log_achievement_place_stone": 17.043010752688172, "train_stats/max_log_achievement_place_table": 2.225806451612903, "train_stats/max_log_achievement_wake_up": 1.3978494623655915, "train_stats/mean_log_entropy": 0.433999189926732, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.289365184550383, "train/action_min": 0.0, "train/action_std": 3.2397812531918895, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.033752260843710025, "train/actor_opt_grad_steps": 53550.0, "train/actor_opt_loss": -8.221066217083914, "train/adv_mag": 0.46095362609746504, "train/adv_max": 0.41287582504506015, "train/adv_mean": 0.002080294229475295, "train/adv_min": -0.3742619813704977, "train/adv_std": 0.05068207514427957, "train/cont_avg": 0.9953629889455783, "train/cont_loss_mean": 0.00015299394107208306, "train/cont_loss_std": 0.0046642537335890135, "train/cont_neg_acc": 0.9973760944645421, "train/cont_neg_loss": 0.007701913097872687, "train/cont_pos_acc": 0.9999665926102879, "train/cont_pos_loss": 0.00010514279134000435, "train/cont_pred": 0.9953393190085482, "train/cont_rate": 0.9953629889455783, "train/dyn_loss_mean": 12.86072032954417, "train/dyn_loss_std": 9.462487811133975, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9032147770025292, "train/extr_critic_critic_opt_grad_steps": 53550.0, "train/extr_critic_critic_opt_loss": 15630.948355123299, "train/extr_critic_mag": 8.151943271662914, "train/extr_critic_max": 8.151943271662914, "train/extr_critic_mean": 2.3434388653761675, "train/extr_critic_min": -0.2144556288816491, "train/extr_critic_std": 1.8719315764044417, "train/extr_return_normed_mag": 1.5170743781693128, "train/extr_return_normed_max": 1.5170743781693128, "train/extr_return_normed_mean": 0.37752625173857424, "train/extr_return_normed_min": -0.10296717772678453, "train/extr_return_normed_std": 0.3131195359489545, "train/extr_return_rate": 0.824776828289032, "train/extr_return_raw_mag": 9.26695881408899, "train/extr_return_raw_max": 9.26695881408899, "train/extr_return_raw_mean": 2.356049879067609, "train/extr_return_raw_min": -0.5574788111610477, "train/extr_return_raw_std": 1.898744600970729, "train/extr_reward_mag": 1.0377986171618612, "train/extr_reward_max": 1.0377986171618612, "train/extr_reward_mean": 0.04068062502612062, "train/extr_reward_min": -0.4777495739411335, "train/extr_reward_std": 0.18823983788895768, "train/image_loss_mean": 6.312433022220119, "train/image_loss_std": 11.257025699226224, "train/model_loss_mean": 14.082338644533742, "train/model_loss_std": 15.142223273815752, "train/model_opt_grad_norm": 54.31614158267067, "train/model_opt_grad_steps": 53498.97959183674, "train/model_opt_loss": 16075.048559072065, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1139.455782312925, "train/policy_entropy_mag": 2.5581286618498718, "train/policy_entropy_max": 2.5581286618498718, "train/policy_entropy_mean": 0.5657628857765068, "train/policy_entropy_min": 0.07937503129649325, "train/policy_entropy_std": 0.7024034403619313, "train/policy_logprob_mag": 7.43838374468745, "train/policy_logprob_max": -0.009455659173327644, "train/policy_logprob_mean": -0.5661871017647438, "train/policy_logprob_min": -7.43838374468745, "train/policy_logprob_std": 1.1193333925033102, "train/policy_randomness_mag": 0.9029071554034745, "train/policy_randomness_max": 0.9029071554034745, "train/policy_randomness_mean": 0.1996894717013755, "train/policy_randomness_min": 0.02801590265870905, "train/policy_randomness_std": 0.24791759059948176, "train/post_ent_mag": 60.33924865722656, "train/post_ent_max": 60.33924865722656, "train/post_ent_mean": 43.61405189669862, "train/post_ent_min": 20.234378633045015, "train/post_ent_std": 7.87091047261037, "train/prior_ent_mag": 70.05060442450906, "train/prior_ent_max": 70.05060442450906, "train/prior_ent_mean": 56.53857100091013, "train/prior_ent_min": 39.52501982085559, "train/prior_ent_std": 4.890086216180503, "train/rep_loss_mean": 12.86072032954417, "train/rep_loss_std": 9.462487811133975, "train/reward_avg": 0.02805325236855721, "train/reward_loss_mean": 0.05332064397987865, "train/reward_loss_std": 0.2452306326757483, "train/reward_max_data": 1.0108843563365288, "train/reward_max_pred": 1.0104628947316383, "train/reward_neg_acc": 0.9927827225250452, "train/reward_neg_loss": 0.026685325517540888, "train/reward_pos_acc": 0.9660081551188514, "train/reward_pos_loss": 0.8567856708351447, "train/reward_pred": 0.02718450908618821, "train/reward_rate": 0.03231956845238095, "eval_stats/sum_log_reward": 8.016666829586029, "eval_stats/max_log_achievement_collect_coal": 0.9583333333333334, "eval_stats/max_log_achievement_collect_drink": 4.958333333333333, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 17.5, "eval_stats/max_log_achievement_collect_wood": 7.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.5416666666666666, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.20833333333333334, "eval_stats/max_log_achievement_place_plant": 1.5833333333333333, "eval_stats/max_log_achievement_place_stone": 11.958333333333334, "eval_stats/max_log_achievement_place_table": 2.5416666666666665, "eval_stats/max_log_achievement_wake_up": 0.9166666666666666, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.644732479799131e-07, "report/cont_loss_std": 8.959119440987706e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.110105409286916e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.4903561640931e-07, "report/cont_pred": 0.99609375, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 16.424943923950195, "report/dyn_loss_std": 9.699434280395508, "report/image_loss_mean": 10.035204887390137, "report/image_loss_std": 13.9110689163208, "report/model_loss_mean": 19.945098876953125, "report/model_loss_std": 17.829626083374023, "report/post_ent_mag": 60.70316696166992, "report/post_ent_max": 60.70316696166992, "report/post_ent_mean": 42.41450119018555, "report/post_ent_min": 18.773258209228516, "report/post_ent_std": 7.524498462677002, "report/prior_ent_mag": 70.04866790771484, "report/prior_ent_max": 70.04866790771484, "report/prior_ent_mean": 58.729156494140625, "report/prior_ent_min": 42.79280090332031, "report/prior_ent_std": 4.954227924346924, "report/rep_loss_mean": 16.424943923950195, "report/rep_loss_std": 9.699434280395508, "report/reward_avg": 0.02666015550494194, "report/reward_loss_mean": 0.05492737889289856, "report/reward_loss_std": 0.21290917694568634, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.096245527267456, "report/reward_neg_acc": 0.9858870506286621, "report/reward_neg_loss": 0.03073776140809059, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.8048053979873657, "report/reward_pred": 0.028285818174481392, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.005889685358852148, "eval/cont_loss_std": 0.1820518523454666, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04026312381029129, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.005721022840589285, "eval/cont_pred": 0.9943291544914246, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.03863525390625, "eval/dyn_loss_std": 10.94615650177002, "eval/image_loss_mean": 12.734625816345215, "eval/image_loss_std": 24.01802635192871, "eval/model_loss_mean": 23.682884216308594, "eval/model_loss_std": 27.98644256591797, "eval/post_ent_mag": 62.333274841308594, "eval/post_ent_max": 62.333274841308594, "eval/post_ent_mean": 41.46363067626953, "eval/post_ent_min": 18.54859733581543, "eval/post_ent_std": 8.091543197631836, "eval/prior_ent_mag": 70.1263656616211, "eval/prior_ent_max": 70.1263656616211, "eval/prior_ent_mean": 57.39954376220703, "eval/prior_ent_min": 41.643463134765625, "eval/prior_ent_std": 4.6741204261779785, "eval/rep_loss_mean": 18.03863525390625, "eval/rep_loss_std": 10.94615650177002, "eval/reward_avg": 0.04511718824505806, "eval/reward_loss_mean": 0.11918886005878448, "eval/reward_loss_std": 0.6294505596160889, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.003021478652954, "eval/reward_neg_acc": 0.9886947870254517, "eval/reward_neg_loss": 0.0514475516974926, "eval/reward_pos_acc": 0.9019607901573181, "eval/reward_pos_loss": 1.4115867614746094, "eval/reward_pred": 0.039260514080524445, "eval/reward_rate": 0.0498046875, "replay/size": 869561.0, "replay/inserts": 23440.0, "replay/samples": 23440.0, "replay/insert_wait_avg": 1.2947023932030583e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.868525111227719e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7992.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.179324733363735e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0132789611816406e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1020.4491596221924, "timer/env.step_count": 2930.0, "timer/env.step_total": 219.51053977012634, "timer/env.step_frac": 0.21511168655516083, "timer/env.step_avg": 0.07491827295908748, "timer/env.step_min": 0.023181438446044922, "timer/env.step_max": 3.2838175296783447, "timer/replay._sample_count": 23440.0, "timer/replay._sample_total": 11.941367626190186, "timer/replay._sample_frac": 0.011702070126268041, "timer/replay._sample_avg": 0.0005094440113562365, "timer/replay._sample_min": 0.00042247772216796875, "timer/replay._sample_max": 0.010839462280273438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3929.0, "timer/agent.policy_total": 59.467933893203735, "timer/agent.policy_frac": 0.058276233884323, "timer/agent.policy_avg": 0.015135641102877, "timer/agent.policy_min": 0.008520364761352539, "timer/agent.policy_max": 0.20855450630187988, "timer/dataset_train_count": 1465.0, "timer/dataset_train_total": 0.1544780731201172, "timer/dataset_train_frac": 0.00015138242965216477, "timer/dataset_train_avg": 0.0001054457836997387, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0005731582641601562, "timer/agent.train_count": 1465.0, "timer/agent.train_total": 636.080442905426, "timer/agent.train_frac": 0.6233337907210648, "timer/agent.train_avg": 0.4341846026658198, "timer/agent.train_min": 0.4214212894439697, "timer/agent.train_max": 1.3842437267303467, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.480668306350708, "timer/agent.report_frac": 0.0004710360156783009, "timer/agent.report_avg": 0.240334153175354, "timer/agent.report_min": 0.23215246200561523, "timer/agent.report_max": 0.24851584434509277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.482269287109375e-05, "timer/dataset_eval_frac": 4.392447428511652e-08, "timer/dataset_eval_avg": 4.482269287109375e-05, "timer/dataset_eval_min": 4.482269287109375e-05, "timer/dataset_eval_max": 4.482269287109375e-05, "fps": 22.969974587224996}
{"step": 870416, "time": 38419.29486680031, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 870632, "time": 38428.19206619263, "episode/length": 241.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 870648, "time": 38430.732927560806, "episode/length": 109.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 870672, "time": 38434.02191877365, "episode/length": 258.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 870992, "time": 38446.29381561279, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 871128, "time": 38451.97608470917, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 871536, "time": 38466.9622130394, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 871600, "time": 38470.4411046505, "episode/length": 336.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 871744, "time": 38476.58235287666, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 872168, "time": 38491.55622410774, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 872400, "time": 38500.81188249588, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 872496, "time": 38505.472232580185, "episode/length": 232.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 872896, "time": 38519.863901376724, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 873136, "time": 38529.06736397743, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 873136, "time": 38529.073642492294, "episode/length": 91.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 873336, "time": 38538.586218357086, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 873496, "time": 38545.31095409393, "episode/length": 218.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 873672, "time": 38552.590297460556, "episode/length": 146.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 873824, "time": 38559.26460814476, "episode/length": 336.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9821958456973294, "episode/intrinsic_return": 0.0}
{"step": 873880, "time": 38562.3564620018, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 874168, "time": 38573.01762723923, "episode/length": 128.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 874536, "time": 38586.318801641464, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 874576, "time": 38589.29912209511, "episode/length": 134.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 874856, "time": 38599.51012516022, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 874984, "time": 38605.1216211319, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 875224, "time": 38614.524154901505, "episode/length": 260.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 875440, "time": 38623.89732861519, "episode/length": 56.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 875576, "time": 38630.23484015465, "episode/length": 211.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 876480, "time": 38661.538836956024, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 876960, "time": 38680.06137275696, "episode/length": 189.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 877016, "time": 38683.20090126991, "episode/length": 269.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 877088, "time": 38687.21656560898, "episode/length": 313.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 877416, "time": 38699.0495967865, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 877800, "time": 38712.92508435249, "episode/length": 277.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 877816, "time": 38714.9666697979, "episode/length": 409.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 878192, "time": 38728.81075644493, "episode/length": 545.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 878528, "time": 38741.11863183975, "episode/length": 179.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 878576, "time": 38744.18617987633, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 878640, "time": 38747.764171123505, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 878992, "time": 38760.75867724419, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 879320, "time": 38772.77437186241, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 879584, "time": 38782.92465424538, "episode/length": 327.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 879640, "time": 38786.040241241455, "episode/length": 227.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 879920, "time": 38796.93228316307, "episode/length": 167.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 38821.761620521545, "eval_episode/length": 148.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 880048, "time": 38823.59388780594, "eval_episode/length": 153.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 880048, "time": 38825.23782944679, "eval_episode/length": 155.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 880048, "time": 38827.02295255661, "eval_episode/length": 162.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 880048, "time": 38829.64072012901, "eval_episode/length": 187.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 880048, "time": 38831.285361766815, "eval_episode/length": 191.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 880048, "time": 38835.125682115555, "eval_episode/length": 244.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 880048, "time": 38839.26119685173, "eval_episode/length": 148.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 880352, "time": 38849.26035928726, "episode/length": 213.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 880560, "time": 38857.45344352722, "episode/length": 295.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 880664, "time": 38862.134350299835, "episode/length": 208.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 881024, "time": 38875.46310210228, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 881224, "time": 38883.330226659775, "episode/length": 336.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 881384, "time": 38889.98479652405, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 881680, "time": 38901.265456199646, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 881776, "time": 38905.97616958618, "episode/length": 231.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 881800, "time": 38908.089309215546, "episode/length": 276.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 881904, "time": 38913.31842494011, "episode/length": 154.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 881944, "time": 38915.93152999878, "episode/length": 172.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 882368, "time": 38931.22528839111, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 882608, "time": 38940.54860162735, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 883008, "time": 38954.990414619446, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 883104, "time": 38960.094673633575, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 883256, "time": 38966.46427297592, "episode/length": 181.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 883544, "time": 38977.30089855194, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 883624, "time": 38981.35896849632, "episode/length": 242.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 883896, "time": 38991.661558389664, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 884416, "time": 39010.23719334602, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 884424, "time": 39011.72829127312, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 884816, "time": 39027.63464164734, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 885312, "time": 39045.158046245575, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 885352, "time": 39047.93812608719, "episode/length": 280.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 885576, "time": 39056.67013502121, "episode/length": 144.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 885656, "time": 39060.69988632202, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 885928, "time": 39070.987494945526, "episode/length": 71.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 885992, "time": 39074.49054336548, "episode/length": 422.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 886008, "time": 39076.495418310165, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 886144, "time": 39082.676000118256, "episode/length": 280.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 886496, "time": 39095.606721401215, "episode/length": 104.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 886704, "time": 39103.72010469437, "episode/length": 284.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 887024, "time": 39115.4993596077, "episode/length": 128.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 887592, "time": 39135.16907143593, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 887696, "time": 39140.28020477295, "episode/length": 210.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 887840, "time": 39146.47578191757, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 888000, "time": 39153.235604286194, "episode/length": 161.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 888528, "time": 39171.61700630188, "episode/length": 297.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 888624, "time": 39176.7946062088, "episode/length": 380.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989501312335958, "episode/intrinsic_return": 0.0}
{"step": 888960, "time": 39190.090869903564, "episode/length": 307.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 889544, "time": 39210.06352972984, "episode/length": 192.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 889856, "time": 39221.99167704582, "episode/length": 282.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 889936, "time": 39226.185077667236, "episode/length": 279.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 39245.902059316635, "eval_episode/length": 65.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 890032, "time": 39253.72183084488, "eval_episode/length": 181.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 890032, "time": 39256.98308610916, "eval_episode/length": 223.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 890032, "time": 39259.08301091194, "eval_episode/length": 235.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 890032, "time": 39260.58573842049, "eval_episode/length": 236.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 890032, "time": 39262.209196805954, "eval_episode/length": 237.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9747899159663865}
{"step": 890032, "time": 39267.15470790863, "eval_episode/length": 320.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9844236760124611}
{"step": 890032, "time": 39269.29044651985, "eval_episode/length": 336.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9881305637982196}
{"step": 890040, "time": 39269.33746147156, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 890256, "time": 39277.99536180496, "episode/length": 215.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 890288, "time": 39280.62145662308, "episode/length": 407.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9877450980392157, "episode/intrinsic_return": 0.0}
{"step": 890304, "time": 39282.6580517292, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 890464, "time": 39289.234456300735, "episode/length": 327.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9786585365853658, "episode/intrinsic_return": 0.0}
{"step": 890592, "time": 39294.810411691666, "episode/length": 130.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 891432, "time": 39323.10526871681, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 891624, "time": 39331.0604698658, "episode/length": 144.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 891656, "time": 39333.777366399765, "episode/length": 168.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 891776, "time": 39339.46964621544, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 891976, "time": 39347.265036821365, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 891976, "time": 39347.27383375168, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 891992, "time": 39350.943590164185, "episode/length": 212.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 892112, "time": 39356.550703048706, "episode/length": 60.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 893160, "time": 39393.08566188812, "episode/length": 389.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 893529, "time": 39407.55438089371, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.448363003665453, "train/action_min": 0.0, "train/action_std": 3.359133537501505, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03317104795411842, "train/actor_opt_grad_steps": 55015.0, "train/actor_opt_loss": -11.208872615882795, "train/adv_mag": 0.4666556958874611, "train/adv_max": 0.41382287932585365, "train/adv_mean": 0.0016435066249261756, "train/adv_min": -0.39498898182829767, "train/adv_std": 0.05018801997377448, "train/cont_avg": 0.9949165239726028, "train/cont_loss_mean": 0.00022416951291971213, "train/cont_loss_std": 0.006247198785122151, "train/cont_neg_acc": 0.9953940893041676, "train/cont_neg_loss": 0.015185927853561789, "train/cont_pos_acc": 0.9999663429717495, "train/cont_pos_loss": 0.00013922885121231713, "train/cont_pred": 0.9949099441913709, "train/cont_rate": 0.9949165239726028, "train/dyn_loss_mean": 12.83935501150889, "train/dyn_loss_std": 9.47050824883866, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8627579440809277, "train/extr_critic_critic_opt_grad_steps": 55015.0, "train/extr_critic_critic_opt_loss": 15403.785370291096, "train/extr_critic_mag": 8.158879302952387, "train/extr_critic_max": 8.158879302952387, "train/extr_critic_mean": 2.2851477624618846, "train/extr_critic_min": -0.2281263535969878, "train/extr_critic_std": 1.921086014950112, "train/extr_return_normed_mag": 1.5191158113414294, "train/extr_return_normed_max": 1.5191158113414294, "train/extr_return_normed_mean": 0.3723036998959437, "train/extr_return_normed_min": -0.09745211501235831, "train/extr_return_normed_std": 0.3190107893658011, "train/extr_return_rate": 0.7962971309276476, "train/extr_return_raw_mag": 9.292152848962235, "train/extr_return_raw_max": 9.292152848962235, "train/extr_return_raw_mean": 2.2951437569644355, "train/extr_return_raw_min": -0.5712941817633094, "train/extr_return_raw_std": 1.9465413101731914, "train/extr_reward_mag": 1.039715827327885, "train/extr_reward_max": 1.039715827327885, "train/extr_reward_mean": 0.04181171681936065, "train/extr_reward_min": -0.46195530483167463, "train/extr_reward_std": 0.19107363679229397, "train/image_loss_mean": 6.317788796882107, "train/image_loss_std": 11.400457542236538, "train/model_loss_mean": 14.07700803835098, "train/model_loss_std": 15.309752464294434, "train/model_opt_grad_norm": 57.568249206020404, "train/model_opt_grad_steps": 54962.66438356164, "train/model_opt_loss": 17596.26007999786, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.56173381413499, "train/policy_entropy_max": 2.56173381413499, "train/policy_entropy_mean": 0.5996833243598677, "train/policy_entropy_min": 0.07937502570144117, "train/policy_entropy_std": 0.731838632936347, "train/policy_logprob_mag": 7.438383840534785, "train/policy_logprob_max": -0.009455658374226664, "train/policy_logprob_mean": -0.6014753606629698, "train/policy_logprob_min": -7.438383840534785, "train/policy_logprob_std": 1.1420338362047118, "train/policy_randomness_mag": 0.9041796187831931, "train/policy_randomness_max": 0.9041796187831931, "train/policy_randomness_mean": 0.21166189790588535, "train/policy_randomness_min": 0.028015900773238647, "train/policy_randomness_std": 0.2583069201201609, "train/post_ent_mag": 60.3889081510779, "train/post_ent_max": 60.3889081510779, "train/post_ent_mean": 43.63533806474241, "train/post_ent_min": 20.161595344543457, "train/post_ent_std": 7.822623380242962, "train/prior_ent_mag": 70.04703579210255, "train/prior_ent_max": 70.04703579210255, "train/prior_ent_mean": 56.5377746477519, "train/prior_ent_min": 39.12457588927386, "train/prior_ent_std": 5.005738277957864, "train/rep_loss_mean": 12.83935501150889, "train/rep_loss_std": 9.47050824883866, "train/reward_avg": 0.028718294952166816, "train/reward_loss_mean": 0.05538217140336151, "train/reward_loss_std": 0.24609514948439926, "train/reward_max_data": 1.0246575401253897, "train/reward_max_pred": 1.015672063174313, "train/reward_neg_acc": 0.9924944524895655, "train/reward_neg_loss": 0.02914865684937941, "train/reward_pos_acc": 0.9739360748088524, "train/reward_pos_loss": 0.8235651626162332, "train/reward_pred": 0.028134213128981934, "train/reward_rate": 0.03313623715753425, "train_stats/sum_log_reward": 8.658823723886528, "train_stats/max_log_achievement_collect_coal": 0.7549019607843137, "train_stats/max_log_achievement_collect_drink": 4.088235294117647, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.5980392156862746, "train_stats/max_log_achievement_collect_stone": 18.53921568627451, "train_stats/max_log_achievement_collect_wood": 8.588235294117647, "train_stats/max_log_achievement_defeat_skeleton": 0.049019607843137254, "train_stats/max_log_achievement_defeat_zombie": 0.7156862745098039, "train_stats/max_log_achievement_eat_cow": 0.0392156862745098, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7352941176470589, "train_stats/max_log_achievement_make_wood_sword": 0.00980392156862745, "train_stats/max_log_achievement_place_furnace": 0.37254901960784315, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 14.343137254901961, "train_stats/max_log_achievement_place_table": 2.4019607843137254, "train_stats/max_log_achievement_wake_up": 1.3627450980392157, "train_stats/mean_log_entropy": 0.40334854041244467, "eval_stats/sum_log_reward": 8.725000321865082, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 4.6875, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 12.6875, "eval_stats/max_log_achievement_collect_wood": 7.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.375, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 8.0, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.001421168795786798, "report/cont_loss_std": 0.04491695016622543, "report/cont_neg_acc": 0.6666666865348816, "report/cont_neg_loss": 0.4822169244289398, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.44844453240512e-06, "report/cont_pred": 0.9978151321411133, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.61227035522461, "report/dyn_loss_std": 9.64065170288086, "report/image_loss_mean": 6.608608245849609, "report/image_loss_std": 15.008617401123047, "report/model_loss_mean": 14.230253219604492, "report/model_loss_std": 18.844236373901367, "report/post_ent_mag": 61.76410675048828, "report/post_ent_max": 61.76410675048828, "report/post_ent_mean": 43.16880798339844, "report/post_ent_min": 22.609973907470703, "report/post_ent_std": 7.250709533691406, "report/prior_ent_mag": 70.47632598876953, "report/prior_ent_max": 70.47632598876953, "report/prior_ent_mean": 56.223628997802734, "report/prior_ent_min": 42.72713088989258, "report/prior_ent_std": 5.072595596313477, "report/rep_loss_mean": 12.61227035522461, "report/rep_loss_std": 9.64065170288086, "report/reward_avg": 0.02988281100988388, "report/reward_loss_mean": 0.05286136642098427, "report/reward_loss_std": 0.2142181545495987, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001086950302124, "report/reward_neg_acc": 0.9909090399742126, "report/reward_neg_loss": 0.027570776641368866, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.789263904094696, "report/reward_pred": 0.028753425925970078, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.47850353945978e-05, "eval/cont_loss_std": 0.0019281909335404634, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.025506123900413513, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.023199716764793e-08, "eval/cont_pred": 0.9971432089805603, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.735862731933594, "eval/dyn_loss_std": 10.826151847839355, "eval/image_loss_mean": 12.714714050292969, "eval/image_loss_std": 17.376773834228516, "eval/model_loss_mean": 22.826425552368164, "eval/model_loss_std": 21.577659606933594, "eval/post_ent_mag": 59.26294708251953, "eval/post_ent_max": 59.26294708251953, "eval/post_ent_mean": 42.03680419921875, "eval/post_ent_min": 18.792964935302734, "eval/post_ent_std": 8.177265167236328, "eval/prior_ent_mag": 69.7279052734375, "eval/prior_ent_max": 69.7279052734375, "eval/prior_ent_mean": 57.20286560058594, "eval/prior_ent_min": 40.541751861572266, "eval/prior_ent_std": 4.818281173706055, "eval/rep_loss_mean": 16.735862731933594, "eval/rep_loss_std": 10.826151847839355, "eval/reward_avg": 0.02177734300494194, "eval/reward_loss_mean": 0.07012002915143967, "eval/reward_loss_std": 0.43660828471183777, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023176670074463, "eval/reward_neg_acc": 0.9899899959564209, "eval/reward_neg_loss": 0.024968411773443222, "eval/reward_pos_acc": 0.7599999904632568, "eval/reward_pos_loss": 1.8743784427642822, "eval/reward_pred": 0.01479581743478775, "eval/reward_rate": 0.0244140625, "replay/size": 893025.0, "replay/inserts": 23464.0, "replay/samples": 23472.0, "replay/insert_wait_avg": 1.3104994631122495e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.773896180291361e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5136.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.152588570972098e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1983096599579, "timer/env.step_count": 2933.0, "timer/env.step_total": 238.51350927352905, "timer/env.step_frac": 0.2384662191187042, "timer/env.step_avg": 0.08132066460058952, "timer/env.step_min": 0.02308344841003418, "timer/env.step_max": 3.330033779144287, "timer/replay._sample_count": 23472.0, "timer/replay._sample_total": 11.88533902168274, "timer/replay._sample_frac": 0.011882982511461606, "timer/replay._sample_avg": 0.0005063624327574446, "timer/replay._sample_min": 0.00040721893310546875, "timer/replay._sample_max": 0.010860443115234375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3575.0, "timer/agent.policy_total": 55.26174521446228, "timer/agent.policy_frac": 0.05525078844939248, "timer/agent.policy_avg": 0.015457830829220219, "timer/agent.policy_min": 0.008508920669555664, "timer/agent.policy_max": 0.10439491271972656, "timer/dataset_train_count": 1467.0, "timer/dataset_train_total": 0.15616774559020996, "timer/dataset_train_frac": 0.00015613678215803327, "timer/dataset_train_avg": 0.00010645381430825492, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0006282329559326172, "timer/agent.train_count": 1467.0, "timer/agent.train_total": 636.8871397972107, "timer/agent.train_frac": 0.636760863966803, "timer/agent.train_avg": 0.43414256291561737, "timer/agent.train_min": 0.42069458961486816, "timer/agent.train_max": 1.362633466720581, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47986483573913574, "timer/agent.report_frac": 0.0004797696927745035, "timer/agent.report_avg": 0.23993241786956787, "timer/agent.report_min": 0.2329871654510498, "timer/agent.report_max": 0.24687767028808594, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7651071701154723e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 23.45904054554026}
{"step": 893592, "time": 39409.3621468544, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 893840, "time": 39419.07297182083, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 893968, "time": 39424.82965874672, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 894872, "time": 39455.255642175674, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 894888, "time": 39457.35370564461, "episode/length": 363.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9917582417582418, "episode/intrinsic_return": 0.0}
{"step": 895216, "time": 39469.64781332016, "episode/length": 429.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 895272, "time": 39472.725680828094, "episode/length": 411.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 895424, "time": 39479.301448106766, "episode/length": 428.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 895632, "time": 39487.68552350998, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 895816, "time": 39494.97071456909, "episode/length": 277.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 896264, "time": 39510.81580853462, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 896416, "time": 39517.58199548721, "episode/length": 321.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 896736, "time": 39529.4176568985, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 897048, "time": 39540.80214071274, "episode/length": 176.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 897112, "time": 39544.52406525612, "episode/length": 161.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 897120, "time": 39546.42883372307, "episode/length": 280.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 897544, "time": 39561.28699302673, "episode/length": 264.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 897928, "time": 39575.10407662392, "episode/length": 148.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 898056, "time": 39580.75202488899, "episode/length": 204.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 898160, "time": 39585.792112112045, "episode/length": 236.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 898784, "time": 39607.62487530708, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 898856, "time": 39611.8047041893, "episode/length": 447.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799107142857143, "episode/intrinsic_return": 0.0}
{"step": 898992, "time": 39617.90615773201, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 899624, "time": 39639.52850604057, "episode/length": 182.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 899704, "time": 39643.66766452789, "episode/length": 221.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 899888, "time": 39651.360756874084, "episode/length": 137.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 899912, "time": 39653.3955283165, "episode/length": 357.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9860335195530726, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 39678.47531247139, "eval_episode/length": 165.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 900016, "time": 39681.63881611824, "eval_episode/length": 189.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 900016, "time": 39683.39523434639, "eval_episode/length": 192.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 900016, "time": 39685.282594680786, "eval_episode/length": 201.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 900016, "time": 39687.7300157547, "eval_episode/length": 224.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 900016, "time": 39689.87845301628, "eval_episode/length": 237.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 900016, "time": 39693.973987579346, "eval_episode/length": 298.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9899665551839465}
{"step": 900016, "time": 39696.93563938141, "eval_episode/length": 132.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 900072, "time": 39698.520089149475, "episode/length": 151.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 900208, "time": 39704.59374952316, "episode/length": 386.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9896640826873385, "episode/intrinsic_return": 0.0}
{"step": 900320, "time": 39709.67969942093, "episode/length": 282.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717314487632509, "episode/intrinsic_return": 0.0}
{"step": 900648, "time": 39721.61339735985, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 900816, "time": 39728.658331394196, "episode/length": 115.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 901240, "time": 39745.2952709198, "episode/length": 165.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 901376, "time": 39751.49613928795, "episode/length": 218.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 901416, "time": 39754.14057421684, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 901736, "time": 39765.90061545372, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 902424, "time": 39789.74488425255, "episode/length": 276.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 902488, "time": 39793.39312171936, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 902552, "time": 39796.99000453949, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 902672, "time": 39802.6324672699, "episode/length": 156.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 902776, "time": 39807.19111728668, "episode/length": 265.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 902936, "time": 39814.0882627964, "episode/length": 211.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 903312, "time": 39828.01060009003, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 903800, "time": 39845.1342022419, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 903992, "time": 39852.750586509705, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 904120, "time": 39858.39733219147, "episode/length": 167.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 904336, "time": 39867.10370516777, "episode/length": 222.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 904368, "time": 39869.66488575935, "episode/length": 234.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 905168, "time": 39897.32610321045, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854227405247813, "episode/intrinsic_return": 0.0}
{"step": 905256, "time": 39901.51702785492, "episode/length": 141.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 905656, "time": 39915.90843319893, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 905952, "time": 39927.00860095024, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 906384, "time": 39942.46170425415, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 906432, "time": 39945.62617564201, "episode/length": 389.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 906456, "time": 39947.64912438393, "episode/length": 439.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 907296, "time": 39976.39357328415, "episode/length": 254.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 907376, "time": 39980.516531705856, "episode/length": 446.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9977628635346756, "episode/intrinsic_return": 0.0}
{"step": 907512, "time": 39986.12520265579, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 908048, "time": 40005.30989122391, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 908168, "time": 40010.42454099655, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 908328, "time": 40017.10838723183, "episode/length": 394.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 908512, "time": 40024.799569129944, "episode/length": 356.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9859943977591037, "episode/intrinsic_return": 0.0}
{"step": 908896, "time": 40038.708426237106, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 908936, "time": 40041.34312605858, "episode/length": 177.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 909056, "time": 40046.874287843704, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 909080, "time": 40049.02339529991, "episode/length": 327.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 909256, "time": 40056.383907318115, "episode/length": 135.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 909416, "time": 40064.5599565506, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 909472, "time": 40068.16277050972, "episode/length": 48.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 909528, "time": 40071.3102517128, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 909800, "time": 40081.772857666016, "episode/length": 47.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 909880, "time": 40085.87926149368, "episode/length": 50.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 40109.587215662, "eval_episode/length": 132.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 910000, "time": 40113.02623581886, "eval_episode/length": 174.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 910000, "time": 40115.38990831375, "eval_episode/length": 194.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 910000, "time": 40117.73741483688, "eval_episode/length": 213.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 910000, "time": 40120.93052792549, "eval_episode/length": 256.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 910000, "time": 40124.92484474182, "eval_episode/length": 315.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9968354430379747}
{"step": 910000, "time": 40127.914998054504, "eval_episode/length": 350.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9857549857549858}
{"step": 910000, "time": 40130.59554743767, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 910280, "time": 40139.37193965912, "episode/length": 243.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 910392, "time": 40144.59414553642, "episode/length": 234.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 910448, "time": 40148.110901117325, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 911448, "time": 40181.75606632233, "episode/length": 239.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 911448, "time": 40181.76440525055, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 911736, "time": 40195.38709998131, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 911840, "time": 40200.411281347275, "episode/length": 322.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9814241486068112, "episode/intrinsic_return": 0.0}
{"step": 911952, "time": 40205.74411582947, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 912080, "time": 40211.264214515686, "episode/length": 274.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 912120, "time": 40213.843812942505, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 912416, "time": 40225.13163495064, "episode/length": 439.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 912744, "time": 40236.96552991867, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 913504, "time": 40263.4675488472, "episode/length": 256.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 913544, "time": 40266.06457281113, "episode/length": 198.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 913592, "time": 40269.06415462494, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 913672, "time": 40273.06130337715, "episode/length": 156.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 913824, "time": 40279.70345330238, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 914040, "time": 40288.03538799286, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 914120, "time": 40292.31319594383, "episode/length": 249.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 914320, "time": 40300.9548099041, "episode/length": 101.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 914792, "time": 40317.82357311249, "episode/length": 93.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 915168, "time": 40331.700828790665, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 915264, "time": 40336.31334590912, "episode/length": 179.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 915272, "time": 40337.786553144455, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 915560, "time": 40348.67301797867, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 915776, "time": 40358.17995071411, "episode/length": 75.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 916512, "time": 40384.35929632187, "episode/length": 214.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 916648, "time": 40390.08443450928, "episode/length": 315.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 916808, "time": 40396.74876379967, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 916880, "time": 40400.852061510086, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 916896, "time": 40402.924324035645, "episode/length": 321.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 916977, "time": 40407.5889377594, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.515402865247662, "train/action_min": 0.0, "train/action_std": 3.317476593718237, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03373993317387542, "train/actor_opt_grad_steps": 56480.0, "train/actor_opt_loss": -5.906330683097547, "train/adv_mag": 0.4653847361503004, "train/adv_max": 0.43253894809151994, "train/adv_mean": 0.0024369360953038935, "train/adv_min": -0.3650737651148621, "train/adv_std": 0.05071965126054628, "train/cont_avg": 0.9950108949829932, "train/cont_loss_mean": 0.00017723346820343823, "train/cont_loss_std": 0.005103694297671529, "train/cont_neg_acc": 0.9926369871995221, "train/cont_neg_loss": 0.0179629654328219, "train/cont_pos_acc": 0.9999865865220829, "train/cont_pos_loss": 8.266792582810351e-05, "train/cont_pred": 0.9950274723727687, "train/cont_rate": 0.9950108949829932, "train/dyn_loss_mean": 12.887318195939875, "train/dyn_loss_std": 9.466249641107053, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8858228483978583, "train/extr_critic_critic_opt_grad_steps": 56480.0, "train/extr_critic_critic_opt_loss": 15644.305345184948, "train/extr_critic_mag": 8.092016479595989, "train/extr_critic_max": 8.092016479595989, "train/extr_critic_mean": 2.208904589114546, "train/extr_critic_min": -0.21887077604021346, "train/extr_critic_std": 1.8937233751322948, "train/extr_return_normed_mag": 1.5175479236914187, "train/extr_return_normed_max": 1.5175479236914187, "train/extr_return_normed_mean": 0.3685616777867687, "train/extr_return_normed_min": -0.08649638793146124, "train/extr_return_normed_std": 0.31768106613434904, "train/extr_return_rate": 0.7837634143375215, "train/extr_return_raw_mag": 9.17423914565521, "train/extr_return_raw_max": 9.17423914565521, "train/extr_return_raw_mean": 2.2236287164039354, "train/extr_return_raw_min": -0.529528385927888, "train/extr_return_raw_std": 1.922267921927835, "train/extr_reward_mag": 1.0405100251541657, "train/extr_reward_max": 1.0405100251541657, "train/extr_reward_mean": 0.04166050340194686, "train/extr_reward_min": -0.43184413634189944, "train/extr_reward_std": 0.1908265046116446, "train/image_loss_mean": 6.3593155056440915, "train/image_loss_std": 11.620324138070451, "train/model_loss_mean": 14.147404274972928, "train/model_loss_std": 15.521535860437925, "train/model_opt_grad_norm": 52.34723156001292, "train/model_opt_grad_steps": 56426.37414965987, "train/model_opt_loss": 18152.50868276998, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1284.0136054421769, "train/policy_entropy_mag": 2.55471454996641, "train/policy_entropy_max": 2.55471454996641, "train/policy_entropy_mean": 0.5881022109466345, "train/policy_entropy_min": 0.07937503271565145, "train/policy_entropy_std": 0.7164647360237277, "train/policy_logprob_mag": 7.4383837738815615, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5886158687727792, "train/policy_logprob_min": -7.4383837738815615, "train/policy_logprob_std": 1.130875022232938, "train/policy_randomness_mag": 0.9017021254617341, "train/policy_randomness_max": 0.9017021254617341, "train/policy_randomness_mean": 0.20757427537927822, "train/policy_randomness_min": 0.028015903241577603, "train/policy_randomness_std": 0.2528806095626078, "train/post_ent_mag": 60.58455113002232, "train/post_ent_max": 60.58455113002232, "train/post_ent_mean": 43.7278180284565, "train/post_ent_min": 20.195628133760827, "train/post_ent_std": 7.835713798496999, "train/prior_ent_mag": 70.09732886074352, "train/prior_ent_max": 70.09732886074352, "train/prior_ent_mean": 56.706957810590055, "train/prior_ent_min": 39.269643277538066, "train/prior_ent_std": 5.001151539030529, "train/rep_loss_mean": 12.887318195939875, "train/rep_loss_std": 9.466249641107053, "train/reward_avg": 0.028350871303403864, "train/reward_loss_mean": 0.05552073867142606, "train/reward_loss_std": 0.24691351123002112, "train/reward_max_data": 1.01564626223376, "train/reward_max_pred": 1.0126387586399002, "train/reward_neg_acc": 0.9922565598877109, "train/reward_neg_loss": 0.028850515094287946, "train/reward_pos_acc": 0.9689154381654701, "train/reward_pos_loss": 0.8429474177814665, "train/reward_pred": 0.027613259123346837, "train/reward_rate": 0.032884247448979595, "train_stats/sum_log_reward": 8.828155517578125, "train_stats/max_log_achievement_collect_coal": 0.8349514563106796, "train_stats/max_log_achievement_collect_drink": 4.242718446601942, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.3689320388349515, "train_stats/max_log_achievement_collect_stone": 13.990291262135923, "train_stats/max_log_achievement_collect_wood": 8.631067961165048, "train_stats/max_log_achievement_defeat_skeleton": 0.038834951456310676, "train_stats/max_log_achievement_defeat_zombie": 0.7184466019417476, "train_stats/max_log_achievement_eat_cow": 0.06796116504854369, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0097087378640777, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 0.7184466019417476, "train_stats/max_log_achievement_place_plant": 1.3398058252427185, "train_stats/max_log_achievement_place_stone": 9.524271844660195, "train_stats/max_log_achievement_place_table": 2.5533980582524274, "train_stats/max_log_achievement_wake_up": 1.5145631067961165, "train_stats/mean_log_entropy": 0.403757815583817, "eval_stats/sum_log_reward": 9.287500351667404, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 15.0625, "eval_stats/max_log_achievement_collect_wood": 8.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.4375, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 12.0, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 7.30570309315226e-06, "report/cont_loss_std": 3.2735842978581786e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00021515342814382166, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.694984676869353e-06, "report/cont_pred": 0.9970642328262329, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.281034469604492, "report/dyn_loss_std": 9.120251655578613, "report/image_loss_mean": 5.1283979415893555, "report/image_loss_std": 9.189384460449219, "report/model_loss_mean": 12.55029582977295, "report/model_loss_std": 13.125330924987793, "report/post_ent_mag": 60.701904296875, "report/post_ent_max": 60.701904296875, "report/post_ent_mean": 45.16267395019531, "report/post_ent_min": 18.952119827270508, "report/post_ent_std": 7.895968437194824, "report/prior_ent_mag": 70.38631439208984, "report/prior_ent_max": 70.38631439208984, "report/prior_ent_mean": 57.70966339111328, "report/prior_ent_min": 42.221412658691406, "report/prior_ent_std": 4.960973739624023, "report/rep_loss_mean": 12.281034469604492, "report/rep_loss_std": 9.120251655578613, "report/reward_avg": 0.02412109449505806, "report/reward_loss_mean": 0.053269609808921814, "report/reward_loss_std": 0.22060050070285797, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0012388229370117, "report/reward_neg_acc": 0.9859438538551331, "report/reward_neg_loss": 0.03460214287042618, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7172982096672058, "report/reward_pred": 0.026322459802031517, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0030867699533700943, "eval/cont_loss_std": 0.0978420078754425, "eval/cont_neg_acc": 0.6666666865348816, "eval/cont_neg_loss": 1.0464904308319092, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0941140974173322e-05, "eval/cont_pred": 0.9979902505874634, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.50572967529297, "eval/dyn_loss_std": 10.701213836669922, "eval/image_loss_mean": 11.66934871673584, "eval/image_loss_std": 16.001733779907227, "eval/model_loss_mean": 22.318796157836914, "eval/model_loss_std": 20.13747787475586, "eval/post_ent_mag": 58.376529693603516, "eval/post_ent_max": 58.376529693603516, "eval/post_ent_mean": 41.12797927856445, "eval/post_ent_min": 21.156051635742188, "eval/post_ent_std": 7.175055980682373, "eval/prior_ent_mag": 70.52790832519531, "eval/prior_ent_max": 70.52790832519531, "eval/prior_ent_mean": 56.244712829589844, "eval/prior_ent_min": 38.63298797607422, "eval/prior_ent_std": 5.133246898651123, "eval/rep_loss_mean": 17.50572967529297, "eval/rep_loss_std": 10.701213836669922, "eval/reward_avg": 0.0439453125, "eval/reward_loss_mean": 0.1429208666086197, "eval/reward_loss_std": 0.6551360487937927, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0013835430145264, "eval/reward_neg_acc": 0.9795082807540894, "eval/reward_neg_loss": 0.06460844725370407, "eval/reward_pos_acc": 0.7916666865348816, "eval/reward_pos_loss": 1.7352737188339233, "eval/reward_pred": 0.0356266014277935, "eval/reward_rate": 0.046875, "replay/size": 916473.0, "replay/inserts": 23448.0, "replay/samples": 23440.0, "replay/insert_wait_avg": 1.3209617573098085e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.866389108599249e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1567052427705351e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0216393470764, "timer/env.step_count": 2931.0, "timer/env.step_total": 236.98698258399963, "timer/env.step_frac": 0.23698185445140035, "timer/env.step_avg": 0.0808553335325826, "timer/env.step_min": 0.022836685180664062, "timer/env.step_max": 4.23141622543335, "timer/replay._sample_count": 23440.0, "timer/replay._sample_total": 11.806147575378418, "timer/replay._sample_frac": 0.011805892103581642, "timer/replay._sample_avg": 0.0005036752378574411, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.009666204452514648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3646.0, "timer/agent.policy_total": 54.72016096115112, "timer/agent.policy_frac": 0.05471897687821879, "timer/agent.policy_avg": 0.015008272342608646, "timer/agent.policy_min": 0.008359909057617188, "timer/agent.policy_max": 0.09546637535095215, "timer/dataset_train_count": 1465.0, "timer/dataset_train_total": 0.1553502082824707, "timer/dataset_train_frac": 0.00015534684667813822, "timer/dataset_train_avg": 0.00010604109780373426, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0003292560577392578, "timer/agent.train_count": 1465.0, "timer/agent.train_total": 636.2157371044159, "timer/agent.train_frac": 0.636201970109174, "timer/agent.train_avg": 0.4342769536548914, "timer/agent.train_min": 0.42361950874328613, "timer/agent.train_max": 1.3463478088378906, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48046231269836426, "timer/agent.report_frac": 0.0004804519160325997, "timer/agent.report_avg": 0.24023115634918213, "timer/agent.report_min": 0.23361706733703613, "timer/agent.report_max": 0.24684524536132812, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 0.00011014938354492188, "timer/dataset_eval_frac": 1.1014700003575867e-07, "timer/dataset_eval_avg": 0.00011014938354492188, "timer/dataset_eval_min": 0.00011014938354492188, "timer/dataset_eval_max": 0.00011014938354492188, "fps": 23.44717957590233}
{"step": 917112, "time": 40411.99232816696, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 917512, "time": 40426.57119703293, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 918344, "time": 40456.62345838547, "episode/length": 384.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9896103896103896, "episode/intrinsic_return": 0.0}
{"step": 918560, "time": 40465.326278209686, "episode/length": 255.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 918840, "time": 40475.71969628334, "episode/length": 215.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 918864, "time": 40478.19736099243, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 919080, "time": 40486.356604099274, "episode/length": 303.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 919128, "time": 40489.57850432396, "episode/length": 201.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 919144, "time": 40491.626600027084, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 919488, "time": 40504.5432536602, "episode/length": 323.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783950617283951, "episode/intrinsic_return": 0.0}
{"step": 919848, "time": 40517.3855278492, "episode/length": 187.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 40543.069759607315, "eval_episode/length": 61.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 920088, "time": 40549.95411038399, "eval_episode/length": 173.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 920088, "time": 40551.82980418205, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 920088, "time": 40554.16175484657, "eval_episode/length": 202.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 920088, "time": 40556.361859321594, "eval_episode/length": 218.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9954337899543378}
{"step": 920088, "time": 40559.30549240112, "eval_episode/length": 194.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 920088, "time": 40563.059708595276, "eval_episode/length": 51.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 920088, "time": 40565.379737615585, "eval_episode/length": 154.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 920248, "time": 40570.50175189972, "episode/length": 137.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 920360, "time": 40575.69211983681, "episode/length": 153.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 920936, "time": 40595.890144348145, "episode/length": 180.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 921224, "time": 40606.574321746826, "episode/length": 121.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9426229508196722, "episode/intrinsic_return": 0.0}
{"step": 921384, "time": 40613.14573407173, "episode/length": 314.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 922072, "time": 40636.70257949829, "episode/length": 277.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 922136, "time": 40640.25677084923, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 922280, "time": 40646.36430668831, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 922688, "time": 40661.253702163696, "episode/length": 450.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977827050997783, "episode/intrinsic_return": 0.0}
{"step": 922752, "time": 40664.85369706154, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 922784, "time": 40667.41190934181, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 923208, "time": 40682.31092953682, "episode/length": 227.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 923528, "time": 40694.18807005882, "episode/length": 173.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 923840, "time": 40705.99669647217, "episode/length": 220.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 924176, "time": 40718.42932724953, "episode/length": 236.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 924296, "time": 40723.611889600754, "episode/length": 192.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 924448, "time": 40730.12704229355, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 924544, "time": 40734.70436787605, "episode/length": 747.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 924672, "time": 40740.39534711838, "episode/length": 61.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 925104, "time": 40755.97265982628, "episode/length": 236.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 925112, "time": 40757.574942827225, "episode/length": 290.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759450171821306, "episode/intrinsic_return": 0.0}
{"step": 925384, "time": 40767.83255434036, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 926064, "time": 40793.22024846077, "episode/length": 189.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 926128, "time": 40796.8077609539, "episode/length": 181.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 926560, "time": 40812.45524811745, "episode/length": 378.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 927024, "time": 40828.9329533577, "episode/length": 321.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 927136, "time": 40834.06909418106, "episode/length": 133.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 927512, "time": 40847.65717101097, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 927888, "time": 40861.66481423378, "episode/length": 219.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 927936, "time": 40864.689442873, "episode/length": 352.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886685552407932, "episode/intrinsic_return": 0.0}
{"step": 928040, "time": 40869.29680395126, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 928248, "time": 40877.454994916916, "episode/length": 392.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 928464, "time": 40886.10728740692, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 928840, "time": 40899.925629377365, "episode/length": 212.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 928840, "time": 40899.93630170822, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 928920, "time": 40905.70739340782, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 929216, "time": 40916.86523294449, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 929392, "time": 40924.10427904129, "episode/length": 68.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 929848, "time": 40940.18180537224, "episode/length": 172.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 929856, "time": 40942.22971868515, "episode/length": 200.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 930008, "time": 40948.34853887558, "episode/length": 258.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 40969.54435300827, "eval_episode/length": 118.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9915966386554622}
{"step": 930072, "time": 40974.08234500885, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 930072, "time": 40977.896710157394, "eval_episode/length": 242.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 930072, "time": 40980.08588933945, "eval_episode/length": 257.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9961240310077519}
{"step": 930072, "time": 40982.962226867676, "eval_episode/length": 286.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9965156794425087}
{"step": 930072, "time": 40985.02868938446, "eval_episode/length": 300.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.973421926910299}
{"step": 930072, "time": 40986.95473456383, "eval_episode/length": 313.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9968152866242038}
{"step": 930072, "time": 40988.493740320206, "eval_episode/length": 56.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 930320, "time": 40996.69870042801, "episode/length": 284.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 930400, "time": 41000.70655083656, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 930592, "time": 41008.48723602295, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 931672, "time": 41044.66191196442, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 931816, "time": 41050.82645058632, "episode/length": 302.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 932120, "time": 41062.09807872772, "episode/length": 362.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9889807162534435, "episode/intrinsic_return": 0.0}
{"step": 932120, "time": 41062.106385707855, "episode/length": 214.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 932136, "time": 41065.8877491951, "episode/length": 192.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 932160, "time": 41068.45040345192, "episode/length": 229.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 932560, "time": 41082.73613238335, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780564263322884, "episode/intrinsic_return": 0.0}
{"step": 932632, "time": 41086.428698539734, "episode/length": 346.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 932888, "time": 41096.33801484108, "episode/length": 133.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 932912, "time": 41098.90008401871, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 933488, "time": 41118.88916182518, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 933544, "time": 41121.90752887726, "episode/length": 122.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 933744, "time": 41130.024316072464, "episode/length": 197.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 934072, "time": 41143.37641096115, "episode/length": 179.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 934336, "time": 41153.578797101974, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 934512, "time": 41160.75553536415, "episode/length": 54.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 934608, "time": 41165.41090512276, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 934736, "time": 41171.088384628296, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 935000, "time": 41180.86818766594, "episode/length": 357.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9916201117318436, "episode/intrinsic_return": 0.0}
{"step": 935144, "time": 41187.596979379654, "episode/length": 174.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 935264, "time": 41193.20325779915, "episode/length": 221.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 935448, "time": 41200.30190753937, "episode/length": 415.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9927884615384616, "episode/intrinsic_return": 0.0}
{"step": 936344, "time": 41230.83154344559, "episode/length": 216.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 936592, "time": 41240.63737034798, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 936656, "time": 41244.25547027588, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 936720, "time": 41247.879558086395, "episode/length": 247.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 937392, "time": 41271.15127873421, "episode/length": 381.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 937824, "time": 41286.71932888031, "episode/length": 296.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 937880, "time": 41289.82316470146, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 938112, "time": 41298.96459531784, "episode/length": 449.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 938184, "time": 41302.59400129318, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 938488, "time": 41313.93928575516, "episode/length": 267.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 938496, "time": 41315.824957847595, "episode/length": 436.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 938944, "time": 41331.68755698204, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 939352, "time": 41346.0896692276, "episode/length": 107.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 939392, "time": 41349.130007743835, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 939944, "time": 41368.10041999817, "episode/length": 219.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 41391.08407711983, "eval_episode/length": 121.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 940056, "time": 41393.87046909332, "eval_episode/length": 150.0, "eval_episode/score": 9.100000038743019, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 940056, "time": 41395.984296798706, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 940056, "time": 41398.93477368355, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 940056, "time": 41400.76006221771, "eval_episode/length": 207.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 940056, "time": 41403.56572651863, "eval_episode/length": 235.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 940056, "time": 41406.30303144455, "eval_episode/length": 55.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 940056, "time": 41409.661356925964, "eval_episode/length": 186.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 940057, "time": 41410.67946958542, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.365819719102648, "train/action_min": 0.0, "train/action_std": 3.224783402350214, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03400006079270194, "train/actor_opt_grad_steps": 57935.0, "train/actor_opt_loss": -3.778515823909806, "train/adv_mag": 0.45770546173055965, "train/adv_max": 0.4204200593133767, "train/adv_mean": 0.0033713985027993155, "train/adv_min": -0.363706902290384, "train/adv_std": 0.0520947916019294, "train/cont_avg": 0.9951985677083334, "train/cont_loss_mean": 0.0001577501237244563, "train/cont_loss_std": 0.004443024922880549, "train/cont_neg_acc": 0.9944838458764638, "train/cont_neg_loss": 0.013098599303232067, "train/cont_pos_acc": 0.9999795216653082, "train/cont_pos_loss": 8.310083179985384e-05, "train/cont_pred": 0.995195755114158, "train/cont_rate": 0.9951985677083334, "train/dyn_loss_mean": 12.833767884307438, "train/dyn_loss_std": 9.561449693308937, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9173825511501895, "train/extr_critic_critic_opt_grad_steps": 57935.0, "train/extr_critic_critic_opt_loss": 15831.635830349393, "train/extr_critic_mag": 8.209032078584036, "train/extr_critic_max": 8.209032078584036, "train/extr_critic_mean": 2.244474252065023, "train/extr_critic_min": -0.21457331462038887, "train/extr_critic_std": 1.892889139552911, "train/extr_return_normed_mag": 1.5215465443001852, "train/extr_return_normed_max": 1.5215465443001852, "train/extr_return_normed_mean": 0.3699344154447317, "train/extr_return_normed_min": -0.09010079231423636, "train/extr_return_normed_std": 0.3150064606840412, "train/extr_return_rate": 0.8020973884397082, "train/extr_return_raw_mag": 9.295164048671722, "train/extr_return_raw_max": 9.295164048671722, "train/extr_return_raw_mean": 2.265082396566868, "train/extr_return_raw_min": -0.5439364005708032, "train/extr_return_raw_std": 1.9229995922909842, "train/extr_reward_mag": 1.0455340461598501, "train/extr_reward_max": 1.0455340461598501, "train/extr_reward_mean": 0.04300624114047322, "train/extr_reward_min": -0.4663560266296069, "train/extr_reward_std": 0.1938449042952723, "train/image_loss_mean": 6.447511596812142, "train/image_loss_std": 11.804196996821297, "train/model_loss_mean": 14.203991585307651, "train/model_loss_std": 15.752863307793936, "train/model_opt_grad_norm": 56.053719109959076, "train/model_opt_grad_steps": 57879.88888888889, "train/model_opt_loss": 18893.74190266927, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1328.125, "train/policy_entropy_mag": 2.570244883497556, "train/policy_entropy_max": 2.570244883497556, "train/policy_entropy_mean": 0.5644402141786284, "train/policy_entropy_min": 0.07937503393946423, "train/policy_entropy_std": 0.6985002348406447, "train/policy_logprob_mag": 7.438383801115884, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5653362706717517, "train/policy_logprob_min": -7.438383801115884, "train/policy_logprob_std": 1.1181523998578389, "train/policy_randomness_mag": 0.9071836500532098, "train/policy_randomness_max": 0.9071836500532098, "train/policy_randomness_mean": 0.199222627406319, "train/policy_randomness_min": 0.028015903598215017, "train/policy_randomness_std": 0.24653993039909336, "train/post_ent_mag": 60.71314960055881, "train/post_ent_max": 60.71314960055881, "train/post_ent_mean": 43.72082490391202, "train/post_ent_min": 20.257737398147583, "train/post_ent_std": 7.867778725094265, "train/prior_ent_mag": 70.1740779876709, "train/prior_ent_max": 70.1740779876709, "train/prior_ent_mean": 56.62433788511488, "train/prior_ent_min": 38.70624089241028, "train/prior_ent_std": 5.104902724424998, "train/rep_loss_mean": 12.833767884307438, "train/rep_loss_std": 9.561449693308937, "train/reward_avg": 0.0287441676029832, "train/reward_loss_mean": 0.05606160799248351, "train/reward_loss_std": 0.24717331346538332, "train/reward_max_data": 1.0173611152503226, "train/reward_max_pred": 1.0115603887372546, "train/reward_neg_acc": 0.9923284616735246, "train/reward_neg_loss": 0.029055266317704484, "train/reward_pos_acc": 0.9658446150521437, "train/reward_pos_loss": 0.8443519704871707, "train/reward_pred": 0.0277930676109261, "train/reward_rate": 0.033182779947916664, "train_stats/sum_log_reward": 8.991304485694222, "train_stats/max_log_achievement_collect_coal": 0.9456521739130435, "train_stats/max_log_achievement_collect_drink": 5.608695652173913, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.358695652173913, "train_stats/max_log_achievement_collect_stone": 14.869565217391305, "train_stats/max_log_achievement_collect_wood": 9.16304347826087, "train_stats/max_log_achievement_defeat_skeleton": 0.07608695652173914, "train_stats/max_log_achievement_defeat_zombie": 0.6739130434782609, "train_stats/max_log_achievement_eat_cow": 0.08695652173913043, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.032608695652174, "train_stats/max_log_achievement_make_wood_sword": 0.010869565217391304, "train_stats/max_log_achievement_place_furnace": 1.391304347826087, "train_stats/max_log_achievement_place_plant": 1.315217391304348, "train_stats/max_log_achievement_place_stone": 7.5, "train_stats/max_log_achievement_place_table": 2.5543478260869565, "train_stats/max_log_achievement_wake_up": 1.5326086956521738, "train_stats/mean_log_entropy": 0.38191321152059926, "eval_stats/sum_log_reward": 8.058333396911621, "eval_stats/max_log_achievement_collect_coal": 0.5833333333333334, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 10.041666666666666, "eval_stats/max_log_achievement_collect_wood": 8.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.8333333333333334, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.7083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.6666666666666666, "eval_stats/max_log_achievement_place_plant": 0.9583333333333334, "eval_stats/max_log_achievement_place_stone": 5.208333333333333, "eval_stats/max_log_achievement_place_table": 2.4166666666666665, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.8139679696105304e-06, "report/cont_loss_std": 1.3018106074014213e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.2657102060038596e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.6645759615130373e-06, "report/cont_pred": 0.9970688223838806, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.3900146484375, "report/dyn_loss_std": 8.807123184204102, "report/image_loss_mean": 5.520630836486816, "report/image_loss_std": 8.479951858520508, "report/model_loss_mean": 12.994821548461914, "report/model_loss_std": 12.010645866394043, "report/post_ent_mag": 58.791481018066406, "report/post_ent_max": 58.791481018066406, "report/post_ent_mean": 44.099998474121094, "report/post_ent_min": 19.011857986450195, "report/post_ent_std": 7.704634666442871, "report/prior_ent_mag": 70.37760925292969, "report/prior_ent_max": 70.37760925292969, "report/prior_ent_mean": 56.704898834228516, "report/prior_ent_min": 42.07246398925781, "report/prior_ent_std": 4.435215473175049, "report/rep_loss_mean": 12.3900146484375, "report/rep_loss_std": 8.807123184204102, "report/reward_avg": 0.01679687574505806, "report/reward_loss_mean": 0.04018034040927887, "report/reward_loss_std": 0.16082949936389923, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002143144607544, "report/reward_neg_acc": 0.9910269379615784, "report/reward_neg_loss": 0.025370139628648758, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7475438714027405, "report/reward_pred": 0.017637643963098526, "report/reward_rate": 0.0205078125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 1.9512346625560895e-05, "eval/cont_loss_std": 0.0005681588081642985, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9512346625560895e-05, "eval/cont_pred": 0.9999806880950928, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 16.006877899169922, "eval/dyn_loss_std": 10.536436080932617, "eval/image_loss_mean": 9.964042663574219, "eval/image_loss_std": 12.90563678741455, "eval/model_loss_mean": 19.63465118408203, "eval/model_loss_std": 17.345457077026367, "eval/post_ent_mag": 60.586708068847656, "eval/post_ent_max": 60.586708068847656, "eval/post_ent_mean": 42.557762145996094, "eval/post_ent_min": 19.551013946533203, "eval/post_ent_std": 8.11762809753418, "eval/prior_ent_mag": 70.37760925292969, "eval/prior_ent_max": 70.37760925292969, "eval/prior_ent_mean": 57.20561218261719, "eval/prior_ent_min": 42.23554611206055, "eval/prior_ent_std": 4.579357624053955, "eval/rep_loss_mean": 16.006877899169922, "eval/rep_loss_std": 10.536436080932617, "eval/reward_avg": 0.03642578050494194, "eval/reward_loss_mean": 0.06646230816841125, "eval/reward_loss_std": 0.3232768476009369, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0013737678527832, "eval/reward_neg_acc": 0.9817259311676025, "eval/reward_neg_loss": 0.03330449387431145, "eval/reward_pos_acc": 0.9230769276618958, "eval/reward_pos_loss": 0.9039099216461182, "eval/reward_pred": 0.03724324703216553, "eval/reward_rate": 0.0380859375, "replay/size": 939553.0, "replay/inserts": 23080.0, "replay/samples": 23088.0, "replay/insert_wait_avg": 1.3001973335623122e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.741271995126746e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1633538249156908e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1003.0704905986786, "timer/env.step_count": 2885.0, "timer/env.step_total": 216.9972803592682, "timer/env.step_frac": 0.21633303181888466, "timer/env.step_avg": 0.07521569509853317, "timer/env.step_min": 0.022875070571899414, "timer/env.step_max": 3.2883262634277344, "timer/replay._sample_count": 23088.0, "timer/replay._sample_total": 11.615944623947144, "timer/replay._sample_frac": 0.011580387154061539, "timer/replay._sample_avg": 0.0005031161046408153, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.010535717010498047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3838.0, "timer/agent.policy_total": 58.56611728668213, "timer/agent.policy_frac": 0.05838684104018171, "timer/agent.policy_avg": 0.015259540720865588, "timer/agent.policy_min": 0.008405447006225586, "timer/agent.policy_max": 0.11390066146850586, "timer/dataset_train_count": 1443.0, "timer/dataset_train_total": 0.15294718742370605, "timer/dataset_train_frac": 0.00015247900208131948, "timer/dataset_train_avg": 0.00010599250687713518, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.000408172607421875, "timer/agent.train_count": 1443.0, "timer/agent.train_total": 625.8613216876984, "timer/agent.train_frac": 0.623945502886996, "timer/agent.train_avg": 0.4337223296519046, "timer/agent.train_min": 0.421097993850708, "timer/agent.train_max": 1.3847365379333496, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47796154022216797, "timer/agent.report_frac": 0.0004764984561921451, "timer/agent.report_avg": 0.23898077011108398, "timer/agent.report_min": 0.2322995662689209, "timer/agent.report_max": 0.24566197395324707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.6145763380516722e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 23.009022994566656}
{"step": 940208, "time": 41415.47822642326, "episode/length": 451.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800884955752213, "episode/intrinsic_return": 0.0}
{"step": 940256, "time": 41418.49268102646, "episode/length": 163.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 940416, "time": 41424.95825576782, "episode/length": 377.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 940464, "time": 41428.161551475525, "episode/length": 245.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 940488, "time": 41430.24384045601, "episode/length": 296.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 941120, "time": 41452.760835409164, "episode/length": 220.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 941584, "time": 41469.62795376778, "episode/length": 57.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9137931034482759, "episode/intrinsic_return": 0.0}
{"step": 941664, "time": 41474.30024147034, "episode/length": 155.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 941984, "time": 41487.05098199844, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 942088, "time": 41492.66728234291, "episode/length": 267.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 942168, "time": 41499.08469438553, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 942600, "time": 41514.50792503357, "episode/length": 53.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 942704, "time": 41519.47370123863, "episode/length": 139.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 942784, "time": 41523.56026506424, "episode/length": 423.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 943040, "time": 41533.438729286194, "episode/length": 118.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 943256, "time": 41541.65125083923, "episode/length": 68.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 943520, "time": 41551.91996574402, "episode/length": 413.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 943856, "time": 41564.2702190876, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 944256, "time": 41578.61924648285, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 944320, "time": 41582.31159520149, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 944456, "time": 41587.94463133812, "episode/length": 495.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9979838709677419, "episode/intrinsic_return": 0.0}
{"step": 944504, "time": 41591.05036878586, "episode/length": 155.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 944624, "time": 41596.68261861801, "episode/length": 369.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9891891891891892, "episode/intrinsic_return": 0.0}
{"step": 944728, "time": 41601.29748392105, "episode/length": 150.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 945312, "time": 41621.87925863266, "episode/length": 315.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778481012658228, "episode/intrinsic_return": 0.0}
{"step": 945512, "time": 41629.70058846474, "episode/length": 125.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 945936, "time": 41645.30857563019, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 946240, "time": 41656.6425743103, "episode/length": 247.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 946264, "time": 41658.78387212753, "episode/length": 242.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 946440, "time": 41666.020540714264, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 946856, "time": 41680.92915773392, "episode/length": 167.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 947408, "time": 41700.522746801376, "episode/length": 443.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 947664, "time": 41710.59321260452, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 947680, "time": 41712.66672706604, "episode/length": 176.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 947904, "time": 41721.25798749924, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 948744, "time": 41749.75971078873, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 948864, "time": 41755.39394116402, "episode/length": 181.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 949184, "time": 41767.24762535095, "episode/length": 290.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 949184, "time": 41767.269882917404, "episode/length": 342.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941690962099126, "episode/intrinsic_return": 0.0}
{"step": 949344, "time": 41775.649002313614, "episode/length": 425.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 949512, "time": 41782.35300946236, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 949984, "time": 41799.49885678291, "episode/length": 259.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 41824.46595668793, "eval_episode/length": 173.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 950040, "time": 41826.48151612282, "eval_episode/length": 175.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 950040, "time": 41828.515367507935, "eval_episode/length": 176.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 950040, "time": 41832.2357609272, "eval_episode/length": 213.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 950040, "time": 41834.29648351669, "eval_episode/length": 226.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 950040, "time": 41836.20980811119, "eval_episode/length": 235.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 950040, "time": 41838.15877342224, "eval_episode/length": 243.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9754098360655737}
{"step": 950040, "time": 41840.57874774933, "eval_episode/length": 51.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 950264, "time": 41847.808109760284, "episode/length": 189.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 950400, "time": 41855.56164050102, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 950680, "time": 41865.94787812233, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 950696, "time": 41868.02543210983, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 950840, "time": 41874.26968932152, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 950856, "time": 41876.29379415512, "episode/length": 73.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9324324324324325, "episode/intrinsic_return": 0.0}
{"step": 951640, "time": 41903.38378882408, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 951728, "time": 41908.47504520416, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 951872, "time": 41915.29217123985, "episode/length": 148.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 952048, "time": 41922.38712191582, "episode/length": 50.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 952344, "time": 41933.16770386696, "episode/length": 58.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9491525423728814, "episode/intrinsic_return": 0.0}
{"step": 952512, "time": 41940.310376644135, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 952752, "time": 41949.696236133575, "episode/length": 256.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 952896, "time": 41955.71808075905, "episode/length": 422.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 953024, "time": 41961.26980996132, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 953048, "time": 41963.277752399445, "episode/length": 66.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 953744, "time": 41987.49408912659, "episode/length": 362.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9889807162534435, "episode/intrinsic_return": 0.0}
{"step": 953920, "time": 41994.75690317154, "episode/length": 127.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 953952, "time": 41997.235223054886, "episode/length": 277.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 954280, "time": 42009.218004226685, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 954512, "time": 42018.524216890335, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 954536, "time": 42020.751333236694, "episode/length": 76.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 954560, "time": 42023.30117034912, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 955168, "time": 42044.58250164986, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 955256, "time": 42048.802949905396, "episode/length": 363.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752747252747253, "episode/intrinsic_return": 0.0}
{"step": 955352, "time": 42053.49316525459, "episode/length": 174.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 955688, "time": 42066.00399494171, "episode/length": 143.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 955760, "time": 42070.03273439407, "episode/length": 149.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 955920, "time": 42076.73863172531, "episode/length": 93.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 956208, "time": 42087.50574755669, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 956272, "time": 42091.21039438248, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 956296, "time": 42093.29155445099, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 956392, "time": 42097.903645038605, "episode/length": 58.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 956520, "time": 42103.45831155777, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 956768, "time": 42113.24117207527, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 957080, "time": 42124.63933992386, "episode/length": 349.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 957280, "time": 42132.92745542526, "episode/length": 125.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 958000, "time": 42157.794729709625, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 958056, "time": 42160.96252202988, "episode/length": 121.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 958368, "time": 42172.930382966995, "episode/length": 325.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 958520, "time": 42180.551520347595, "episode/length": 288.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 958632, "time": 42185.959064245224, "episode/length": 78.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.0}
{"step": 958760, "time": 42192.20093393326, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 959080, "time": 42204.67369437218, "episode/length": 347.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 959312, "time": 42214.15930604935, "episode/length": 348.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9914040114613181, "episode/intrinsic_return": 0.0}
{"step": 959776, "time": 42230.47592806816, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 959784, "time": 42231.997717142105, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 42257.412173986435, "eval_episode/length": 87.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 960024, "time": 42262.0517847538, "eval_episode/length": 76.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.987012987012987}
{"step": 960024, "time": 42263.78687596321, "eval_episode/length": 170.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 960024, "time": 42263.79785299301, "eval_episode/length": 170.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 960024, "time": 42267.09758090973, "eval_episode/length": 174.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 960024, "time": 42270.98787403107, "eval_episode/length": 231.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 960024, "time": 42273.281942129135, "eval_episode/length": 249.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 960024, "time": 42276.457591056824, "eval_episode/length": 124.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.992}
{"step": 960120, "time": 42279.54481601715, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 960976, "time": 42309.09533405304, "episode/length": 106.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 961048, "time": 42312.73945069313, "episode/length": 315.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 961248, "time": 42321.174293756485, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 961312, "time": 42325.27265167236, "episode/length": 367.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 961640, "time": 42337.81697130203, "episode/length": 290.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9759450171821306, "episode/intrinsic_return": 0.0}
{"step": 961824, "time": 42345.46752309799, "episode/length": 63.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 961832, "time": 42347.01405596733, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 962504, "time": 42370.25841116905, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 962576, "time": 42374.22520804405, "episode/length": 93.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 962608, "time": 42376.783282995224, "episode/length": 203.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 962696, "time": 42380.946617126465, "episode/length": 363.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9917582417582418, "episode/intrinsic_return": 0.0}
{"step": 962936, "time": 42390.199998140335, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 963416, "time": 42407.49935722351, "episode/length": 221.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 963433, "time": 42410.88288331032, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.278290212970891, "train/action_min": 0.0, "train/action_std": 3.219867714463848, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0336313887486515, "train/actor_opt_grad_steps": 59385.0, "train/actor_opt_loss": -3.9109041865864027, "train/adv_mag": 0.45216987128943614, "train/adv_max": 0.4052223889795068, "train/adv_mean": 0.0034127618750286796, "train/adv_min": -0.3765713310200874, "train/adv_std": 0.05153260053428885, "train/cont_avg": 0.995431560359589, "train/cont_loss_mean": 0.00016916693361698803, "train/cont_loss_std": 0.005122725277416668, "train/cont_neg_acc": 0.9947977829469393, "train/cont_neg_loss": 0.013877574024995551, "train/cont_pos_acc": 0.9999731227959672, "train/cont_pos_loss": 0.00010368353667296535, "train/cont_pred": 0.9954255125293993, "train/cont_rate": 0.995431560359589, "train/dyn_loss_mean": 13.099628931855502, "train/dyn_loss_std": 9.574934430318336, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.939111690815181, "train/extr_critic_critic_opt_grad_steps": 59385.0, "train/extr_critic_critic_opt_loss": 15963.618311215754, "train/extr_critic_mag": 8.471956403288123, "train/extr_critic_max": 8.471956403288123, "train/extr_critic_mean": 2.397417043169884, "train/extr_critic_min": -0.1906511710114675, "train/extr_critic_std": 2.010186494213261, "train/extr_return_normed_mag": 1.4961732617796284, "train/extr_return_normed_max": 1.4961732617796284, "train/extr_return_normed_mean": 0.37590089399520665, "train/extr_return_normed_min": -0.07526311321719868, "train/extr_return_normed_std": 0.31784605479811967, "train/extr_return_rate": 0.7942392164713716, "train/extr_return_raw_mag": 9.62126667858803, "train/extr_return_raw_max": 9.62126667858803, "train/extr_return_raw_mean": 2.4192913011328816, "train/extr_return_raw_min": -0.48087759091429516, "train/extr_return_raw_std": 2.043808683957139, "train/extr_reward_mag": 1.0426327920939824, "train/extr_reward_max": 1.0426327920939824, "train/extr_reward_mean": 0.042437434183714325, "train/extr_reward_min": -0.43679808835460715, "train/extr_reward_std": 0.19126942018940024, "train/image_loss_mean": 6.643367105967378, "train/image_loss_std": 11.904616235053702, "train/model_loss_mean": 14.558845840088308, "train/model_loss_std": 15.847680568695068, "train/model_opt_grad_norm": 54.76916223029568, "train/model_opt_grad_steps": 59328.50684931507, "train/model_opt_loss": 18327.14040427012, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.5616438356165, "train/policy_entropy_mag": 2.545758872816007, "train/policy_entropy_max": 2.545758872816007, "train/policy_entropy_mean": 0.5335598402235606, "train/policy_entropy_min": 0.07937502360915484, "train/policy_entropy_std": 0.6673210271417278, "train/policy_logprob_mag": 7.438383798076682, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5332499630238912, "train/policy_logprob_min": -7.438383798076682, "train/policy_logprob_std": 1.0944496503431502, "train/policy_randomness_mag": 0.8985411643165432, "train/policy_randomness_max": 0.8985411643165432, "train/policy_randomness_mean": 0.18832320913876574, "train/policy_randomness_min": 0.028015900046041566, "train/policy_randomness_std": 0.23553504008952886, "train/post_ent_mag": 60.59680290744729, "train/post_ent_max": 60.59680290744729, "train/post_ent_mean": 43.620228571434545, "train/post_ent_min": 20.32356308584344, "train/post_ent_std": 7.856913230190538, "train/prior_ent_mag": 70.08069103711271, "train/prior_ent_max": 70.08069103711271, "train/prior_ent_mean": 56.75480761593335, "train/prior_ent_min": 38.366694594082766, "train/prior_ent_std": 5.116534611950182, "train/rep_loss_mean": 13.099628931855502, "train/rep_loss_std": 9.574934430318336, "train/reward_avg": 0.02860057231498091, "train/reward_loss_mean": 0.05553224088292416, "train/reward_loss_std": 0.24861402850445002, "train/reward_max_data": 1.0136986334029943, "train/reward_max_pred": 1.0108497730673176, "train/reward_neg_acc": 0.9922095737228654, "train/reward_neg_loss": 0.028449755015285457, "train/reward_pos_acc": 0.9689249139126033, "train/reward_pos_loss": 0.8569615352643679, "train/reward_pred": 0.027614738903812146, "train/reward_rate": 0.03291550727739726, "train_stats/sum_log_reward": 8.896116687256155, "train_stats/max_log_achievement_collect_coal": 0.9514563106796117, "train_stats/max_log_achievement_collect_drink": 3.883495145631068, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.2815533980582525, "train_stats/max_log_achievement_collect_stone": 14.58252427184466, "train_stats/max_log_achievement_collect_wood": 7.553398058252427, "train_stats/max_log_achievement_defeat_skeleton": 0.08737864077669903, "train_stats/max_log_achievement_defeat_zombie": 0.5631067961165048, "train_stats/max_log_achievement_eat_cow": 0.08737864077669903, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7087378640776698, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.8737864077669903, "train_stats/max_log_achievement_place_plant": 1.2621359223300972, "train_stats/max_log_achievement_place_stone": 5.203883495145631, "train_stats/max_log_achievement_place_table": 2.1359223300970873, "train_stats/max_log_achievement_wake_up": 1.233009708737864, "train_stats/mean_log_entropy": 0.37297461594192727, "eval_stats/sum_log_reward": 8.600000143051147, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 7.5, "eval_stats/max_log_achievement_collect_wood": 7.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.9375, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 2.6875, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.358211066981312e-06, "report/cont_loss_std": 1.4834586181677878e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.90204862318933e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.903538294660393e-06, "report/cont_pred": 0.9951118230819702, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.56353759765625, "report/dyn_loss_std": 9.471904754638672, "report/image_loss_mean": 5.662839889526367, "report/image_loss_std": 11.599377632141113, "report/model_loss_mean": 13.259908676147461, "report/model_loss_std": 15.502933502197266, "report/post_ent_mag": 60.99345397949219, "report/post_ent_max": 60.99345397949219, "report/post_ent_mean": 43.64559555053711, "report/post_ent_min": 18.288013458251953, "report/post_ent_std": 7.768446922302246, "report/prior_ent_mag": 69.94680786132812, "report/prior_ent_max": 69.94680786132812, "report/prior_ent_mean": 56.14206314086914, "report/prior_ent_min": 36.04907989501953, "report/prior_ent_std": 4.705121040344238, "report/rep_loss_mean": 12.56353759765625, "report/rep_loss_std": 9.471904754638672, "report/reward_avg": 0.02802734449505806, "report/reward_loss_mean": 0.05893948674201965, "report/reward_loss_std": 0.2953585386276245, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002763032913208, "report/reward_neg_acc": 0.992929220199585, "report/reward_neg_loss": 0.031091587617993355, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.8698047399520874, "report/reward_pred": 0.028916897252202034, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00015266993432305753, "eval/cont_loss_std": 0.004550537094473839, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00026637344853952527, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00015233583690132946, "eval/cont_pred": 0.9969290494918823, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 15.97402572631836, "eval/dyn_loss_std": 10.997169494628906, "eval/image_loss_mean": 9.869901657104492, "eval/image_loss_std": 11.060189247131348, "eval/model_loss_mean": 19.555625915527344, "eval/model_loss_std": 15.642820358276367, "eval/post_ent_mag": 60.16160583496094, "eval/post_ent_max": 60.16160583496094, "eval/post_ent_mean": 42.668495178222656, "eval/post_ent_min": 20.305435180664062, "eval/post_ent_std": 7.911657333374023, "eval/prior_ent_mag": 69.94680786132812, "eval/prior_ent_max": 69.94680786132812, "eval/prior_ent_mean": 56.836036682128906, "eval/prior_ent_min": 38.19181823730469, "eval/prior_ent_std": 5.677065372467041, "eval/rep_loss_mean": 15.97402572631836, "eval/rep_loss_std": 10.997169494628906, "eval/reward_avg": 0.04501952975988388, "eval/reward_loss_mean": 0.10115700960159302, "eval/reward_loss_std": 0.5800379514694214, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001070499420166, "eval/reward_neg_acc": 0.9907597899436951, "eval/reward_neg_loss": 0.047768380492925644, "eval/reward_pos_acc": 0.9199999570846558, "eval/reward_pos_loss": 1.1411675214767456, "eval/reward_pred": 0.04309298098087311, "eval/reward_rate": 0.048828125, "replay/size": 962929.0, "replay/inserts": 23376.0, "replay/samples": 23376.0, "replay/insert_wait_avg": 1.321389281855798e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.768186455634585e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1560728224061376e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1875057220459, "timer/env.step_count": 2922.0, "timer/env.step_total": 241.93429446220398, "timer/env.step_frac": 0.24188893890206023, "timer/env.step_avg": 0.08279749981594935, "timer/env.step_min": 0.022996902465820312, "timer/env.step_max": 3.842959403991699, "timer/replay._sample_count": 23376.0, "timer/replay._sample_total": 11.844688892364502, "timer/replay._sample_frac": 0.01184246836178352, "timer/replay._sample_avg": 0.0005067029813639845, "timer/replay._sample_min": 0.0004241466522216797, "timer/replay._sample_max": 0.035445213317871094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3478.0, "timer/agent.policy_total": 53.5930335521698, "timer/agent.policy_frac": 0.05358298643560881, "timer/agent.policy_avg": 0.01540915283271127, "timer/agent.policy_min": 0.008454561233520508, "timer/agent.policy_max": 0.1518540382385254, "timer/dataset_train_count": 1461.0, "timer/dataset_train_total": 0.15432405471801758, "timer/dataset_train_frac": 0.00015429512349947764, "timer/dataset_train_avg": 0.00010562905867078548, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0005791187286376953, "timer/agent.train_count": 1461.0, "timer/agent.train_total": 635.8740339279175, "timer/agent.train_frac": 0.6357548262601754, "timer/agent.train_avg": 0.4352320560766033, "timer/agent.train_min": 0.4222550392150879, "timer/agent.train_max": 1.445847749710083, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47788095474243164, "timer/agent.report_frac": 0.00047779136612733866, "timer/agent.report_avg": 0.23894047737121582, "timer/agent.report_min": 0.2329578399658203, "timer/agent.report_max": 0.24492311477661133, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.0511856977226526e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 23.37118560053667}
{"step": 963528, "time": 42413.729670763016, "episode/length": 103.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 963696, "time": 42420.909883499146, "episode/length": 232.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 963776, "time": 42425.035204172134, "episode/length": 340.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9824046920821115, "episode/intrinsic_return": 0.0}
{"step": 963888, "time": 42430.085507154465, "episode/length": 172.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 964176, "time": 42440.847312927246, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 964344, "time": 42447.554020643234, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 964640, "time": 42458.80683851242, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 964880, "time": 42468.044208049774, "episode/length": 87.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 965000, "time": 42473.49159646034, "episode/length": 162.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 965048, "time": 42476.502306222916, "episode/length": 189.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 965120, "time": 42480.52180123329, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 965448, "time": 42492.549825668335, "episode/length": 194.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 965592, "time": 42498.72346878052, "episode/length": 226.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 965808, "time": 42507.42055559158, "episode/length": 94.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 966152, "time": 42519.77994942665, "episode/length": 143.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 966224, "time": 42523.82335233688, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 966336, "time": 42529.00931119919, "episode/length": 110.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 966648, "time": 42540.33302664757, "episode/length": 250.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 966696, "time": 42544.84086704254, "episode/length": 226.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 966968, "time": 42555.049909353256, "episode/length": 230.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 967184, "time": 42563.64421439171, "episode/length": 66.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 967208, "time": 42565.77503633499, "episode/length": 174.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 967264, "time": 42569.28826570511, "episode/length": 129.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 967520, "time": 42579.10042095184, "episode/length": 147.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 967784, "time": 42588.93227672577, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 968184, "time": 42603.319834947586, "episode/length": 151.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 968240, "time": 42606.90145778656, "episode/length": 131.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 968896, "time": 42629.686638593674, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 968976, "time": 42633.85743737221, "episode/length": 352.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 969048, "time": 42637.41502785683, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 969136, "time": 42642.08934926987, "episode/length": 111.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 969136, "time": 42642.09900665283, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 969344, "time": 42652.05393862724, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 969496, "time": 42658.24285650253, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 969664, "time": 42665.478444337845, "episode/length": 65.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 969728, "time": 42669.040588617325, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 42698.769020318985, "eval_episode/length": 162.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 970008, "time": 42698.81321501732, "eval_episode/length": 162.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 970008, "time": 42702.76726794243, "eval_episode/length": 179.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 970008, "time": 42704.626777887344, "eval_episode/length": 186.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 970008, "time": 42706.30918383598, "eval_episode/length": 189.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.968421052631579}
{"step": 970008, "time": 42708.56020307541, "eval_episode/length": 204.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 970008, "time": 42710.42817258835, "eval_episode/length": 211.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 970008, "time": 42714.48917603493, "eval_episode/length": 272.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9963369963369964}
{"step": 970616, "time": 42734.224316596985, "episode/length": 195.0, "episode/score": 12.099999949336052, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 970816, "time": 42742.51997303963, "episode/length": 183.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 970904, "time": 42746.648069143295, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 970904, "time": 42746.65680074692, "episode/length": 250.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 971168, "time": 42758.67773962021, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 971184, "time": 42760.66549682617, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 971696, "time": 42778.72949910164, "episode/length": 134.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 971904, "time": 42786.97950839996, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 971928, "time": 42789.09538912773, "episode/length": 348.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9885386819484241, "episode/intrinsic_return": 0.0}
{"step": 972008, "time": 42793.31218791008, "episode/length": 102.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 972232, "time": 42802.181151628494, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 972280, "time": 42805.32791876793, "episode/length": 171.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 972984, "time": 42830.32807159424, "episode/length": 160.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 973160, "time": 42837.44968700409, "episode/length": 248.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 973344, "time": 42845.2115085125, "episode/length": 138.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 973448, "time": 42849.878224372864, "episode/length": 192.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 973600, "time": 42856.44922232628, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 973896, "time": 42867.2635884285, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 973920, "time": 42869.720938682556, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 973920, "time": 42869.72680687904, "episode/length": 58.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 974112, "time": 42879.1601524353, "episode/length": 140.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 974192, "time": 42883.18170237541, "episode/length": 105.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 974200, "time": 42884.89197945595, "episode/length": 422.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952718676122931, "episode/intrinsic_return": 0.0}
{"step": 974272, "time": 42889.005244493484, "episode/length": 138.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 974744, "time": 42905.550922870636, "episode/length": 67.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 975200, "time": 42923.50509881973, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 975568, "time": 42936.98662734032, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 975752, "time": 42944.230422496796, "episode/length": 268.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 975752, "time": 42944.2387239933, "episode/length": 228.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 975760, "time": 42947.959904670715, "episode/length": 195.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 975864, "time": 42952.626999378204, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 976560, "time": 42976.58010292053, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 976896, "time": 42988.930653333664, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 977024, "time": 42994.644588947296, "episode/length": 390.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.989769820971867, "episode/intrinsic_return": 0.0}
{"step": 977064, "time": 42997.19593024254, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 977112, "time": 43000.14717078209, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 977312, "time": 43008.296882629395, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 977776, "time": 43024.89755010605, "episode/length": 109.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 978280, "time": 43042.40264415741, "episode/length": 338.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 978408, "time": 43048.056926727295, "episode/length": 167.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 978464, "time": 43051.71443128586, "episode/length": 179.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 978720, "time": 43061.521446466446, "episode/length": 269.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 978792, "time": 43065.134467601776, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 978800, "time": 43067.0812933445, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 979016, "time": 43075.39745235443, "episode/length": 212.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 979288, "time": 43085.759516477585, "episode/length": 188.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 979792, "time": 43103.82587432861, "episode/length": 133.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 979912, "time": 43108.934876441956, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 980000, "time": 43113.67033576965, "episode/length": 149.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 980064, "time": 43117.25461053848, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 43138.20681142807, "eval_episode/length": 130.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9923664122137404}
{"step": 980096, "time": 43141.02716636658, "eval_episode/length": 163.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.975609756097561}
{"step": 980096, "time": 43143.963366508484, "eval_episode/length": 194.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 980096, "time": 43145.84930706024, "eval_episode/length": 203.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9656862745098039}
{"step": 980096, "time": 43148.034663915634, "eval_episode/length": 220.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 980096, "time": 43150.02782559395, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 980096, "time": 43152.85799074173, "eval_episode/length": 261.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 980096, "time": 43155.64862346649, "eval_episode/length": 295.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9831081081081081}
{"step": 980176, "time": 43158.242878198624, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 980456, "time": 43168.405339717865, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 981184, "time": 43193.61060214043, "episode/length": 139.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 981568, "time": 43207.50114250183, "episode/length": 221.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 981616, "time": 43212.825973033905, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 981736, "time": 43217.945447683334, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 982000, "time": 43228.01886224747, "episode/length": 338.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9941002949852508, "episode/intrinsic_return": 0.0}
{"step": 982024, "time": 43230.426436424255, "episode/length": 230.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 982120, "time": 43235.84472346306, "episode/length": 387.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 982784, "time": 43259.19183731079, "episode/length": 94.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 982904, "time": 43264.414880514145, "episode/length": 160.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 982992, "time": 43269.150185108185, "episode/length": 108.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 983120, "time": 43276.9903819561, "episode/length": 193.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 983296, "time": 43285.00696182251, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 983328, "time": 43288.0481364727, "episode/length": 358.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 983792, "time": 43305.552037239075, "episode/length": 110.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 983880, "time": 43309.70968222618, "episode/length": 267.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 984216, "time": 43322.0674226284, "episode/length": 276.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 984464, "time": 43331.7295293808, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 984664, "time": 43339.51823878288, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 984704, "time": 43342.69500398636, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 984984, "time": 43353.09115290642, "episode/length": 148.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 985160, "time": 43360.28122591972, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 985640, "time": 43377.00075316429, "episode/length": 219.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 985976, "time": 43389.33915781975, "episode/length": 188.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 986528, "time": 43408.893512010574, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 986529, "time": 43411.10207462311, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.122120824353448, "train/action_min": 0.0, "train/action_std": 3.00816843756314, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03392141412558227, "train/actor_opt_grad_steps": 60840.0, "train/actor_opt_loss": -3.991142332759397, "train/adv_mag": 0.4521294678079671, "train/adv_max": 0.39866672199347924, "train/adv_mean": 0.003095496439621864, "train/adv_min": -0.3663499654367052, "train/adv_std": 0.05140018583885555, "train/cont_avg": 0.9950228987068965, "train/cont_loss_mean": 0.0001295917281058321, "train/cont_loss_std": 0.0038204103163660217, "train/cont_neg_acc": 0.9956948806499613, "train/cont_neg_loss": 0.014224856139819542, "train/cont_pos_acc": 0.9999932108254268, "train/cont_pos_loss": 3.796311487090422e-05, "train/cont_pred": 0.9950367734350007, "train/cont_rate": 0.9950228987068965, "train/dyn_loss_mean": 12.956046887101799, "train/dyn_loss_std": 9.545406913757324, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9527900395722225, "train/extr_critic_critic_opt_grad_steps": 60840.0, "train/extr_critic_critic_opt_loss": 15957.800552262932, "train/extr_critic_mag": 8.697366826287631, "train/extr_critic_max": 8.697366826287631, "train/extr_critic_mean": 2.6147781150094396, "train/extr_critic_min": -0.21906725373761407, "train/extr_critic_std": 2.0857099944147572, "train/extr_return_normed_mag": 1.4712786189441023, "train/extr_return_normed_max": 1.4712786189441023, "train/extr_return_normed_mean": 0.3943956210695464, "train/extr_return_normed_min": -0.0875169831103292, "train/extr_return_normed_std": 0.3211860644406286, "train/extr_return_rate": 0.8174151819327782, "train/extr_return_raw_mag": 9.724851720086459, "train/extr_return_raw_max": 9.724851720086459, "train/extr_return_raw_mean": 2.6351546501291208, "train/extr_return_raw_min": -0.5376252038725491, "train/extr_return_raw_std": 2.1145258073149056, "train/extr_reward_mag": 1.041147100514379, "train/extr_reward_max": 1.041147100514379, "train/extr_reward_mean": 0.04444883849857182, "train/extr_reward_min": -0.47346890137113373, "train/extr_reward_std": 0.19709840797144793, "train/image_loss_mean": 6.395744455271754, "train/image_loss_std": 11.778992985034812, "train/model_loss_mean": 14.2276938997466, "train/model_loss_std": 15.75410275294863, "train/model_opt_grad_norm": 53.39444265694454, "train/model_opt_grad_steps": 60782.24827586207, "train/model_opt_loss": 19876.81587419181, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1396.551724137931, "train/policy_entropy_mag": 2.564197847760957, "train/policy_entropy_max": 2.564197847760957, "train/policy_entropy_mean": 0.4984749888551646, "train/policy_entropy_min": 0.07937501915569962, "train/policy_entropy_std": 0.6424700478027607, "train/policy_logprob_mag": 7.438383822605528, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.49853298561326387, "train/policy_logprob_min": -7.438383822605528, "train/policy_logprob_std": 1.0745272804950845, "train/policy_randomness_mag": 0.9050493145811147, "train/policy_randomness_max": 0.9050493145811147, "train/policy_randomness_mean": 0.17593979732743625, "train/policy_randomness_min": 0.028015898476386893, "train/policy_randomness_std": 0.2267637322688925, "train/post_ent_mag": 60.54697894392342, "train/post_ent_max": 60.54697894392342, "train/post_ent_mean": 43.636288031216324, "train/post_ent_min": 20.270074804897966, "train/post_ent_std": 7.822105055841907, "train/prior_ent_mag": 70.16935456374596, "train/prior_ent_max": 70.16935456374596, "train/prior_ent_mean": 56.629847191120014, "train/prior_ent_min": 38.80556961585735, "train/prior_ent_std": 5.084964255628915, "train/rep_loss_mean": 12.956046887101799, "train/rep_loss_std": 9.545406913757324, "train/reward_avg": 0.030412176623940468, "train/reward_loss_mean": 0.05819174079545613, "train/reward_loss_std": 0.25621923917326433, "train/reward_max_data": 1.01724138342101, "train/reward_max_pred": 1.0110676444810012, "train/reward_neg_acc": 0.9923450420642721, "train/reward_neg_loss": 0.029860443737486312, "train/reward_pos_acc": 0.9684597064708841, "train/reward_pos_loss": 0.8451390689816968, "train/reward_pred": 0.029628073289219674, "train/reward_rate": 0.03481950431034483, "train_stats/sum_log_reward": 9.260714515178863, "train_stats/max_log_achievement_collect_coal": 1.2142857142857142, "train_stats/max_log_achievement_collect_drink": 4.107142857142857, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.2857142857142858, "train_stats/max_log_achievement_collect_stone": 15.535714285714286, "train_stats/max_log_achievement_collect_wood": 7.026785714285714, "train_stats/max_log_achievement_defeat_skeleton": 0.05357142857142857, "train_stats/max_log_achievement_defeat_zombie": 0.5982142857142857, "train_stats/max_log_achievement_eat_cow": 0.07142857142857142, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5982142857142858, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 1.8482142857142858, "train_stats/max_log_achievement_place_plant": 1.2678571428571428, "train_stats/max_log_achievement_place_stone": 5.6875, "train_stats/max_log_achievement_place_table": 2.0, "train_stats/max_log_achievement_wake_up": 1.0089285714285714, "train_stats/mean_log_entropy": 0.28626615793577265, "eval_stats/sum_log_reward": 9.100000202655792, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 4.4375, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0625, "eval_stats/max_log_achievement_collect_stone": 14.0625, "eval_stats/max_log_achievement_collect_wood": 8.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 1.6875, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 5.375, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 1.6065446288848761e-06, "report/cont_loss_std": 1.7576880054548383e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.3695183042727876e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.5233384829116403e-06, "report/cont_pred": 0.9931626915931702, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.332799911499023, "report/dyn_loss_std": 9.539397239685059, "report/image_loss_mean": 7.151943206787109, "report/image_loss_std": 11.06641674041748, "report/model_loss_mean": 15.216989517211914, "report/model_loss_std": 15.135476112365723, "report/post_ent_mag": 60.889644622802734, "report/post_ent_max": 60.889644622802734, "report/post_ent_mean": 43.98563766479492, "report/post_ent_min": 18.952421188354492, "report/post_ent_std": 8.252577781677246, "report/prior_ent_mag": 69.93924713134766, "report/prior_ent_max": 69.93924713134766, "report/prior_ent_mean": 57.28515625, "report/prior_ent_min": 41.097007751464844, "report/prior_ent_std": 4.806843280792236, "report/rep_loss_mean": 13.332799911499023, "report/rep_loss_std": 9.539397239685059, "report/reward_avg": 0.03339843451976776, "report/reward_loss_mean": 0.0653650313615799, "report/reward_loss_std": 0.2776329219341278, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041041374206543, "report/reward_neg_acc": 0.9908629655838013, "report/reward_neg_loss": 0.03056933544576168, "report/reward_pos_acc": 0.9230769276618958, "report/reward_pos_loss": 0.9441795349121094, "report/reward_pred": 0.029932992532849312, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.357124907983234e-06, "eval/cont_loss_std": 8.275489381048828e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008339030900970101, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.9196738776372513e-06, "eval/cont_pred": 0.9970709085464478, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 16.979267120361328, "eval/dyn_loss_std": 9.999824523925781, "eval/image_loss_mean": 11.610837936401367, "eval/image_loss_std": 12.635499000549316, "eval/model_loss_mean": 21.886857986450195, "eval/model_loss_std": 15.972846984863281, "eval/post_ent_mag": 57.30119323730469, "eval/post_ent_max": 57.30119323730469, "eval/post_ent_mean": 43.12327575683594, "eval/post_ent_min": 18.70859718322754, "eval/post_ent_std": 7.670535087585449, "eval/prior_ent_mag": 69.93924713134766, "eval/prior_ent_max": 69.93924713134766, "eval/prior_ent_mean": 58.21657180786133, "eval/prior_ent_min": 38.329254150390625, "eval/prior_ent_std": 4.546102523803711, "eval/rep_loss_mean": 16.979267120361328, "eval/rep_loss_std": 9.999824523925781, "eval/reward_avg": 0.03281249850988388, "eval/reward_loss_mean": 0.08845360577106476, "eval/reward_loss_std": 0.6432605981826782, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9994262456893921, "eval/reward_neg_acc": 0.9969604015350342, "eval/reward_neg_loss": 0.02541104331612587, "eval/reward_pos_acc": 0.8648648262023926, "eval/reward_pos_loss": 1.7701566219329834, "eval/reward_pred": 0.02636469528079033, "eval/reward_rate": 0.0361328125, "replay/size": 986025.0, "replay/inserts": 23096.0, "replay/samples": 23088.0, "replay/insert_wait_avg": 1.314626171137166e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.879027705678326e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1689424095757187e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.18008852005, "timer/env.step_count": 2887.0, "timer/env.step_total": 251.32779145240784, "timer/env.step_frac": 0.2512825383519616, "timer/env.step_avg": 0.08705500223498713, "timer/env.step_min": 0.022863149642944336, "timer/env.step_max": 3.3244078159332275, "timer/replay._sample_count": 23088.0, "timer/replay._sample_total": 11.646150588989258, "timer/replay._sample_frac": 0.0116440536286039, "timer/replay._sample_avg": 0.0005044244018099991, "timer/replay._sample_min": 0.00040721893310546875, "timer/replay._sample_max": 0.03287172317504883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3456.0, "timer/agent.policy_total": 51.7284734249115, "timer/agent.policy_frac": 0.05171915939803727, "timer/agent.policy_avg": 0.014967729578967448, "timer/agent.policy_min": 0.008191108703613281, "timer/agent.policy_max": 0.09572386741638184, "timer/dataset_train_count": 1443.0, "timer/dataset_train_total": 0.15314793586730957, "timer/dataset_train_frac": 0.0001531203606481709, "timer/dataset_train_avg": 0.00010613162568767122, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0008857250213623047, "timer/agent.train_count": 1443.0, "timer/agent.train_total": 629.2300510406494, "timer/agent.train_frac": 0.6291167543354225, "timer/agent.train_avg": 0.43605686142803146, "timer/agent.train_min": 0.4237673282623291, "timer/agent.train_max": 2.698425531387329, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790973663330078, "timer/agent.report_frac": 0.0004790111019325732, "timer/agent.report_avg": 0.2395486831665039, "timer/agent.report_min": 0.23321127891540527, "timer/agent.report_max": 0.24588608741760254, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6936448493331994e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 23.091487747128948}
{"step": 986576, "time": 43412.89570641518, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 986672, "time": 43417.461975336075, "episode/length": 306.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.993485342019544, "episode/intrinsic_return": 0.0}
{"step": 986728, "time": 43420.582468509674, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 986896, "time": 43427.737609386444, "episode/length": 273.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 987144, "time": 43437.04504942894, "episode/length": 70.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 987976, "time": 43465.48995375633, "episode/length": 413.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975845410628019, "episode/intrinsic_return": 0.0}
{"step": 988064, "time": 43470.01994013786, "episode/length": 114.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 988488, "time": 43485.05421876907, "episode/length": 226.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 988576, "time": 43489.56450653076, "episode/length": 366.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 989048, "time": 43506.07727408409, "episode/length": 268.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 989056, "time": 43508.097584962845, "episode/length": 134.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 989256, "time": 43515.811515808105, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9926829268292683, "episode/intrinsic_return": 0.0}
{"step": 989472, "time": 43524.44257450104, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 989720, "time": 43533.85084152222, "episode/length": 398.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 43565.22441458702, "eval_episode/length": 73.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9864864864864865}
{"step": 990080, "time": 43568.763496637344, "eval_episode/length": 122.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.991869918699187}
{"step": 990080, "time": 43571.00321435928, "eval_episode/length": 137.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 990080, "time": 43575.43852162361, "eval_episode/length": 207.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 990080, "time": 43575.445935726166, "eval_episode/length": 207.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 990080, "time": 43579.567789554596, "eval_episode/length": 226.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9911894273127754}
{"step": 990080, "time": 43587.534915685654, "eval_episode/length": 378.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9920844327176781}
{"step": 990080, "time": 43590.341819524765, "eval_episode/length": 199.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.995}
{"step": 990152, "time": 43592.55552268028, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 990776, "time": 43614.25519275665, "episode/length": 215.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 990928, "time": 43620.86397027969, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 990984, "time": 43624.16722226143, "episode/length": 157.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 991096, "time": 43629.424350738525, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 991304, "time": 43639.16301035881, "episode/length": 143.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 991496, "time": 43646.887609004974, "episode/length": 304.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 991552, "time": 43650.3828959465, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 991664, "time": 43655.748012304306, "episode/length": 44.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 991880, "time": 43663.859446287155, "episode/length": 40.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 992272, "time": 43678.04849910736, "episode/length": 146.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 992680, "time": 43692.55615091324, "episode/length": 743.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9986559139784946, "episode/intrinsic_return": 0.0}
{"step": 992904, "time": 43701.24798488617, "episode/length": 265.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 993032, "time": 43706.929837703705, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 993120, "time": 43711.49415874481, "episode/length": 154.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 993592, "time": 43727.83791255951, "episode/length": 325.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 993624, "time": 43730.34000992775, "episode/length": 336.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 993928, "time": 43741.53692364693, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787985865724381, "episode/intrinsic_return": 0.0}
{"step": 994040, "time": 43746.62304496765, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 994280, "time": 43755.82595562935, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 994760, "time": 43772.838217020035, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 995528, "time": 43799.35001921654, "episode/length": 355.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9915730337078652, "episode/intrinsic_return": 0.0}
{"step": 995752, "time": 43808.18360996246, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 995760, "time": 43810.13961529732, "episode/length": 266.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 995824, "time": 43813.73942422867, "episode/length": 192.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 995872, "time": 43816.854560136795, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 996328, "time": 43832.775161504745, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 996496, "time": 43839.878776073456, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 996632, "time": 43845.50139546394, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 996816, "time": 43853.01816987991, "episode/length": 132.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 996864, "time": 43856.02213335037, "episode/length": 166.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 997616, "time": 43881.88064575195, "episode/length": 231.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 997624, "time": 43883.465549468994, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 997640, "time": 43885.50413417816, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 998032, "time": 43899.980838537216, "episode/length": 145.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 998240, "time": 43908.279695510864, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 998592, "time": 43921.12137389183, "episode/length": 244.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 998832, "time": 43930.40655326843, "episode/length": 312.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 998896, "time": 43933.89461874962, "episode/length": 107.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 999000, "time": 43938.58535218239, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 999320, "time": 43950.47224140167, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 999464, "time": 43958.13003563881, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 999808, "time": 43971.018684864044, "episode/length": 151.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 43997.99621105194, "eval_episode/length": 97.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9897959183673469}
{"step": 1000064, "time": 43999.84386897087, "eval_episode/length": 105.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9905660377358491}
{"step": 1000064, "time": 44004.63791871071, "eval_episode/length": 182.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 1000064, "time": 44007.44456410408, "eval_episode/length": 213.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 1000064, "time": 44009.62662601471, "eval_episode/length": 231.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 1000064, "time": 44012.23417639732, "eval_episode/length": 41.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 1000064, "time": 44014.18928027153, "eval_episode/length": 265.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9849624060150376}
{"step": 1000064, "time": 44016.823632478714, "eval_episode/length": 185.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 1000128, "time": 44018.900156497955, "episode/length": 140.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 1000168, "time": 44021.50175666809, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 1000168, "time": 44021.542842149734, "episode/length": 317.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 1000328, "time": 44029.634774684906, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 1000360, "time": 44032.10777235031, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 1000744, "time": 44046.01857495308, "episode/length": 177.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1001288, "time": 44065.06633687019, "episode/length": 139.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 1001480, "time": 44072.828691244125, "episode/length": 168.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1001584, "time": 44077.92906689644, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 1001616, "time": 44080.43657231331, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 1001784, "time": 44087.15677976608, "episode/length": 289.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 1002064, "time": 44097.90911793709, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1002400, "time": 44110.57740306854, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1002408, "time": 44112.12797355652, "episode/length": 98.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 1002480, "time": 44116.200540065765, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 1002992, "time": 44134.37519240379, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1003176, "time": 44141.59349608421, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 1003584, "time": 44156.39760541916, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 1003720, "time": 44162.20089650154, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 1003760, "time": 44165.27893280983, "episode/length": 169.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 1004152, "time": 44179.11330246925, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 1004240, "time": 44183.75131368637, "episode/length": 228.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1004312, "time": 44187.44976758957, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 1004344, "time": 44190.05674910545, "episode/length": 319.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 1004768, "time": 44205.709914684296, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 1004944, "time": 44212.85793042183, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1005280, "time": 44225.24069714546, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1005504, "time": 44233.96322393417, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 1005520, "time": 44235.950095415115, "episode/length": 146.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 1005800, "time": 44246.64307427406, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 1006128, "time": 44258.99890589714, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1006200, "time": 44262.61556887627, "episode/length": 235.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 1006216, "time": 44264.7475810051, "episode/length": 180.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 1006376, "time": 44271.390763282776, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 1007480, "time": 44308.72308397293, "episode/length": 316.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9842271293375394, "episode/intrinsic_return": 0.0}
{"step": 1007512, "time": 44311.40178823471, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 1007536, "time": 44313.86876177788, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 1007904, "time": 44328.77733850479, "episode/length": 212.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 1008640, "time": 44354.013402700424, "episode/length": 391.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 1008760, "time": 44359.22758221626, "episode/length": 317.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 1009264, "time": 44377.42066001892, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9944598337950139, "episode/intrinsic_return": 0.0}
{"step": 1009568, "time": 44388.86343765259, "episode/length": 253.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 1009584, "time": 44390.86133313179, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1009656, "time": 44394.43108153343, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 1009728, "time": 44398.560286045074, "episode/length": 276.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 1009984, "time": 44408.58510327339, "episode/length": 312.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 1009993, "time": 44411.16289615631, "train_stats/sum_log_reward": 9.313592447817904, "train_stats/max_log_achievement_collect_coal": 1.116504854368932, "train_stats/max_log_achievement_collect_drink": 5.757281553398058, "train_stats/max_log_achievement_collect_iron": 0.0, "train_stats/max_log_achievement_collect_sapling": 1.233009708737864, "train_stats/max_log_achievement_collect_stone": 18.941747572815533, "train_stats/max_log_achievement_collect_wood": 8.45631067961165, "train_stats/max_log_achievement_defeat_skeleton": 0.05825242718446602, "train_stats/max_log_achievement_defeat_zombie": 0.6019417475728155, "train_stats/max_log_achievement_eat_cow": 0.06796116504854369, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6213592233009708, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_furnace": 2.5533980582524274, "train_stats/max_log_achievement_place_plant": 1.1941747572815533, "train_stats/max_log_achievement_place_stone": 5.990291262135922, "train_stats/max_log_achievement_place_table": 2.0097087378640777, "train_stats/max_log_achievement_wake_up": 1.174757281553398, "train_stats/mean_log_entropy": 0.32434467002026085, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.102326693600172, "train/action_min": 0.0, "train/action_std": 3.033288052637283, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03445006649277798, "train/actor_opt_grad_steps": 62295.0, "train/actor_opt_loss": -4.4943358813450764, "train/adv_mag": 0.43967265013146073, "train/adv_max": 0.39525918193059423, "train/adv_mean": 0.003532791129650645, "train/adv_min": -0.3715728253942646, "train/adv_std": 0.051899180811357824, "train/cont_avg": 0.994976723030822, "train/cont_loss_mean": 0.0001865165967871786, "train/cont_loss_std": 0.005700166389417923, "train/cont_neg_acc": 0.987377692167073, "train/cont_neg_loss": 0.030635464367244587, "train/cont_pos_acc": 0.9999797936171702, "train/cont_pos_loss": 5.8366154224144065e-05, "train/cont_pred": 0.9949968538872184, "train/cont_rate": 0.994976723030822, "train/dyn_loss_mean": 12.785803076339095, "train/dyn_loss_std": 9.49160023258157, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9569974210980821, "train/extr_critic_critic_opt_grad_steps": 62295.0, "train/extr_critic_critic_opt_loss": 16064.327061483305, "train/extr_critic_mag": 9.108566924317243, "train/extr_critic_max": 9.108566924317243, "train/extr_critic_mean": 2.795910943860877, "train/extr_critic_min": -0.22092298122301493, "train/extr_critic_std": 2.196392736206316, "train/extr_return_normed_mag": 1.476118601348302, "train/extr_return_normed_max": 1.476118601348302, "train/extr_return_normed_mean": 0.4076776458588365, "train/extr_return_normed_min": -0.08589533172956068, "train/extr_return_normed_std": 0.3242906517770192, "train/extr_return_rate": 0.8130757241216424, "train/extr_return_raw_mag": 10.17567962489716, "train/extr_return_raw_max": 10.17567962489716, "train/extr_return_raw_mean": 2.8201432530194115, "train/extr_return_raw_min": -0.5782479004908915, "train/extr_return_raw_std": 2.233752937349555, "train/extr_reward_mag": 1.0413129950222904, "train/extr_reward_max": 1.0413129950222904, "train/extr_reward_mean": 0.04634350012630632, "train/extr_reward_min": -0.48541336843412214, "train/extr_reward_std": 0.20086307772626616, "train/image_loss_mean": 6.399723626162908, "train/image_loss_std": 11.848532477470293, "train/model_loss_mean": 14.127967266187277, "train/model_loss_std": 15.745097630644498, "train/model_opt_grad_norm": 53.252879678386535, "train/model_opt_grad_steps": 62235.71232876712, "train/model_opt_loss": 18040.65487879923, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1284.2465753424658, "train/policy_entropy_mag": 2.544303965895143, "train/policy_entropy_max": 2.544303965895143, "train/policy_entropy_mean": 0.4978579223564226, "train/policy_entropy_min": 0.07937501636269974, "train/policy_entropy_std": 0.6517497380710628, "train/policy_logprob_mag": 7.438383830736761, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4978765908577671, "train/policy_logprob_min": -7.438383830736761, "train/policy_logprob_std": 1.0744696190095928, "train/policy_randomness_mag": 0.8980276445819907, "train/policy_randomness_max": 0.8980276445819907, "train/policy_randomness_mean": 0.17572199910470884, "train/policy_randomness_min": 0.028015897507230714, "train/policy_randomness_std": 0.23003905868693575, "train/post_ent_mag": 60.565965521825504, "train/post_ent_max": 60.565965521825504, "train/post_ent_mean": 43.8010090867134, "train/post_ent_min": 20.022085568676257, "train/post_ent_std": 7.90161802670727, "train/prior_ent_mag": 70.26120611739485, "train/prior_ent_max": 70.26120611739485, "train/prior_ent_mean": 56.68161300763692, "train/prior_ent_min": 38.75831896638217, "train/prior_ent_std": 5.062369251904422, "train/rep_loss_mean": 12.785803076339095, "train/rep_loss_std": 9.49160023258157, "train/reward_avg": 0.02945339224263005, "train/reward_loss_mean": 0.05657546620254647, "train/reward_loss_std": 0.24961151580696236, "train/reward_max_data": 1.0164383600835931, "train/reward_max_pred": 1.0150612658017302, "train/reward_neg_acc": 0.9926292786042984, "train/reward_neg_loss": 0.028985094967974374, "train/reward_pos_acc": 0.9690858048118957, "train/reward_pos_loss": 0.8395646002194653, "train/reward_pred": 0.028576023442900344, "train/reward_rate": 0.03395226883561644, "eval_stats/sum_log_reward": 9.037500202655792, "eval_stats/max_log_achievement_collect_coal": 1.0625, "eval_stats/max_log_achievement_collect_drink": 3.8125, "eval_stats/max_log_achievement_collect_iron": 0.0, "eval_stats/max_log_achievement_collect_sapling": 1.0, "eval_stats/max_log_achievement_collect_stone": 18.75, "eval_stats/max_log_achievement_collect_wood": 6.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 2.5625, "eval_stats/max_log_achievement_place_plant": 1.0, "eval_stats/max_log_achievement_place_stone": 5.9375, "eval_stats/max_log_achievement_place_table": 1.5625, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.5714645996922627e-05, "report/cont_loss_std": 0.00020370491256471723, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007750749937258661, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.123904439737089e-05, "report/cont_pred": 0.9941340088844299, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.378239631652832, "report/dyn_loss_std": 9.40127182006836, "report/image_loss_mean": 5.927340030670166, "report/image_loss_std": 9.663987159729004, "report/model_loss_mean": 13.40717887878418, "report/model_loss_std": 13.913257598876953, "report/post_ent_mag": 60.946380615234375, "report/post_ent_max": 60.946380615234375, "report/post_ent_mean": 44.4766845703125, "report/post_ent_min": 21.40032958984375, "report/post_ent_std": 7.810690879821777, "report/prior_ent_mag": 69.31974792480469, "report/prior_ent_max": 69.31974792480469, "report/prior_ent_mean": 56.82856750488281, "report/prior_ent_min": 34.30109786987305, "report/prior_ent_std": 4.744164943695068, "report/rep_loss_mean": 12.378239631652832, "report/rep_loss_std": 9.40127182006836, "report/reward_avg": 0.03564453125, "report/reward_loss_mean": 0.05287949740886688, "report/reward_loss_std": 0.2039729803800583, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006370544433594, "report/reward_neg_acc": 0.9979633688926697, "report/reward_neg_loss": 0.02133028768002987, "report/reward_pos_acc": 0.9761905074119568, "report/reward_pos_loss": 0.7905300855636597, "report/reward_pred": 0.03351426497101784, "report/reward_rate": 0.041015625, "eval/cont_avg": 0.9912109375, "eval/cont_loss_mean": 0.002213933039456606, "eval/cont_loss_std": 0.056700631976127625, "eval/cont_neg_acc": 0.8888888955116272, "eval/cont_neg_loss": 0.24524590373039246, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.896967195440084e-05, "eval/cont_pred": 0.9923146963119507, "eval/cont_rate": 0.9912109375, "eval/dyn_loss_mean": 16.87047004699707, "eval/dyn_loss_std": 10.379632949829102, "eval/image_loss_mean": 10.672253608703613, "eval/image_loss_std": 12.502405166625977, "eval/model_loss_mean": 20.910560607910156, "eval/model_loss_std": 16.825037002563477, "eval/post_ent_mag": 58.55691909790039, "eval/post_ent_max": 58.55691909790039, "eval/post_ent_mean": 43.36820983886719, "eval/post_ent_min": 20.67873764038086, "eval/post_ent_std": 8.047486305236816, "eval/prior_ent_mag": 69.31974792480469, "eval/prior_ent_max": 69.31974792480469, "eval/prior_ent_mean": 58.46065902709961, "eval/prior_ent_min": 41.67797088623047, "eval/prior_ent_std": 5.078832149505615, "eval/rep_loss_mean": 16.87047004699707, "eval/rep_loss_std": 10.379632949829102, "eval/reward_avg": 0.04277343675494194, "eval/reward_loss_mean": 0.11381155997514725, "eval/reward_loss_std": 0.574389636516571, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0486674308776855, "eval/reward_neg_acc": 0.9927909970283508, "eval/reward_neg_loss": 0.06205242872238159, "eval/reward_pos_acc": 0.9622641801834106, "eval/reward_pos_loss": 1.0620779991149902, "eval/reward_pred": 0.04192778468132019, "eval/reward_rate": 0.0517578125, "replay/size": 1000000.0, "replay/inserts": 23464.0, "replay/samples": 23472.0, "replay/insert_wait_avg": 1.2773744815289262e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.757745637484124e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5600.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1533073016575404e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0511441230774, "timer/env.step_count": 2933.0, "timer/env.step_total": 235.01915168762207, "timer/env.step_frac": 0.23500713245391577, "timer/env.step_avg": 0.08012927094702423, "timer/env.step_min": 0.02277827262878418, "timer/env.step_max": 2.966832399368286, "timer/replay._sample_count": 23472.0, "timer/replay._sample_total": 11.877905130386353, "timer/replay._sample_frac": 0.011877297676412163, "timer/replay._sample_avg": 0.0005060457195972373, "timer/replay._sample_min": 0.0004012584686279297, "timer/replay._sample_max": 0.010709285736083984, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3633.0, "timer/agent.policy_total": 56.29626727104187, "timer/agent.policy_frac": 0.05629338819506758, "timer/agent.policy_avg": 0.015495807121123554, "timer/agent.policy_min": 0.00845479965209961, "timer/agent.policy_max": 0.10266351699829102, "timer/dataset_train_count": 1467.0, "timer/dataset_train_total": 0.1735525131225586, "timer/dataset_train_frac": 0.00017354363738540885, "timer/dataset_train_avg": 0.0001183043715900195, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.021672964096069336, "timer/agent.train_count": 1467.0, "timer/agent.train_total": 636.3474318981171, "timer/agent.train_frac": 0.6363148881311625, "timer/agent.train_avg": 0.4337746638705638, "timer/agent.train_min": 0.42293620109558105, "timer/agent.train_max": 1.51930570602417, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4865422248840332, "timer/agent.report_frac": 0.0004865173423811952, "timer/agent.report_avg": 0.2432711124420166, "timer/agent.report_min": 0.23778510093688965, "timer/agent.report_max": 0.24875712394714355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.910064697265625e-05, "timer/dataset_eval_frac": 3.909864730662624e-08, "timer/dataset_eval_avg": 3.910064697265625e-05, "timer/dataset_eval_min": 3.910064697265625e-05, "timer/dataset_eval_max": 3.910064697265625e-05, "fps": 23.462487573569355}
{"step": 1010048, "time": 44429.83396267891, "eval_episode/length": 110.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.990990990990991}
{"step": 1010048, "time": 44432.65618348122, "eval_episode/length": 139.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 1010048, "time": 44435.60971283913, "eval_episode/length": 173.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 1010048, "time": 44437.408415555954, "eval_episode/length": 180.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.994475138121547}
{"step": 1010048, "time": 44439.88266015053, "eval_episode/length": 202.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 1010048, "time": 44441.73523187637, "eval_episode/length": 209.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 1010048, "time": 44444.11532783508, "eval_episode/length": 230.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 1010048, "time": 44449.232592105865, "eval_episode/length": 312.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9968051118210862}
{"step": 1010264, "time": 44455.94236159325, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901477832512315, "episode/intrinsic_return": 0.0}
{"step": 1010856, "time": 44476.61167931557, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1011008, "time": 44483.201300382614, "episode/length": 280.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1011136, "time": 44488.80332112312, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 1011240, "time": 44493.582129240036, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 1011288, "time": 44496.6190161705, "episode/length": 194.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 1011296, "time": 44498.52350687981, "episode/length": 128.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9922480620155039, "episode/intrinsic_return": 0.0}
{"step": 1011480, "time": 44505.89486503601, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1012400, "time": 44537.106674194336, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1012512, "time": 44542.20053625107, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 1012552, "time": 44544.71321964264, "episode/length": 133.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 1012640, "time": 44549.342822790146, "episode/length": 381.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.0}
{"step": 1012640, "time": 44549.35089993477, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 1013024, "time": 44564.81053352356, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1013408, "time": 44578.64921283722, "episode/length": 318.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 1013992, "time": 44598.82852959633, "episode/length": 343.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 1014304, "time": 44610.56229352951, "episode/length": 223.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 1014520, "time": 44618.946425914764, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 1014776, "time": 44628.711361169815, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 1014912, "time": 44634.82965993881, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 1015184, "time": 44645.255367040634, "episode/length": 50.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 1015312, "time": 44650.905005931854, "episode/length": 164.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1015320, "time": 44652.4048807621, "episode/length": 238.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 1015480, "time": 44659.042560100555, "episode/length": 365.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 1015592, "time": 44664.16257691383, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.989159891598916, "episode/intrinsic_return": 0.0}
{"step": 1015704, "time": 44669.26867055893, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1016328, "time": 44692.29005241394, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1016832, "time": 44710.3249733448, "episode/length": 154.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 1017064, "time": 44719.04514670372, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 1017272, "time": 44727.29301452637, "episode/length": 244.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 1017536, "time": 44737.48627972603, "episode/length": 327.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9847560975609756, "episode/intrinsic_return": 0.0}
{"step": 1017832, "time": 44748.25694608688, "episode/length": 413.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9975845410628019, "episode/intrinsic_return": 0.0}
{"step": 1017984, "time": 44754.83187699318, "episode/length": 332.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984984984984985, "episode/intrinsic_return": 0.0}
{"step": 1017992, "time": 44756.39005613327, "episode/length": 285.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 1018032, "time": 44759.46067452431, "episode/length": 61.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 1018512, "time": 44776.53597474098, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 1018608, "time": 44781.098533153534, "episode/length": 284.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1018824, "time": 44789.321056842804, "episode/length": 248.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 1018968, "time": 44795.42651486397, "episode/length": 116.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 1019024, "time": 44798.99688100815, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1019072, "time": 44802.054419755936, "episode/length": 134.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 1019184, "time": 44807.065799713135, "episode/length": 168.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
