{"step": 1360, "time": 126.21959471702576, "episode/length": 169.0, "episode/score": 0.535035413041669, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.06316040228489328}
{"step": 1560, "time": 150.4388666152954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.4478120803833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.4578127861023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.46414351463318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.47040700912476, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.47656536102295, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.48273015022278, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 150.48906016349792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 273.6624336242676, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.85614013671875, "train/action_min": 0.0, "train/action_std": 1.8609813451766968, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008905932772904634, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -1.7944833040237427, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.998046875, "train/cont_loss_mean": 0.6057953834533691, "train/cont_loss_std": 0.2560645043849945, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 0.9919320344924927, "train/cont_pos_acc": 0.6771036982536316, "train/cont_pos_loss": 0.6050397157669067, "train/cont_pred": 0.5628912448883057, "train/cont_rate": 0.998046875, "train/dyn_loss_mean": 10.99018669128418, "train/dyn_loss_std": 0.360476016998291, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 10.043615341186523, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 40035.171875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5008.38623046875, "train/image_loss_std": 40.027809143066406, "train/model_loss_mean": 5021.1279296875, "train/model_loss_std": 40.00346374511719, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50211280.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.934278130531311, "train/policy_entropy_max": 1.934278130531311, "train/policy_entropy_mean": 1.6483901739120483, "train/policy_entropy_min": 0.7221497893333435, "train/policy_entropy_std": 0.13966836035251617, "train/policy_logprob_mag": 4.552525997161865, "train/policy_logprob_max": -0.17354606091976166, "train/policy_logprob_mean": -1.655091643333435, "train/policy_logprob_min": -4.552525997161865, "train/policy_logprob_std": 0.7186247706413269, "train/policy_randomness_mag": 0.9940223693847656, "train/policy_randomness_max": 0.9940223693847656, "train/policy_randomness_mean": 0.847105085849762, "train/policy_randomness_min": 0.37111160159111023, "train/policy_randomness_std": 0.07177533954381943, "train/post_ent_mag": 105.63153839111328, "train/post_ent_max": 105.63153839111328, "train/post_ent_mean": 105.30377197265625, "train/post_ent_min": 104.95295715332031, "train/post_ent_std": 0.11065018177032471, "train/prior_ent_mag": 106.32019805908203, "train/prior_ent_max": 106.32019805908203, "train/prior_ent_mean": 105.58714294433594, "train/prior_ent_min": 104.76918029785156, "train/prior_ent_std": 0.2593315541744232, "train/rep_loss_mean": 10.99018669128418, "train/rep_loss_std": 0.360476016998291, "train/reward_avg": 0.0012296425411477685, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.787751895994006e-07, "train/reward_max_data": 0.47312501072883606, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.001953125, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.6078053712844849, "report/cont_loss_std": 0.25327759981155396, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 0.9965183734893799, "report/cont_pos_acc": 0.6653620004653931, "report/cont_pos_loss": 0.6070446372032166, "report/cont_pred": 0.5617117285728455, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 10.995245933532715, "report/dyn_loss_std": 0.37876757979393005, "report/image_loss_mean": 5010.9208984375, "report/image_loss_std": 40.03861999511719, "report/model_loss_mean": 5023.6669921875, "report/model_loss_std": 40.0471076965332, "report/post_ent_mag": 105.64813232421875, "report/post_ent_max": 105.64813232421875, "report/post_ent_mean": 105.31172180175781, "report/post_ent_min": 104.94590759277344, "report/post_ent_std": 0.10516182333230972, "report/prior_ent_mag": 106.2506332397461, "report/prior_ent_max": 106.2506332397461, "report/prior_ent_mean": 105.55571746826172, "report/prior_ent_min": 104.42889404296875, "report/prior_ent_std": 0.28433674573898315, "report/rep_loss_mean": 10.995245933532715, "report/rep_loss_std": 0.37876757979393005, "report/reward_avg": 0.0012296425411477685, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.787751895994006e-07, "report/reward_max_data": 0.47312501072883606, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.001953125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.6798469424247742, "eval/cont_loss_std": 0.2896100878715515, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.578125, "eval/cont_pos_loss": 0.6798469424247742, "eval/cont_pred": 0.5269622206687927, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 11.043779373168945, "eval/dyn_loss_std": 0.36890920996665955, "eval/image_loss_mean": 4998.8154296875, "eval/image_loss_std": 38.26459884643555, "eval/model_loss_mean": 5011.66259765625, "eval/model_loss_std": 38.27133560180664, "eval/post_ent_mag": 105.6070556640625, "eval/post_ent_max": 105.6070556640625, "eval/post_ent_mean": 105.28947448730469, "eval/post_ent_min": 104.94449615478516, "eval/post_ent_std": 0.10919646918773651, "eval/prior_ent_mag": 106.30194091796875, "eval/prior_ent_max": 106.30194091796875, "eval/prior_ent_mean": 105.55811309814453, "eval/prior_ent_min": 104.7650375366211, "eval/prior_ent_std": 0.2669561803340912, "eval/rep_loss_mean": 11.043779373168945, "eval/rep_loss_std": 0.36890920996665955, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 5.37152321922858e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.514442716326033e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.9305675443164526e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.621386119297572e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 150.03245663642883, "timer/env.step_count": 196.0, "timer/env.step_total": 1.3917460441589355, "timer/env.step_frac": 0.009276299777797618, "timer/env.step_avg": 0.007100745123259875, "timer/env.step_min": 0.006249189376831055, "timer/env.step_max": 0.020273685455322266, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.09478378295898438, "timer/replay._sample_frac": 0.0006317551887367435, "timer/replay._sample_avg": 0.0008462837764195033, "timer/replay._sample_min": 0.0003361701965332031, "timer/replay._sample_max": 0.00530242919921875, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.1034979820251465, "timer/agent.save_frac": 0.014020286204621165, "timer/agent.save_avg": 2.1034979820251465, "timer/agent.save_min": 2.1034979820251465, "timer/agent.save_max": 2.1034979820251465, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.040523052215576, "timer/agent.policy_frac": 0.1469050333930478, "timer/agent.policy_avg": 0.07600180362832958, "timer/agent.policy_min": 0.009128332138061523, "timer/agent.policy_max": 16.927510738372803, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.1948089599609375e-05, "timer/dataset_train_frac": 2.1294118829920017e-07, "timer/dataset_train_avg": 3.1948089599609375e-05, "timer/dataset_train_min": 3.1948089599609375e-05, "timer/dataset_train_max": 3.1948089599609375e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 90.46660089492798, "timer/agent.train_frac": 0.6029802012384173, "timer/agent.train_avg": 90.46660089492798, "timer/agent.train_min": 90.46660089492798, "timer/agent.train_max": 90.46660089492798, "timer/agent.report_count": 2.0, "timer/agent.report_total": 30.322015285491943, "timer/agent.report_frac": 0.2021030380044418, "timer/agent.report_avg": 15.161007642745972, "timer/agent.report_min": 7.3958964347839355, "timer/agent.report_max": 22.926118850708008, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.57763671875e-05, "timer/dataset_eval_frac": 3.0510976233915246e-07, "timer/dataset_eval_avg": 4.57763671875e-05, "timer/dataset_eval_min": 4.57763671875e-05, "timer/dataset_eval_max": 4.57763671875e-05}
{"step": 2312, "time": 297.21708703041077, "episode/length": 288.0, "episode/score": 0.07568338586895607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07568338586895607}
{"step": 2312, "time": 297.22566843032837, "episode/length": 288.0, "episode/score": 0.09361807139043776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09361807139043776}
{"step": 2312, "time": 297.2331292629242, "episode/length": 288.0, "episode/score": 0.07631379297572494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07631379297572494}
{"step": 2312, "time": 297.2405378818512, "episode/length": 288.0, "episode/score": 0.07098555045206467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07098555045206467}
{"step": 2312, "time": 297.2474675178528, "episode/length": 288.0, "episode/score": 0.055695192038911046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055695192038911046}
{"step": 2312, "time": 297.267520904541, "episode/length": 288.0, "episode/score": 0.07216681950433212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07216681950433212}
{"step": 2312, "time": 297.2753396034241, "episode/length": 288.0, "episode/score": 0.10338054381804795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10338054381804795}
{"step": 3672, "time": 340.44370675086975, "episode/length": 288.0, "episode/score": 0.07150950413256396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07150950413256396}
{"step": 4624, "time": 370.9737992286682, "episode/length": 288.0, "episode/score": 0.05275822504466987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05275822504466987}
{"step": 4624, "time": 370.9827473163605, "episode/length": 288.0, "episode/score": 0.059207889317292484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059207889317292484}
{"step": 4624, "time": 370.99163794517517, "episode/length": 288.0, "episode/score": 0.05371621984664898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05371621984664898}
{"step": 4624, "time": 370.99963998794556, "episode/length": 288.0, "episode/score": 0.08536167262218441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08536167262218441}
{"step": 4624, "time": 371.0201802253723, "episode/length": 288.0, "episode/score": 0.07061807596085146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07061807596085146}
{"step": 4624, "time": 371.0462222099304, "episode/length": 288.0, "episode/score": 0.060466882274511136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060466882274511136}
{"step": 4624, "time": 371.0532808303833, "episode/length": 288.0, "episode/score": 0.0842168545410118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0842168545410118}
{"step": 5984, "time": 414.249685049057, "episode/length": 288.0, "episode/score": 0.053220450887181414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053220450887181414}
{"step": 6936, "time": 444.05670166015625, "episode/length": 288.0, "episode/score": 0.04693071089229761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04693071089229761}
{"step": 6936, "time": 444.06496024131775, "episode/length": 288.0, "episode/score": 0.047036180579993925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047036180579993925}
{"step": 6936, "time": 444.07235622406006, "episode/length": 288.0, "episode/score": 0.03787100846193425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03787100846193425}
{"step": 6936, "time": 444.0794734954834, "episode/length": 288.0, "episode/score": 0.038365185440000005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038365185440000005}
{"step": 6936, "time": 444.0866582393646, "episode/length": 288.0, "episode/score": 0.039921301855656566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039921301855656566}
{"step": 6936, "time": 444.0937259197235, "episode/length": 288.0, "episode/score": 0.04668535388907458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04668535388907458}
{"step": 6936, "time": 444.10059809684753, "episode/length": 288.0, "episode/score": 0.05801775573644363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05801775573644363}
{"step": 8008, "time": 478.08692240715027, "episode/length": 133.0, "episode/score": 0.63096955245544, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.04659449997541287}
{"step": 8296, "time": 487.6522705554962, "episode/length": 288.0, "episode/score": 0.05291426092543361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05291426092543361}
{"step": 9112, "time": 513.3561298847198, "episode/length": 137.0, "episode/score": 0.6301901476996932, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.05831514290338191}
{"step": 9248, "time": 517.8529508113861, "episode/length": 288.0, "episode/score": 0.07535329948137814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07535329948137814}
{"step": 9248, "time": 517.8611581325531, "episode/length": 288.0, "episode/score": 0.0630745538537667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0630745538537667}
{"step": 9248, "time": 517.8682539463043, "episode/length": 288.0, "episode/score": 0.042139826484969944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042139826484969944}
{"step": 9248, "time": 517.87526679039, "episode/length": 288.0, "episode/score": 0.044843358515606724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044843358515606724}
{"step": 9248, "time": 517.8823492527008, "episode/length": 288.0, "episode/score": 0.06803864244682245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06803864244682245}
{"step": 9248, "time": 517.8899719715118, "episode/length": 288.0, "episode/score": 0.07542675414657651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07542675414657651}
{"step": 10088, "time": 549.3577711582184, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.3654639720917, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.3718764781952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.3783538341522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.3845958709717, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.3906219005585, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.3972699642181, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 549.4038934707642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10608, "time": 566.0957412719727, "episode/length": 288.0, "episode/score": 0.06297588716392966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06297588716392966}
{"step": 10784, "time": 571.6237480640411, "episode/length": 21.0, "episode/score": 0.947440579713998, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.013065592449834185}
{"step": 11424, "time": 591.8801567554474, "episode/length": 288.0, "episode/score": 0.07759814830831147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07759814830831147}
{"step": 11560, "time": 595.9808676242828, "episode/length": 288.0, "episode/score": 0.058349656823907026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058349656823907026}
{"step": 11560, "time": 595.989972114563, "episode/length": 288.0, "episode/score": 0.07573990532887365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07573990532887365}
{"step": 11560, "time": 595.9972443580627, "episode/length": 288.0, "episode/score": 0.06417607842263351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06417607842263351}
{"step": 11560, "time": 596.0046138763428, "episode/length": 288.0, "episode/score": 0.05872276696265999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05872276696265999}
{"step": 11560, "time": 596.0118229389191, "episode/length": 288.0, "episode/score": 0.07050254251021215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07050254251021215}
{"step": 11560, "time": 596.0191612243652, "episode/length": 288.0, "episode/score": 0.06785225180681209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06785225180681209}
{"step": 13096, "time": 644.4161503314972, "episode/length": 288.0, "episode/score": 0.06634911393484799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06634911393484799}
{"step": 13736, "time": 664.5633027553558, "episode/length": 288.0, "episode/score": 0.051713948563531176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051713948563531176}
{"step": 13872, "time": 669.0569152832031, "episode/length": 288.0, "episode/score": 0.0402558742177348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0402558742177348}
{"step": 13872, "time": 669.065780878067, "episode/length": 288.0, "episode/score": 0.05633707170107982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05633707170107982}
{"step": 13872, "time": 669.073805809021, "episode/length": 288.0, "episode/score": 0.03318511415807279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03318511415807279}
{"step": 13872, "time": 669.0811276435852, "episode/length": 288.0, "episode/score": 0.045633002706210846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045633002706210846}
{"step": 13872, "time": 669.0898129940033, "episode/length": 288.0, "episode/score": 0.05418440578864647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05418440578864647}
{"step": 13872, "time": 669.0983271598816, "episode/length": 288.0, "episode/score": 0.060232277989598515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060232277989598515}
{"step": 14976, "time": 704.144537448883, "episode/length": 154.0, "episode/score": 0.554731242143987, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.035981206881785965}
{"step": 15408, "time": 718.0811975002289, "episode/length": 288.0, "episode/score": 0.05750525168923559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05750525168923559}
{"step": 16184, "time": 742.4015371799469, "episode/length": 288.0, "episode/score": 0.0592231406483279, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0592231406483279}
{"step": 16184, "time": 742.4100089073181, "episode/length": 288.0, "episode/score": 0.07204033104824248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07204033104824248}
{"step": 16184, "time": 742.4174766540527, "episode/length": 288.0, "episode/score": 0.03613670122331314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03613670122331314}
{"step": 16184, "time": 742.4245283603668, "episode/length": 288.0, "episode/score": 0.03301466329395453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03301466329395453}
{"step": 16184, "time": 742.4314022064209, "episode/length": 288.0, "episode/score": 0.06419960382140744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06419960382140744}
{"step": 16184, "time": 742.438333272934, "episode/length": 288.0, "episode/score": 0.06769181465807605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06769181465807605}
{"step": 17112, "time": 772.3781411647797, "episode/length": 115.0, "episode/score": 0.666921150328136, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.026296121689966867}
{"step": 17288, "time": 779.0765907764435, "episode/length": 288.0, "episode/score": 0.06225105211046866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06225105211046866}
{"step": 17720, "time": 792.9411828517914, "episode/length": 288.0, "episode/score": 0.04981503981184687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04981503981184687}
{"step": 18496, "time": 817.4844734668732, "episode/length": 288.0, "episode/score": 0.07773624334765827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07773624334765827}
{"step": 18496, "time": 817.4926257133484, "episode/length": 288.0, "episode/score": 0.06435639188066489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06435639188066489}
{"step": 18496, "time": 817.4996502399445, "episode/length": 288.0, "episode/score": 0.05367955720743112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05367955720743112}
{"step": 18496, "time": 817.5065813064575, "episode/length": 288.0, "episode/score": 0.07877914191320201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07877914191320201}
{"step": 18496, "time": 817.514128446579, "episode/length": 288.0, "episode/score": 0.07344989541400082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07344989541400082}
{"step": 19424, "time": 846.8140985965729, "episode/length": 288.0, "episode/score": 0.08750443079023285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08750443079023285}
{"step": 19600, "time": 852.4128823280334, "episode/length": 288.0, "episode/score": 0.056943450992719136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056943450992719136}
{"step": 20032, "time": 865.9348967075348, "episode/length": 288.0, "episode/score": 0.06788911099886263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06788911099886263}
{"step": 20072, "time": 872.8595533370972, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.8681712150574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.8751604557037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.8818669319153, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.8885500431061, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.8951725959778, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.9017255306244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 872.9083542823792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20808, "time": 896.2774193286896, "episode/length": 288.0, "episode/score": 0.07776675851209802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07776675851209802}
{"step": 20808, "time": 896.2856521606445, "episode/length": 288.0, "episode/score": 0.07556234273317841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07556234273317841}
{"step": 20808, "time": 896.2926323413849, "episode/length": 288.0, "episode/score": 0.06359804747000908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06359804747000908}
{"step": 20808, "time": 896.2997465133667, "episode/length": 288.0, "episode/score": 0.05288294065303489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05288294065303489}
{"step": 20808, "time": 896.3069341182709, "episode/length": 288.0, "episode/score": 0.0729017365144955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0729017365144955}
{"step": 21736, "time": 925.6362018585205, "episode/length": 288.0, "episode/score": 0.07761022752970348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07761022752970348}
{"step": 21912, "time": 931.1725652217865, "episode/length": 288.0, "episode/score": 0.08099237493405553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08099237493405553}
{"step": 22344, "time": 944.8468914031982, "episode/length": 288.0, "episode/score": 0.06366919547082261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06366919547082261}
{"step": 23120, "time": 969.3103761672974, "episode/length": 288.0, "episode/score": 0.04320625146073098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04320625146073098}
{"step": 23120, "time": 969.3185868263245, "episode/length": 288.0, "episode/score": 0.043942878230438964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043942878230438964}
{"step": 23120, "time": 969.3256902694702, "episode/length": 288.0, "episode/score": 0.058410688353092155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058410688353092155}
{"step": 23120, "time": 969.3327519893646, "episode/length": 288.0, "episode/score": 0.05933618808438723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05933618808438723}
{"step": 23120, "time": 969.3400490283966, "episode/length": 288.0, "episode/score": 0.055613061719043344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055613061719043344}
{"step": 23944, "time": 995.0262863636017, "episode/length": 275.0, "episode/score": 0.1860029161778698, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.04537791734202301}
{"step": 24224, "time": 1004.2394907474518, "episode/length": 288.0, "episode/score": 0.07596871094170865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07596871094170865}
{"step": 24656, "time": 1018.5537669658661, "episode/length": 288.0, "episode/score": 0.07516448520584618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07516448520584618}
{"step": 25432, "time": 1043.187950372696, "episode/length": 288.0, "episode/score": 0.06159020818142835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06159020818142835}
{"step": 25432, "time": 1043.1961605548859, "episode/length": 288.0, "episode/score": 0.05288452434950841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05288452434950841}
{"step": 25432, "time": 1043.2040259838104, "episode/length": 288.0, "episode/score": 0.0675442631637111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0675442631637111}
{"step": 25432, "time": 1043.2109959125519, "episode/length": 288.0, "episode/score": 0.07283423639529474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07283423639529474}
{"step": 25432, "time": 1043.2180032730103, "episode/length": 288.0, "episode/score": 0.06119810930067615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06119810930067615}
{"step": 26256, "time": 1069.3280744552612, "episode/length": 288.0, "episode/score": 0.04681997311723762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04681997311723762}
{"step": 26536, "time": 1077.9324543476105, "episode/length": 288.0, "episode/score": 0.041039612251267954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041039612251267954}
{"step": 26968, "time": 1091.5882828235626, "episode/length": 288.0, "episode/score": 0.048953719358962644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048953719358962644}
{"step": 27744, "time": 1116.2606616020203, "episode/length": 288.0, "episode/score": 0.06767989780652783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06767989780652783}
{"step": 27744, "time": 1116.2688956260681, "episode/length": 288.0, "episode/score": 0.05254677962361143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05254677962361143}
{"step": 27744, "time": 1116.2759628295898, "episode/length": 288.0, "episode/score": 0.04828218083778779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04828218083778779}
{"step": 27744, "time": 1116.2827785015106, "episode/length": 288.0, "episode/score": 0.05370153292062696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05370153292062696}
{"step": 27744, "time": 1116.2901692390442, "episode/length": 288.0, "episode/score": 0.053295315878727934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053295315878727934}
{"step": 28568, "time": 1142.1603200435638, "episode/length": 288.0, "episode/score": 0.05562780828961422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05562780828961422}
{"step": 28848, "time": 1151.260811328888, "episode/length": 288.0, "episode/score": 0.0847212073950061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0847212073950061}
{"step": 29280, "time": 1164.9648447036743, "episode/length": 288.0, "episode/score": 0.05581355751553474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05581355751553474}
{"step": 29952, "time": 1186.0959935188293, "episode/length": 137.0, "episode/score": 0.6225806325006715, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.05070562770436027}
{"step": 30056, "time": 1189.1597139835358, "episode/length": 288.0, "episode/score": 0.08746751475382553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08746751475382553}
{"step": 30056, "time": 1189.1677949428558, "episode/length": 288.0, "episode/score": 0.05764368386235219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05764368386235219}
{"step": 30056, "time": 1189.174934387207, "episode/length": 288.0, "episode/score": 0.06383717496862573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06383717496862573}
{"step": 30056, "time": 1189.1820847988129, "episode/length": 288.0, "episode/score": 0.07708731602178887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07708731602178887}
{"step": 30056, "time": 1189.1890349388123, "episode/length": 288.0, "episode/score": 0.05810226051448808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05810226051448808}
{"step": 30056, "time": 1193.3693597316742, "eval_episode/length": 236.0, "eval_episode/score": 0.26249998807907104, "eval_episode/reward_rate": 0.004219409282700422}
{"step": 30056, "time": 1194.2818732261658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1194.2891538143158, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1194.295776128769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1194.301952123642, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1194.308123588562, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1194.3142495155334, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1194.3204879760742, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30488, "time": 1207.8223860263824, "episode/length": 239.0, "episode/score": 0.29987727033562805, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.04675225957885232}
{"step": 31592, "time": 1243.1150228977203, "episode/length": 288.0, "episode/score": 0.06417518861337612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06417518861337612}
{"step": 31593, "time": 1244.1310997009277, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0036020533923797, "train/action_min": 0.0, "train/action_std": 1.999880534442351, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0008047784983372206, "train/actor_opt_grad_steps": 940.0, "train/actor_opt_loss": 22.464085951208432, "train/adv_mag": 0.002527880082942085, "train/adv_max": 0.002526669826602666, "train/adv_mean": 0.001475602061927762, "train/adv_min": 0.00018011285818544362, "train/adv_std": 0.0006866031158770336, "train/cont_avg": 0.9967674214572193, "train/cont_loss_mean": 0.025125721750365704, "train/cont_loss_std": 0.3103342953509299, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.768131943072303, "train/cont_pos_acc": 0.9981983084092165, "train/cont_pos_loss": 0.006552603785273866, "train/cont_pred": 0.9943798241768291, "train/cont_rate": 0.9967674214572193, "train/dyn_loss_mean": 1.0716447607081203, "train/dyn_loss_std": 0.004891147154950964, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.47098845825157, "train/extr_critic_critic_opt_grad_steps": 940.0, "train/extr_critic_critic_opt_loss": 12565.708026090408, "train/extr_critic_mag": 0.02404591680210542, "train/extr_critic_max": 0.024045867078444538, "train/extr_critic_mean": 0.023996445331824493, "train/extr_critic_min": 0.02393082883906237, "train/extr_critic_std": 1.5251468467223266e-05, "train/extr_return_normed_mag": 0.004792861573821605, "train/extr_return_normed_max": 0.004791835068512283, "train/extr_return_normed_mean": 0.0037901617871273583, "train/extr_return_normed_min": 0.002515623597289845, "train/extr_return_normed_std": 0.0006858763445485483, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.02647495085175096, "train/extr_return_raw_max": 0.02647371191251291, "train/extr_return_raw_mean": 0.025472039785568806, "train/extr_return_raw_min": 0.024197500433601932, "train/extr_return_raw_std": 0.0006858763457717457, "train/extr_reward_mag": 0.0003057775650432403, "train/extr_reward_max": 0.0003055914200563482, "train/extr_reward_mean": 0.00030525111013621133, "train/extr_reward_min": 0.00030456124780012326, "train/extr_reward_std": 1.2162728527837043e-07, "train/image_loss_mean": 28.03075708361233, "train/image_loss_std": 0.3920556545297411, "train/model_loss_mean": 28.82296938086576, "train/model_loss_std": 0.6969087159330832, "train/model_opt_grad_norm": 103.51145573585264, "train/model_opt_grad_steps": 930.0, "train/model_opt_loss": 547.7340120325752, "train/model_opt_model_opt_grad_overflow": 0.0053475935828877, "train/model_opt_model_opt_grad_scale": 14.256768048128341, "train/policy_entropy_mag": 1.945768288750062, "train/policy_entropy_max": 1.945768288750062, "train/policy_entropy_mean": 1.9403511126411153, "train/policy_entropy_min": 1.8878954789217781, "train/policy_entropy_std": 0.003223951681539476, "train/policy_logprob_mag": 2.3790331205582236, "train/policy_logprob_max": -1.522905865614427, "train/policy_logprob_mean": -1.9403969234323757, "train/policy_logprob_min": -2.3790331205582236, "train/policy_logprob_std": 0.09482664234418282, "train/policy_randomness_mag": 0.9999271564305148, "train/policy_randomness_max": 0.9999271564305148, "train/policy_randomness_mean": 0.9971432775099647, "train/policy_randomness_min": 0.9701864142468907, "train/policy_randomness_std": 0.0016567835159086806, "train/post_ent_mag": 78.16945968464734, "train/post_ent_max": 78.16945968464734, "train/post_ent_mean": 78.13715062676904, "train/post_ent_min": 77.93588836180335, "train/post_ent_std": 0.0393695675065731, "train/prior_ent_mag": 83.52962085907473, "train/prior_ent_max": 83.52962085907473, "train/prior_ent_mean": 83.43376628855333, "train/prior_ent_min": 83.08070393934607, "train/prior_ent_std": 0.06429716022336547, "train/rep_loss_mean": 1.0716447607081203, "train/rep_loss_std": 0.004891147154950964, "train/reward_avg": 0.0004108841965201605, "train/reward_loss_mean": 0.12409997199049448, "train/reward_loss_std": 0.09604020148662219, "train/reward_max_data": 0.17109336384402757, "train/reward_max_pred": 0.00030565644330519406, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12124346388892375, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.92806241247389, "train/reward_pred": 0.00030492174371897696, "train/reward_rate": 0.00032378008021390374, "train_stats/mean_log_entropy": 1.9268580708238814, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020067276433110237, "report/cont_loss_std": 0.30507132411003113, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.648061752319336, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035305656492710114, "report/cont_pred": 0.9964754581451416, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25268155336380005, "report/image_loss_std": 0.09494587779045105, "report/model_loss_mean": 0.88257896900177, "report/model_loss_std": 0.32485726475715637, "report/post_ent_mag": 61.424251556396484, "report/post_ent_max": 61.424251556396484, "report/post_ent_mean": 61.37840270996094, "report/post_ent_min": 61.32473373413086, "report/post_ent_std": 0.012132642790675163, "report/prior_ent_mag": 70.56692504882812, "report/prior_ent_max": 70.56692504882812, "report/prior_ent_mean": 70.49755859375, "report/prior_ent_min": 70.25300598144531, "report/prior_ent_std": 0.04200519621372223, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018526778148952872, "report/reward_loss_mean": 0.009830161929130554, "report/reward_loss_std": 0.015146896243095398, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00033736228942871094, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009830161929130554, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00033705192618072033, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003530565882101655, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003530565882101655, "eval/cont_pred": 0.9964754581451416, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24327974021434784, "eval/image_loss_std": 0.09050175547599792, "eval/model_loss_mean": 0.8489679098129272, "eval/model_loss_std": 0.09050153195858002, "eval/post_ent_mag": 61.423126220703125, "eval/post_ent_max": 61.423126220703125, "eval/post_ent_mean": 61.37861251831055, "eval/post_ent_min": 61.33067321777344, "eval/post_ent_std": 0.010917955078184605, "eval/prior_ent_mag": 70.56881713867188, "eval/prior_ent_max": 70.56881713867188, "eval/prior_ent_mean": 70.49821472167969, "eval/prior_ent_min": 70.25300598144531, "eval/prior_ent_std": 0.03784448280930519, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0021575912833213806, "eval/reward_loss_std": 2.2571075533051044e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00033736228942871094, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0021575912833213806, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00033707800321280956, "eval/reward_rate": 0.0, "replay/size": 31089.0, "replay/inserts": 30032.0, "replay/samples": 30032.0, "replay/insert_wait_avg": 1.2868109318444114e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.129905244423851e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1475440952604618e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 970.4554307460785, "timer/env.step_count": 3754.0, "timer/env.step_total": 36.900192737579346, "timer/env.step_frac": 0.03802358312242198, "timer/env.step_avg": 0.00982956652572705, "timer/env.step_min": 0.008020639419555664, "timer/env.step_max": 0.03992271423339844, "timer/replay._sample_count": 30032.0, "timer/replay._sample_total": 15.263173341751099, "timer/replay._sample_frac": 0.01572784577032754, "timer/replay._sample_avg": 0.0005082303323705081, "timer/replay._sample_min": 0.0003376007080078125, "timer/replay._sample_max": 0.030437231063842773, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4621.0, "timer/agent.policy_total": 47.16278052330017, "timer/agent.policy_frac": 0.048598605385763875, "timer/agent.policy_avg": 0.010206184921726936, "timer/agent.policy_min": 0.00899052619934082, "timer/agent.policy_max": 0.08594346046447754, "timer/dataset_train_count": 1877.0, "timer/dataset_train_total": 0.200042724609375, "timer/dataset_train_frac": 0.00020613283028936603, "timer/dataset_train_avg": 0.00010657577230121204, "timer/dataset_train_min": 7.486343383789062e-05, "timer/dataset_train_max": 0.0010738372802734375, "timer/agent.train_count": 1877.0, "timer/agent.train_total": 837.1527361869812, "timer/agent.train_frac": 0.8626390348945595, "timer/agent.train_avg": 0.44600571986520043, "timer/agent.train_min": 0.4356117248535156, "timer/agent.train_max": 0.8309013843536377, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.476818323135376, "timer/agent.report_frac": 0.0004913345920160412, "timer/agent.report_avg": 0.238409161567688, "timer/agent.report_min": 0.23485541343688965, "timer/agent.report_max": 0.24196290969848633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.611451903668098e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 30.94579406773536}
{"step": 32264, "time": 1264.9843287467957, "episode/length": 288.0, "episode/score": 0.08153862523431599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08153862523431599}
{"step": 32368, "time": 1268.4881494045258, "episode/length": 288.0, "episode/score": 0.047454337870362906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047454337870362906}
{"step": 32368, "time": 1268.4965481758118, "episode/length": 288.0, "episode/score": 0.07100397971748862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07100397971748862}
{"step": 32368, "time": 1268.5038793087006, "episode/length": 288.0, "episode/score": 0.053638746068259024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053638746068259024}
{"step": 32368, "time": 1268.5107724666595, "episode/length": 288.0, "episode/score": 0.06637083856344361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06637083856344361}
{"step": 32368, "time": 1268.51784157753, "episode/length": 288.0, "episode/score": 0.054113406666260744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054113406666260744}
{"step": 32800, "time": 1282.7306604385376, "episode/length": 288.0, "episode/score": 0.07591337381961694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07591337381961694}
{"step": 33904, "time": 1317.3633780479431, "episode/length": 288.0, "episode/score": 0.04594897689435129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04594897689435129}
{"step": 34576, "time": 1338.8727753162384, "episode/length": 288.0, "episode/score": 0.05824423599210604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05824423599210604}
{"step": 34680, "time": 1341.999122619629, "episode/length": 288.0, "episode/score": 0.05962183740189175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05962183740189175}
{"step": 34680, "time": 1342.0085344314575, "episode/length": 288.0, "episode/score": 0.047057063495003604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047057063495003604}
{"step": 34680, "time": 1342.016138792038, "episode/length": 288.0, "episode/score": 0.06615198873095096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06615198873095096}
{"step": 34680, "time": 1342.0236518383026, "episode/length": 288.0, "episode/score": 0.03822120097930792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03822120097930792}
{"step": 34680, "time": 1342.0312063694, "episode/length": 288.0, "episode/score": 0.0629519175267319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0629519175267319}
{"step": 35112, "time": 1355.6226999759674, "episode/length": 288.0, "episode/score": 0.06951080676475385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06951080676475385}
{"step": 35600, "time": 1371.2342941761017, "episode/length": 114.0, "episode/score": 0.6776398372459767, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.033889796686878526}
{"step": 36216, "time": 1390.4305212497711, "episode/length": 288.0, "episode/score": 0.061255864322333764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061255864322333764}
{"step": 36888, "time": 1411.7084743976593, "episode/length": 288.0, "episode/score": 0.05661221014241846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05661221014241846}
{"step": 36992, "time": 1415.2099022865295, "episode/length": 288.0, "episode/score": 0.05907634009741969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05907634009741969}
{"step": 36992, "time": 1415.2183451652527, "episode/length": 288.0, "episode/score": 0.050779404690842966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050779404690842966}
{"step": 36992, "time": 1415.2252316474915, "episode/length": 288.0, "episode/score": 0.05699988436288095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05699988436288095}
{"step": 36992, "time": 1415.2321569919586, "episode/length": 288.0, "episode/score": 0.05039596479315378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05039596479315378}
{"step": 37424, "time": 1428.8973126411438, "episode/length": 288.0, "episode/score": 0.056368659760892115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056368659760892115}
{"step": 37912, "time": 1444.0012793540955, "episode/length": 288.0, "episode/score": 0.04307442206209089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04307442206209089}
{"step": 38528, "time": 1463.6798243522644, "episode/length": 288.0, "episode/score": 0.04884773226217476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04884773226217476}
{"step": 39200, "time": 1484.9371218681335, "episode/length": 288.0, "episode/score": 0.07217510282737294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07217510282737294}
{"step": 39304, "time": 1488.0027000904083, "episode/length": 288.0, "episode/score": 0.05690288591239323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05690288591239323}
{"step": 39304, "time": 1488.0108716487885, "episode/length": 288.0, "episode/score": 0.040274213656914526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040274213656914526}
{"step": 39304, "time": 1488.0179331302643, "episode/length": 288.0, "episode/score": 0.07566978204033603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07566978204033603}
{"step": 39304, "time": 1488.024870634079, "episode/length": 288.0, "episode/score": 0.0705043347247738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0705043347247738}
{"step": 39736, "time": 1501.7066667079926, "episode/length": 288.0, "episode/score": 0.030765924678235024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030765924678235024}
{"step": 40040, "time": 1516.6673724651337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.6762697696686, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.6828699111938, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.6909246444702, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.6978859901428, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.7047414779663, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.7110450267792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1516.7173392772675, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40224, "time": 1522.760354757309, "episode/length": 288.0, "episode/score": 0.04902174440633189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04902174440633189}
{"step": 40840, "time": 1542.0466425418854, "episode/length": 288.0, "episode/score": 0.044529334844810364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044529334844810364}
{"step": 41512, "time": 1563.7182717323303, "episode/length": 288.0, "episode/score": 0.04953189710914785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04953189710914785}
{"step": 41616, "time": 1567.231960773468, "episode/length": 288.0, "episode/score": 0.062055143385521205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062055143385521205}
{"step": 41616, "time": 1567.240228652954, "episode/length": 288.0, "episode/score": 0.07091610358492062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07091610358492062}
{"step": 41616, "time": 1567.2473225593567, "episode/length": 288.0, "episode/score": 0.07444904758750681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07444904758750681}
{"step": 41616, "time": 1567.2545461654663, "episode/length": 288.0, "episode/score": 0.0628424645504424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0628424645504424}
{"step": 42048, "time": 1580.9725790023804, "episode/length": 288.0, "episode/score": 0.06528986542309667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06528986542309667}
{"step": 42096, "time": 1582.5003094673157, "episode/length": 59.0, "episode/score": 0.8299680840645465, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.01434304350544835}
{"step": 42536, "time": 1596.1585562229156, "episode/length": 288.0, "episode/score": 0.07015191512823549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07015191512823549}
{"step": 43152, "time": 1615.9599199295044, "episode/length": 288.0, "episode/score": 0.05482963384247341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05482963384247341}
{"step": 43824, "time": 1637.3638515472412, "episode/length": 288.0, "episode/score": 0.07801600981167667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07801600981167667}
{"step": 43928, "time": 1640.4130761623383, "episode/length": 288.0, "episode/score": 0.03387162604445848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03387162604445848}
{"step": 43928, "time": 1640.4216957092285, "episode/length": 288.0, "episode/score": 0.04195822396258109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04195822396258109}
{"step": 43928, "time": 1640.4292829036713, "episode/length": 288.0, "episode/score": 0.055985522934861365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055985522934861365}
{"step": 44360, "time": 1654.0278792381287, "episode/length": 288.0, "episode/score": 0.04412979425183039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04412979425183039}
{"step": 44408, "time": 1655.5461225509644, "episode/length": 288.0, "episode/score": 0.02945474560800676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02945474560800676}
{"step": 44848, "time": 1669.6738266944885, "episode/length": 288.0, "episode/score": 0.06620858655696793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06620858655696793}
{"step": 45464, "time": 1688.8279519081116, "episode/length": 288.0, "episode/score": 0.061087306930517116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061087306930517116}
{"step": 46136, "time": 1710.033881187439, "episode/length": 288.0, "episode/score": 0.044149760092295764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044149760092295764}
{"step": 46240, "time": 1713.5454196929932, "episode/length": 288.0, "episode/score": 0.03397379996715699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03397379996715699}
{"step": 46240, "time": 1713.5534131526947, "episode/length": 288.0, "episode/score": 0.061258160608815615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061258160608815615}
{"step": 46240, "time": 1713.5612819194794, "episode/length": 288.0, "episode/score": 0.05131208181356328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05131208181356328}
{"step": 46672, "time": 1727.1911418437958, "episode/length": 288.0, "episode/score": 0.04670273847486328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04670273847486328}
{"step": 46720, "time": 1728.7026793956757, "episode/length": 288.0, "episode/score": 0.05446103635108557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05446103635108557}
{"step": 47160, "time": 1742.2935423851013, "episode/length": 288.0, "episode/score": 0.06857350497617176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06857350497617176}
{"step": 47776, "time": 1761.958797454834, "episode/length": 288.0, "episode/score": 0.04624417879725229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04624417879725229}
{"step": 48448, "time": 1783.1571862697601, "episode/length": 288.0, "episode/score": 0.041215090140781285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041215090140781285}
{"step": 48552, "time": 1786.1949155330658, "episode/length": 288.0, "episode/score": 0.055930531078786316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055930531078786316}
{"step": 48552, "time": 1786.2032487392426, "episode/length": 288.0, "episode/score": 0.06311720281320277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06311720281320277}
{"step": 48552, "time": 1786.2104704380035, "episode/length": 288.0, "episode/score": 0.057462439638356955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057462439638356955}
{"step": 48984, "time": 1799.83518075943, "episode/length": 288.0, "episode/score": 0.05275352682528478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05275352682528478}
{"step": 49032, "time": 1801.3502578735352, "episode/length": 288.0, "episode/score": 0.0717588239019733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0717588239019733}
{"step": 49472, "time": 1816.1035985946655, "episode/length": 288.0, "episode/score": 0.04258851371341166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04258851371341166}
{"step": 50024, "time": 1838.431203365326, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.4387118816376, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.4452047348022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.451323747635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.4578185081482, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.4640221595764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.4703812599182, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1838.4768736362457, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50088, "time": 1840.4949233531952, "episode/length": 288.0, "episode/score": 0.05820423579197609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05820423579197609}
{"step": 50760, "time": 1861.6627490520477, "episode/length": 288.0, "episode/score": 0.06127438977611632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06127438977611632}
{"step": 50864, "time": 1865.1808488368988, "episode/length": 288.0, "episode/score": 0.04505739663233044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04505739663233044}
{"step": 50864, "time": 1865.189440727234, "episode/length": 288.0, "episode/score": 0.057545475127511736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057545475127511736}
{"step": 50864, "time": 1865.1969046592712, "episode/length": 288.0, "episode/score": 0.05965170316392232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05965170316392232}
{"step": 51296, "time": 1879.162192106247, "episode/length": 288.0, "episode/score": 0.05782685759203332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05782685759203332}
{"step": 51344, "time": 1880.697946548462, "episode/length": 288.0, "episode/score": 0.0396820833042284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0396820833042284}
{"step": 51784, "time": 1894.2422196865082, "episode/length": 288.0, "episode/score": 0.05699412869606135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05699412869606135}
{"step": 52400, "time": 1913.9418776035309, "episode/length": 288.0, "episode/score": 0.05518585577635804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05518585577635804}
{"step": 53072, "time": 1935.119870185852, "episode/length": 288.0, "episode/score": 0.05597917295193611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05597917295193611}
{"step": 53176, "time": 1938.1729927062988, "episode/length": 288.0, "episode/score": 0.06555986203187558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06555986203187558}
{"step": 53176, "time": 1938.180742740631, "episode/length": 288.0, "episode/score": 0.04473459430514026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04473459430514026}
{"step": 53176, "time": 1938.1876714229584, "episode/length": 288.0, "episode/score": 0.038072141031676665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038072141031676665}
{"step": 53608, "time": 1951.7856469154358, "episode/length": 288.0, "episode/score": 0.05311301308876182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05311301308876182}
{"step": 53656, "time": 1953.3029806613922, "episode/length": 288.0, "episode/score": 0.05368232291618824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05368232291618824}
{"step": 54096, "time": 1967.4072456359863, "episode/length": 288.0, "episode/score": 0.06956704584769113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06956704584769113}
{"step": 54712, "time": 1986.769519329071, "episode/length": 288.0, "episode/score": 0.03940017549712138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03940017549712138}
{"step": 55384, "time": 2007.986846446991, "episode/length": 288.0, "episode/score": 0.07590558502806743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07590558502806743}
{"step": 55488, "time": 2011.5036578178406, "episode/length": 288.0, "episode/score": 0.07166842595631806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07166842595631806}
{"step": 55488, "time": 2011.5116291046143, "episode/length": 288.0, "episode/score": 0.05631057827247332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05631057827247332}
{"step": 55488, "time": 2011.5191893577576, "episode/length": 288.0, "episode/score": 0.0478062720685557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0478062720685557}
{"step": 55920, "time": 2025.109235048294, "episode/length": 288.0, "episode/score": 0.039522900126371496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039522900126371496}
{"step": 55968, "time": 2026.6370933055878, "episode/length": 288.0, "episode/score": 0.06811923601514991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06811923601514991}
{"step": 56408, "time": 2040.2201609611511, "episode/length": 288.0, "episode/score": 0.05004452569835394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05004452569835394}
{"step": 57024, "time": 2059.883549928665, "episode/length": 288.0, "episode/score": 0.0866742530373017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0866742530373017}
{"step": 57696, "time": 2081.5145995616913, "episode/length": 288.0, "episode/score": 0.06264077113439726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06264077113439726}
{"step": 57800, "time": 2084.653886795044, "episode/length": 288.0, "episode/score": 0.057529230761758754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057529230761758754}
{"step": 57800, "time": 2084.682442188263, "episode/length": 288.0, "episode/score": 0.0627549533369347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0627549533369347}
{"step": 57800, "time": 2084.6898231506348, "episode/length": 288.0, "episode/score": 0.07668963693538444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07668963693538444}
{"step": 58232, "time": 2098.225462436676, "episode/length": 288.0, "episode/score": 0.05505975169995736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05505975169995736}
{"step": 58280, "time": 2099.7287628650665, "episode/length": 288.0, "episode/score": 0.0787108829337626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0787108829337626}
{"step": 58720, "time": 2113.8928027153015, "episode/length": 288.0, "episode/score": 0.05326854351602606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05326854351602606}
{"step": 59336, "time": 2133.0334804058075, "episode/length": 288.0, "episode/score": 0.043756624550212564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043756624550212564}
{"step": 60008, "time": 2154.1885113716125, "episode/length": 288.0, "episode/score": 0.04583938740989879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04583938740989879}
{"step": 60008, "time": 2159.910377264023, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.9177601337433, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.924350500107, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.9304933547974, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.936581850052, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.9425117969513, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.9484350681305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2159.954612016678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2163.448600292206, "episode/length": 288.0, "episode/score": 0.0714263588874644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0714263588874644}
{"step": 60112, "time": 2163.456860780716, "episode/length": 288.0, "episode/score": 0.04350043763940903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04350043763940903}
{"step": 60112, "time": 2163.4646797180176, "episode/length": 288.0, "episode/score": 0.03693234266853551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03693234266853551}
{"step": 60544, "time": 2177.1436789035797, "episode/length": 288.0, "episode/score": 0.05323687388542453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05323687388542453}
{"step": 60592, "time": 2178.679000854492, "episode/length": 288.0, "episode/score": 0.06829165941329052, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06829165941329052}
{"step": 61032, "time": 2192.2754757404327, "episode/length": 288.0, "episode/score": 0.057525212751073695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057525212751073695}
{"step": 61648, "time": 2211.9488985538483, "episode/length": 288.0, "episode/score": 0.056763305925358054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056763305925358054}
{"step": 62320, "time": 2233.154134988785, "episode/length": 288.0, "episode/score": 0.047233030467651815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047233030467651815}
{"step": 62424, "time": 2236.2036731243134, "episode/length": 288.0, "episode/score": 0.05866032684110678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05866032684110678}
{"step": 62424, "time": 2236.2114334106445, "episode/length": 288.0, "episode/score": 0.05453086571682775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05453086571682775}
{"step": 62424, "time": 2236.2187099456787, "episode/length": 288.0, "episode/score": 0.05492358192768165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05492358192768165}
{"step": 62649, "time": 2244.240563392639, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000656914465206, "train/action_min": 0.0, "train/action_std": 1.9995752714343906, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003108083445713231, "train/actor_opt_grad_steps": 2845.0, "train/actor_opt_loss": 7.156001489191825, "train/adv_mag": 0.0012450528897575497, "train/adv_max": 0.0012450528897575497, "train/adv_mean": 0.0006731210081308801, "train/adv_min": -6.887408875927483e-06, "train/adv_std": 0.0003174006869625204, "train/cont_avg": 0.9966172680412371, "train/cont_loss_mean": 0.022709468370015473, "train/cont_loss_std": 0.3181296926686792, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.678089049474107, "train/cont_pos_acc": 0.9999999855596995, "train/cont_pos_loss": 0.0035145603355557957, "train/cont_pred": 0.9964919139429466, "train/cont_rate": 0.9966172680412371, "train/dyn_loss_mean": 1.0000000092172132, "train/dyn_loss_std": 2.8997012648068985e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08644130069416822, "train/extr_critic_critic_opt_grad_steps": 2845.0, "train/extr_critic_critic_opt_loss": 13124.795566204897, "train/extr_critic_mag": 0.06593953026938684, "train/extr_critic_max": 0.06593953026938684, "train/extr_critic_mean": 0.06582728043659446, "train/extr_critic_min": 0.065737935071139, "train/extr_critic_std": 2.922129115146686e-05, "train/extr_return_normed_mag": 0.0024497114582774566, "train/extr_return_normed_max": 0.0024497114582774566, "train/extr_return_normed_mean": 0.0019609044573315393, "train/extr_return_normed_min": 0.0013359469006356504, "train/extr_return_normed_std": 0.0003145118468646896, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06698918880261097, "train/extr_return_raw_max": 0.06698918880261097, "train/extr_return_raw_mean": 0.06650038514785546, "train/extr_return_raw_min": 0.06587542424496916, "train/extr_return_raw_std": 0.00031451184701470936, "train/extr_reward_mag": 0.00030435360584062397, "train/extr_reward_max": 0.00030435360584062397, "train/extr_reward_mean": 0.00030410640833109675, "train/extr_reward_min": 0.0003036180722344782, "train/extr_reward_std": 1.0901888924597894e-07, "train/image_loss_mean": 0.2721287431483416, "train/image_loss_std": 0.08405923217381399, "train/model_loss_mean": 0.9067655924669246, "train/model_loss_std": 0.3641474021541089, "train/model_opt_grad_norm": 81.55766953143876, "train/model_opt_grad_steps": 2835.0, "train/model_opt_loss": 48.64364240587372, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 53.76127577319588, "train/policy_entropy_mag": 1.9458844649423028, "train/policy_entropy_max": 1.9458844649423028, "train/policy_entropy_mean": 1.9447921717289798, "train/policy_entropy_min": 1.9304394580654263, "train/policy_entropy_std": 0.000711279753811619, "train/policy_logprob_mag": 2.183713268987911, "train/policy_logprob_max": -1.7095691358920224, "train/policy_logprob_mean": -1.9447983337431838, "train/policy_logprob_min": -2.183713268987911, "train/policy_logprob_std": 0.04661592683687653, "train/policy_randomness_mag": 0.9999868617844336, "train/policy_randomness_max": 0.9999868617844336, "train/policy_randomness_mean": 0.9994255255178078, "train/policy_randomness_min": 0.9920496949830007, "train/policy_randomness_std": 0.00036552550823826187, "train/post_ent_mag": 51.77244056623007, "train/post_ent_max": 51.77244056623007, "train/post_ent_mean": 51.723417242777714, "train/post_ent_min": 51.670181372731, "train/post_ent_std": 0.012918295641189691, "train/prior_ent_mag": 60.507999990404265, "train/prior_ent_max": 60.507999990404265, "train/prior_ent_mean": 60.4292070644418, "train/prior_ent_min": 60.31645810235407, "train/prior_ent_std": 0.02492932251356926, "train/rep_loss_mean": 1.0000000092172132, "train/rep_loss_std": 2.8997012648068985e-07, "train/reward_avg": 0.00029412081104177577, "train/reward_loss_mean": 0.011927356237795242, "train/reward_loss_std": 0.057339634357461915, "train/reward_max_data": 0.08332560456372298, "train/reward_max_pred": 0.0003049404350752683, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01049863212002614, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.932403301370554, "train/reward_pred": 0.00030441324829037504, "train/reward_rate": 0.00016108247422680412, "train_stats/mean_log_entropy": 1.9377889784899625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025570396333932877, "report/cont_loss_std": 0.3503878116607666, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.620815753936768, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0036282602231949568, "report/cont_pred": 0.9963781833648682, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25232213735580444, "report/image_loss_std": 0.07938463240861893, "report/model_loss_mean": 0.88758385181427, "report/model_loss_std": 0.36302250623703003, "report/post_ent_mag": 44.22878646850586, "report/post_ent_max": 44.22878646850586, "report/post_ent_mean": 44.20652770996094, "report/post_ent_min": 44.140480041503906, "report/post_ent_std": 0.015313653275370598, "report/prior_ent_mag": 53.595298767089844, "report/prior_ent_max": 53.595298767089844, "report/prior_ent_mean": 53.55281448364258, "report/prior_ent_min": 53.44757843017578, "report/prior_ent_std": 0.021637197583913803, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00019460919429548085, "report/reward_loss_mean": 0.009691309183835983, "report/reward_loss_std": 0.016610318794846535, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002353191375732422, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009691310115158558, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002350106369704008, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0036282604560256004, "eval/cont_loss_std": 9.313225746154785e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036282604560256004, "eval/cont_pred": 0.9963781833648682, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.25363367795944214, "eval/image_loss_std": 0.08354239910840988, "eval/model_loss_mean": 0.8586521148681641, "eval/model_loss_std": 0.08354241400957108, "eval/post_ent_mag": 44.22712707519531, "eval/post_ent_max": 44.22712707519531, "eval/post_ent_mean": 44.207252502441406, "eval/post_ent_min": 44.13649368286133, "eval/post_ent_std": 0.01485560555011034, "eval/prior_ent_mag": 53.60764694213867, "eval/prior_ent_max": 53.60764694213867, "eval/prior_ent_mean": 53.55382537841797, "eval/prior_ent_min": 53.44948959350586, "eval/prior_ent_std": 0.0195495393127203, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001390109769999981, "eval/reward_loss_std": 2.265296188852517e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002353191375732422, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001390109769999981, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023499608505517244, "eval/reward_rate": 0.0, "replay/size": 62145.0, "replay/inserts": 31056.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.2688173699907148e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.397084545192492e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1005547357403008e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0939228534698, "timer/env.step_count": 3882.0, "timer/env.step_total": 37.67262291908264, "timer/env.step_frac": 0.03766908493113831, "timer/env.step_avg": 0.009704436609758537, "timer/env.step_min": 0.007811546325683594, "timer/env.step_max": 0.035913944244384766, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 15.917253732681274, "timer/replay._sample_frac": 0.015915758879192204, "timer/replay._sample_avg": 0.0005125339300837608, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.010551214218139648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4749.0, "timer/agent.policy_total": 48.01924180984497, "timer/agent.policy_frac": 0.048014732129194805, "timer/agent.policy_avg": 0.010111442790028421, "timer/agent.policy_min": 0.008717775344848633, "timer/agent.policy_max": 0.09410333633422852, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.2016141414642334, "timer/dataset_train_frac": 0.0002015952070671398, "timer/dataset_train_avg": 0.00010387127329429851, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0010678768157958984, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 864.9163415431976, "timer/agent.train_frac": 0.8648351137615322, "timer/agent.train_avg": 0.4456034732319411, "timer/agent.train_min": 0.4367363452911377, "timer/agent.train_max": 0.5838079452514648, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4646742343902588, "timer/agent.report_frac": 0.00046463059495897087, "timer/agent.report_avg": 0.2323371171951294, "timer/agent.report_min": 0.224029541015625, "timer/agent.report_max": 0.2406446933746338, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.4805843484690616e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 31.052589423091522}
{"step": 62856, "time": 2250.4997565746307, "episode/length": 288.0, "episode/score": 0.03789147583765384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03789147583765384}
{"step": 62904, "time": 2252.0106291770935, "episode/length": 288.0, "episode/score": 0.021012482174256775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021012482174256775}
{"step": 63344, "time": 2266.125766992569, "episode/length": 288.0, "episode/score": 0.05755344409462282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05755344409462282}
{"step": 63960, "time": 2285.230874300003, "episode/length": 288.0, "episode/score": 0.06928616368099938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06928616368099938}
{"step": 64632, "time": 2306.4329249858856, "episode/length": 288.0, "episode/score": 0.04180843106530574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04180843106530574}
{"step": 64736, "time": 2309.917491674423, "episode/length": 288.0, "episode/score": 0.029159167424154475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029159167424154475}
{"step": 64736, "time": 2309.9255352020264, "episode/length": 288.0, "episode/score": 0.06391659625023749, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06391659625023749}
{"step": 64736, "time": 2309.9327478408813, "episode/length": 288.0, "episode/score": 0.05353477868959544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05353477868959544}
{"step": 64784, "time": 2311.461067676544, "episode/length": 179.0, "episode/score": 0.47916595335084367, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.03854094259406793}
{"step": 65168, "time": 2323.5932791233063, "episode/length": 288.0, "episode/score": 0.04073350897567707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04073350897567707}
{"step": 65216, "time": 2325.101000547409, "episode/length": 288.0, "episode/score": 0.07461736223797288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07461736223797288}
{"step": 66272, "time": 2358.8597626686096, "episode/length": 288.0, "episode/score": 0.03691271564127874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03691271564127874}
{"step": 66944, "time": 2379.9538431167603, "episode/length": 288.0, "episode/score": 0.043474990248228096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043474990248228096}
{"step": 67048, "time": 2383.1085579395294, "episode/length": 288.0, "episode/score": 0.045853493899130626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045853493899130626}
{"step": 67048, "time": 2383.1164968013763, "episode/length": 288.0, "episode/score": 0.030527576662223055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030527576662223055}
{"step": 67048, "time": 2383.1235904693604, "episode/length": 288.0, "episode/score": 0.07220495122646753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07220495122646753}
{"step": 67096, "time": 2384.6236338615417, "episode/length": 288.0, "episode/score": 0.06425530206223584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06425530206223584}
{"step": 67480, "time": 2396.6915662288666, "episode/length": 288.0, "episode/score": 0.03955492017848883, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03955492017848883}
{"step": 67528, "time": 2398.2027032375336, "episode/length": 288.0, "episode/score": 0.0351710136156953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0351710136156953}
{"step": 68584, "time": 2431.4119532108307, "episode/length": 288.0, "episode/score": 0.06737655930413666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06737655930413666}
{"step": 69256, "time": 2452.5845227241516, "episode/length": 288.0, "episode/score": 0.06310048877867303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06310048877867303}
{"step": 69360, "time": 2456.0592823028564, "episode/length": 288.0, "episode/score": 0.06102518664351919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06102518664351919}
{"step": 69360, "time": 2456.0672056674957, "episode/length": 288.0, "episode/score": 0.035523896199720184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035523896199720184}
{"step": 69360, "time": 2456.0742173194885, "episode/length": 288.0, "episode/score": 0.054192838323956494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054192838323956494}
{"step": 69408, "time": 2457.5980517864227, "episode/length": 288.0, "episode/score": 0.05072888874428827, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05072888874428827}
{"step": 69792, "time": 2469.6769013404846, "episode/length": 288.0, "episode/score": 0.07901499033954451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07901499033954451}
{"step": 69840, "time": 2471.175441980362, "episode/length": 288.0, "episode/score": 0.03295329780439715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03295329780439715}
{"step": 70096, "time": 2484.468725681305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.4776611328125, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.484772205353, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.4918155670166, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.499128103256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.505697488785, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.5120577812195, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2484.518796682358, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70896, "time": 2509.645261287689, "episode/length": 288.0, "episode/score": 0.028511649655456495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028511649655456495}
{"step": 71568, "time": 2530.7819106578827, "episode/length": 288.0, "episode/score": 0.05575993689620873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05575993689620873}
{"step": 71672, "time": 2533.9642333984375, "episode/length": 288.0, "episode/score": 0.05173149631789897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05173149631789897}
{"step": 71672, "time": 2533.97314953804, "episode/length": 288.0, "episode/score": 0.05882759438162566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05882759438162566}
{"step": 71672, "time": 2533.980851173401, "episode/length": 288.0, "episode/score": 0.04895298622415112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04895298622415112}
{"step": 71720, "time": 2535.5146703720093, "episode/length": 288.0, "episode/score": 0.04743475852427537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04743475852427537}
{"step": 72104, "time": 2547.6299242973328, "episode/length": 288.0, "episode/score": 0.0571741035641935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0571741035641935}
{"step": 72152, "time": 2549.1486258506775, "episode/length": 288.0, "episode/score": 0.030010037472720796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030010037472720796}
{"step": 73208, "time": 2582.2987565994263, "episode/length": 288.0, "episode/score": 0.04200601479641364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04200601479641364}
{"step": 73880, "time": 2604.0009412765503, "episode/length": 288.0, "episode/score": 0.055356986785454865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055356986785454865}
{"step": 73984, "time": 2607.487066745758, "episode/length": 288.0, "episode/score": 0.05510577241813053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05510577241813053}
{"step": 73984, "time": 2607.5604128837585, "episode/length": 288.0, "episode/score": 0.048583286091343325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048583286091343325}
{"step": 73984, "time": 2607.5683743953705, "episode/length": 288.0, "episode/score": 0.04542988904267986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04542988904267986}
{"step": 74032, "time": 2609.107094526291, "episode/length": 288.0, "episode/score": 0.07198321885977066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07198321885977066}
{"step": 74416, "time": 2621.1839175224304, "episode/length": 288.0, "episode/score": 0.0674538715354629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0674538715354629}
{"step": 74464, "time": 2622.832349061966, "episode/length": 288.0, "episode/score": 0.07974886319527741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07974886319527741}
{"step": 75520, "time": 2656.020007133484, "episode/length": 288.0, "episode/score": 0.05151190611752554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05151190611752554}
{"step": 76192, "time": 2677.213425397873, "episode/length": 288.0, "episode/score": 0.03694275677560199, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03694275677560199}
{"step": 76296, "time": 2680.2815923690796, "episode/length": 288.0, "episode/score": 0.06036043612766662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06036043612766662}
{"step": 76296, "time": 2680.289543867111, "episode/length": 288.0, "episode/score": 0.06121187986241239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06121187986241239}
{"step": 76296, "time": 2680.2966244220734, "episode/length": 288.0, "episode/score": 0.07319079288481589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07319079288481589}
{"step": 76344, "time": 2681.892650604248, "episode/length": 288.0, "episode/score": 0.07371093812150775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07371093812150775}
{"step": 76728, "time": 2693.9927406311035, "episode/length": 288.0, "episode/score": 0.08670401509004932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08670401509004932}
{"step": 76776, "time": 2695.5321180820465, "episode/length": 288.0, "episode/score": 0.08244235109452802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08244235109452802}
{"step": 77832, "time": 2728.8713529109955, "episode/length": 288.0, "episode/score": 0.07071949475050587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07071949475050587}
{"step": 78504, "time": 2750.0135445594788, "episode/length": 288.0, "episode/score": 0.0704928019658837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0704928019658837}
{"step": 78608, "time": 2753.506083726883, "episode/length": 288.0, "episode/score": 0.09103054880193895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09103054880193895}
{"step": 78608, "time": 2753.5141322612762, "episode/length": 288.0, "episode/score": 0.06270748009097815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06270748009097815}
{"step": 78608, "time": 2753.521559238434, "episode/length": 288.0, "episode/score": 0.059806603765480304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059806603765480304}
{"step": 78656, "time": 2755.0200090408325, "episode/length": 288.0, "episode/score": 0.057088608171227406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057088608171227406}
{"step": 79040, "time": 2767.0852942466736, "episode/length": 288.0, "episode/score": 0.06971638314865913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06971638314865913}
{"step": 79088, "time": 2768.597427845001, "episode/length": 288.0, "episode/score": 0.04734057130929159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04734057130929159}
{"step": 80080, "time": 2805.8304522037506, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.8411948680878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.8483533859253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.8567967414856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.8647809028625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.873518705368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.8860261440277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2805.8922567367554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80144, "time": 2807.9415984153748, "episode/length": 288.0, "episode/score": 0.09019345570823134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09019345570823134}
{"step": 80816, "time": 2828.9548573493958, "episode/length": 288.0, "episode/score": 0.0761408949788347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0761408949788347}
{"step": 80920, "time": 2832.105920791626, "episode/length": 288.0, "episode/score": 0.07294984232532897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07294984232532897}
{"step": 80920, "time": 2832.1139800548553, "episode/length": 288.0, "episode/score": 0.04775781451758121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04775781451758121}
{"step": 80920, "time": 2832.1211202144623, "episode/length": 288.0, "episode/score": 0.06236467016140068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06236467016140068}
{"step": 80968, "time": 2833.624664783478, "episode/length": 288.0, "episode/score": 0.08061843276038871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08061843276038871}
{"step": 81352, "time": 2845.600296020508, "episode/length": 288.0, "episode/score": 0.05773923229276079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05773923229276079}
{"step": 81400, "time": 2847.11786031723, "episode/length": 288.0, "episode/score": 0.045063077569921006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045063077569921006}
{"step": 81992, "time": 2866.1200971603394, "episode/length": 73.0, "episode/score": 0.7979672811543423, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.026092228674315265}
{"step": 82456, "time": 2880.619636297226, "episode/length": 288.0, "episode/score": 0.04096428952516362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04096428952516362}
{"step": 83128, "time": 2901.6653912067413, "episode/length": 288.0, "episode/score": 0.07762746867001624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07762746867001624}
{"step": 83232, "time": 2905.134777069092, "episode/length": 288.0, "episode/score": 0.06097574097407232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06097574097407232}
{"step": 83232, "time": 2905.1428303718567, "episode/length": 288.0, "episode/score": 0.05696397394433461, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05696397394433461}
{"step": 83232, "time": 2905.1506021022797, "episode/length": 288.0, "episode/score": 0.05895066198058885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05895066198058885}
{"step": 83280, "time": 2906.645849466324, "episode/length": 288.0, "episode/score": 0.08283681466627968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08283681466627968}
{"step": 83664, "time": 2918.6440019607544, "episode/length": 288.0, "episode/score": 0.05188885910604313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05188885910604313}
{"step": 84304, "time": 2938.657301902771, "episode/length": 288.0, "episode/score": 0.04810591766397465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04810591766397465}
{"step": 84768, "time": 2953.173773288727, "episode/length": 288.0, "episode/score": 0.04936495166566601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04936495166566601}
{"step": 85440, "time": 2974.145678758621, "episode/length": 288.0, "episode/score": 0.05276630546688921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05276630546688921}
{"step": 85544, "time": 2977.171881198883, "episode/length": 288.0, "episode/score": 0.06260084450855175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06260084450855175}
{"step": 85544, "time": 2977.179848909378, "episode/length": 288.0, "episode/score": 0.08196386538344314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08196386538344314}
{"step": 85544, "time": 2977.186913728714, "episode/length": 288.0, "episode/score": 0.061853898365825444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061853898365825444}
{"step": 85592, "time": 2978.7061648368835, "episode/length": 288.0, "episode/score": 0.055075621297930866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055075621297930866}
{"step": 85976, "time": 2990.827373981476, "episode/length": 288.0, "episode/score": 0.04603966366425993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04603966366425993}
{"step": 86616, "time": 3010.7997591495514, "episode/length": 288.0, "episode/score": 0.05401682962593668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05401682962593668}
{"step": 87080, "time": 3025.3421308994293, "episode/length": 288.0, "episode/score": 0.06433118136089888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06433118136089888}
{"step": 87752, "time": 3046.332936525345, "episode/length": 288.0, "episode/score": 0.09029215982570804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09029215982570804}
{"step": 87856, "time": 3049.8060200214386, "episode/length": 288.0, "episode/score": 0.06714844671796527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06714844671796527}
{"step": 87856, "time": 3049.813945055008, "episode/length": 288.0, "episode/score": 0.07078163759894096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07078163759894096}
{"step": 87856, "time": 3049.8214585781097, "episode/length": 288.0, "episode/score": 0.05738951158372174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05738951158372174}
{"step": 87904, "time": 3051.324982404709, "episode/length": 288.0, "episode/score": 0.06583490613610365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06583490613610365}
{"step": 88288, "time": 3063.2494707107544, "episode/length": 288.0, "episode/score": 0.06988692101305105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06988692101305105}
{"step": 88480, "time": 3069.598393201828, "episode/length": 77.0, "episode/score": 0.7825570711002001, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02318206630388886}
{"step": 88928, "time": 3083.699692964554, "episode/length": 288.0, "episode/score": 0.06277004768804773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06277004768804773}
{"step": 89224, "time": 3092.781203508377, "episode/length": 164.0, "episode/score": 0.5394007685781617, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.05190075747213996}
{"step": 89368, "time": 3097.306436777115, "episode/length": 201.0, "episode/score": 0.4210343743689009, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.04915937197074527}
{"step": 89392, "time": 3098.292466402054, "episode/length": 288.0, "episode/score": 0.07874303697320784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07874303697320784}
{"step": 90064, "time": 3125.1223204135895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.130437374115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.1373839378357, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.144146680832, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.150890350342, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.1573708057404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.164331436157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3125.1711976528168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3128.726394176483, "episode/length": 288.0, "episode/score": 0.06841257227006281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06841257227006281}
{"step": 90168, "time": 3128.7349128723145, "episode/length": 288.0, "episode/score": 0.060433698838323835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060433698838323835}
{"step": 90600, "time": 3142.4493482112885, "episode/length": 288.0, "episode/score": 0.08711762123107292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08711762123107292}
{"step": 90792, "time": 3148.4096829891205, "episode/length": 288.0, "episode/score": 0.06453524614880735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06453524614880735}
{"step": 91240, "time": 3162.384699344635, "episode/length": 288.0, "episode/score": 0.06954519590908603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06954519590908603}
{"step": 91536, "time": 3171.8081641197205, "episode/length": 288.0, "episode/score": 0.045338274079199437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045338274079199437}
{"step": 91680, "time": 3176.3068854808807, "episode/length": 288.0, "episode/score": 0.05696195261111825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05696195261111825}
{"step": 91704, "time": 3176.839792251587, "episode/length": 288.0, "episode/score": 0.048323587716595284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048323587716595284}
{"step": 92480, "time": 3201.4079773426056, "episode/length": 288.0, "episode/score": 0.06888083523631394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06888083523631394}
{"step": 92480, "time": 3201.41680765152, "episode/length": 288.0, "episode/score": 0.07449278142144067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07449278142144067}
{"step": 92912, "time": 3214.924872159958, "episode/length": 288.0, "episode/score": 0.09276507648996812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09276507648996812}
{"step": 93104, "time": 3220.9032893180847, "episode/length": 288.0, "episode/score": 0.05584028601265345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05584028601265345}
{"step": 93552, "time": 3234.9848062992096, "episode/length": 288.0, "episode/score": 0.061855426733131935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061855426733131935}
{"step": 93833, "time": 3244.459814786911, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0006253756009613, "train/action_min": 0.0, "train/action_std": 2.000337728475913, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.798802492749065e-05, "train/actor_opt_grad_steps": 4790.0, "train/actor_opt_loss": -2.146081376725282, "train/adv_mag": 0.0004156673565889016, "train/adv_max": 0.00041086440667127954, "train/adv_mean": 0.00018585900871346148, "train/adv_min": -9.186741633292956e-05, "train/adv_std": 9.823156029387274e-05, "train/cont_avg": 0.9967047275641026, "train/cont_loss_mean": 0.02218035355162544, "train/cont_loss_std": 0.31068734633521067, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.659198511214483, "train/cont_pos_acc": 0.999999986245082, "train/cont_pos_loss": 0.003531237359707936, "train/cont_pred": 0.9964751368913896, "train/cont_rate": 0.9967047275641026, "train/dyn_loss_mean": 1.001554382764376, "train/dyn_loss_std": 2.1661661613063934e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03324779727233526, "train/extr_critic_critic_opt_grad_steps": 4790.0, "train/extr_critic_critic_opt_loss": 13525.950580929488, "train/extr_critic_mag": 0.07952605699881529, "train/extr_critic_max": 0.07952605699881529, "train/extr_critic_mean": 0.07940562554658988, "train/extr_critic_min": 0.07933482206784762, "train/extr_critic_std": 2.5095692494622093e-05, "train/extr_return_normed_mag": 0.0006862809642767295, "train/extr_return_normed_max": 0.0006808207203180362, "train/extr_return_normed_mean": 0.000520852810232333, "train/extr_return_normed_min": 0.00031081464810249135, "train/extr_return_normed_std": 9.195496704880778e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07975147377986175, "train/extr_return_raw_max": 0.07975147377986175, "train/extr_return_raw_mean": 0.0795915099290701, "train/extr_return_raw_min": 0.0793814677076462, "train/extr_return_raw_std": 9.195496690538746e-05, "train/extr_reward_mag": 0.000268102303529397, "train/extr_reward_max": 0.000268102303529397, "train/extr_reward_mean": 0.0002679318052310592, "train/extr_reward_min": 0.00026773917369353467, "train/extr_reward_std": 6.724987294558761e-08, "train/image_loss_mean": 0.26173957013166865, "train/image_loss_std": 0.08410785926076082, "train/model_loss_mean": 0.8963713453366207, "train/model_loss_std": 0.359960275888443, "train/model_opt_grad_norm": 65.65300686176006, "train/model_opt_grad_steps": 4780.0, "train/model_opt_loss": 186.63983068221654, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 208.33333333333334, "train/policy_entropy_mag": 1.9458980028445905, "train/policy_entropy_max": 1.9458980028445905, "train/policy_entropy_mean": 1.945329189300537, "train/policy_entropy_min": 1.9353137933290923, "train/policy_entropy_std": 0.0004188291722526535, "train/policy_logprob_mag": 2.1349206753266166, "train/policy_logprob_max": -1.7551638664343419, "train/policy_logprob_mean": -1.9453461396388518, "train/policy_logprob_min": -2.1349206753266166, "train/policy_logprob_std": 0.03396782729870234, "train/policy_randomness_mag": 0.9999938179285098, "train/policy_randomness_max": 0.9999938179285098, "train/policy_randomness_mean": 0.9997015023842836, "train/policy_randomness_min": 0.9945546104357793, "train/policy_randomness_std": 0.00021523563355470125, "train/post_ent_mag": 40.44721075204703, "train/post_ent_max": 40.44721075204703, "train/post_ent_mean": 40.42008588741987, "train/post_ent_min": 40.28649186354417, "train/post_ent_std": 0.03229784143563264, "train/prior_ent_mag": 49.863079423170824, "train/prior_ent_max": 49.863079423170824, "train/prior_ent_mean": 49.81699744982597, "train/prior_ent_min": 49.69920458671374, "train/prior_ent_std": 0.0187655383362793, "train/rep_loss_mean": 1.001554382764376, "train/rep_loss_std": 2.1661661613063934e-05, "train/reward_avg": 0.00028597881259301153, "train/reward_loss_mean": 0.011518780247141154, "train/reward_loss_std": 0.05977423099848705, "train/reward_max_data": 0.08455149873804588, "train/reward_max_pred": 0.00026819583697196763, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010028367632856736, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.061845702509727, "train/reward_pred": 0.00026788078367901157, "train/reward_rate": 0.00016526442307692309, "train_stats/mean_log_entropy": 1.9382337408328274, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02018284983932972, "report/cont_loss_std": 0.29768210649490356, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.51185941696167, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004046675283461809, "report/cont_pred": 0.9959613680839539, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2556145191192627, "report/image_loss_std": 0.09327489882707596, "report/model_loss_mean": 0.8852112293243408, "report/model_loss_std": 0.3174033463001251, "report/post_ent_mag": 34.23633575439453, "report/post_ent_max": 34.23633575439453, "report/post_ent_mean": 34.22813034057617, "report/post_ent_min": 34.21745681762695, "report/post_ent_std": 0.0032860226929187775, "report/prior_ent_mag": 33.960594177246094, "report/prior_ent_max": 33.960594177246094, "report/prior_ent_mean": 33.95008087158203, "report/prior_ent_min": 33.921180725097656, "report/prior_ent_std": 0.006559318397194147, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018773354531731457, "report/reward_loss_mean": 0.009413781575858593, "report/reward_loss_std": 0.015089879743754864, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002995729446411133, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009413781575858593, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00029841111972928047, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.004046706482768059, "eval/cont_loss_std": 9.821349067351548e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004046706482768059, "eval/cont_pred": 0.9959613084793091, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2465846836566925, "eval/image_loss_std": 0.09348069876432419, "eval/model_loss_mean": 0.8522266149520874, "eval/model_loss_std": 0.09348070621490479, "eval/post_ent_mag": 34.23574447631836, "eval/post_ent_max": 34.23574447631836, "eval/post_ent_mean": 34.22808837890625, "eval/post_ent_min": 34.2169189453125, "eval/post_ent_std": 0.003124954178929329, "eval/prior_ent_mag": 33.96240997314453, "eval/prior_ent_max": 33.96240997314453, "eval/prior_ent_mean": 33.95037841796875, "eval/prior_ent_min": 33.91498565673828, "eval/prior_ent_std": 0.006475718691945076, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015951353125274181, "eval/reward_loss_std": 8.36514175261982e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002995729446411133, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015951353125274181, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002984029706567526, "eval/reward_rate": 0.0, "replay/size": 93329.0, "replay/inserts": 31184.0, "replay/samples": 31184.0, "replay/insert_wait_avg": 1.2465291539481384e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.304434718077705e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1631499249767406e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2049286365509, "timer/env.step_count": 3898.0, "timer/env.step_total": 37.11481809616089, "timer/env.step_frac": 0.037107213765437734, "timer/env.step_avg": 0.009521502846629268, "timer/env.step_min": 0.007752895355224609, "timer/env.step_max": 0.035509586334228516, "timer/replay._sample_count": 31184.0, "timer/replay._sample_total": 15.88184905052185, "timer/replay._sample_frac": 0.015878595071683467, "timer/replay._sample_avg": 0.0005092948002347951, "timer/replay._sample_min": 0.00038695335388183594, "timer/replay._sample_max": 0.026328563690185547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4765.0, "timer/agent.policy_total": 48.017046213150024, "timer/agent.policy_frac": 0.04800720816143689, "timer/agent.policy_avg": 0.010077029635498431, "timer/agent.policy_min": 0.008661508560180664, "timer/agent.policy_max": 0.4965188503265381, "timer/dataset_train_count": 1949.0, "timer/dataset_train_total": 0.1979689598083496, "timer/dataset_train_frac": 0.00019792839861148745, "timer/dataset_train_avg": 0.00010157463304686998, "timer/dataset_train_min": 8.749961853027344e-05, "timer/dataset_train_max": 0.00039267539978027344, "timer/agent.train_count": 1949.0, "timer/agent.train_total": 865.5326645374298, "timer/agent.train_frac": 0.8653553284498385, "timer/agent.train_avg": 0.44409064368262174, "timer/agent.train_min": 0.4327809810638428, "timer/agent.train_max": 0.5902414321899414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47366809844970703, "timer/agent.report_frac": 0.00047357105018008366, "timer/agent.report_avg": 0.23683404922485352, "timer/agent.report_min": 0.2300105094909668, "timer/agent.report_max": 0.24365758895874023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.098806494130535e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 31.177103112233738}
{"step": 93848, "time": 3244.529623746872, "episode/length": 288.0, "episode/score": 0.04143968376843077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04143968376843077}
{"step": 93992, "time": 3249.379648923874, "episode/length": 288.0, "episode/score": 0.051262108589980926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051262108589980926}
{"step": 94016, "time": 3250.355614900589, "episode/length": 288.0, "episode/score": 0.07555872135696973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07555872135696973}
{"step": 94792, "time": 3274.6366691589355, "episode/length": 288.0, "episode/score": 0.05528168305943382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05528168305943382}
{"step": 94792, "time": 3274.644768476486, "episode/length": 288.0, "episode/score": 0.0693988989725085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0693988989725085}
{"step": 95224, "time": 3288.2764990329742, "episode/length": 288.0, "episode/score": 0.04630137357065678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04630137357065678}
{"step": 95416, "time": 3294.3030400276184, "episode/length": 288.0, "episode/score": 0.04023782410462218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04023782410462218}
{"step": 95864, "time": 3308.3172414302826, "episode/length": 288.0, "episode/score": 0.0708413461131272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0708413461131272}
{"step": 96160, "time": 3317.8478960990906, "episode/length": 288.0, "episode/score": 0.0686264717532481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0686264717532481}
{"step": 96176, "time": 3318.3518772125244, "episode/length": 272.0, "episode/score": 0.2405672898448188, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.09056728504850753}
{"step": 96328, "time": 3322.886516571045, "episode/length": 288.0, "episode/score": 0.052649488159829616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052649488159829616}
{"step": 96408, "time": 3325.38289475441, "episode/length": 201.0, "episode/score": 0.4228466692653683, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.050971682350450465}
{"step": 97104, "time": 3347.4194996356964, "episode/length": 288.0, "episode/score": 0.0574501874575617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0574501874575617}
{"step": 97536, "time": 3360.931381702423, "episode/length": 288.0, "episode/score": 0.04061362760302245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04061362760302245}
{"step": 97728, "time": 3366.9429268836975, "episode/length": 288.0, "episode/score": 0.06995152960445239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06995152960445239}
{"step": 98176, "time": 3381.019156217575, "episode/length": 288.0, "episode/score": 0.05641980649318157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05641980649318157}
{"step": 98472, "time": 3390.491395711899, "episode/length": 288.0, "episode/score": 0.0719051851294239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0719051851294239}
{"step": 98488, "time": 3390.9963421821594, "episode/length": 288.0, "episode/score": 0.06078614495521606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06078614495521606}
{"step": 98640, "time": 3395.94274187088, "episode/length": 288.0, "episode/score": 0.04490242239904774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04490242239904774}
{"step": 98720, "time": 3398.4511818885803, "episode/length": 288.0, "episode/score": 0.0691998456855174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0691998456855174}
{"step": 99416, "time": 3420.050367116928, "episode/length": 288.0, "episode/score": 0.05692043705906258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05692043705906258}
{"step": 99824, "time": 3433.0838470458984, "episode/length": 285.0, "episode/score": 0.15670943804730086, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.04733443921145408}
{"step": 100040, "time": 3439.5889835357666, "episode/length": 288.0, "episode/score": 0.02611000099835792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02611000099835792}
{"step": 100048, "time": 3444.974521636963, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.981614112854, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.988065481186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.9940366744995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3444.9999618530273, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3445.0059745311737, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3445.0125715732574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3445.0189459323883, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100488, "time": 3458.463080406189, "episode/length": 288.0, "episode/score": 0.04561020293601814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04561020293601814}
{"step": 100784, "time": 3467.957948446274, "episode/length": 288.0, "episode/score": 0.05218039355790438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05218039355790438}
{"step": 100800, "time": 3468.4618697166443, "episode/length": 288.0, "episode/score": 0.07324337433004757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07324337433004757}
{"step": 100952, "time": 3472.9859466552734, "episode/length": 288.0, "episode/score": 0.056014408300256946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056014408300256946}
{"step": 101032, "time": 3475.4659526348114, "episode/length": 288.0, "episode/score": 0.056057516622843195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056057516622843195}
{"step": 101728, "time": 3497.407725095749, "episode/length": 288.0, "episode/score": 0.0656061741664189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0656061741664189}
{"step": 102136, "time": 3509.856556892395, "episode/length": 288.0, "episode/score": 0.04923769346748941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04923769346748941}
{"step": 102352, "time": 3516.8147296905518, "episode/length": 288.0, "episode/score": 0.054315636455044114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054315636455044114}
{"step": 102800, "time": 3530.800404071808, "episode/length": 288.0, "episode/score": 0.06965156046339871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06965156046339871}
{"step": 103096, "time": 3539.823110818863, "episode/length": 288.0, "episode/score": 0.04224134596489648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04224134596489648}
{"step": 103112, "time": 3540.329985141754, "episode/length": 288.0, "episode/score": 0.060392201349372954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060392201349372954}
{"step": 103264, "time": 3545.3097536563873, "episode/length": 288.0, "episode/score": 0.06615610500301727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06615610500301727}
{"step": 103344, "time": 3547.8452203273773, "episode/length": 288.0, "episode/score": 0.05050330858216512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05050330858216512}
{"step": 103680, "time": 3558.393161535263, "episode/length": 165.0, "episode/score": 0.5147361123711107, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.03036111353526394}
{"step": 103904, "time": 3565.3932769298553, "episode/length": 98.0, "episode/score": 0.7242962477602077, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.030546195280180655}
{"step": 104040, "time": 3569.4462265968323, "episode/length": 288.0, "episode/score": 0.04889749346739336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04889749346739336}
{"step": 104448, "time": 3582.4806208610535, "episode/length": 288.0, "episode/score": 0.031101365181370966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031101365181370966}
{"step": 105112, "time": 3602.9805295467377, "episode/length": 288.0, "episode/score": 0.043335977455853936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043335977455853936}
{"step": 105408, "time": 3612.5340054035187, "episode/length": 288.0, "episode/score": 0.043386562797479655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043386562797479655}
{"step": 105576, "time": 3617.5587582588196, "episode/length": 288.0, "episode/score": 0.04523324614933699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04523324614933699}
{"step": 105656, "time": 3620.0505611896515, "episode/length": 288.0, "episode/score": 0.05752206598486964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05752206598486964}
{"step": 105992, "time": 3630.516421556473, "episode/length": 288.0, "episode/score": 0.06289817381997409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06289817381997409}
{"step": 106216, "time": 3637.537514925003, "episode/length": 288.0, "episode/score": 0.08378308496105547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08378308496105547}
{"step": 106352, "time": 3642.111550092697, "episode/length": 288.0, "episode/score": 0.06643628255477552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06643628255477552}
{"step": 106760, "time": 3655.0887076854706, "episode/length": 288.0, "episode/score": 0.05636214639230275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05636214639230275}
{"step": 107424, "time": 3676.053491592407, "episode/length": 288.0, "episode/score": 0.08681766156166759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08681766156166759}
{"step": 107720, "time": 3685.0637986660004, "episode/length": 288.0, "episode/score": 0.03484203643137107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03484203643137107}
{"step": 107888, "time": 3690.4990317821503, "episode/length": 288.0, "episode/score": 0.06254502460001277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06254502460001277}
{"step": 107968, "time": 3693.0070128440857, "episode/length": 288.0, "episode/score": 0.0663856860718397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0663856860718397}
{"step": 108304, "time": 3703.588067293167, "episode/length": 288.0, "episode/score": 0.06975452521322723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06975452521322723}
{"step": 108528, "time": 3710.551609516144, "episode/length": 288.0, "episode/score": 0.07786571906103745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07786571906103745}
{"step": 108664, "time": 3714.5755610466003, "episode/length": 288.0, "episode/score": 0.07779013708159255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07779013708159255}
{"step": 109072, "time": 3727.5711472034454, "episode/length": 288.0, "episode/score": 0.04520994512040488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04520994512040488}
{"step": 109736, "time": 3748.172242641449, "episode/length": 288.0, "episode/score": 0.08205182273013634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08205182273013634}
{"step": 110032, "time": 3757.796869277954, "episode/length": 288.0, "episode/score": 0.052374412831227346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052374412831227346}
{"step": 110032, "time": 3763.010350704193, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.0178728103638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.024342775345, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.0306055545807, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.0366876125336, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.0424902439117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.049362897873, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3763.055430650711, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110200, "time": 3768.057264328003, "episode/length": 288.0, "episode/score": 0.06322979558956376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06322979558956376}
{"step": 110280, "time": 3770.5593752861023, "episode/length": 288.0, "episode/score": 0.05525047718822407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05525047718822407}
{"step": 110616, "time": 3781.036108016968, "episode/length": 288.0, "episode/score": 0.06318266274388407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06318266274388407}
{"step": 110840, "time": 3788.7118151187897, "episode/length": 288.0, "episode/score": 0.047166490410518236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047166490410518236}
{"step": 110976, "time": 3793.2714624404907, "episode/length": 288.0, "episode/score": 0.03580864471609857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03580864471609857}
{"step": 111384, "time": 3805.7817347049713, "episode/length": 288.0, "episode/score": 0.039474661484973694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039474661484973694}
{"step": 112048, "time": 3826.8146402835846, "episode/length": 288.0, "episode/score": 0.0716741972607906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0716741972607906}
{"step": 112344, "time": 3835.812769174576, "episode/length": 288.0, "episode/score": 0.04424698806201377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04424698806201377}
{"step": 112512, "time": 3841.278116464615, "episode/length": 288.0, "episode/score": 0.07587722951950582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07587722951950582}
{"step": 112592, "time": 3843.7889642715454, "episode/length": 288.0, "episode/score": 0.08629573751784392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08629573751784392}
{"step": 112928, "time": 3854.3035492897034, "episode/length": 288.0, "episode/score": 0.054214858530258425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054214858530258425}
{"step": 113152, "time": 3861.2416203022003, "episode/length": 288.0, "episode/score": 0.06825145719005832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06825145719005832}
{"step": 113288, "time": 3865.2380652427673, "episode/length": 288.0, "episode/score": 0.07576243522464665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07576243522464665}
{"step": 113696, "time": 3878.131442785263, "episode/length": 288.0, "episode/score": 0.054767803088054734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054767803088054734}
{"step": 114360, "time": 3898.6511850357056, "episode/length": 288.0, "episode/score": 0.07223652730903041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07223652730903041}
{"step": 114656, "time": 3908.1193373203278, "episode/length": 288.0, "episode/score": 0.05792690937420275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05792690937420275}
{"step": 114824, "time": 3913.7042529582977, "episode/length": 288.0, "episode/score": 0.06156809458798307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06156809458798307}
{"step": 114904, "time": 3916.218919277191, "episode/length": 288.0, "episode/score": 0.04499499589451261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04499499589451261}
{"step": 115240, "time": 3926.664649963379, "episode/length": 288.0, "episode/score": 0.0771402232041396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0771402232041396}
{"step": 115464, "time": 3933.63662815094, "episode/length": 288.0, "episode/score": 0.082783014209042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.082783014209042}
{"step": 115600, "time": 3938.1023132801056, "episode/length": 288.0, "episode/score": 0.0623708657952875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0623708657952875}
{"step": 116008, "time": 3950.674642801285, "episode/length": 288.0, "episode/score": 0.06748514499446401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06748514499446401}
{"step": 116672, "time": 3971.64963054657, "episode/length": 288.0, "episode/score": 0.0684546013355316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0684546013355316}
{"step": 116968, "time": 3980.665471315384, "episode/length": 288.0, "episode/score": 0.051718678873101, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051718678873101}
{"step": 117136, "time": 3986.119695663452, "episode/length": 288.0, "episode/score": 0.050911066132812266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050911066132812266}
{"step": 117216, "time": 3988.6022901535034, "episode/length": 288.0, "episode/score": 0.05230184733090937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05230184733090937}
{"step": 117552, "time": 3999.0407102108, "episode/length": 288.0, "episode/score": 0.03951236606059183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03951236606059183}
{"step": 117776, "time": 4006.068297624588, "episode/length": 288.0, "episode/score": 0.0374265844443471, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0374265844443471}
{"step": 117912, "time": 4010.107123374939, "episode/length": 288.0, "episode/score": 0.0713339485367328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0713339485367328}
{"step": 118320, "time": 4023.019451856613, "episode/length": 288.0, "episode/score": 0.043681408964317825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043681408964317825}
{"step": 118984, "time": 4043.520288467407, "episode/length": 288.0, "episode/score": 0.05062402432076851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05062402432076851}
{"step": 119280, "time": 4052.975749015808, "episode/length": 288.0, "episode/score": 0.05080701564156698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05080701564156698}
{"step": 119448, "time": 4058.0322744846344, "episode/length": 288.0, "episode/score": 0.056003473196653886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056003473196653886}
{"step": 119528, "time": 4060.553738117218, "episode/length": 288.0, "episode/score": 0.03074450812036389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03074450812036389}
{"step": 119864, "time": 4071.108119726181, "episode/length": 288.0, "episode/score": 0.07788096111985965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07788096111985965}
{"step": 120016, "time": 4078.183660030365, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 120016, "time": 4081.314032316208, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4081.3221118450165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4081.3291652202606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4081.3383073806763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4081.3436136245728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4081.3504736423492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4081.3572437763214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120088, "time": 4083.4152688980103, "episode/length": 288.0, "episode/score": 0.0637121603685955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0637121603685955}
{"step": 120224, "time": 4087.9643721580505, "episode/length": 288.0, "episode/score": 0.04260897505471917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04260897505471917}
{"step": 120632, "time": 4100.716785907745, "episode/length": 288.0, "episode/score": 0.0288803464042644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0288803464042644}
{"step": 121296, "time": 4121.847365617752, "episode/length": 288.0, "episode/score": 0.06928835508736597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06928835508736597}
{"step": 121592, "time": 4130.8402490615845, "episode/length": 288.0, "episode/score": 0.07831030526776317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07831030526776317}
{"step": 121760, "time": 4136.329229354858, "episode/length": 288.0, "episode/score": 0.06855341835151307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06855341835151307}
{"step": 121840, "time": 4138.821187734604, "episode/length": 288.0, "episode/score": 0.06181727617473598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06181727617473598}
{"step": 122000, "time": 4143.811331510544, "episode/length": 50.0, "episode/score": 0.8598795296963999, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.016129501058230744}
{"step": 122176, "time": 4149.32235622406, "episode/length": 288.0, "episode/score": 0.07195292120096042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07195292120096042}
{"step": 122400, "time": 4156.395056724548, "episode/length": 288.0, "episode/score": 0.07615826595304043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07615826595304043}
{"step": 122536, "time": 4160.431843042374, "episode/length": 288.0, "episode/score": 0.06761800485099911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06761800485099911}
{"step": 122944, "time": 4173.889191389084, "episode/length": 288.0, "episode/score": 0.05647584321260979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05647584321260979}
{"step": 123608, "time": 4194.438724040985, "episode/length": 288.0, "episode/score": 0.043920731135500546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043920731135500546}
{"step": 124072, "time": 4208.855263471603, "episode/length": 288.0, "episode/score": 0.05782048852992716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05782048852992716}
{"step": 124152, "time": 4211.39098072052, "episode/length": 288.0, "episode/score": 0.07265688934236891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07265688934236891}
{"step": 124312, "time": 4216.530838727951, "episode/length": 288.0, "episode/score": 0.07790143104082858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07790143104082858}
{"step": 124488, "time": 4221.9765639305115, "episode/length": 288.0, "episode/score": 0.05092981165384458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05092981165384458}
{"step": 124712, "time": 4228.985233783722, "episode/length": 288.0, "episode/score": 0.04740059790179885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04740059790179885}
{"step": 124848, "time": 4233.445020914078, "episode/length": 288.0, "episode/score": 0.06653181969619482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06653181969619482}
{"step": 125177, "time": 4244.568940877914, "train_stats/mean_log_entropy": 1.9382297918200493, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9992538763552297, "train/action_min": 0.0, "train/action_std": 2.0001571549444783, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 7.073427041734472e-05, "train/actor_opt_grad_steps": 6745.0, "train/actor_opt_loss": -3.0180676682372294, "train/adv_mag": 0.00039830157647327503, "train/adv_max": 0.0003798679657736603, "train/adv_mean": 0.0001401665805047389, "train/adv_min": -0.0001240944375797194, "train/adv_std": 8.925462992460687e-05, "train/cont_avg": 0.996452487244898, "train/cont_loss_mean": 0.023575736513855507, "train/cont_loss_std": 0.321884555333503, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.670583675044994, "train/cont_pos_acc": 0.9999999866193655, "train/cont_pos_loss": 0.0034977978615717466, "train/cont_pred": 0.9965084748608726, "train/cont_rate": 0.996452487244898, "train/dyn_loss_mean": 1.0002453169044183, "train/dyn_loss_std": 2.9414811418676865e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.024133662946227635, "train/extr_critic_critic_opt_grad_steps": 6745.0, "train/extr_critic_critic_opt_loss": 13500.741918447065, "train/extr_critic_mag": 0.08645954059094799, "train/extr_critic_max": 0.08645954059094799, "train/extr_critic_mean": 0.08634145337404037, "train/extr_critic_min": 0.08624538231869133, "train/extr_critic_std": 2.9009432859548e-05, "train/extr_return_normed_mag": 0.0005911341203110558, "train/extr_return_normed_max": 0.00057218429081294, "train/extr_return_normed_mean": 0.0004183697265916078, "train/extr_return_normed_min": 0.00022767385353847426, "train/extr_return_normed_std": 8.046155802932789e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08663547727070292, "train/extr_return_raw_max": 0.08663547727070292, "train/extr_return_raw_mean": 0.08648166687664938, "train/extr_return_raw_min": 0.08629096683342846, "train/extr_return_raw_std": 8.046155801540705e-05, "train/extr_reward_mag": 0.00028169337584047903, "train/extr_reward_max": 0.00028169337584047903, "train/extr_reward_mean": 0.00028154918945059467, "train/extr_reward_min": 0.000281419681043041, "train/extr_reward_std": 5.218495127973346e-08, "train/image_loss_mean": 0.2556514847947627, "train/image_loss_std": 0.08566741618726935, "train/model_loss_mean": 0.8915948548487255, "train/model_loss_std": 0.3814494408743114, "train/model_opt_grad_norm": 56.8554977884098, "train/model_opt_grad_steps": 6735.0, "train/model_opt_loss": 723.3683308192661, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 811.5433673469388, "train/policy_entropy_mag": 1.9459014376815484, "train/policy_entropy_max": 1.9459014376815484, "train/policy_entropy_mean": 1.9454746142942079, "train/policy_entropy_min": 1.9340393549325514, "train/policy_entropy_std": 0.00040183463671401485, "train/policy_logprob_mag": 2.132317530865572, "train/policy_logprob_max": -1.7361385816214037, "train/policy_logprob_mean": -1.945455647852956, "train/policy_logprob_min": -2.132317530865572, "train/policy_logprob_std": 0.029448782359915122, "train/policy_randomness_mag": 0.9999955828700747, "train/policy_randomness_max": 0.9999955828700747, "train/policy_randomness_mean": 0.9997762341280373, "train/policy_randomness_min": 0.9938996780891808, "train/policy_randomness_std": 0.00020650216011206942, "train/post_ent_mag": 34.54777011092828, "train/post_ent_max": 34.54777011092828, "train/post_ent_mean": 34.540120436220754, "train/post_ent_min": 34.5255194099582, "train/post_ent_std": 0.0035546809857787223, "train/prior_ent_mag": 33.81936419740015, "train/prior_ent_max": 33.81936419740015, "train/prior_ent_mean": 33.796001103459574, "train/prior_ent_min": 33.78114702263657, "train/prior_ent_std": 0.00490743438451912, "train/rep_loss_mean": 1.0002453169044183, "train/rep_loss_std": 2.9414811418676865e-05, "train/reward_avg": 0.00032502638179944277, "train/reward_loss_mean": 0.012220422708790521, "train/reward_loss_std": 0.07391252997331321, "train/reward_max_data": 0.10888945876516173, "train/reward_max_pred": 0.00028190016746520996, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.01017929960460383, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.47753193503932, "train/reward_pred": 0.0002816815923528784, "train/reward_rate": 0.00021424585459183673, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014612475410103798, "report/cont_loss_std": 0.24765948951244354, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.61303186416626, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036566639319062233, "report/cont_pred": 0.9963502287864685, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2349604219198227, "report/image_loss_std": 0.0935848206281662, "report/model_loss_mean": 0.8597923517227173, "report/model_loss_std": 0.26528143882751465, "report/post_ent_mag": 34.618289947509766, "report/post_ent_max": 34.618289947509766, "report/post_ent_mean": 34.61158752441406, "report/post_ent_min": 34.59741973876953, "report/post_ent_std": 0.003240829799324274, "report/prior_ent_mag": 33.82954406738281, "report/prior_ent_max": 33.82954406738281, "report/prior_ent_mean": 33.8131103515625, "report/prior_ent_min": 33.801734924316406, "report/prior_ent_std": 0.0037234409246593714, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020763042266480625, "report/reward_loss_mean": 0.010219398885965347, "report/reward_loss_std": 0.01690126582980156, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002824068069458008, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010219399817287922, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002824068069458008, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0036566639319062233, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036566639319062233, "eval/cont_pred": 0.9963502287864685, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.226128488779068, "eval/image_loss_std": 0.0881437361240387, "eval/model_loss_mean": 0.8313072323799133, "eval/model_loss_std": 0.0881437286734581, "eval/post_ent_mag": 34.61823272705078, "eval/post_ent_max": 34.61823272705078, "eval/post_ent_mean": 34.61187744140625, "eval/post_ent_min": 34.59553146362305, "eval/post_ent_std": 0.003207023022696376, "eval/prior_ent_mag": 33.82954406738281, "eval/prior_ent_max": 33.82954406738281, "eval/prior_ent_mean": 33.81285095214844, "eval/prior_ent_min": 33.80370330810547, "eval/prior_ent_std": 0.003746442496776581, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001522064208984375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002824068069458008, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001522064208984375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002824068069458008, "eval/reward_rate": 0.0, "replay/size": 124673.0, "replay/inserts": 31344.0, "replay/samples": 31344.0, "replay/insert_wait_avg": 1.2447832189329185e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.191150813275542e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.097461069056457e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0910358428955, "timer/env.step_count": 3918.0, "timer/env.step_total": 37.04204821586609, "timer/env.step_frac": 0.037038676368743126, "timer/env.step_avg": 0.009454325731461483, "timer/env.step_min": 0.0078105926513671875, "timer/env.step_max": 0.03530311584472656, "timer/replay._sample_count": 31344.0, "timer/replay._sample_total": 15.473330974578857, "timer/replay._sample_frac": 0.015471922475075126, "timer/replay._sample_avg": 0.0004936616569225005, "timer/replay._sample_min": 0.0003566741943359375, "timer/replay._sample_max": 0.025844097137451172, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4785.0, "timer/agent.policy_total": 47.01660370826721, "timer/agent.policy_frac": 0.04701232390173434, "timer/agent.policy_avg": 0.00982583149598061, "timer/agent.policy_min": 0.008577823638916016, "timer/agent.policy_max": 0.0786440372467041, "timer/dataset_train_count": 1959.0, "timer/dataset_train_total": 0.19541263580322266, "timer/dataset_train_frac": 0.0001953948478685495, "timer/dataset_train_avg": 9.975121786790335e-05, "timer/dataset_train_min": 8.702278137207031e-05, "timer/dataset_train_max": 0.00041747093200683594, "timer/agent.train_count": 1959.0, "timer/agent.train_total": 866.4316778182983, "timer/agent.train_frac": 0.8663528086601171, "timer/agent.train_avg": 0.4422826328832559, "timer/agent.train_min": 0.43254899978637695, "timer/agent.train_max": 0.5947475433349609, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.470914363861084, "timer/agent.report_frac": 0.00047087149767739743, "timer/agent.report_avg": 0.235457181930542, "timer/agent.report_min": 0.22919797897338867, "timer/agent.report_max": 0.2417163848876953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1468387690208306e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 31.340601651756472}
{"step": 125256, "time": 4246.8203020095825, "episode/length": 288.0, "episode/score": 0.05141624866990924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05141624866990924}
{"step": 125920, "time": 4267.660006523132, "episode/length": 288.0, "episode/score": 0.07454611951899892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07454611951899892}
{"step": 126384, "time": 4282.290798664093, "episode/length": 288.0, "episode/score": 0.07125258320445482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07125258320445482}
{"step": 126464, "time": 4284.820559978485, "episode/length": 288.0, "episode/score": 0.0515531304642991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0515531304642991}
{"step": 126624, "time": 4289.896334886551, "episode/length": 288.0, "episode/score": 0.04919286018503044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04919286018503044}
{"step": 126800, "time": 4295.460966825485, "episode/length": 288.0, "episode/score": 0.05418901967016154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05418901967016154}
{"step": 127024, "time": 4302.630052089691, "episode/length": 288.0, "episode/score": 0.07365454696162033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07365454696162033}
{"step": 127104, "time": 4305.1607546806335, "episode/length": 230.0, "episode/score": 0.34401973548358455, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.06276973664773777}
{"step": 127160, "time": 4306.706529378891, "episode/length": 288.0, "episode/score": 0.04797910893307744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04797910893307744}
{"step": 128232, "time": 4340.185845851898, "episode/length": 288.0, "episode/score": 0.03811978250166703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03811978250166703}
{"step": 128696, "time": 4354.721898317337, "episode/length": 288.0, "episode/score": 0.08084615779677051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08084615779677051}
{"step": 128776, "time": 4357.274042367935, "episode/length": 288.0, "episode/score": 0.0639207813596272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0639207813596272}
{"step": 128936, "time": 4362.4186289310455, "episode/length": 288.0, "episode/score": 0.07074294083810173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07074294083810173}
{"step": 129112, "time": 4367.980239391327, "episode/length": 288.0, "episode/score": 0.025071649064216217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025071649064216217}
{"step": 129336, "time": 4375.023724794388, "episode/length": 288.0, "episode/score": 0.08588083149453496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08588083149453496}
{"step": 129416, "time": 4377.541821718216, "episode/length": 288.0, "episode/score": 0.07246330738854567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07246330738854567}
{"step": 129472, "time": 4379.511399030685, "episode/length": 288.0, "episode/score": 0.08754238044173235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08754238044173235}
{"step": 130000, "time": 4397.856895685196, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 130000, "time": 4401.740415096283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4401.748029232025, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4401.754829645157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4401.761430263519, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4401.767775297165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4401.774523258209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4401.781317234039, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130544, "time": 4418.792197704315, "episode/length": 288.0, "episode/score": 0.0687148048039603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0687148048039603}
{"step": 131008, "time": 4433.3257484436035, "episode/length": 288.0, "episode/score": 0.08140105303186829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08140105303186829}
{"step": 131088, "time": 4436.283298492432, "episode/length": 288.0, "episode/score": 0.06908232773866985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06908232773866985}
{"step": 131248, "time": 4441.295099258423, "episode/length": 288.0, "episode/score": 0.04158577508030703, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04158577508030703}
{"step": 131424, "time": 4446.801169872284, "episode/length": 288.0, "episode/score": 0.06853727685177091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06853727685177091}
{"step": 131648, "time": 4453.9451496601105, "episode/length": 288.0, "episode/score": 0.038073322262221154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038073322262221154}
{"step": 131728, "time": 4456.447509050369, "episode/length": 288.0, "episode/score": 0.059191299662415986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059191299662415986}
{"step": 131784, "time": 4457.9768970012665, "episode/length": 288.0, "episode/score": 0.04534606276490649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04534606276490649}
{"step": 132856, "time": 4491.610283613205, "episode/length": 288.0, "episode/score": 0.07468158707467865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07468158707467865}
{"step": 133320, "time": 4506.261480331421, "episode/length": 288.0, "episode/score": 0.05408676801607726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05408676801607726}
{"step": 133400, "time": 4508.783971309662, "episode/length": 288.0, "episode/score": 0.08522553222348961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08522553222348961}
{"step": 133560, "time": 4513.898348331451, "episode/length": 288.0, "episode/score": 0.0778008597914095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0778008597914095}
{"step": 133704, "time": 4518.44184589386, "episode/length": 246.0, "episode/score": 0.2750234684777979, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.043773466661718885}
{"step": 133736, "time": 4519.464783668518, "episode/length": 288.0, "episode/score": 0.04975494921382051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04975494921382051}
{"step": 133960, "time": 4526.443630456924, "episode/length": 288.0, "episode/score": 0.06518726820536358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06518726820536358}
{"step": 134096, "time": 4530.9152500629425, "episode/length": 288.0, "episode/score": 0.06327345718943889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06327345718943889}
{"step": 135168, "time": 4564.475495100021, "episode/length": 288.0, "episode/score": 0.07461654286646535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07461654286646535}
{"step": 135632, "time": 4579.60170173645, "episode/length": 288.0, "episode/score": 0.06695812714349358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06695812714349358}
{"step": 135712, "time": 4582.093133687973, "episode/length": 288.0, "episode/score": 0.04513537081601271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04513537081601271}
{"step": 135872, "time": 4587.088065624237, "episode/length": 288.0, "episode/score": 0.047627050885466815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047627050885466815}
{"step": 136016, "time": 4591.604429960251, "episode/length": 288.0, "episode/score": 0.0686348938933179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0686348938933179}
{"step": 136048, "time": 4592.6050136089325, "episode/length": 288.0, "episode/score": 0.0525834883064249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0525834883064249}
{"step": 136272, "time": 4599.617670297623, "episode/length": 288.0, "episode/score": 0.0610379522370863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0610379522370863}
{"step": 136408, "time": 4603.719051837921, "episode/length": 288.0, "episode/score": 0.055855959496000196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055855959496000196}
{"step": 137480, "time": 4637.391890287399, "episode/length": 288.0, "episode/score": 0.06447739010701525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06447739010701525}
{"step": 137944, "time": 4651.925667524338, "episode/length": 288.0, "episode/score": 0.08111044392347821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08111044392347821}
{"step": 138024, "time": 4654.42128777504, "episode/length": 288.0, "episode/score": 0.04380132901957268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04380132901957268}
{"step": 138184, "time": 4659.447635650635, "episode/length": 288.0, "episode/score": 0.0760492718264345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0760492718264345}
{"step": 138328, "time": 4664.045438289642, "episode/length": 288.0, "episode/score": 0.07155617765079114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07155617765079114}
{"step": 138360, "time": 4665.063180208206, "episode/length": 288.0, "episode/score": 0.038449418401228286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038449418401228286}
{"step": 138584, "time": 4672.053785800934, "episode/length": 288.0, "episode/score": 0.07304829125166634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07304829125166634}
{"step": 138720, "time": 4676.525976896286, "episode/length": 288.0, "episode/score": 0.07761443515278188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07761443515278188}
{"step": 139792, "time": 4710.628059625626, "episode/length": 288.0, "episode/score": 0.055699703638993014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055699703638993014}
{"step": 140088, "time": 4724.822878360748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.830548524857, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.837193250656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.845396280289, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.852595090866, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.859839439392, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.866131305695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4724.872079849243, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140256, "time": 4730.33890914917, "episode/length": 288.0, "episode/score": 0.06489397094674132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06489397094674132}
{"step": 140336, "time": 4732.874580621719, "episode/length": 288.0, "episode/score": 0.06785316894342941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06785316894342941}
{"step": 140496, "time": 4737.906622409821, "episode/length": 288.0, "episode/score": 0.06942761697871447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06942761697871447}
{"step": 140640, "time": 4742.4263327121735, "episode/length": 288.0, "episode/score": 0.0606956876579261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0606956876579261}
{"step": 140672, "time": 4743.439540147781, "episode/length": 288.0, "episode/score": 0.0871863963643591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0871863963643591}
{"step": 140712, "time": 4744.478103637695, "episode/length": 265.0, "episode/score": 0.24897123265930077, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.07709623382345399}
{"step": 141032, "time": 4754.56062412262, "episode/length": 288.0, "episode/score": 0.05376325569011442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05376325569011442}
{"step": 142104, "time": 4788.144473075867, "episode/length": 288.0, "episode/score": 0.06986600682739663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06986600682739663}
{"step": 142568, "time": 4802.695345878601, "episode/length": 288.0, "episode/score": 0.054910905018800804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054910905018800804}
{"step": 142648, "time": 4805.202354669571, "episode/length": 288.0, "episode/score": 0.07952344029746428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07952344029746428}
{"step": 142808, "time": 4810.231864452362, "episode/length": 288.0, "episode/score": 0.07360959482878116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07360959482878116}
{"step": 142952, "time": 4814.851769924164, "episode/length": 288.0, "episode/score": 0.05410407198513667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05410407198513667}
{"step": 142984, "time": 4818.962289571762, "episode/length": 288.0, "episode/score": 0.052155113847788925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052155113847788925}
{"step": 143024, "time": 4820.459525823593, "episode/length": 288.0, "episode/score": 0.06564557453287989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06564557453287989}
{"step": 143344, "time": 4830.521264076233, "episode/length": 288.0, "episode/score": 0.03482513933431619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03482513933431619}
{"step": 144216, "time": 4857.9933705329895, "episode/length": 153.0, "episode/score": 0.5543931629534882, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.03251811047346109}
{"step": 144416, "time": 4864.496904850006, "episode/length": 288.0, "episode/score": 0.043195180539612466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043195180539612466}
{"step": 144880, "time": 4879.147956132889, "episode/length": 288.0, "episode/score": 0.040465476048098026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040465476048098026}
{"step": 144960, "time": 4881.678623914719, "episode/length": 288.0, "episode/score": 0.04612260948073299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04612260948073299}
{"step": 145120, "time": 4886.702888011932, "episode/length": 288.0, "episode/score": 0.057523898394435946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057523898394435946}
{"step": 145264, "time": 4891.2291431427, "episode/length": 288.0, "episode/score": 0.06269934151919188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06269934151919188}
{"step": 145336, "time": 4893.259612560272, "episode/length": 288.0, "episode/score": 0.038873584585815024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038873584585815024}
{"step": 145656, "time": 4903.374222278595, "episode/length": 288.0, "episode/score": 0.06790281230223627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06790281230223627}
{"step": 146528, "time": 4930.9098880290985, "episode/length": 288.0, "episode/score": 0.04013379154363861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04013379154363861}
{"step": 146728, "time": 4937.08264875412, "episode/length": 288.0, "episode/score": 0.04719895639226479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04719895639226479}
{"step": 147192, "time": 4951.677004098892, "episode/length": 288.0, "episode/score": 0.04925682783422758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04925682783422758}
{"step": 147272, "time": 4954.185116291046, "episode/length": 288.0, "episode/score": 0.030751945997934627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030751945997934627}
{"step": 147432, "time": 4959.1954872608185, "episode/length": 288.0, "episode/score": 0.038427848594551506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038427848594551506}
{"step": 147576, "time": 4964.348635435104, "episode/length": 288.0, "episode/score": 0.06595095903804804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06595095903804804}
{"step": 147648, "time": 4966.843132257462, "episode/length": 288.0, "episode/score": 0.041276109187009524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041276109187009524}
{"step": 147968, "time": 4976.870959043503, "episode/length": 288.0, "episode/score": 0.039703304155011665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039703304155011665}
{"step": 148840, "time": 5004.108328104019, "episode/length": 288.0, "episode/score": 0.058312834798101676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058312834798101676}
{"step": 149040, "time": 5010.632168531418, "episode/length": 288.0, "episode/score": 0.05195844376220293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05195844376220293}
{"step": 149504, "time": 5025.30893778801, "episode/length": 288.0, "episode/score": 0.057825700705762983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057825700705762983}
{"step": 149584, "time": 5027.839763879776, "episode/length": 288.0, "episode/score": 0.030988643812264627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030988643812264627}
{"step": 149744, "time": 5032.854286909103, "episode/length": 288.0, "episode/score": 0.04537580663736662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04537580663736662}
{"step": 149888, "time": 5037.391498804092, "episode/length": 288.0, "episode/score": 0.0732182970635904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0732182970635904}
{"step": 149960, "time": 5039.432760715485, "episode/length": 288.0, "episode/score": 0.05995339153813006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05995339153813006}
{"step": 150072, "time": 5047.954883575439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5047.962520122528, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5047.970098018646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5047.976595878601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5047.983551740646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5047.990723609924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5047.99783539772, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5048.004895925522, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150280, "time": 5054.610777139664, "episode/length": 288.0, "episode/score": 0.03579930283174804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03579930283174804}
{"step": 150840, "time": 5072.190751314163, "episode/length": 118.0, "episode/score": 0.6631248990931624, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.03187484661313533}
{"step": 151152, "time": 5082.274332284927, "episode/length": 288.0, "episode/score": 0.06555176638804028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06555176638804028}
{"step": 151352, "time": 5088.316118955612, "episode/length": 288.0, "episode/score": 0.05368444141632267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05368444141632267}
{"step": 151816, "time": 5103.023470878601, "episode/length": 288.0, "episode/score": 0.06095404282751815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06095404282751815}
{"step": 151896, "time": 5105.557910442352, "episode/length": 288.0, "episode/score": 0.0320658950004713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0320658950004713}
{"step": 152056, "time": 5110.5845148563385, "episode/length": 288.0, "episode/score": 0.04515945060907711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04515945060907711}
{"step": 152272, "time": 5117.72306895256, "episode/length": 288.0, "episode/score": 0.03769280096994976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03769280096994976}
{"step": 152592, "time": 5127.751204967499, "episode/length": 288.0, "episode/score": 0.06735415393455924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06735415393455924}
{"step": 153152, "time": 5145.372010231018, "episode/length": 288.0, "episode/score": 0.062372384907234846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062372384907234846}
{"step": 153464, "time": 5155.03130197525, "episode/length": 288.0, "episode/score": 0.03987121876548372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03987121876548372}
{"step": 153664, "time": 5161.605765342712, "episode/length": 288.0, "episode/score": 0.057442167236217756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057442167236217756}
{"step": 154128, "time": 5176.443988323212, "episode/length": 288.0, "episode/score": 0.037792215582385325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037792215582385325}
{"step": 154208, "time": 5179.014711380005, "episode/length": 288.0, "episode/score": 0.06114221169752909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06114221169752909}
{"step": 154368, "time": 5184.088320970535, "episode/length": 288.0, "episode/score": 0.06189867344528466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06189867344528466}
{"step": 154584, "time": 5190.732522726059, "episode/length": 288.0, "episode/score": 0.05094374856912509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05094374856912509}
{"step": 154904, "time": 5200.9087109565735, "episode/length": 288.0, "episode/score": 0.05516890860337753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05516890860337753}
{"step": 155464, "time": 5218.792818546295, "episode/length": 288.0, "episode/score": 0.0640395705494825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0640395705494825}
{"step": 155776, "time": 5229.351780653, "episode/length": 288.0, "episode/score": 0.052459595548100424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052459595548100424}
{"step": 155976, "time": 5235.52142906189, "episode/length": 288.0, "episode/score": 0.040561179464361885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040561179464361885}
{"step": 156249, "time": 5245.02631688118, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999809658404478, "train/action_min": 0.0, "train/action_std": 1.999628971532448, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 5.810071194535283e-05, "train/actor_opt_grad_steps": 8695.0, "train/actor_opt_loss": -4.990094541351206, "train/adv_mag": 0.0003143583530003263, "train/adv_max": 0.00024218465556803437, "train/adv_mean": 3.6934991660778046e-05, "train/adv_min": -0.00018412105201445905, "train/adv_std": 7.35109420582882e-05, "train/cont_avg": 0.9964612193943299, "train/cont_loss_mean": 0.023533623816791114, "train/cont_loss_std": 0.32411775761523964, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.658016080657641, "train/cont_pos_acc": 0.9999999846379781, "train/cont_pos_loss": 0.0035252213650911125, "train/cont_pred": 0.9964811129053843, "train/cont_rate": 0.9964612193943299, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.021947522684883747, "train/extr_critic_critic_opt_grad_steps": 8695.0, "train/extr_critic_critic_opt_loss": 13462.256634584408, "train/extr_critic_mag": 0.08905586385235344, "train/extr_critic_max": 0.08905586385235344, "train/extr_critic_mean": 0.08894004688127753, "train/extr_critic_min": 0.08885609980711003, "train/extr_critic_std": 3.352489023254531e-05, "train/extr_return_normed_mag": 0.00039070886895828643, "train/extr_return_normed_max": 0.00029878260702202, "train/extr_return_normed_mean": 0.0001683530189422489, "train/extr_return_normed_min": 3.759862528633825e-05, "train/extr_return_normed_std": 6.100634257296575e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08910737148265249, "train/extr_return_raw_max": 0.08910737148265249, "train/extr_return_raw_mean": 0.0889769458048737, "train/extr_return_raw_min": 0.0888461875009168, "train/extr_return_raw_std": 6.100634341213869e-05, "train/extr_reward_mag": 0.0002731846779892125, "train/extr_reward_max": 0.0002731846779892125, "train/extr_reward_mean": 0.0002730405514702182, "train/extr_reward_min": 0.00027293765667787533, "train/extr_reward_std": 3.8654779539894774e-08, "train/image_loss_mean": 0.2505377232260311, "train/image_loss_std": 0.0849844753050927, "train/model_loss_mean": 0.8856400856652211, "train/model_loss_std": 0.3696067078595923, "train/model_opt_grad_norm": 49.49490323017553, "train/model_opt_grad_steps": 8684.670103092783, "train/model_opt_loss": 2059.818981681902, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2326.0309278350514, "train/policy_entropy_mag": 1.9459025786095059, "train/policy_entropy_max": 1.9459025786095059, "train/policy_entropy_mean": 1.9455166483662791, "train/policy_entropy_min": 1.9374952500628442, "train/policy_entropy_std": 0.0003065273889398068, "train/policy_logprob_mag": 2.106464673563377, "train/policy_logprob_max": -1.7734048944158651, "train/policy_logprob_mean": -1.9455233886069858, "train/policy_logprob_min": -2.106464673563377, "train/policy_logprob_std": 0.027919354512519444, "train/policy_randomness_mag": 0.999996169633472, "train/policy_randomness_max": 0.999996169633472, "train/policy_randomness_mean": 0.9997978388648672, "train/policy_randomness_min": 0.9956756572133487, "train/policy_randomness_std": 0.00015752392592383838, "train/post_ent_mag": 35.23338606922897, "train/post_ent_max": 35.23338606922897, "train/post_ent_mean": 35.223760309907576, "train/post_ent_min": 35.20778636342472, "train/post_ent_std": 0.004309834399951871, "train/prior_ent_mag": 33.87408071694915, "train/prior_ent_max": 33.87408071694915, "train/prior_ent_mean": 33.84597495167526, "train/prior_ent_min": 33.83337408242767, "train/prior_ent_std": 0.005832185426285279, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.00028028955511189517, "train/reward_loss_mean": 0.011568718455424629, "train/reward_loss_std": 0.05753746807824859, "train/reward_max_data": 0.0669909808508687, "train/reward_max_pred": 0.00027318344902746455, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.010101666414783788, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.832852675996978, "train/reward_pred": 0.0002730289190892399, "train/reward_rate": 0.00016611630154639176, "train_stats/mean_log_entropy": 1.9385985301600561, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014561206102371216, "report/cont_loss_std": 0.24903921782970428, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.644169330596924, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0035443599335849285, "report/cont_pred": 0.9964619278907776, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24306350946426392, "report/image_loss_std": 0.07591861486434937, "report/model_loss_mean": 0.8680903911590576, "report/model_loss_std": 0.2624261677265167, "report/post_ent_mag": 37.459686279296875, "report/post_ent_max": 37.459686279296875, "report/post_ent_mean": 37.418983459472656, "report/post_ent_min": 37.388877868652344, "report/post_ent_std": 0.012860613875091076, "report/prior_ent_mag": 34.208641052246094, "report/prior_ent_max": 34.208641052246094, "report/prior_ent_mean": 34.13465881347656, "report/prior_ent_min": 34.092132568359375, "report/prior_ent_std": 0.019060246646404266, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021389039466157556, "report/reward_loss_mean": 0.010465744882822037, "report/reward_loss_std": 0.017543727532029152, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002410411834716797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010465744882822037, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00024099810980260372, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003544360166415572, "eval/cont_loss_std": 2.3283064365386963e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003544360166415572, "eval/cont_pred": 0.9964619278907776, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23501527309417725, "eval/image_loss_std": 0.07583499699831009, "eval/model_loss_mean": 0.8398563861846924, "eval/model_loss_std": 0.0758349820971489, "eval/post_ent_mag": 37.45265579223633, "eval/post_ent_max": 37.45265579223633, "eval/post_ent_mean": 37.41767883300781, "eval/post_ent_min": 37.39274597167969, "eval/post_ent_std": 0.011853925883769989, "eval/prior_ent_mag": 34.20261001586914, "eval/prior_ent_max": 34.20261001586914, "eval/prior_ent_mean": 34.13641357421875, "eval/prior_ent_min": 34.093055725097656, "eval/prior_ent_std": 0.018143169581890106, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012968294322490692, "eval/reward_loss_std": 3.6300082228990505e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002410411834716797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012968294322490692, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000240999273955822, "eval/reward_rate": 0.0, "replay/size": 155745.0, "replay/inserts": 31072.0, "replay/samples": 31072.0, "replay/insert_wait_avg": 1.2588105044576092e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.102103561377795e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0635682318312349e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.443929195404, "timer/env.step_count": 3884.0, "timer/env.step_total": 36.70428276062012, "timer/env.step_frac": 0.03668799588812451, "timer/env.step_avg": 0.009450124294701368, "timer/env.step_min": 0.007752418518066406, "timer/env.step_max": 0.0353701114654541, "timer/replay._sample_count": 31072.0, "timer/replay._sample_total": 15.318271160125732, "timer/replay._sample_frac": 0.015311473949814742, "timer/replay._sample_avg": 0.000492992763907239, "timer/replay._sample_min": 0.00036597251892089844, "timer/replay._sample_max": 0.031378746032714844, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4751.0, "timer/agent.policy_total": 46.82743740081787, "timer/agent.policy_frac": 0.04680665855854443, "timer/agent.policy_avg": 0.009856332856412938, "timer/agent.policy_min": 0.008262872695922852, "timer/agent.policy_max": 0.08416223526000977, "timer/dataset_train_count": 1942.0, "timer/dataset_train_total": 0.19287776947021484, "timer/dataset_train_frac": 0.00019279218339136173, "timer/dataset_train_avg": 9.931913978898807e-05, "timer/dataset_train_min": 8.606910705566406e-05, "timer/dataset_train_max": 0.00023555755615234375, "timer/agent.train_count": 1942.0, "timer/agent.train_total": 865.7667229175568, "timer/agent.train_frac": 0.8653825543364935, "timer/agent.train_avg": 0.44581190675466364, "timer/agent.train_min": 0.4330449104309082, "timer/agent.train_max": 1.0355205535888672, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4678177833557129, "timer/agent.report_frac": 0.0004676101975369576, "timer/agent.report_avg": 0.23390889167785645, "timer/agent.report_min": 0.22548770904541016, "timer/agent.report_max": 0.24233007431030273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.336378991380668e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 31.05772532976923}
{"step": 156440, "time": 5251.837792158127, "episode/length": 288.0, "episode/score": 0.023862742351354882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023862742351354882}
{"step": 156520, "time": 5254.352774381638, "episode/length": 288.0, "episode/score": 0.041793955333389476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041793955333389476}
{"step": 156680, "time": 5259.367262840271, "episode/length": 288.0, "episode/score": 0.04044937872151877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04044937872151877}
{"step": 156896, "time": 5266.431610822678, "episode/length": 288.0, "episode/score": 0.03849605954741264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03849605954741264}
{"step": 157216, "time": 5276.477867603302, "episode/length": 288.0, "episode/score": 0.055445951262299786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055445951262299786}
{"step": 157776, "time": 5294.157016515732, "episode/length": 288.0, "episode/score": 0.035241829772530764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035241829772530764}
{"step": 158088, "time": 5303.774053573608, "episode/length": 288.0, "episode/score": 0.03476234737826189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03476234737826189}
{"step": 158288, "time": 5310.369131326675, "episode/length": 288.0, "episode/score": 0.0511070804271867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0511070804271867}
{"step": 158752, "time": 5325.197783231735, "episode/length": 288.0, "episode/score": 0.041816646758718434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041816646758718434}
{"step": 158832, "time": 5327.786622047424, "episode/length": 288.0, "episode/score": 0.05663241339158276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05663241339158276}
{"step": 158992, "time": 5332.908262491226, "episode/length": 288.0, "episode/score": 0.035434521667184526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035434521667184526}
{"step": 159208, "time": 5339.598410367966, "episode/length": 288.0, "episode/score": 0.04367052871600663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04367052871600663}
{"step": 159528, "time": 5349.713111877441, "episode/length": 288.0, "episode/score": 0.04822591902160411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04822591902160411}
{"step": 160056, "time": 5369.067810297012, "eval_episode/length": 154.0, "eval_episode/score": 0.518750011920929, "eval_episode/reward_rate": 0.0064516129032258064}
{"step": 160056, "time": 5371.351963043213, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.360244274139, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.366874456406, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.3748025894165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.380932807922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.389389038086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5371.397424459457, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160088, "time": 5372.40411233902, "episode/length": 288.0, "episode/score": 0.03681485609047286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03681485609047286}
{"step": 160400, "time": 5382.46408700943, "episode/length": 288.0, "episode/score": 0.05730952644910303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05730952644910303}
{"step": 160600, "time": 5388.510669469833, "episode/length": 288.0, "episode/score": 0.04076737123352814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04076737123352814}
{"step": 161064, "time": 5403.048060894012, "episode/length": 288.0, "episode/score": 0.05613589282256726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05613589282256726}
{"step": 161144, "time": 5405.5553867816925, "episode/length": 288.0, "episode/score": 0.034204062236653954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034204062236653954}
{"step": 161304, "time": 5410.562433481216, "episode/length": 288.0, "episode/score": 0.043671183055550955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043671183055550955}
{"step": 161520, "time": 5417.648281812668, "episode/length": 288.0, "episode/score": 0.029504792958107373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029504792958107373}
{"step": 161840, "time": 5427.858476161957, "episode/length": 288.0, "episode/score": 0.04750869866802532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04750869866802532}
{"step": 162400, "time": 5445.4883580207825, "episode/length": 288.0, "episode/score": 0.03826178001781955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03826178001781955}
{"step": 162712, "time": 5455.164080381393, "episode/length": 288.0, "episode/score": 0.039649843786662586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039649843786662586}
{"step": 162912, "time": 5461.720225572586, "episode/length": 288.0, "episode/score": 0.05463903325465935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05463903325465935}
{"step": 163376, "time": 5476.7812469005585, "episode/length": 288.0, "episode/score": 0.03608636158907075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03608636158907075}
{"step": 163456, "time": 5479.345462322235, "episode/length": 288.0, "episode/score": 0.040632310760827295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040632310760827295}
{"step": 163616, "time": 5484.358815193176, "episode/length": 288.0, "episode/score": 0.03617850722827143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03617850722827143}
{"step": 163832, "time": 5490.934722900391, "episode/length": 288.0, "episode/score": 0.046378921649022686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046378921649022686}
{"step": 164152, "time": 5501.536991119385, "episode/length": 288.0, "episode/score": 0.04624952452161324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04624952452161324}
{"step": 164712, "time": 5519.158162117004, "episode/length": 288.0, "episode/score": 0.05394292200946893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05394292200946893}
{"step": 165024, "time": 5529.173486471176, "episode/length": 288.0, "episode/score": 0.07624256719367395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07624256719367395}
{"step": 165224, "time": 5535.358528614044, "episode/length": 288.0, "episode/score": 0.05495429681354835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05495429681354835}
{"step": 165688, "time": 5549.921183586121, "episode/length": 288.0, "episode/score": 0.04577314933192156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04577314933192156}
{"step": 165768, "time": 5552.446832180023, "episode/length": 288.0, "episode/score": 0.04006730057841423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04006730057841423}
{"step": 165800, "time": 5553.455259561539, "episode/length": 272.0, "episode/score": 0.20808285229554713, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.05808284749923587}
{"step": 166144, "time": 5564.595713376999, "episode/length": 288.0, "episode/score": 0.07304821353278612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07304821353278612}
{"step": 166464, "time": 5574.641303777695, "episode/length": 288.0, "episode/score": 0.04083925070995065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04083925070995065}
{"step": 167024, "time": 5592.350469350815, "episode/length": 288.0, "episode/score": 0.04669836515182624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04669836515182624}
{"step": 167336, "time": 5601.950330018997, "episode/length": 288.0, "episode/score": 0.07729704939998783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07729704939998783}
{"step": 167536, "time": 5608.457863807678, "episode/length": 288.0, "episode/score": 0.051346927940585374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051346927940585374}
{"step": 168000, "time": 5623.113028764725, "episode/length": 288.0, "episode/score": 0.06488090750571018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06488090750571018}
{"step": 168080, "time": 5625.622193098068, "episode/length": 288.0, "episode/score": 0.05325295871654134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05325295871654134}
{"step": 168112, "time": 5626.649564981461, "episode/length": 288.0, "episode/score": 0.05344829407613361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05344829407613361}
{"step": 168456, "time": 5637.227272510529, "episode/length": 288.0, "episode/score": 0.05707698434366648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05707698434366648}
{"step": 168776, "time": 5647.29368185997, "episode/length": 288.0, "episode/score": 0.04861497392198544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04861497392198544}
{"step": 169336, "time": 5665.0571756362915, "episode/length": 288.0, "episode/score": 0.06327101835859139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06327101835859139}
{"step": 169648, "time": 5675.124274492264, "episode/length": 288.0, "episode/score": 0.0541120637089989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0541120637089989}
{"step": 169848, "time": 5681.208146810532, "episode/length": 288.0, "episode/score": 0.041996853629626685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041996853629626685}
{"step": 170040, "time": 5689.210610866547, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 170040, "time": 5693.0170793533325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.024580717087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.031274795532, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.038232088089, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.052551984787, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.0653393268585, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5693.072477579117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170312, "time": 5701.574997425079, "episode/length": 288.0, "episode/score": 0.0689510221573073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0689510221573073}
{"step": 170392, "time": 5704.10625743866, "episode/length": 288.0, "episode/score": 0.02985344978887383, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02985344978887383}
{"step": 170424, "time": 5705.115435600281, "episode/length": 288.0, "episode/score": 0.024503813782501993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024503813782501993}
{"step": 170768, "time": 5716.162504434586, "episode/length": 288.0, "episode/score": 0.05847807436677499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05847807436677499}
{"step": 171088, "time": 5726.185078382492, "episode/length": 288.0, "episode/score": 0.06243380371370222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06243380371370222}
{"step": 171648, "time": 5743.843287706375, "episode/length": 288.0, "episode/score": 0.058192391727345694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058192391727345694}
{"step": 171960, "time": 5753.422706604004, "episode/length": 288.0, "episode/score": 0.04474301390118285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04474301390118285}
{"step": 172160, "time": 5760.394685268402, "episode/length": 288.0, "episode/score": 0.036866789817850076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036866789817850076}
{"step": 172624, "time": 5775.080893278122, "episode/length": 288.0, "episode/score": 0.06229846067657263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06229846067657263}
{"step": 172704, "time": 5777.5973353385925, "episode/length": 288.0, "episode/score": 0.05288308386633389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05288308386633389}
{"step": 172736, "time": 5778.611035585403, "episode/length": 288.0, "episode/score": 0.057941886648620766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057941886648620766}
{"step": 173080, "time": 5789.207041978836, "episode/length": 288.0, "episode/score": 0.062264583964264375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062264583964264375}
{"step": 173400, "time": 5799.272437334061, "episode/length": 288.0, "episode/score": 0.050618768340370934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050618768340370934}
{"step": 173960, "time": 5817.008940935135, "episode/length": 288.0, "episode/score": 0.06195846231051405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06195846231051405}
{"step": 174272, "time": 5827.013906002045, "episode/length": 288.0, "episode/score": 0.06257955974791685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06257955974791685}
{"step": 174472, "time": 5833.17143702507, "episode/length": 288.0, "episode/score": 0.046055818857354325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046055818857354325}
{"step": 174936, "time": 5847.841293811798, "episode/length": 288.0, "episode/score": 0.05402451887579218, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05402451887579218}
{"step": 175016, "time": 5850.38006234169, "episode/length": 288.0, "episode/score": 0.0785114857006306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0785114857006306}
{"step": 175048, "time": 5851.391442298889, "episode/length": 288.0, "episode/score": 0.04773103063641315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04773103063641315}
{"step": 175392, "time": 5862.562536001205, "episode/length": 288.0, "episode/score": 0.04738811559610667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04738811559610667}
{"step": 175712, "time": 5872.7124280929565, "episode/length": 288.0, "episode/score": 0.052664648304471484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052664648304471484}
{"step": 176272, "time": 5890.380700111389, "episode/length": 288.0, "episode/score": 0.06452124165946316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06452124165946316}
{"step": 176584, "time": 5900.08008480072, "episode/length": 288.0, "episode/score": 0.05035775287473143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05035775287473143}
{"step": 176784, "time": 5906.624411821365, "episode/length": 288.0, "episode/score": 0.07333551959297324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07333551959297324}
{"step": 177248, "time": 5921.2054307460785, "episode/length": 288.0, "episode/score": 0.07848733767971794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07848733767971794}
{"step": 177328, "time": 5923.842353343964, "episode/length": 288.0, "episode/score": 0.06658080639900277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06658080639900277}
{"step": 177360, "time": 5924.851265668869, "episode/length": 288.0, "episode/score": 0.08037379908486741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08037379908486741}
{"step": 177704, "time": 5935.4821190834045, "episode/length": 288.0, "episode/score": 0.055207911823487166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055207911823487166}
{"step": 178024, "time": 5945.571265220642, "episode/length": 288.0, "episode/score": 0.062077730939790854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062077730939790854}
{"step": 178296, "time": 5954.2204303741455, "episode/length": 120.0, "episode/score": 0.6578343448061332, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03283431616796406}
{"step": 178584, "time": 5963.243437767029, "episode/length": 288.0, "episode/score": 0.07344155092619076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07344155092619076}
{"step": 178896, "time": 5973.27494764328, "episode/length": 288.0, "episode/score": 0.08309580232332792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08309580232332792}
{"step": 179096, "time": 5979.334431409836, "episode/length": 288.0, "episode/score": 0.056758354738008165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056758354738008165}
{"step": 179560, "time": 5993.957004070282, "episode/length": 288.0, "episode/score": 0.06327520129934783, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06327520129934783}
{"step": 179672, "time": 5997.483573675156, "episode/length": 288.0, "episode/score": 0.06862446298953273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06862446298953273}
{"step": 180016, "time": 6008.553582429886, "episode/length": 288.0, "episode/score": 0.06017587046352446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06017587046352446}
{"step": 180024, "time": 6009.894911766052, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 180024, "time": 6013.862458229065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6013.872142791748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6013.879300832748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6013.886306762695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6013.892840623856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6013.899249076843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6013.905925273895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180336, "time": 6024.451516628265, "episode/length": 288.0, "episode/score": 0.0607063485037429, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0607063485037429}
{"step": 180608, "time": 6032.9743711948395, "episode/length": 288.0, "episode/score": 0.051899614419312456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051899614419312456}
{"step": 180896, "time": 6042.113974571228, "episode/length": 288.0, "episode/score": 0.06268114309619932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06268114309619932}
{"step": 181208, "time": 6051.734251499176, "episode/length": 288.0, "episode/score": 0.08494606666312166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08494606666312166}
{"step": 181408, "time": 6058.273695230484, "episode/length": 288.0, "episode/score": 0.06926460160809711, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06926460160809711}
{"step": 181528, "time": 6061.813498735428, "episode/length": 114.0, "episode/score": 0.6599707339033216, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.01622069334422349}
{"step": 181872, "time": 6072.9363050460815, "episode/length": 288.0, "episode/score": 0.04594359439522577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04594359439522577}
{"step": 181984, "time": 6076.426070213318, "episode/length": 288.0, "episode/score": 0.06284430356572557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06284430356572557}
{"step": 182328, "time": 6086.981545209885, "episode/length": 288.0, "episode/score": 0.07495716068217462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07495716068217462}
{"step": 182648, "time": 6096.968603849411, "episode/length": 288.0, "episode/score": 0.06600566995683721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06600566995683721}
{"step": 183208, "time": 6114.69772362709, "episode/length": 288.0, "episode/score": 0.02765030403725177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02765030403725177}
{"step": 183352, "time": 6119.2302441596985, "episode/length": 242.0, "episode/score": 0.28373359586760216, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.0399835910712909}
{"step": 183520, "time": 6124.70955657959, "episode/length": 288.0, "episode/score": 0.030831232794866992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030831232794866992}
{"step": 183840, "time": 6134.857856750488, "episode/length": 288.0, "episode/score": 0.042456869909131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042456869909131}
{"step": 184184, "time": 6145.403347969055, "episode/length": 288.0, "episode/score": 0.053917276374789935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053917276374789935}
{"step": 184296, "time": 6148.935387372971, "episode/length": 288.0, "episode/score": 0.045441648617128294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045441648617128294}
{"step": 184640, "time": 6160.0122265815735, "episode/length": 288.0, "episode/score": 0.07238582916002656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07238582916002656}
{"step": 184960, "time": 6170.208033323288, "episode/length": 288.0, "episode/score": 0.048947802170374644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048947802170374644}
{"step": 185520, "time": 6187.89439868927, "episode/length": 288.0, "episode/score": 0.044467127398547746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044467127398547746}
{"step": 185664, "time": 6192.595191955566, "episode/length": 288.0, "episode/score": 0.07565985200810132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07565985200810132}
{"step": 185832, "time": 6197.741379976273, "episode/length": 288.0, "episode/score": 0.05326527944254167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05326527944254167}
{"step": 186152, "time": 6207.807390928268, "episode/length": 288.0, "episode/score": 0.057247622806301024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057247622806301024}
{"step": 186496, "time": 6218.838697195053, "episode/length": 288.0, "episode/score": 0.059511167892736694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059511167892736694}
{"step": 186608, "time": 6222.465402841568, "episode/length": 288.0, "episode/score": 0.06465424102660222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06465424102660222}
{"step": 186952, "time": 6233.049298763275, "episode/length": 288.0, "episode/score": 0.05212380077469447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05212380077469447}
{"step": 187272, "time": 6243.111797094345, "episode/length": 288.0, "episode/score": 0.017290309493859013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017290309493859013}
{"step": 187305, "time": 6245.136121034622, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9919827974759614, "train/action_min": 0.0, "train/action_std": 2.009432751093155, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00016930468358250202, "train/actor_opt_grad_steps": 10640.0, "train/actor_opt_loss": -6.011729076275459, "train/adv_mag": 0.0006804921688177647, "train/adv_max": 0.0005610112196359879, "train/adv_mean": -1.7128309258250504e-05, "train/adv_min": -0.0005335590014090905, "train/adv_std": 0.00013712977729133294, "train/cont_avg": 0.9966245993589744, "train/cont_loss_mean": 0.022605186901413478, "train/cont_loss_std": 0.31930423111845857, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.670386687996461, "train/cont_pos_acc": 0.9999999837997632, "train/cont_pos_loss": 0.0034856113569381145, "train/cont_pred": 0.9965205693856264, "train/cont_rate": 0.9966245993589744, "train/dyn_loss_mean": 1.0009836019613805, "train/dyn_loss_std": 0.0010315895695478107, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.011062930891505228, "train/extr_critic_critic_opt_grad_steps": 10640.0, "train/extr_critic_critic_opt_loss": 13470.146694711539, "train/extr_critic_mag": 0.08886897502801357, "train/extr_critic_max": 0.08886897502801357, "train/extr_critic_mean": 0.08859268224392182, "train/extr_critic_min": 0.0880809771708953, "train/extr_critic_std": 0.00010560250556036175, "train/extr_return_normed_mag": 0.000595626311424451, "train/extr_return_normed_max": 0.00040446099562522694, "train/extr_return_normed_mean": 0.00010469850479105448, "train/extr_return_normed_min": -0.00032979742838786197, "train/extr_return_normed_std": 0.00010880920200202709, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08887530962626139, "train/extr_return_raw_max": 0.08887530962626139, "train/extr_return_raw_mean": 0.08857555133409989, "train/extr_return_raw_min": 0.0881410512022483, "train/extr_return_raw_std": 0.00010880920168486997, "train/extr_reward_mag": 0.00026386273212921924, "train/extr_reward_max": 0.00026386273212921924, "train/extr_reward_mean": 0.0002636943216949033, "train/extr_reward_min": 0.00026349593431521687, "train/extr_reward_std": 8.758853546100344e-08, "train/image_loss_mean": 0.23375779214577797, "train/image_loss_std": 0.08645395684318664, "train/model_loss_mean": 0.8682512188569094, "train/model_loss_std": 0.36591157641930455, "train/model_opt_grad_norm": 43.63592478434245, "train/model_opt_grad_steps": 10628.035897435897, "train/model_opt_loss": 2446.278465544872, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2833.3333333333335, "train/policy_entropy_mag": 1.945776235140287, "train/policy_entropy_max": 1.945776235140287, "train/policy_entropy_mean": 1.9393973784568983, "train/policy_entropy_min": 1.8821134958511745, "train/policy_entropy_std": 0.004820237545750271, "train/policy_logprob_mag": 2.459598224590986, "train/policy_logprob_max": -1.4799632809101007, "train/policy_logprob_mean": -1.9394731588852712, "train/policy_logprob_min": -2.459598224590986, "train/policy_logprob_std": 0.10146987934907277, "train/policy_randomness_mag": 0.9999312397761223, "train/policy_randomness_max": 0.9999312397761223, "train/policy_randomness_mean": 0.9966531570141132, "train/policy_randomness_min": 0.967215061493409, "train/policy_randomness_std": 0.002477112229620942, "train/post_ent_mag": 37.138375541491385, "train/post_ent_max": 37.138375541491385, "train/post_ent_mean": 36.96880841377454, "train/post_ent_min": 36.87356102772248, "train/post_ent_std": 0.0654710782548556, "train/prior_ent_mag": 34.72712438534467, "train/prior_ent_max": 34.72712438534467, "train/prior_ent_mean": 34.105750665909206, "train/prior_ent_min": 33.83884644141564, "train/prior_ent_std": 0.1406377345848924, "train/rep_loss_mean": 1.0009836019613805, "train/rep_loss_std": 0.0010315895695478107, "train/reward_avg": 0.0002848106250614644, "train/reward_loss_mean": 0.011298060949700765, "train/reward_loss_std": 0.058020086810947995, "train/reward_max_data": 0.08265427634096108, "train/reward_max_pred": 0.00026407914283948066, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009861132249427147, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.573587673051017, "train/reward_pred": 0.00026382736993046143, "train/reward_rate": 0.00015024038461538462, "train_stats/mean_log_entropy": 1.932656011798165, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020028777420520782, "report/cont_loss_std": 0.30971601605415344, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.73370885848999, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032402994111180305, "report/cont_pred": 0.9967650771141052, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20241262018680573, "report/image_loss_std": 0.09319939464330673, "report/model_loss_mean": 0.8314868211746216, "report/model_loss_std": 0.32239413261413574, "report/post_ent_mag": 32.28575134277344, "report/post_ent_max": 32.28575134277344, "report/post_ent_mean": 32.163116455078125, "report/post_ent_min": 32.06064224243164, "report/post_ent_std": 0.04635365307331085, "report/prior_ent_mag": 31.548561096191406, "report/prior_ent_max": 31.548561096191406, "report/prior_ent_mean": 30.908767700195312, "report/prior_ent_min": 30.239492416381836, "report/prior_ent_std": 0.20052498579025269, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018112090765498579, "report/reward_loss_mean": 0.009045381098985672, "report/reward_loss_std": 0.014924795366823673, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00025653839111328125, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009045381098985672, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00025653839111328125, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0032402994111180305, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032402994111180305, "eval/cont_pred": 0.9967650771141052, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17414435744285583, "eval/image_loss_std": 0.09930669516324997, "eval/model_loss_mean": 0.7788113951683044, "eval/model_loss_std": 0.09930669516324997, "eval/post_ent_mag": 32.28678512573242, "eval/post_ent_max": 32.28678512573242, "eval/post_ent_mean": 32.173370361328125, "eval/post_ent_min": 32.06455612182617, "eval/post_ent_std": 0.05022895708680153, "eval/prior_ent_mag": 31.629650115966797, "eval/prior_ent_max": 31.629650115966797, "eval/prior_ent_mean": 30.977352142333984, "eval/prior_ent_min": 30.281890869140625, "eval/prior_ent_std": 0.23191817104816437, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.00142669677734375, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00025653839111328125, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.00142669677734375, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025653839111328125, "eval/reward_rate": 0.0, "replay/size": 186801.0, "replay/inserts": 31056.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.2657542255721958e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.417735819593034e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0811677578548796e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0915102958679, "timer/env.step_count": 3882.0, "timer/env.step_total": 36.795732498168945, "timer/env.step_frac": 0.03679236561790557, "timer/env.step_avg": 0.009478550360167167, "timer/env.step_min": 0.007771015167236328, "timer/env.step_max": 0.03568124771118164, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 14.739975214004517, "timer/replay._sample_frac": 0.014738626477934834, "timer/replay._sample_avg": 0.00047462568308875955, "timer/replay._sample_min": 0.0003604888916015625, "timer/replay._sample_max": 0.029602766036987305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4749.0, "timer/agent.policy_total": 46.977293968200684, "timer/agent.policy_frac": 0.04697299545548875, "timer/agent.policy_avg": 0.009892039159444237, "timer/agent.policy_min": 0.00833892822265625, "timer/agent.policy_max": 0.08331131935119629, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.19850993156433105, "timer/dataset_train_frac": 0.00019849176752395758, "timer/dataset_train_avg": 0.00010227198947157704, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0004055500030517578, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 867.1052153110504, "timer/agent.train_frac": 0.8670258735168398, "timer/agent.train_avg": 0.44673117738848556, "timer/agent.train_min": 0.4373667240142822, "timer/agent.train_max": 0.5893909931182861, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4771707057952881, "timer/agent.report_frac": 0.0004771270437583472, "timer/agent.report_avg": 0.23858535289764404, "timer/agent.report_min": 0.23117780685424805, "timer/agent.report_max": 0.24599289894104004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051478570793152e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 31.052657816798472}
{"step": 187832, "time": 6261.5015914440155, "episode/length": 288.0, "episode/score": 0.06076898859870994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06076898859870994}
{"step": 187976, "time": 6266.0097777843475, "episode/length": 288.0, "episode/score": 0.03949497851226624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03949497851226624}
{"step": 188144, "time": 6271.542392015457, "episode/length": 288.0, "episode/score": 0.07029815314976418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07029815314976418}
{"step": 188464, "time": 6282.129165649414, "episode/length": 288.0, "episode/score": 0.05561214461226882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05561214461226882}
{"step": 188656, "time": 6288.1502597332, "episode/length": 255.0, "episode/score": 0.28011532233270486, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.07699032349685808}
{"step": 188808, "time": 6292.71631360054, "episode/length": 288.0, "episode/score": 0.0790935008801057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0790935008801057}
{"step": 189264, "time": 6307.302898406982, "episode/length": 288.0, "episode/score": 0.07172419808074437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07172419808074437}
{"step": 189584, "time": 6317.431852579117, "episode/length": 288.0, "episode/score": 0.06616617427812344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06616617427812344}
{"step": 190008, "time": 6335.777799367905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.785999536514, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.795161485672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.800171136856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.806895494461, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.814877033234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.826826572418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6335.842715024948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190144, "time": 6340.354850292206, "episode/length": 288.0, "episode/score": 0.0822857821632681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0822857821632681}
{"step": 190288, "time": 6344.941436052322, "episode/length": 288.0, "episode/score": 0.08022309225904678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08022309225904678}
{"step": 190456, "time": 6349.986141443253, "episode/length": 288.0, "episode/score": 0.07577992055303184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07577992055303184}
{"step": 190776, "time": 6360.063248157501, "episode/length": 288.0, "episode/score": 0.05162206135719316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05162206135719316}
{"step": 190968, "time": 6366.123750448227, "episode/length": 288.0, "episode/score": 0.0661824501812589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0661824501812589}
{"step": 191120, "time": 6371.155725240707, "episode/length": 288.0, "episode/score": 0.06165724298557507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06165724298557507}
{"step": 191576, "time": 6385.362585544586, "episode/length": 288.0, "episode/score": 0.049670992084543286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049670992084543286}
{"step": 191896, "time": 6395.397096633911, "episode/length": 288.0, "episode/score": 0.06114594031419074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06114594031419074}
{"step": 192456, "time": 6413.102615118027, "episode/length": 288.0, "episode/score": 0.07721487836579399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07721487836579399}
{"step": 192600, "time": 6417.619639635086, "episode/length": 288.0, "episode/score": 0.04558320905198343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04558320905198343}
{"step": 192768, "time": 6423.096656560898, "episode/length": 288.0, "episode/score": 0.07594445102370173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07594445102370173}
{"step": 193088, "time": 6433.270405292511, "episode/length": 288.0, "episode/score": 0.08162228839353247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08162228839353247}
{"step": 193280, "time": 6439.27858042717, "episode/length": 288.0, "episode/score": 0.07755328128007477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07755328128007477}
{"step": 193432, "time": 6443.833033800125, "episode/length": 288.0, "episode/score": 0.06321523681577901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06321523681577901}
{"step": 193888, "time": 6458.488603591919, "episode/length": 288.0, "episode/score": 0.05310113129092997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05310113129092997}
{"step": 194208, "time": 6468.680812597275, "episode/length": 288.0, "episode/score": 0.05975899122631745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05975899122631745}
{"step": 194768, "time": 6486.213700294495, "episode/length": 288.0, "episode/score": 0.063204585387723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.063204585387723}
{"step": 194912, "time": 6490.73784661293, "episode/length": 288.0, "episode/score": 0.06099535969246972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06099535969246972}
{"step": 195080, "time": 6495.921427488327, "episode/length": 288.0, "episode/score": 0.07934939530963447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07934939530963447}
{"step": 195400, "time": 6505.957946300507, "episode/length": 288.0, "episode/score": 0.058679491720852184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058679491720852184}
{"step": 195592, "time": 6512.06545996666, "episode/length": 288.0, "episode/score": 0.07203877474466935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07203877474466935}
{"step": 195744, "time": 6517.117543935776, "episode/length": 288.0, "episode/score": 0.06527664777843256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06527664777843256}
{"step": 196200, "time": 6531.391956329346, "episode/length": 288.0, "episode/score": 0.07224743074169737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07224743074169737}
{"step": 196520, "time": 6541.517740011215, "episode/length": 288.0, "episode/score": 0.049314609475857196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049314609475857196}
{"step": 197080, "time": 6559.7561202049255, "episode/length": 288.0, "episode/score": 0.056177046519451324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056177046519451324}
{"step": 197224, "time": 6564.246941804886, "episode/length": 288.0, "episode/score": 0.07509239272167179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07509239272167179}
{"step": 197392, "time": 6569.74450969696, "episode/length": 288.0, "episode/score": 0.04869555082154875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04869555082154875}
{"step": 197712, "time": 6579.909243822098, "episode/length": 288.0, "episode/score": 0.08909152552178057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08909152552178057}
{"step": 197904, "time": 6586.155694484711, "episode/length": 288.0, "episode/score": 0.054635154195466384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054635154195466384}
{"step": 198056, "time": 6591.510292291641, "episode/length": 288.0, "episode/score": 0.04406340513560281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04406340513560281}
{"step": 198512, "time": 6605.99841427803, "episode/length": 288.0, "episode/score": 0.09190324104861247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09190324104861247}
{"step": 198832, "time": 6616.097400188446, "episode/length": 288.0, "episode/score": 0.045316653328654866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045316653328654866}
{"step": 199392, "time": 6633.636923313141, "episode/length": 288.0, "episode/score": 0.0964623552648618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0964623552648618}
{"step": 199536, "time": 6638.1343512535095, "episode/length": 288.0, "episode/score": 0.10318716164692887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10318716164692887}
{"step": 199704, "time": 6643.28521156311, "episode/length": 288.0, "episode/score": 0.08180407876739082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08180407876739082}
{"step": 200024, "time": 6653.329913377762, "episode/length": 288.0, "episode/score": 0.11049305549568089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11049305549568089}
{"step": 200096, "time": 6661.306683778763, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.311675786972, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.318113565445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.324562549591, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.330715417862, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.339100122452, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.346376419067, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6661.35306096077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200216, "time": 6664.879170179367, "episode/length": 288.0, "episode/score": 0.1060793550066137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1060793550066137}
{"step": 200368, "time": 6669.846169710159, "episode/length": 288.0, "episode/score": 0.10215630840389167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10215630840389167}
{"step": 200824, "time": 6683.9778163433075, "episode/length": 288.0, "episode/score": 0.08642482096388449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08642482096388449}
{"step": 201144, "time": 6693.98007273674, "episode/length": 288.0, "episode/score": 0.11176890446745347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11176890446745347}
{"step": 201704, "time": 6711.606215715408, "episode/length": 288.0, "episode/score": 0.08652048908481902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08652048908481902}
{"step": 201848, "time": 6716.131912469864, "episode/length": 288.0, "episode/score": 0.11159050149558425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11159050149558425}
{"step": 202016, "time": 6721.61351442337, "episode/length": 288.0, "episode/score": 0.08420234134734983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08420234134734983}
{"step": 202336, "time": 6731.739439964294, "episode/length": 288.0, "episode/score": 0.07350477673981004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07350477673981004}
{"step": 202528, "time": 6737.745270252228, "episode/length": 288.0, "episode/score": 0.08258347944752131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08258347944752131}
{"step": 202680, "time": 6742.282956361771, "episode/length": 288.0, "episode/score": 0.09061761186330841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09061761186330841}
{"step": 203136, "time": 6756.762341499329, "episode/length": 288.0, "episode/score": 0.11147739687271496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11147739687271496}
{"step": 203456, "time": 6766.874708890915, "episode/length": 288.0, "episode/score": 0.09428351876294983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09428351876294983}
{"step": 204016, "time": 6784.449503183365, "episode/length": 288.0, "episode/score": 0.10049427961007495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10049427961007495}
{"step": 204160, "time": 6788.981575965881, "episode/length": 288.0, "episode/score": 0.04602201681245788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04602201681245788}
{"step": 204328, "time": 6794.117156505585, "episode/length": 288.0, "episode/score": 0.12350983841122343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12350983841122343}
{"step": 204648, "time": 6804.166499614716, "episode/length": 288.0, "episode/score": 0.11317950966906665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11317950966906665}
{"step": 204840, "time": 6810.665535926819, "episode/length": 288.0, "episode/score": 0.07547239628320312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07547239628320312}
{"step": 204992, "time": 6815.637125015259, "episode/length": 288.0, "episode/score": 0.0976315679641857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0976315679641857}
{"step": 205448, "time": 6829.752074480057, "episode/length": 288.0, "episode/score": 0.09205426753817392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09205426753817392}
{"step": 205768, "time": 6839.88685297966, "episode/length": 288.0, "episode/score": 0.08179822183274155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08179822183274155}
{"step": 206328, "time": 6857.652071475983, "episode/length": 288.0, "episode/score": 0.04988161029280036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04988161029280036}
{"step": 206472, "time": 6862.157136678696, "episode/length": 288.0, "episode/score": 0.10633049658736127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10633049658736127}
{"step": 206640, "time": 6867.656900167465, "episode/length": 288.0, "episode/score": 0.09261984784677679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09261984784677679}
{"step": 206960, "time": 6877.645298480988, "episode/length": 288.0, "episode/score": 0.08409277786722669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08409277786722669}
{"step": 207152, "time": 6885.410479068756, "episode/length": 288.0, "episode/score": 0.08781188858893074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08781188858893074}
{"step": 207304, "time": 6889.931501626968, "episode/length": 288.0, "episode/score": 0.05996393433792946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05996393433792946}
{"step": 207760, "time": 6904.471403360367, "episode/length": 288.0, "episode/score": 0.10599801794944597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10599801794944597}
{"step": 208080, "time": 6914.561002492905, "episode/length": 288.0, "episode/score": 0.08133307252921895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08133307252921895}
{"step": 208640, "time": 6932.146883010864, "episode/length": 288.0, "episode/score": 0.114373911152029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.114373911152029}
{"step": 208784, "time": 6936.657476425171, "episode/length": 288.0, "episode/score": 0.11035683162276655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11035683162276655}
{"step": 208952, "time": 6941.863005638123, "episode/length": 288.0, "episode/score": 0.07414219225472607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07414219225472607}
{"step": 209272, "time": 6951.88757443428, "episode/length": 288.0, "episode/score": 0.08851582928014068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08851582928014068}
{"step": 209464, "time": 6957.889400959015, "episode/length": 288.0, "episode/score": 0.12853818919199966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12853818919199966}
{"step": 209616, "time": 6962.893044710159, "episode/length": 288.0, "episode/score": 0.10727938532158987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10727938532158987}
{"step": 210072, "time": 6977.076934099197, "episode/length": 288.0, "episode/score": 0.11059003976049553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11059003976049553}
{"step": 210080, "time": 6982.483803510666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.490843772888, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.498028993607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.504796743393, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.511073112488, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.523553609848, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.531361579895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 6982.537485599518, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210392, "time": 6992.075594186783, "episode/length": 288.0, "episode/score": 0.08982549700340314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08982549700340314}
{"step": 210952, "time": 7009.597503185272, "episode/length": 288.0, "episode/score": 0.0716799131788548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0716799131788548}
{"step": 211096, "time": 7014.12854719162, "episode/length": 288.0, "episode/score": 0.07488551596179605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07488551596179605}
{"step": 211264, "time": 7019.584613084793, "episode/length": 288.0, "episode/score": 0.07878441783248036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07878441783248036}
{"step": 211584, "time": 7029.608808517456, "episode/length": 288.0, "episode/score": 0.076002622959777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.076002622959777}
{"step": 211776, "time": 7035.700071334839, "episode/length": 288.0, "episode/score": 0.07629339043774053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07629339043774053}
{"step": 211928, "time": 7040.246330738068, "episode/length": 288.0, "episode/score": 0.09739335308881891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09739335308881891}
{"step": 212384, "time": 7054.738538742065, "episode/length": 288.0, "episode/score": 0.0693996354010551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0693996354010551}
{"step": 212704, "time": 7064.837268590927, "episode/length": 288.0, "episode/score": 0.06307571449769966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06307571449769966}
{"step": 213144, "time": 7078.94734120369, "episode/length": 234.0, "episode/score": 0.3368706013920928, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.06812059063531706}
{"step": 213264, "time": 7082.949248313904, "episode/length": 288.0, "episode/score": 0.06430348444843048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06430348444843048}
{"step": 213384, "time": 7086.4863266944885, "episode/length": 29.0, "episode/score": 0.920707301022162, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.011332260463063903}
{"step": 213408, "time": 7087.48518204689, "episode/length": 288.0, "episode/score": 0.042654187866673965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042654187866673965}
{"step": 213896, "time": 7102.653407335281, "episode/length": 288.0, "episode/score": 0.0704104094419904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0704104094419904}
{"step": 214088, "time": 7108.684433698654, "episode/length": 288.0, "episode/score": 0.05975747886452609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05975747886452609}
{"step": 214240, "time": 7113.697053432465, "episode/length": 288.0, "episode/score": 0.09923063051201098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09923063051201098}
{"step": 214696, "time": 7127.880564212799, "episode/length": 288.0, "episode/score": 0.0727960921812496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0727960921812496}
{"step": 215016, "time": 7137.913353443146, "episode/length": 288.0, "episode/score": 0.05717580168317227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05717580168317227}
{"step": 215576, "time": 7155.568910360336, "episode/length": 288.0, "episode/score": 0.07596728012475751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07596728012475751}
{"step": 215696, "time": 7159.574279546738, "episode/length": 288.0, "episode/score": 0.06328267598587445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06328267598587445}
{"step": 215720, "time": 7160.11607837677, "episode/length": 288.0, "episode/score": 0.078436134477613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.078436134477613}
{"step": 216208, "time": 7175.603875875473, "episode/length": 288.0, "episode/score": 0.07773450488843991, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07773450488843991}
{"step": 216400, "time": 7181.685561418533, "episode/length": 288.0, "episode/score": 0.071364502837298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.071364502837298}
{"step": 216552, "time": 7186.231627702713, "episode/length": 288.0, "episode/score": 0.04366702752616902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04366702752616902}
{"step": 217008, "time": 7200.726660728455, "episode/length": 288.0, "episode/score": 0.06197337881064868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06197337881064868}
{"step": 217328, "time": 7210.781917333603, "episode/length": 288.0, "episode/score": 0.08121681639744338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08121681639744338}
{"step": 217888, "time": 7228.379225254059, "episode/length": 288.0, "episode/score": 0.09152286389763731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09152286389763731}
{"step": 218008, "time": 7231.9092309474945, "episode/length": 288.0, "episode/score": 0.06970394772804411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06970394772804411}
{"step": 218032, "time": 7232.907160520554, "episode/length": 288.0, "episode/score": 0.07646796250566013, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07646796250566013}
{"step": 218409, "time": 7245.507028579712, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4077302598461663, "train/action_min": 0.0, "train/action_std": 1.8844225296040171, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0004915832946561253, "train/actor_opt_grad_steps": 12585.0, "train/actor_opt_loss": 0.13630367569702187, "train/adv_mag": 0.0025550309453428407, "train/adv_max": 0.002510565611505017, "train/adv_mean": 0.0003809000043329328, "train/adv_min": -0.0012904988582601252, "train/adv_std": 0.0004900176365819001, "train/cont_avg": 0.9964561855670103, "train/cont_loss_mean": 0.023570392410434092, "train/cont_loss_std": 0.32556773730332855, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.654196284711361, "train/cont_pos_acc": 0.9999999846379781, "train/cont_pos_loss": 0.003532554756264327, "train/cont_pred": 0.9964737698589403, "train/cont_rate": 0.9964561855670103, "train/dyn_loss_mean": 1.0000000380978142, "train/dyn_loss_std": 1.2287645469918924e-06, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.082904238034503, "train/extr_critic_critic_opt_grad_steps": 12585.0, "train/extr_critic_critic_opt_loss": 13279.612420465528, "train/extr_critic_mag": 0.09495243768102114, "train/extr_critic_max": 0.09495243768102114, "train/extr_critic_mean": 0.09427354442550964, "train/extr_critic_min": 0.0927874286150195, "train/extr_critic_std": 0.00027919862713105496, "train/extr_return_normed_mag": 0.003541799012533168, "train/extr_return_normed_max": 0.003467393405351442, "train/extr_return_normed_mean": 0.0015029657854343315, "train/extr_return_normed_min": -0.00015716899916068795, "train/extr_return_normed_std": 0.0005058360784272567, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09661885953901969, "train/extr_return_raw_max": 0.09661885953901969, "train/extr_return_raw_mean": 0.09465443750017698, "train/extr_return_raw_min": 0.09299429713450756, "train/extr_return_raw_std": 0.0005058360760269408, "train/extr_reward_mag": 0.0007560498935660136, "train/extr_reward_max": 0.0007560498935660136, "train/extr_reward_mean": 0.00035421990431825983, "train/extr_reward_min": 0.0001264448018418145, "train/extr_reward_std": 0.00016053412353117638, "train/image_loss_mean": 0.20181985030469207, "train/image_loss_std": 0.09680802102402314, "train/model_loss_mean": 0.8364327592948049, "train/model_loss_std": 0.37657737685847525, "train/model_opt_grad_norm": 40.276514397454015, "train/model_opt_grad_steps": 12571.268041237114, "train/model_opt_loss": 2218.5321013460452, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2654.639175257732, "train/policy_entropy_mag": 1.9230665503088962, "train/policy_entropy_max": 1.9230665503088962, "train/policy_entropy_mean": 1.7831649540625896, "train/policy_entropy_min": 1.4690129114794976, "train/policy_entropy_std": 0.054543086342014296, "train/policy_logprob_mag": 3.2294406731104113, "train/policy_logprob_max": -0.7214910934880837, "train/policy_logprob_mean": -1.783692410311748, "train/policy_logprob_min": -3.2294406731104113, "train/policy_logprob_std": 0.5025924871262816, "train/policy_randomness_mag": 0.9882607721176344, "train/policy_randomness_max": 0.9882607721176344, "train/policy_randomness_mean": 0.9163655660201594, "train/policy_randomness_min": 0.7549233439656877, "train/policy_randomness_std": 0.028029603225937515, "train/post_ent_mag": 32.434958005688856, "train/post_ent_max": 32.434958005688856, "train/post_ent_mean": 32.309124042078395, "train/post_ent_min": 32.207524142314476, "train/post_ent_std": 0.05061501663984712, "train/prior_ent_mag": 32.84705066680908, "train/prior_ent_max": 32.84705066680908, "train/prior_ent_mean": 31.23495314293301, "train/prior_ent_min": 30.422116141958334, "train/prior_ent_std": 0.35754954046809795, "train/rep_loss_mean": 1.0000000380978142, "train/rep_loss_std": 1.2287645469918924e-06, "train/reward_avg": 0.0002878032211117091, "train/reward_loss_mean": 0.011042473204049868, "train/reward_loss_std": 0.05877736798900458, "train/reward_max_data": 0.07675945304799825, "train/reward_max_pred": 0.0007094341455046664, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00948381873529366, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.081241788535282, "train/reward_pred": 0.0002604471441579157, "train/reward_rate": 0.00017115012886597937, "train_stats/mean_log_entropy": 1.786262419488695, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.03637713938951492, "report/cont_loss_std": 0.4227522015571594, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.542985439300537, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00392169738188386, "report/cont_pred": 0.9960859417915344, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.19220809638500214, "report/image_loss_std": 0.10747430473566055, "report/model_loss_mean": 0.8448765277862549, "report/model_loss_std": 0.6086960434913635, "report/post_ent_mag": 31.496299743652344, "report/post_ent_max": 31.496299743652344, "report/post_ent_mean": 31.38184356689453, "report/post_ent_min": 31.294189453125, "report/post_ent_std": 0.03887311741709709, "report/prior_ent_mag": 33.7769889831543, "report/prior_ent_max": 33.7769889831543, "report/prior_ent_mean": 31.330730438232422, "report/prior_ent_min": 30.08917999267578, "report/prior_ent_std": 0.5425828695297241, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0005368682323023677, "report/reward_loss_mean": 0.016291208565235138, "report/reward_loss_std": 0.26619744300842285, "report/reward_max_data": 0.37312498688697815, "report/reward_max_pred": 0.0009866952896118164, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007980228401720524, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 8.518425941467285, "report/reward_pred": 0.0002946605673059821, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02014956995844841, "eval/cont_loss_std": 0.29937106370925903, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.542985439300537, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003921848721802235, "eval/cont_pred": 0.9960858225822449, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0001566410064697, "eval/dyn_loss_std": 0.00403641490265727, "eval/image_loss_mean": 0.18081006407737732, "eval/image_loss_std": 0.11123200505971909, "eval/model_loss_mean": 0.8024943470954895, "eval/model_loss_std": 0.3179490566253662, "eval/post_ent_mag": 31.505695343017578, "eval/post_ent_max": 31.505695343017578, "eval/post_ent_mean": 31.39032745361328, "eval/post_ent_min": 31.306026458740234, "eval/post_ent_std": 0.039684850722551346, "eval/prior_ent_mag": 37.43580627441406, "eval/prior_ent_max": 37.43580627441406, "eval/prior_ent_mean": 31.584571838378906, "eval/prior_ent_min": 29.810903549194336, "eval/prior_ent_std": 0.7653330564498901, "eval/rep_loss_mean": 1.0001566410064697, "eval/rep_loss_std": 0.00403641490265727, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001440633088350296, "eval/reward_loss_std": 0.0013834412675350904, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.001215815544128418, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001440633088350296, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00031432160176336765, "eval/reward_rate": 0.0, "replay/size": 217905.0, "replay/inserts": 31104.0, "replay/samples": 31104.0, "replay/insert_wait_avg": 1.1665984191031121e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.150487767325508e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.067521250371702e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3555247783661, "timer/env.step_count": 3888.0, "timer/env.step_total": 35.9032416343689, "timer/env.step_frac": 0.03589048167882458, "timer/env.step_avg": 0.00923437284834591, "timer/env.step_min": 0.0074863433837890625, "timer/env.step_max": 0.0366663932800293, "timer/replay._sample_count": 31104.0, "timer/replay._sample_total": 14.877117156982422, "timer/replay._sample_frac": 0.014871829852970047, "timer/replay._sample_avg": 0.00047830237773220234, "timer/replay._sample_min": 0.0003521442413330078, "timer/replay._sample_max": 0.02070450782775879, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4755.0, "timer/agent.policy_total": 46.09703540802002, "timer/agent.policy_frac": 0.04608065259421949, "timer/agent.policy_avg": 0.0096944343655142, "timer/agent.policy_min": 0.008394002914428711, "timer/agent.policy_max": 0.08083701133728027, "timer/dataset_train_count": 1944.0, "timer/dataset_train_total": 0.19197916984558105, "timer/dataset_train_frac": 0.00019191094075090456, "timer/dataset_train_avg": 9.875471699875569e-05, "timer/dataset_train_min": 8.58306884765625e-05, "timer/dataset_train_max": 0.00041484832763671875, "timer/agent.train_count": 1944.0, "timer/agent.train_total": 868.9945075511932, "timer/agent.train_frac": 0.8686856682715112, "timer/agent.train_avg": 0.44701363557160145, "timer/agent.train_min": 0.43706822395324707, "timer/agent.train_max": 1.1938040256500244, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47197508811950684, "timer/agent.report_frac": 0.00047180734891635184, "timer/agent.report_avg": 0.23598754405975342, "timer/agent.report_min": 0.2299501895904541, "timer/agent.report_max": 0.24202489852905273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7646726079619245e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 31.09242523434877}
{"step": 218520, "time": 7248.739477157593, "episode/length": 288.0, "episode/score": 0.11332730979512462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11332730979512462}
{"step": 218712, "time": 7254.7358045578, "episode/length": 288.0, "episode/score": 0.08730552676962589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08730552676962589}
{"step": 218864, "time": 7259.716258525848, "episode/length": 288.0, "episode/score": 0.07615955171343103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07615955171343103}
{"step": 219320, "time": 7274.029093503952, "episode/length": 288.0, "episode/score": 0.10990307450799719, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10990307450799719}
{"step": 219640, "time": 7284.096990585327, "episode/length": 288.0, "episode/score": 0.10708875603853585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10708875603853585}
{"step": 220064, "time": 7302.800801515579, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.808578252792, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.815872192383, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.822664499283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.829644203186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.837600708008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.845529079437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7302.852663040161, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220200, "time": 7306.919452905655, "episode/length": 288.0, "episode/score": 0.08983551847489935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08983551847489935}
{"step": 220320, "time": 7310.922005653381, "episode/length": 288.0, "episode/score": 0.11624508912319698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11624508912319698}
{"step": 220344, "time": 7311.463803768158, "episode/length": 288.0, "episode/score": 0.10315332638174368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10315332638174368}
{"step": 220832, "time": 7327.00821518898, "episode/length": 288.0, "episode/score": 0.11691735467297804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11691735467297804}
{"step": 221024, "time": 7333.1186311244965, "episode/length": 288.0, "episode/score": 0.10763645183629933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10763645183629933}
{"step": 221176, "time": 7337.675979614258, "episode/length": 288.0, "episode/score": 0.11550785714433687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11550785714433687}
{"step": 221632, "time": 7352.721859693527, "episode/length": 288.0, "episode/score": 0.11471424997375834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11471424997375834}
{"step": 221952, "time": 7362.882188796997, "episode/length": 288.0, "episode/score": 0.09914940937756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09914940937756}
{"step": 222512, "time": 7380.4234137535095, "episode/length": 288.0, "episode/score": 0.12676608703554848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12676608703554848}
{"step": 222632, "time": 7383.945145845413, "episode/length": 288.0, "episode/score": 0.07269104052238617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07269104052238617}
{"step": 222656, "time": 7384.926276922226, "episode/length": 288.0, "episode/score": 0.14113628627683283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14113628627683283}
{"step": 223144, "time": 7400.069977045059, "episode/length": 288.0, "episode/score": 0.07712738789405194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07712738789405194}
{"step": 223336, "time": 7406.080884218216, "episode/length": 288.0, "episode/score": 0.1109339756440022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1109339756440022}
{"step": 223488, "time": 7411.078237295151, "episode/length": 288.0, "episode/score": 0.0961960623651521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0961960623651521}
{"step": 223944, "time": 7425.287901163101, "episode/length": 288.0, "episode/score": 0.11713917003544339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11713917003544339}
{"step": 224264, "time": 7435.331128358841, "episode/length": 288.0, "episode/score": 0.10419474750142399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10419474750142399}
{"step": 224824, "time": 7452.945497274399, "episode/length": 288.0, "episode/score": 0.1144746199383917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1144746199383917}
{"step": 224944, "time": 7456.9395406246185, "episode/length": 288.0, "episode/score": 0.10249412377197586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10249412377197586}
{"step": 224968, "time": 7457.477961301804, "episode/length": 288.0, "episode/score": 0.08818131412488128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08818131412488128}
{"step": 225456, "time": 7472.974403619766, "episode/length": 288.0, "episode/score": 0.09272449136221894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09272449136221894}
{"step": 225648, "time": 7478.980920553207, "episode/length": 288.0, "episode/score": 0.08036970339117033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08036970339117033}
{"step": 225800, "time": 7483.5946300029755, "episode/length": 288.0, "episode/score": 0.066159164361693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.066159164361693}
{"step": 226256, "time": 7498.113555669785, "episode/length": 288.0, "episode/score": 0.0825879971488348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0825879971488348}
{"step": 226576, "time": 7508.173065662384, "episode/length": 288.0, "episode/score": 0.08840397760388896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08840397760388896}
{"step": 227136, "time": 7525.810550928116, "episode/length": 288.0, "episode/score": 0.05769924756907585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05769924756907585}
{"step": 227256, "time": 7529.359701633453, "episode/length": 288.0, "episode/score": 0.08975659943632763, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08975659943632763}
{"step": 227280, "time": 7530.340990304947, "episode/length": 288.0, "episode/score": 0.07646227499503766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07646227499503766}
{"step": 227768, "time": 7545.946651935577, "episode/length": 288.0, "episode/score": 0.07176956123032596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07176956123032596}
{"step": 227960, "time": 7551.9819049835205, "episode/length": 288.0, "episode/score": 0.06196368565957755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06196368565957755}
{"step": 228112, "time": 7556.9623856544495, "episode/length": 288.0, "episode/score": 0.09715777036393547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09715777036393547}
{"step": 228568, "time": 7571.079256057739, "episode/length": 288.0, "episode/score": 0.10643303570242324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10643303570242324}
{"step": 228888, "time": 7581.313956975937, "episode/length": 288.0, "episode/score": 0.0944462208033201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0944462208033201}
{"step": 229448, "time": 7599.473531961441, "episode/length": 288.0, "episode/score": 0.09747001737957817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09747001737957817}
{"step": 229568, "time": 7603.569171667099, "episode/length": 288.0, "episode/score": 0.07631835650505536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07631835650505536}
{"step": 229592, "time": 7604.104027748108, "episode/length": 288.0, "episode/score": 0.10412288191781727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10412288191781727}
{"step": 230048, "time": 7623.581600427628, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.588897943497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.596207857132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.602892160416, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.610764503479, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.618163347244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.624794721603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7623.631272315979, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230080, "time": 7624.638086080551, "episode/length": 288.0, "episode/score": 0.0701714673546121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0701714673546121}
{"step": 230272, "time": 7630.683806180954, "episode/length": 288.0, "episode/score": 0.07856031112453365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07856031112453365}
{"step": 230424, "time": 7635.377598524094, "episode/length": 288.0, "episode/score": 0.09478205711093324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09478205711093324}
{"step": 230880, "time": 7649.872869968414, "episode/length": 288.0, "episode/score": 0.07790285820789222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07790285820789222}
{"step": 231200, "time": 7659.901254653931, "episode/length": 288.0, "episode/score": 0.11508485117605005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11508485117605005}
{"step": 231760, "time": 7677.518814563751, "episode/length": 288.0, "episode/score": 0.07458908474578152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07458908474578152}
{"step": 231880, "time": 7681.05907869339, "episode/length": 288.0, "episode/score": 0.09686055767394919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09686055767394919}
{"step": 231904, "time": 7682.047493457794, "episode/length": 288.0, "episode/score": 0.061704049249954096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061704049249954096}
{"step": 232392, "time": 7697.460474491119, "episode/length": 288.0, "episode/score": 0.09065909695880237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09065909695880237}
{"step": 232584, "time": 7703.542428731918, "episode/length": 288.0, "episode/score": 0.05590084997029976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05590084997029976}
{"step": 232736, "time": 7708.528254032135, "episode/length": 288.0, "episode/score": 0.06631653484626554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06631653484626554}
{"step": 233192, "time": 7722.607754945755, "episode/length": 288.0, "episode/score": 0.06773254798565631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06773254798565631}
{"step": 233512, "time": 7732.587324857712, "episode/length": 288.0, "episode/score": 0.03270260375052203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03270260375052203}
{"step": 234072, "time": 7750.154590845108, "episode/length": 288.0, "episode/score": 0.025715675021814377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025715675021814377}
{"step": 234192, "time": 7754.217398405075, "episode/length": 288.0, "episode/score": 0.026677637151010458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026677637151010458}
{"step": 234216, "time": 7754.752171039581, "episode/length": 288.0, "episode/score": 0.01658003071048597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01658003071048597}
{"step": 234704, "time": 7770.414110660553, "episode/length": 288.0, "episode/score": 0.006374633666524687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006374633666524687}
{"step": 234896, "time": 7776.519502878189, "episode/length": 288.0, "episode/score": 0.0013550344246482382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0013550344246482382}
{"step": 235048, "time": 7781.125611543655, "episode/length": 288.0, "episode/score": 0.0021913999291029995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0021913999291029995}
{"step": 235504, "time": 7795.665347099304, "episode/length": 288.0, "episode/score": 0.004777343988166649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.004777343988166649}
{"step": 235592, "time": 7798.183975219727, "episode/length": 189.0, "episode/score": 0.4223261522276971, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.012951141470921357}
{"step": 235744, "time": 7803.147697210312, "episode/length": 105.0, "episode/score": 0.6822392227453804, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.010364223560287655}
{"step": 235824, "time": 7805.666646003723, "episode/length": 288.0, "episode/score": 0.00017547033635878506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.00017547033635878506}
{"step": 236504, "time": 7826.81050491333, "episode/length": 288.0, "episode/score": 0.013301206322978487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013301206322978487}
{"step": 236528, "time": 7827.785630941391, "episode/length": 288.0, "episode/score": 0.00893795753302129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.00893795753302129}
{"step": 237016, "time": 7843.013648271561, "episode/length": 288.0, "episode/score": 0.006054213992285895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006054213992285895}
{"step": 237360, "time": 7854.044747591019, "episode/length": 288.0, "episode/score": 0.013847232553743538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013847232553743538}
{"step": 237816, "time": 7868.56684756279, "episode/length": 288.0, "episode/score": 0.016868136362717223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016868136362717223}
{"step": 237904, "time": 7871.5857474803925, "episode/length": 288.0, "episode/score": 0.015835874245539117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015835874245539117}
{"step": 238056, "time": 7876.12752699852, "episode/length": 288.0, "episode/score": 0.015897005772771422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015897005772771422}
{"step": 238136, "time": 7878.7031536102295, "episode/length": 288.0, "episode/score": 0.019496618335494986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019496618335494986}
{"step": 238552, "time": 7891.756083488464, "episode/length": 255.0, "episode/score": 0.23354428686512563, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.030419288029278846}
{"step": 238840, "time": 7900.923197746277, "episode/length": 288.0, "episode/score": 0.036572954779444444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036572954779444444}
{"step": 239328, "time": 7916.623796224594, "episode/length": 288.0, "episode/score": 0.038296356892686845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038296356892686845}
{"step": 239672, "time": 7927.190512180328, "episode/length": 288.0, "episode/score": 0.08122263735160118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08122263735160118}
{"step": 240032, "time": 7943.722685575485, "eval_episode/length": 248.0, "eval_episode/score": 0.22499999403953552, "eval_episode/reward_rate": 0.004016064257028112}
{"step": 240032, "time": 7944.41886973381, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7944.426804304123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7944.434033632278, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7944.440681219101, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7944.4472219944, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7944.4532122612, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7944.460332870483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240128, "time": 7947.505356788635, "episode/length": 288.0, "episode/score": 0.07996773744227426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07996773744227426}
{"step": 240216, "time": 7950.080074548721, "episode/length": 288.0, "episode/score": 0.10239016585489935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10239016585489935}
{"step": 240368, "time": 7955.154542922974, "episode/length": 288.0, "episode/score": 0.066223569625663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.066223569625663}
{"step": 240448, "time": 7957.711784362793, "episode/length": 288.0, "episode/score": 0.08593297217089457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08593297217089457}
{"step": 240864, "time": 7970.985481500626, "episode/length": 288.0, "episode/score": 0.08157770531420283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08157770531420283}
{"step": 241152, "time": 7980.086634159088, "episode/length": 288.0, "episode/score": 0.09774410260934019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09774410260934019}
{"step": 241640, "time": 7995.34737610817, "episode/length": 288.0, "episode/score": 0.11227639741531448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11227639741531448}
{"step": 241984, "time": 8006.3849840164185, "episode/length": 288.0, "episode/score": 0.10498188283781928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10498188283781928}
{"step": 242440, "time": 8020.4686160087585, "episode/length": 288.0, "episode/score": 0.11624682472177028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11624682472177028}
{"step": 242528, "time": 8023.565626144409, "episode/length": 288.0, "episode/score": 0.08996658205205676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08996658205205676}
{"step": 242680, "time": 8028.104141712189, "episode/length": 288.0, "episode/score": 0.08672684147995824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08672684147995824}
{"step": 242760, "time": 8030.610112905502, "episode/length": 288.0, "episode/score": 0.0753424262239264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0753424262239264}
{"step": 243176, "time": 8043.733013391495, "episode/length": 288.0, "episode/score": 0.059197445262270776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059197445262270776}
{"step": 243464, "time": 8052.864233016968, "episode/length": 288.0, "episode/score": 0.08338591013648511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08338591013648511}
{"step": 243952, "time": 8068.374423027039, "episode/length": 288.0, "episode/score": 0.0752343143425378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0752343143425378}
{"step": 244296, "time": 8078.957803249359, "episode/length": 288.0, "episode/score": 0.12779334479569116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12779334479569116}
{"step": 244496, "time": 8085.535650730133, "episode/length": 256.0, "episode/score": 0.28532457610884876, "episode/reward_rate": 0.0038910505836575876, "episode/intrinsic_return": 0.08532457394352377}
{"step": 244840, "time": 8096.099016189575, "episode/length": 288.0, "episode/score": 0.06692009362950557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06692009362950557}
{"step": 244864, "time": 8097.072407245636, "episode/length": 113.0, "episode/score": 0.6910151266075104, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.04414007412748333}
{"step": 244872, "time": 8097.108409404755, "episode/length": 273.0, "episode/score": 0.24853561737080554, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.10166062449542324}
{"step": 245072, "time": 8103.595005273819, "episode/length": 288.0, "episode/score": 0.10340045264575792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10340045264575792}
{"step": 245488, "time": 8116.6742560863495, "episode/length": 288.0, "episode/score": 0.10225438656198094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10225438656198094}
{"step": 245776, "time": 8126.217122554779, "episode/length": 288.0, "episode/score": 0.12110874815539319, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12110874815539319}
{"step": 246608, "time": 8152.312511920929, "episode/length": 288.0, "episode/score": 0.10502080585467866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10502080585467866}
{"step": 246808, "time": 8158.364865064621, "episode/length": 288.0, "episode/score": 0.08655207456911285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08655207456911285}
{"step": 247152, "time": 8169.336022377014, "episode/length": 288.0, "episode/score": 0.09119444585928704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09119444585928704}
{"step": 247176, "time": 8169.870084285736, "episode/length": 288.0, "episode/score": 0.1260886699753314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1260886699753314}
{"step": 247184, "time": 8170.350009441376, "episode/length": 288.0, "episode/score": 0.09487401990401167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09487401990401167}
{"step": 247384, "time": 8176.435380458832, "episode/length": 288.0, "episode/score": 0.12002635043535292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12002635043535292}
{"step": 247800, "time": 8189.4617710113525, "episode/length": 288.0, "episode/score": 0.12155258371893751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12155258371893751}
{"step": 248088, "time": 8198.44212436676, "episode/length": 288.0, "episode/score": 0.10557564997850477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10557564997850477}
{"step": 248384, "time": 8208.033752679825, "episode/length": 150.0, "episode/score": 0.576153907567118, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.044903893248033455}
{"step": 248920, "time": 8224.721396684647, "episode/length": 288.0, "episode/score": 0.07341884396998921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07341884396998921}
{"step": 249016, "time": 8227.768681526184, "episode/length": 78.0, "episode/score": 0.7882901096394903, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03204008661253965}
{"step": 249120, "time": 8231.315150976181, "episode/length": 288.0, "episode/score": 0.07810102469431968, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07810102469431968}
{"step": 249288, "time": 8236.47668671608, "episode/length": 266.0, "episode/score": 0.2561396883797329, "episode/reward_rate": 0.003745318352059925, "episode/intrinsic_return": 0.08738968656365387}
{"step": 249496, "time": 8242.998054265976, "episode/length": 288.0, "episode/score": 0.0745051092926019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0745051092926019}
{"step": 249545, "time": 8245.556436777115, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.620111553485577, "train/action_min": 0.0, "train/action_std": 1.7510148054514176, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0015123497876816262, "train/actor_opt_grad_steps": 14530.0, "train/actor_opt_loss": 1.9908068164108463, "train/adv_mag": 0.005921202439528245, "train/adv_max": 0.005712863497245006, "train/adv_mean": 0.0007935297788907729, "train/adv_min": -0.002303444727873191, "train/adv_std": 0.0010678965802817869, "train/cont_avg": 0.9965494791666667, "train/cont_loss_mean": 0.023028434059606532, "train/cont_loss_std": 0.32203680168814597, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.673765876750254, "train/cont_pos_acc": 0.9999999871620765, "train/cont_pos_loss": 0.003464377517453753, "train/cont_pred": 0.9965416902150863, "train/cont_rate": 0.9965494791666667, "train/dyn_loss_mean": 1.000005963521126, "train/dyn_loss_std": 0.00017885194960026404, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08444926019113225, "train/extr_critic_critic_opt_grad_steps": 14530.0, "train/extr_critic_critic_opt_loss": 11090.077924679486, "train/extr_critic_mag": 0.1234685310950646, "train/extr_critic_max": 0.1234685310950646, "train/extr_critic_mean": 0.12240984898347121, "train/extr_critic_min": 0.12044943418258276, "train/extr_critic_std": 0.00041201402745149934, "train/extr_return_normed_mag": 0.008278527626624474, "train/extr_return_normed_max": 0.00826206230200254, "train/extr_return_normed_mean": 0.0032236617798611033, "train/extr_return_normed_min": 6.743933145816509e-05, "train/extr_return_normed_std": 0.001141055502767603, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.12824177180345242, "train/extr_return_raw_max": 0.12824177180345242, "train/extr_return_raw_mean": 0.12320337776954357, "train/extr_return_raw_min": 0.12004714883290804, "train/extr_return_raw_std": 0.0011410555021706013, "train/extr_reward_mag": 0.0022749503453572593, "train/extr_reward_max": 0.0022749503453572593, "train/extr_reward_mean": 0.000476618105909811, "train/extr_reward_min": 3.6263465881347655e-05, "train/extr_reward_std": 0.0003694570807662482, "train/image_loss_mean": 0.19184335821714157, "train/image_loss_std": 0.10166608779094158, "train/model_loss_mean": 0.825717152082003, "train/model_loss_std": 0.3682815534564165, "train/model_opt_grad_norm": 37.5181576753274, "train/model_opt_grad_steps": 14514.569230769232, "train/model_opt_loss": 2341.4494272085335, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2833.3333333333335, "train/policy_entropy_mag": 1.7974089396305573, "train/policy_entropy_max": 1.7974089396305573, "train/policy_entropy_mean": 1.4116347474929614, "train/policy_entropy_min": 0.6599116649765234, "train/policy_entropy_std": 0.18881615908482136, "train/policy_logprob_mag": 4.854580632234231, "train/policy_logprob_max": -0.19998380936300142, "train/policy_logprob_mean": -1.4119562439429454, "train/policy_logprob_min": -4.854580632234231, "train/policy_logprob_std": 0.8298668733009925, "train/policy_randomness_mag": 0.9236855302101526, "train/policy_randomness_max": 0.9236855302101526, "train/policy_randomness_mean": 0.725436804157037, "train/policy_randomness_min": 0.3391275326984051, "train/policy_randomness_std": 0.0970323176147082, "train/post_ent_mag": 30.4464784964537, "train/post_ent_max": 30.4464784964537, "train/post_ent_mean": 30.346310561742538, "train/post_ent_min": 30.252700962164464, "train/post_ent_std": 0.03804614945099904, "train/prior_ent_mag": 32.98000699556791, "train/prior_ent_max": 32.98000699556791, "train/prior_ent_mean": 30.82163614126352, "train/prior_ent_min": 29.55917402414175, "train/prior_ent_std": 0.4952518900235494, "train/rep_loss_mean": 1.000005963521126, "train/rep_loss_std": 0.00017885194960026404, "train/reward_avg": 0.000290034967698515, "train/reward_loss_mean": 0.01084176188048262, "train/reward_loss_std": 0.050674102684626215, "train/reward_max_data": 0.0702222245781181, "train/reward_max_pred": 0.001687946686377892, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009559002695366359, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.337576756110558, "train/reward_pred": 0.00026998529568887674, "train/reward_rate": 0.00015524839743589743, "train_stats/mean_log_entropy": 1.4027333217007774, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020093223080039024, "report/cont_loss_std": 0.3029601275920868, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.609139919281006, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036709497217088938, "report/cont_pred": 0.9963359236717224, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.18305844068527222, "report/image_loss_std": 0.09689588844776154, "report/model_loss_mean": 0.8106210231781006, "report/model_loss_std": 0.3181740343570709, "report/post_ent_mag": 30.274187088012695, "report/post_ent_max": 30.274187088012695, "report/post_ent_mean": 30.144811630249023, "report/post_ent_min": 30.01256561279297, "report/post_ent_std": 0.05016360059380531, "report/prior_ent_mag": 31.791309356689453, "report/prior_ent_max": 31.791309356689453, "report/prior_ent_mean": 30.026439666748047, "report/prior_ent_min": 28.72686195373535, "report/prior_ent_std": 0.5042716860771179, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00016695729573257267, "report/reward_loss_mean": 0.007469361647963524, "report/reward_loss_std": 0.013845308683812618, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0018124580383300781, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007469361647963524, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000226098345592618, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020093228667974472, "eval/cont_loss_std": 0.3029600977897644, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.609139919281006, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00367094948887825, "eval/cont_pred": 0.9963359236717224, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20378394424915314, "eval/image_loss_std": 0.11118607968091965, "eval/model_loss_mean": 0.8251542448997498, "eval/model_loss_std": 0.32342594861984253, "eval/post_ent_mag": 30.280078887939453, "eval/post_ent_max": 30.280078887939453, "eval/post_ent_mean": 30.144916534423828, "eval/post_ent_min": 30.012680053710938, "eval/post_ent_std": 0.048632655292749405, "eval/prior_ent_mag": 31.54157257080078, "eval/prior_ent_max": 31.54157257080078, "eval/prior_ent_mean": 29.935867309570312, "eval/prior_ent_min": 28.589492797851562, "eval/prior_ent_std": 0.504432201385498, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012770830653607845, "eval/reward_loss_std": 0.0014774358132854104, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0024760961532592773, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012770830653607845, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022237072698771954, "eval/reward_rate": 0.0, "replay/size": 249041.0, "replay/inserts": 31136.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.179963687218473e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.275457494918023e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.04854676137746e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0295157432556, "timer/env.step_count": 3892.0, "timer/env.step_total": 35.22438931465149, "timer/env.step_frac": 0.03522334967130599, "timer/env.step_avg": 0.009050459741688461, "timer/env.step_min": 0.007247209548950195, "timer/env.step_max": 0.034392595291137695, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 15.10681414604187, "timer/replay._sample_frac": 0.015106368270354477, "timer/replay._sample_avg": 0.0004851880185650652, "timer/replay._sample_min": 0.00035190582275390625, "timer/replay._sample_max": 0.028934478759765625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4759.0, "timer/agent.policy_total": 46.31849718093872, "timer/agent.policy_frac": 0.046317130096418455, "timer/agent.policy_avg": 0.009732821429068863, "timer/agent.policy_min": 0.008389711380004883, "timer/agent.policy_max": 0.08794975280761719, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.19597363471984863, "timer/dataset_train_frac": 0.00019596785058308448, "timer/dataset_train_avg": 0.00010070587601225521, "timer/dataset_train_min": 8.416175842285156e-05, "timer/dataset_train_max": 0.0010564327239990234, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 870.8177046775818, "timer/agent.train_frac": 0.8707920026044039, "timer/agent.train_avg": 0.44749111237285805, "timer/agent.train_min": 0.4346926212310791, "timer/agent.train_max": 0.5990583896636963, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4789698123931885, "timer/agent.report_frac": 0.00047895567566043487, "timer/agent.report_avg": 0.23948490619659424, "timer/agent.report_min": 0.23344159126281738, "timer/agent.report_max": 0.2455282211303711, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.170873511362324e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.1344779060615}
{"step": 249696, "time": 8250.30159854889, "episode/length": 288.0, "episode/score": 0.10618652152078312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10618652152078312}
{"step": 250016, "time": 8262.79459309578, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 250016, "time": 8262.852984189987, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 250016, "time": 8263.98364496231, "eval_episode/length": 207.0, "eval_episode/score": 0.3531250059604645, "eval_episode/reward_rate": 0.004807692307692308}
{"step": 250016, "time": 8265.382516145706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8265.390502691269, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8265.397750377655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8265.40415096283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8265.410909891129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250112, "time": 8268.403645515442, "episode/length": 288.0, "episode/score": 0.08821322528484643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08821322528484643}
{"step": 250288, "time": 8273.876559734344, "episode/length": 98.0, "episode/score": 0.7400159325513869, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04626590952443621}
{"step": 250400, "time": 8277.383784294128, "episode/length": 288.0, "episode/score": 0.09518912695364179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09518912695364179}
{"step": 251232, "time": 8303.38598036766, "episode/length": 288.0, "episode/score": 0.08320451642529747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08320451642529747}
{"step": 251232, "time": 8303.39386510849, "episode/length": 191.0, "episode/score": 0.4528593237395171, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.049734321341361465}
{"step": 251328, "time": 8306.394517183304, "episode/length": 288.0, "episode/score": 0.10888107496904809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10888107496904809}
{"step": 251400, "time": 8308.419652700424, "episode/length": 284.0, "episode/score": 0.20012541607559342, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.08762541963790227}
{"step": 251600, "time": 8314.907531499863, "episode/length": 288.0, "episode/score": 0.0974232495760532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0974232495760532}
{"step": 252120, "time": 8331.077881336212, "episode/length": 64.0, "episode/score": 0.8174484142918459, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.01744837902964491}
{"step": 252392, "time": 8340.272876262665, "episode/length": 248.0, "episode/score": 0.2894306696336457, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.06443068205516056}
{"step": 252424, "time": 8341.276429891586, "episode/length": 288.0, "episode/score": 0.06663117846264299, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06663117846264299}
{"step": 252600, "time": 8346.763951778412, "episode/length": 288.0, "episode/score": 0.08360258289704348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08360258289704348}
{"step": 253544, "time": 8376.320852994919, "episode/length": 288.0, "episode/score": 0.05263521963894391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05263521963894391}
{"step": 253544, "time": 8376.329246997833, "episode/length": 288.0, "episode/score": 0.05731952712019961, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05731952712019961}
{"step": 253640, "time": 8379.37488412857, "episode/length": 288.0, "episode/score": 0.06667085122492722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06667085122492722}
{"step": 253712, "time": 8382.014528751373, "episode/length": 288.0, "episode/score": 0.07423911032526576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07423911032526576}
{"step": 253880, "time": 8387.1339905262, "episode/length": 41.0, "episode/score": 0.8832184129601615, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.011343395486221652}
{"step": 254432, "time": 8405.142406702042, "episode/length": 288.0, "episode/score": 0.054838870412055485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054838870412055485}
{"step": 254496, "time": 8407.162177562714, "episode/length": 106.0, "episode/score": 0.7053962579294364, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.03664624045549658}
{"step": 254704, "time": 8413.87757229805, "episode/length": 288.0, "episode/score": 0.058395993559344106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058395993559344106}
{"step": 254736, "time": 8414.893673658371, "episode/length": 288.0, "episode/score": 0.0649430127575954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0649430127575954}
{"step": 254912, "time": 8420.45458316803, "episode/length": 288.0, "episode/score": 0.05024805141948718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05024805141948718}
{"step": 255192, "time": 8429.132664203644, "episode/length": 205.0, "episode/score": 0.4103167981945717, "episode/reward_rate": 0.0048543689320388345, "episode/intrinsic_return": 0.050941790016395316}
{"step": 255304, "time": 8432.678264856339, "episode/length": 198.0, "episode/score": 0.4292769216854708, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.048026919467758944}
{"step": 255440, "time": 8437.183810710907, "episode/length": 91.0, "episode/score": 0.7309843953227357, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.015359392924580106}
{"step": 256192, "time": 8460.664816856384, "episode/length": 288.0, "episode/score": 0.08478622839078298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08478622839078298}
{"step": 256744, "time": 8477.672767877579, "episode/length": 288.0, "episode/score": 0.07149639917241757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07149639917241757}
{"step": 256808, "time": 8479.67675614357, "episode/length": 288.0, "episode/score": 0.07074368535850795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07074368535850795}
{"step": 257048, "time": 8487.126783132553, "episode/length": 288.0, "episode/score": 0.05241954105673585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05241954105673585}
{"step": 257224, "time": 8492.629379272461, "episode/length": 288.0, "episode/score": 0.033500331469781486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033500331469781486}
{"step": 257504, "time": 8501.641046524048, "episode/length": 288.0, "episode/score": 0.04596835493836693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04596835493836693}
{"step": 257616, "time": 8505.132592201233, "episode/length": 288.0, "episode/score": 0.048002930181525016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048002930181525016}
{"step": 257752, "time": 8509.195692539215, "episode/length": 288.0, "episode/score": 0.040939773669549595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040939773669549595}
{"step": 258400, "time": 8529.794860601425, "episode/length": 97.0, "episode/score": 0.7251344144832501, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.028259458464958698}
{"step": 258504, "time": 8532.886868953705, "episode/length": 288.0, "episode/score": 0.040099398210060144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040099398210060144}
{"step": 259056, "time": 8550.3359208107, "episode/length": 288.0, "episode/score": 0.05910945467525153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05910945467525153}
{"step": 259072, "time": 8550.842290401459, "episode/length": 195.0, "episode/score": 0.4168803035270514, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.026255289207966825}
{"step": 259120, "time": 8552.344721794128, "episode/length": 288.0, "episode/score": 0.04001293052911592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04001293052911592}
{"step": 259320, "time": 8558.408410549164, "episode/length": 261.0, "episode/score": 0.2277089474038263, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.04333395088464442}
{"step": 259360, "time": 8559.874225854874, "episode/length": 288.0, "episode/score": 0.05372704467066569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05372704467066569}
{"step": 259912, "time": 8576.939388513565, "episode/length": 188.0, "episode/score": 0.4654332305645852, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.05293323674332839}
{"step": 259968, "time": 8578.926132202148, "episode/length": 111.0, "episode/score": 0.6805766635506245, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.027451667293377113}
{"step": 260000, "time": 8582.382647752762, "eval_episode/length": 141.0, "eval_episode/score": 0.559374988079071, "eval_episode/reward_rate": 0.007042253521126761}
{"step": 260000, "time": 8582.932916641235, "eval_episode/length": 172.0, "eval_episode/score": 0.4625000059604645, "eval_episode/reward_rate": 0.005780346820809248}
{"step": 260000, "time": 8583.328245162964, "eval_episode/length": 195.0, "eval_episode/score": 0.390625, "eval_episode/reward_rate": 0.00510204081632653}
{"step": 260000, "time": 8584.010729551315, "eval_episode/length": 234.0, "eval_episode/score": 0.26875001192092896, "eval_episode/reward_rate": 0.00425531914893617}
{"step": 260000, "time": 8584.644981145859, "eval_episode/length": 271.0, "eval_episode/score": 0.15312500298023224, "eval_episode/reward_rate": 0.003676470588235294}
{"step": 260000, "time": 8584.94123673439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8584.949942588806, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8584.959253072739, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260064, "time": 8586.975489377975, "episode/length": 288.0, "episode/score": 0.14840048402429318, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.04840048282521536}
{"step": 260224, "time": 8592.108994483948, "episode/length": 214.0, "episode/score": 0.3793144584000032, "episode/reward_rate": 0.004651162790697674, "episode/intrinsic_return": 0.04806443931953197}
{"step": 260352, "time": 8596.165765047073, "episode/length": 47.0, "episode/score": 0.8638664110939516, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.010741455075660156}
{"step": 260632, "time": 8604.64583826065, "episode/length": 89.0, "episode/score": 0.7443071966996229, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.022432204918544585}
{"step": 261360, "time": 8627.512400865555, "episode/length": 125.0, "episode/score": 0.637281215626885, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.02790621584516373}
{"step": 261368, "time": 8627.550567865372, "episode/length": 288.0, "episode/score": 0.06349623286088502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06349623286088502}
{"step": 261432, "time": 8629.54484796524, "episode/length": 288.0, "episode/score": 0.07276362181175955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07276362181175955}
{"step": 261632, "time": 8635.93093252182, "episode/length": 288.0, "episode/score": 0.05221217355673957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05221217355673957}
{"step": 261632, "time": 8635.938812732697, "episode/length": 283.0, "episode/score": 0.1662944279170091, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.050669426630619796}
{"step": 261696, "time": 8637.917544841766, "episode/length": 183.0, "episode/score": 0.4653970033634067, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.03727200954214993}
{"step": 262000, "time": 8647.396682024002, "episode/length": 79.0, "episode/score": 0.7885229214278127, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.035397924611771714}
{"step": 262248, "time": 8655.64764213562, "episode/length": 30.0, "episode/score": 0.9130922309457077, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.006842243023797323}
{"step": 262336, "time": 8658.655143499374, "episode/length": 120.0, "episode/score": 0.6769764552550015, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.05197647539485217}
{"step": 262376, "time": 8659.722380161285, "episode/length": 288.0, "episode/score": 0.06998491298864451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06998491298864451}
{"step": 262584, "time": 8666.321150302887, "episode/length": 243.0, "episode/score": 0.2718768469424191, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.03125185936393393}
{"step": 262696, "time": 8669.90017914772, "episode/length": 44.0, "episode/score": 0.8791985524642172, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.016698566765839473}
{"step": 262744, "time": 8671.424804925919, "episode/length": 130.0, "episode/score": 0.6218206789778122, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.028070679196090964}
{"step": 263048, "time": 8680.96318435669, "episode/length": 57.0, "episode/score": 0.8398479893598676, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.017973013420004236}
{"step": 263120, "time": 8683.534469604492, "episode/length": 185.0, "episode/score": 0.46233705367426126, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.04046205009449011}
{"step": 263440, "time": 8693.557521104813, "episode/length": 132.0, "episode/score": 0.6084595123964078, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.02095950684339698}
{"step": 263576, "time": 8697.600571870804, "episode/length": 242.0, "episode/score": 0.28685987372590205, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.04310986060589528}
{"step": 263600, "time": 8698.574273586273, "episode/length": 59.0, "episode/score": 0.8225502685426562, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.00692522850742705}
{"step": 263624, "time": 8699.10784626007, "episode/length": 273.0, "episode/score": 0.1829631091867583, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.03608811683524493}
{"step": 264112, "time": 8714.621225118637, "episode/length": 83.0, "episode/score": 0.7513475437829698, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.01072253708326798}
{"step": 264208, "time": 8717.59695148468, "episode/length": 182.0, "episode/score": 0.4680166949198252, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.03676668487027257}
{"step": 264240, "time": 8718.58955860138, "episode/length": 82.0, "episode/score": 0.7617068639244735, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01795691398888266}
{"step": 264408, "time": 8723.578085660934, "episode/length": 169.0, "episode/score": 0.5222213184256788, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.05034631557059299}
{"step": 264472, "time": 8725.579105615616, "episode/length": 105.0, "episode/score": 0.7014230029811728, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02954799582163048}
{"step": 264480, "time": 8726.053960084915, "episode/length": 29.0, "episode/score": 0.9227269435105825, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.013351901896470508}
{"step": 264560, "time": 8728.530767679214, "episode/length": 288.0, "episode/score": 0.047629562927525626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047629562927525626}
{"step": 264728, "time": 8733.522424936295, "episode/length": 30.0, "episode/score": 0.9189974329164983, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.012747453056348945}
{"step": 264816, "time": 8736.485565662384, "episode/length": 31.0, "episode/score": 0.9091560806748618, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.006031110727477085}
{"step": 264832, "time": 8736.989287137985, "episode/length": 153.0, "episode/score": 0.5394772932701954, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.017602284533225543}
{"step": 264984, "time": 8741.565659761429, "episode/length": 63.0, "episode/score": 0.8092090001569261, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.006083999423509567}
{"step": 265008, "time": 8742.580201148987, "episode/length": 74.0, "episode/score": 0.7868781918040071, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.01812815763319975}
{"step": 265008, "time": 8742.588459730148, "episode/length": 288.0, "episode/score": 0.02474506319207137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02474506319207137}
{"step": 265072, "time": 8744.594186782837, "episode/length": 31.0, "episode/score": 0.9133912074352537, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.010266234461070667}
{"step": 265184, "time": 8748.06945681572, "episode/length": 21.0, "episode/score": 0.9438341661423806, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.009459193168197544}
{"step": 265224, "time": 8749.10455942154, "episode/length": 48.0, "episode/score": 0.8563782959687956, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.006378255530478327}
{"step": 265360, "time": 8753.579629659653, "episode/length": 43.0, "episode/score": 0.8750213234141455, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.009396311650377243}
{"step": 266184, "time": 8779.080587148666, "episode/length": 102.0, "episode/score": 0.7049919912458762, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.023742041666807268}
{"step": 266272, "time": 8782.058757543564, "episode/length": 192.0, "episode/score": 0.4439047519701518, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.04390475808777694}
{"step": 266312, "time": 8783.094181776047, "episode/length": 140.0, "episode/score": 0.5772247799910986, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.014724794150112075}
{"step": 266424, "time": 8786.609464168549, "episode/length": 288.0, "episode/score": 0.025873708513827864, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025873708513827864}
{"step": 266520, "time": 8789.609538078308, "episode/length": 288.0, "episode/score": 0.02113461602640143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02113461602640143}
{"step": 266960, "time": 8803.575880527496, "episode/length": 246.0, "episode/score": 0.26219527366825446, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.030945267864950665}
{"step": 267256, "time": 8812.587403059006, "episode/length": 91.0, "episode/score": 0.7301304004606664, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.014505426540608823}
{"step": 267384, "time": 8816.59545493126, "episode/length": 288.0, "episode/score": 0.030421418085481378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030421418085481378}
{"step": 267392, "time": 8817.07624411583, "episode/length": 134.0, "episode/score": 0.5970439248394257, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.015793924472717435}
{"step": 267504, "time": 8820.618869304657, "episode/length": 14.0, "episode/score": 0.9611109910874944, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.004860997749361218}
{"step": 267536, "time": 8821.634335517883, "episode/length": 288.0, "episode/score": 0.01809671165820248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01809671165820248}
{"step": 267696, "time": 8826.87803721428, "episode/length": 23.0, "episode/score": 0.9350380814176447, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.006913043256702167}
{"step": 267824, "time": 8830.904779672623, "episode/length": 70.0, "episode/score": 0.7958581414431052, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.014608112804936013}
{"step": 268208, "time": 8842.972817897797, "episode/length": 47.0, "episode/score": 0.8766187019400604, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.02349369714374916}
{"step": 268336, "time": 8846.967672109604, "episode/length": 257.0, "episode/score": 0.2505148360177998, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.05363983122148852}
{"step": 268496, "time": 8851.953967094421, "episode/length": 288.0, "episode/score": 0.059920889483805695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059920889483805695}
{"step": 268640, "time": 8856.44784784317, "episode/length": 155.0, "episode/score": 0.556066265112463, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.040441265927370296}
{"step": 268680, "time": 8857.476820707321, "episode/length": 58.0, "episode/score": 0.8492766561039389, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.03052661794299638}
{"step": 268736, "time": 8859.44837808609, "episode/length": 288.0, "episode/score": 0.06140828068788551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06140828068788551}
{"step": 269232, "time": 8876.03358578682, "episode/length": 91.0, "episode/score": 0.7554197925246626, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.039794781104319554}
{"step": 269272, "time": 8877.079208135605, "episode/length": 288.0, "episode/score": 0.054212430982687465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054212430982687465}
{"step": 269648, "time": 8889.04207277298, "episode/length": 113.0, "episode/score": 0.6751228779485245, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.02824785492157389}
{"step": 269656, "time": 8889.07717037201, "episode/length": 47.0, "episode/score": 0.8723220166680221, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.019197011115011264}
{"step": 269840, "time": 8895.083003044128, "episode/length": 267.0, "episode/score": 0.23998879804935314, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.07436379290379591}
{"step": 269848, "time": 8895.119721651077, "episode/length": 288.0, "episode/score": 0.06277541163126443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06277541163126443}
{"step": 270088, "time": 8903.366818904877, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 270088, "time": 8903.475376605988, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 270088, "time": 8903.926990747452, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 270088, "time": 8904.50881433487, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 270088, "time": 8904.516424655914, "eval_episode/length": 61.0, "eval_episode/score": 0.809374988079071, "eval_episode/reward_rate": 0.016129032258064516}
{"step": 270088, "time": 8905.31376695633, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 270088, "time": 8906.869525432587, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 270088, "time": 8907.99438071251, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8908.00194978714, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8908.00828576088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8908.014623880386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8908.020815610886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270648, "time": 8926.041615962982, "episode/length": 288.0, "episode/score": 0.05785442698186216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05785442698186216}
{"step": 270776, "time": 8930.019503593445, "episode/length": 261.0, "episode/score": 0.22133225065203987, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.036957254132858}
{"step": 270952, "time": 8935.464801311493, "episode/length": 288.0, "episode/score": 0.04721956076923561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04721956076923561}
{"step": 270968, "time": 8935.96031332016, "episode/length": 23.0, "episode/score": 0.9357902769600059, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0076652459586057375}
{"step": 271544, "time": 8953.861365318298, "episode/length": 288.0, "episode/score": 0.027396785033488413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027396785033488413}
{"step": 271960, "time": 8966.961833715439, "episode/length": 288.0, "episode/score": 0.0342056877457253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0342056877457253}
{"step": 271968, "time": 8967.443156003952, "episode/length": 288.0, "episode/score": 0.03847732968552009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03847732968552009}
{"step": 272152, "time": 8973.0218064785, "episode/length": 288.0, "episode/score": 0.034279736884059275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034279736884059275}
{"step": 272160, "time": 8973.507210731506, "episode/length": 288.0, "episode/score": 0.03753648933172826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03753648933172826}
{"step": 272960, "time": 8998.440566062927, "episode/length": 288.0, "episode/score": 0.08728716113228074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08728716113228074}
{"step": 273184, "time": 9005.389773368835, "episode/length": 276.0, "episode/score": 0.19456237073700322, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.05706236833884759}
{"step": 273264, "time": 9007.889702796936, "episode/length": 288.0, "episode/score": 0.07922677542285328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07922677542285328}
{"step": 273552, "time": 9016.93584728241, "episode/length": 197.0, "episode/score": 0.47431613715582444, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.08994113201026721}
{"step": 273616, "time": 9018.911804914474, "episode/length": 258.0, "episode/score": 0.29745799008310314, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.10370798888402533}
{"step": 274272, "time": 9039.519401550293, "episode/length": 288.0, "episode/score": 0.07665903233237259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07665903233237259}
{"step": 274464, "time": 9045.673657417297, "episode/length": 288.0, "episode/score": 0.13184193900974606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13184193900974606}
{"step": 274472, "time": 9045.712274312973, "episode/length": 288.0, "episode/score": 0.1295562274628992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1295562274628992}
{"step": 275272, "time": 9070.952329874039, "episode/length": 288.0, "episode/score": 0.0952901816361873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0952901816361873}
{"step": 275496, "time": 9078.084383487701, "episode/length": 288.0, "episode/score": 0.05158002860360966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05158002860360966}
{"step": 275576, "time": 9080.59634757042, "episode/length": 288.0, "episode/score": 0.05246854008368018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05246854008368018}
{"step": 275864, "time": 9089.643099546432, "episode/length": 288.0, "episode/score": 0.06587703030658076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06587703030658076}
{"step": 275928, "time": 9091.64970946312, "episode/length": 288.0, "episode/score": 0.04525462900784305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04525462900784305}
{"step": 276584, "time": 9112.332273244858, "episode/length": 288.0, "episode/score": 0.046057656459254304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046057656459254304}
{"step": 276688, "time": 9115.870585680008, "episode/length": 94.0, "episode/score": 0.7415956780678812, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03534563750878306}
{"step": 276776, "time": 9118.40952706337, "episode/length": 288.0, "episode/score": 0.043374213529318695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043374213529318695}
{"step": 276784, "time": 9118.885424613953, "episode/length": 288.0, "episode/score": 0.031822292580272915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031822292580272915}
{"step": 276928, "time": 9123.382654428482, "episode/length": 42.0, "episode/score": 0.90171200716577, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.03296200236945879}
{"step": 277048, "time": 9126.904978990555, "episode/length": 193.0, "episode/score": 0.4572806498078421, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.060405656932459806}
{"step": 277584, "time": 9143.937866687775, "episode/length": 288.0, "episode/score": 0.06931099598432411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06931099598432411}
{"step": 277888, "time": 9153.496150255203, "episode/length": 288.0, "episode/score": 0.033729310455214545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033729310455214545}
{"step": 278056, "time": 9158.561225652695, "episode/length": 140.0, "episode/score": 0.6002407508212855, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.037740751636192726}
{"step": 278144, "time": 9161.567103385925, "episode/length": 69.0, "episode/score": 0.803409737232414, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.019034726126392343}
{"step": 278176, "time": 9162.605080127716, "episode/length": 288.0, "episode/score": 0.044855076778503644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044855076778503644}
{"step": 278288, "time": 9166.117931842804, "episode/length": 17.0, "episode/score": 0.9578085135772199, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.010933538233985018}
{"step": 278936, "time": 9186.707679271698, "episode/length": 94.0, "episode/score": 0.7492875569962507, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.043037530756237175}
{"step": 279000, "time": 9188.720106124878, "episode/length": 288.0, "episode/score": 0.0633710356262327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0633710356262327}
{"step": 279088, "time": 9191.80806851387, "episode/length": 288.0, "episode/score": 0.07550198131116304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07550198131116304}
{"step": 279096, "time": 9191.845287322998, "episode/length": 288.0, "episode/score": 0.06718102892295974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06718102892295974}
{"step": 279360, "time": 9200.380721330643, "episode/length": 288.0, "episode/score": 0.07176200561730184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07176200561730184}
{"step": 279416, "time": 9201.926483631134, "episode/length": 40.0, "episode/score": 0.8969670668536764, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.021967043512404416}
{"step": 279464, "time": 9203.431400060654, "episode/length": 45.0, "episode/score": 0.8825100288063368, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.023135014487252192}
{"step": 279792, "time": 9213.949912309647, "episode/length": 187.0, "episode/score": 0.4755621739227536, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.05993715364320451}
{"step": 279888, "time": 9216.9394094944, "episode/length": 58.0, "episode/score": 0.8467323469910752, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.027982314971040978}
{"step": 279912, "time": 9217.47174191475, "episode/length": 252.0, "episode/score": 0.2986541372406464, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.08615413774123226}
{"step": 280072, "time": 9223.272866725922, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 280072, "time": 9223.527766227722, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 280072, "time": 9224.456478595734, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 280072, "time": 9224.689319372177, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 280072, "time": 9225.210750818253, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 280072, "time": 9225.269990205765, "eval_episode/length": 152.0, "eval_episode/score": 0.5249999761581421, "eval_episode/reward_rate": 0.006535947712418301}
{"step": 280072, "time": 9227.590095043182, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9227.597535133362, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9227.60427069664, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280368, "time": 9237.054213047028, "episode/length": 288.0, "episode/score": 0.08556831081580185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08556831081580185}
{"step": 280617, "time": 9245.561828374863, "train_stats/mean_log_entropy": 0.6460498730146808, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2825414913216817, "train/action_min": 0.0, "train/action_std": 1.648970165818008, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003407552642399714, "train/actor_opt_grad_steps": 16475.0, "train/actor_opt_loss": 19.38965956037192, "train/adv_mag": 0.022769991961336628, "train/adv_max": 0.02242282232672898, "train/adv_mean": 0.005665045385238458, "train/adv_min": -0.00460719793420477, "train/adv_std": 0.0039673264641866815, "train/cont_avg": 0.9963152384020618, "train/cont_loss_mean": 0.02432432581944218, "train/cont_loss_std": 0.3310743192224464, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.631150023475367, "train/cont_pos_acc": 0.9999999834090164, "train/cont_pos_loss": 0.0035729109280809913, "train/cont_pred": 0.9964333557590996, "train/cont_rate": 0.9963152384020618, "train/dyn_loss_mean": 1.0059697099567688, "train/dyn_loss_std": 0.003025463399044196, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5275021844625127, "train/extr_critic_critic_opt_grad_steps": 16475.0, "train/extr_critic_critic_opt_loss": 8180.238492356133, "train/extr_critic_mag": 0.21849885367855584, "train/extr_critic_max": 0.21849885367855584, "train/extr_critic_mean": 0.21541543220429077, "train/extr_critic_min": 0.21005163672044105, "train/extr_critic_std": 0.0016197963311251724, "train/extr_return_normed_mag": 0.03400281555566591, "train/extr_return_normed_max": 0.03396114637864005, "train/extr_return_normed_mean": 0.016376099327204692, "train/extr_return_normed_min": 0.005497315572094671, "train/extr_return_normed_std": 0.0044278804904099595, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.23866550609008552, "train/extr_return_raw_max": 0.23866550609008552, "train/extr_return_raw_mean": 0.221080468641114, "train/extr_return_raw_min": 0.21020167528354017, "train/extr_return_raw_std": 0.004427880487109525, "train/extr_reward_mag": 0.012592762401423504, "train/extr_reward_max": 0.012592762401423504, "train/extr_reward_mean": 0.001429132200278265, "train/extr_reward_min": 1.816589807726673e-05, "train/extr_reward_std": 0.0025272447689821628, "train/image_loss_mean": 0.18408808887926573, "train/image_loss_std": 0.10422952922502744, "train/model_loss_mean": 0.8237176457631219, "train/model_loss_std": 0.3907976326023795, "train/model_opt_grad_norm": 34.55155002947935, "train/model_opt_grad_steps": 16457.943298969072, "train/model_opt_loss": 2054.101173007611, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2500.0, "train/policy_entropy_mag": 1.6450826304475057, "train/policy_entropy_max": 1.6450826304475057, "train/policy_entropy_mean": 0.6724859091270831, "train/policy_entropy_min": 0.081942736718458, "train/policy_entropy_std": 0.3166490018214147, "train/policy_logprob_mag": 6.379960003587389, "train/policy_logprob_max": -0.01151176880968293, "train/policy_logprob_mean": -0.6719206497841275, "train/policy_logprob_min": -6.379960003587389, "train/policy_logprob_std": 0.9107479450014448, "train/policy_randomness_mag": 0.8454052870421066, "train/policy_randomness_max": 0.8454052870421066, "train/policy_randomness_mean": 0.3455894185787009, "train/policy_randomness_min": 0.042110239030774106, "train/policy_randomness_std": 0.16272540682369901, "train/post_ent_mag": 33.935852139266494, "train/post_ent_max": 33.935852139266494, "train/post_ent_mean": 33.613772382441255, "train/post_ent_min": 33.242963073179894, "train/post_ent_std": 0.13589803331061123, "train/prior_ent_mag": 37.62878887923723, "train/prior_ent_max": 37.62878887923723, "train/prior_ent_mean": 33.67273576480826, "train/prior_ent_min": 31.15718420756232, "train/prior_ent_std": 1.1168184042284168, "train/rep_loss_mean": 1.0059697099567688, "train/rep_loss_std": 0.003025463399044196, "train/reward_avg": 0.00038347136147965955, "train/reward_loss_mean": 0.011723384249129706, "train/reward_loss_std": 0.06481037647991451, "train/reward_max_data": 0.13188810758988767, "train/reward_max_pred": 0.008475947625858267, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00980658002543388, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.522128417756822, "train/reward_pred": 0.0003378439890268768, "train/reward_rate": 0.0002969958118556701, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.024933796375989914, "report/cont_loss_std": 0.3483274281024933, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.585819244384766, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0031264019198715687, "report/cont_pred": 0.9968758821487427, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16252753138542175, "report/image_loss_std": 0.09459969401359558, "report/model_loss_mean": 0.8178305625915527, "report/model_loss_std": 0.7240684628486633, "report/post_ent_mag": 44.924407958984375, "report/post_ent_max": 44.924407958984375, "report/post_ent_mean": 43.98081970214844, "report/post_ent_min": 42.874427795410156, "report/post_ent_std": 0.39586561918258667, "report/prior_ent_mag": 51.006290435791016, "report/prior_ent_max": 51.006290435791016, "report/prior_ent_mean": 43.81743240356445, "report/prior_ent_min": 38.11183166503906, "report/prior_ent_std": 2.4251868724823, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023008743301033974, "report/reward_loss_mean": 0.030369248241186142, "report/reward_loss_std": 0.3830479085445404, "report/reward_max_data": 0.8626562356948853, "report/reward_max_pred": 0.00446009635925293, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009979271329939365, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.969758033752441, "report/reward_pred": 0.00028318807017058134, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014275314286351204, "eval/cont_loss_std": 0.2525154948234558, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.722036361694336, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003105528885498643, "eval/cont_pred": 0.9968989491462708, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.000314712524414, "eval/dyn_loss_std": 0.00725608691573143, "eval/image_loss_mean": 0.17555749416351318, "eval/image_loss_std": 0.11255286633968353, "eval/model_loss_mean": 0.7912681102752686, "eval/model_loss_std": 0.27665096521377563, "eval/post_ent_mag": 44.97539520263672, "eval/post_ent_max": 44.97539520263672, "eval/post_ent_mean": 43.983299255371094, "eval/post_ent_min": 42.87297821044922, "eval/post_ent_std": 0.3878556489944458, "eval/prior_ent_mag": 55.402366638183594, "eval/prior_ent_max": 55.402366638183594, "eval/prior_ent_mean": 44.026241302490234, "eval/prior_ent_min": 38.64836883544922, "eval/prior_ent_std": 2.492034673690796, "eval/rep_loss_mean": 1.000314712524414, "eval/rep_loss_std": 0.00725608691573143, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012464001774787903, "eval/reward_loss_std": 0.001526312087662518, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0018552541732788086, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012464001774787903, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021237344481050968, "eval/reward_rate": 0.0, "replay/size": 280113.0, "replay/inserts": 31072.0, "replay/samples": 31072.0, "replay/insert_wait_avg": 1.1706619257784528e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.353746068465354e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68104.0, "eval_replay/inserts": 9248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0409930585577414e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9885699748993, "timer/env.step_count": 3884.0, "timer/env.step_total": 35.523436069488525, "timer/env.step_frac": 0.03552384210789549, "timer/env.step_avg": 0.009146095795439887, "timer/env.step_min": 0.007391691207885742, "timer/env.step_max": 0.04473376274108887, "timer/replay._sample_count": 31072.0, "timer/replay._sample_total": 15.218951940536499, "timer/replay._sample_frac": 0.015219125895527496, "timer/replay._sample_avg": 0.0004897963420615506, "timer/replay._sample_min": 0.0003814697265625, "timer/replay._sample_max": 0.028408288955688477, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 5040.0, "timer/agent.policy_total": 48.99549341201782, "timer/agent.policy_frac": 0.048996053438138454, "timer/agent.policy_avg": 0.009721328057940045, "timer/agent.policy_min": 0.008145809173583984, "timer/agent.policy_max": 0.08631706237792969, "timer/dataset_train_count": 1942.0, "timer/dataset_train_total": 0.19752788543701172, "timer/dataset_train_frac": 0.00019753014321150677, "timer/dataset_train_avg": 0.00010171363822709152, "timer/dataset_train_min": 8.654594421386719e-05, "timer/dataset_train_max": 0.0004405975341796875, "timer/agent.train_count": 1942.0, "timer/agent.train_total": 863.891726732254, "timer/agent.train_frac": 0.8639016011492398, "timer/agent.train_avg": 0.4448464092339104, "timer/agent.train_min": 0.43329739570617676, "timer/agent.train_max": 1.3323593139648438, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47089099884033203, "timer/agent.report_frac": 0.00047089638119778894, "timer/agent.report_avg": 0.23544549942016602, "timer/agent.report_min": 0.2302231788635254, "timer/agent.report_max": 0.24066781997680664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8610556511566572e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 31.07180031481326}
{"step": 280856, "time": 9252.865823745728, "episode/length": 186.0, "episode/score": 0.47605089132844114, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.05730090365682372}
{"step": 280944, "time": 9255.836164236069, "episode/length": 128.0, "episode/score": 0.6509828868620389, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0509828548420046}
{"step": 281248, "time": 9265.34923195839, "episode/length": 288.0, "episode/score": 0.07417583787059812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07417583787059812}
{"step": 281312, "time": 9267.352932929993, "episode/length": 288.0, "episode/score": 0.0632757906353163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0632757906353163}
{"step": 281584, "time": 9275.88261961937, "episode/length": 33.0, "episode/score": 0.9124026565059467, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.015527652803939418}
{"step": 281776, "time": 9282.07238650322, "episode/length": 288.0, "episode/score": 0.0727200644671484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0727200644671484}
{"step": 282104, "time": 9292.21966958046, "episode/length": 288.0, "episode/score": 0.07747007110367576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07747007110367576}
{"step": 282200, "time": 9295.26351428032, "episode/length": 288.0, "episode/score": 0.08116136306114186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08116136306114186}
{"step": 282232, "time": 9296.280136108398, "episode/length": 56.0, "episode/score": 0.8440385573497906, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.019038540632550394}
{"step": 282496, "time": 9304.747596025467, "episode/length": 48.0, "episode/score": 0.8654578606619907, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.015457854951819172}
{"step": 282680, "time": 9310.290549755096, "episode/length": 288.0, "episode/score": 0.05492919919038286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05492919919038286}
{"step": 282920, "time": 9317.819076299667, "episode/length": 85.0, "episode/score": 0.7528556618310631, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.018480662049341845}
{"step": 283080, "time": 9322.781569242477, "episode/length": 109.0, "episode/score": 0.691173066997294, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.0317980781848064}
{"step": 283168, "time": 9325.740506410599, "episode/length": 288.0, "episode/score": 0.04669291549703303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04669291549703303}
{"step": 283256, "time": 9328.234127521515, "episode/length": 288.0, "episode/score": 0.061646309171806024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061646309171806024}
{"step": 283536, "time": 9337.125146627426, "episode/length": 129.0, "episode/score": 0.6372811642326042, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.04040615312658247}
{"step": 283560, "time": 9337.655885457993, "episode/length": 288.0, "episode/score": 0.06086267386376676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06086267386376676}
{"step": 283896, "time": 9348.092283964157, "episode/length": 288.0, "episode/score": 0.05725252267450287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05725252267450287}
{"step": 284992, "time": 9382.453209400177, "episode/length": 288.0, "episode/score": 0.04707266468250282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04707266468250282}
{"step": 285056, "time": 9384.442461252213, "episode/length": 246.0, "episode/score": 0.27097288807686937, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.03972288530036394}
{"step": 285232, "time": 9390.021379470825, "episode/length": 288.0, "episode/score": 0.048293765185746906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048293765185746906}
{"step": 285480, "time": 9397.526145219803, "episode/length": 288.0, "episode/score": 0.04244107589812529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04244107589812529}
{"step": 285536, "time": 9399.4866669178, "episode/length": 204.0, "episode/score": 0.38176408897152214, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.019264070356712182}
{"step": 285568, "time": 9400.502475261688, "episode/length": 288.0, "episode/score": 0.04790800170104603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04790800170104603}
{"step": 285744, "time": 9406.049613952637, "episode/length": 63.0, "episode/score": 0.8176690162977138, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01454401259570659}
{"step": 285824, "time": 9408.540986061096, "episode/length": 285.0, "episode/score": 0.1351544554750035, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.02577945189523234}
{"step": 285832, "time": 9408.577626228333, "episode/length": 283.0, "episode/score": 0.13491709428257082, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.019292095411799437}
{"step": 286024, "time": 9414.59652876854, "episode/length": 128.0, "episode/score": 0.6126745175148471, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.012674507832002746}
{"step": 286288, "time": 9423.073617696762, "episode/length": 89.0, "episode/score": 0.7358497708743243, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.013974768019238581}
{"step": 286512, "time": 9430.078250169754, "episode/length": 60.0, "episode/score": 0.8386008869786679, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.026100872659583274}
{"step": 286576, "time": 9432.121191263199, "episode/length": 92.0, "episode/score": 0.7381755708301512, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.02567560373785227}
{"step": 286944, "time": 9444.008197069168, "episode/length": 45.0, "episode/score": 0.8760600384790109, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.0166850151377389}
{"step": 286976, "time": 9445.000274419785, "episode/length": 153.0, "episode/score": 0.5354857871896002, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.013610783487592926}
{"step": 286976, "time": 9445.007247209549, "episode/length": 85.0, "episode/score": 0.7568814948326121, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.022506486654435776}
{"step": 286976, "time": 9445.01355600357, "episode/length": 179.0, "episode/score": 0.4592048801813462, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.01857985658978123}
{"step": 287368, "time": 9456.946386814117, "episode/length": 288.0, "episode/score": 0.04682123691435436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04682123691435436}
{"step": 287792, "time": 9470.452132701874, "episode/length": 288.0, "episode/score": 0.04001276926794617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04001276926794617}
{"step": 288016, "time": 9477.385166406631, "episode/length": 187.0, "episode/score": 0.4490718622110421, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.03344684807240128}
{"step": 288136, "time": 9480.909415006638, "episode/length": 288.0, "episode/score": 0.02334605927700295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02334605927700295}
{"step": 288400, "time": 9489.32521033287, "episode/length": 75.0, "episode/score": 0.7802182354186584, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.0145932555585091}
{"step": 288792, "time": 9501.400267124176, "episode/length": 226.0, "episode/score": 0.3243484915717545, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.030598491822047436}
{"step": 288856, "time": 9503.391338825226, "episode/length": 104.0, "episode/score": 0.6927393918848566, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.01773938902977079}
{"step": 289024, "time": 9508.829020023346, "episode/length": 77.0, "episode/score": 0.773550490353955, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.014175510106724687}
{"step": 289256, "time": 9515.876822710037, "episode/length": 288.0, "episode/score": 0.04978086987375718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04978086987375718}
{"step": 289288, "time": 9516.89546251297, "episode/length": 288.0, "episode/score": 0.03826801640315125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03826801640315125}
{"step": 289288, "time": 9516.904010295868, "episode/length": 288.0, "episode/score": 0.050388878243012414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050388878243012414}
{"step": 289680, "time": 9529.632716417313, "episode/length": 288.0, "episode/score": 0.033624434436376305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033624434436376305}
{"step": 290056, "time": 9546.005891799927, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.013844013214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.020085573196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.02666592598, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.032601594925, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.03908610344, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.045372962952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290056, "time": 9546.051634311676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 290448, "time": 9558.709329128265, "episode/length": 288.0, "episode/score": 0.04482100368556985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04482100368556985}
{"step": 291104, "time": 9579.049764633179, "episode/length": 288.0, "episode/score": 0.04085084490719737, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04085084490719737}
{"step": 291168, "time": 9581.053104162216, "episode/length": 288.0, "episode/score": 0.02601094563016204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02601094563016204}
{"step": 291336, "time": 9586.102684020996, "episode/length": 288.0, "episode/score": 0.05529181493122337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05529181493122337}
{"step": 291568, "time": 9593.494252681732, "episode/length": 288.0, "episode/score": 0.043454281571769116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043454281571769116}
{"step": 291600, "time": 9594.494762897491, "episode/length": 288.0, "episode/score": 0.06141310637110564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06141310637110564}
{"step": 291600, "time": 9594.50298833847, "episode/length": 288.0, "episode/score": 0.031070217745480022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031070217745480022}
{"step": 291992, "time": 9606.431437015533, "episode/length": 288.0, "episode/score": 0.04249066144319613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04249066144319613}
{"step": 292760, "time": 9630.38448381424, "episode/length": 288.0, "episode/score": 0.02355309640950054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02355309640950054}
{"step": 293416, "time": 9650.914762496948, "episode/length": 288.0, "episode/score": 0.03237797810925258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03237797810925258}
{"step": 293480, "time": 9652.903530836105, "episode/length": 288.0, "episode/score": 0.045836627506901095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045836627506901095}
{"step": 293648, "time": 9658.355369567871, "episode/length": 288.0, "episode/score": 0.02323632282264043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02323632282264043}
{"step": 293880, "time": 9665.345335483551, "episode/length": 288.0, "episode/score": 0.06111975648173029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06111975648173029}
{"step": 293912, "time": 9666.346996307373, "episode/length": 288.0, "episode/score": 0.06935512996892612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06935512996892612}
{"step": 293912, "time": 9666.355045080185, "episode/length": 288.0, "episode/score": 0.028453728369299824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028453728369299824}
{"step": 294304, "time": 9678.863954782486, "episode/length": 288.0, "episode/score": 0.04632972571255323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04632972571255323}
{"step": 295040, "time": 9702.373992919922, "episode/length": 173.0, "episode/score": 0.5401285326923926, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.08075353981701028}
{"step": 295072, "time": 9703.382071971893, "episode/length": 288.0, "episode/score": 0.04516319803940405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04516319803940405}
{"step": 295256, "time": 9708.877625226974, "episode/length": 167.0, "episode/score": 0.5466671375752412, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.06854213277892995}
{"step": 295696, "time": 9722.866887807846, "episode/length": 81.0, "episode/score": 0.7717804920574736, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.024905504793309774}
{"step": 295728, "time": 9723.867854118347, "episode/length": 288.0, "episode/score": 0.11605447129858248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11605447129858248}
{"step": 295768, "time": 9724.89419746399, "episode/length": 231.0, "episode/score": 0.36584423820602296, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.08771925129110514}
{"step": 295792, "time": 9725.883207798004, "episode/length": 288.0, "episode/score": 0.0937392729254043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0937392729254043}
{"step": 295992, "time": 9731.979566574097, "episode/length": 91.0, "episode/score": 0.7613291568416116, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.04570416957744783}
{"step": 296016, "time": 9732.954684972763, "episode/length": 30.0, "episode/score": 0.9256937354321053, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.01944372111302073}
{"step": 296192, "time": 9738.444769382477, "episode/length": 288.0, "episode/score": 0.09150549131999242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09150549131999242}
{"step": 296464, "time": 9746.961377382278, "episode/length": 91.0, "episode/score": 0.751804830709375, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03617982831121935}
{"step": 296520, "time": 9748.495228528976, "episode/length": 90.0, "episode/score": 0.7589381003265885, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.040188101141495736}
{"step": 296616, "time": 9751.516126155853, "episode/length": 288.0, "episode/score": 0.09771645716676858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09771645716676858}
{"step": 296952, "time": 9762.13350892067, "episode/length": 41.0, "episode/score": 0.8856171907921748, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.013742194534927421}
{"step": 296952, "time": 9762.140084266663, "episode/length": 94.0, "episode/score": 0.7457286992740251, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03947865795822736}
{"step": 297352, "time": 9774.66939496994, "episode/length": 169.0, "episode/score": 0.5208212840108786, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.048946273254102834}
{"step": 297384, "time": 9775.677749872208, "episode/length": 288.0, "episode/score": 0.09257987287577407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09257987287577407}
{"step": 297384, "time": 9775.684209823608, "episode/length": 53.0, "episode/score": 0.8547577000165347, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.020382646779808056}
{"step": 297584, "time": 9782.179886817932, "episode/length": 78.0, "episode/score": 0.7810142077298678, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.024764176728467646}
{"step": 297624, "time": 9783.20706319809, "episode/length": 200.0, "episode/score": 0.41876479866851923, "episode/reward_rate": 0.004975124378109453, "episode/intrinsic_return": 0.043764799483426486}
{"step": 297960, "time": 9793.81469321251, "episode/length": 46.0, "episode/score": 0.8724646189014607, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.016214623662847316}
{"step": 298008, "time": 9795.308724403381, "episode/length": 288.0, "episode/score": 0.08483541169374575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08483541169374575}
{"step": 298152, "time": 9799.837948799133, "episode/length": 203.0, "episode/score": 0.4156567727910101, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.050031769089002864}
{"step": 298696, "time": 9816.894916057587, "episode/length": 67.0, "episode/score": 0.8171846350407463, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.02655964456351967}
{"step": 298696, "time": 9816.903110980988, "episode/length": 91.0, "episode/score": 0.7456068783150727, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.029981910375852294}
{"step": 298736, "time": 9818.360489845276, "episode/length": 172.0, "episode/score": 0.5084880896611708, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.04598808410815991}
{"step": 298776, "time": 9819.384328842163, "episode/length": 288.0, "episode/score": 0.05001966806003111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05001966806003111}
{"step": 298976, "time": 9825.895691156387, "episode/length": 168.0, "episode/score": 0.5234981798831768, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.04849817152455671}
{"step": 299120, "time": 9830.403059244156, "episode/length": 138.0, "episode/score": 0.6073237786859522, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.038573740525009725}
{"step": 299296, "time": 9835.885296344757, "episode/length": 69.0, "episode/score": 0.8114977737862432, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.02712273322714509}
{"step": 299320, "time": 9836.43354511261, "episode/length": 42.0, "episode/score": 0.8845783168675325, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.015828326390305847}
{"step": 299400, "time": 9838.904544115067, "episode/length": 87.0, "episode/score": 0.7621175186285427, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03399251383223145}
{"step": 299696, "time": 9848.319376707077, "episode/length": 288.0, "episode/score": 0.042099443331551356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042099443331551356}
{"step": 299696, "time": 9848.327676773071, "episode/length": 288.0, "episode/score": 0.04836495944937269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04836495944937269}
{"step": 300040, "time": 9859.11862707138, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 300040, "time": 9859.420577526093, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 300040, "time": 9859.85078549385, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 300040, "time": 9860.752551317215, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 300040, "time": 9861.082725524902, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 300040, "time": 9861.257414102554, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 300040, "time": 9861.566549301147, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 300040, "time": 9861.846067905426, "eval_episode/length": 43.0, "eval_episode/score": 0.8656250238418579, "eval_episode/reward_rate": 0.022727272727272728}
{"step": 300128, "time": 9864.810279846191, "episode/length": 103.0, "episode/score": 0.7089807292668411, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.030855706239890424}
{"step": 301008, "time": 9892.269407510757, "episode/length": 288.0, "episode/score": 0.02952538551210182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02952538551210182}
{"step": 301088, "time": 9894.772903203964, "episode/length": 288.0, "episode/score": 0.043378307078171474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043378307078171474}
{"step": 301432, "time": 9905.196365594864, "episode/length": 288.0, "episode/score": 0.04980702675334214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04980702675334214}
{"step": 301592, "time": 9910.145463943481, "episode/length": 62.0, "episode/score": 0.8308722525920302, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.0246222772487954}
{"step": 301632, "time": 9911.68218421936, "episode/length": 288.0, "episode/score": 0.02724274983563646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02724274983563646}
{"step": 301712, "time": 9914.218852996826, "episode/length": 288.0, "episode/score": 0.022600521249273697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022600521249273697}
{"step": 301984, "time": 9922.746064424515, "episode/length": 48.0, "episode/score": 0.8621451033394578, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.012145056156327882}
{"step": 302008, "time": 9923.283208608627, "episode/length": 288.0, "episode/score": 0.02922356395595216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02922356395595216}
{"step": 302008, "time": 9923.291855335236, "episode/length": 288.0, "episode/score": 0.02862628525792843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02862628525792843}
{"step": 302336, "time": 9933.754197597504, "episode/length": 77.0, "episode/score": 0.7776108899149676, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.018235890415553513}
{"step": 302368, "time": 9934.77477312088, "episode/length": 44.0, "episode/score": 0.8699944384260334, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.007494418326928098}
{"step": 302384, "time": 9935.278578042984, "episode/length": 49.0, "episode/score": 0.8565761309594109, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.009701089643613159}
{"step": 302440, "time": 9936.805478811264, "episode/length": 288.0, "episode/score": 0.03570977064748604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03570977064748604}
{"step": 302944, "time": 9952.773864030838, "episode/length": 62.0, "episode/score": 0.8136723211673598, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.007422365149068355}
{"step": 303000, "time": 9954.342317819595, "episode/length": 82.0, "episode/score": 0.757593795477078, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.013843812159393565}
{"step": 303184, "time": 9960.785051107407, "episode/length": 99.0, "episode/score": 0.7083835345515581, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.017758508311544574}
{"step": 303320, "time": 9964.801148414612, "episode/length": 288.0, "episode/score": 0.02930878202897702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02930878202897702}
{"step": 303424, "time": 9968.236115455627, "episode/length": 29.0, "episode/score": 0.9211895051774945, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.011814469915293557}
{"step": 303560, "time": 9972.360199213028, "episode/length": 76.0, "episode/score": 0.7791979968977785, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.016698000640531063}
{"step": 303744, "time": 9978.375623464584, "episode/length": 288.0, "episode/score": 0.040614041107915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040614041107915}
{"step": 303768, "time": 9978.912143468857, "episode/length": 55.0, "episode/score": 0.8479708000772916, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.019845818208978017}
{"step": 303944, "time": 9984.388198137283, "episode/length": 288.0, "episode/score": 0.02952732089448773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02952732089448773}
{"step": 304072, "time": 9988.374042510986, "episode/length": 80.0, "episode/score": 0.7621442700910279, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.012144288222714295}
{"step": 304168, "time": 9991.351733922958, "episode/length": 224.0, "episode/score": 0.325409831130969, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.025409820024947294}
{"step": 304320, "time": 9996.299772500992, "episode/length": 288.0, "episode/score": 0.044473358825825926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044473358825825926}
{"step": 304424, "time": 9999.314044952393, "episode/length": 107.0, "episode/score": 0.6872323525353181, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.021607377192083277}
{"step": 304456, "time": 10000.331164121628, "episode/length": 85.0, "episode/score": 0.7519018278535441, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.017526847993394767}
{"step": 304744, "time": 10009.31684589386, "episode/length": 52.0, "episode/score": 0.8577177979680641, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.02021781465037975}
{"step": 304816, "time": 10011.789829492569, "episode/length": 133.0, "episode/score": 0.6233632495944335, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.03898821143349096}
{"step": 304912, "time": 10014.77682685852, "episode/length": 92.0, "episode/score": 0.745336235276568, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03283627925827659}
{"step": 305312, "time": 10027.143218040466, "episode/length": 288.0, "episode/score": 0.0300023191746277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0300023191746277}
{"step": 305488, "time": 10032.71736907959, "episode/length": 71.0, "episode/score": 0.8004977442842574, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.02237277433687268}
{"step": 305616, "time": 10036.694280862808, "episode/length": 99.0, "episode/score": 0.7026695273976884, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.01204453058164745}
{"step": 305632, "time": 10037.19528722763, "episode/length": 146.0, "episode/score": 0.5572016365622972, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.01345164030504975}
{"step": 305760, "time": 10041.19388461113, "episode/length": 55.0, "episode/score": 0.8387257274594049, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.010600719281228521}
{"step": 305768, "time": 10041.228738069534, "episode/length": 16.0, "episode/score": 0.9576145429747953, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.007614578004165651}
{"step": 306056, "time": 10050.193031787872, "episode/length": 203.0, "episode/score": 0.3809175117179393, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.015292503359319198}
{"step": 306096, "time": 10051.68093585968, "episode/length": 75.0, "episode/score": 0.7742790828168609, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.00865406849777628}
{"step": 306152, "time": 10053.219046115875, "episode/length": 175.0, "episode/score": 0.4663044966533789, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.013179488475202561}
{"step": 306256, "time": 10056.727056026459, "episode/length": 288.0, "episode/score": 0.023680131750268174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023680131750268174}
{"step": 306384, "time": 10060.788702487946, "episode/length": 288.0, "episode/score": 0.019406647333255478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019406647333255478}
{"step": 306752, "time": 10072.515578746796, "episode/length": 81.0, "episode/score": 0.760760592842189, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.01388562490296863}
{"step": 307184, "time": 10085.9287276268, "episode/length": 99.0, "episode/score": 0.7055781892420327, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.014953178136011047}
{"step": 307248, "time": 10087.914179325104, "episode/length": 136.0, "episode/score": 0.6013661470055922, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.02636613558524914}
{"step": 307664, "time": 10100.946417808533, "episode/length": 113.0, "episode/score": 0.6748383942948522, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.02796334105812548}
{"step": 307928, "time": 10108.920431137085, "episode/length": 288.0, "episode/score": 0.025253864688579597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025253864688579597}
{"step": 308000, "time": 10111.386753320694, "episode/length": 93.0, "episode/score": 0.7275118352026766, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.018136803182642325}
{"step": 308072, "time": 10113.404627799988, "episode/length": 288.0, "episode/score": 0.04990340113033653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04990340113033653}
{"step": 308080, "time": 10113.87934756279, "episode/length": 288.0, "episode/score": 0.0381684305019121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0381684305019121}
{"step": 308080, "time": 10113.888311862946, "episode/length": 111.0, "episode/score": 0.6726911588909843, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.019566147470641226}
{"step": 308256, "time": 10119.331578493118, "episode/length": 31.0, "episode/score": 0.9092040131954491, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.006078995721509273}
{"step": 308368, "time": 10122.882765769958, "episode/length": 288.0, "episode/score": 0.03063640914797361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03063640914797361}
{"step": 308568, "time": 10128.868557929993, "episode/length": 288.0, "episode/score": 0.03239773999177942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03239773999177942}
{"step": 308624, "time": 10130.835501432419, "episode/length": 68.0, "episode/score": 0.8012933480526954, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.01379330989175287}
{"step": 308688, "time": 10132.815522909164, "episode/length": 75.0, "episode/score": 0.7855266679783881, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.019901644637116078}
{"step": 308872, "time": 10138.294620752335, "episode/length": 76.0, "episode/score": 0.7790763751847862, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.016576357710846423}
{"step": 308888, "time": 10138.796536684036, "episode/length": 32.0, "episode/score": 0.9128016794732048, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.012801696155520403}
{"step": 309048, "time": 10143.749593496323, "episode/length": 84.0, "episode/score": 0.754817759446496, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.01731773934739067}
{"step": 309096, "time": 10145.254945516586, "episode/length": 145.0, "episode/score": 0.564644269032101, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.017769260853924607}
{"step": 309280, "time": 10151.15618610382, "episode/length": 88.0, "episode/score": 0.7429908815913677, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.01799087588119619}
{"step": 309288, "time": 10151.194269418716, "episode/length": 202.0, "episode/score": 0.4077027171364307, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.03895271158341984}
{"step": 309416, "time": 10155.286804676056, "episode/length": 67.0, "episode/score": 0.7955452956643967, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.004920337637940975}
{"step": 309472, "time": 10157.238149881363, "episode/length": 97.0, "episode/score": 0.7144397837204224, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.01756482770213097}
{"step": 309584, "time": 10160.708664417267, "episode/length": 20.0, "episode/score": 0.9450511629175935, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.00755116313587223}
{"step": 310024, "time": 10175.799921751022, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 310024, "time": 10179.564066171646, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10179.571293830872, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10179.577857494354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10179.584130764008, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10179.590370416641, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10179.596566200256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10179.603297472, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310392, "time": 10191.041753053665, "episode/length": 288.0, "episode/score": 0.060941657658645454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060941657658645454}
{"step": 310808, "time": 10203.913062095642, "episode/length": 166.0, "episode/score": 0.5259005967656094, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.04465059701590235}
{"step": 311200, "time": 10216.377995729446, "episode/length": 288.0, "episode/score": 0.05966062528500515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05966062528500515}
{"step": 311360, "time": 10221.835132360458, "episode/length": 288.0, "episode/score": 0.029210675393642305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029210675393642305}
{"step": 311408, "time": 10223.351657629013, "episode/length": 288.0, "episode/score": 0.0389766639895015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0389766639895015}
{"step": 311592, "time": 10228.922159433365, "episode/length": 288.0, "episode/score": 0.05022073805560012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05022073805560012}
{"step": 311600, "time": 10229.40306186676, "episode/length": 288.0, "episode/score": 0.061017956044224775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061017956044224775}
{"step": 311864, "time": 10237.515525102615, "episode/length": 32.0, "episode/score": 0.9113271126934706, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.011327128357152105}
{"step": 311896, "time": 10238.523792266846, "episode/length": 288.0, "episode/score": 0.034160567953335885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034160567953335885}
{"step": 311960, "time": 10240.565155506134, "episode/length": 45.0, "episode/score": 0.8760987076320816, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.016723699453905283}
{"step": 312089, "time": 10245.647992372513, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.158185997787787, "train/action_min": 0.0, "train/action_std": 1.6043570826248246, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.003241721058100443, "train/actor_opt_grad_steps": 18425.0, "train/actor_opt_loss": 11.992383641913078, "train/adv_mag": 0.030700276244659812, "train/adv_max": 0.03049006434727688, "train/adv_mean": 0.006554548275799993, "train/adv_min": -0.010499631871982497, "train/adv_std": 0.0053797776362982256, "train/cont_avg": 0.9962930484693877, "train/cont_loss_mean": 0.023853333766705224, "train/cont_loss_std": 0.3194405629497962, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.438001838990444, "train/cont_pos_acc": 0.9999999838824175, "train/cont_pos_loss": 0.0037288537120674643, "train/cont_pred": 0.9962737079785795, "train/cont_rate": 0.9962930484693877, "train/dyn_loss_mean": 1.000049879964517, "train/dyn_loss_std": 0.0014320835358870106, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.48129763975929546, "train/extr_critic_critic_opt_grad_steps": 18425.0, "train/extr_critic_critic_opt_loss": 9596.660722382214, "train/extr_critic_mag": 0.4360894499992838, "train/extr_critic_max": 0.4360894499992838, "train/extr_critic_mean": 0.4312554991671017, "train/extr_critic_min": 0.4173573760353789, "train/extr_critic_std": 0.002900449981988997, "train/extr_return_normed_mag": 0.046210523162569316, "train/extr_return_normed_max": 0.04616975236912163, "train/extr_return_normed_mean": 0.020630307552483847, "train/extr_return_normed_min": 0.0028897127022548597, "train/extr_return_normed_std": 0.006229423725388336, "train/extr_return_rate": 0.19910249615999678, "train/extr_return_raw_mag": 0.463349454256953, "train/extr_return_raw_max": 0.463349454256953, "train/extr_return_raw_mean": 0.4378100358405892, "train/extr_return_raw_min": 0.42006941459008623, "train/extr_return_raw_std": 0.0062294237384553615, "train/extr_reward_mag": 0.02204785541612275, "train/extr_reward_max": 0.02204785541612275, "train/extr_reward_mean": 0.002102675127537864, "train/extr_reward_min": 1.416644271539182e-05, "train/extr_reward_std": 0.0044619983809938354, "train/image_loss_mean": 0.16790488096220152, "train/image_loss_std": 0.10794815170217534, "train/model_loss_mean": 0.8049638076704375, "train/model_loss_std": 0.39727186153129657, "train/model_opt_grad_norm": 31.960805552346365, "train/model_opt_grad_steps": 18406.816326530614, "train/model_opt_loss": 1917.5127227160394, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2385.204081632653, "train/policy_entropy_mag": 1.5046225889604918, "train/policy_entropy_max": 1.5046225889604918, "train/policy_entropy_mean": 0.2820257779438885, "train/policy_entropy_min": 0.0647936760238847, "train/policy_entropy_std": 0.27851915808052435, "train/policy_logprob_mag": 6.550706756358244, "train/policy_logprob_max": -0.0086249044516637, "train/policy_logprob_mean": -0.2824494615957445, "train/policy_logprob_min": -6.550706756358244, "train/policy_logprob_std": 0.7975569531625631, "train/policy_randomness_mag": 0.7732231002681109, "train/policy_randomness_max": 0.7732231002681109, "train/policy_randomness_mean": 0.14493258791614552, "train/policy_randomness_min": 0.033297364657022516, "train/policy_randomness_std": 0.14313054282446297, "train/post_ent_mag": 33.41262704498914, "train/post_ent_max": 33.41262704498914, "train/post_ent_mean": 32.62888288497925, "train/post_ent_min": 31.773195578127492, "train/post_ent_std": 0.31683638752723225, "train/prior_ent_mag": 40.72475141408492, "train/prior_ent_max": 40.72475141408492, "train/prior_ent_mean": 33.22100224786875, "train/prior_ent_min": 29.1968840676911, "train/prior_ent_std": 1.8208014892072093, "train/rep_loss_mean": 1.000049879964517, "train/rep_loss_std": 0.0014320835358870106, "train/reward_avg": 0.0005263380512680706, "train/reward_loss_mean": 0.013175644526942348, "train/reward_loss_std": 0.09349339764223111, "train/reward_max_data": 0.2457765008558101, "train/reward_max_pred": 0.015324734303416038, "train/reward_neg_acc": 0.9999999993917893, "train/reward_neg_loss": 0.01010335872082838, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.792140675179752, "train/reward_pred": 0.0004624807452830505, "train/reward_rate": 0.0005381058673469387, "train_stats/mean_log_entropy": 0.2438119989928118, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.015258658677339554, "report/cont_loss_std": 0.19700098037719727, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.6458871364593506, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004590798169374466, "report/cont_pred": 0.9953638315200806, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13949286937713623, "report/image_loss_std": 0.09942502528429031, "report/model_loss_mean": 0.7786006927490234, "report/model_loss_std": 0.4781457781791687, "report/post_ent_mag": 26.51895523071289, "report/post_ent_max": 26.51895523071289, "report/post_ent_mean": 25.86651611328125, "report/post_ent_min": 25.131561279296875, "report/post_ent_std": 0.2763947546482086, "report/prior_ent_mag": 33.204139709472656, "report/prior_ent_max": 33.204139709472656, "report/prior_ent_mean": 26.80721092224121, "report/prior_ent_min": 23.219772338867188, "report/prior_ent_std": 1.578084111213684, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.002484859200194478, "report/reward_loss_mean": 0.0238491240888834, "report/reward_loss_std": 0.25469300150871277, "report/reward_max_data": 0.828374981880188, "report/reward_max_pred": 0.020394325256347656, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01010197028517723, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.702464580535889, "report/reward_pred": 0.0005917770322412252, "report/reward_rate": 0.0029296875, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.036739252507686615, "eval/cont_loss_std": 0.42697206139564514, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.591754913330078, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003998495638370514, "eval/cont_pred": 0.9960111975669861, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17370684444904327, "eval/image_loss_std": 0.10454144328832626, "eval/model_loss_mean": 0.8117586374282837, "eval/model_loss_std": 0.43986067175865173, "eval/post_ent_mag": 26.517330169677734, "eval/post_ent_max": 26.517330169677734, "eval/post_ent_mean": 25.7446346282959, "eval/post_ent_min": 25.10968017578125, "eval/post_ent_std": 0.26484742760658264, "eval/prior_ent_mag": 32.7425537109375, "eval/prior_ent_max": 32.7425537109375, "eval/prior_ent_mean": 26.36666488647461, "eval/prior_ent_min": 23.39376449584961, "eval/prior_ent_std": 1.4257233142852783, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013125138357281685, "eval/reward_loss_std": 0.0015757341170683503, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005291938781738281, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013125138357281685, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023363390937447548, "eval/reward_rate": 0.0, "replay/size": 311585.0, "replay/inserts": 31472.0, "replay/samples": 31472.0, "replay/insert_wait_avg": 1.16894193027731e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.368309823886113e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74112.0, "eval_replay/inserts": 6008.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.000461184708637e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0668623447418, "timer/env.step_count": 3934.0, "timer/env.step_total": 35.707700967788696, "timer/env.step_frac": 0.035705313626799864, "timer/env.step_avg": 0.009076690637465353, "timer/env.step_min": 0.007363319396972656, "timer/env.step_max": 0.035408735275268555, "timer/replay._sample_count": 31472.0, "timer/replay._sample_total": 15.524015665054321, "timer/replay._sample_frac": 0.015522977762363754, "timer/replay._sample_avg": 0.0004932643513298907, "timer/replay._sample_min": 0.00035643577575683594, "timer/replay._sample_max": 0.034612178802490234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4685.0, "timer/agent.policy_total": 45.4783296585083, "timer/agent.policy_frac": 0.045475289074052995, "timer/agent.policy_avg": 0.0097072208449324, "timer/agent.policy_min": 0.008143901824951172, "timer/agent.policy_max": 0.08499002456665039, "timer/dataset_train_count": 1967.0, "timer/dataset_train_total": 0.2008824348449707, "timer/dataset_train_frac": 0.0002008690042723591, "timer/dataset_train_avg": 0.00010212630139551128, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.00026226043701171875, "timer/agent.train_count": 1967.0, "timer/agent.train_total": 871.4949610233307, "timer/agent.train_frac": 0.8714366947226275, "timer/agent.train_avg": 0.44305793646330993, "timer/agent.train_min": 0.4339175224304199, "timer/agent.train_max": 0.5913827419281006, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47768306732177734, "timer/agent.report_frac": 0.0004776511304472271, "timer/agent.report_avg": 0.23884153366088867, "timer/agent.report_min": 0.2323765754699707, "timer/agent.report_max": 0.24530649185180664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2661161535071837e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 31.46935795098063}
{"step": 312200, "time": 10248.859938383102, "episode/length": 104.0, "episode/score": 0.6967337465624723, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.021733705246674617}
{"step": 312216, "time": 10249.35915517807, "episode/length": 227.0, "episode/score": 0.35737344598635445, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.0667484411900432}
{"step": 312616, "time": 10261.817033290863, "episode/length": 176.0, "episode/score": 0.5143520585904753, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.06435206335186194}
{"step": 312984, "time": 10273.350033283234, "episode/length": 45.0, "episode/score": 0.8715465948018846, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.012171565407015805}
{"step": 313120, "time": 10277.819396734238, "episode/length": 144.0, "episode/score": 0.5868783285400241, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.036878293277823104}
{"step": 313120, "time": 10277.827783584595, "episode/length": 288.0, "episode/score": 0.048524746016710196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048524746016710196}
{"step": 313368, "time": 10285.289972543716, "episode/length": 187.0, "episode/score": 0.4568314478195816, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.04120644302327037}
{"step": 313720, "time": 10296.226605415344, "episode/length": 288.0, "episode/score": 0.05578285739773037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05578285739773037}
{"step": 313912, "time": 10302.320307254791, "episode/length": 115.0, "episode/score": 0.6649785599829556, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.024353551804779272}
{"step": 314208, "time": 10311.69514799118, "episode/length": 288.0, "episode/score": 0.047031794406109384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047031794406109384}
{"step": 314240, "time": 10312.687466144562, "episode/length": 64.0, "episode/score": 0.8120605210668828, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.01206047975108504}
{"step": 314256, "time": 10313.187770605087, "episode/length": 141.0, "episode/score": 0.5980915293735052, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.03871651795316211}
{"step": 314400, "time": 10317.664544343948, "episode/length": 159.0, "episode/score": 0.518107181733285, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.014982184917244012}
{"step": 314512, "time": 10321.14801812172, "episode/length": 288.0, "episode/score": 0.036116123356180196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036116123356180196}
{"step": 314528, "time": 10321.649393558502, "episode/length": 288.0, "episode/score": 0.04976812278573561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04976812278573561}
{"step": 314824, "time": 10330.62317943573, "episode/length": 36.0, "episode/score": 0.8905334945644654, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.0030335067036730834}
{"step": 314856, "time": 10331.713930130005, "episode/length": 80.0, "episode/score": 0.7609059485960188, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.01090594041784243}
{"step": 314952, "time": 10334.688340187073, "episode/length": 86.0, "episode/score": 0.7459946894269933, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.014744694188379981}
{"step": 314992, "time": 10336.173920154572, "episode/length": 59.0, "episode/score": 0.8219584087028693, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.006333416921791013}
{"step": 315352, "time": 10347.200464487076, "episode/length": 61.0, "episode/score": 0.8226858897093052, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.013310894470691892}
{"step": 315528, "time": 10352.690116167068, "episode/length": 71.0, "episode/score": 0.795808213506632, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.017683225645839684}
{"step": 315560, "time": 10353.69052696228, "episode/length": 25.0, "episode/score": 0.9266720871405596, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.004797102245447604}
{"step": 315680, "time": 10357.655705451965, "episode/length": 288.0, "episode/score": 0.03202786593709561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03202786593709561}
{"step": 315800, "time": 10361.164520025253, "episode/length": 121.0, "episode/score": 0.632520839401991, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.010645871462770629}
{"step": 316160, "time": 10372.665392875671, "episode/length": 78.0, "episode/score": 0.7627655307846339, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.006515522047664035}
{"step": 316176, "time": 10373.170350313187, "episode/length": 282.0, "episode/score": 0.1443588445594628, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.02560884634061722}
{"step": 316184, "time": 10373.207782030106, "episode/length": 222.0, "episode/score": 0.32173707196903933, "episode/reward_rate": 0.004484304932735426, "episode/intrinsic_return": 0.015487078086664496}
{"step": 316400, "time": 10380.185286521912, "episode/length": 175.0, "episode/score": 0.4693779059808776, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.016252891283443205}
{"step": 316512, "time": 10383.737331867218, "episode/length": 41.0, "episode/score": 0.879170070006694, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.00729507783853478}
{"step": 316552, "time": 10384.782541275024, "episode/length": 288.0, "episode/score": 0.012046038543360282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012046038543360282}
{"step": 316576, "time": 10385.76840209961, "episode/length": 51.0, "episode/score": 0.8560932813450108, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.015468305344029432}
{"step": 316584, "time": 10385.805884599686, "episode/length": 112.0, "episode/score": 0.6625665923455699, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.012566631292315833}
{"step": 317144, "time": 10403.425954341888, "episode/length": 78.0, "episode/score": 0.7666242076160756, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.010374195852307366}
{"step": 317280, "time": 10407.854523181915, "episode/length": 90.0, "episode/score": 0.7357417266336483, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.016991740792661858}
{"step": 317304, "time": 10408.383306264877, "episode/length": 90.0, "episode/score": 0.7379052678245444, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.01915527789446969}
{"step": 317872, "time": 10426.543521404266, "episode/length": 288.0, "episode/score": 0.01773553450067311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01773553450067311}
{"step": 318112, "time": 10433.997683763504, "episode/length": 288.0, "episode/score": 0.04516482100251551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04516482100251551}
{"step": 318336, "time": 10440.9351978302, "episode/length": 148.0, "episode/score": 0.5599814693888447, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.02248145561691217}
{"step": 318496, "time": 10445.911729574203, "episode/length": 288.0, "episode/score": 0.05023457223535388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05023457223535388}
{"step": 318712, "time": 10452.517221450806, "episode/length": 288.0, "episode/score": 0.024959119841241773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024959119841241773}
{"step": 318768, "time": 10454.47528553009, "episode/length": 81.0, "episode/score": 0.7665069527852211, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.01963199092870127}
{"step": 318896, "time": 10458.480580329895, "episode/length": 288.0, "episode/score": 0.017934492948711522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017934492948711522}
{"step": 319264, "time": 10469.904885053635, "episode/length": 45.0, "episode/score": 0.8810201710337537, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.021645194142195123}
{"step": 319440, "time": 10475.372084140778, "episode/length": 83.0, "episode/score": 0.7626969999764128, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.022071988212644555}
{"step": 319536, "time": 10478.851792573929, "episode/length": 129.0, "episode/score": 0.6310960194795143, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.03422100039904308}
{"step": 319592, "time": 10480.378799200058, "episode/length": 288.0, "episode/score": 0.04925252099883437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04925252099883437}
{"step": 319616, "time": 10481.350548505783, "episode/length": 288.0, "episode/score": 0.052161109883854806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052161109883854806}
{"step": 319760, "time": 10485.90235042572, "episode/length": 20.0, "episode/score": 0.9467555858030323, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.009255597881121957}
{"step": 320008, "time": 10494.32453083992, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 320008, "time": 10494.453524827957, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 320008, "time": 10494.579782247543, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 320008, "time": 10494.657360315323, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 320008, "time": 10494.716974973679, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 320008, "time": 10494.826888561249, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 320008, "time": 10495.210889816284, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 320008, "time": 10495.695944309235, "eval_episode/length": 67.0, "eval_episode/score": 0.7906249761581421, "eval_episode/reward_rate": 0.014705882352941176}
{"step": 320176, "time": 10501.167685747147, "episode/length": 79.0, "episode/score": 0.7769860940318267, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.023861102250748445}
{"step": 320184, "time": 10501.204790592194, "episode/length": 288.0, "episode/score": 0.06398494139290278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06398494139290278}
{"step": 320648, "time": 10515.63908290863, "episode/length": 288.0, "episode/score": 0.06621572854891156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06621572854891156}
{"step": 321024, "time": 10527.526182889938, "episode/length": 288.0, "episode/score": 0.07165966333877805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07165966333877805}
{"step": 321104, "time": 10530.026360034943, "episode/length": 207.0, "episode/score": 0.38088780293520585, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.02776280343579174}
{"step": 321144, "time": 10531.054385662079, "episode/length": 61.0, "episode/score": 0.834995275743438, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.02562025826949821}
{"step": 321504, "time": 10542.5694065094, "episode/length": 165.0, "episode/score": 0.534592765187881, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.050217753517245}
{"step": 321552, "time": 10544.073910951614, "episode/length": 170.0, "episode/score": 0.5196090766419843, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.05085907255289612}
{"step": 321576, "time": 10544.603596448898, "episode/length": 288.0, "episode/score": 0.06525050511226027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06525050511226027}
{"step": 321928, "time": 10555.535956382751, "episode/length": 288.0, "episode/score": 0.05226064303684552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05226064303684552}
{"step": 322072, "time": 10559.988081216812, "episode/length": 288.0, "episode/score": 0.05539081494555376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05539081494555376}
{"step": 322096, "time": 10560.954599380493, "episode/length": 118.0, "episode/score": 0.6573269967736906, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.026076985009922282}
{"step": 322144, "time": 10562.44149017334, "episode/length": 73.0, "episode/score": 0.8094508547192163, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.03757582269918203}
{"step": 322496, "time": 10573.440125465393, "episode/length": 114.0, "episode/score": 0.6648835878041837, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.021133576101533436}
{"step": 322608, "time": 10576.920686483383, "episode/length": 197.0, "episode/score": 0.4192911366091039, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.03491611595120503}
{"step": 322664, "time": 10578.441555023193, "episode/length": 73.0, "episode/score": 0.8130453956387669, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.04117039490535035}
{"step": 322776, "time": 10581.913158893585, "episode/length": 34.0, "episode/score": 0.9074153780012466, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.013665378158407293}
{"step": 323384, "time": 10600.727159261703, "episode/length": 89.0, "episode/score": 0.7414515429582593, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.01957655725988161}
{"step": 323416, "time": 10601.84238910675, "episode/length": 288.0, "episode/score": 0.04201728043165076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04201728043165076}
{"step": 323664, "time": 10609.753038167953, "episode/length": 189.0, "episode/score": 0.4410319929412765, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.03165697386080524}
{"step": 323792, "time": 10613.722012281418, "episode/length": 50.0, "episode/score": 0.8610504208881196, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.017300441027970237}
{"step": 323808, "time": 10614.22171497345, "episode/length": 128.0, "episode/score": 0.6393258184273805, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.03932580874453606}
{"step": 323816, "time": 10614.259897947311, "episode/length": 288.0, "episode/score": 0.05610587521746879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05610587521746879}
{"step": 324240, "time": 10627.644526481628, "episode/length": 288.0, "episode/score": 0.06577880198699404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06577880198699404}
{"step": 324408, "time": 10632.730015039444, "episode/length": 288.0, "episode/score": 0.06511649600875558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06511649600875558}
{"step": 324920, "time": 10648.61903476715, "episode/length": 288.0, "episode/score": 0.030857858311179598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030857858311179598}
{"step": 325088, "time": 10655.434119462967, "episode/length": 105.0, "episode/score": 0.7055221661649114, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.03364719238746261}
{"step": 325320, "time": 10662.51221704483, "episode/length": 187.0, "episode/score": 0.4482525803503279, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.03262758854887693}
{"step": 325512, "time": 10668.471879720688, "episode/length": 261.0, "episode/score": 0.26136207408958967, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.07698706828628588}
{"step": 325528, "time": 10668.980389595032, "episode/length": 216.0, "episode/score": 0.3887363955525984, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.06373641754345272}
{"step": 325760, "time": 10676.445677518845, "episode/length": 83.0, "episode/score": 0.762034691672028, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.021409676896013252}
{"step": 325936, "time": 10682.03469324112, "episode/length": 52.0, "episode/score": 0.8518715965196577, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.014371629427358812}
{"step": 325952, "time": 10682.545063018799, "episode/length": 267.0, "episode/score": 0.2365227257175775, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.07089771986625237}
{"step": 325976, "time": 10683.08661532402, "episode/length": 288.0, "episode/score": 0.06367548643095233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06367548643095233}
{"step": 326192, "time": 10690.10839343071, "episode/length": 158.0, "episode/score": 0.5480412679565347, "episode/reward_rate": 0.006289308176100629, "episode/intrinsic_return": 0.0417912622463632}
{"step": 326680, "time": 10705.264161586761, "episode/length": 92.0, "episode/score": 0.7354224575518344, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.022922507616243593}
{"step": 326720, "time": 10706.735954284668, "episode/length": 288.0, "episode/score": 0.058230672632021196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058230672632021196}
{"step": 327352, "time": 10726.36149597168, "episode/length": 83.0, "episode/score": 0.7535075395736328, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.01288251595005363}
{"step": 327456, "time": 10729.82477426529, "episode/length": 240.0, "episode/score": 0.30986842705013373, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.05986844120914725}
{"step": 327632, "time": 10735.346997737885, "episode/length": 288.0, "episode/score": 0.05291655949406504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05291655949406504}
{"step": 328072, "time": 10749.414268255234, "episode/length": 288.0, "episode/score": 0.03269331763792138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03269331763792138}
{"step": 328264, "time": 10755.545773267746, "episode/length": 288.0, "episode/score": 0.0518321407384974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0518321407384974}
{"step": 328288, "time": 10756.545758247375, "episode/length": 288.0, "episode/score": 0.038800063060932644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038800063060932644}
{"step": 328464, "time": 10762.120749473572, "episode/length": 138.0, "episode/score": 0.5990246870975682, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.03027466407061752}
{"step": 328504, "time": 10763.174764156342, "episode/length": 288.0, "episode/score": 0.027650214846346444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027650214846346444}
{"step": 328824, "time": 10773.336601734161, "episode/length": 170.0, "episode/score": 0.5045663023144868, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.0358163031293941}
{"step": 329032, "time": 10779.905598163605, "episode/length": 288.0, "episode/score": 0.052971632542721636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052971632542721636}
{"step": 329392, "time": 10791.661349773407, "episode/length": 164.0, "episode/score": 0.547017082874163, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.059517072117387215}
{"step": 329520, "time": 10795.708192586899, "episode/length": 153.0, "episode/score": 0.5547535724538193, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.03287853429287679}
{"step": 329880, "time": 10806.823209762573, "episode/length": 131.0, "episode/score": 0.6528682861010111, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.062243298836847316}
{"step": 329944, "time": 10808.81398177147, "episode/length": 288.0, "episode/score": 0.09121101194907055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09121101194907055}
{"step": 330032, "time": 10811.870825529099, "episode/length": 220.0, "episode/score": 0.3758609744174919, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.06336098087854225}
{"step": 330096, "time": 10814.217636585236, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 330096, "time": 10815.159312963486, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 330096, "time": 10815.397565603256, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 330096, "time": 10815.634080648422, "eval_episode/length": 104.0, "eval_episode/score": 0.675000011920929, "eval_episode/reward_rate": 0.009523809523809525}
{"step": 330096, "time": 10815.913816213608, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 330096, "time": 10815.988464355469, "eval_episode/length": 124.0, "eval_episode/score": 0.612500011920929, "eval_episode/reward_rate": 0.008}
{"step": 330096, "time": 10816.669188976288, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 330096, "time": 10817.671822309494, "eval_episode/length": 204.0, "eval_episode/score": 0.36250001192092896, "eval_episode/reward_rate": 0.004878048780487805}
{"step": 330768, "time": 10838.57892870903, "episode/length": 171.0, "episode/score": 0.5390010945156973, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0733761076007795}
{"step": 330776, "time": 10838.615344285965, "episode/length": 288.0, "episode/score": 0.07785323876862549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07785323876862549}
{"step": 330816, "time": 10840.081839561462, "episode/length": 288.0, "episode/score": 0.09061378505873563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09061378505873563}
{"step": 331152, "time": 10850.621922492981, "episode/length": 47.0, "episode/score": 0.8711650248732212, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.018040034395994553}
{"step": 331256, "time": 10853.646399974823, "episode/length": 59.0, "episode/score": 0.831763219105369, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.016138183843168008}
{"step": 331344, "time": 10856.633681058884, "episode/length": 288.0, "episode/score": 0.1089893858763844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1089893858763844}
{"step": 331616, "time": 10865.101126909256, "episode/length": 99.0, "episode/score": 0.7219812907172809, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03135626447726736}
{"step": 331792, "time": 10870.630041837692, "episode/length": 283.0, "episode/score": 0.18115149958930488, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.06552649868126537}
{"step": 331864, "time": 10872.760457515717, "episode/length": 228.0, "episode/score": 0.34179187323854876, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.0542918856600636}
{"step": 332192, "time": 10883.224147558212, "episode/length": 288.0, "episode/score": 0.05886433906471211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05886433906471211}
{"step": 332256, "time": 10885.211766958237, "episode/length": 288.0, "episode/score": 0.049945333053187824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049945333053187824}
{"step": 332296, "time": 10886.264489889145, "episode/length": 84.0, "episode/score": 0.7657270107279146, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.028226969412116887}
{"step": 332392, "time": 10889.275156974792, "episode/length": 65.0, "episode/score": 0.8189489696917462, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.022073970506653495}
{"step": 332544, "time": 10894.257762432098, "episode/length": 93.0, "episode/score": 0.7414860446099283, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03211102158297763}
{"step": 332936, "time": 10906.762064933777, "episode/length": 67.0, "episode/score": 0.8164878369880171, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.025862846510790405}
{"step": 333120, "time": 10912.727435827255, "episode/length": 71.0, "episode/score": 0.8050880497216895, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.026963033004449244}
{"step": 333192, "time": 10914.747242927551, "episode/length": 124.0, "episode/score": 0.6548315858540263, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.042331559614012804}
{"step": 333464, "time": 10923.25826215744, "episode/length": 288.0, "episode/score": 0.04450022650212304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04450022650212304}
{"step": 333568, "time": 10926.763576030731, "episode/length": 288.0, "episode/score": 0.053156782011456016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053156782011456016}
{"step": 333656, "time": 10929.31357550621, "episode/length": 288.0, "episode/score": 0.03437176292970889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03437176292970889}
{"step": 333688, "time": 10930.34178352356, "episode/length": 70.0, "episode/score": 0.8071665979300633, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.025916598744970543}
{"step": 334272, "time": 10949.08387875557, "episode/length": 251.0, "episode/score": 0.23880625278104617, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.02318125626186429}
{"step": 334288, "time": 10949.587005615234, "episode/length": 136.0, "episode/score": 0.6245884602442402, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.049588472980076403}
{"step": 334304, "time": 10950.090095758438, "episode/length": 104.0, "episode/score": 0.7047374462777043, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.029737404961906577}
{"step": 334608, "time": 10959.558125972748, "episode/length": 288.0, "episode/score": 0.03153963693546302, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03153963693546302}
{"step": 334792, "time": 10965.134313583374, "episode/length": 137.0, "episode/score": 0.6169066745187592, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.04503166972244799}
{"step": 334800, "time": 10965.608647108078, "episode/length": 142.0, "episode/score": 0.5927291313021215, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.036479140824894785}
{"step": 334936, "time": 10969.628139972687, "episode/length": 80.0, "episode/score": 0.7759680596561793, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.025968036314907295}
{"step": 335248, "time": 10979.634000062943, "episode/length": 288.0, "episode/score": 0.05924062534836594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05924062534836594}
{"step": 335400, "time": 10984.134395599365, "episode/length": 98.0, "episode/score": 0.7163220992467814, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.02257204601005469}
{"step": 335424, "time": 10985.101837158203, "episode/length": 139.0, "episode/score": 0.5917741740420297, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.026149153942924386}
{"step": 335880, "time": 10999.447241783142, "episode/length": 288.0, "episode/score": 0.05200102699780018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05200102699780018}
{"step": 336584, "time": 11021.731998682022, "episode/length": 288.0, "episode/score": 0.05256289855628893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05256289855628893}
{"step": 336752, "time": 11027.206236839294, "episode/length": 243.0, "episode/score": 0.2720677825875555, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.03144278971217318}
{"step": 336904, "time": 11031.692561864853, "episode/length": 127.0, "episode/score": 0.6593577177773113, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.05623272730008466}
{"step": 337104, "time": 11038.180409908295, "episode/length": 288.0, "episode/score": 0.09049067297496549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09049067297496549}
{"step": 337200, "time": 11041.163630008698, "episode/length": 224.0, "episode/score": 0.3478860001737303, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.047885989416954544}
{"step": 337248, "time": 11042.677782773972, "episode/length": 288.0, "episode/score": 0.05649225109186773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05649225109186773}
{"step": 337432, "time": 11048.190023899078, "episode/length": 250.0, "episode/score": 0.26462884443662915, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.04587884560078237}
{"step": 337560, "time": 11052.299344539642, "episode/length": 288.0, "episode/score": 0.08980879759860727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08980879759860727}
{"step": 337568, "time": 11052.774252414703, "episode/length": 122.0, "episode/score": 0.6700083542893935, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.05125836381216686}
{"step": 337976, "time": 11065.229833126068, "episode/length": 67.0, "episode/score": 0.8183962483885807, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.02777125791135404}
{"step": 338016, "time": 11066.690482378006, "episode/length": 56.0, "episode/score": 0.8470854172142026, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.022085420956955204}
{"step": 338048, "time": 11067.701867580414, "episode/length": 105.0, "episode/score": 0.7159693096682531, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.044094280273384356}
{"step": 339064, "time": 11099.347546577454, "episode/length": 288.0, "episode/score": 0.046964803450237014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046964803450237014}
{"step": 339216, "time": 11104.326355457306, "episode/length": 288.0, "episode/score": 0.05825396464047117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05825396464047117}
{"step": 339392, "time": 11109.829734802246, "episode/length": 167.0, "episode/score": 0.5317466421315657, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.05362163733525449}
{"step": 339416, "time": 11110.363554239273, "episode/length": 288.0, "episode/score": 0.075275714551708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.075275714551708}
{"step": 339560, "time": 11114.94378042221, "episode/length": 288.0, "episode/score": 0.05674200119199213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05674200119199213}
{"step": 339880, "time": 11124.945464372635, "episode/length": 288.0, "episode/score": 0.04435980336643297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04435980336643297}
{"step": 340080, "time": 11131.749834060669, "eval_episode/length": 19.0, "eval_episode/score": 0.940625011920929, "eval_episode/reward_rate": 0.05}
{"step": 340080, "time": 11131.970632076263, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 340080, "time": 11132.508314371109, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 340080, "time": 11133.543601989746, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 340080, "time": 11133.886925697327, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 340080, "time": 11134.526735782623, "eval_episode/length": 161.0, "eval_episode/score": 0.49687498807907104, "eval_episode/reward_rate": 0.006172839506172839}
{"step": 340080, "time": 11135.08698797226, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 340080, "time": 11135.578893899918, "eval_episode/length": 243.0, "eval_episode/score": 0.24062499403953552, "eval_episode/reward_rate": 0.004098360655737705}
{"step": 340152, "time": 11139.182737350464, "episode/length": 116.0, "episode/score": 0.6743441194769275, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.03684414952954285}
{"step": 340288, "time": 11143.764056921005, "episode/length": 288.0, "episode/score": 0.07068115352819859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07068115352819859}
{"step": 340328, "time": 11144.795253753662, "episode/length": 288.0, "episode/score": 0.07455902449839868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07455902449839868}
{"step": 340360, "time": 11145.798156499863, "episode/length": 161.0, "episode/score": 0.5581973422002875, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.0613223549361237}
{"step": 340568, "time": 11152.270343542099, "episode/length": 125.0, "episode/score": 0.663364391534742, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.05398937721565744}
{"step": 341104, "time": 11169.38122677803, "episode/length": 118.0, "episode/score": 0.6751040096972929, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.04385396251416296}
{"step": 341472, "time": 11180.930482387543, "episode/length": 147.0, "episode/score": 0.5916461200317826, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.05102113671409825}
{"step": 341672, "time": 11186.914357185364, "episode/length": 167.0, "episode/score": 0.5018521062944501, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.02372710114889287}
{"step": 341704, "time": 11187.913389444351, "episode/length": 288.0, "episode/score": 0.07337882868841916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07337882868841916}
{"step": 341728, "time": 11188.899822473526, "episode/length": 288.0, "episode/score": 0.027795927069973914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027795927069973914}
{"step": 342192, "time": 11203.45501446724, "episode/length": 288.0, "episode/score": 0.03647519791286413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03647519791286413}
{"step": 342672, "time": 11218.445016622543, "episode/length": 288.0, "episode/score": 0.060735853164089804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060735853164089804}
{"step": 342880, "time": 11224.932757854462, "episode/length": 288.0, "episode/score": 0.05015935604620836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05015935604620836}
{"step": 343280, "time": 11237.533652067184, "episode/length": 271.0, "episode/score": 0.2369598379914919, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.08383483559333627}
{"step": 343529, "time": 11246.078717470169, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2849492881503806, "train/action_min": 0.0, "train/action_std": 1.4985066942757157, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.006750508786242947, "train/actor_opt_grad_steps": 20390.0, "train/actor_opt_loss": 13.408863898083037, "train/adv_mag": 0.1020600822976398, "train/adv_max": 0.10134694570212195, "train/adv_mean": 0.011505091549109326, "train/adv_min": -0.020432079201422367, "train/adv_std": 0.01521037331886287, "train/cont_avg": 0.9961433217005076, "train/cont_loss_mean": 0.024053510609390167, "train/cont_loss_std": 0.31657783937437206, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.20127771338638, "train/cont_pos_acc": 0.9999999842667943, "train/cont_pos_loss": 0.003965263241939814, "train/cont_pred": 0.9960338548960419, "train/cont_rate": 0.9961433217005076, "train/dyn_loss_mean": 1.0000435912669612, "train/dyn_loss_std": 0.0013626342334106167, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9820922310771373, "train/extr_critic_critic_opt_grad_steps": 20390.0, "train/extr_critic_critic_opt_loss": 8883.826950770344, "train/extr_critic_mag": 0.653587716485038, "train/extr_critic_max": 0.653587716485038, "train/extr_critic_mean": 0.6447348491794567, "train/extr_critic_min": 0.6276988081520584, "train/extr_critic_std": 0.004589020842769027, "train/extr_return_normed_mag": 0.12516129289181704, "train/extr_return_normed_max": 0.12516129289181704, "train/extr_return_normed_mean": 0.031176845907253746, "train/extr_return_normed_min": 0.00037413200146050625, "train/extr_return_normed_std": 0.016553203642680335, "train/extr_return_rate": 1.0, "train/extr_return_raw_mag": 0.7502243806262912, "train/extr_return_raw_max": 0.7502243806262912, "train/extr_return_raw_mean": 0.6562399637275541, "train/extr_return_raw_min": 0.6254372197359347, "train/extr_return_raw_std": 0.016553203684046183, "train/extr_reward_mag": 0.08215533113721664, "train/extr_reward_max": 0.08215533113721664, "train/extr_reward_mean": 0.003244162769988179, "train/extr_reward_min": -6.184541634496698e-05, "train/extr_reward_std": 0.009531312425937598, "train/image_loss_mean": 0.1523284713931495, "train/image_loss_std": 0.11002614776495144, "train/model_loss_mean": 0.7908536271395417, "train/model_loss_std": 0.41325257022671286, "train/model_opt_grad_norm": 30.905453730355664, "train/model_opt_grad_steps": 20370.71573604061, "train/model_opt_loss": 3118.107042651491, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3946.700507614213, "train/policy_entropy_mag": 1.444220046706611, "train/policy_entropy_max": 1.444220046706611, "train/policy_entropy_mean": 0.24168866070999107, "train/policy_entropy_min": 0.06470137940445528, "train/policy_entropy_std": 0.2553800910257446, "train/policy_logprob_mag": 6.550978992191063, "train/policy_logprob_max": -0.00861064008517465, "train/policy_logprob_mean": -0.24137499735591375, "train/policy_logprob_min": -6.550978992191063, "train/policy_logprob_std": 0.7578475163672781, "train/policy_randomness_mag": 0.7421823319444801, "train/policy_randomness_max": 0.7421823319444801, "train/policy_randomness_mean": 0.12420341011306961, "train/policy_randomness_min": 0.03324993353734162, "train/policy_randomness_std": 0.13123941292920088, "train/post_ent_mag": 26.43615581299448, "train/post_ent_max": 26.43615581299448, "train/post_ent_mean": 25.59465137229958, "train/post_ent_min": 24.77159562086696, "train/post_ent_std": 0.3213983670557816, "train/prior_ent_mag": 30.76842292553277, "train/prior_ent_max": 30.76842292553277, "train/prior_ent_mean": 23.686116320227608, "train/prior_ent_min": 20.71185878811754, "train/prior_ent_std": 1.3631392360338705, "train/rep_loss_mean": 1.0000435912669612, "train/rep_loss_std": 0.0013626342334106167, "train/reward_avg": 0.0006869436063443849, "train/reward_loss_mean": 0.01444546710037943, "train/reward_loss_std": 0.11968388937432603, "train/reward_max_data": 0.36779212308598463, "train/reward_max_pred": 0.022988143306093167, "train/reward_neg_acc": 0.9999900753728024, "train/reward_neg_loss": 0.010181043828899032, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.341104888079459, "train/reward_pred": 0.0006042714118437492, "train/reward_rate": 0.000788190038071066, "train_stats/mean_log_entropy": 0.21451319304363028, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.038010500371456146, "report/cont_loss_std": 0.42987507581710815, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.059537887573242, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003447381779551506, "report/cont_pred": 0.9965065121650696, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12891104817390442, "report/image_loss_std": 0.10684847831726074, "report/model_loss_mean": 0.7912670373916626, "report/model_loss_std": 0.6255053877830505, "report/post_ent_mag": 25.351123809814453, "report/post_ent_max": 25.351123809814453, "report/post_ent_mean": 24.589290618896484, "report/post_ent_min": 23.76468276977539, "report/post_ent_std": 0.3215841054916382, "report/prior_ent_mag": 28.87602996826172, "report/prior_ent_max": 28.87602996826172, "report/prior_ent_mean": 21.817190170288086, "report/prior_ent_min": 18.87042999267578, "report/prior_ent_std": 1.3268991708755493, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0016303444281220436, "report/reward_loss_mean": 0.024345481768250465, "report/reward_loss_std": 0.30194976925849915, "report/reward_max_data": 0.8971527814865112, "report/reward_max_pred": 0.051233649253845215, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.012015454471111298, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.324989318847656, "report/reward_pred": 0.0009407792240381241, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009121800772845745, "eval/cont_loss_std": 0.20494408905506134, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.563911437988281, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002714382018893957, "eval/cont_pred": 0.9972919821739197, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.17541715502738953, "eval/image_loss_std": 0.10625914484262466, "eval/model_loss_mean": 0.7858172655105591, "eval/model_loss_std": 0.23435497283935547, "eval/post_ent_mag": 25.441543579101562, "eval/post_ent_max": 25.441543579101562, "eval/post_ent_mean": 24.462753295898438, "eval/post_ent_min": 23.819761276245117, "eval/post_ent_std": 0.2993945777416229, "eval/prior_ent_mag": 30.62058448791504, "eval/prior_ent_max": 30.62058448791504, "eval/prior_ent_mean": 21.567543029785156, "eval/prior_ent_min": 18.62097930908203, "eval/prior_ent_std": 1.3722964525222778, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012783044949173927, "eval/reward_loss_std": 0.0016654911451041698, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.008760571479797363, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012783044949173927, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022574199829250574, "eval/reward_rate": 0.0, "replay/size": 343025.0, "replay/inserts": 31440.0, "replay/samples": 31440.0, "replay/insert_wait_avg": 1.1807407131631866e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.337362105003143e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 78864.0, "eval_replay/inserts": 4752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.070324820701522e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4124500751495, "timer/env.step_count": 3930.0, "timer/env.step_total": 35.64121770858765, "timer/env.step_frac": 0.03562652354627367, "timer/env.step_avg": 0.009069012139589732, "timer/env.step_min": 0.007543087005615234, "timer/env.step_max": 0.051294803619384766, "timer/replay._sample_count": 31440.0, "timer/replay._sample_total": 15.530847787857056, "timer/replay._sample_frac": 0.015524444729461734, "timer/replay._sample_avg": 0.0004939837082651735, "timer/replay._sample_min": 0.0003733634948730469, "timer/replay._sample_max": 0.03146839141845703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4524.0, "timer/agent.policy_total": 43.38639283180237, "timer/agent.policy_frac": 0.043368505488454535, "timer/agent.policy_avg": 0.009590272509240135, "timer/agent.policy_min": 0.008387565612792969, "timer/agent.policy_max": 0.07958602905273438, "timer/dataset_train_count": 1965.0, "timer/dataset_train_total": 0.2010037899017334, "timer/dataset_train_frac": 0.00020092092005315836, "timer/dataset_train_avg": 0.00010229200503905007, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.00043892860412597656, "timer/agent.train_count": 1965.0, "timer/agent.train_total": 872.1372261047363, "timer/agent.train_frac": 0.8717776613428018, "timer/agent.train_avg": 0.4438357384756928, "timer/agent.train_min": 0.4338071346282959, "timer/agent.train_max": 0.5944726467132568, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47571825981140137, "timer/agent.report_frac": 0.00047552213067287007, "timer/agent.report_avg": 0.23785912990570068, "timer/agent.report_min": 0.23310494422912598, "timer/agent.report_max": 0.2426133155822754, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.574920654296875e-05, "timer/dataset_eval_frac": 2.573859065931707e-08, "timer/dataset_eval_avg": 2.574920654296875e-05, "timer/dataset_eval_min": 2.574920654296875e-05, "timer/dataset_eval_max": 2.574920654296875e-05, "fps": 31.42647953114318}
{"step": 343680, "time": 11250.778696537018, "episode/length": 99.0, "episode/score": 0.7159568105277572, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.02533181874667889}
{"step": 343752, "time": 11252.802305936813, "episode/length": 134.0, "episode/score": 0.635939734063868, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.054689740274625365}
{"step": 343784, "time": 11253.804060459137, "episode/length": 288.0, "episode/score": 0.0713420464594492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0713420464594492}
{"step": 343984, "time": 11260.298112392426, "episode/length": 288.0, "episode/score": 0.07726354645274114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07726354645274114}
{"step": 344016, "time": 11261.31060385704, "episode/length": 288.0, "episode/score": 0.05042940942769292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05042940942769292}
{"step": 344040, "time": 11261.910262823105, "episode/length": 288.0, "episode/score": 0.05840102845320416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05840102845320416}
{"step": 344152, "time": 11265.931173086166, "episode/length": 49.0, "episode/score": 0.8519048849760793, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.005029888160038354}
{"step": 344504, "time": 11276.908195018768, "episode/length": 288.0, "episode/score": 0.06510813568144158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06510813568144158}
{"step": 345592, "time": 11310.823204517365, "episode/length": 288.0, "episode/score": 0.04373511889184556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04373511889184556}
{"step": 345832, "time": 11318.261687040329, "episode/length": 165.0, "episode/score": 0.5115390058131766, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.027163991115742192}
{"step": 345992, "time": 11323.39028930664, "episode/length": 288.0, "episode/score": 0.03127603511660482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03127603511660482}
{"step": 346096, "time": 11326.917262077332, "episode/length": 288.0, "episode/score": 0.02651988916591108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02651988916591108}
{"step": 346296, "time": 11332.994106054306, "episode/length": 288.0, "episode/score": 0.032694662555456944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032694662555456944}
{"step": 346328, "time": 11333.99747300148, "episode/length": 288.0, "episode/score": 0.04536081548428683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04536081548428683}
{"step": 346352, "time": 11334.991364240646, "episode/length": 288.0, "episode/score": 0.04168599561913311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04168599561913311}
{"step": 346464, "time": 11338.477613687515, "episode/length": 288.0, "episode/score": 0.03822250440288144, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03822250440288144}
{"step": 346880, "time": 11351.49775648117, "episode/length": 68.0, "episode/score": 0.8054316348195982, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.01793160688865214}
{"step": 347904, "time": 11383.76761007309, "episode/length": 288.0, "episode/score": 0.029378202461288083, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029378202461288083}
{"step": 348144, "time": 11391.253720760345, "episode/length": 288.0, "episode/score": 0.04153699278262479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04153699278262479}
{"step": 348304, "time": 11396.246837377548, "episode/length": 288.0, "episode/score": 0.028979741057440833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028979741057440833}
{"step": 348408, "time": 11399.255480527878, "episode/length": 242.0, "episode/score": 0.28758606413487087, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.043836064897391225}
{"step": 348408, "time": 11399.2668466568, "episode/length": 288.0, "episode/score": 0.02218378416043265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02218378416043265}
{"step": 348496, "time": 11402.244418382645, "episode/length": 73.0, "episode/score": 0.7880525706511321, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.016177566949124866}
{"step": 348608, "time": 11405.758043289185, "episode/length": 288.0, "episode/score": 0.038388060399938695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038388060399938695}
{"step": 348664, "time": 11407.291717290878, "episode/length": 288.0, "episode/score": 0.041965422347061576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041965422347061576}
{"step": 348872, "time": 11413.962918758392, "episode/length": 248.0, "episode/score": 0.27340218901915136, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.048402201440666204}
{"step": 349088, "time": 11421.068219184875, "episode/length": 59.0, "episode/score": 0.8351526461655681, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.01952762708509681}
{"step": 350064, "time": 11457.956277608871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11457.965692043304, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11457.9741563797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11457.981793403625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11457.988199710846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11457.994108438492, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11458.004387617111, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11458.010431289673, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350456, "time": 11469.984779834747, "episode/length": 288.0, "episode/score": 0.02831548555275276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02831548555275276}
{"step": 350616, "time": 11475.057007312775, "episode/length": 288.0, "episode/score": 0.04104643901030158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04104643901030158}
{"step": 350720, "time": 11478.515889406204, "episode/length": 288.0, "episode/score": 0.047745683741140965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047745683741140965}
{"step": 350720, "time": 11478.530260324478, "episode/length": 288.0, "episode/score": 0.0434558927900639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0434558927900639}
{"step": 350808, "time": 11481.042630195618, "episode/length": 288.0, "episode/score": 0.029623654582024983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029623654582024983}
{"step": 350976, "time": 11486.466126680374, "episode/length": 288.0, "episode/score": 0.019736293602761634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019736293602761634}
{"step": 351184, "time": 11492.965413093567, "episode/length": 288.0, "episode/score": 0.030724957952088516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030724957952088516}
{"step": 351400, "time": 11499.429672956467, "episode/length": 288.0, "episode/score": 0.024535692437410717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024535692437410717}
{"step": 352768, "time": 11542.765060424805, "episode/length": 288.0, "episode/score": 0.03183190223177235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03183190223177235}
{"step": 352824, "time": 11544.296767234802, "episode/length": 251.0, "episode/score": 0.2412880853344177, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.025663087592874945}
{"step": 352928, "time": 11547.821094036102, "episode/length": 288.0, "episode/score": 0.037416601691262485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037416601691262485}
{"step": 353032, "time": 11550.85775756836, "episode/length": 288.0, "episode/score": 0.05407139581478759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05407139581478759}
{"step": 353032, "time": 11550.866266489029, "episode/length": 288.0, "episode/score": 0.03668158959399648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03668158959399648}
{"step": 353288, "time": 11558.904438734055, "episode/length": 288.0, "episode/score": 0.03796718975661406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03796718975661406}
{"step": 353496, "time": 11565.483442306519, "episode/length": 288.0, "episode/score": 0.04554360663999546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04554360663999546}
{"step": 353712, "time": 11572.44165277481, "episode/length": 288.0, "episode/score": 0.028636751962096696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028636751962096696}
{"step": 353800, "time": 11574.941667556763, "episode/length": 63.0, "episode/score": 0.8119210480210199, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.008796036257251671}
{"step": 354136, "time": 11585.354038715363, "episode/length": 79.0, "episode/score": 0.7815403849757558, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.028415385132916526}
{"step": 355024, "time": 11613.198851823807, "episode/length": 261.0, "episode/score": 0.21622773254284766, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.03185272997006905}
{"step": 355080, "time": 11614.716293096542, "episode/length": 288.0, "episode/score": 0.02199235444456349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02199235444456349}
{"step": 355136, "time": 11616.664785385132, "episode/length": 288.0, "episode/score": 0.03158763667653375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03158763667653375}
{"step": 355344, "time": 11623.244639396667, "episode/length": 288.0, "episode/score": 0.03987932227539659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03987932227539659}
{"step": 355344, "time": 11623.252888679504, "episode/length": 288.0, "episode/score": 0.04110953567487741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04110953567487741}
{"step": 355424, "time": 11625.74115896225, "episode/length": 49.0, "episode/score": 0.8630629690059664, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.016187949925495104}
{"step": 356024, "time": 11644.240359067917, "episode/length": 288.0, "episode/score": 0.041154156701168176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041154156701168176}
{"step": 356112, "time": 11647.217957019806, "episode/length": 288.0, "episode/score": 0.044651927742378916, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044651927742378916}
{"step": 356144, "time": 11648.22012758255, "episode/length": 99.0, "episode/score": 0.7109423600536218, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.020317319494523645}
{"step": 356152, "time": 11648.25522351265, "episode/length": 126.0, "episode/score": 0.6389718769400332, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.032721898930887505}
{"step": 356320, "time": 11653.834571123123, "episode/length": 121.0, "episode/score": 0.655363208189371, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.03348822032857868}
{"step": 356448, "time": 11657.846584558487, "episode/length": 288.0, "episode/score": 0.017200373444836714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017200373444836714}
{"step": 356592, "time": 11662.42083787918, "episode/length": 70.0, "episode/score": 0.7979358863860568, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.016685900545070353}
{"step": 357136, "time": 11679.486176490784, "episode/length": 101.0, "episode/score": 0.7221761728622909, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03780118500149854}
{"step": 357392, "time": 11687.586592197418, "episode/length": 288.0, "episode/score": 0.041289528829565825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041289528829565825}
{"step": 357736, "time": 11698.096612215042, "episode/length": 288.0, "episode/score": 0.03739602496365535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03739602496365535}
{"step": 358424, "time": 11719.557524681091, "episode/length": 288.0, "episode/score": 0.036628028609612784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036628028609612784}
{"step": 358456, "time": 11720.560259580612, "episode/length": 288.0, "episode/score": 0.038462809188601454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038462809188601454}
{"step": 358464, "time": 11721.037692546844, "episode/length": 288.0, "episode/score": 0.02875006225423249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02875006225423249}
{"step": 358760, "time": 11730.021847963333, "episode/length": 288.0, "episode/score": 0.025770051251868153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025770051251868153}
{"step": 358904, "time": 11734.523983240128, "episode/length": 288.0, "episode/score": 0.02933153494132057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02933153494132057}
{"step": 359448, "time": 11751.73530459404, "episode/length": 288.0, "episode/score": 0.01390903399018839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01390903399018839}
{"step": 359704, "time": 11759.723650455475, "episode/length": 288.0, "episode/score": 0.02919236766454958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02919236766454958}
{"step": 359808, "time": 11763.206670045853, "episode/length": 112.0, "episode/score": 0.6798320204983668, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.02983203718068239}
{"step": 359928, "time": 11766.709045886993, "episode/length": 273.0, "episode/score": 0.18560627017738796, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.038731276341579246}
{"step": 360048, "time": 11771.342283248901, "eval_episode/length": 29.0, "eval_episode/score": 0.909375011920929, "eval_episode/reward_rate": 0.03333333333333333}
{"step": 360048, "time": 11772.536678552628, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 360048, "time": 11772.812423229218, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 360048, "time": 11773.071553468704, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 360048, "time": 11773.128838300705, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 360048, "time": 11774.122864723206, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 360048, "time": 11774.495367527008, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 360048, "time": 11774.552742958069, "eval_episode/length": 180.0, "eval_episode/score": 0.4375, "eval_episode/reward_rate": 0.0055248618784530384}
{"step": 360064, "time": 11775.058288097382, "episode/length": 162.0, "episode/score": 0.5368404821004589, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.04309046944611339}
{"step": 360096, "time": 11776.056472539902, "episode/length": 203.0, "episode/score": 0.4192684716662711, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.053643478441642856}
{"step": 360112, "time": 11776.574890851974, "episode/length": 82.0, "episode/score": 0.7703997826742324, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.026649826655940956}
{"step": 360584, "time": 11791.543431282043, "episode/length": 109.0, "episode/score": 0.692015541305139, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03264051506512544}
{"step": 360736, "time": 11796.517342567444, "episode/length": 288.0, "episode/score": 0.050212613215549595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050212613215549595}
{"step": 360768, "time": 11797.543373346329, "episode/length": 288.0, "episode/score": 0.06561453272693996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06561453272693996}
{"step": 361264, "time": 11813.046281814575, "episode/length": 143.0, "episode/score": 0.5971884229104205, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.04406341720024898}
{"step": 361688, "time": 11826.043158531189, "episode/length": 234.0, "episode/score": 0.3282600855762041, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.05951007387355389}
{"step": 361800, "time": 11829.570658922195, "episode/length": 66.0, "episode/score": 0.8175440080791105, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.023794015910951316}
{"step": 361864, "time": 11831.60757303238, "episode/length": 140.0, "episode/score": 0.6219522314302992, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.059452246535187214}
{"step": 362240, "time": 11843.617410182953, "episode/length": 288.0, "episode/score": 0.08802369817763633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08802369817763633}
{"step": 362376, "time": 11847.670095205307, "episode/length": 288.0, "episode/score": 0.06797336319705494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06797336319705494}
{"step": 362408, "time": 11848.679784059525, "episode/length": 288.0, "episode/score": 0.09035391364005818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09035391364005818}
{"step": 362896, "time": 11864.17862868309, "episode/length": 288.0, "episode/score": 0.07492813682371491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07492813682371491}
{"step": 363080, "time": 11869.693601846695, "episode/length": 288.0, "episode/score": 0.061998019832202544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061998019832202544}
{"step": 363544, "time": 11884.21925330162, "episode/length": 217.0, "episode/score": 0.3771607208908989, "episode/reward_rate": 0.0045871559633027525, "episode/intrinsic_return": 0.05528571084134626}
{"step": 363736, "time": 11890.248152256012, "episode/length": 165.0, "episode/score": 0.5210066406151128, "episode/reward_rate": 0.006024096385542169, "episode/intrinsic_return": 0.036631636526024636}
{"step": 363856, "time": 11894.315311670303, "episode/length": 201.0, "episode/score": 0.41382202015978464, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.041947046239727115}
{"step": 364000, "time": 11898.880244016647, "episode/length": 288.0, "episode/score": 0.09420693606422503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09420693606422503}
{"step": 364072, "time": 11900.911145210266, "episode/length": 211.0, "episode/score": 0.3945635973368411, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.05393861094579222}
{"step": 364176, "time": 11904.404171943665, "episode/length": 288.0, "episode/score": 0.08602994194497171, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08602994194497171}
{"step": 364400, "time": 11911.4076192379, "episode/length": 40.0, "episode/score": 0.8851131024729, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.010113079131627956}
{"step": 365096, "time": 11933.0335791111, "episode/length": 114.0, "episode/score": 0.6767029557647675, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.03295295800285203}
{"step": 365208, "time": 11936.512917041779, "episode/length": 288.0, "episode/score": 0.06698018415033857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06698018415033857}
{"step": 365392, "time": 11942.485911607742, "episode/length": 288.0, "episode/score": 0.062752653105008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062752653105008}
{"step": 365856, "time": 11957.042355537415, "episode/length": 288.0, "episode/score": 0.04736279445366165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04736279445366165}
{"step": 365960, "time": 11960.065788030624, "episode/length": 93.0, "episode/score": 0.7279663973866235, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.018591383614690926}
{"step": 366008, "time": 11961.562537670135, "episode/length": 76.0, "episode/score": 0.7869291952937658, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.02442917781982601}
{"step": 366048, "time": 11963.05838394165, "episode/length": 288.0, "episode/score": 0.049021094892268025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049021094892268025}
{"step": 366160, "time": 11966.553134441376, "episode/length": 219.0, "episode/score": 0.3706913502373652, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.0550663301382599}
{"step": 366168, "time": 11966.588630199432, "episode/length": 133.0, "episode/score": 0.6239022319100656, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.03952720090866535}
{"step": 366168, "time": 11966.596633911133, "episode/length": 288.0, "episode/score": 0.04519647174139152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04519647174139152}
{"step": 366240, "time": 11969.07789182663, "episode/length": 279.0, "episode/score": 0.1699672458032211, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.041842250471475495}
{"step": 366336, "time": 11972.082196950912, "episode/length": 59.0, "episode/score": 0.8261526806873576, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.010527640652128412}
{"step": 366496, "time": 11977.08862376213, "episode/length": 40.0, "episode/score": 0.8830886063859396, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.008088578271639335}
{"step": 366808, "time": 11986.720671415329, "episode/length": 80.0, "episode/score": 0.7661656134982877, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.01616563064044385}
{"step": 366840, "time": 11987.744243144989, "episode/length": 83.0, "episode/score": 0.7616470946441893, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.021022087944487566}
{"step": 367128, "time": 11996.721575021744, "episode/length": 139.0, "episode/score": 0.5934520874496627, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.027827045835550734}
{"step": 367144, "time": 11997.224778652191, "episode/length": 80.0, "episode/score": 0.7654685222547926, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.015468542394643237}
{"step": 367432, "time": 12006.1832010746, "episode/length": 77.0, "episode/score": 0.7770072943900317, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.017632318450168327}
{"step": 367440, "time": 12006.661120414734, "episode/length": 184.0, "episode/score": 0.4677041815057521, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.04270416980310188}
{"step": 367680, "time": 12014.265372037888, "episode/length": 66.0, "episode/score": 0.8245785265537364, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.030828553579553386}
{"step": 368360, "time": 12035.227402448654, "episode/length": 288.0, "episode/score": 0.037660493194962896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037660493194962896}
{"step": 368552, "time": 12041.213816642761, "episode/length": 288.0, "episode/score": 0.07535975113559346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07535975113559346}
{"step": 368592, "time": 12042.82558298111, "episode/length": 113.0, "episode/score": 0.6728681062761552, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.025993059216716574}
{"step": 368648, "time": 12044.624994277954, "episode/length": 288.0, "episode/score": 0.07386224860387358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07386224860387358}
{"step": 369016, "time": 12056.2902135849, "episode/length": 45.0, "episode/score": 0.8730833505749018, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.01370833397844251}
{"step": 369064, "time": 12057.785688877106, "episode/length": 63.0, "episode/score": 0.8202293411100499, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.017104326334035136}
{"step": 369152, "time": 12060.77235198021, "episode/length": 288.0, "episode/score": 0.049869821189787444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049869821189787444}
{"step": 369440, "time": 12069.896320343018, "episode/length": 288.0, "episode/score": 0.04073573370669692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04073573370669692}
{"step": 369640, "time": 12076.008065462112, "episode/length": 60.0, "episode/score": 0.8374226047080242, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.02492258811156489}
{"step": 369744, "time": 12079.488321304321, "episode/length": 288.0, "episode/score": 0.14000261535495895, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.04000261462154242}
{"step": 369752, "time": 12079.524732351303, "episode/length": 288.0, "episode/score": 0.028715671346830618, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028715671346830618}
{"step": 369912, "time": 12084.586380958557, "episode/length": 33.0, "episode/score": 0.9178744610060221, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.020999408525995023}
{"step": 370032, "time": 12089.315279483795, "eval_episode/length": 44.0, "eval_episode/score": 0.862500011920929, "eval_episode/reward_rate": 0.022222222222222223}
{"step": 370032, "time": 12089.652945756912, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 370032, "time": 12089.79294013977, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 370032, "time": 12089.898992300034, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 370032, "time": 12090.007751464844, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 370032, "time": 12090.53841662407, "eval_episode/length": 113.0, "eval_episode/score": 0.6468750238418579, "eval_episode/reward_rate": 0.008771929824561403}
{"step": 370032, "time": 12090.665711641312, "eval_episode/length": 120.0, "eval_episode/score": 0.625, "eval_episode/reward_rate": 0.008264462809917356}
{"step": 370032, "time": 12090.807634592056, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 370056, "time": 12091.34581899643, "episode/length": 182.0, "episode/score": 0.4671147299917777, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.03586470971222866}
{"step": 370160, "time": 12094.830144643784, "episode/length": 136.0, "episode/score": 0.6170346320260904, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.04203461530885022}
{"step": 370488, "time": 12105.120331764221, "episode/length": 71.0, "episode/score": 0.8046051529518081, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.02648016568764433}
{"step": 370608, "time": 12109.153086423874, "episode/length": 107.0, "episode/score": 0.6889912910496321, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.023366315706397245}
{"step": 370648, "time": 12110.201862335205, "episode/length": 73.0, "episode/score": 0.802449149693075, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.030574126666124357}
{"step": 370672, "time": 12111.214255094528, "episode/length": 288.0, "episode/score": 0.05594969253479576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05594969253479576}
{"step": 370760, "time": 12113.806819915771, "episode/length": 33.0, "episode/score": 0.9090659813073216, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.012190934124191699}
{"step": 371312, "time": 12131.639086484909, "episode/length": 79.0, "episode/score": 0.7820480103830505, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.028922999277028794}
{"step": 371312, "time": 12131.650656461716, "episode/length": 87.0, "episode/score": 0.7604807912255183, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.03235581588228342}
{"step": 371328, "time": 12132.16869354248, "episode/length": 288.0, "episode/score": 0.06089585363717731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06089585363717731}
{"step": 371752, "time": 12145.269964456558, "episode/length": 288.0, "episode/score": 0.07584654917017986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07584654917017986}
{"step": 371880, "time": 12149.279574155807, "episode/length": 153.0, "episode/score": 0.5699292643680565, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.048054211131329794}
{"step": 372064, "time": 12155.272964000702, "episode/length": 288.0, "episode/score": 0.05244054017018129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05244054017018129}
{"step": 372472, "time": 12167.892749547958, "episode/length": 288.0, "episode/score": 0.08953953528134662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08953953528134662}
{"step": 373072, "time": 12187.073990106583, "episode/length": 288.0, "episode/score": 0.06562837432966262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06562837432966262}
{"step": 373624, "time": 12204.136550188065, "episode/length": 288.0, "episode/score": 0.038903180938177684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038903180938177684}
{"step": 373624, "time": 12204.144735097885, "episode/length": 288.0, "episode/score": 0.0446351149222437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0446351149222437}
{"step": 373640, "time": 12204.65495300293, "episode/length": 288.0, "episode/score": 0.084322468951882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.084322468951882}
{"step": 374064, "time": 12218.133845329285, "episode/length": 288.0, "episode/score": 0.08712553359703179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08712553359703179}
{"step": 374192, "time": 12222.204196929932, "episode/length": 288.0, "episode/score": 0.09745608105220072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09745608105220072}
{"step": 374376, "time": 12227.706259965897, "episode/length": 288.0, "episode/score": 0.0729060155111938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0729060155111938}
{"step": 374784, "time": 12240.665297269821, "episode/length": 288.0, "episode/score": 0.07068727827925159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07068727827925159}
{"step": 374937, "time": 12246.181917667389, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3142242431640625, "train/action_min": 0.0, "train/action_std": 1.5486681166352059, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007410533982804235, "train/actor_opt_grad_steps": 22355.0, "train/actor_opt_loss": 0.42977795590247425, "train/adv_mag": 0.22229517996311188, "train/adv_max": 0.19116701885145537, "train/adv_mean": 0.006920643633974907, "train/adv_min": -0.07222024792311144, "train/adv_std": 0.01968758882317996, "train/cont_avg": 0.9960837850765306, "train/cont_loss_mean": 0.023008300316976194, "train/cont_loss_std": 0.3037959141585482, "train/cont_neg_acc": 0.0017094017603458502, "train/cont_neg_loss": 4.8543561385228085, "train/cont_pos_acc": 0.999989989460731, "train/cont_pos_loss": 0.003932915196744535, "train/cont_pred": 0.9960494750008291, "train/cont_rate": 0.9960837850765306, "train/dyn_loss_mean": 1.0000312577704995, "train/dyn_loss_std": 0.0009073365036616748, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8260890015648031, "train/extr_critic_critic_opt_grad_steps": 22355.0, "train/extr_critic_critic_opt_loss": 6229.847989452129, "train/extr_critic_mag": 0.8824245309343144, "train/extr_critic_max": 0.8824245309343144, "train/extr_critic_mean": 0.8679294850753279, "train/extr_critic_min": 0.8453458425950031, "train/extr_critic_std": 0.00626798074339678, "train/extr_return_normed_mag": 0.24446353802875598, "train/extr_return_normed_max": 0.2191514527919341, "train/extr_return_normed_mean": 0.02992854967098018, "train/extr_return_normed_min": -0.04574290222051192, "train/extr_return_normed_std": 0.021568884536129783, "train/extr_return_rate": 0.999940213500237, "train/extr_return_raw_mag": 1.0640729756987826, "train/extr_return_raw_max": 1.0640729756987826, "train/extr_return_raw_mean": 0.8748501140852364, "train/extr_return_raw_min": 0.7991786206863365, "train/extr_return_raw_std": 0.021568884586022064, "train/extr_reward_mag": 0.19355728735729139, "train/extr_reward_max": 0.19355728735729139, "train/extr_reward_mean": 0.0028692648115886225, "train/extr_reward_min": 8.926099660445233e-06, "train/extr_reward_std": 0.010796188156783335, "train/image_loss_mean": 0.13955100371065188, "train/image_loss_std": 0.10950396886589575, "train/model_loss_mean": 0.7781689446799609, "train/model_loss_std": 0.41675291997285524, "train/model_opt_grad_norm": 29.348662074731322, "train/model_opt_grad_steps": 22333.469387755104, "train/model_opt_loss": 2173.7364875637754, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2793.3673469387754, "train/policy_entropy_mag": 1.4342635042813359, "train/policy_entropy_max": 1.4342635042813359, "train/policy_entropy_mean": 0.17473121052037696, "train/policy_entropy_min": 0.06468790146161099, "train/policy_entropy_std": 0.2127246083881782, "train/policy_logprob_mag": 6.551077314785549, "train/policy_logprob_max": -0.00860845291873022, "train/policy_logprob_mean": -0.17463437441204274, "train/policy_logprob_min": -6.551077314785549, "train/policy_logprob_std": 0.7066644916729051, "train/policy_randomness_mag": 0.7370656813894, "train/policy_randomness_max": 0.7370656813894, "train/policy_randomness_mean": 0.08979408505695816, "train/policy_randomness_min": 0.03324300734972467, "train/policy_randomness_std": 0.10931883022493245, "train/post_ent_mag": 23.296432154519216, "train/post_ent_max": 23.296432154519216, "train/post_ent_mean": 22.50027553402648, "train/post_ent_min": 21.715853759220668, "train/post_ent_std": 0.29756989322450694, "train/prior_ent_mag": 27.15201284447495, "train/prior_ent_max": 27.15201284447495, "train/prior_ent_mean": 19.567773595148203, "train/prior_ent_min": 17.015430946739354, "train/prior_ent_std": 1.2430858158943605, "train/rep_loss_mean": 1.0000312577704995, "train/rep_loss_std": 0.0009073365036616748, "train/reward_avg": 0.0008412728460899992, "train/reward_loss_mean": 0.015590863535180688, "train/reward_loss_std": 0.13561808189605268, "train/reward_max_data": 0.44335385438586983, "train/reward_max_pred": 0.039820716697342544, "train/reward_neg_acc": 0.9999700742108482, "train/reward_neg_loss": 0.01037358170213672, "train/reward_pos_acc": 0.03409090909090909, "train/reward_pos_loss": 5.047909840489879, "train/reward_pred": 0.0006764137681469093, "train/reward_rate": 0.0010263871173469387, "train_stats/mean_log_entropy": 0.15673111118886568, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02583063393831253, "report/cont_loss_std": 0.3746945559978485, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.923430919647217, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0027027882169932127, "report/cont_pred": 0.9973108768463135, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12080415338277817, "report/image_loss_std": 0.1044757142663002, "report/model_loss_mean": 0.7612937688827515, "report/model_loss_std": 0.5205098390579224, "report/post_ent_mag": 19.318885803222656, "report/post_ent_max": 19.318885803222656, "report/post_ent_mean": 18.65260887145996, "report/post_ent_min": 18.048828125, "report/post_ent_std": 0.2328786551952362, "report/prior_ent_mag": 23.172653198242188, "report/prior_ent_max": 23.172653198242188, "report/prior_ent_mean": 16.9599666595459, "report/prior_ent_min": 14.69459056854248, "report/prior_ent_std": 1.2404327392578125, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009034815593622625, "report/reward_loss_mean": 0.014658976346254349, "report/reward_loss_std": 0.1989523321390152, "report/reward_max_data": 0.7407440543174744, "report/reward_max_pred": 0.014492273330688477, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008453458547592163, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 6.362903594970703, "report/reward_pred": 0.0003919044975191355, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.028433535248041153, "eval/cont_loss_std": 0.40601933002471924, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.482263565063477, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003124401206150651, "eval/cont_pred": 0.9969135522842407, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21203479170799255, "eval/image_loss_std": 0.1382366269826889, "eval/model_loss_mean": 0.841723620891571, "eval/model_loss_std": 0.43384960293769836, "eval/post_ent_mag": 19.241283416748047, "eval/post_ent_max": 19.241283416748047, "eval/post_ent_mean": 18.621397018432617, "eval/post_ent_min": 17.914196014404297, "eval/post_ent_std": 0.2257823944091797, "eval/prior_ent_mag": 25.120452880859375, "eval/prior_ent_max": 25.120452880859375, "eval/prior_ent_mean": 17.003398895263672, "eval/prior_ent_min": 14.45787239074707, "eval/prior_ent_std": 1.1344373226165771, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012552561238408089, "eval/reward_loss_std": 0.0016583751421421766, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0044956207275390625, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012552561238408089, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002245549112558365, "eval/reward_rate": 0.0, "replay/size": 374433.0, "replay/inserts": 31408.0, "replay/samples": 31408.0, "replay/insert_wait_avg": 1.1856708973570254e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.331781222148629e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 83656.0, "eval_replay/inserts": 4792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0703959329697445e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4603137969970703e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.088675737381, "timer/env.step_count": 3926.0, "timer/env.step_total": 35.49597358703613, "timer/env.step_frac": 0.03549282623449805, "timer/env.step_avg": 0.009041256644685719, "timer/env.step_min": 0.007427692413330078, "timer/env.step_max": 0.03526186943054199, "timer/replay._sample_count": 31408.0, "timer/replay._sample_total": 15.47923231124878, "timer/replay._sample_frac": 0.01547785980061788, "timer/replay._sample_avg": 0.0004928436166342582, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.03247785568237305, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4525.0, "timer/agent.policy_total": 44.12258434295654, "timer/agent.policy_frac": 0.044118672087176944, "timer/agent.policy_avg": 0.009750847368609181, "timer/agent.policy_min": 0.008375406265258789, "timer/agent.policy_max": 0.15033411979675293, "timer/dataset_train_count": 1963.0, "timer/dataset_train_total": 0.20295166969299316, "timer/dataset_train_frac": 0.00020293367439977634, "timer/dataset_train_avg": 0.00010338852251298684, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.0010771751403808594, "timer/agent.train_count": 1963.0, "timer/agent.train_total": 873.4336845874786, "timer/agent.train_frac": 0.8733562390789821, "timer/agent.train_avg": 0.4449483874617823, "timer/agent.train_min": 0.43273067474365234, "timer/agent.train_max": 1.5110254287719727, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47388148307800293, "timer/agent.report_frac": 0.0004738394650140426, "timer/agent.report_avg": 0.23694074153900146, "timer/agent.report_min": 0.23418521881103516, "timer/agent.report_max": 0.23969626426696777, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.2649765014648438e-05, "timer/dataset_eval_frac": 2.264775670812232e-08, "timer/dataset_eval_avg": 2.2649765014648438e-05, "timer/dataset_eval_min": 2.2649765014648438e-05, "timer/dataset_eval_max": 2.2649765014648438e-05, "fps": 31.404680599632055}
{"step": 375384, "time": 12259.950355768204, "episode/length": 288.0, "episode/score": 0.07143496433013752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07143496433013752}
{"step": 375936, "time": 12277.528398275375, "episode/length": 288.0, "episode/score": 0.09018458294042375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09018458294042375}
{"step": 375936, "time": 12277.53743815422, "episode/length": 288.0, "episode/score": 0.044192206597699624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044192206597699624}
{"step": 375952, "time": 12278.063534259796, "episode/length": 288.0, "episode/score": 0.05082212155286925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05082212155286925}
{"step": 376376, "time": 12291.090175151825, "episode/length": 288.0, "episode/score": 0.05442519246560096, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05442519246560096}
{"step": 376504, "time": 12295.104759216309, "episode/length": 288.0, "episode/score": 0.07420309572535189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07420309572535189}
{"step": 376688, "time": 12301.075760364532, "episode/length": 288.0, "episode/score": 0.07256294752914982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07256294752914982}
{"step": 377096, "time": 12314.28873705864, "episode/length": 288.0, "episode/score": 0.05222121099814103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05222121099814103}
{"step": 377696, "time": 12333.342370033264, "episode/length": 288.0, "episode/score": 0.054694491461305006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054694491461305006}
{"step": 378248, "time": 12350.434047937393, "episode/length": 288.0, "episode/score": 0.07609800186082794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07609800186082794}
{"step": 378248, "time": 12350.44226694107, "episode/length": 288.0, "episode/score": 0.08686912375605971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08686912375605971}
{"step": 378264, "time": 12350.953392505646, "episode/length": 288.0, "episode/score": 0.06579923311846869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06579923311846869}
{"step": 378688, "time": 12364.477705717087, "episode/length": 288.0, "episode/score": 0.06380453162410049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06380453162410049}
{"step": 378720, "time": 12365.479806661606, "episode/length": 276.0, "episode/score": 0.2108249921584502, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.07332499034237117}
{"step": 379000, "time": 12374.08737707138, "episode/length": 288.0, "episode/score": 0.07277361124874915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07277361124874915}
{"step": 379408, "time": 12387.053425073624, "episode/length": 288.0, "episode/score": 0.0679323055187524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0679323055187524}
{"step": 380008, "time": 12405.851956367493, "episode/length": 288.0, "episode/score": 0.06050352282545646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06050352282545646}
{"step": 380016, "time": 12408.554935455322, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 380016, "time": 12411.307488441467, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12411.318941116333, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12411.326834201813, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12411.337582588196, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12411.343944311142, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12411.353413105011, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12411.361738204956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380344, "time": 12421.379072189331, "episode/length": 167.0, "episode/score": 0.5182114494523375, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.04008644465602629}
{"step": 380560, "time": 12428.393976211548, "episode/length": 288.0, "episode/score": 0.035216689055573625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035216689055573625}
{"step": 380560, "time": 12428.401849031448, "episode/length": 288.0, "episode/score": 0.04184529888539146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04184529888539146}
{"step": 380576, "time": 12428.9117333889, "episode/length": 288.0, "episode/score": 0.03451358618292488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03451358618292488}
{"step": 381000, "time": 12442.046891450882, "episode/length": 288.0, "episode/score": 0.06426127654401625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06426127654401625}
{"step": 381032, "time": 12443.047590970993, "episode/length": 288.0, "episode/score": 0.07533299376723335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07533299376723335}
{"step": 381720, "time": 12464.593783140182, "episode/length": 288.0, "episode/score": 0.05093331608702556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05093331608702556}
{"step": 381888, "time": 12470.061710357666, "episode/length": 163.0, "episode/score": 0.5218113631977985, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.03118635483917842}
{"step": 382320, "time": 12483.496414661407, "episode/length": 288.0, "episode/score": 0.0737658828281269, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0737658828281269}
{"step": 382544, "time": 12490.479471206665, "episode/length": 81.0, "episode/score": 0.7761434070823725, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.029268419818208713}
{"step": 382656, "time": 12494.089894771576, "episode/length": 288.0, "episode/score": 0.057945161288728286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057945161288728286}
{"step": 382848, "time": 12500.096094846725, "episode/length": 285.0, "episode/score": 0.16713872875970992, "episode/reward_rate": 0.0034965034965034965, "episode/intrinsic_return": 0.05776372957461717}
{"step": 382848, "time": 12500.10322380066, "episode/length": 65.0, "episode/score": 0.8259585579579607, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.029083558772867946}
{"step": 382872, "time": 12500.639226675034, "episode/length": 288.0, "episode/score": 0.04869214424314805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04869214424314805}
{"step": 383312, "time": 12514.64742898941, "episode/length": 288.0, "episode/score": 0.0496194203125242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0496194203125242}
{"step": 383344, "time": 12515.651171445847, "episode/length": 288.0, "episode/score": 0.029889133520100586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029889133520100586}
{"step": 384032, "time": 12537.168019294739, "episode/length": 288.0, "episode/score": 0.06015121291585501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06015121291585501}
{"step": 384088, "time": 12538.690641403198, "episode/length": 178.0, "episode/score": 0.46597759898645563, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.022227590627835525}
{"step": 384856, "time": 12562.82872891426, "episode/length": 288.0, "episode/score": 0.04359968672793002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04359968672793002}
{"step": 385120, "time": 12571.753737449646, "episode/length": 221.0, "episode/score": 0.3731431974080124, "episode/reward_rate": 0.0045045045045045045, "episode/intrinsic_return": 0.06376821014384859}
{"step": 385160, "time": 12572.778164625168, "episode/length": 288.0, "episode/score": 0.05952734980576224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05952734980576224}
{"step": 385160, "time": 12572.795196771622, "episode/length": 288.0, "episode/score": 0.06885495600977265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06885495600977265}
{"step": 385184, "time": 12573.766813278198, "episode/length": 288.0, "episode/score": 0.053033016627523466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053033016627523466}
{"step": 385248, "time": 12575.77612233162, "episode/length": 48.0, "episode/score": 0.8631676092520593, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.013167556015332593}
{"step": 385560, "time": 12585.38541173935, "episode/length": 280.0, "episode/score": 0.1687774130230082, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.043777419484058555}
{"step": 386344, "time": 12609.79862999916, "episode/length": 288.0, "episode/score": 0.0441479825449278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0441479825449278}
{"step": 386400, "time": 12611.868277311325, "episode/length": 288.0, "episode/score": 0.04308710720874842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04308710720874842}
{"step": 386992, "time": 12630.311921834946, "episode/length": 178.0, "episode/score": 0.47777807244483483, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.03402807956945253}
{"step": 387072, "time": 12632.80865764618, "episode/length": 90.0, "episode/score": 0.7497581016175445, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03100808729845994}
{"step": 387432, "time": 12643.930268526077, "episode/length": 288.0, "episode/score": 0.051204490559257465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051204490559257465}
{"step": 387472, "time": 12645.418294429779, "episode/length": 288.0, "episode/score": 0.02385089077097291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02385089077097291}
{"step": 387472, "time": 12645.430262327194, "episode/length": 288.0, "episode/score": 0.06797219979807778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06797219979807778}
{"step": 387496, "time": 12645.972030639648, "episode/length": 288.0, "episode/score": 0.042638142435066584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042638142435066584}
{"step": 387560, "time": 12647.972565412521, "episode/length": 288.0, "episode/score": 0.03638363544052936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03638363544052936}
{"step": 388272, "time": 12670.42774772644, "episode/length": 149.0, "episode/score": 0.583486540368142, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.04911149905234424}
{"step": 388712, "time": 12684.038981199265, "episode/length": 288.0, "episode/score": 0.0647577065563496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0647577065563496}
{"step": 389304, "time": 12702.612362623215, "episode/length": 288.0, "episode/score": 0.04974373853616498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04974373853616498}
{"step": 389744, "time": 12716.662374734879, "episode/length": 288.0, "episode/score": 0.05542169825912424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05542169825912424}
{"step": 389784, "time": 12717.718685150146, "episode/length": 288.0, "episode/score": 0.05005450241833387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05005450241833387}
{"step": 389784, "time": 12717.727582931519, "episode/length": 288.0, "episode/score": 0.06344027225350146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06344027225350146}
{"step": 389808, "time": 12718.72477221489, "episode/length": 288.0, "episode/score": 0.040636267700222106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040636267700222106}
{"step": 389872, "time": 12720.776645421982, "episode/length": 288.0, "episode/score": 0.06941691855871568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06941691855871568}
{"step": 390000, "time": 12729.672721147537, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.68311715126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.691811800003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.704307556152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.717289686203, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.722831249237, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.73432803154, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12729.741618871689, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390584, "time": 12747.809199094772, "episode/length": 288.0, "episode/score": 0.05630897902693732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05630897902693732}
{"step": 391024, "time": 12761.848226070404, "episode/length": 288.0, "episode/score": 0.057232049369872584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057232049369872584}
{"step": 391544, "time": 12777.83937549591, "episode/length": 219.0, "episode/score": 0.3382597461769592, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.02263473466348387}
{"step": 391616, "time": 12780.30910229683, "episode/length": 288.0, "episode/score": 0.04416461364905899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04416461364905899}
{"step": 392056, "time": 12793.884097337723, "episode/length": 288.0, "episode/score": 0.03987505042283601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03987505042283601}
{"step": 392096, "time": 12795.348699331284, "episode/length": 288.0, "episode/score": 0.05836793174756849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05836793174756849}
{"step": 392120, "time": 12795.901920318604, "episode/length": 288.0, "episode/score": 0.062459579779044816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062459579779044816}
{"step": 392120, "time": 12795.912192344666, "episode/length": 280.0, "episode/score": 0.17664405954604945, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.05164406277657463}
{"step": 392136, "time": 12796.418764352798, "episode/length": 73.0, "episode/score": 0.7817764520674473, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.009901448365440046}
{"step": 392400, "time": 12804.868495702744, "episode/length": 42.0, "episode/score": 0.8787182367719311, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.009968278745475345}
{"step": 392432, "time": 12805.893031597137, "episode/length": 38.0, "episode/score": 0.8878212640823335, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.006571216899203591}
{"step": 392480, "time": 12807.39331483841, "episode/length": 236.0, "episode/score": 0.3151607080297367, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.05266072641171604}
{"step": 392624, "time": 12811.896001338959, "episode/length": 62.0, "episode/score": 0.8182993047737455, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.012049343720491379}
{"step": 393336, "time": 12834.459037542343, "episode/length": 288.0, "episode/score": 0.031452620376228424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031452620376228424}
{"step": 393928, "time": 12853.02553987503, "episode/length": 288.0, "episode/score": 0.040492420956184105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040492420956184105}
{"step": 394336, "time": 12865.980823755264, "episode/length": 231.0, "episode/score": 0.2954038680198323, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.017278871762584913}
{"step": 394408, "time": 12868.0423848629, "episode/length": 288.0, "episode/score": 0.02678656558163084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02678656558163084}
{"step": 394448, "time": 12869.545726537704, "episode/length": 288.0, "episode/score": 0.03836396889198568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03836396889198568}
{"step": 394712, "time": 12877.705260753632, "episode/length": 288.0, "episode/score": 0.03561719607114355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03561719607114355}
{"step": 394744, "time": 12878.723529815674, "episode/length": 288.0, "episode/score": 0.01603933041332084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01603933041332084}
{"step": 394936, "time": 12884.91720533371, "episode/length": 288.0, "episode/score": 0.02898390547071017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02898390547071017}
{"step": 395648, "time": 12907.481503009796, "episode/length": 288.0, "episode/score": 0.02612735529140764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02612735529140764}
{"step": 396240, "time": 12926.078595399857, "episode/length": 288.0, "episode/score": 0.036944771183925695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036944771183925695}
{"step": 396632, "time": 12938.284249067307, "episode/length": 272.0, "episode/score": 0.21614736937775092, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.06614736399936305}
{"step": 396648, "time": 12938.798336744308, "episode/length": 288.0, "episode/score": 0.03025168325191885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03025168325191885}
{"step": 396720, "time": 12941.312274932861, "episode/length": 288.0, "episode/score": 0.14812657719932076, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.04812657629128125}
{"step": 397024, "time": 12951.003060340881, "episode/length": 288.0, "episode/score": 0.04777930118788731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04777930118788731}
{"step": 397056, "time": 12952.005243062973, "episode/length": 288.0, "episode/score": 0.04596486530354582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04596486530354582}
{"step": 397248, "time": 12958.023478746414, "episode/length": 288.0, "episode/score": 0.04168644094272622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04168644094272622}
{"step": 397928, "time": 12979.086345672607, "episode/length": 108.0, "episode/score": 0.6952951721241334, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.03279511964410631}
{"step": 397960, "time": 12980.085092782974, "episode/length": 288.0, "episode/score": 0.05461968697352404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05461968697352404}
{"step": 398312, "time": 12991.05837392807, "episode/length": 258.0, "episode/score": 0.22285788578494703, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.02910789820646187}
{"step": 398944, "time": 13011.155866146088, "episode/length": 288.0, "episode/score": 0.027885018287747698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027885018287747698}
{"step": 398960, "time": 13011.665634155273, "episode/length": 288.0, "episode/score": 0.021590933637867238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021590933637867238}
{"step": 399032, "time": 13013.710176229477, "episode/length": 288.0, "episode/score": 0.027808285006130973, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027808285006130973}
{"step": 399336, "time": 13023.290628433228, "episode/length": 288.0, "episode/score": 0.041527018021611184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041527018021611184}
{"step": 399560, "time": 13030.33126282692, "episode/length": 288.0, "episode/score": 0.023715176983614583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023715176983614583}
{"step": 400064, "time": 13046.40915942192, "episode/length": 128.0, "episode/score": 0.6162600883852747, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.01626005022433219}
{"step": 400088, "time": 13047.848061323166, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 400088, "time": 13049.529990196228, "eval_episode/length": 153.0, "eval_episode/score": 0.5218750238418579, "eval_episode/reward_rate": 0.006493506493506494}
{"step": 400088, "time": 13050.533805847168, "eval_episode/length": 176.0, "eval_episode/score": 0.44999998807907104, "eval_episode/reward_rate": 0.005649717514124294}
{"step": 400088, "time": 13051.648570299149, "eval_episode/length": 186.0, "eval_episode/score": 0.41874998807907104, "eval_episode/reward_rate": 0.0053475935828877}
{"step": 400088, "time": 13051.742378950119, "eval_episode/length": 91.0, "eval_episode/score": 0.715624988079071, "eval_episode/reward_rate": 0.010869565217391304}
{"step": 400088, "time": 13051.800416231155, "eval_episode/length": 248.0, "eval_episode/score": 0.22499999403953552, "eval_episode/reward_rate": 0.004016064257028112}
{"step": 400088, "time": 13052.132070541382, "eval_episode/length": 267.0, "eval_episode/score": 0.16562500596046448, "eval_episode/reward_rate": 0.0037313432835820895}
{"step": 400088, "time": 13052.501371383667, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13052.51014637947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13052.522883415222, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400160, "time": 13054.994534254074, "episode/length": 278.0, "episode/score": 0.17366960210102889, "episode/reward_rate": 0.0035842293906810036, "episode/intrinsic_return": 0.042419614522543725}
{"step": 400272, "time": 13058.507270812988, "episode/length": 288.0, "episode/score": 0.031236279442225623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031236279442225623}
{"step": 400624, "time": 13069.697340726852, "episode/length": 288.0, "episode/score": 0.03392734615670179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03392734615670179}
{"step": 400840, "time": 13076.258808135986, "episode/length": 159.0, "episode/score": 0.5399711699699878, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.036846128654190125}
{"step": 401256, "time": 13089.22184419632, "episode/length": 288.0, "episode/score": 0.03325232978670556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03325232978670556}
{"step": 401272, "time": 13089.729068517685, "episode/length": 288.0, "episode/score": 0.014521498574197267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014521498574197267}
{"step": 401480, "time": 13096.894154071808, "episode/length": 79.0, "episode/score": 0.7799480246932262, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.02682298413412809}
{"step": 401648, "time": 13102.376101255417, "episode/length": 288.0, "episode/score": 0.027355134281606297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027355134281606297}
{"step": 401664, "time": 13102.882865190506, "episode/length": 48.0, "episode/score": 0.8731312124069177, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.023131174245975217}
{"step": 401896, "time": 13110.060602664948, "episode/length": 216.0, "episode/score": 0.3820878850605709, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.057087903442550214}
{"step": 402008, "time": 13113.608279705048, "episode/length": 93.0, "episode/score": 0.7461106698807498, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03673563786071554}
{"step": 402192, "time": 13119.710390090942, "episode/length": 65.0, "episode/score": 0.8333589974293432, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.03648396879117399}
{"step": 402376, "time": 13125.357898950577, "episode/length": 288.0, "episode/score": 0.053657237054153484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053657237054153484}
{"step": 402432, "time": 13127.35820221901, "episode/length": 66.0, "episode/score": 0.8273698789822106, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.033619876584054964}
{"step": 402464, "time": 13128.386626243591, "episode/length": 101.0, "episode/score": 0.733192445044665, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.048817442646509335}
{"step": 402584, "time": 13131.981504678726, "episode/length": 288.0, "episode/score": 0.06742554302030612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06742554302030612}
{"step": 402784, "time": 13138.526817560196, "episode/length": 73.0, "episode/score": 0.8161868584738841, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.04431180599385698}
{"step": 402936, "time": 13143.117960214615, "episode/length": 288.0, "episode/score": 0.0754233717730699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0754233717730699}
{"step": 403040, "time": 13146.641543865204, "episode/length": 71.0, "episode/score": 0.8083627071805495, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.03023770478239385}
{"step": 403296, "time": 13154.670138835907, "episode/length": 88.0, "episode/score": 0.762664686944845, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.03766465492481075}
{"step": 403656, "time": 13165.677769422531, "episode/length": 89.0, "episode/score": 0.7532943341948339, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.03141929363573581}
{"step": 403664, "time": 13166.153602600098, "episode/length": 109.0, "episode/score": 0.7161882236559904, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.05681321254996874}
{"step": 403792, "time": 13170.153148412704, "episode/length": 288.0, "episode/score": 0.07677784804764087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07677784804764087}
{"step": 403856, "time": 13172.153528213501, "episode/length": 101.0, "episode/score": 0.7155249956422267, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.031150000403613376}
{"step": 404008, "time": 13176.671383619308, "episode/length": 88.0, "episode/score": 0.7638044149171037, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.03880440920693218}
{"step": 404096, "time": 13179.631735086441, "episode/length": 37.0, "episode/score": 0.906840697879943, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.02246570740271636}
{"step": 404128, "time": 13180.647661685944, "episode/length": 57.0, "episode/score": 0.8598959344546984, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.03802095113701398}
{"step": 404320, "time": 13186.728646278381, "episode/length": 288.0, "episode/score": 0.06182402853937674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06182402853937674}
{"step": 404640, "time": 13196.719735145569, "episode/length": 122.0, "episode/score": 0.6624421129970415, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.04369210820073022}
{"step": 404688, "time": 13198.218051671982, "episode/length": 288.0, "episode/score": 0.07422510327774035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07422510327774035}
{"step": 404744, "time": 13199.752320289612, "episode/length": 288.0, "episode/score": 0.08188606219778194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08188606219778194}
{"step": 404864, "time": 13203.748572587967, "episode/length": 91.0, "episode/score": 0.7556113071616437, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03998633922242334}
{"step": 404904, "time": 13204.782619953156, "episode/length": 100.0, "episode/score": 0.7166645742559012, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.029164597364342626}
{"step": 404904, "time": 13204.789679765701, "episode/length": 72.0, "episode/score": 0.8058369405341637, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.030836987484462952}
{"step": 405072, "time": 13210.296519517899, "episode/length": 132.0, "episode/score": 0.6351685373608689, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.04766853180785802}
{"step": 405448, "time": 13221.887407302856, "episode/length": 94.0, "episode/score": 0.7310008352706063, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.024750849572228617}
{"step": 405472, "time": 13222.861807823181, "episode/length": 103.0, "episode/score": 0.7077072750930711, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.029582247162124986}
{"step": 406104, "time": 13242.475321531296, "episode/length": 81.0, "episode/score": 0.7790923357259771, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03221733946872973}
{"step": 406168, "time": 13244.49067902565, "episode/length": 177.0, "episode/score": 0.49690797517996543, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.05003297003440821}
{"step": 406168, "time": 13244.499688863754, "episode/length": 288.0, "episode/score": 0.03250054806312619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03250054806312619}
{"step": 406201, "time": 13246.524125814438, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.247418462013712, "train/action_min": 0.0, "train/action_std": 1.4866089930339736, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00918452654803666, "train/actor_opt_grad_steps": 24315.0, "train/actor_opt_loss": -5.93639868851371, "train/adv_mag": 0.5364599614119043, "train/adv_max": 0.1920285976054717, "train/adv_mean": 0.0029561899199859686, "train/adv_min": -0.48709950884994196, "train/adv_std": 0.02895941443465726, "train/cont_avg": 0.9961086973852041, "train/cont_loss_mean": 0.02009587951850298, "train/cont_loss_std": 0.2766461151423959, "train/cont_neg_acc": 0.0786669551565939, "train/cont_neg_loss": 4.220827250945743, "train/cont_pos_acc": 0.9999349354481211, "train/cont_pos_loss": 0.0036982198582002322, "train/cont_pred": 0.9960422458089128, "train/cont_rate": 0.9961086973852041, "train/dyn_loss_mean": 1.0000248788570871, "train/dyn_loss_std": 0.0007596633852012836, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9771395284796551, "train/extr_critic_critic_opt_grad_steps": 24315.0, "train/extr_critic_critic_opt_loss": 6021.604621731505, "train/extr_critic_mag": 0.9196026100187885, "train/extr_critic_max": 0.9196026100187885, "train/extr_critic_mean": 0.9018374520296953, "train/extr_critic_min": 0.8830309114894088, "train/extr_critic_std": 0.007831019189622139, "train/extr_return_normed_mag": 0.5326483848751807, "train/extr_return_normed_max": 0.22858145893836507, "train/extr_return_normed_mean": 0.02848715740089704, "train/extr_return_normed_min": -0.4580742211974397, "train/extr_return_normed_std": 0.03068062387958017, "train/extr_return_rate": 0.9986444684315701, "train/extr_return_raw_mag": 1.104887907602349, "train/extr_return_raw_max": 1.104887907602349, "train/extr_return_raw_mean": 0.9047936562980924, "train/extr_return_raw_min": 0.4182322274665443, "train/extr_return_raw_std": 0.030680624041136126, "train/extr_reward_mag": 0.2153723811616703, "train/extr_reward_max": 0.2153723811616703, "train/extr_reward_mean": 0.0024801007787072175, "train/extr_reward_min": 6.954280697569555e-06, "train/extr_reward_std": 0.01077220423513256, "train/image_loss_mean": 0.12819974763052805, "train/image_loss_std": 0.10891147976627155, "train/model_loss_mean": 0.7633071596525154, "train/model_loss_std": 0.38474515646848145, "train/model_opt_grad_norm": 28.4654365072445, "train/model_opt_grad_steps": 24292.168367346938, "train/model_opt_loss": 3216.2282241509884, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4209.183673469388, "train/policy_entropy_mag": 1.4099530851354405, "train/policy_entropy_max": 1.4099530851354405, "train/policy_entropy_mean": 0.13509466749977092, "train/policy_entropy_min": 0.06468674213606485, "train/policy_entropy_std": 0.17664213740856063, "train/policy_logprob_mag": 6.551079681941441, "train/policy_logprob_max": -0.008608178344878311, "train/policy_logprob_mean": -0.13582470556911158, "train/policy_logprob_min": -6.551079681941441, "train/policy_logprob_std": 0.6763866327855051, "train/policy_randomness_mag": 0.7245725992382789, "train/policy_randomness_max": 0.7245725992382789, "train/policy_randomness_mean": 0.0694249303327227, "train/policy_randomness_min": 0.03324241136029667, "train/policy_randomness_std": 0.09077610759710779, "train/post_ent_mag": 18.582181361256815, "train/post_ent_max": 18.582181361256815, "train/post_ent_mean": 17.9512181768612, "train/post_ent_min": 17.376611894490768, "train/post_ent_std": 0.221623460477104, "train/prior_ent_mag": 21.847976528868383, "train/prior_ent_max": 21.847976528868383, "train/prior_ent_mean": 15.179810971629863, "train/prior_ent_min": 12.990149609896601, "train/prior_ent_std": 1.0207926427223244, "train/rep_loss_mean": 1.0000248788570871, "train/rep_loss_std": 0.0007596633852012836, "train/reward_avg": 0.0007996852311444688, "train/reward_loss_mean": 0.01499658145191034, "train/reward_loss_std": 0.12522869716797555, "train/reward_max_data": 0.4076063486531244, "train/reward_max_pred": 0.07128723725980642, "train/reward_neg_acc": 0.9999052353051244, "train/reward_neg_loss": 0.010269487789851062, "train/reward_pos_acc": 0.10301837301629735, "train/reward_pos_loss": 4.721640580282436, "train/reward_pred": 0.000724354966743184, "train/reward_rate": 0.0010064572704081632, "train_stats/mean_log_entropy": 0.12283767330167937, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.024446062743663788, "report/cont_loss_std": 0.26734381914138794, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.9165334701538086, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0045398566871881485, "report/cont_pred": 0.9944717884063721, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09653173387050629, "report/image_loss_std": 0.09987256675958633, "report/model_loss_mean": 0.7539981603622437, "report/model_loss_std": 0.5939733982086182, "report/post_ent_mag": 16.05455780029297, "report/post_ent_max": 16.05455780029297, "report/post_ent_mean": 15.500267028808594, "report/post_ent_min": 15.110254287719727, "report/post_ent_std": 0.17983821034431458, "report/prior_ent_mag": 22.2554988861084, "report/prior_ent_max": 22.2554988861084, "report/prior_ent_mean": 13.9266996383667, "report/prior_ent_min": 11.37086296081543, "report/prior_ent_std": 1.086620569229126, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0018160019535571337, "report/reward_loss_mean": 0.03302031382918358, "report/reward_loss_std": 0.33298200368881226, "report/reward_max_data": 0.9284375309944153, "report/reward_max_pred": 0.05263543128967285, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.01238207146525383, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.295772552490234, "report/reward_pred": 0.00130540004465729, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.017822489142417908, "eval/cont_loss_std": 0.35022589564323425, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.914485931396484, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002369137480854988, "eval/cont_pred": 0.9976511001586914, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20767931640148163, "eval/image_loss_std": 0.15921658277511597, "eval/model_loss_mean": 0.8268778324127197, "eval/model_loss_std": 0.3866128623485565, "eval/post_ent_mag": 15.91314697265625, "eval/post_ent_max": 15.91314697265625, "eval/post_ent_mean": 15.433679580688477, "eval/post_ent_min": 15.031702041625977, "eval/post_ent_std": 0.154190331697464, "eval/prior_ent_mag": 20.519590377807617, "eval/prior_ent_max": 20.519590377807617, "eval/prior_ent_mean": 13.79331111907959, "eval/prior_ent_min": 11.75803279876709, "eval/prior_ent_std": 1.1023892164230347, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013759895227849483, "eval/reward_loss_std": 0.0018760361708700657, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.011063218116760254, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013759895227849483, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00026536581572145224, "eval/reward_rate": 0.0, "replay/size": 405697.0, "replay/inserts": 31264.0, "replay/samples": 31264.0, "replay/insert_wait_avg": 1.1833230207007885e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.349917686095379e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90592.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0289535390464493e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3216211795807, "timer/env.step_count": 3908.0, "timer/env.step_total": 35.643426179885864, "timer/env.step_frac": 0.0356319661848907, "timer/env.step_avg": 0.009120631059336198, "timer/env.step_min": 0.007435321807861328, "timer/env.step_max": 0.03497767448425293, "timer/replay._sample_count": 31264.0, "timer/replay._sample_total": 15.544661521911621, "timer/replay._sample_frac": 0.015539663636962414, "timer/replay._sample_avg": 0.0004972064202249111, "timer/replay._sample_min": 0.0003688335418701172, "timer/replay._sample_max": 0.03337574005126953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4775.0, "timer/agent.policy_total": 46.52503681182861, "timer/agent.policy_frac": 0.04651007818562016, "timer/agent.policy_avg": 0.009743463206665678, "timer/agent.policy_min": 0.008436203002929688, "timer/agent.policy_max": 0.09476017951965332, "timer/dataset_train_count": 1954.0, "timer/dataset_train_total": 0.20354795455932617, "timer/dataset_train_frac": 0.0002034825102743477, "timer/dataset_train_avg": 0.00010416988462606252, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0010766983032226562, "timer/agent.train_count": 1954.0, "timer/agent.train_total": 869.5690720081329, "timer/agent.train_frac": 0.8692894900969309, "timer/agent.train_avg": 0.44501999590999636, "timer/agent.train_min": 0.4336516857147217, "timer/agent.train_max": 0.5961265563964844, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4650294780731201, "timer/agent.report_frac": 0.000464879962831111, "timer/agent.report_avg": 0.23251473903656006, "timer/agent.report_min": 0.2234039306640625, "timer/agent.report_max": 0.24162554740905762, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7647663101761813e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 31.25341757294736}
{"step": 406720, "time": 13262.704563379288, "episode/length": 155.0, "episode/score": 0.5570348186311094, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.04140983877096005}
{"step": 407008, "time": 13271.848215579987, "episode/length": 104.0, "episode/score": 0.6939249120829345, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.018924912240095182}
{"step": 407176, "time": 13276.899725198746, "episode/length": 288.0, "episode/score": 0.047911165414689094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047911165414689094}
{"step": 407216, "time": 13278.376179933548, "episode/length": 288.0, "episode/score": 0.07940253926574314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07940253926574314}
{"step": 407216, "time": 13278.384528875351, "episode/length": 288.0, "episode/score": 0.07420903418437774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07420903418437774}
{"step": 407344, "time": 13282.383777141571, "episode/length": 41.0, "episode/score": 0.8859862601636905, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.014111281150462673}
{"step": 407384, "time": 13283.420801401138, "episode/length": 288.0, "episode/score": 0.06344936552511626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06344936552511626}
{"step": 407544, "time": 13288.444342136383, "episode/length": 24.0, "episode/score": 0.9370776865157495, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.012077651253548538}
{"step": 407752, "time": 13294.991993188858, "episode/length": 128.0, "episode/score": 0.6441170667666256, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.04411703576522541}
{"step": 407912, "time": 13300.044657230377, "episode/length": 86.0, "episode/score": 0.7472395932419431, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.015989575469689044}
{"step": 408008, "time": 13303.165799856186, "episode/length": 31.0, "episode/score": 0.9150279015075284, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.01190293156014377}
{"step": 408064, "time": 13305.130017757416, "episode/length": 18.0, "episode/score": 0.9522418159531298, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.008491802181197272}
{"step": 408088, "time": 13305.660330057144, "episode/length": 247.0, "episode/score": 0.26943467257569864, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.04130966719731077}
{"step": 408480, "time": 13318.131164550781, "episode/length": 288.0, "episode/score": 0.030532447891687298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030532447891687298}
{"step": 408528, "time": 13319.627898693085, "episode/length": 142.0, "episode/score": 0.5963928582004883, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.040142873864169815}
{"step": 408768, "time": 13327.110934019089, "episode/length": 84.0, "episode/score": 0.7667411055952016, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.02924110374419797}
{"step": 408800, "time": 13328.101761817932, "episode/length": 91.0, "episode/score": 0.7385644518718664, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0229394356784951}
{"step": 409016, "time": 13334.664150953293, "episode/length": 183.0, "episode/score": 0.47923596092107346, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.051110973342588295}
{"step": 409304, "time": 13343.589389562607, "episode/length": 96.0, "episode/score": 0.7250145629550389, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.025014583941810997}
{"step": 409488, "time": 13349.514162302017, "episode/length": 288.0, "episode/score": 0.04934031935937355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04934031935937355}
{"step": 409528, "time": 13350.53349852562, "episode/length": 288.0, "episode/score": 0.04461506410552829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04461506410552829}
{"step": 409960, "time": 13364.571589231491, "episode/length": 58.0, "episode/score": 0.8311822060110217, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.012432152475980729}
{"step": 410072, "time": 13368.621808290482, "eval_episode/length": 30.0, "eval_episode/score": 0.90625, "eval_episode/reward_rate": 0.03225806451612903}
{"step": 410072, "time": 13369.556699752808, "eval_episode/length": 81.0, "eval_episode/score": 0.746874988079071, "eval_episode/reward_rate": 0.012195121951219513}
{"step": 410072, "time": 13370.39255452156, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 410072, "time": 13373.071685314178, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13373.079578876495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13373.087285757065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13373.09427857399, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13373.100868463516, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13373.107172250748, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410312, "time": 13380.572502374649, "episode/length": 97.0, "episode/score": 0.728157791385172, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03128283335871629}
{"step": 410320, "time": 13381.044843435287, "episode/length": 288.0, "episode/score": 0.05780294392934593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05780294392934593}
{"step": 410400, "time": 13383.545877933502, "episode/length": 203.0, "episode/score": 0.3977606768817168, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.032135683249634894}
{"step": 410608, "time": 13390.007495641708, "episode/length": 162.0, "episode/score": 0.5347874802603201, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.041037466121679245}
{"step": 410616, "time": 13390.043370723724, "episode/length": 199.0, "episode/score": 0.41325469811380344, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.035129676530402776}
{"step": 410792, "time": 13395.601215839386, "episode/length": 288.0, "episode/score": 0.047819365714588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047819365714588}
{"step": 411112, "time": 13405.504102230072, "episode/length": 288.0, "episode/score": 0.045570727907602304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045570727907602304}
{"step": 411184, "time": 13407.987660169601, "episode/length": 97.0, "episode/score": 0.7325462694516318, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.035671293511768454}
{"step": 411208, "time": 13408.524631500244, "episode/length": 110.0, "episode/score": 0.6806892604296877, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.02443928056953837}
{"step": 412040, "time": 13434.897305488586, "episode/length": 215.0, "episode/score": 0.38709339325959036, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.05896839336872972}
{"step": 412144, "time": 13438.406526327133, "episode/length": 272.0, "episode/score": 0.2066185459743224, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.05661854324438309}
{"step": 412344, "time": 13444.443215847015, "episode/length": 193.0, "episode/score": 0.4495909605091697, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.052715966687912896}
{"step": 412552, "time": 13450.913892030716, "episode/length": 167.0, "episode/score": 0.5099108377484072, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.031785832195396324}
{"step": 412560, "time": 13451.38861322403, "episode/length": 180.0, "episode/score": 0.48287241147170334, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.045372418056444985}
{"step": 412776, "time": 13458.029103755951, "episode/length": 53.0, "episode/score": 0.8597961806371472, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.02542113454541095}
{"step": 412888, "time": 13461.518007993698, "episode/length": 284.0, "episode/score": 0.1490956229903304, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.03659562524296689}
{"step": 412928, "time": 13463.029596567154, "episode/length": 288.0, "episode/score": 0.04009053886380798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04009053886380798}
{"step": 413072, "time": 13467.624980449677, "episode/length": 235.0, "episode/score": 0.34185680292483767, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.07623178822740329}
{"step": 413256, "time": 13473.25476527214, "episode/length": 86.0, "episode/score": 0.7607507085729708, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.029500735598787742}
{"step": 413344, "time": 13476.214781999588, "episode/length": 162.0, "episode/score": 0.5501129060031644, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.05636291324856302}
{"step": 413440, "time": 13479.21779680252, "episode/length": 45.0, "episode/score": 0.8786608479059623, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.01928587101440371}
{"step": 413496, "time": 13480.742961645126, "episode/length": 89.0, "episode/score": 0.7435653276527319, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.02169032780989255}
{"step": 413784, "time": 13489.861731290817, "episode/length": 54.0, "episode/score": 0.8468208720677239, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.015570852987252692}
{"step": 414088, "time": 13499.327383518219, "episode/length": 37.0, "episode/score": 0.8966923681140884, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.012317403510166969}
{"step": 414144, "time": 13501.294571876526, "episode/length": 87.0, "episode/score": 0.7551385931709547, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.027013643235363816}
{"step": 414168, "time": 13501.831998109818, "episode/length": 159.0, "episode/score": 0.5341075026109365, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.03098248864546349}
{"step": 414456, "time": 13510.858922958374, "episode/length": 288.0, "episode/score": 0.04895884015138563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04895884015138563}
{"step": 414664, "time": 13517.43837094307, "episode/length": 25.0, "episode/score": 0.9336484438269963, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.011773463966846975}
{"step": 414712, "time": 13518.963320970535, "episode/length": 67.0, "episode/score": 0.823257164911297, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03263218897143361}
{"step": 414760, "time": 13520.472566604614, "episode/length": 83.0, "episode/score": 0.7565698384333359, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.01594483769991939}
{"step": 414864, "time": 13523.976311206818, "episode/length": 288.0, "episode/score": 0.02559750417668738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02559750417668738}
{"step": 414936, "time": 13526.01224565506, "episode/length": 33.0, "episode/score": 0.9078756328551094, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.011000606968707416}
{"step": 414992, "time": 13528.023947954178, "episode/length": 105.0, "episode/score": 0.6991335508590737, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02725856944186944}
{"step": 415240, "time": 13535.597523927689, "episode/length": 288.0, "episode/score": 0.03267532548869667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03267532548869667}
{"step": 415568, "time": 13546.161833763123, "episode/length": 288.0, "episode/score": 0.05822139143651839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05822139143651839}
{"step": 415808, "time": 13553.667385578156, "episode/length": 288.0, "episode/score": 0.05174769747179653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05174769747179653}
{"step": 415848, "time": 13554.6897752285, "episode/length": 135.0, "episode/score": 0.609269754514628, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.031144766592717588}
{"step": 416120, "time": 13563.1800365448, "episode/length": 109.0, "episode/score": 0.6881346586902168, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.028759646849323417}
{"step": 416944, "time": 13589.717613697052, "episode/length": 141.0, "episode/score": 0.627650411178081, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.06827543517709955}
{"step": 417008, "time": 13591.715745925903, "episode/length": 179.0, "episode/score": 0.4999339667744209, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.05930895127372082}
{"step": 417024, "time": 13592.223337173462, "episode/length": 288.0, "episode/score": 0.06463958524543045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06463958524543045}
{"step": 417064, "time": 13593.257931947708, "episode/length": 265.0, "episode/score": 0.22891853269086937, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.05704353194872169}
{"step": 417176, "time": 13596.77595114708, "episode/length": 288.0, "episode/score": 0.06310044730753361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06310044730753361}
{"step": 417304, "time": 13600.793186664581, "episode/length": 288.0, "episode/score": 0.05415166042936903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05415166042936903}
{"step": 417384, "time": 13603.375605106354, "episode/length": 25.0, "episode/score": 0.9273402631963279, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.005465277355341414}
{"step": 417488, "time": 13606.846827983856, "episode/length": 170.0, "episode/score": 0.4872476862713597, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.018497699382635346}
{"step": 417640, "time": 13611.383709907532, "episode/length": 76.0, "episode/score": 0.7844170511366144, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.02191707312746871}
{"step": 417736, "time": 13614.4073843956, "episode/length": 90.0, "episode/score": 0.7520622020777239, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.033312202296002624}
{"step": 418032, "time": 13624.422270059586, "episode/length": 36.0, "episode/score": 0.8962343886684891, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.008734410659343439}
{"step": 418160, "time": 13628.414291858673, "episode/length": 288.0, "episode/score": 0.06539944167514022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06539944167514022}
{"step": 418352, "time": 13634.555150985718, "episode/length": 160.0, "episode/score": 0.5289564462210308, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.028956456290956112}
{"step": 418848, "time": 13650.058632850647, "episode/length": 182.0, "episode/score": 0.4679412271478327, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.036691222875390395}
{"step": 419088, "time": 13657.63052892685, "episode/length": 199.0, "episode/score": 0.4028849372285208, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.024759912647425608}
{"step": 419256, "time": 13662.884207963943, "episode/length": 288.0, "episode/score": 0.05525675094835947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05525675094835947}
{"step": 419264, "time": 13663.371819972992, "episode/length": 21.0, "episode/score": 0.9420495676106952, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.007674588597467391}
{"step": 419616, "time": 13674.390273332596, "episode/length": 288.0, "episode/score": 0.0518868084386952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0518868084386952}
{"step": 419624, "time": 13674.42522740364, "episode/length": 96.0, "episode/score": 0.724582451589697, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.024582486619067367}
{"step": 419952, "time": 13685.00812625885, "episode/length": 288.0, "episode/score": 0.04661660153360003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04661660153360003}
{"step": 420056, "time": 13690.324021100998, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 420056, "time": 13693.155021190643, "eval_episode/length": 279.0, "eval_episode/score": 0.12812499701976776, "eval_episode/reward_rate": 0.0035714285714285713}
{"step": 420056, "time": 13693.320348024368, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13693.328958749771, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13693.335866689682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13693.343567848206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13693.350186109543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13693.356944799423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420344, "time": 13702.408543348312, "episode/length": 288.0, "episode/score": 0.046210969150280334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046210969150280334}
{"step": 420392, "time": 13703.910562992096, "episode/length": 95.0, "episode/score": 0.7174697329088531, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.014344710186037446}
{"step": 420472, "time": 13706.432076931, "episode/length": 288.0, "episode/score": 0.023624601981396154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023624601981396154}
{"step": 420576, "time": 13709.903798103333, "episode/length": 164.0, "episode/score": 0.5290870603087683, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.04158705497258097}
{"step": 420664, "time": 13712.441417217255, "episode/length": 288.0, "episode/score": 0.050150800288463415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050150800288463415}
{"step": 421192, "time": 13729.061482191086, "episode/length": 196.0, "episode/score": 0.4249523112062832, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.03745233067965614}
{"step": 421336, "time": 13733.570303201675, "episode/length": 117.0, "episode/score": 0.66503523301472, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.030660279062800555}
{"step": 421520, "time": 13739.523335933685, "episode/length": 281.0, "episode/score": 0.17624845671548428, "episode/reward_rate": 0.0035460992907801418, "episode/intrinsic_return": 0.05437345091218049}
{"step": 421560, "time": 13740.582284212112, "episode/length": 111.0, "episode/score": 0.6876468510963605, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.034521840294473805}
{"step": 421800, "time": 13748.099123001099, "episode/length": 230.0, "episode/score": 0.31578576663181934, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.03453576674095871}
{"step": 422000, "time": 13754.680505990982, "episode/length": 24.0, "episode/score": 0.9310792052074248, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.006079179229345755}
{"step": 422104, "time": 13757.714013338089, "episode/length": 67.0, "episode/score": 0.8146739984737223, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.02404902735054293}
{"step": 422216, "time": 13761.223784923553, "episode/length": 233.0, "episode/score": 0.3234828315881657, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.05160784510107419}
{"step": 422784, "time": 13779.219247102737, "episode/length": 288.0, "episode/score": 0.05402396828662859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05402396828662859}
{"step": 422888, "time": 13782.398756027222, "episode/length": 288.0, "episode/score": 0.030821741309779327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030821741309779327}
{"step": 423504, "time": 13801.765983104706, "episode/length": 288.0, "episode/score": 0.021038208462982766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021038208462982766}
{"step": 423536, "time": 13802.757318496704, "episode/length": 251.0, "episode/score": 0.24215812114516666, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.0265331149416852}
{"step": 423560, "time": 13803.286644935608, "episode/length": 277.0, "episode/score": 0.18006740749814298, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.0456924060706001}
{"step": 423800, "time": 13810.7922270298, "episode/length": 32.0, "episode/score": 0.9074390376791541, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.007439089089615436}
{"step": 424088, "time": 13819.875799655914, "episode/length": 162.0, "episode/score": 0.5200626756550548, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.026312683853603858}
{"step": 424120, "time": 13820.899241924286, "episode/length": 39.0, "episode/score": 0.8890299870961655, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.010904949905835792}
{"step": 424152, "time": 13821.900873422623, "episode/length": 241.0, "episode/score": 0.30283648022836474, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.05596147402488327}
{"step": 424216, "time": 13823.907143831253, "episode/length": 276.0, "episode/score": 0.1800143278342432, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.042514331438752606}
{"step": 424320, "time": 13827.399530172348, "episode/length": 28.0, "episode/score": 0.9180406897189357, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.005540680832808675}
{"step": 424416, "time": 13830.421488761902, "episode/length": 288.0, "episode/score": 0.04226715431241246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04226715431241246}
{"step": 424600, "time": 13836.013619661331, "episode/length": 136.0, "episode/score": 0.6025681851167519, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.02756822361675404}
{"step": 424800, "time": 13842.60637140274, "episode/length": 154.0, "episode/score": 0.5440276480304078, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.025277642148523682}
{"step": 424960, "time": 13847.689509868622, "episode/length": 100.0, "episode/score": 0.7148751077175461, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.027375078322677382}
{"step": 425144, "time": 13853.222949504852, "episode/length": 102.0, "episode/score": 0.7202516883539829, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.039001697876756225}
{"step": 425200, "time": 13855.191064119339, "episode/length": 288.0, "episode/score": 0.058394218619042704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058394218619042704}
{"step": 425424, "time": 13862.199481010437, "episode/length": 57.0, "episode/score": 0.8441010338194701, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.022226028266459252}
{"step": 425712, "time": 13871.224789619446, "episode/length": 63.0, "episode/score": 0.8198402679197443, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.016715229758801797}
{"step": 426016, "time": 13881.315980434418, "episode/length": 108.0, "episode/score": 0.6949717074005548, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.03247167538052054}
{"step": 426024, "time": 13881.35459780693, "episode/length": 237.0, "episode/score": 0.30122576422843395, "episode/reward_rate": 0.004201680672268907, "episode/intrinsic_return": 0.04185075908287672}
{"step": 426232, "time": 13887.96783876419, "episode/length": 203.0, "episode/score": 0.41644617775440906, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.05082117553669718}
{"step": 426528, "time": 13897.530305147171, "episode/length": 288.0, "episode/score": 0.05110674631220036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05110674631220036}
{"step": 426560, "time": 13898.533013105392, "episode/length": 267.0, "episode/score": 0.24105140806904046, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.07542640883156082}
{"step": 427112, "time": 13915.647927761078, "episode/length": 288.0, "episode/score": 0.0719626466001273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0719626466001273}
{"step": 427120, "time": 13916.128684997559, "episode/length": 211.0, "episode/score": 0.40623765045143045, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.06561266883340977}
{"step": 427672, "time": 13933.407987833023, "episode/length": 142.0, "episode/score": 0.5788245602459483, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.022574575909629857}
{"step": 427736, "time": 13935.425560712814, "episode/length": 252.0, "episode/score": 0.2392669209716587, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.026766915826101467}
{"step": 427840, "time": 13938.909172296524, "episode/length": 159.0, "episode/score": 0.5377169169710214, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.03459189073100788}
{"step": 427848, "time": 13938.943959712982, "episode/length": 91.0, "episode/score": 0.7357236736811501, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.020098656207210297}
{"step": 427888, "time": 13940.412544488907, "episode/length": 233.0, "episode/score": 0.3361114016462352, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.06423640842160694}
{"step": 427992, "time": 13943.456676721573, "episode/length": 17.0, "episode/score": 0.9563523015467581, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.009477302047343983}
{"step": 428336, "time": 13954.432490348816, "episode/length": 288.0, "episode/score": 0.04424288454640646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04424288454640646}
{"step": 428416, "time": 13956.939814329147, "episode/length": 65.0, "episode/score": 0.8073286174985697, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.010453609320393298}
{"step": 428544, "time": 13960.961686134338, "episode/length": 288.0, "episode/score": 0.06021423205879728, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06021423205879728}
{"step": 428640, "time": 13964.072855710983, "episode/length": 120.0, "episode/score": 0.6390482496883578, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.014048269828208504}
{"step": 429016, "time": 13975.56720495224, "episode/length": 58.0, "episode/score": 0.8353243296786559, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01657429151771339}
{"step": 429128, "time": 13979.083513975143, "episode/length": 250.0, "episode/score": 0.2609414845642277, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.04219149128721256}
{"step": 429256, "time": 13983.176072359085, "episode/length": 176.0, "episode/score": 0.47243789966580607, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.022437904427192734}
{"step": 429368, "time": 13986.752613544464, "episode/length": 118.0, "episode/score": 0.660109852764208, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.02885982176280777}
{"step": 429432, "time": 13988.798984527588, "episode/length": 211.0, "episode/score": 0.3560594454452257, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.015434445695518662}
{"step": 429448, "time": 13989.305793523788, "episode/length": 181.0, "episode/score": 0.4826898603762402, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.04831486263469742}
{"step": 429464, "time": 13989.816431045532, "episode/length": 102.0, "episode/score": 0.7156510498857642, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.03440109386747281}
{"step": 429472, "time": 13990.293207883835, "episode/length": 42.0, "episode/score": 0.8826171564035121, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.013867198377056411}
{"step": 429608, "time": 13994.416734933853, "episode/length": 17.0, "episode/score": 0.9561315312469105, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.009256570193656444}
{"step": 429736, "time": 13998.415104866028, "episode/length": 89.0, "episode/score": 0.7473445732366599, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.025469581455581647}
{"step": 429776, "time": 13999.884866714478, "episode/length": 64.0, "episode/score": 0.8213340279439763, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.02133400784487094}
{"step": 430040, "time": 14007.948354959488, "episode/length": 53.0, "episode/score": 0.8533433003919981, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.018968296689990893}
{"step": 430040, "time": 14009.64796423912, "eval_episode/length": 99.0, "eval_episode/score": 0.690625011920929, "eval_episode/reward_rate": 0.01}
{"step": 430040, "time": 14009.82636809349, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 430040, "time": 14011.01725435257, "eval_episode/length": 79.0, "eval_episode/score": 0.753125011920929, "eval_episode/reward_rate": 0.0125}
{"step": 430040, "time": 14012.255742073059, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 430040, "time": 14012.849377632141, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14012.857140779495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14012.864604711533, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14012.871030807495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14012.87722992897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14012.883565664291, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430392, "time": 14023.940840959549, "episode/length": 43.0, "episode/score": 0.8715714247523465, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.005946424018929974}
{"step": 430592, "time": 14030.431368350983, "episode/length": 106.0, "episode/score": 0.6811383592886386, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.012388367120479415}
{"step": 430648, "time": 14031.974080562592, "episode/length": 288.0, "episode/score": 0.04241502304557798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04241502304557798}
{"step": 431072, "time": 14045.494403362274, "episode/length": 84.0, "episode/score": 0.7544244578326698, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.01692446101662881}
{"step": 431328, "time": 14053.63532447815, "episode/length": 91.0, "episode/score": 0.749131996443225, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03350703147259537}
{"step": 431680, "time": 14064.655037164688, "episode/length": 288.0, "episode/score": 0.02885893842801579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02885893842801579}
{"step": 431744, "time": 14066.658564567566, "episode/length": 288.0, "episode/score": 0.028509910088928336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028509910088928336}
{"step": 431760, "time": 14067.162599563599, "episode/length": 288.0, "episode/score": 0.03741029883212832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03741029883212832}
{"step": 431784, "time": 14067.690616607666, "episode/length": 288.0, "episode/score": 0.03812475788129177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03812475788129177}
{"step": 431888, "time": 14071.138224124908, "episode/length": 69.0, "episode/score": 0.7993292555440803, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.014954255701240982}
{"step": 432088, "time": 14077.174721717834, "episode/length": 288.0, "episode/score": 0.02066026598345161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02066026598345161}
{"step": 432120, "time": 14078.199618816376, "episode/length": 54.0, "episode/score": 0.8453798946502502, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.01412989688833477}
{"step": 432752, "time": 14098.398577690125, "episode/length": 120.0, "episode/score": 0.6502677227279037, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.025267694613603453}
{"step": 432960, "time": 14104.975786685944, "episode/length": 288.0, "episode/score": 0.029290001140054756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029290001140054756}
{"step": 432984, "time": 14105.515112876892, "episode/length": 136.0, "episode/score": 0.6125647015991831, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.03756470943102386}
{"step": 433384, "time": 14118.051489114761, "episode/length": 288.0, "episode/score": 0.03786911048979391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03786911048979391}
{"step": 433456, "time": 14120.522864103317, "episode/length": 58.0, "episode/score": 0.8269086183036052, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.008158595276654523}
{"step": 433528, "time": 14122.545973062515, "episode/length": 70.0, "episode/score": 0.7994038100724765, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.01815381088738377}
{"step": 433640, "time": 14126.055583953857, "episode/length": 236.0, "episode/score": 0.29964127794005435, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.03714129632203367}
{"step": 433664, "time": 14127.02688574791, "episode/length": 113.0, "episode/score": 0.6655724299314443, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.018697420248599883}
{"step": 433952, "time": 14136.023673057556, "episode/length": 52.0, "episode/score": 0.8482483612408487, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.010748395152631929}
{"step": 434056, "time": 14139.105435848236, "episode/length": 74.0, "episode/score": 0.7816603860426312, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.012910392253388636}
{"step": 434072, "time": 14139.613393306732, "episode/length": 288.0, "episode/score": 0.013668028855022385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013668028855022385}
{"step": 434248, "time": 14145.701313495636, "episode/length": 75.0, "episode/score": 0.7750411343802739, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.009416104687090865}
{"step": 434296, "time": 14147.201662540436, "episode/length": 113.0, "episode/score": 0.6630715378459513, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.016196531146249527}
{"step": 434400, "time": 14150.68271613121, "episode/length": 288.0, "episode/score": 0.03116617664682053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03116617664682053}
{"step": 434432, "time": 14151.689744710922, "episode/length": 288.0, "episode/score": 0.025393270605832186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025393270605832186}
{"step": 434888, "time": 14165.80257320404, "episode/length": 56.0, "episode/score": 0.8350308117123291, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.010030816473715731}
{"step": 434896, "time": 14166.289242982864, "episode/length": 74.0, "episode/score": 0.7811030612958234, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.012353067506580828}
{"step": 435152, "time": 14174.379409313202, "episode/length": 185.0, "episode/score": 0.4330417112348641, "episode/reward_rate": 0.005376344086021506, "episode/intrinsic_return": 0.011166711453142852}
{"step": 435272, "time": 14177.89504814148, "episode/length": 46.0, "episode/score": 0.8660989263810848, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.009848916052135337}
{"step": 435504, "time": 14185.391057252884, "episode/length": 156.0, "episode/score": 0.5397350979317252, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.027235124011667722}
{"step": 435760, "time": 14193.36932682991, "episode/length": 75.0, "episode/score": 0.7823890594171985, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.016764085639749737}
{"step": 435800, "time": 14194.427743673325, "episode/length": 65.0, "episode/score": 0.8136883467857388, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.016813366925589435}
{"step": 436048, "time": 14202.636129617691, "episode/length": 248.0, "episode/score": 0.2504419819800887, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.025441983109317334}
{"step": 436112, "time": 14204.682896375656, "episode/length": 75.0, "episode/score": 0.7756853262618506, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.010060349370291988}
{"step": 436264, "time": 14209.244441509247, "episode/length": 288.0, "episode/score": 0.027542410740863943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027542410740863943}
{"step": 436384, "time": 14213.276537656784, "episode/length": 288.0, "episode/score": 0.02358416506120875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02358416506120875}
{"step": 436472, "time": 14215.857192516327, "episode/length": 52.0, "episode/score": 0.8441198922743638, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.006619933258377841}
{"step": 436712, "time": 14223.388625144958, "episode/length": 288.0, "episode/score": 0.024883684544192874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024883684544192874}
{"step": 436984, "time": 14231.982675075531, "episode/length": 74.0, "episode/score": 0.7752140289060776, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.006464032090036653}
{"step": 437112, "time": 14235.987699747086, "episode/length": 79.0, "episode/score": 0.7632185776702727, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.010093588857785107}
{"step": 437200, "time": 14238.942563772202, "episode/length": 288.0, "episode/score": 0.020552738650167157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020552738650167157}
{"step": 437425, "time": 14246.56042098999, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.053009815705128, "train/action_min": 0.0, "train/action_std": 1.7306860214624649, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.007638225873383001, "train/actor_opt_grad_steps": 26270.0, "train/actor_opt_loss": -4.027459287614777, "train/adv_mag": 0.7601517353302393, "train/adv_max": 0.17551980324280567, "train/adv_mean": 0.002938174538949403, "train/adv_min": -0.7386270098197154, "train/adv_std": 0.024864106508306203, "train/cont_avg": 0.9958082932692308, "train/cont_loss_mean": 0.01672592988022818, "train/cont_loss_std": 0.24153814419196584, "train/cont_neg_acc": 0.25385166527991443, "train/cont_neg_loss": 3.200072218347149, "train/cont_pos_acc": 0.9998541562985152, "train/cont_pos_loss": 0.003260265169545817, "train/cont_pred": 0.9958362212547889, "train/cont_rate": 0.9958082932692308, "train/dyn_loss_mean": 1.0000094395417434, "train/dyn_loss_std": 0.00026708209890131956, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5651171746544349, "train/extr_critic_critic_opt_grad_steps": 26270.0, "train/extr_critic_critic_opt_loss": 12246.165780248397, "train/extr_critic_mag": 1.0137714551045345, "train/extr_critic_max": 1.0137714551045345, "train/extr_critic_mean": 0.9801486091736036, "train/extr_critic_min": 0.9478080083162357, "train/extr_critic_std": 0.009688308039823403, "train/extr_return_normed_mag": 0.7515839919065818, "train/extr_return_normed_max": 0.21188007104091156, "train/extr_return_normed_mean": 0.024858469082615697, "train/extr_return_normed_min": -0.7165927816659976, "train/extr_return_normed_std": 0.02723534089059402, "train/extr_return_rate": 0.9990021103467697, "train/extr_return_raw_mag": 1.1701083372800778, "train/extr_return_raw_max": 1.1701083372800778, "train/extr_return_raw_mean": 0.9830868008809212, "train/extr_return_raw_min": 0.24163548457316864, "train/extr_return_raw_std": 0.027235341038650426, "train/extr_reward_mag": 0.21418735002860045, "train/extr_reward_max": 0.21418735002860045, "train/extr_reward_mean": 0.002283841234822877, "train/extr_reward_min": 6.058888557629708e-06, "train/extr_reward_std": 0.008165210844853367, "train/image_loss_mean": 0.12185272505650153, "train/image_loss_std": 0.1066190541172639, "train/model_loss_mean": 0.7542481596653278, "train/model_loss_std": 0.36974458197752635, "train/model_opt_grad_norm": 26.965124839391464, "train/model_opt_grad_steps": 26245.420512820514, "train/model_opt_loss": 2456.5176544971955, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3256.4102564102564, "train/policy_entropy_mag": 1.3335423475656754, "train/policy_entropy_max": 1.3335423475656754, "train/policy_entropy_mean": 0.12377210221229455, "train/policy_entropy_min": 0.06468668916286566, "train/policy_entropy_std": 0.1598707784826939, "train/policy_logprob_mag": 6.551080168210543, "train/policy_logprob_max": -0.008608200381963681, "train/policy_logprob_mean": -0.12373318614868017, "train/policy_logprob_min": -6.551080168210543, "train/policy_logprob_std": 0.6603475515659039, "train/policy_randomness_mag": 0.6853052426607181, "train/policy_randomness_max": 0.6853052426607181, "train/policy_randomness_mean": 0.06360628148302054, "train/policy_randomness_min": 0.033242383847634, "train/policy_randomness_std": 0.08215733267940008, "train/post_ent_mag": 15.403176615788386, "train/post_ent_max": 15.403176615788386, "train/post_ent_mean": 14.901189354138497, "train/post_ent_min": 14.483362667377179, "train/post_ent_std": 0.16944233721647506, "train/prior_ent_mag": 17.815618280264047, "train/prior_ent_max": 17.815618280264047, "train/prior_ent_mean": 12.652165090120755, "train/prior_ent_min": 10.76588973020896, "train/prior_ent_std": 0.897606118214436, "train/rep_loss_mean": 1.0000094395417434, "train/rep_loss_std": 0.00026708209890131956, "train/reward_avg": 0.0009058618829257261, "train/reward_loss_mean": 0.015663815275407753, "train/reward_loss_std": 0.13734975608113484, "train/reward_max_data": 0.48819148171788607, "train/reward_max_pred": 0.09267509228143937, "train/reward_neg_acc": 0.9998445636186845, "train/reward_neg_loss": 0.010361397135047577, "train/reward_pos_acc": 0.13945578271839895, "train/reward_pos_loss": 4.513170621022075, "train/reward_pred": 0.0007525907554783118, "train/reward_rate": 0.0011668669871794872, "train_stats/mean_log_entropy": 0.11162472998156496, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.006499348673969507, "report/cont_loss_std": 0.10682260990142822, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 2.3635425567626953, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0018867391627281904, "report/cont_pred": 0.997937798500061, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09510244429111481, "report/image_loss_std": 0.08670493215322495, "report/model_loss_mean": 0.7144005298614502, "report/model_loss_std": 0.23846091330051422, "report/post_ent_mag": 14.794572830200195, "report/post_ent_max": 14.794572830200195, "report/post_ent_mean": 14.234758377075195, "report/post_ent_min": 13.863391876220703, "report/post_ent_std": 0.17353425920009613, "report/prior_ent_mag": 14.092126846313477, "report/prior_ent_max": 14.092126846313477, "report/prior_ent_mean": 11.355260848999023, "report/prior_ent_min": 9.698914527893066, "report/prior_ent_std": 0.7753130793571472, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006146264495328069, "report/reward_loss_mean": 0.012798696756362915, "report/reward_loss_std": 0.13041363656520844, "report/reward_max_data": 0.44437500834465027, "report/reward_max_pred": 0.11716532707214355, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.008755272254347801, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.1492228507995605, "report/reward_pred": 0.0005512256175279617, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.027389416471123695, "eval/cont_loss_std": 0.42078226804733276, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.689187049865723, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.001264719758182764, "eval/cont_pred": 0.9987524747848511, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22691529989242554, "eval/image_loss_std": 0.12961654365062714, "eval/model_loss_mean": 0.867946982383728, "eval/model_loss_std": 0.7132164239883423, "eval/post_ent_mag": 14.707418441772461, "eval/post_ent_max": 14.707418441772461, "eval/post_ent_mean": 14.173093795776367, "eval/post_ent_min": 13.799341201782227, "eval/post_ent_std": 0.1656864881515503, "eval/prior_ent_mag": 16.260557174682617, "eval/prior_ent_max": 16.260557174682617, "eval/prior_ent_mean": 11.242177963256836, "eval/prior_ent_min": 9.405340194702148, "eval/prior_ent_std": 0.830758273601532, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006286621210165322, "eval/reward_loss_mean": 0.013642193749547005, "eval/reward_loss_std": 0.3891456723213196, "eval/reward_max_data": 0.643750011920929, "eval/reward_max_pred": 0.006618499755859375, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014755630400031805, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.460103988647461, "eval/reward_pred": 0.00024955649860203266, "eval/reward_rate": 0.0009765625, "replay/size": 436921.0, "replay/inserts": 31224.0, "replay/samples": 31216.0, "replay/insert_wait_avg": 1.19672015847654e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.433777647345937e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 97528.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.073055476328356e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.109476089477539e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.017320394516, "timer/env.step_count": 3903.0, "timer/env.step_total": 35.864171504974365, "timer/env.step_frac": 0.03586355033413383, "timer/env.step_avg": 0.009188873047649081, "timer/env.step_min": 0.0075054168701171875, "timer/env.step_max": 0.03564572334289551, "timer/replay._sample_count": 31216.0, "timer/replay._sample_total": 15.581746339797974, "timer/replay._sample_frac": 0.015581476462478502, "timer/replay._sample_avg": 0.0004991589678305348, "timer/replay._sample_min": 0.0003554821014404297, "timer/replay._sample_max": 0.011391401290893555, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4770.0, "timer/agent.policy_total": 46.39990496635437, "timer/agent.policy_frac": 0.046399101315614394, "timer/agent.policy_avg": 0.009727443389172825, "timer/agent.policy_min": 0.008375406265258789, "timer/agent.policy_max": 0.09090161323547363, "timer/dataset_train_count": 1951.0, "timer/dataset_train_total": 0.20145440101623535, "timer/dataset_train_frac": 0.00020145091180696724, "timer/dataset_train_avg": 0.00010325699693297557, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.000392913818359375, "timer/agent.train_count": 1951.0, "timer/agent.train_total": 869.1332652568817, "timer/agent.train_frac": 0.8691182117865726, "timer/agent.train_avg": 0.4454809150470947, "timer/agent.train_min": 0.433255672454834, "timer/agent.train_max": 0.594254732131958, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755992889404297, "timer/agent.report_frac": 0.0004755910515157892, "timer/agent.report_avg": 0.23779964447021484, "timer/agent.report_min": 0.23067212104797363, "timer/agent.report_max": 0.24492716789245605, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.05170495576622e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 31.222902483605203}
{"step": 437872, "time": 14260.796356916428, "episode/length": 110.0, "episode/score": 0.6736335054974347, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.017383476859265556}
{"step": 438072, "time": 14266.896835803986, "episode/length": 288.0, "episode/score": 0.015033779706982386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015033779706982386}
{"step": 438112, "time": 14268.376225471497, "episode/length": 288.0, "episode/score": 0.0195851037411785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0195851037411785}
{"step": 438424, "time": 14277.935209274292, "episode/length": 288.0, "episode/score": 0.043009737526404024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043009737526404024}
{"step": 438576, "time": 14282.9057803154, "episode/length": 288.0, "episode/score": 0.02827089579903941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02827089579903941}
{"step": 439024, "time": 14297.03817653656, "episode/length": 288.0, "episode/score": 0.047677231589375424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047677231589375424}
{"step": 439424, "time": 14309.52489733696, "episode/length": 288.0, "episode/score": 0.05353465082936282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05353465082936282}
{"step": 439512, "time": 14312.075428009033, "episode/length": 288.0, "episode/score": 0.066036094837159, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.066036094837159}
{"step": 439616, "time": 14315.569874286652, "episode/length": 73.0, "episode/score": 0.8077544676420985, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.035879444615147804}
{"step": 439624, "time": 14315.60533452034, "episode/length": 24.0, "episode/score": 0.9374005084791861, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.01240047321698512}
{"step": 439624, "time": 14315.612114906311, "episode/length": 130.0, "episode/score": 0.6437876733116354, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.05003764997036342}
{"step": 439792, "time": 14321.208970069885, "episode/length": 34.0, "episode/score": 0.911275201399576, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.017525160083778246}
{"step": 440024, "time": 14329.855528593063, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 440024, "time": 14330.285070180893, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 440024, "time": 14330.360800743103, "eval_episode/length": 76.0, "eval_episode/score": 0.762499988079071, "eval_episode/reward_rate": 0.012987012987012988}
{"step": 440024, "time": 14330.485872507095, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 440024, "time": 14330.80337715149, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 440024, "time": 14330.913394212723, "eval_episode/length": 34.0, "eval_episode/score": 0.893750011920929, "eval_episode/reward_rate": 0.02857142857142857}
{"step": 440024, "time": 14331.123189210892, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 440024, "time": 14332.892441511154, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 440184, "time": 14337.891583919525, "episode/length": 288.0, "episode/score": 0.05856454080912954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05856454080912954}
{"step": 440320, "time": 14342.354523897171, "episode/length": 280.0, "episode/score": 0.19442649235725185, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.06942649352140506}
{"step": 440408, "time": 14344.881129264832, "episode/length": 97.0, "episode/score": 0.7441814229860029, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.04730641818969161}
{"step": 440424, "time": 14345.389226198196, "episode/length": 288.0, "episode/score": 0.04288720609497432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04288720609497432}
{"step": 440464, "time": 14346.876732110977, "episode/length": 104.0, "episode/score": 0.716218902410219, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.041218891304197314}
{"step": 440736, "time": 14355.438623666763, "episode/length": 288.0, "episode/score": 0.0315448954686417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0315448954686417}
{"step": 440808, "time": 14357.48500919342, "episode/length": 126.0, "episode/score": 0.653965362598683, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.047715375334519194}
{"step": 441072, "time": 14365.978395223618, "episode/length": 93.0, "episode/score": 0.7330346761089004, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.023659623628873305}
{"step": 441216, "time": 14370.452157735825, "episode/length": 199.0, "episode/score": 0.4281353446056073, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.05001033914572872}
{"step": 441288, "time": 14372.512167930603, "episode/length": 68.0, "episode/score": 0.8148528837514277, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.027352852750027523}
{"step": 441560, "time": 14381.136607646942, "episode/length": 141.0, "episode/score": 0.5869573768532064, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.0275823654328633}
{"step": 441624, "time": 14383.214406728745, "episode/length": 50.0, "episode/score": 0.8604052824445034, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.01665528325941068}
{"step": 441936, "time": 14393.207594633102, "episode/length": 183.0, "episode/score": 0.45935096962750777, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.031225967409795885}
{"step": 442376, "time": 14406.962482213974, "episode/length": 135.0, "episode/score": 0.6347864822936344, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.05666146797454985}
{"step": 442496, "time": 14411.137514591217, "episode/length": 288.0, "episode/score": 0.05282706079367472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05282706079367472}
{"step": 442720, "time": 14418.21690940857, "episode/length": 288.0, "episode/score": 0.0387797843509361, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0387797843509361}
{"step": 442792, "time": 14420.252357721329, "episode/length": 51.0, "episode/score": 0.8548595491564583, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.014234581217237974}
{"step": 443048, "time": 14428.329464197159, "episode/length": 279.0, "episode/score": 0.19467767782123246, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.06655268138354131}
{"step": 443112, "time": 14430.337587356567, "episode/length": 146.0, "episode/score": 0.5841738871225743, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.040423891883961005}
{"step": 443312, "time": 14436.845848321915, "episode/length": 210.0, "episode/score": 0.4033161013554718, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.05956609169300009}
{"step": 443320, "time": 14436.881633996964, "episode/length": 219.0, "episode/score": 0.36397119171158465, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.04834618019810932}
{"step": 443344, "time": 14437.862506389618, "episode/length": 77.0, "episode/score": 0.7836111339818217, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.024236128428810844}
{"step": 443384, "time": 14438.892663955688, "episode/length": 288.0, "episode/score": 0.0346591291573759, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0346591291573759}
{"step": 443408, "time": 14439.86929988861, "episode/length": 113.0, "episode/score": 0.6878778216706678, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.0410027906692676}
{"step": 443568, "time": 14444.962330579758, "episode/length": 27.0, "episode/score": 0.9271726377105551, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.011547632157544285}
{"step": 443608, "time": 14445.990218639374, "episode/length": 101.0, "episode/score": 0.7158617128895912, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03148671765097788}
{"step": 443864, "time": 14454.006391525269, "episode/length": 68.0, "episode/score": 0.8076495184630517, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.020149512752880128}
{"step": 443904, "time": 14455.472003936768, "episode/length": 61.0, "episode/score": 0.8253833894463583, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.016008421507137882}
{"step": 443952, "time": 14456.988150596619, "episode/length": 78.0, "episode/score": 0.7829891856421227, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.026739154640722518}
{"step": 443984, "time": 14457.989399671555, "episode/length": 74.0, "episode/score": 0.7916880841275429, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.022938072424892653}
{"step": 444040, "time": 14459.8390417099, "episode/length": 58.0, "episode/score": 0.8315343071104735, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01278425387374682}
{"step": 444056, "time": 14460.34554696083, "episode/length": 125.0, "episode/score": 0.624351365849634, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.014976358690091729}
{"step": 444352, "time": 14469.807672739029, "episode/length": 92.0, "episode/score": 0.734311021804956, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.021811068755255292}
{"step": 444496, "time": 14474.37075996399, "episode/length": 73.0, "episode/score": 0.7878246689940624, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.015949645370483267}
{"step": 444640, "time": 14478.855530023575, "episode/length": 72.0, "episode/score": 0.7910428079886742, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.0160428519703828}
{"step": 444912, "time": 14487.375986814499, "episode/length": 130.0, "episode/score": 0.6227429667784463, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.028992981883334323}
{"step": 444992, "time": 14489.89178442955, "episode/length": 118.0, "episode/score": 0.6534439960218492, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.022193972398270034}
{"step": 445272, "time": 14498.422081232071, "episode/length": 78.0, "episode/score": 0.7773963353211002, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.021146311697521014}
{"step": 445296, "time": 14499.388904094696, "episode/length": 163.0, "episode/score": 0.5197620704009296, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.029137088439483705}
{"step": 445400, "time": 14502.51107287407, "episode/length": 112.0, "episode/score": 0.6740398563824215, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.024039895329167393}
{"step": 445424, "time": 14503.479429721832, "episode/length": 288.0, "episode/score": 0.04167844356487649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04167844356487649}
{"step": 445488, "time": 14505.460289239883, "episode/length": 71.0, "episode/score": 0.7967575842174597, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.018632608216478275}
{"step": 445688, "time": 14511.456477880478, "episode/length": 86.0, "episode/score": 0.7439178560716755, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.012667886124290817}
{"step": 445848, "time": 14516.442972183228, "episode/length": 186.0, "episode/score": 0.44093688788643703, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.02218691188545563}
{"step": 446088, "time": 14523.917867183685, "episode/length": 82.0, "episode/score": 0.7639998832364086, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.020249922183154467}
{"step": 446168, "time": 14526.414466381073, "episode/length": 108.0, "episode/score": 0.6899605077971387, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.027460498114294296}
{"step": 446208, "time": 14527.91128396988, "episode/length": 44.0, "episode/score": 0.8705308326634054, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.008030830812401746}
{"step": 446264, "time": 14529.451492071152, "episode/length": 288.0, "episode/score": 0.04527218162036206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04527218162036206}
{"step": 446288, "time": 14530.429298639297, "episode/length": 126.0, "episode/score": 0.6532584693782724, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.04700850752175256}
{"step": 446424, "time": 14534.584520101547, "episode/length": 127.0, "episode/score": 0.6197436069450077, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.01661864792902179}
{"step": 446424, "time": 14534.591326713562, "episode/length": 116.0, "episode/score": 0.6597555894171023, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.022255597248943104}
{"step": 446568, "time": 14539.08030128479, "episode/length": 109.0, "episode/score": 0.6874499654486499, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.028074949438632757}
{"step": 446744, "time": 14544.627796888351, "episode/length": 66.0, "episode/score": 0.8097298184830493, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.015979856626529454}
{"step": 446856, "time": 14548.186084270477, "episode/length": 73.0, "episode/score": 0.7917027145947486, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.019827662638590482}
{"step": 447024, "time": 14553.662824392319, "episode/length": 74.0, "episode/score": 0.7883084990988891, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.01955848739623889}
{"step": 447112, "time": 14556.181354045868, "episode/length": 85.0, "episode/score": 0.7420535633398799, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.007678575417969569}
{"step": 447152, "time": 14557.67175412178, "episode/length": 122.0, "episode/score": 0.6555228938373716, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.03677292975731916}
{"step": 447208, "time": 14559.19831109047, "episode/length": 57.0, "episode/score": 0.8315747791373269, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.009699817138198341}
{"step": 447504, "time": 14568.762320280075, "episode/length": 151.0, "episode/score": 0.5596906894559766, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.03156572759945675}
{"step": 447720, "time": 14575.250603437424, "episode/length": 143.0, "episode/score": 0.5702842483066206, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.01715924160691884}
{"step": 447856, "time": 14579.707296609879, "episode/length": 103.0, "episode/score": 0.6999701842242416, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.021845183490825093}
{"step": 447912, "time": 14581.234213590622, "episode/length": 131.0, "episode/score": 0.6242222810801081, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.033597307160050605}
{"step": 448056, "time": 14585.716287851334, "episode/length": 105.0, "episode/score": 0.6991135271579196, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.027238544300075773}
{"step": 448080, "time": 14586.684702157974, "episode/length": 71.0, "episode/score": 0.7878141167590229, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.00968910643007348}
{"step": 448328, "time": 14594.371362447739, "episode/length": 146.0, "episode/score": 0.5700134707505526, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.026263454557181376}
{"step": 448400, "time": 14596.83846449852, "episode/length": 288.0, "episode/score": 0.03252804040880619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03252804040880619}
{"step": 448472, "time": 14598.884760141373, "episode/length": 93.0, "episode/score": 0.7240639765229275, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.01468896174691281}
{"step": 448664, "time": 14604.871600151062, "episode/length": 93.0, "episode/score": 0.732578173972172, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.023203176352865285}
{"step": 449208, "time": 14622.147125959396, "episode/length": 109.0, "episode/score": 0.6966549941547555, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03727995359565739}
{"step": 449248, "time": 14623.63824391365, "episode/length": 145.0, "episode/score": 0.5984044210719333, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.05152939243376409}
{"step": 449288, "time": 14624.670582056046, "episode/length": 178.0, "episode/score": 0.5026625718203377, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.05891257859570942}
{"step": 449344, "time": 14626.643274068832, "episode/length": 108.0, "episode/score": 0.7066575129679791, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.04415747480703658}
{"step": 449424, "time": 14629.162473917007, "episode/length": 288.0, "episode/score": 0.06674294317014073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06674294317014073}
{"step": 449792, "time": 14640.624726772308, "episode/length": 67.0, "episode/score": 0.8268565465032225, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.03623154700380837}
{"step": 449904, "time": 14644.145381450653, "episode/length": 59.0, "episode/score": 0.8452448613334127, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.029619820774314576}
{"step": 449960, "time": 14645.679228067398, "episode/length": 76.0, "episode/score": 0.7972607079582303, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.03476069124099013}
{"step": 450008, "time": 14647.544466733932, "eval_episode/length": 20.0, "eval_episode/score": 0.9375, "eval_episode/reward_rate": 0.047619047619047616}
{"step": 450008, "time": 14647.805922031403, "eval_episode/length": 35.0, "eval_episode/score": 0.890625, "eval_episode/reward_rate": 0.027777777777777776}
{"step": 450008, "time": 14647.911409139633, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 450008, "time": 14648.086470365524, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 450008, "time": 14648.410059928894, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 450008, "time": 14648.71663928032, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 450008, "time": 14648.7571849823, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 450008, "time": 14649.00446653366, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 450048, "time": 14650.484185934067, "episode/length": 94.0, "episode/score": 0.7442337934030547, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03798378229703303}
{"step": 450264, "time": 14657.097013235092, "episode/length": 199.0, "episode/score": 0.44409062904600205, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.06596560894689674}
{"step": 450320, "time": 14659.064854860306, "episode/length": 65.0, "episode/score": 0.8176452418942972, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.020770242709204467}
{"step": 450368, "time": 14660.573773860931, "episode/length": 288.0, "episode/score": 0.06177952115163521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06177952115163521}
{"step": 450424, "time": 14662.09216594696, "episode/length": 151.0, "episode/score": 0.5912030592853625, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.0630780640467492}
{"step": 450424, "time": 14662.098942756653, "episode/length": 57.0, "episode/score": 0.845587051549046, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.023712095530754596}
{"step": 450536, "time": 14665.588675022125, "episode/length": 78.0, "episode/score": 0.7928065865708049, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.03655656354385428}
{"step": 450576, "time": 14667.528896808624, "episode/length": 65.0, "episode/score": 0.8274235426006271, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.03054852828154253}
{"step": 450712, "time": 14671.582208871841, "episode/length": 288.0, "episode/score": 0.07040661286501404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07040661286501404}
{"step": 450960, "time": 14679.50782251358, "episode/length": 52.0, "episode/score": 0.8572818788882159, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.019781879388801826}
{"step": 451168, "time": 14686.100312948227, "episode/length": 92.0, "episode/score": 0.748406969478765, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03590696997935083}
{"step": 451392, "time": 14693.062846422195, "episode/length": 120.0, "episode/score": 0.6691135673606823, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.04411353796581352}
{"step": 451512, "time": 14696.571732759476, "episode/length": 155.0, "episode/score": 0.5689705767863416, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.05334556246725697}
{"step": 451560, "time": 14698.060717821121, "episode/length": 74.0, "episode/score": 0.787016800625679, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.018266806836436444}
{"step": 451704, "time": 14702.555244922638, "episode/length": 66.0, "episode/score": 0.816922814225336, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.023172802804992898}
{"step": 451800, "time": 14705.585565328598, "episode/length": 152.0, "episode/score": 0.5691474252212174, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.044147464167963335}
{"step": 452216, "time": 14718.660017490387, "episode/length": 102.0, "episode/score": 0.7090979596590614, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.027847976341377034}
{"step": 452464, "time": 14726.628044366837, "episode/length": 112.0, "episode/score": 0.6897076066535419, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.039707601100531065}
{"step": 452632, "time": 14731.636906862259, "episode/length": 288.0, "episode/score": 0.048816805555134124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048816805555134124}
{"step": 452680, "time": 14733.137019634247, "episode/length": 288.0, "episode/score": 0.047613636626238076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047613636626238076}
{"step": 452824, "time": 14737.672533988953, "episode/length": 263.0, "episode/score": 0.24420600089706568, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.06608101331858052}
{"step": 452888, "time": 14739.679318666458, "episode/length": 52.0, "episode/score": 0.8491140681427396, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.011614110116283882}
{"step": 452960, "time": 14742.297280550003, "episode/length": 92.0, "episode/score": 0.7354368088385854, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.022936847785331338}
{"step": 453064, "time": 14745.307606458664, "episode/length": 29.0, "episode/score": 0.9194521954885886, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.010077175389483273}
{"step": 453496, "time": 14758.809977293015, "episode/length": 75.0, "episode/score": 0.7805540977643659, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.01492911589605228}
{"step": 453640, "time": 14763.372912883759, "episode/length": 125.0, "episode/score": 0.6403019653373576, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.030926988445798997}
{"step": 453672, "time": 14764.380257368088, "episode/length": 75.0, "episode/score": 0.7813822002573261, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.015757212335415716}
{"step": 453824, "time": 14769.32992386818, "episode/length": 288.0, "episode/score": 0.028483275794656038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028483275794656038}
{"step": 454016, "time": 14775.395414829254, "episode/length": 288.0, "episode/score": 0.06390625079370693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06390625079370693}
{"step": 454112, "time": 14778.419814825058, "episode/length": 288.0, "episode/score": 0.047135647820937265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047135647820937265}
{"step": 454272, "time": 14783.43513250351, "episode/length": 74.0, "episode/score": 0.788419808684921, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.019669792674903874}
{"step": 454544, "time": 14791.942574262619, "episode/length": 53.0, "episode/score": 0.8413498155709931, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.006974817951686418}
{"step": 454584, "time": 14792.97268652916, "episode/length": 94.0, "episode/score": 0.7365136738479805, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.030263653748875186}
{"step": 454960, "time": 14805.039865016937, "episode/length": 117.0, "episode/score": 0.6602549148327057, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.025879931515021326}
{"step": 454992, "time": 14806.057085037231, "episode/length": 288.0, "episode/score": 0.04535146792005662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04535146792005662}
{"step": 455272, "time": 14814.54601097107, "episode/length": 288.0, "episode/score": 0.029752826934100085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029752826934100085}
{"step": 455784, "time": 14830.508135080338, "episode/length": 63.0, "episode/score": 0.8165786272115838, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.013453596210183605}
{"step": 455808, "time": 14831.529182434082, "episode/length": 288.0, "episode/score": 0.02985871620285252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02985871620285252}
{"step": 455952, "time": 14836.097197294235, "episode/length": 288.0, "episode/score": 0.04322526275103655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04322526275103655}
{"step": 456352, "time": 14848.698874473572, "episode/length": 70.0, "episode/score": 0.7910926207846956, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.00984263891638193}
{"step": 456488, "time": 14852.71751666069, "episode/length": 84.0, "episode/score": 0.7641033629192293, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.026603365157313874}
{"step": 456584, "time": 14855.707177639008, "episode/length": 288.0, "episode/score": 0.017557715586065115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017557715586065115}
{"step": 456688, "time": 14859.166642427444, "episode/length": 24.0, "episode/score": 0.9349034836828309, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.009903497984453224}
{"step": 456704, "time": 14859.66994524002, "episode/length": 43.0, "episode/score": 0.8768890332784167, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.011264032545000191}
{"step": 456856, "time": 14864.352360725403, "episode/length": 288.0, "episode/score": 0.02559541248712094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02559541248712094}
{"step": 456896, "time": 14865.821243047714, "episode/length": 288.0, "episode/score": 0.03377177705141321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03377177705141321}
{"step": 457272, "time": 14877.346561431885, "episode/length": 288.0, "episode/score": 0.02019810644719655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02019810644719655}
{"step": 457296, "time": 14878.314352750778, "episode/length": 73.0, "episode/score": 0.7972824613551666, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.025407423194224066}
{"step": 457304, "time": 14878.350913524628, "episode/length": 288.0, "episode/score": 0.0467565897263853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0467565897263853}
{"step": 457392, "time": 14881.314542770386, "episode/length": 87.0, "episode/score": 0.746318764639625, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.01819378929639015}
{"step": 458064, "time": 14902.286636829376, "episode/length": 98.0, "episode/score": 0.7185951901610679, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.02484514297793794}
{"step": 458248, "time": 14907.787947654724, "episode/length": 117.0, "episode/score": 0.6725965807477223, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.03822157595141107}
{"step": 458264, "time": 14908.290222167969, "episode/length": 288.0, "episode/score": 0.026375293521084586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026375293521084586}
{"step": 458656, "time": 14920.722572803497, "episode/length": 50.0, "episode/score": 0.8590859495504901, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.015335935231405529}
{"step": 458888, "time": 14928.329276800156, "episode/length": 77.0, "episode/score": 0.7847628692379658, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.025387863684954937}
{"step": 458896, "time": 14928.803025007248, "episode/length": 288.0, "episode/score": 0.04557783752301248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04557783752301248}
{"step": 459168, "time": 14937.270554065704, "episode/length": 288.0, "episode/score": 0.04089658880729985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04089658880729985}
{"step": 459208, "time": 14938.296025037766, "episode/length": 288.0, "episode/score": 0.04201945192983203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04201945192983203}
{"step": 459336, "time": 14942.293594360352, "episode/length": 55.0, "episode/score": 0.8418462188971034, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.013721210718927068}
{"step": 459400, "time": 14944.290306806564, "episode/length": 62.0, "episode/score": 0.8207666066593902, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.014516623341705781}
{"step": 459584, "time": 14950.244884252548, "episode/length": 115.0, "episode/score": 0.6665648719224464, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.025939864762904108}
{"step": 459608, "time": 14950.776069879532, "episode/length": 288.0, "episode/score": 0.03653674234533355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03653674234533355}
{"step": 459704, "time": 14953.875764608383, "episode/length": 288.0, "episode/score": 0.018068482444164147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018068482444164147}
{"step": 460096, "time": 14966.526689529419, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 460096, "time": 14966.96740102768, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 460096, "time": 14967.10985159874, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 460096, "time": 14967.149487495422, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 460096, "time": 14967.32285785675, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 460096, "time": 14967.512732744217, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 460096, "time": 14967.965796232224, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 460096, "time": 14968.188644647598, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 460376, "time": 14976.696245670319, "episode/length": 288.0, "episode/score": 0.02377180692201364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02377180692201364}
{"step": 460488, "time": 14980.164709568024, "episode/length": 135.0, "episode/score": 0.6152574790484096, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.03713247188886726}
{"step": 460792, "time": 14989.840599536896, "episode/length": 135.0, "episode/score": 0.6107488313163003, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.032623832131207564}
{"step": 461008, "time": 14996.868574619293, "episode/length": 26.0, "episode/score": 0.9348296741376316, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.016079677880384224}
{"step": 461480, "time": 15011.53644156456, "episode/length": 288.0, "episode/score": 0.017246003742457106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017246003742457106}
{"step": 461520, "time": 15013.054456233978, "episode/length": 288.0, "episode/score": 0.029795994521577995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029795994521577995}
{"step": 461648, "time": 15017.053628206253, "episode/length": 288.0, "episode/score": 0.036104617075807255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036104617075807255}
{"step": 461688, "time": 15018.08130121231, "episode/length": 84.0, "episode/score": 0.7612289318998364, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.023728905659822885}
{"step": 461896, "time": 15024.53162431717, "episode/length": 288.0, "episode/score": 0.025580912509440168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025580912509440168}
{"step": 461920, "time": 15025.502795219421, "episode/length": 288.0, "episode/score": 0.039617264779565176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039617264779565176}
{"step": 461928, "time": 15025.538653612137, "episode/length": 34.0, "episode/score": 0.9129734981680713, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.019223462905870292}
{"step": 462056, "time": 15029.543615102768, "episode/length": 71.0, "episode/score": 0.8080987299698563, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.029973712495916516}
{"step": 462152, "time": 15032.529689788818, "episode/length": 57.0, "episode/score": 0.8408965661839147, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.01902158184759628}
{"step": 462688, "time": 15049.563555955887, "episode/length": 288.0, "episode/score": 0.04804619748682626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04804619748682626}
{"step": 462696, "time": 15049.600001096725, "episode/length": 96.0, "episode/score": 0.7457423901199718, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.04574237264603198}
{"step": 462800, "time": 15053.050996780396, "episode/length": 288.0, "episode/score": 0.046981734553980914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046981734553980914}
{"step": 462840, "time": 15054.091010093689, "episode/length": 117.0, "episode/score": 0.6643809461826891, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.03000596184637061}
{"step": 463136, "time": 15063.488733053207, "episode/length": 54.0, "episode/score": 0.8554887297487994, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.024238710668328167}
{"step": 463248, "time": 15066.975618124008, "episode/length": 69.0, "episode/score": 0.8093184601419807, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.024943468360902443}
{"step": 463496, "time": 15074.570317268372, "episode/length": 86.0, "episode/score": 0.751461957675815, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.02021196243720169}
{"step": 463600, "time": 15077.994673252106, "episode/length": 192.0, "episode/score": 0.43209335941759264, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.03209334379465645}
{"step": 463672, "time": 15080.024047851562, "episode/length": 103.0, "episode/score": 0.7016918336280469, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0235667811480198}
{"step": 463688, "time": 15080.530016422272, "episode/length": 191.0, "episode/score": 0.43131936142214045, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.02819437356134813}
{"step": 463696, "time": 15081.004775047302, "episode/length": 271.0, "episode/score": 0.20576820702649457, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.05264320424998914}
{"step": 463728, "time": 15082.001091480255, "episode/length": 224.0, "episode/score": 0.3265048314041792, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.02650481539416205}
{"step": 463912, "time": 15087.516556739807, "episode/length": 82.0, "episode/score": 0.7763839956587617, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03263402031552687}
{"step": 464232, "time": 15097.4830493927, "episode/length": 62.0, "episode/score": 0.8313399531339201, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.025089948337608803}
{"step": 464264, "time": 15098.491421937943, "episode/length": 82.0, "episode/score": 0.7797872025279844, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.03603719773167313}
{"step": 464336, "time": 15100.9647731781, "episode/length": 104.0, "episode/score": 0.7109660256402321, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.035966014534210444}
{"step": 464344, "time": 15101.001596212387, "episode/length": 81.0, "episode/score": 0.7736712914182817, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.02679627470104151}
{"step": 464512, "time": 15106.528625249863, "episode/length": 101.0, "episode/score": 0.7224620173531093, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03808703008894554}
{"step": 464560, "time": 15108.01929116249, "episode/length": 80.0, "episode/score": 0.7742053005379717, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.024205286218887068}
{"step": 464648, "time": 15110.547582149506, "episode/length": 121.0, "episode/score": 0.6743237830009434, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.05244878060278779}
{"step": 464720, "time": 15112.998949289322, "episode/length": 56.0, "episode/score": 0.8558254286563169, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.03082541193907673}
{"step": 464944, "time": 15119.973183393478, "episode/length": 75.0, "episode/score": 0.7932804726879112, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.027655458368826658}
{"step": 464976, "time": 15120.97686457634, "episode/length": 40.0, "episode/score": 0.8921824782364638, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.017182454895191768}
{"step": 465088, "time": 15124.48089146614, "episode/length": 92.0, "episode/score": 0.7456681698599823, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03316817036056818}
{"step": 465344, "time": 15132.531524896622, "episode/length": 103.0, "episode/score": 0.7117676270811444, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.033642579898014446}
{"step": 465376, "time": 15133.5260784626, "episode/length": 101.0, "episode/score": 0.7148310069455874, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03045601068834003}
{"step": 465448, "time": 15135.558571100235, "episode/length": 288.0, "episode/score": 0.06912293938353287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06912293938353287}
{"step": 465448, "time": 15135.565021514893, "episode/length": 62.0, "episode/score": 0.8228404776050411, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.01659049326872264}
{"step": 465840, "time": 15147.988830804825, "episode/length": 57.0, "episode/score": 0.8477558967456389, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.02588089119262804}
{"step": 465984, "time": 15152.466933488846, "episode/length": 157.0, "episode/score": 0.5685860838716508, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.05921107831863992}
{"step": 466120, "time": 15156.497064590454, "episode/length": 142.0, "episode/score": 0.6038390513438117, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.04758906700749321}
{"step": 466280, "time": 15161.55922293663, "episode/length": 116.0, "episode/score": 0.6820848229001513, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.044584835635987474}
{"step": 466288, "time": 15162.079621553421, "episode/length": 104.0, "episode/score": 0.7155452471031367, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.04054522086312318}
{"step": 466296, "time": 15162.115598201752, "episode/length": 150.0, "episode/score": 0.5623555874410613, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.031105607580911965}
{"step": 466536, "time": 15169.593978881836, "episode/length": 29.0, "episode/score": 0.9185856745850742, "episode/reward_rate": 0.03333333333333333, "episode/intrinsic_return": 0.009210682803995951}
{"step": 466544, "time": 15170.074683904648, "episode/length": 288.0, "episode/score": 0.04673809174869348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04673809174869348}
{"step": 466648, "time": 15173.107398986816, "episode/length": 100.0, "episode/score": 0.7197894563870477, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.0322894765268984}
{"step": 466984, "time": 15184.058283805847, "episode/length": 55.0, "episode/score": 0.8513798617855173, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.02325483844424525}
{"step": 467152, "time": 15189.535162687302, "episode/length": 75.0, "episode/score": 0.7857023637981229, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.020077355619946502}
{"step": 467592, "time": 15203.042372226715, "episode/length": 117.0, "episode/score": 0.6767745460778087, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.042399562760124354}
{"step": 467760, "time": 15208.478353023529, "episode/length": 288.0, "episode/score": 0.03962529396744685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03962529396744685}
{"step": 468008, "time": 15216.048045158386, "episode/length": 127.0, "episode/score": 0.6384517981176714, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.035326842099379974}
{"step": 468296, "time": 15225.151319980621, "episode/length": 288.0, "episode/score": 0.04046088391135072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04046088391135072}
{"step": 468424, "time": 15229.13273692131, "episode/length": 103.0, "episode/score": 0.7125862015276425, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.034461177904063334}
{"step": 468432, "time": 15229.630116224289, "episode/length": 288.0, "episode/score": 0.04113713738399838, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04113713738399838}
{"step": 468592, "time": 15234.64363694191, "episode/length": 288.0, "episode/score": 0.049270746522552145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049270746522552145}
{"step": 468600, "time": 15234.680184602737, "episode/length": 288.0, "episode/score": 0.04107138975973612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04107138975973612}
{"step": 468624, "time": 15235.648692131042, "episode/length": 24.0, "episode/score": 0.9400829257239138, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.015082933942835552}
{"step": 468800, "time": 15241.12013912201, "episode/length": 24.0, "episode/score": 0.9381229178975445, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.013122898817073292}
{"step": 468953, "time": 15246.825665712357, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.189473263503331, "train/action_min": 0.0, "train/action_std": 1.6914901503451585, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009591857559960051, "train/actor_opt_grad_steps": 28230.0, "train/actor_opt_loss": -5.9218345998507465, "train/adv_mag": 0.8350421825641303, "train/adv_max": 0.2391243011213196, "train/adv_mean": 0.0017261965537091566, "train/adv_min": -0.8073653049275354, "train/adv_std": 0.03520137541525557, "train/cont_avg": 0.9956327331852792, "train/cont_loss_mean": 0.015885641083338765, "train/cont_loss_std": 0.2316888823802701, "train/cont_neg_acc": 0.32085961621576153, "train/cont_neg_loss": 2.901930216955125, "train/cont_pos_acc": 0.9997857567017454, "train/cont_pos_loss": 0.00327829133747571, "train/cont_pred": 0.9955677057280758, "train/cont_rate": 0.9956327331852792, "train/dyn_loss_mean": 1.0000107203643334, "train/dyn_loss_std": 0.0003428749278008106, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6870567265538697, "train/extr_critic_critic_opt_grad_steps": 28230.0, "train/extr_critic_critic_opt_loss": 13538.054642885469, "train/extr_critic_mag": 1.0665149059392474, "train/extr_critic_max": 1.0665149059392474, "train/extr_critic_mean": 1.0328567115788532, "train/extr_critic_min": 0.9910452759205387, "train/extr_critic_std": 0.010032831232635504, "train/extr_return_normed_mag": 0.8207997129048188, "train/extr_return_normed_max": 0.2798035692442492, "train/extr_return_normed_mean": 0.028946356460880732, "train/extr_return_normed_min": -0.7806314535552475, "train/extr_return_normed_std": 0.03736276962903096, "train/extr_return_rate": 0.9979976763580051, "train/extr_return_raw_mag": 1.2854400836876807, "train/extr_return_raw_max": 1.2854400836876807, "train/extr_return_raw_mean": 1.0345829241166866, "train/extr_return_raw_min": 0.2250050608881839, "train/extr_return_raw_std": 0.03736276976140169, "train/extr_reward_mag": 0.299019785701926, "train/extr_reward_max": 0.299019785701926, "train/extr_reward_mean": 0.0029041191668197665, "train/extr_reward_min": 5.3396079745994605e-06, "train/extr_reward_std": 0.01129895711889689, "train/image_loss_mean": 0.11217211062079153, "train/image_loss_std": 0.10480386359134906, "train/model_loss_mean": 0.7450466588669017, "train/model_loss_std": 0.3790736303187264, "train/model_opt_grad_norm": 26.757956766235043, "train/model_opt_grad_steps": 28204.39086294416, "train/model_opt_loss": 3725.2333030119767, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.324649223216294, "train/policy_entropy_max": 1.324649223216294, "train/policy_entropy_mean": 0.11384409900546678, "train/policy_entropy_min": 0.0646866561495108, "train/policy_entropy_std": 0.14704991880861032, "train/policy_logprob_mag": 6.551080202693261, "train/policy_logprob_max": -0.008608184750120955, "train/policy_logprob_mean": -0.11413944081455318, "train/policy_logprob_min": -6.551080202693261, "train/policy_logprob_std": 0.6535987394110201, "train/policy_randomness_mag": 0.6807350800727224, "train/policy_randomness_max": 0.6807350800727224, "train/policy_randomness_mean": 0.05850429713801684, "train/policy_randomness_min": 0.03324236728364441, "train/policy_randomness_std": 0.07556871379616902, "train/post_ent_mag": 13.868400017017036, "train/post_ent_max": 13.868400017017036, "train/post_ent_mean": 13.394570370010918, "train/post_ent_min": 13.04848189281328, "train/post_ent_std": 0.15338641416451654, "train/prior_ent_mag": 15.478519396128387, "train/prior_ent_max": 15.478519396128387, "train/prior_ent_mean": 11.127065290654372, "train/prior_ent_min": 9.629062241104048, "train/prior_ent_std": 0.736169941231684, "train/rep_loss_mean": 1.0000107203643334, "train/rep_loss_std": 0.0003428749278008106, "train/reward_avg": 0.001108105325061464, "train/reward_loss_mean": 0.016982451873136503, "train/reward_loss_std": 0.15550551733219534, "train/reward_max_data": 0.5602440340846285, "train/reward_max_pred": 0.12122105341877429, "train/reward_neg_acc": 0.9997269925732298, "train/reward_neg_loss": 0.010519785636345747, "train/reward_pos_acc": 0.14926624822916476, "train/reward_pos_loss": 4.476052622375248, "train/reward_pred": 0.0009014697409788061, "train/reward_rate": 0.001447493654822335, "train_stats/mean_log_entropy": 0.09680165067105226, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.012321341782808304, "report/cont_loss_std": 0.21188198029994965, "report/cont_neg_acc": 0.3333333432674408, "report/cont_neg_loss": 3.186115026473999, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029957969672977924, "report/cont_pred": 0.9963673949241638, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10453370213508606, "report/image_loss_std": 0.10255853086709976, "report/model_loss_mean": 0.7321531772613525, "report/model_loss_std": 0.32888588309288025, "report/post_ent_mag": 13.528467178344727, "report/post_ent_max": 13.528467178344727, "report/post_ent_mean": 13.025768280029297, "report/post_ent_min": 12.719629287719727, "report/post_ent_std": 0.15602318942546844, "report/prior_ent_mag": 17.024829864501953, "report/prior_ent_max": 17.024829864501953, "report/prior_ent_mean": 10.576780319213867, "report/prior_ent_min": 9.193575859069824, "report/prior_ent_std": 0.6901555061340332, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0009055534610524774, "report/reward_loss_mean": 0.015298089943826199, "report/reward_loss_std": 0.1307760626077652, "report/reward_max_data": 0.7127082943916321, "report/reward_max_pred": 0.16108274459838867, "report/reward_neg_acc": 0.9990224838256836, "report/reward_neg_loss": 0.011263065971434116, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.143126964569092, "report/reward_pred": 0.0011878557270392776, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.03265991806983948, "eval/cont_loss_std": 0.5200828909873962, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 8.162954330444336, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0007764078327454627, "eval/cont_pred": 0.999229907989502, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22754746675491333, "eval/image_loss_std": 0.1334538608789444, "eval/model_loss_mean": 0.8620726466178894, "eval/model_loss_std": 0.5435336232185364, "eval/post_ent_mag": 13.520779609680176, "eval/post_ent_max": 13.520779609680176, "eval/post_ent_mean": 12.984869003295898, "eval/post_ent_min": 12.609106063842773, "eval/post_ent_std": 0.16602468490600586, "eval/prior_ent_mag": 13.028658866882324, "eval/prior_ent_max": 13.028658866882324, "eval/prior_ent_mean": 10.474502563476562, "eval/prior_ent_min": 9.136197090148926, "eval/prior_ent_std": 0.5786757469177246, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0018652291037142277, "eval/reward_loss_std": 0.0023566866293549538, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.014101028442382812, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0018652291037142277, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0003671938320621848, "eval/reward_rate": 0.0, "replay/size": 468449.0, "replay/inserts": 31528.0, "replay/samples": 31536.0, "replay/insert_wait_avg": 1.171614669416496e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.356531664782039e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 2928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0657994473566773e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.071549654007, "timer/env.step_count": 3941.0, "timer/env.step_total": 35.80382418632507, "timer/env.step_frac": 0.035801262618371715, "timer/env.step_avg": 0.009084959194703139, "timer/env.step_min": 0.007401704788208008, "timer/env.step_max": 0.038893938064575195, "timer/replay._sample_count": 31536.0, "timer/replay._sample_total": 15.758764505386353, "timer/replay._sample_frac": 0.01575763705190732, "timer/replay._sample_avg": 0.0004997071443869341, "timer/replay._sample_min": 0.0003719329833984375, "timer/replay._sample_max": 0.03375983238220215, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4307.0, "timer/agent.policy_total": 43.346901178359985, "timer/agent.policy_frac": 0.043343799944470615, "timer/agent.policy_avg": 0.010064290963166933, "timer/agent.policy_min": 0.008130311965942383, "timer/agent.policy_max": 1.2724018096923828, "timer/dataset_train_count": 1971.0, "timer/dataset_train_total": 0.1990354061126709, "timer/dataset_train_frac": 0.00019902116621708802, "timer/dataset_train_avg": 0.00010098194120379042, "timer/dataset_train_min": 8.630752563476562e-05, "timer/dataset_train_max": 0.00018525123596191406, "timer/agent.train_count": 1971.0, "timer/agent.train_total": 875.9275689125061, "timer/agent.train_frac": 0.8758649010818769, "timer/agent.train_avg": 0.444407696048963, "timer/agent.train_min": 0.43272876739501953, "timer/agent.train_max": 0.5896568298339844, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47466492652893066, "timer/agent.report_frac": 0.00047463096684747174, "timer/agent.report_avg": 0.23733246326446533, "timer/agent.report_min": 0.23263978958129883, "timer/agent.report_max": 0.24202513694763184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.7670135498046875e-05, "timer/dataset_eval_frac": 3.7667440405718515e-08, "timer/dataset_eval_avg": 3.7670135498046875e-05, "timer/dataset_eval_min": 3.7670135498046875e-05, "timer/dataset_eval_max": 3.7670135498046875e-05, "fps": 31.525216631860197}
{"step": 469440, "time": 15262.03530883789, "episode/length": 125.0, "episode/score": 0.6375077327209056, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.02813273293918428}
{"step": 469464, "time": 15262.566396474838, "episode/length": 288.0, "episode/score": 0.048853141187976235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048853141187976235}
{"step": 469472, "time": 15263.041499614716, "episode/length": 146.0, "episode/score": 0.5628938665848864, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.019143878724094066}
{"step": 469944, "time": 15277.577828407288, "episode/length": 58.0, "episode/score": 0.8289786372563981, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.010228609325451998}
{"step": 469984, "time": 15279.057604074478, "episode/length": 67.0, "episode/score": 0.8127474602714528, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.022122502244997122}
{"step": 470072, "time": 15281.683188676834, "episode/length": 288.0, "episode/score": 0.05443853727405212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05443853727405212}
{"step": 470080, "time": 15282.478928089142, "eval_episode/length": 17.0, "eval_episode/score": 0.9468749761581421, "eval_episode/reward_rate": 0.05555555555555555}
{"step": 470080, "time": 15283.005670309067, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 470080, "time": 15283.473865509033, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 470080, "time": 15283.866234779358, "eval_episode/length": 96.0, "eval_episode/score": 0.699999988079071, "eval_episode/reward_rate": 0.010309278350515464}
{"step": 470080, "time": 15284.230684041977, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 470080, "time": 15285.126411914825, "eval_episode/length": 71.0, "eval_episode/score": 0.778124988079071, "eval_episode/reward_rate": 0.013888888888888888}
{"step": 470080, "time": 15285.241401672363, "eval_episode/length": 126.0, "eval_episode/score": 0.606249988079071, "eval_episode/reward_rate": 0.007874015748031496}
{"step": 470080, "time": 15287.258409500122, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15287.266949653625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15287.27394914627, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470248, "time": 15292.388727664948, "episode/length": 97.0, "episode/score": 0.720485874551855, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.023610898611991615}
{"step": 470320, "time": 15294.889622449875, "episode/length": 288.0, "episode/score": 0.025437988403552936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025437988403552936}
{"step": 470640, "time": 15304.914393424988, "episode/length": 86.0, "episode/score": 0.757521971055553, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0262720031163326}
{"step": 470848, "time": 15311.47445845604, "episode/length": 74.0, "episode/score": 0.7915732300475611, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.022823236258318502}
{"step": 470904, "time": 15313.092556715012, "episode/length": 288.0, "episode/score": 0.031075916913835044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031075916913835044}
{"step": 470936, "time": 15314.091622829437, "episode/length": 288.0, "episode/score": 0.011029581790012344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011029581790012344}
{"step": 471112, "time": 15319.579489946365, "episode/length": 288.0, "episode/score": 0.03516322172583841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03516322172583841}
{"step": 471152, "time": 15321.079191207886, "episode/length": 103.0, "episode/score": 0.706746738098218, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.02862172936124807}
{"step": 471336, "time": 15326.623247146606, "episode/length": 49.0, "episode/score": 0.8637420555146491, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.016867066702161537}
{"step": 471552, "time": 15333.639323234558, "episode/length": 80.0, "episode/score": 0.7687915853246636, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.01879158123557545}
{"step": 471584, "time": 15334.657567977905, "episode/length": 188.0, "episode/score": 0.4502437591077637, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.037743760979140006}
{"step": 471768, "time": 15340.252648830414, "episode/length": 81.0, "episode/score": 0.7600514994813921, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.013176523480410651}
{"step": 471840, "time": 15342.8618350029, "episode/length": 62.0, "episode/score": 0.8187885472567586, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.012538567009528379}
{"step": 471952, "time": 15346.327590942383, "episode/length": 99.0, "episode/score": 0.719390814660585, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.02876582896220725}
{"step": 472056, "time": 15349.330804347992, "episode/length": 62.0, "episode/score": 0.8180248552743024, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.011774889186085602}
{"step": 472296, "time": 15356.792031526566, "episode/length": 288.0, "episode/score": 0.02267916319044616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02267916319044616}
{"step": 472368, "time": 15359.238217115402, "episode/length": 74.0, "episode/score": 0.789046080807168, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.020296040771938806}
{"step": 472376, "time": 15359.272322416306, "episode/length": 66.0, "episode/score": 0.8080225219705994, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.014272554031379059}
{"step": 472768, "time": 15371.772288322449, "episode/length": 49.0, "episode/score": 0.8607353545701244, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.013860338560107266}
{"step": 472880, "time": 15375.24746799469, "episode/length": 72.0, "episode/score": 0.7888872253550403, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.013887275419449452}
{"step": 472952, "time": 15377.286638259888, "episode/length": 288.0, "episode/score": 0.044380521241180304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044380521241180304}
{"step": 473056, "time": 15380.749783039093, "episode/length": 183.0, "episode/score": 0.4751847021859703, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.04705970405734661}
{"step": 473136, "time": 15383.263094902039, "episode/length": 134.0, "episode/score": 0.6101926857295439, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.02894269691705631}
{"step": 473160, "time": 15383.802350521088, "episode/length": 288.0, "episode/score": 0.01911741715179005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01911741715179005}
{"step": 473696, "time": 15400.654890537262, "episode/length": 92.0, "episode/score": 0.7442929994033989, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.03179303532334643}
{"step": 473808, "time": 15404.31418299675, "episode/length": 115.0, "episode/score": 0.6616133461298546, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.020988372352405804}
{"step": 474016, "time": 15410.851034164429, "episode/length": 106.0, "episode/score": 0.6797892956826672, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.011039316669439359}
{"step": 474096, "time": 15413.366068601608, "episode/length": 119.0, "episode/score": 0.6590407015185633, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.030915699667559693}
{"step": 474104, "time": 15413.401734113693, "episode/length": 36.0, "episode/score": 0.900415227046949, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.012915249037803278}
{"step": 474256, "time": 15418.382731199265, "episode/length": 69.0, "episode/score": 0.7902754266506236, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.00590042379553779}
{"step": 474264, "time": 15418.421100378036, "episode/length": 288.0, "episode/score": 0.050133450405581925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050133450405581925}
{"step": 474504, "time": 15425.860661029816, "episode/length": 216.0, "episode/score": 0.36565278375064736, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.04065280574150165}
{"step": 474544, "time": 15427.339552879333, "episode/length": 34.0, "episode/score": 0.9015057383799672, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.007755735524881402}
{"step": 474688, "time": 15431.896785974503, "episode/length": 288.0, "episode/score": 0.028335643578373038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028335643578373038}
{"step": 474736, "time": 15433.38712644577, "episode/length": 89.0, "episode/score": 0.7462271438459993, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.02435210223188733}
{"step": 474736, "time": 15433.393868207932, "episode/length": 59.0, "episode/score": 0.8267478081366733, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.011122822438295543}
{"step": 474760, "time": 15433.924070119858, "episode/length": 82.0, "episode/score": 0.750718439767013, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.006968480751027073}
{"step": 474928, "time": 15439.398380756378, "episode/length": 47.0, "episode/score": 0.8631307119922269, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.010005752976240956}
{"step": 475016, "time": 15441.93809056282, "episode/length": 34.0, "episode/score": 0.9057761443251877, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.012026158626810002}
{"step": 475168, "time": 15447.381269693375, "episode/length": 59.0, "episode/score": 0.8289737137536122, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.013348715991696736}
{"step": 475224, "time": 15448.903335094452, "episode/length": 89.0, "episode/score": 0.7342896608026024, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.01241466043589412}
{"step": 475368, "time": 15453.408788919449, "episode/length": 288.0, "episode/score": 0.041444574342278884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041444574342278884}
{"step": 475448, "time": 15455.9120054245, "episode/length": 85.0, "episode/score": 0.7576711991627008, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.023296176912822375}
{"step": 475728, "time": 15464.951382398605, "episode/length": 123.0, "episode/score": 0.6411628405899421, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.02553784332715736}
{"step": 476040, "time": 15474.417600393295, "episode/length": 101.0, "episode/score": 0.7073581290059678, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.022983155085910312}
{"step": 476088, "time": 15475.906827449799, "episode/length": 144.0, "episode/score": 0.5869026203501164, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.036902618499112805}
{"step": 476112, "time": 15476.893394470215, "episode/length": 47.0, "episode/score": 0.8646999256649224, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.011574961061000977}
{"step": 476216, "time": 15479.890887260437, "episode/length": 149.0, "episode/score": 0.5569986019953035, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.02262356782449615}
{"step": 476336, "time": 15483.817586898804, "episode/length": 145.0, "episode/score": 0.5544161357304631, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.007541147284683802}
{"step": 476408, "time": 15485.836592197418, "episode/length": 36.0, "episode/score": 0.8944974998555324, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.006997488558880605}
{"step": 476416, "time": 15486.314783096313, "episode/length": 288.0, "episode/score": 0.031236608020435597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031236608020435597}
{"step": 476848, "time": 15499.848049402237, "episode/length": 174.0, "episode/score": 0.5051208804308089, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.04887087757572317}
{"step": 476912, "time": 15501.854002475739, "episode/length": 62.0, "episode/score": 0.8215325972198855, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.015282638203899523}
{"step": 477032, "time": 15505.356061935425, "episode/length": 76.0, "episode/score": 0.7750779328908379, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.012577961953923023}
{"step": 477128, "time": 15508.372526407242, "episode/length": 34.0, "episode/score": 0.8999167518638274, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.00616674900874159}
{"step": 477680, "time": 15525.865764379501, "episode/length": 288.0, "episode/score": 0.023965620655388875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023965620655388875}
{"step": 477736, "time": 15527.407275676727, "episode/length": 87.0, "episode/score": 0.7473390709575938, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.019214111941607825}
{"step": 477816, "time": 15529.904982089996, "episode/length": 112.0, "episode/score": 0.6603034792666165, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.010303503188509922}
{"step": 477816, "time": 15529.912552595139, "episode/length": 16.0, "episode/score": 0.9564599032156309, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.00645989191897911}
{"step": 477880, "time": 15531.9164352417, "episode/length": 229.0, "episode/score": 0.3116989847711409, "episode/reward_rate": 0.004347826086956522, "episode/intrinsic_return": 0.02732397943495357}
{"step": 478400, "time": 15548.338761806488, "episode/length": 288.0, "episode/score": 0.01476201500244656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01476201500244656}
{"step": 478496, "time": 15551.323165655136, "episode/length": 84.0, "episode/score": 0.758922725976447, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.021422691805639715}
{"step": 478528, "time": 15552.4186565876, "episode/length": 288.0, "episode/score": 0.02152902050306693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02152902050306693}
{"step": 478648, "time": 15555.937611579895, "episode/length": 288.0, "episode/score": 0.032782624300836005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032782624300836005}
{"step": 478680, "time": 15556.961076021194, "episode/length": 99.0, "episode/score": 0.6983599405615735, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.007734926596100422}
{"step": 478864, "time": 15562.927852392197, "episode/length": 57.0, "episode/score": 0.8321879685716169, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.010312970163596447}
{"step": 479440, "time": 15580.850528001785, "episode/length": 288.0, "episode/score": 0.011534366760287185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011534366760287185}
{"step": 479456, "time": 15581.356489658356, "episode/length": 100.0, "episode/score": 0.7016070863432731, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.014107097897493759}
{"step": 479480, "time": 15581.997623205185, "episode/length": 122.0, "episode/score": 0.6291685575625934, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.010418581484486822}
{"step": 479560, "time": 15584.496338129044, "episode/length": 86.0, "episode/score": 0.7408731807671529, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.009623204242302563}
{"step": 480048, "time": 15599.94779753685, "episode/length": 288.0, "episode/score": 0.010176637125141497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010176637125141497}
{"step": 480064, "time": 15601.306753873825, "eval_episode/length": 45.0, "eval_episode/score": 0.859375, "eval_episode/reward_rate": 0.021739130434782608}
{"step": 480064, "time": 15601.574474334717, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 480064, "time": 15602.184935331345, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 480064, "time": 15602.429864406586, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 480064, "time": 15602.539244651794, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 480064, "time": 15602.649209737778, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 480064, "time": 15602.765176534653, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 480064, "time": 15602.979350328445, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 480128, "time": 15604.999093294144, "episode/length": 288.0, "episode/score": 0.01212972409092572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01212972409092572}
{"step": 480160, "time": 15606.005510807037, "episode/length": 74.0, "episode/score": 0.7823712139509666, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.013621185433578376}
{"step": 480192, "time": 15607.013454437256, "episode/length": 88.0, "episode/score": 0.7446232484966799, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.019623230693866844}
{"step": 480576, "time": 15619.118808984756, "episode/length": 65.0, "episode/score": 0.8095645386589752, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.012689521967928385}
{"step": 480640, "time": 15621.147544145584, "episode/length": 59.0, "episode/score": 0.8209816559476621, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.005356666232955831}
{"step": 480840, "time": 15627.18853354454, "episode/length": 288.0, "episode/score": 0.025590224400929173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025590224400929173}
{"step": 480856, "time": 15627.69630408287, "episode/length": 82.0, "episode/score": 0.7616912299464786, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.017941229690364935}
{"step": 480984, "time": 15631.71422123909, "episode/length": 106.0, "episode/score": 0.6867062563029833, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.017956295792515675}
{"step": 480992, "time": 15632.194322824478, "episode/length": 288.0, "episode/score": 0.021987935447924656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021987935447924656}
{"step": 481496, "time": 15647.777809143066, "episode/length": 114.0, "episode/score": 0.6599951205886612, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.016245086417853827}
{"step": 481632, "time": 15652.251556634903, "episode/length": 79.0, "episode/score": 0.7694828459072198, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.01635781992914076}
{"step": 481648, "time": 15652.758106708527, "episode/length": 98.0, "episode/score": 0.7061425218236366, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.01239250301674133}
{"step": 481752, "time": 15655.824880599976, "episode/length": 288.0, "episode/score": 0.019388356123414496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019388356123414496}
{"step": 481768, "time": 15656.334928035736, "episode/length": 288.0, "episode/score": 0.03648333339870646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03648333339870646}
{"step": 481952, "time": 15662.329050540924, "episode/length": 138.0, "episode/score": 0.5932536387670666, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.024503612880664605}
{"step": 482240, "time": 15671.346877098083, "episode/length": 75.0, "episode/score": 0.7754989662780929, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.009873992857166058}
{"step": 482256, "time": 15671.95134472847, "episode/length": 37.0, "episode/score": 0.8893771707258509, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.005002222136312184}
{"step": 482400, "time": 15676.450414180756, "episode/length": 93.0, "episode/score": 0.7185353921846911, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.009160390549055819}
{"step": 482600, "time": 15682.491752147675, "episode/length": 42.0, "episode/score": 0.8801517561661001, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.011401786047002815}
{"step": 482664, "time": 15684.492471933365, "episode/length": 113.0, "episode/score": 0.6658014126906835, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.018926366598947197}
{"step": 482816, "time": 15689.47490477562, "episode/length": 71.0, "episode/score": 0.7977879659472933, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.019662961177175475}
{"step": 482952, "time": 15693.52835392952, "episode/length": 288.0, "episode/score": 0.020434510684410157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020434510684410157}
{"step": 483296, "time": 15704.595530033112, "episode/length": 288.0, "episode/score": 0.01633568856806278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01633568856806278}
{"step": 483352, "time": 15706.640103578568, "episode/length": 85.0, "episode/score": 0.7521140879442925, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.017739071253245697}
{"step": 483408, "time": 15708.601842880249, "episode/length": 100.0, "episode/score": 0.707418966812611, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.01991896476806687}
{"step": 483488, "time": 15711.111604690552, "episode/length": 135.0, "episode/score": 0.5969913339583002, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.018866339997344994}
{"step": 483520, "time": 15712.110262155533, "episode/length": 87.0, "episode/score": 0.743378428166551, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.015253449963864796}
{"step": 483808, "time": 15721.140891313553, "episode/length": 288.0, "episode/score": 0.009749096909544619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.009749096909544619}
{"step": 484080, "time": 15729.685310840607, "episode/length": 288.0, "episode/score": 0.02832127522179917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02832127522179917}
{"step": 484184, "time": 15732.85291337967, "episode/length": 110.0, "episode/score": 0.6835979127219503, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.027347890472071867}
{"step": 484616, "time": 15746.323652267456, "episode/length": 150.0, "episode/score": 0.5459766723412258, "episode/reward_rate": 0.006622516556291391, "episode/intrinsic_return": 0.014726683895446513}
{"step": 484664, "time": 15747.830159187317, "episode/length": 213.0, "episode/score": 0.35997446506809183, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.02559947706760113}
{"step": 484728, "time": 15749.843685150146, "episode/length": 67.0, "episode/score": 0.8093960643832077, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.01877107162860625}
{"step": 484976, "time": 15757.842141866684, "episode/length": 38.0, "episode/score": 0.8954503664780873, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.014200364842452018}
{"step": 485040, "time": 15759.863691091537, "episode/length": 52.0, "episode/score": 0.8666766018178862, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.02917665223881727}
{"step": 485544, "time": 15775.530173301697, "episode/length": 101.0, "episode/score": 0.7157233032423278, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.031348320198219426}
{"step": 485664, "time": 15779.531278371811, "episode/length": 288.0, "episode/score": 0.03750414748508035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03750414748508035}
{"step": 485800, "time": 15783.568935871124, "episode/length": 288.0, "episode/score": 0.046905659919517007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046905659919517007}
{"step": 485832, "time": 15784.575037240982, "episode/length": 288.0, "episode/score": 0.02421779531650259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02421779531650259}
{"step": 486120, "time": 15793.65100312233, "episode/length": 288.0, "episode/score": 0.05370016842871905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05370016842871905}
{"step": 486184, "time": 15795.645659208298, "episode/length": 79.0, "episode/score": 0.7767404904591615, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.02361549009245323}
{"step": 486392, "time": 15802.183278560638, "episode/length": 288.0, "episode/score": 0.028016226188213977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028016226188213977}
{"step": 486552, "time": 15810.1538271904, "episode/length": 89.0, "episode/score": 0.743145274093223, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.021270248115143886}
{"step": 486976, "time": 15823.696338653564, "episode/length": 106.0, "episode/score": 0.7012149562461047, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.03246495410988359}
{"step": 487288, "time": 15833.209903001785, "episode/length": 288.0, "episode/score": 0.04944884162644314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04944884162644314}
{"step": 487352, "time": 15835.22441124916, "episode/length": 288.0, "episode/score": 0.033823039081795514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033823039081795514}
{"step": 487480, "time": 15839.21939253807, "episode/length": 115.0, "episode/score": 0.6631317644115029, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.02250676446971056}
{"step": 487856, "time": 15851.212197065353, "episode/length": 182.0, "episode/score": 0.4512381093802986, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.019988116531109767}
{"step": 487976, "time": 15854.910564422607, "episode/length": 288.0, "episode/score": 0.13076551283046456, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.0307655109692746}
{"step": 488064, "time": 15857.899746656418, "episode/length": 96.0, "episode/score": 0.7256357711283812, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.02563575777990934}
{"step": 488112, "time": 15859.430919885635, "episode/length": 288.0, "episode/score": 0.0604585275596321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0604585275596321}
{"step": 488240, "time": 15863.432126760483, "episode/length": 47.0, "episode/score": 0.8641711102489325, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.011046134148998021}
{"step": 488408, "time": 15868.473671913147, "episode/length": 42.0, "episode/score": 0.8826155233030448, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.013865572152369054}
{"step": 488496, "time": 15871.462319612503, "episode/length": 288.0, "episode/score": 0.047238290355437584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047238290355437584}
{"step": 488872, "time": 15883.073722839355, "episode/length": 94.0, "episode/score": 0.719282521202004, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.013032514316037691}
{"step": 489288, "time": 15896.058239936829, "episode/length": 288.0, "episode/score": 0.020773751052942657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020773751052942657}
{"step": 489312, "time": 15897.031418323517, "episode/length": 133.0, "episode/score": 0.610400992176551, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.026025945611877432}
{"step": 489480, "time": 15902.072521686554, "episode/length": 133.0, "episode/score": 0.6326024769222869, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.04822747166322472}
{"step": 489664, "time": 15908.012727499008, "episode/length": 288.0, "episode/score": 0.02540770403533088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02540770403533088}
{"step": 489792, "time": 15912.125088691711, "episode/length": 288.0, "episode/score": 0.029291515748511188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029291515748511188}
{"step": 489912, "time": 15915.664051771164, "episode/length": 74.0, "episode/score": 0.7905710393439733, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02182105499164777}
{"step": 490048, "time": 15920.870899915695, "eval_episode/length": 41.0, "eval_episode/score": 0.871874988079071, "eval_episode/reward_rate": 0.023809523809523808}
{"step": 490048, "time": 15921.661312580109, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 490048, "time": 15922.18144249916, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 490048, "time": 15922.389526128769, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 490048, "time": 15922.887690067291, "eval_episode/length": 160.0, "eval_episode/score": 0.5, "eval_episode/reward_rate": 0.006211180124223602}
{"step": 490048, "time": 15924.29156756401, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 490048, "time": 15925.671002864838, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15925.678335666656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15925.684809923172, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 15925.691178798676, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490272, "time": 15932.683363676071, "episode/length": 286.0, "episode/score": 0.12963061598210857, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.023380613060083988}
{"step": 490400, "time": 15936.686909675598, "episode/length": 138.0, "episode/score": 0.5954866687130362, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.02673662077320671}
{"step": 490512, "time": 15940.191860675812, "episode/length": 89.0, "episode/score": 0.7402853767797808, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.01841037981458271}
{"step": 490664, "time": 15944.839955806732, "episode/length": 93.0, "episode/score": 0.7374182731863783, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.02804327592359357}
{"step": 490808, "time": 15949.322708845139, "episode/length": 288.0, "episode/score": 0.02747405200062758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02747405200062758}
{"step": 490968, "time": 15954.338021755219, "episode/length": 70.0, "episode/score": 0.7941849042305194, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.012934919186250227}
{"step": 491184, "time": 15961.335235118866, "episode/length": 288.0, "episode/score": 0.03761262482649386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03761262482649386}
{"step": 491240, "time": 15962.868834972382, "episode/length": 120.0, "episode/score": 0.6508572922200813, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.025857319788684663}
{"step": 491328, "time": 15965.855146169662, "episode/length": 101.0, "episode/score": 0.7098750692054665, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.025500099709191204}
{"step": 491488, "time": 15970.854114294052, "episode/length": 250.0, "episode/score": 0.2545930085283743, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.03584301221000885}
{"step": 491512, "time": 15971.390615701675, "episode/length": 230.0, "episode/score": 0.306603063519006, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.025353063599041548}
{"step": 491816, "time": 15981.558225393295, "episode/length": 71.0, "episode/score": 0.7912956615359974, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.013170679495971171}
{"step": 491992, "time": 15987.084337711334, "episode/length": 82.0, "episode/score": 0.7668538277022918, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.023103851624185268}
{"step": 492320, "time": 15997.566035270691, "episode/length": 141.0, "episode/score": 0.5837245420815833, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.02434954239372189}
{"step": 492328, "time": 15997.600919485092, "episode/length": 41.0, "episode/score": 0.8859718637068568, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.014096850358384927}
{"step": 492624, "time": 16007.22676539421, "episode/length": 206.0, "episode/score": 0.3765260343159582, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.020276046309646745}
{"step": 492768, "time": 16011.749117136002, "episode/length": 262.0, "episode/score": 0.22123350284188348, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.03998349695417858}
{"step": 492928, "time": 16016.736839532852, "episode/length": 138.0, "episode/score": 0.6048058800877953, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.03605583955489067}
{"step": 492976, "time": 16018.228593587875, "episode/length": 80.0, "episode/score": 0.7744944475019224, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.024494426270678105}
{"step": 493120, "time": 16022.744895219803, "episode/length": 288.0, "episode/score": 0.006933347196223849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006933347196223849}
{"step": 493312, "time": 16028.73575758934, "episode/length": 123.0, "episode/score": 0.6390343529974984, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.023409312464593768}
{"step": 493440, "time": 16032.848650217056, "episode/length": 83.0, "episode/score": 0.7486311647375601, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.008006139727910977}
{"step": 493720, "time": 16041.384991168976, "episode/length": 92.0, "episode/score": 0.7272042371285181, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.014704283176598665}
{"step": 493800, "time": 16043.87514424324, "episode/length": 288.0, "episode/score": 0.018707852666665303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018707852666665303}
{"step": 493824, "time": 16044.846285104752, "episode/length": 288.0, "episode/score": 0.0368089662919715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0368089662919715}
{"step": 493928, "time": 16047.878952026367, "episode/length": 100.0, "episode/score": 0.7158457048845861, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.028345704957345674}
{"step": 494056, "time": 16051.89122390747, "episode/length": 76.0, "episode/score": 0.7852364817185276, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0227364795823064}
{"step": 494280, "time": 16058.875932455063, "episode/length": 206.0, "episode/score": 0.37670788287390167, "episode/reward_rate": 0.004830917874396135, "episode/intrinsic_return": 0.02045790187433738}
{"step": 494528, "time": 16067.002147197723, "episode/length": 90.0, "episode/score": 0.7382320836317717, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.01948205953380011}
{"step": 494632, "time": 16070.059350728989, "episode/length": 212.0, "episode/score": 0.35675653683402686, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.019256536577913153}
{"step": 494680, "time": 16071.581172704697, "episode/length": 119.0, "episode/score": 0.6463200434958907, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.01819505572022706}
{"step": 494752, "time": 16074.046167850494, "episode/length": 179.0, "episode/score": 0.47680602517380066, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.03618101828783438}
{"step": 494840, "time": 16076.598935127258, "episode/length": 126.0, "episode/score": 0.6321164564993609, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.025866492565555177}
{"step": 495232, "time": 16089.15111207962, "episode/length": 59.0, "episode/score": 0.8263488565588659, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.010723836339707304}
{"step": 495864, "time": 16108.850006103516, "episode/length": 78.0, "episode/score": 0.7705350822016186, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.014285085928364083}
{"step": 496080, "time": 16115.852150440216, "episode/length": 154.0, "episode/score": 0.5336155289026863, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.01486551703996497}
{"step": 496160, "time": 16118.358921051025, "episode/length": 184.0, "episode/score": 0.43829552074858213, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.013295513360574773}
{"step": 496168, "time": 16118.396219015121, "episode/length": 191.0, "episode/score": 0.4323457324676667, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.02922074892151727}
{"step": 496240, "time": 16120.85773396492, "episode/length": 288.0, "episode/score": 0.026073981825263104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026073981825263104}
{"step": 496368, "time": 16124.986979722977, "episode/length": 288.0, "episode/score": 0.02784649731312072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02784649731312072}
{"step": 496392, "time": 16125.53224849701, "episode/length": 27.0, "episode/score": 0.9182402216480341, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.0026152700789907612}
{"step": 496496, "time": 16129.03904747963, "episode/length": 78.0, "episode/score": 0.7687022021375327, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.012452193251405674}
{"step": 496592, "time": 16132.06842136383, "episode/length": 288.0, "episode/score": 0.01883202573917231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01883202573917231}
{"step": 496744, "time": 16136.594547510147, "episode/length": 82.0, "episode/score": 0.7590183242176209, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01526832279007806}
{"step": 496784, "time": 16138.084065437317, "episode/length": 48.0, "episode/score": 0.8617865621734779, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.011786560868898732}
{"step": 496840, "time": 16139.63685631752, "episode/length": 288.0, "episode/score": 0.01850844454686751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01850844454686751}
{"step": 497064, "time": 16146.649351119995, "episode/length": 34.0, "episode/score": 0.9051621302635766, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.011412104285497549}
{"step": 497240, "time": 16152.245186805725, "episode/length": 61.0, "episode/score": 0.8244332593595516, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.01505829884908394}
{"step": 497344, "time": 16155.712041139603, "episode/length": 137.0, "episode/score": 0.6002921630079356, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.028417161580392758}
{"step": 497408, "time": 16157.71647977829, "episode/length": 155.0, "episode/score": 0.5422624711835908, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.02663748613932171}
{"step": 497768, "time": 16168.755197525024, "episode/length": 65.0, "episode/score": 0.8061653888045441, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.009290392831786676}
{"step": 497824, "time": 16170.738961458206, "episode/length": 181.0, "episode/score": 0.4492330944025724, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.014858106381709035}
{"step": 497856, "time": 16171.745164632797, "episode/length": 157.0, "episode/score": 0.5256482264171751, "episode/reward_rate": 0.006329113924050633, "episode/intrinsic_return": 0.016273250317240695}
{"step": 498080, "time": 16178.810618162155, "episode/length": 126.0, "episode/score": 0.6303921129573524, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.024142113269491006}
{"step": 498136, "time": 16180.348395109177, "episode/length": 38.0, "episode/score": 0.8922363297108973, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.010986284637795052}
{"step": 498184, "time": 16181.94053697586, "episode/length": 104.0, "episode/score": 0.6985861339194201, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.023586122056698855}
{"step": 498536, "time": 16192.97505235672, "episode/length": 49.0, "episode/score": 0.8613920810606288, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.014517093284965199}
{"step": 498560, "time": 16193.952781200409, "episode/length": 46.0, "episode/score": 0.8634359847956148, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.007185975485299423}
{"step": 498576, "time": 16194.459759950638, "episode/length": 145.0, "episode/score": 0.5782746055059818, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03139962046171263}
{"step": 498752, "time": 16199.968605995178, "episode/length": 111.0, "episode/score": 0.6670989170750659, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.013973954003461131}
{"step": 498808, "time": 16201.49158167839, "episode/length": 288.0, "episode/score": 0.038644096286247986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038644096286247986}
{"step": 499024, "time": 16208.473401069641, "episode/length": 60.0, "episode/score": 0.8269778906630876, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.014477882364857919}
{"step": 499152, "time": 16212.577441692352, "episode/length": 288.0, "episode/score": 0.03742735238765249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03742735238765249}
{"step": 499352, "time": 16218.580740451813, "episode/length": 96.0, "episode/score": 0.7107117637898028, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.010711790666462662}
{"step": 499352, "time": 16218.587238073349, "episode/length": 67.0, "episode/score": 0.8022750463310047, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.011650085128593446}
{"step": 499376, "time": 16219.557364702225, "episode/length": 27.0, "episode/score": 0.9293828346240076, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.013757862493108064}
{"step": 499392, "time": 16220.062694311142, "episode/length": 103.0, "episode/score": 0.693521630958017, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.015396631705257846}
{"step": 499752, "time": 16231.577029943466, "episode/length": 90.0, "episode/score": 0.7408991918672712, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.022149180258480783}
{"step": 500032, "time": 16241.891071557999, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 500032, "time": 16241.936421871185, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 500032, "time": 16242.604984521866, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 500032, "time": 16242.700028419495, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 500032, "time": 16243.080852031708, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 500032, "time": 16243.106014966965, "eval_episode/length": 134.0, "eval_episode/score": 0.581250011920929, "eval_episode/reward_rate": 0.007407407407407408}
{"step": 500032, "time": 16243.53543138504, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 500032, "time": 16243.57852935791, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 500080, "time": 16245.090485334396, "episode/length": 288.0, "episode/score": 0.036701806003804904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036701806003804904}
{"step": 500105, "time": 16246.655167102814, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2021199544270833, "train/action_min": 0.0, "train/action_std": 1.6921638788321078, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010159682609045352, "train/actor_opt_grad_steps": 30190.0, "train/actor_opt_loss": -3.888252422442803, "train/adv_mag": 1.040822424644079, "train/adv_max": 0.29662979443868004, "train/adv_mean": 0.0054887965335719624, "train/adv_min": -1.0280785924349076, "train/adv_std": 0.03732319752661846, "train/cont_avg": 0.9952774439102564, "train/cont_loss_mean": 0.015433583279641776, "train/cont_loss_std": 0.22586677346665127, "train/cont_neg_acc": 0.3582547146922503, "train/cont_neg_loss": 2.6368349071926414, "train/cont_pos_acc": 0.9998491256664961, "train/cont_pos_loss": 0.003079686590577834, "train/cont_pred": 0.9954225555444375, "train/cont_rate": 0.9952774439102564, "train/dyn_loss_mean": 1.0000622926614224, "train/dyn_loss_std": 0.0017646401929549682, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.5141228211422761, "train/extr_critic_critic_opt_grad_steps": 30190.0, "train/extr_critic_critic_opt_loss": 6930.571344150641, "train/extr_critic_mag": 1.2139054310627473, "train/extr_critic_max": 1.2139054310627473, "train/extr_critic_mean": 1.1738844009546132, "train/extr_critic_min": 1.069083460783347, "train/extr_critic_std": 0.012573112504413494, "train/extr_return_normed_mag": 1.0248682829049918, "train/extr_return_normed_max": 0.314974028024918, "train/extr_return_normed_mean": 0.036077102510115276, "train/extr_return_normed_min": -1.0081781479028555, "train/extr_return_normed_std": 0.040581677448100005, "train/extr_return_rate": 0.9987590652245741, "train/extr_return_raw_mag": 1.4582700582650991, "train/extr_return_raw_max": 1.4582700582650991, "train/extr_return_raw_mean": 1.1793731787265875, "train/extr_return_raw_min": 0.13511788233732566, "train/extr_return_raw_std": 0.040581677209299345, "train/extr_reward_mag": 0.34400003812251945, "train/extr_reward_max": 0.34400003812251945, "train/extr_reward_mean": 0.003238388903749486, "train/extr_reward_min": 4.552572201459836e-06, "train/extr_reward_std": 0.012317938807730874, "train/image_loss_mean": 0.10677575442271355, "train/image_loss_std": 0.1045049820190821, "train/model_loss_mean": 0.7401333674406394, "train/model_loss_std": 0.38080093050614383, "train/model_opt_grad_norm": 24.437349500411596, "train/model_opt_grad_steps": 30162.210256410257, "train/model_opt_loss": 3247.685803535657, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4410.25641025641, "train/policy_entropy_mag": 1.309972259325859, "train/policy_entropy_max": 1.309972259325859, "train/policy_entropy_mean": 0.11105912029743195, "train/policy_entropy_min": 0.06468659532375824, "train/policy_entropy_std": 0.14199388535358967, "train/policy_logprob_mag": 6.551080234234149, "train/policy_logprob_max": -0.008608148218347477, "train/policy_logprob_mean": -0.11016292388622577, "train/policy_logprob_min": -6.551080234234149, "train/policy_logprob_std": 0.643738993925926, "train/policy_randomness_mag": 0.6731926129414485, "train/policy_randomness_max": 0.6731926129414485, "train/policy_randomness_mean": 0.05707310111476825, "train/policy_randomness_min": 0.03324233687076813, "train/policy_randomness_std": 0.07297042646469214, "train/post_ent_mag": 13.311460617261055, "train/post_ent_max": 13.311460617261055, "train/post_ent_mean": 12.873954083369329, "train/post_ent_min": 12.59871051005828, "train/post_ent_std": 0.1352587600166981, "train/prior_ent_mag": 13.002402266477928, "train/prior_ent_max": 13.002402266477928, "train/prior_ent_mean": 10.613765481802133, "train/prior_ent_min": 9.744414182809683, "train/prior_ent_std": 0.3901326887882673, "train/rep_loss_mean": 1.0000622926614224, "train/rep_loss_std": 0.0017646401929549682, "train/reward_avg": 0.0013374093487166251, "train/reward_loss_mean": 0.017886628709637965, "train/reward_loss_std": 0.16037197273033552, "train/reward_max_data": 0.6212270744777738, "train/reward_max_pred": 0.16490048750852926, "train/reward_neg_acc": 0.9997090788987967, "train/reward_neg_loss": 0.010708679203899243, "train/reward_pos_acc": 0.19645061849811932, "train/reward_pos_loss": 4.17581820819113, "train/reward_pred": 0.0010915240475860163, "train/reward_rate": 0.0017477964743589744, "train_stats/mean_log_entropy": 0.10207122010021394, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.009935962036252022, "report/cont_loss_std": 0.11898288875818253, "report/cont_neg_acc": 0.5714285969734192, "report/cont_neg_loss": 0.8230823278427124, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004339084029197693, "report/cont_pred": 0.9913793206214905, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10911687463521957, "report/image_loss_std": 0.10629505664110184, "report/model_loss_mean": 0.7369251251220703, "report/model_loss_std": 0.31513068079948425, "report/post_ent_mag": 13.035999298095703, "report/post_ent_max": 13.035999298095703, "report/post_ent_mean": 12.674898147583008, "report/post_ent_min": 12.468742370605469, "report/post_ent_std": 0.11140353977680206, "report/prior_ent_mag": 12.952774047851562, "report/prior_ent_max": 12.952774047851562, "report/prior_ent_mean": 10.497331619262695, "report/prior_ent_min": 9.614460945129395, "report/prior_ent_std": 0.3444836735725403, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0017920918762683868, "report/reward_loss_mean": 0.01787230186164379, "report/reward_loss_std": 0.16242285072803497, "report/reward_max_data": 0.8657916784286499, "report/reward_max_pred": 0.11654293537139893, "report/reward_neg_acc": 0.9990215301513672, "report/reward_neg_loss": 0.011073742993175983, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 3.4919347763061523, "report/reward_pred": 0.001289063598960638, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04835750535130501, "eval/cont_loss_std": 0.7566467523574829, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.041035652160645, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.001327392179518938, "eval/cont_pred": 0.9987046122550964, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1982358694076538, "eval/image_loss_std": 0.1378588080406189, "eval/model_loss_mean": 0.8628504872322083, "eval/model_loss_std": 1.0517743825912476, "eval/post_ent_mag": 13.035941123962402, "eval/post_ent_max": 13.035941123962402, "eval/post_ent_mean": 12.652487754821777, "eval/post_ent_min": 12.45830249786377, "eval/post_ent_std": 0.11068267375230789, "eval/prior_ent_mag": 11.83731460571289, "eval/prior_ent_max": 11.83731460571289, "eval/prior_ent_mean": 10.446832656860352, "eval/prior_ent_min": 9.684057235717773, "eval/prior_ent_std": 0.3404282331466675, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0007720947032794356, "eval/reward_loss_mean": 0.016257062554359436, "eval/reward_loss_std": 0.46439704298973083, "eval/reward_max_data": 0.7906249761581421, "eval/reward_max_pred": 0.014510035514831543, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017377344192937016, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 14.869529724121094, "eval/reward_pred": 0.00032890611328184605, "eval/reward_rate": 0.0009765625, "replay/size": 499601.0, "replay/inserts": 31152.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.1825108442419178e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.430069496769996e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0123645717447454e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.9903559684753, "timer/env.step_count": 3894.0, "timer/env.step_total": 35.33648705482483, "timer/env.step_frac": 0.03533682784430654, "timer/env.step_avg": 0.009074598627330465, "timer/env.step_min": 0.007439613342285156, "timer/env.step_max": 0.03944587707519531, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.609008550643921, "timer/replay._sample_frac": 0.015609159085866218, "timer/replay._sample_avg": 0.0005010595965152774, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.010564804077148438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4774.0, "timer/agent.policy_total": 46.49692940711975, "timer/agent.policy_frac": 0.04649737782929735, "timer/agent.policy_avg": 0.00973961654945952, "timer/agent.policy_min": 0.008431434631347656, "timer/agent.policy_max": 0.08221054077148438, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.19930243492126465, "timer/dataset_train_frac": 0.00019930435701876674, "timer/dataset_train_avg": 0.0001023638597438442, "timer/dataset_train_min": 8.821487426757812e-05, "timer/dataset_train_max": 0.000530242919921875, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 866.2344431877136, "timer/agent.train_frac": 0.8662427972605584, "timer/agent.train_avg": 0.44490726409230286, "timer/agent.train_min": 0.43268346786499023, "timer/agent.train_max": 0.5863351821899414, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47716307640075684, "timer/agent.report_frac": 0.00047716767822088816, "timer/agent.report_avg": 0.23858153820037842, "timer/agent.report_min": 0.23119211196899414, "timer/agent.report_max": 0.2459709644317627, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.004103068344382e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 31.15178392151603}
{"step": 500280, "time": 16251.88518500328, "episode/length": 115.0, "episode/score": 0.6555797633500902, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.014954752225150969}
{"step": 500392, "time": 16255.391963005066, "episode/length": 288.0, "episode/score": 0.016961559428494866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016961559428494866}
{"step": 500456, "time": 16257.41954255104, "episode/length": 46.0, "episode/score": 0.8696099210003041, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.013359936948475593}
{"step": 500512, "time": 16259.389385700226, "episode/length": 94.0, "episode/score": 0.7239398265796666, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.017689790633525604}
{"step": 500888, "time": 16270.94608950615, "episode/length": 75.0, "episode/score": 0.7798389512651909, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.014213973802469582}
{"step": 501024, "time": 16276.769815921783, "episode/length": 63.0, "episode/score": 0.809542868162012, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.006417868465419474}
{"step": 501064, "time": 16277.798084020615, "episode/length": 288.0, "episode/score": 0.04120706572538779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04120706572538779}
{"step": 501192, "time": 16281.790621757507, "episode/length": 91.0, "episode/score": 0.7355849919432274, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0199599873513705}
{"step": 501280, "time": 16284.763497829437, "episode/length": 110.0, "episode/score": 0.6798178721188322, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.02356787095104096}
{"step": 501456, "time": 16290.267950296402, "episode/length": 70.0, "episode/score": 0.7956247566152115, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.014374745006421108}
{"step": 501648, "time": 16296.294150352478, "episode/length": 77.0, "episode/score": 0.7724222617402035, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.013047277283831704}
{"step": 501664, "time": 16296.800159931183, "episode/length": 288.0, "episode/score": 0.03314545867497998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03314545867497998}
{"step": 501688, "time": 16297.335186004639, "episode/length": 288.0, "episode/score": 0.012297814479580893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012297814479580893}
{"step": 501704, "time": 16297.840700149536, "episode/length": 288.0, "episode/score": 0.030644353670979285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030644353670979285}
{"step": 502104, "time": 16310.389175415039, "episode/length": 49.0, "episode/score": 0.853234920894721, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.006359884948579975}
{"step": 502216, "time": 16313.889170646667, "episode/length": 116.0, "episode/score": 0.6574094249819638, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.019909425777953516}
{"step": 502360, "time": 16318.392549037933, "episode/length": 31.0, "episode/score": 0.9180079184971106, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.014882929395767519}
{"step": 502384, "time": 16319.368922472, "episode/length": 115.0, "episode/score": 0.6604141828792791, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.019789158854067068}
{"step": 502600, "time": 16325.89227604866, "episode/length": 116.0, "episode/score": 0.6564318237473543, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.018931824543344078}
{"step": 502824, "time": 16332.93914437294, "episode/length": 75.0, "episode/score": 0.7776086179162718, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.011983616748480586}
{"step": 503048, "time": 16339.92201423645, "episode/length": 85.0, "episode/score": 0.7455059611928334, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.011130960025042214}
{"step": 503064, "time": 16340.423774719238, "episode/length": 57.0, "episode/score": 0.832443877980424, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.010568900800009828}
{"step": 503336, "time": 16348.898723840714, "episode/length": 63.0, "episode/score": 0.8131796673264517, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.01005466602187255}
{"step": 503376, "time": 16350.363430261612, "episode/length": 288.0, "episode/score": 0.03868767713710497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03868767713710497}
{"step": 503504, "time": 16354.364828586578, "episode/length": 288.0, "episode/score": 0.02161132849879266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02161132849879266}
{"step": 503760, "time": 16362.430613040924, "episode/length": 171.0, "episode/score": 0.4875704991990659, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.021945505906771245}
{"step": 503960, "time": 16368.502669811249, "episode/length": 288.0, "episode/score": 0.017095240698793646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017095240698793646}
{"step": 504000, "time": 16369.97208738327, "episode/length": 288.0, "episode/score": 0.01742067397354674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01742067397354674}
{"step": 504016, "time": 16370.47568655014, "episode/length": 79.0, "episode/score": 0.7677156401812226, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.014590652849392427}
{"step": 504128, "time": 16373.972472190857, "episode/length": 132.0, "episode/score": 0.6080562627892334, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.0205562959224892}
{"step": 504384, "time": 16381.962550163269, "episode/length": 109.0, "episode/score": 0.6743280301901251, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.014953042858294907}
{"step": 504432, "time": 16383.484903812408, "episode/length": 53.0, "episode/score": 0.8472028262744828, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.012827794134395276}
{"step": 504456, "time": 16384.02388358116, "episode/length": 54.0, "episode/score": 0.8402421622869269, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.008992174955096743}
{"step": 504528, "time": 16386.489284276962, "episode/length": 17.0, "episode/score": 0.9566637436216752, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.009788790000811787}
{"step": 504536, "time": 16386.52600169182, "episode/length": 96.0, "episode/score": 0.7247849558252284, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.024784951233371544}
{"step": 504664, "time": 16390.601102113724, "episode/length": 87.0, "episode/score": 0.743022826431428, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.014897849251013895}
{"step": 504832, "time": 16396.262312173843, "episode/length": 49.0, "episode/score": 0.8595632993209392, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.012688286377738223}
{"step": 504920, "time": 16398.833132982254, "episode/length": 48.0, "episode/score": 0.8570730581446071, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.007073043594147066}
{"step": 504976, "time": 16400.819781780243, "episode/length": 105.0, "episode/score": 0.6897363077839316, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.017861301763076654}
{"step": 505360, "time": 16412.859210014343, "episode/length": 288.0, "episode/score": 0.03164465312228515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03164465312228515}
{"step": 505368, "time": 16412.896644353867, "episode/length": 103.0, "episode/score": 0.6895635914944762, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.011438576944016177}
{"step": 505376, "time": 16413.372604608536, "episode/length": 67.0, "episode/score": 0.8012739141913983, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.010648908270951551}
{"step": 505456, "time": 16415.89145731926, "episode/length": 98.0, "episode/score": 0.7040207884800225, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.010270740838507209}
{"step": 505640, "time": 16421.610171318054, "episode/length": 287.0, "episode/score": 0.1252120099335059, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.02208701223852927}
{"step": 505656, "time": 16422.161404132843, "episode/length": 91.0, "episode/score": 0.7369501835049448, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.021325166787704575}
{"step": 505776, "time": 16426.152812957764, "episode/length": 164.0, "episode/score": 0.5110157149311902, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.023515688691176706}
{"step": 505920, "time": 16430.68768954277, "episode/length": 34.0, "episode/score": 0.9078085372957503, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.014058495979952568}
{"step": 505936, "time": 16431.196893692017, "episode/length": 59.0, "episode/score": 0.8263935106556204, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.010768475393419408}
{"step": 506024, "time": 16433.74111700058, "episode/length": 80.0, "episode/score": 0.7790580437478098, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.029058029428725263}
{"step": 506152, "time": 16437.776572704315, "episode/length": 98.0, "episode/score": 0.7208613470243819, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.02711131602298167}
{"step": 506200, "time": 16439.30269765854, "episode/length": 103.0, "episode/score": 0.7001516532330214, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.022026647522849885}
{"step": 506312, "time": 16442.814857006073, "episode/length": 166.0, "episode/score": 0.5116381483535548, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.030388150612012055}
{"step": 506392, "time": 16445.332906007767, "episode/length": 76.0, "episode/score": 0.7741645207208876, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.011664555750257932}
{"step": 506448, "time": 16447.30714559555, "episode/length": 98.0, "episode/score": 0.7147853768842651, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.02103535326068595}
{"step": 506512, "time": 16449.320922851562, "episode/length": 73.0, "episode/score": 0.7980321593836379, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.02615711220050798}
{"step": 506808, "time": 16458.4519033432, "episode/length": 81.0, "episode/score": 0.7602759229343974, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.013400926677149982}
{"step": 506840, "time": 16459.478957653046, "episode/length": 112.0, "episode/score": 0.6747629165370199, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.02476293220070147}
{"step": 506864, "time": 16460.46212863922, "episode/length": 104.0, "episode/score": 0.7011443641799815, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.026144353073959792}
{"step": 506880, "time": 16460.96759724617, "episode/length": 84.0, "episode/score": 0.7705057740772645, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.0330057629712428}
{"step": 507144, "time": 16469.033569335938, "episode/length": 93.0, "episode/score": 0.7274713473379961, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.018096341627824586}
{"step": 507296, "time": 16474.003229618073, "episode/length": 105.0, "episode/score": 0.6945809712860864, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02270598639097443}
{"step": 507320, "time": 16474.55542588234, "episode/length": 54.0, "episode/score": 0.8489994409080737, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.017749429802051964}
{"step": 507456, "time": 16479.015206336975, "episode/length": 142.0, "episode/score": 0.5940544319803394, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.03780444764402091}
{"step": 507576, "time": 16482.65078186989, "episode/length": 132.0, "episode/score": 0.6170940797330786, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.029594096415394233}
{"step": 507800, "time": 16489.6754655838, "episode/length": 123.0, "episode/score": 0.657766451564612, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.0421414134036695}
{"step": 507840, "time": 16491.139345645905, "episode/length": 64.0, "episode/score": 0.8222073292456571, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.022207337464578814}
{"step": 507960, "time": 16495.147567033768, "episode/length": 136.0, "episode/score": 0.6239226530406086, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.04892268006642553}
{"step": 507992, "time": 16496.15072274208, "episode/length": 105.0, "episode/score": 0.723319755087914, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.05144474076882943}
{"step": 508048, "time": 16498.12371468544, "episode/length": 30.0, "episode/score": 0.9184073727062696, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.012157349364997572}
{"step": 508096, "time": 16499.62557864189, "episode/length": 64.0, "episode/score": 0.8279104878442922, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.027910499031804648}
{"step": 508200, "time": 16502.681362867355, "episode/length": 112.0, "episode/score": 0.6937551605039971, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.04375515495098625}
{"step": 508520, "time": 16512.789454698563, "episode/length": 132.0, "episode/score": 0.6189828791482341, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.03148287359522328}
{"step": 508520, "time": 16512.805102586746, "episode/length": 58.0, "episode/score": 0.8377109139597678, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01896089033618864}
{"step": 508552, "time": 16513.808077812195, "episode/length": 43.0, "episode/score": 0.8880753158914558, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.02245028387142156}
{"step": 508752, "time": 16520.368739128113, "episode/length": 94.0, "episode/score": 0.7394624981146762, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.03321247801557092}
{"step": 508888, "time": 16524.39324116707, "episode/length": 130.0, "episode/score": 0.6323937290444519, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.038643755267003144}
{"step": 508920, "time": 16525.418377637863, "episode/length": 119.0, "episode/score": 0.6662756984267162, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.03815067934624494}
{"step": 509136, "time": 16532.42488002777, "episode/length": 129.0, "episode/score": 0.6454893480567989, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.04861432897632767}
{"step": 509152, "time": 16532.931358098984, "episode/length": 288.0, "episode/score": 0.05432683304150032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05432683304150032}
{"step": 509392, "time": 16540.44468808174, "episode/length": 104.0, "episode/score": 0.6928537478622729, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.01785375104623199}
{"step": 509408, "time": 16540.951823949814, "episode/length": 81.0, "episode/score": 0.7636916616987719, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.01681667383797958}
{"step": 509560, "time": 16545.600656747818, "episode/length": 52.0, "episode/score": 0.8529753696045645, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.015475393664701187}
{"step": 509560, "time": 16545.62932896614, "episode/length": 83.0, "episode/score": 0.7663825445387147, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.0257575209151355}
{"step": 509752, "time": 16551.64407801628, "episode/length": 103.0, "episode/score": 0.7079846254932818, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.0298596018697026}
{"step": 509816, "time": 16553.647818803787, "episode/length": 52.0, "episode/score": 0.8528530649429058, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.01535310388965172}
{"step": 509952, "time": 16558.144172668457, "episode/length": 48.0, "episode/score": 0.867591373443247, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.017591349819667812}
{"step": 510016, "time": 16561.06059527397, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 510016, "time": 16561.18664240837, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 510016, "time": 16561.725784301758, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 510016, "time": 16561.78534054756, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 510016, "time": 16562.103190898895, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 510016, "time": 16562.510888814926, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 510016, "time": 16562.568897485733, "eval_episode/length": 138.0, "eval_episode/score": 0.5687500238418579, "eval_episode/reward_rate": 0.007194244604316547}
{"step": 510016, "time": 16562.83611869812, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 510144, "time": 16566.91180896759, "episode/length": 91.0, "episode/score": 0.7331280738578698, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.017503095848724115}
{"step": 510344, "time": 16573.131054401398, "episode/length": 65.0, "episode/score": 0.8149128564360808, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.018037852346992622}
{"step": 510392, "time": 16574.68352651596, "episode/length": 54.0, "episode/score": 0.8416836938797587, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.010433691024672953}
{"step": 510544, "time": 16579.752676010132, "episode/length": 24.0, "episode/score": 0.9314708189128851, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.0064708190700457635}
{"step": 510816, "time": 16588.356948375702, "episode/length": 33.0, "episode/score": 0.9126167906428009, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.01574178990938435}
{"step": 510832, "time": 16588.88972377777, "episode/length": 288.0, "episode/score": 0.04904822705839251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04904822705839251}
{"step": 510832, "time": 16588.899183511734, "episode/length": 288.0, "episode/score": 0.05036164852714364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05036164852714364}
{"step": 510992, "time": 16594.07118177414, "episode/length": 105.0, "episode/score": 0.688175058900697, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.016300073059710485}
{"step": 511248, "time": 16602.355006456375, "episode/length": 51.0, "episode/score": 0.8518096460480251, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.011184668038879408}
{"step": 511464, "time": 16608.89080452919, "episode/length": 288.0, "episode/score": 0.05071615356575876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05071615356575876}
{"step": 511656, "time": 16614.896966934204, "episode/length": 82.0, "episode/score": 0.7636433957570148, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.019893419817151425}
{"step": 511664, "time": 16615.37082195282, "episode/length": 105.0, "episode/score": 0.693886063758498, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.022011077917511557}
{"step": 511872, "time": 16621.87249994278, "episode/length": 288.0, "episode/score": 0.029832913943437234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029832913943437234}
{"step": 512064, "time": 16627.89736199379, "episode/length": 288.0, "episode/score": 0.047571991664426605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047571991664426605}
{"step": 512072, "time": 16627.932426929474, "episode/length": 51.0, "episode/score": 0.853130657221925, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.012505669361132732}
{"step": 512184, "time": 16631.499480724335, "episode/length": 89.0, "episode/score": 0.7474310561582342, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.025556056315394926}
{"step": 512192, "time": 16632.05409359932, "episode/length": 169.0, "episode/score": 0.5082920873797434, "episode/reward_rate": 0.0058823529411764705, "episode/intrinsic_return": 0.03641708552873979}
{"step": 512328, "time": 16636.0945789814, "episode/length": 17.0, "episode/score": 0.9519121554964158, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.005037188404116932}
{"step": 512448, "time": 16640.06943321228, "episode/length": 97.0, "episode/score": 0.7153961523066528, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.018521190307524193}
{"step": 512648, "time": 16646.0981464386, "episode/length": 71.0, "episode/score": 0.7899526233825327, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.011827647381551287}
{"step": 512704, "time": 16648.073536157608, "episode/length": 288.0, "episode/score": 0.04499764467999512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04499764467999512}
{"step": 512768, "time": 16650.110155582428, "episode/length": 111.0, "episode/score": 0.6836312258613475, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.030506246848119645}
{"step": 512896, "time": 16654.1200671196, "episode/length": 55.0, "episode/score": 0.8379018470452593, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.009776873267810515}
{"step": 512904, "time": 16654.15632390976, "episode/length": 88.0, "episode/score": 0.739700311392653, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.014700283461706931}
{"step": 512976, "time": 16656.651892900467, "episode/length": 33.0, "episode/score": 0.9139818293281223, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.017106819645277938}
{"step": 513008, "time": 16657.661107063293, "episode/length": 117.0, "episode/score": 0.6676166043327498, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.03324160006030752}
{"step": 513256, "time": 16665.321211338043, "episode/length": 75.0, "episode/score": 0.7812603815779084, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.015635351884725424}
{"step": 513272, "time": 16665.825607299805, "episode/length": 117.0, "episode/score": 0.6531422765904153, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.018767309498116447}
{"step": 513280, "time": 16666.297899246216, "episode/length": 33.0, "episode/score": 0.9088659790843394, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.011990951153393326}
{"step": 513560, "time": 16674.826770305634, "episode/length": 288.0, "episode/score": 0.028171688930285654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028171688930285654}
{"step": 513848, "time": 16683.850044965744, "episode/length": 70.0, "episode/score": 0.7982993013513351, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.017049315510348606}
{"step": 513936, "time": 16686.820741176605, "episode/length": 82.0, "episode/score": 0.7711568353960843, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.02740686830378536}
{"step": 514312, "time": 16698.38351392746, "episode/length": 93.0, "episode/score": 0.7221147820407054, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.012739767264690727}
{"step": 514504, "time": 16704.36364197731, "episode/length": 23.0, "episode/score": 0.936916782538276, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.008791767762261316}
{"step": 514544, "time": 16705.846945762634, "episode/length": 86.0, "episode/score": 0.7520668541711188, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.020816842874467056}
{"step": 514544, "time": 16705.853224277496, "episode/length": 75.0, "episode/score": 0.7827792554960524, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.017154225802869405}
{"step": 514896, "time": 16716.80278134346, "episode/length": 43.0, "episode/score": 0.8842576703498821, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.018632660667037726}
{"step": 515032, "time": 16720.87225151062, "episode/length": 65.0, "episode/score": 0.8127491087213912, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.015874079028208143}
{"step": 515080, "time": 16722.50282549858, "episode/length": 288.0, "episode/score": 0.04900025668774788, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04900025668774788}
{"step": 515208, "time": 16726.584602355957, "episode/length": 288.0, "episode/score": 0.028619759400100975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028619759400100975}
{"step": 515216, "time": 16727.07001376152, "episode/length": 288.0, "episode/score": 0.012679860681544142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012679860681544142}
{"step": 515288, "time": 16729.132844686508, "episode/length": 288.0, "episode/score": 0.042401323946194225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042401323946194225}
{"step": 515568, "time": 16738.285259962082, "episode/length": 288.0, "episode/score": 0.029616507688615457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029616507688615457}
{"step": 515568, "time": 16738.293291568756, "episode/length": 60.0, "episode/score": 0.8228598321938989, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.010359815597439592}
{"step": 515728, "time": 16743.33408665657, "episode/length": 86.0, "episode/score": 0.7540152885368343, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.02276527234346304}
{"step": 515752, "time": 16743.86682653427, "episode/length": 57.0, "episode/score": 0.8296509047848417, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.007775912030240306}
{"step": 515896, "time": 16748.380222797394, "episode/length": 20.0, "episode/score": 0.9431108162177679, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.005610842796841098}
{"step": 515952, "time": 16750.367815971375, "episode/length": 47.0, "episode/score": 0.8607763836326399, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.007651424616653912}
{"step": 516008, "time": 16751.998603582382, "episode/length": 138.0, "episode/score": 0.5936929233674846, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.024942882929167354}
{"step": 516032, "time": 16752.99649786949, "episode/length": 102.0, "episode/score": 0.70376674367958, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.022516779075658633}
{"step": 516216, "time": 16759.107204914093, "episode/length": 80.0, "episode/score": 0.7688279493071661, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.01882793271070682}
{"step": 516248, "time": 16760.121516942978, "episode/length": 128.0, "episode/score": 0.6277550014760891, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.027754996217026928}
{"step": 516832, "time": 16778.75506877899, "episode/length": 72.0, "episode/score": 0.7914655863474422, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.016465580496117127}
{"step": 516856, "time": 16779.293273687363, "episode/length": 288.0, "episode/score": 0.02512524027309837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02512524027309837}
{"step": 516936, "time": 16781.902281284332, "episode/length": 129.0, "episode/score": 0.6120547968149879, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.015179811473132077}
{"step": 517112, "time": 16787.418267965317, "episode/length": 137.0, "episode/score": 0.5972582338083896, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.025383274792403654}
{"step": 517304, "time": 16793.410664081573, "episode/length": 135.0, "episode/score": 0.5992347521608963, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.021109729911017894}
{"step": 517376, "time": 16795.893211603165, "episode/length": 67.0, "episode/score": 0.804976604817341, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.014351655238272087}
{"step": 517408, "time": 16796.916946411133, "episode/length": 68.0, "episode/score": 0.804192206376996, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.016692165938678727}
{"step": 517656, "time": 16804.452109336853, "episode/length": 67.0, "episode/score": 0.7961607925011549, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.005535822382057631}
{"step": 517728, "time": 16806.93484711647, "episode/length": 98.0, "episode/score": 0.7209791918913027, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.027229166004900662}
{"step": 517880, "time": 16811.566697359085, "episode/length": 58.0, "episode/score": 0.8272615242447046, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.00851150644189147}
{"step": 518064, "time": 16817.59553360939, "episode/length": 288.0, "episode/score": 0.0386775113034048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0386775113034048}
{"step": 518216, "time": 16822.123115301132, "episode/length": 69.0, "episode/score": 0.7983447601554872, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.013969725984679826}
{"step": 518264, "time": 16823.618255138397, "episode/length": 288.0, "episode/score": 0.03180729234108526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03180729234108526}
{"step": 518328, "time": 16825.60331439972, "episode/length": 127.0, "episode/score": 0.6338415173921419, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.03071652454295304}
{"step": 518344, "time": 16826.110117912292, "episode/length": 288.0, "episode/score": 0.032914872908207826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032914872908207826}
{"step": 518800, "time": 16840.49478316307, "episode/length": 133.0, "episode/score": 0.6041888533950157, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.019813856132230967}
{"step": 518872, "time": 16842.644424438477, "episode/length": 81.0, "episode/score": 0.765256343785552, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.018381360741443586}
{"step": 518928, "time": 16844.61074447632, "episode/length": 130.0, "episode/score": 0.6206327065392543, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.026882683816438657}
{"step": 519008, "time": 16847.119493961334, "episode/length": 117.0, "episode/score": 0.6492254002050402, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.01485045161550147}
{"step": 519072, "time": 16849.824028491974, "episode/length": 100.0, "episode/score": 0.7017917635777167, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.014291746886669898}
{"step": 519320, "time": 16857.34691286087, "episode/length": 38.0, "episode/score": 0.8904788051920605, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.009228807929275717}
{"step": 519360, "time": 16858.82374215126, "episode/length": 53.0, "episode/score": 0.8421450051466195, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.007769987343806406}
{"step": 519528, "time": 16863.906697511673, "episode/length": 20.0, "episode/score": 0.9501046634489114, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.012604634054042663}
{"step": 519688, "time": 16868.910091638565, "episode/length": 288.0, "episode/score": 0.012359651688456097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012359651688456097}
{"step": 519712, "time": 16869.885106801987, "episode/length": 113.0, "episode/score": 0.6643959677872715, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.017520929626329007}
{"step": 519856, "time": 16874.49719929695, "episode/length": 122.0, "episode/score": 0.646350111613458, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.027600127277139563}
{"step": 519856, "time": 16874.50351691246, "episode/length": 40.0, "episode/score": 0.8865733082570841, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.011573301097541844}
{"step": 519912, "time": 16876.026752233505, "episode/length": 73.0, "episode/score": 0.784111406312519, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.012236353075792294}
{"step": 520000, "time": 16879.967015504837, "eval_episode/length": 54.0, "eval_episode/score": 0.831250011920929, "eval_episode/reward_rate": 0.01818181818181818}
{"step": 520000, "time": 16880.04151582718, "eval_episode/length": 58.0, "eval_episode/score": 0.8187500238418579, "eval_episode/reward_rate": 0.01694915254237288}
{"step": 520000, "time": 16880.318537950516, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 520000, "time": 16881.030833482742, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 520000, "time": 16881.05487370491, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 520000, "time": 16881.328801631927, "eval_episode/length": 57.0, "eval_episode/score": 0.8218749761581421, "eval_episode/reward_rate": 0.017241379310344827}
{"step": 520000, "time": 16881.38619685173, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 520000, "time": 16881.690422058105, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 520312, "time": 16891.230370283127, "episode/length": 74.0, "episode/score": 0.7879666581793572, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.019216616863559466}
{"step": 520384, "time": 16893.69680929184, "episode/length": 58.0, "episode/score": 0.8273635414582259, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.00861348822149921}
{"step": 520480, "time": 16896.710681915283, "episode/length": 77.0, "episode/score": 0.7697980871594154, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.010423102823096997}
{"step": 520640, "time": 16901.845702648163, "episode/length": 288.0, "episode/score": 0.024546394496610446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024546394496610446}
{"step": 520656, "time": 16902.35250043869, "episode/length": 288.0, "episode/score": 0.028881242711946697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028881242711946697}
{"step": 520720, "time": 16904.350350141525, "episode/length": 50.0, "episode/score": 0.8583416201252021, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.014591640265052774}
{"step": 521000, "time": 16912.894177675247, "episode/length": 44.0, "episode/score": 0.8735570251658373, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.01105703137659475}
{"step": 521104, "time": 16916.42410349846, "episode/length": 89.0, "episode/score": 0.7365536124349319, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.014678618645689312}
{"step": 521280, "time": 16921.95465040207, "episode/length": 34.0, "episode/score": 0.8999410444805562, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.00619105269947795}
{"step": 521384, "time": 16924.983141183853, "episode/length": 288.0, "episode/score": 0.04218970608289396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04218970608289396}
{"step": 521480, "time": 16928.01675271988, "episode/length": 94.0, "episode/score": 0.7186080029316599, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.012358006115618991}
{"step": 521656, "time": 16933.6410241127, "episode/length": 46.0, "episode/score": 0.8663685776782586, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.010118566257915518}
{"step": 521856, "time": 16940.135528564453, "episode/length": 93.0, "episode/score": 0.7392077154827348, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.029832692455784127}
{"step": 522000, "time": 16944.6803047657, "episode/length": 288.0, "episode/score": 0.020092713665462725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020092713665462725}
{"step": 522016, "time": 16945.19102883339, "episode/length": 78.0, "episode/score": 0.764123087584835, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.007873083882827814}
{"step": 522168, "time": 16949.727702617645, "episode/length": 288.0, "episode/score": 0.031024994843960485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031024994843960485}
{"step": 522280, "time": 16953.240310192108, "episode/length": 99.0, "episode/score": 0.7004634651113975, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.009838465268558139}
{"step": 522664, "time": 16965.36232328415, "episode/length": 100.0, "episode/score": 0.712877027326158, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.025377019147981628}
{"step": 522792, "time": 16969.369251728058, "episode/length": 288.0, "episode/score": 0.04074081500544935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04074081500544935}
{"step": 522896, "time": 16972.856550693512, "episode/length": 109.0, "episode/score": 0.6682111140127063, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.008836116250790838}
{"step": 522968, "time": 16974.891684293747, "episode/length": 288.0, "episode/score": 0.024680534533558784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024680534533558784}
{"step": 523016, "time": 16976.41989660263, "episode/length": 126.0, "episode/score": 0.6326614024400783, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.026411440583558488}
{"step": 523144, "time": 16980.484673023224, "episode/length": 107.0, "episode/score": 0.6798946451539791, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.014269669214115765}
{"step": 523176, "time": 16981.524691820145, "episode/length": 125.0, "episode/score": 0.6308453071958411, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.021470277800972326}
{"step": 523248, "time": 16984.03377056122, "episode/length": 72.0, "episode/score": 0.7802852415165944, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.005285279517465824}
{"step": 523440, "time": 16990.09297323227, "episode/length": 52.0, "episode/score": 0.8477306686191923, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.010230669119778213}
{"step": 523472, "time": 16991.107881307602, "episode/length": 71.0, "episode/score": 0.7926094567219479, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.014484461483334599}
{"step": 523560, "time": 16993.70329618454, "episode/length": 95.0, "episode/score": 0.7182849354898053, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.015159955629655997}
{"step": 523704, "time": 16998.1647233963, "episode/length": 91.0, "episode/score": 0.7407499048894692, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.025124934942084565}
{"step": 523912, "time": 17004.635125160217, "episode/length": 95.0, "episode/score": 0.7139726641875086, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.010847682319194973}
{"step": 523968, "time": 17006.62216591835, "episode/length": 288.0, "episode/score": 0.028957217436868632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028957217436868632}
{"step": 524088, "time": 17010.12130999565, "episode/length": 113.0, "episode/score": 0.6745588020927471, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.027683770072712832}
{"step": 524232, "time": 17014.64276075363, "episode/length": 83.0, "episode/score": 0.7577415380401362, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.01711648480340955}
{"step": 524312, "time": 17017.657212018967, "episode/length": 104.0, "episode/score": 0.7042182624230691, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.029218227160868082}
{"step": 524536, "time": 17024.724736452103, "episode/length": 70.0, "episode/score": 0.7959570652334378, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.014707065451716517}
{"step": 524536, "time": 17024.731803178787, "episode/length": 160.0, "episode/score": 0.5175588997105933, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.01755891481548133}
{"step": 524672, "time": 17029.1830599308, "episode/length": 153.0, "episode/score": 0.5462221847209321, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.024347179010760556}
{"step": 524920, "time": 17036.675549268723, "episode/length": 47.0, "episode/score": 0.8668159668815179, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.013691008855062137}
{"step": 524960, "time": 17038.126094579697, "episode/length": 108.0, "episode/score": 0.674956198133259, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.012456192423087487}
{"step": 525024, "time": 17040.108333826065, "episode/length": 88.0, "episode/score": 0.7344893084874684, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.00948930277729687}
{"step": 525296, "time": 17048.531352758408, "episode/length": 77.0, "episode/score": 0.7693865423534589, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.010011586335167522}
{"step": 526016, "time": 17071.099736213684, "episode/length": 288.0, "episode/score": 0.027347013911366957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027347013911366957}
{"step": 526016, "time": 17071.109684705734, "episode/length": 184.0, "episode/score": 0.4505111948802778, "episode/reward_rate": 0.005405405405405406, "episode/intrinsic_return": 0.025511183177627572}
{"step": 526224, "time": 17077.615583896637, "episode/length": 288.0, "episode/score": 0.022809664326075563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022809664326075563}
{"step": 526248, "time": 17078.15255522728, "episode/length": 152.0, "episode/score": 0.5516516252688461, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.026651664215592064}
{"step": 526376, "time": 17082.211869955063, "episode/length": 176.0, "episode/score": 0.4753580373517252, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.02535804518356599}
{"step": 526512, "time": 17086.657471895218, "episode/length": 61.0, "episode/score": 0.8194505186247056, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.010075542623724232}
{"step": 526520, "time": 17086.693058252335, "episode/length": 36.0, "episode/score": 0.896002630244709, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.008502635006095716}
{"step": 526544, "time": 17087.66058588028, "episode/length": 288.0, "episode/score": 0.012256863645006888, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012256863645006888}
{"step": 526792, "time": 17095.124314546585, "episode/length": 51.0, "episode/score": 0.8466130800497922, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.00598810707560915}
{"step": 526824, "time": 17096.122934103012, "episode/length": 190.0, "episode/score": 0.44254204451647183, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.03629203782259083}
{"step": 526840, "time": 17096.643333911896, "episode/length": 73.0, "episode/score": 0.7792651490283333, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.007390151409026657}
{"step": 527152, "time": 17106.602548599243, "episode/length": 78.0, "episode/score": 0.7776970181026854, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02144700936571553}
{"step": 527168, "time": 17107.106696605682, "episode/length": 81.0, "episode/score": 0.7570427600843459, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.010167786164288373}
{"step": 527232, "time": 17109.103934526443, "episode/length": 288.0, "episode/score": 0.029564068086358475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029564068086358475}
{"step": 527280, "time": 17110.6022400856, "episode/length": 60.0, "episode/score": 0.8196410959035916, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0071410918145033975}
{"step": 527288, "time": 17110.637896060944, "episode/length": 92.0, "episode/score": 0.733638363381317, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.021138387441453688}
{"step": 527608, "time": 17120.69741487503, "episode/length": 97.0, "episode/score": 0.714378364168681, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.017503383921450677}
{"step": 527736, "time": 17124.681466579437, "episode/length": 111.0, "episode/score": 0.6745363475992008, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.021411355431041557}
{"step": 527856, "time": 17128.652319908142, "episode/length": 70.0, "episode/score": 0.7912776392100227, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.01002763512093452}
{"step": 528000, "time": 17133.12335395813, "episode/length": 89.0, "episode/score": 0.73922299737103, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.017348003581787452}
{"step": 528232, "time": 17140.117624282837, "episode/length": 132.0, "episode/score": 0.6080145322928274, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.020514568212774975}
{"step": 528240, "time": 17140.592211961746, "episode/length": 135.0, "episode/score": 0.5988512391653558, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.020726251243445404}
{"step": 528328, "time": 17143.21990275383, "episode/length": 288.0, "episode/score": 0.027376405266068105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027376405266068105}
{"step": 528392, "time": 17145.21266746521, "episode/length": 97.0, "episode/score": 0.7106650624850204, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.013790100485891799}
{"step": 528664, "time": 17153.664419174194, "episode/length": 82.0, "episode/score": 0.7596311411524539, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.01588117915332532}
{"step": 528744, "time": 17156.15441966057, "episode/length": 51.0, "episode/score": 0.8538603048145887, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.013235316953796428}
{"step": 528976, "time": 17163.59735417366, "episode/length": 154.0, "episode/score": 0.5439082561456416, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.025158216110412468}
{"step": 529000, "time": 17164.125878572464, "episode/length": 95.0, "episode/score": 0.7218484960176283, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.01872351315978449}
{"step": 529040, "time": 17165.585841178894, "episode/length": 99.0, "episode/score": 0.6992883847998428, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.00866334318573081}
{"step": 529280, "time": 17173.14385008812, "episode/length": 110.0, "episode/score": 0.6711174708882481, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.014867485047261653}
{"step": 529488, "time": 17179.636551618576, "episode/length": 60.0, "episode/score": 0.821358908864795, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.00885888075049479}
{"step": 529544, "time": 17181.208137512207, "episode/length": 288.0, "episode/score": 0.022518534436073878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022518534436073878}
{"step": 529904, "time": 17192.844292640686, "episode/length": 77.0, "episode/score": 0.7749955241172302, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.015620574181639313}
{"step": 529976, "time": 17194.896068811417, "episode/length": 124.0, "episode/score": 0.6413598258168349, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.02885980673636368}
{"step": 530016, "time": 17196.383555412292, "episode/length": 168.0, "episode/score": 0.5025232566625846, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.027523276782062567}
{"step": 530088, "time": 17200.136575460434, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 530088, "time": 17200.412715435028, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 530088, "time": 17201.082216739655, "eval_episode/length": 145.0, "eval_episode/score": 0.546875, "eval_episode/reward_rate": 0.00684931506849315}
{"step": 530088, "time": 17201.897622823715, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 530088, "time": 17202.209947109222, "eval_episode/length": 105.0, "eval_episode/score": 0.671875, "eval_episode/reward_rate": 0.009433962264150943}
{"step": 530088, "time": 17202.670609474182, "eval_episode/length": 78.0, "eval_episode/score": 0.7562500238418579, "eval_episode/reward_rate": 0.012658227848101266}
{"step": 530088, "time": 17203.328019618988, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 530088, "time": 17203.783460378647, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17203.794454813004, "eval_episode/length": 89.0, "eval_episode/score": 0.721875011920929, "eval_episode/reward_rate": 0.011111111111111112}
{"step": 530088, "time": 17203.803236722946, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17203.816509246826, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17203.825724840164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530088, "time": 17203.837760210037, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 530128, "time": 17205.307637929916, "episode/length": 135.0, "episode/score": 0.6080430722680035, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.02991804415370325}
{"step": 530136, "time": 17205.343042373657, "episode/length": 73.0, "episode/score": 0.8009799672371969, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.029104963535189654}
{"step": 530168, "time": 17206.337212324142, "episode/length": 288.0, "episode/score": 0.026685331850444527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026685331850444527}
{"step": 530336, "time": 17211.770305871964, "episode/length": 44.0, "episode/score": 0.8750892957247629, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.012589310026385192}
{"step": 530408, "time": 17213.8119597435, "episode/length": 62.0, "episode/score": 0.8266591422856777, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.020409180286549145}
{"step": 530584, "time": 17219.274669647217, "episode/length": 136.0, "episode/score": 0.6150902403596774, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.0400902623505317}
{"step": 530768, "time": 17225.191110372543, "episode/length": 79.0, "episode/score": 0.7749241212832771, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.021799118428191377}
{"step": 530920, "time": 17229.675415992737, "episode/length": 97.0, "episode/score": 0.7215696288948266, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.02469467287653515}
{"step": 531056, "time": 17234.19261264801, "episode/length": 288.0, "episode/score": 0.040838608025069334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040838608025069334}
{"step": 531192, "time": 17238.20021700859, "episode/length": 97.0, "episode/score": 0.7280267832421714, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03115182521571569}
{"step": 531208, "time": 17238.704045295715, "episode/length": 108.0, "episode/score": 0.6969426608767435, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.03444265516657197}
{"step": 531441, "time": 17246.67400407791, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.258753380408654, "train/action_min": 0.0, "train/action_std": 1.6972875381127381, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.010617055297375489, "train/actor_opt_grad_steps": 32140.0, "train/actor_opt_loss": -6.198644392154155, "train/adv_mag": 1.124726211413359, "train/adv_max": 0.3500624974568685, "train/adv_mean": 0.003958044956459325, "train/adv_min": -1.0988084997886267, "train/adv_std": 0.03951407464650961, "train/cont_avg": 0.995332532051282, "train/cont_loss_mean": 0.014622923081072095, "train/cont_loss_std": 0.20969832592810958, "train/cont_neg_acc": 0.3801260437661161, "train/cont_neg_loss": 2.478914777530008, "train/cont_pos_acc": 0.9998138054823265, "train/cont_pos_loss": 0.003206761435378725, "train/cont_pred": 0.9952663106796069, "train/cont_rate": 0.995332532051282, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.44127823289197227, "train/extr_critic_critic_opt_grad_steps": 32140.0, "train/extr_critic_critic_opt_loss": 10757.778881209935, "train/extr_critic_mag": 1.3472368815006355, "train/extr_critic_max": 1.3472368815006355, "train/extr_critic_mean": 1.288156460493039, "train/extr_critic_min": 1.1286467081461198, "train/extr_critic_std": 0.01745577918795439, "train/extr_return_normed_mag": 1.1150297238276554, "train/extr_return_normed_max": 0.32195423749776986, "train/extr_return_normed_mean": 0.03752675106605658, "train/extr_return_normed_min": -1.0871615232565464, "train/extr_return_normed_std": 0.043764694636830914, "train/extr_return_rate": 0.9987650700104542, "train/extr_return_raw_mag": 1.5765419415938549, "train/extr_return_raw_max": 1.5765419415938549, "train/extr_return_raw_mean": 1.2921145194616073, "train/extr_return_raw_min": 0.16742618083953859, "train/extr_return_raw_std": 0.043764694636830914, "train/extr_reward_mag": 0.3671318995646941, "train/extr_reward_max": 0.3671318995646941, "train/extr_reward_mean": 0.002826273228185108, "train/extr_reward_min": 4.8319498697916664e-06, "train/extr_reward_std": 0.010698156125652484, "train/image_loss_mean": 0.10139048596223195, "train/image_loss_std": 0.10252456111021531, "train/model_loss_mean": 0.7345079351694156, "train/model_loss_std": 0.38235597748022815, "train/model_opt_grad_norm": 24.24920565776336, "train/model_opt_grad_steps": 32110.79487179487, "train/model_opt_loss": 3347.7411270532853, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4564.102564102564, "train/policy_entropy_mag": 1.3079657175602057, "train/policy_entropy_max": 1.3079657175602057, "train/policy_entropy_mean": 0.11005313587494385, "train/policy_entropy_min": 0.06468659333693676, "train/policy_entropy_std": 0.13987612693737714, "train/policy_logprob_mag": 6.551080224452875, "train/policy_logprob_max": -0.008608143972471739, "train/policy_logprob_mean": -0.10982069957714814, "train/policy_logprob_min": -6.551080224452875, "train/policy_logprob_std": 0.6460381837991568, "train/policy_randomness_mag": 0.6721614513641748, "train/policy_randomness_max": 0.6721614513641748, "train/policy_randomness_mean": 0.05655612773620165, "train/policy_randomness_min": 0.033242335877357386, "train/policy_randomness_std": 0.07188211394808232, "train/post_ent_mag": 12.413766772930439, "train/post_ent_max": 12.413766772930439, "train/post_ent_mean": 12.036937522888184, "train/post_ent_min": 11.812795903132512, "train/post_ent_std": 0.11895984502939078, "train/prior_ent_mag": 11.883744885371282, "train/prior_ent_max": 11.883744885371282, "train/prior_ent_mean": 10.307076302552835, "train/prior_ent_min": 9.390356176327437, "train/prior_ent_std": 0.3479301932530525, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.001417331937745285, "train/reward_loss_mean": 0.018494501461585364, "train/reward_loss_std": 0.1717583762625089, "train/reward_max_data": 0.6386654066196523, "train/reward_max_pred": 0.1762023687362671, "train/reward_neg_acc": 0.9997490393809784, "train/reward_neg_loss": 0.010638100751795066, "train/reward_pos_acc": 0.17979651299673458, "train/reward_pos_loss": 4.148742692415104, "train/reward_pred": 0.0011697475159636293, "train/reward_rate": 0.0019180689102564102, "train_stats/mean_log_entropy": 0.08782031516665997, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019141916185617447, "report/cont_loss_std": 0.23207297921180725, "report/cont_neg_acc": 0.2857142984867096, "report/cont_neg_loss": 2.161747694015503, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004394382704049349, "report/cont_pred": 0.9934481382369995, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0985000729560852, "report/image_loss_std": 0.1174134835600853, "report/model_loss_mean": 0.7406229972839355, "report/model_loss_std": 0.42602598667144775, "report/post_ent_mag": 11.58660888671875, "report/post_ent_max": 11.58660888671875, "report/post_ent_mean": 11.294075012207031, "report/post_ent_min": 11.108224868774414, "report/post_ent_std": 0.102312833070755, "report/prior_ent_mag": 11.470036506652832, "report/prior_ent_max": 11.470036506652832, "report/prior_ent_mean": 9.834393501281738, "report/prior_ent_min": 8.917867660522461, "report/prior_ent_std": 0.40176671743392944, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0023383379448205233, "report/reward_loss_mean": 0.022981008514761925, "report/reward_loss_std": 0.1905061900615692, "report/reward_max_data": 0.7094675898551941, "report/reward_max_pred": 0.5946613550186157, "report/reward_neg_acc": 0.9970587491989136, "report/reward_neg_loss": 0.012627500109374523, "report/reward_pos_acc": 0.5, "report/reward_pos_loss": 2.663125514984131, "report/reward_pred": 0.0027157531585544348, "report/reward_rate": 0.00390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02817675471305847, "eval/cont_loss_std": 0.43971654772758484, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.917839050292969, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.005080040544271469, "eval/cont_pred": 0.9957457780838013, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.154920756816864, "eval/image_loss_std": 0.12520329654216766, "eval/model_loss_mean": 0.7970468997955322, "eval/model_loss_std": 0.6107053160667419, "eval/post_ent_mag": 11.584961891174316, "eval/post_ent_max": 11.584961891174316, "eval/post_ent_mean": 11.273193359375, "eval/post_ent_min": 11.101919174194336, "eval/post_ent_std": 0.10339682549238205, "eval/prior_ent_mag": 11.494649887084961, "eval/prior_ent_max": 11.494649887084961, "eval/prior_ent_mean": 9.839361190795898, "eval/prior_ent_min": 8.93884563446045, "eval/prior_ent_std": 0.3776162564754486, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0015075684059411287, "eval/reward_loss_mean": 0.013949393294751644, "eval/reward_loss_std": 0.2675835192203522, "eval/reward_max_data": 0.793749988079071, "eval/reward_max_pred": 0.05640459060668945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.002165755722671747, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 6.035388469696045, "eval/reward_pred": 0.0005554074887186289, "eval/reward_rate": 0.001953125, "replay/size": 530937.0, "replay/inserts": 31336.0, "replay/samples": 31328.0, "replay/insert_wait_avg": 1.1902440406851905e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.391371692895158e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4776.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0192693777419815e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0057663917542, "timer/env.step_count": 3917.0, "timer/env.step_total": 36.15622878074646, "timer/env.step_frac": 0.03615602029096919, "timer/env.step_avg": 0.009230591978745586, "timer/env.step_min": 0.007431745529174805, "timer/env.step_max": 0.03930234909057617, "timer/replay._sample_count": 31328.0, "timer/replay._sample_total": 15.869539737701416, "timer/replay._sample_frac": 0.01586944822824601, "timer/replay._sample_avg": 0.0005065608956110003, "timer/replay._sample_min": 0.00040030479431152344, "timer/replay._sample_max": 0.028507471084594727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4514.0, "timer/agent.policy_total": 43.876625776290894, "timer/agent.policy_frac": 0.04387637276793676, "timer/agent.policy_avg": 0.009720120907463645, "timer/agent.policy_min": 0.00839853286743164, "timer/agent.policy_max": 0.08291411399841309, "timer/dataset_train_count": 1958.0, "timer/dataset_train_total": 0.2025315761566162, "timer/dataset_train_frac": 0.0002025304082869399, "timer/dataset_train_avg": 0.00010343798577968141, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0004181861877441406, "timer/agent.train_count": 1958.0, "timer/agent.train_total": 871.4486181735992, "timer/agent.train_frac": 0.8714435930884499, "timer/agent.train_avg": 0.44507079579856956, "timer/agent.train_min": 0.43054676055908203, "timer/agent.train_max": 0.5841221809387207, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472226619720459, "timer/agent.report_frac": 0.00047222389669247496, "timer/agent.report_avg": 0.2361133098602295, "timer/agent.report_min": 0.22849535942077637, "timer/agent.report_max": 0.24373126029968262, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.9802150536820202e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 31.335316552616703}
{"step": 531488, "time": 17248.357784748077, "episode/length": 89.0, "episode/score": 0.7439592456823902, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.02208424282730448}
{"step": 531544, "time": 17249.875283241272, "episode/length": 171.0, "episode/score": 0.5061699068000394, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.040544918939247054}
{"step": 531776, "time": 17257.363095760345, "episode/length": 106.0, "episode/score": 0.6873976644438926, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.018647699473262946}
{"step": 531896, "time": 17260.94236421585, "episode/length": 163.0, "episode/score": 0.5316768009648172, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.04105179222784727}
{"step": 531944, "time": 17262.597526073456, "episode/length": 110.0, "episode/score": 0.689670461534206, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.03342048464264735}
{"step": 532096, "time": 17267.589291095734, "episode/length": 75.0, "episode/score": 0.7863834174372073, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.02075842951529694}
{"step": 532328, "time": 17274.74047422409, "episode/length": 288.0, "episode/score": 0.03832258193722282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03832258193722282}
{"step": 532336, "time": 17275.222401857376, "episode/length": 140.0, "episode/score": 0.5943419722564727, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.03184198132231586}
{"step": 532432, "time": 17278.239099264145, "episode/length": 110.0, "episode/score": 0.6721801219218833, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.01593014503032464}
{"step": 532616, "time": 17284.23504781723, "episode/length": 89.0, "episode/score": 0.732252452187538, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.010377417049028281}
{"step": 532632, "time": 17284.73941373825, "episode/length": 85.0, "episode/score": 0.7573468083486432, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.02297183457119445}
{"step": 532688, "time": 17286.708709716797, "episode/length": 73.0, "episode/score": 0.7965400427447094, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.02466502796869463}
{"step": 532752, "time": 17288.727694511414, "episode/length": 121.0, "episode/score": 0.640892631597751, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.019017657677693478}
{"step": 533224, "time": 17303.313326358795, "episode/length": 58.0, "episode/score": 0.8337526531102526, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.015002606050813938}
{"step": 533376, "time": 17308.271067619324, "episode/length": 18.0, "episode/score": 0.9560775397542329, "episode/reward_rate": 0.05263157894736842, "episode/intrinsic_return": 0.01232752799046466}
{"step": 533400, "time": 17308.82155108452, "episode/length": 120.0, "episode/score": 0.6499141683424341, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.02491414512485335}
{"step": 533504, "time": 17312.277862787247, "episode/length": 288.0, "episode/score": 0.029705576972730796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029705576972730796}
{"step": 533552, "time": 17313.796437978745, "episode/length": 151.0, "episode/score": 0.5653746087907052, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.037249591018451156}
{"step": 533560, "time": 17313.83173584938, "episode/length": 117.0, "episode/score": 0.6549785834477575, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.02060357917531519}
{"step": 533832, "time": 17322.372114896774, "episode/length": 33.0, "episode/score": 0.9090803940716796, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.01220538737197785}
{"step": 534128, "time": 17331.805883169174, "episode/length": 90.0, "episode/score": 0.729477594731236, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.010727608890249485}
{"step": 534168, "time": 17332.83646583557, "episode/length": 191.0, "episode/score": 0.43053887779620936, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.02741389726958232}
{"step": 534408, "time": 17340.2990090847, "episode/length": 112.0, "episode/score": 0.6743233128668749, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.02432334826295346}
{"step": 534640, "time": 17347.74302124977, "episode/length": 288.0, "episode/score": 0.049018575868473135, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049018575868473135}
{"step": 534864, "time": 17354.862374782562, "episode/length": 91.0, "episode/score": 0.7360321461063677, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.020407129912996425}
{"step": 534992, "time": 17358.857714891434, "episode/length": 144.0, "episode/score": 0.5876299126480262, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.03762992694964851}
{"step": 535000, "time": 17358.894331216812, "episode/length": 288.0, "episode/score": 0.04761583999322738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04761583999322738}
{"step": 535032, "time": 17359.899372577667, "episode/length": 77.0, "episode/score": 0.7734120048766897, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.014037040272768309}
{"step": 535072, "time": 17361.381764411926, "episode/length": 53.0, "episode/score": 0.8512959711451344, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.016920956369119722}
{"step": 535096, "time": 17361.91261124611, "episode/length": 115.0, "episode/score": 0.6690768576560799, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.02845184105962062}
{"step": 535200, "time": 17365.395978450775, "episode/length": 41.0, "episode/score": 0.8811172272077954, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.009242248194567537}
{"step": 535384, "time": 17370.890732765198, "episode/length": 22.0, "episode/score": 0.9403850136476137, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.009135056072267389}
{"step": 535392, "time": 17371.36721277237, "episode/length": 48.0, "episode/score": 0.8677390655411443, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.017739055858299935}
{"step": 535632, "time": 17378.862118959427, "episode/length": 79.0, "episode/score": 0.7661297813814656, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.013004767415992546}
{"step": 535688, "time": 17380.388884067535, "episode/length": 288.0, "episode/score": 0.03423175902403841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03423175902403841}
{"step": 535864, "time": 17385.948143959045, "episode/length": 288.0, "episode/score": 0.03896518082481748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03896518082481748}
{"step": 536040, "time": 17391.436538219452, "episode/length": 80.0, "episode/score": 0.7681226916221249, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.018122689577580786}
{"step": 536080, "time": 17392.89989209175, "episode/length": 125.0, "episode/score": 0.6330597701955014, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.023684768150957325}
{"step": 536256, "time": 17398.35660290718, "episode/length": 152.0, "episode/score": 0.5537724297375917, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.02877242388626655}
{"step": 536384, "time": 17402.355646133423, "episode/length": 42.0, "episode/score": 0.8784768411625521, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.00972687507433534}
{"step": 536432, "time": 17403.893383026123, "episode/length": 92.0, "episode/score": 0.723967851722108, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.01146789270612203}
{"step": 536552, "time": 17407.473667383194, "episode/length": 145.0, "episode/score": 0.5724897223947778, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.025614700144899416}
{"step": 536672, "time": 17411.548982858658, "episode/length": 51.0, "episode/score": 0.8525811505716092, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.011956168531582989}
{"step": 536704, "time": 17412.650760173798, "episode/length": 133.0, "episode/score": 0.6216921134090114, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.0373170729706942}
{"step": 536776, "time": 17414.728276252747, "episode/length": 86.0, "episode/score": 0.7468817415566207, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.015631751433005547}
{"step": 536864, "time": 17417.743316411972, "episode/length": 59.0, "episode/score": 0.8249635520127185, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.009338510398606559}
{"step": 536872, "time": 17417.780300617218, "episode/length": 125.0, "episode/score": 0.6323247578618805, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.02294976390092529}
{"step": 537208, "time": 17428.311091899872, "episode/length": 53.0, "episode/score": 0.8455937907583007, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.011218778470663437}
{"step": 537248, "time": 17429.801858901978, "episode/length": 86.0, "episode/score": 0.7508264120231729, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.019576421899557772}
{"step": 537408, "time": 17434.79266309738, "episode/length": 288.0, "episode/score": 0.03521982971426496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03521982971426496}
{"step": 537544, "time": 17438.79259443283, "episode/length": 108.0, "episode/score": 0.6846250575123918, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.022125052253329613}
{"step": 537712, "time": 17444.365008592606, "episode/length": 104.0, "episode/score": 0.6919442176316011, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.016944205790707656}
{"step": 537912, "time": 17450.364043712616, "episode/length": 24.0, "episode/score": 0.928663988559947, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.003663959947971307}
{"step": 537936, "time": 17451.33276438713, "episode/length": 65.0, "episode/score": 0.8067226784149, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.009847655692084345}
{"step": 537968, "time": 17452.3259203434, "episode/length": 52.0, "episode/score": 0.8461374228850218, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.008637422628908098}
{"step": 537984, "time": 17452.830285787582, "episode/length": 159.0, "episode/score": 0.5301602850307177, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.027035278144751373}
{"step": 538016, "time": 17453.830300092697, "episode/length": 143.0, "episode/score": 0.5770501522501661, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.023925134447353003}
{"step": 538360, "time": 17464.45034146309, "episode/length": 48.0, "episode/score": 0.860904901125906, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.01090487809895535}
{"step": 538480, "time": 17468.38259267807, "episode/length": 70.0, "episode/score": 0.7983451724610688, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.017095158141984257}
{"step": 538504, "time": 17468.91216444969, "episode/length": 70.0, "episode/score": 0.8054392937360433, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.024189279416958698}
{"step": 538592, "time": 17471.9715924263, "episode/length": 172.0, "episode/score": 0.4993353215500065, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.036835308429999714}
{"step": 538624, "time": 17472.96709871292, "episode/length": 75.0, "episode/score": 0.7828934213659409, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.017268407046856282}
{"step": 538744, "time": 17476.484614133835, "episode/length": 94.0, "episode/score": 0.7214541941698656, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.015204158907664578}
{"step": 538744, "time": 17476.493906259537, "episode/length": 288.0, "episode/score": 0.02902985678974801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02902985678974801}
{"step": 538760, "time": 17476.99346923828, "episode/length": 49.0, "episode/score": 0.8533269233619194, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.006451903262814085}
{"step": 539368, "time": 17495.862499952316, "episode/length": 77.0, "episode/score": 0.7680486939243565, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.008673709588038037}
{"step": 539424, "time": 17497.813316583633, "episode/length": 103.0, "episode/score": 0.7021093062535328, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.023984283226582193}
{"step": 539560, "time": 17501.9274289608, "episode/length": 288.0, "episode/score": 0.03702048035017924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03702048035017924}
{"step": 539616, "time": 17503.91546034813, "episode/length": 141.0, "episode/score": 0.5756944324068627, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.016319414932922882}
{"step": 539872, "time": 17512.00527572632, "episode/length": 140.0, "episode/score": 0.5928960091619047, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.0303960009837283}
{"step": 539920, "time": 17513.50303030014, "episode/length": 68.0, "episode/score": 0.7943502952755352, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.006850291573528011}
{"step": 539960, "time": 17514.54587340355, "episode/length": 149.0, "episode/score": 0.554984523579833, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.020609531798754688}
{"step": 540072, "time": 17518.754719734192, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 540072, "time": 17518.76093196869, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 540072, "time": 17518.955729484558, "eval_episode/length": 53.0, "eval_episode/score": 0.8343750238418579, "eval_episode/reward_rate": 0.018518518518518517}
{"step": 540072, "time": 17519.498703718185, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 540072, "time": 17519.800876379013, "eval_episode/length": 101.0, "eval_episode/score": 0.684374988079071, "eval_episode/reward_rate": 0.00980392156862745}
{"step": 540072, "time": 17520.04567027092, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 540072, "time": 17520.395273447037, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 540072, "time": 17520.49824142456, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 540112, "time": 17521.983211040497, "episode/length": 68.0, "episode/score": 0.8125627306237675, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.025062692462824998}
{"step": 540152, "time": 17523.02770090103, "episode/length": 66.0, "episode/score": 0.8051774441610178, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.011427474213633104}
{"step": 540256, "time": 17526.516136407852, "episode/length": 103.0, "episode/score": 0.6935809734688974, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.015455964731927452}
{"step": 540256, "time": 17526.525238513947, "episode/length": 203.0, "episode/score": 0.398979154331073, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.03335416050981621}
{"step": 540600, "time": 17537.16852235794, "episode/length": 55.0, "episode/score": 0.8365772952290627, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.008452310333950663}
{"step": 540704, "time": 17541.09523653984, "episode/length": 92.0, "episode/score": 0.7380263147935011, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.0255263587752097}
{"step": 540816, "time": 17544.576676130295, "episode/length": 69.0, "episode/score": 0.7942776104721361, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.009902598769485849}
{"step": 540816, "time": 17544.588541030884, "episode/length": 288.0, "episode/score": 0.042083699088038884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042083699088038884}
{"step": 541552, "time": 17567.541139364243, "episode/length": 203.0, "episode/score": 0.3962634232615301, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.030638429440273285}
{"step": 542104, "time": 17584.467895269394, "episode/length": 68.0, "episode/score": 0.7959402234544655, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.00844022272104894}
{"step": 542184, "time": 17586.958315849304, "episode/length": 288.0, "episode/score": 0.03206781852162521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03206781852162521}
{"step": 542424, "time": 17594.535558462143, "episode/length": 288.0, "episode/score": 0.031247832051121804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031247832051121804}
{"step": 542568, "time": 17599.025686502457, "episode/length": 288.0, "episode/score": 0.01935045561390325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01935045561390325}
{"step": 542912, "time": 17609.96378135681, "episode/length": 288.0, "episode/score": 0.03134691653201571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03134691653201571}
{"step": 542976, "time": 17611.954874038696, "episode/length": 98.0, "episode/score": 0.7095138162768535, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.01576381056668197}
{"step": 543016, "time": 17613.0038189888, "episode/length": 288.0, "episode/score": 0.03266025640760972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03266025640760972}
{"step": 543128, "time": 17616.477644443512, "episode/length": 288.0, "episode/score": 0.038235182576841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038235182576841}
{"step": 543128, "time": 17616.485882520676, "episode/length": 288.0, "episode/score": 0.032666369365870196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032666369365870196}
{"step": 543672, "time": 17633.52703475952, "episode/length": 155.0, "episode/score": 0.5414462103005349, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.02582123340897624}
{"step": 543888, "time": 17640.44532060623, "episode/length": 94.0, "episode/score": 0.7194769944836708, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.013226994640831435}
{"step": 543896, "time": 17640.480831623077, "episode/length": 122.0, "episode/score": 0.6528804571668161, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.03413047691958582}
{"step": 544032, "time": 17644.919513702393, "episode/length": 126.0, "episode/score": 0.6304546288070583, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.024204611333118464}
{"step": 544416, "time": 17656.94841837883, "episode/length": 288.0, "episode/score": 0.03283054295764032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03283054295764032}
{"step": 544512, "time": 17659.969067573547, "episode/length": 104.0, "episode/score": 0.6973399290465068, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.02233990996603552}
{"step": 544608, "time": 17662.984935998917, "episode/length": 89.0, "episode/score": 0.742567184623681, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.020692192842602708}
{"step": 544664, "time": 17664.509027004242, "episode/length": 95.0, "episode/score": 0.7267976839351604, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.02367268415343915}
{"step": 544880, "time": 17671.42933011055, "episode/length": 288.0, "episode/score": 0.02213386524562111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02213386524562111}
{"step": 544952, "time": 17673.496541261673, "episode/length": 42.0, "episode/score": 0.8814045239905681, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.012654518437557272}
{"step": 545288, "time": 17684.080924987793, "episode/length": 288.0, "episode/score": 0.021871280251787084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021871280251787084}
{"step": 545416, "time": 17688.07987332344, "episode/length": 66.0, "episode/score": 0.8159125225645312, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.022162511144188102}
{"step": 545440, "time": 17689.050051927567, "episode/length": 288.0, "episode/score": 0.033851719182052875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033851719182052875}
{"step": 545784, "time": 17699.530546426773, "episode/length": 103.0, "episode/score": 0.6997327391643466, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.021607701003404145}
{"step": 545808, "time": 17700.50037431717, "episode/length": 64.0, "episode/score": 0.807953768468451, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.00795374938797977}
{"step": 545880, "time": 17702.53907418251, "episode/length": 57.0, "episode/score": 0.837282275675193, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.015407270122182126}
{"step": 546080, "time": 17708.975492239, "episode/length": 79.0, "episode/score": 0.7720999929533718, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.018974951637574122}
{"step": 546344, "time": 17717.08166050911, "episode/length": 288.0, "episode/score": 0.023391149208521256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023391149208521256}
{"step": 546368, "time": 17718.08131337166, "episode/length": 72.0, "episode/score": 0.797391819785048, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.022391836467363646}
{"step": 546632, "time": 17726.05383682251, "episode/length": 35.0, "episode/score": 0.8993122703848258, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.008687262206649393}
{"step": 546728, "time": 17729.040016174316, "episode/length": 288.0, "episode/score": 0.017099635532531465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017099635532531465}
{"step": 546824, "time": 17732.010103464127, "episode/length": 288.0, "episode/score": 0.01565324274338309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01565324274338309}
{"step": 546864, "time": 17733.49240899086, "episode/length": 61.0, "episode/score": 0.8237808225223944, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.014405820124238744}
{"step": 546976, "time": 17736.97289609909, "episode/length": 288.0, "episode/score": 0.03233084339188963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03233084339188963}
{"step": 547280, "time": 17748.076478242874, "episode/length": 149.0, "episode/score": 0.5614468111791666, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.027071800073144914}
{"step": 547400, "time": 17751.583852291107, "episode/length": 198.0, "episode/score": 0.4191365322873253, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.037886523928705174}
{"step": 547424, "time": 17752.548506736755, "episode/length": 98.0, "episode/score": 0.7196037955263819, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.025853748343251937}
{"step": 547424, "time": 17752.555070638657, "episode/length": 86.0, "episode/score": 0.768751993673277, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.037501982252933885}
{"step": 547528, "time": 17755.60910820961, "episode/length": 87.0, "episode/score": 0.7510613107010613, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.022936320223834628}
{"step": 547608, "time": 17758.150795459747, "episode/length": 92.0, "episode/score": 0.7353504886843893, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.022850483131378496}
{"step": 547632, "time": 17759.160306215286, "episode/length": 81.0, "episode/score": 0.7712588028581422, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.024383806600894786}
{"step": 547816, "time": 17764.772965431213, "episode/length": 66.0, "episode/score": 0.817598331731574, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.023848335474326632}
{"step": 548032, "time": 17771.903714179993, "episode/length": 49.0, "episode/score": 0.8587087296481286, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.011833737867050331}
{"step": 548192, "time": 17776.9498796463, "episode/length": 95.0, "episode/score": 0.740726060373504, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03760103703223194}
{"step": 548192, "time": 17776.95772767067, "episode/length": 288.0, "episode/score": 0.03590456030792666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03590456030792666}
{"step": 548200, "time": 17776.99506521225, "episode/length": 99.0, "episode/score": 0.7243511930935256, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03372617299442027}
{"step": 548328, "time": 17780.97733592987, "episode/length": 99.0, "episode/score": 0.7291594380957349, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.038534419015263666}
{"step": 548408, "time": 17783.464317560196, "episode/length": 99.0, "episode/score": 0.7235080333049382, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0328830415238599}
{"step": 548440, "time": 17784.479482650757, "episode/length": 126.0, "episode/score": 0.641119093849511, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.03486907637557124}
{"step": 548568, "time": 17788.459611177444, "episode/length": 66.0, "episode/score": 0.8103031152842277, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.016553145336843045}
{"step": 548576, "time": 17788.93614578247, "episode/length": 94.0, "episode/score": 0.7357011711467294, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.029451177357486813}
{"step": 548624, "time": 17790.456960439682, "episode/length": 36.0, "episode/score": 0.8977890320858251, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.010289035828577653}
{"step": 548688, "time": 17792.450365781784, "episode/length": 61.0, "episode/score": 0.8253698183467577, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.01599484839937304}
{"step": 548728, "time": 17793.47368979454, "episode/length": 66.0, "episode/score": 0.8180964763679412, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.024346458894001444}
{"step": 549000, "time": 17802.58295941353, "episode/length": 33.0, "episode/score": 0.9073936800442652, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.010518676342258004}
{"step": 549104, "time": 17806.05131840706, "episode/length": 12.0, "episode/score": 0.9717948741523514, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.009294898212488079}
{"step": 549144, "time": 17807.072194337845, "episode/length": 91.0, "episode/score": 0.7398985425751334, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.024273569600950395}
{"step": 549224, "time": 17809.54830813408, "episode/length": 74.0, "episode/score": 0.7904938770806211, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.021743865377970906}
{"step": 549328, "time": 17813.0241420269, "episode/length": 94.0, "episode/score": 0.7441434153043929, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0378934264919053}
{"step": 549336, "time": 17813.0603351593, "episode/length": 111.0, "episode/score": 0.6855116722767889, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.03238668010862966}
{"step": 549496, "time": 17818.043152809143, "episode/length": 48.0, "episode/score": 0.8659990839970533, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.015999075260083373}
{"step": 549808, "time": 17827.97399353981, "episode/length": 72.0, "episode/score": 0.8001970495188289, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.025197069271598593}
{"step": 549912, "time": 17831.00345134735, "episode/length": 12.0, "episode/score": 0.9675331187594338, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.005033154679381369}
{"step": 550056, "time": 17836.70232772827, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 550056, "time": 17837.18567967415, "eval_episode/length": 94.0, "eval_episode/score": 0.706250011920929, "eval_episode/reward_rate": 0.010526315789473684}
{"step": 550056, "time": 17837.20877814293, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 550056, "time": 17838.108181476593, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 550056, "time": 17838.43224811554, "eval_episode/length": 131.0, "eval_episode/score": 0.590624988079071, "eval_episode/reward_rate": 0.007575757575757576}
{"step": 550056, "time": 17839.08032131195, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 550056, "time": 17839.3998606205, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 550056, "time": 17840.311767578125, "eval_episode/length": 243.0, "eval_episode/score": 0.24062499403953552, "eval_episode/reward_rate": 0.004098360655737705}
{"step": 550072, "time": 17840.819639205933, "episode/length": 91.0, "episode/score": 0.7421348679089306, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.02650987165168317}
{"step": 550080, "time": 17841.291224241257, "episode/length": 93.0, "episode/score": 0.7410273835819225, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.03165237181815428}
{"step": 550368, "time": 17850.218494176865, "episode/length": 56.0, "episode/score": 0.8476647325910562, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.0226647373524429}
{"step": 550512, "time": 17854.70628595352, "episode/length": 288.0, "episode/score": 0.055062667421452716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055062667421452716}
{"step": 550888, "time": 17866.22955942154, "episode/length": 288.0, "episode/score": 0.042955328417235705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042955328417235705}
{"step": 550952, "time": 17868.222578525543, "episode/length": 108.0, "episode/score": 0.6970294406224866, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.03452942885871835}
{"step": 551000, "time": 17869.739874362946, "episode/length": 288.0, "episode/score": 0.04156415969157479, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04156415969157479}
{"step": 551096, "time": 17872.714191675186, "episode/length": 90.0, "episode/score": 0.7435026285721733, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.024752642731186825}
{"step": 551192, "time": 17875.695739269257, "episode/length": 84.0, "episode/score": 0.7579541891165604, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.020454203418182715}
{"step": 551288, "time": 17878.667285203934, "episode/length": 41.0, "episode/score": 0.8846047796433254, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.012729801634179694}
{"step": 551456, "time": 17884.115083694458, "episode/length": 288.0, "episode/score": 0.03738897715862777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03738897715862777}
{"step": 551808, "time": 17895.151705026627, "episode/length": 288.0, "episode/score": 0.046736332398836566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046736332398836566}
{"step": 551912, "time": 17898.154001235962, "episode/length": 127.0, "episode/score": 0.6372287215898496, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.034103738272165174}
{"step": 551976, "time": 17900.166461229324, "episode/length": 85.0, "episode/score": 0.7498329795814129, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.015457988647256116}
{"step": 552120, "time": 17904.638206243515, "episode/length": 127.0, "episode/score": 0.6367942914238824, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.03366932942475387}
{"step": 552384, "time": 17913.045152902603, "episode/length": 288.0, "episode/score": 0.043270158932841696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043270158932841696}
{"step": 552456, "time": 17915.07083272934, "episode/length": 67.0, "episode/score": 0.8066047736162432, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.01597981759795175}
{"step": 552800, "time": 17926.081105709076, "episode/length": 84.0, "episode/score": 0.7668726350985935, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.029372643317515212}
{"step": 552856, "time": 17927.600904226303, "episode/length": 109.0, "episode/score": 0.6765724148520462, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.017197403149395996}
{"step": 553008, "time": 17932.574253082275, "episode/length": 149.0, "episode/score": 0.5732849307586889, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.03890992790360315}
{"step": 553096, "time": 17935.092518806458, "episode/length": 88.0, "episode/score": 0.7457141220979224, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.020714070141764296}
{"step": 553192, "time": 17938.065128564835, "episode/length": 41.0, "episode/score": 0.8876572056456666, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.015782235698281966}
{"step": 553216, "time": 17939.031987667084, "episode/length": 94.0, "episode/score": 0.7322651758718735, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.026015181093100637}
{"step": 553312, "time": 17942.027362585068, "episode/length": 288.0, "episode/score": 0.016647074544550833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016647074544550833}
{"step": 553320, "time": 17942.065651893616, "episode/length": 265.0, "episode/score": 0.2196023272594516, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.04772732056557061}
{"step": 553560, "time": 17949.534383296967, "episode/length": 94.0, "episode/score": 0.7241722674972948, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.017922232358785095}
{"step": 553680, "time": 17953.582584619522, "episode/length": 72.0, "episode/score": 0.7897897783944359, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.014789825344735164}
{"step": 553680, "time": 17953.591337442398, "episode/length": 45.0, "episode/score": 0.8781576324496996, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.018782649591855716}
{"step": 553768, "time": 17956.114295959473, "episode/length": 288.0, "episode/score": 0.04560770030923322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04560770030923322}
{"step": 553800, "time": 17957.11171746254, "episode/length": 59.0, "episode/score": 0.8237918670971567, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.00816683857976841}
{"step": 553816, "time": 17957.613783597946, "episode/length": 100.0, "episode/score": 0.7029767244300729, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.01547669473688984}
{"step": 553968, "time": 17962.539719343185, "episode/length": 93.0, "episode/score": 0.728938315294954, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.01956327485663678}
{"step": 554176, "time": 17969.001633405685, "episode/length": 61.0, "episode/score": 0.8242040583541552, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.014829082353173817}
{"step": 554360, "time": 17974.511323928833, "episode/length": 99.0, "episode/score": 0.7124821540563175, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.021857112442205562}
{"step": 554424, "time": 17976.499089717865, "episode/length": 77.0, "episode/score": 0.7670693449142618, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.007694395335192894}
{"step": 554544, "time": 17980.46160054207, "episode/length": 90.0, "episode/score": 0.746429281061296, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.027679276972207845}
{"step": 554584, "time": 17981.5433781147, "episode/length": 112.0, "episode/score": 0.6649276957254528, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.014927729637236098}
{"step": 555248, "time": 18002.547383069992, "episode/length": 133.0, "episode/score": 0.5970145293232463, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.012639524064184116}
{"step": 555264, "time": 18003.05366897583, "episode/length": 89.0, "episode/score": 0.741800456034639, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.019925459218598007}
{"step": 555432, "time": 18008.05485033989, "episode/length": 105.0, "episode/score": 0.6964231426575225, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.02454816576596386}
{"step": 555504, "time": 18010.52583837509, "episode/length": 288.0, "episode/score": 0.04530101630393801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04530101630393801}
{"step": 555584, "time": 18013.09305024147, "episode/length": 152.0, "episode/score": 0.5564706688232377, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.03147070682410913}
{"step": 556008, "time": 18026.090648174286, "episode/length": 94.0, "episode/score": 0.7288255358714082, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.022575509631394652}
{"step": 556080, "time": 18028.547265529633, "episode/length": 288.0, "episode/score": 0.03446201960107942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03446201960107942}
{"step": 556280, "time": 18034.543937444687, "episode/length": 288.0, "episode/score": 0.027562638182558885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027562638182558885}
{"step": 556368, "time": 18037.498950242996, "episode/length": 137.0, "episode/score": 0.613113126033312, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.04123812123700077}
{"step": 556440, "time": 18039.540120363235, "episode/length": 106.0, "episode/score": 0.7020927466056719, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.0333427593415081}
{"step": 556464, "time": 18040.511429786682, "episode/length": 47.0, "episode/score": 0.872158787925855, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.019033812582620158}
{"step": 556736, "time": 18049.038901805878, "episode/length": 288.0, "episode/score": 0.012096823375031818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012096823375031818}
{"step": 556792, "time": 18050.575566530228, "episode/length": 63.0, "episode/score": 0.8176908637951783, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.014565840768227645}
{"step": 556808, "time": 18051.074872732162, "episode/length": 54.0, "episode/score": 0.8400752104855655, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.008825169169767832}
{"step": 557136, "time": 18061.966255426407, "episode/length": 86.0, "episode/score": 0.7646678045771296, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.0334177931567865}
{"step": 557376, "time": 18069.45908856392, "episode/length": 79.0, "episode/score": 0.7766572246407577, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.023532189378556723}
{"step": 557688, "time": 18079.079677820206, "episode/length": 38.0, "episode/score": 0.8980526618272506, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.016802638800299974}
{"step": 557744, "time": 18081.069850444794, "episode/length": 288.0, "episode/score": 0.03860215805187295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03860215805187295}
{"step": 557816, "time": 18083.090037345886, "episode/length": 288.0, "episode/score": 0.044882232717469606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044882232717469606}
{"step": 557936, "time": 18087.04079580307, "episode/length": 99.0, "episode/score": 0.7201301626009808, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.0295051363609673}
{"step": 558320, "time": 18098.977726459503, "episode/length": 288.0, "episode/score": 0.04689025554546333, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04689025554546333}
{"step": 558320, "time": 18098.985409736633, "episode/length": 62.0, "episode/score": 0.833453252435902, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.027203252936487843}
{"step": 558360, "time": 18100.024097681046, "episode/length": 83.0, "episode/score": 0.7735387714903936, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03291371825366696}
{"step": 558416, "time": 18102.11775135994, "episode/length": 83.0, "episode/score": 0.773285238235303, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03266020723390284}
{"step": 558488, "time": 18104.17109131813, "episode/length": 20.0, "episode/score": 0.9481722843754596, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.010672261034187613}
{"step": 558720, "time": 18111.73312854767, "episode/length": 44.0, "episode/score": 0.8837723042953485, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.021272278055334937}
{"step": 558776, "time": 18113.2783267498, "episode/length": 288.0, "episode/score": 0.05757729055369509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05757729055369509}
{"step": 558784, "time": 18113.759171247482, "episode/length": 45.0, "episode/score": 0.8779794263015219, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.018604396906653164}
{"step": 558880, "time": 18116.812811374664, "episode/length": 48.0, "episode/score": 0.869563546165864, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.01956354246385672}
{"step": 559016, "time": 18120.87837743759, "episode/length": 86.0, "episode/score": 0.7514029953138106, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.02015300745301829}
{"step": 559088, "time": 18123.354469776154, "episode/length": 143.0, "episode/score": 0.6011183325841785, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.04799330056414419}
{"step": 559104, "time": 18123.87116074562, "episode/length": 288.0, "episode/score": 0.050732179843294034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050732179843294034}
{"step": 559120, "time": 18124.380572080612, "episode/length": 288.0, "episode/score": 0.036035719352298656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036035719352298656}
{"step": 559440, "time": 18134.5448346138, "episode/length": 39.0, "episode/score": 0.8946169200160057, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.01649189377599214}
{"step": 559616, "time": 18140.010038137436, "episode/length": 103.0, "episode/score": 0.7099372791958558, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.031812270458885905}
{"step": 560040, "time": 18153.415439605713, "eval_episode/length": 21.0, "eval_episode/score": 0.934374988079071, "eval_episode/reward_rate": 0.045454545454545456}
{"step": 560040, "time": 18153.513928174973, "eval_episode/length": 26.0, "eval_episode/score": 0.918749988079071, "eval_episode/reward_rate": 0.037037037037037035}
{"step": 560040, "time": 18153.91713285446, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 560040, "time": 18153.95872449875, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 560040, "time": 18154.19734787941, "eval_episode/length": 63.0, "eval_episode/score": 0.8031250238418579, "eval_episode/reward_rate": 0.015625}
{"step": 560040, "time": 18154.64181113243, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 560040, "time": 18154.839560985565, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 560040, "time": 18154.981355905533, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 560192, "time": 18159.97553873062, "episode/length": 146.0, "episode/score": 0.5629606779924643, "episode/reward_rate": 0.006802721088435374, "episode/intrinsic_return": 0.019210685824305074}
{"step": 560216, "time": 18160.516023397446, "episode/length": 96.0, "episode/score": 0.7376076917853425, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.037607695528095064}
{"step": 560280, "time": 18162.661211252213, "episode/length": 148.0, "episode/score": 0.5783184455556238, "episode/reward_rate": 0.006711409395973154, "episode/intrinsic_return": 0.0408183983724939}
{"step": 560328, "time": 18164.186200380325, "episode/length": 88.0, "episode/score": 0.7605094838744435, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.0355094528730433}
{"step": 560568, "time": 18171.6798517704, "episode/length": 35.0, "episode/score": 0.9009232201226496, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.010298246345200823}
{"step": 561032, "time": 18186.13404560089, "episode/length": 288.0, "episode/score": 0.03304400265892582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03304400265892582}
{"step": 561088, "time": 18188.10633945465, "episode/length": 288.0, "episode/score": 0.05000070952269198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05000070952269198}
{"step": 561192, "time": 18191.122708320618, "episode/length": 288.0, "episode/score": 0.04425023333499212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04425023333499212}
{"step": 561216, "time": 18192.16631436348, "episode/length": 110.0, "episode/score": 0.7034195534447463, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.0471695248065771}
{"step": 561352, "time": 18196.171874523163, "episode/length": 39.0, "episode/score": 0.899863586131687, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.02173854557258892}
{"step": 561416, "time": 18198.18298816681, "episode/length": 288.0, "episode/score": 0.04731905350854504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04731905350854504}
{"step": 561504, "time": 18201.139115333557, "episode/length": 116.0, "episode/score": 0.6737283406087045, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.036228353344540665}
{"step": 561808, "time": 18210.61817932129, "episode/length": 48.0, "episode/score": 0.876991807689592, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.02699175520956487}
{"step": 561920, "time": 18214.1562666893, "episode/length": 103.0, "episode/score": 0.723986336424332, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.04586131339738131}
{"step": 562008, "time": 18216.703803777695, "episode/length": 98.0, "episode/score": 0.740817935384257, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.04706788290422992}
{"step": 562016, "time": 18217.18587064743, "episode/length": 63.0, "episode/score": 0.8368051663182996, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.03368014329134894}
{"step": 562024, "time": 18217.223024129868, "episode/length": 83.0, "episode/score": 0.7711815025704709, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.030556479543520254}
{"step": 562504, "time": 18232.31347799301, "episode/length": 288.0, "episode/score": 0.07593614512472868, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07593614512472868}
{"step": 562528, "time": 18233.316899061203, "episode/length": 288.0, "episode/score": 0.06522823166881153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06522823166881153}
{"step": 562584, "time": 18234.86359858513, "episode/length": 69.0, "episode/score": 0.8174278239387149, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.0330527976987014}
{"step": 562896, "time": 18244.941277503967, "episode/length": 121.0, "episode/score": 0.6507105381920155, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.02883552677167245}
{"step": 562937, "time": 18246.96618771553, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2874204374206855, "train/action_min": 0.0, "train/action_std": 1.7522202736230066, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01187765644154119, "train/actor_opt_grad_steps": 34100.0, "train/actor_opt_loss": -7.513215104473736, "train/adv_mag": 1.261298881266928, "train/adv_max": 0.41372426149203695, "train/adv_mean": 0.0037604820860587776, "train/adv_min": -1.2412140463209393, "train/adv_std": 0.040265838180663927, "train/cont_avg": 0.9953898318527918, "train/cont_loss_mean": 0.014799358558410846, "train/cont_loss_std": 0.21126173554357083, "train/cont_neg_acc": 0.3760077023353332, "train/cont_neg_loss": 2.478018169957571, "train/cont_pos_acc": 0.9998405551547327, "train/cont_pos_loss": 0.0033424760753922355, "train/cont_pred": 0.9951128660119729, "train/cont_rate": 0.9953898318527918, "train/dyn_loss_mean": 1.0000004066428558, "train/dyn_loss_std": 1.300527208347611e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.26618820401428617, "train/extr_critic_critic_opt_grad_steps": 34100.0, "train/extr_critic_critic_opt_loss": 12374.149711492702, "train/extr_critic_mag": 1.4906864650358402, "train/extr_critic_max": 1.4906864650358402, "train/extr_critic_mean": 1.427117106878213, "train/extr_critic_min": 1.1169312260477675, "train/extr_critic_std": 0.022058921856663857, "train/extr_return_normed_mag": 1.2477461680542998, "train/extr_return_normed_max": 0.30708362729416283, "train/extr_return_normed_mean": 0.04333686240509077, "train/extr_return_normed_min": -1.2327731157922504, "train/extr_return_normed_std": 0.04624213136467837, "train/extr_return_rate": 0.9989501186433782, "train/extr_return_raw_mag": 1.6946243441044377, "train/extr_return_raw_max": 1.6946243441044377, "train/extr_return_raw_mean": 1.4308776504497238, "train/extr_return_raw_min": 0.1547676010180246, "train/extr_return_raw_std": 0.04624213144031878, "train/extr_reward_mag": 0.3417592738485578, "train/extr_reward_max": 0.3417592738485578, "train/extr_reward_mean": 0.0028325585077568737, "train/extr_reward_min": 4.071874666940137e-06, "train/extr_reward_std": 0.009807053734761128, "train/image_loss_mean": 0.09800558794422198, "train/image_loss_std": 0.10282253848417157, "train/model_loss_mean": 0.73218697672568, "train/model_loss_std": 0.391004054982045, "train/model_opt_grad_norm": 23.418664260786407, "train/model_opt_grad_steps": 34069.17258883249, "train/model_opt_loss": 3849.5378219681947, "train/model_opt_model_opt_grad_overflow": 0.005076142131979695, "train/model_opt_model_opt_grad_scale": 5228.426395939086, "train/policy_entropy_mag": 1.2519275004488564, "train/policy_entropy_max": 1.2519275004488564, "train/policy_entropy_mean": 0.10570241798301638, "train/policy_entropy_min": 0.06468656579703849, "train/policy_entropy_std": 0.13528267316860595, "train/policy_logprob_mag": 6.5510802293186865, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.10575625682391492, "train/policy_logprob_min": -6.5510802293186865, "train/policy_logprob_std": 0.6432136974964046, "train/policy_randomness_mag": 0.6433635054506021, "train/policy_randomness_max": 0.6433635054506021, "train/policy_randomness_mean": 0.0543203005557738, "train/policy_randomness_min": 0.033242322107408254, "train/policy_randomness_std": 0.0695215453237749, "train/post_ent_mag": 11.826836968436458, "train/post_ent_max": 11.826836968436458, "train/post_ent_mean": 11.485955761168814, "train/post_ent_min": 11.271366356593099, "train/post_ent_std": 0.1126211960303602, "train/prior_ent_mag": 11.547946804065996, "train/prior_ent_max": 11.547946804065996, "train/prior_ent_mean": 9.932264497437453, "train/prior_ent_min": 9.023726429430967, "train/prior_ent_std": 0.34972399715239627, "train/rep_loss_mean": 1.0000004066428558, "train/rep_loss_std": 1.300527208347611e-05, "train/reward_avg": 0.0015515710465340558, "train/reward_loss_mean": 0.019381764108494758, "train/reward_loss_std": 0.17812052255184366, "train/reward_max_data": 0.6659561096652775, "train/reward_max_pred": 0.20642621989177568, "train/reward_neg_acc": 0.9996372648907191, "train/reward_neg_loss": 0.010968332984933847, "train/reward_pos_acc": 0.22129251888820103, "train/reward_pos_loss": 3.998593159743718, "train/reward_pred": 0.0013670007181755706, "train/reward_rate": 0.0020869685913705582, "train_stats/mean_log_entropy": 0.088032376542056, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.01654748246073723, "report/cont_loss_std": 0.2072046399116516, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.6225017309188843, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0039021724369376898, "report/cont_pred": 0.9922873973846436, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09849106520414352, "report/image_loss_std": 0.09267682582139969, "report/model_loss_mean": 0.7452715635299683, "report/model_loss_std": 0.5137714147567749, "report/post_ent_mag": 11.780359268188477, "report/post_ent_max": 11.780359268188477, "report/post_ent_mean": 11.445050239562988, "report/post_ent_min": 11.255428314208984, "report/post_ent_std": 0.11568978428840637, "report/prior_ent_mag": 12.008136749267578, "report/prior_ent_max": 12.008136749267578, "report/prior_ent_mean": 10.459321975708008, "report/prior_ent_min": 9.166167259216309, "report/prior_ent_std": 0.4002397358417511, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0033925215248018503, "report/reward_loss_mean": 0.030232958495616913, "report/reward_loss_std": 0.2819055914878845, "report/reward_max_data": 0.8377272486686707, "report/reward_max_pred": 0.5650342702865601, "report/reward_neg_acc": 0.9980372786521912, "report/reward_neg_loss": 0.011972447857260704, "report/reward_pos_acc": 0.20000000298023224, "report/reward_pos_loss": 3.7517249584198, "report/reward_pred": 0.002409628126770258, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.04026671499013901, "eval/cont_loss_std": 0.6020238399505615, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.436821937561035, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0034174846950918436, "eval/cont_pred": 0.99715256690979, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18620897829532623, "eval/image_loss_std": 0.14778470993041992, "eval/model_loss_mean": 0.8292942047119141, "eval/model_loss_std": 0.6220304369926453, "eval/post_ent_mag": 11.780067443847656, "eval/post_ent_max": 11.780067443847656, "eval/post_ent_mean": 11.436283111572266, "eval/post_ent_min": 11.26805305480957, "eval/post_ent_std": 0.11152945458889008, "eval/prior_ent_mag": 11.426950454711914, "eval/prior_ent_max": 11.426950454711914, "eval/prior_ent_mean": 10.376436233520508, "eval/prior_ent_min": 8.593914031982422, "eval/prior_ent_std": 0.4156557619571686, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0028184326365590096, "eval/reward_loss_std": 0.01977814920246601, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.08521032333374023, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0028184326365590096, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0006595316808670759, "eval/reward_rate": 0.0, "replay/size": 562433.0, "replay/inserts": 31496.0, "replay/samples": 31504.0, "replay/insert_wait_avg": 1.2061575932462778e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.390415928822717e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0274849363563026e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2764098644257, "timer/env.step_count": 3937.0, "timer/env.step_total": 36.27049446105957, "timer/env.step_frac": 0.03626047170899048, "timer/env.step_avg": 0.009212724018557168, "timer/env.step_min": 0.007470130920410156, "timer/env.step_max": 0.040100812911987305, "timer/replay._sample_count": 31504.0, "timer/replay._sample_total": 15.87337851524353, "timer/replay._sample_frac": 0.01586899216926945, "timer/replay._sample_avg": 0.0005038527969541496, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.009500980377197266, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4430.0, "timer/agent.policy_total": 43.58497428894043, "timer/agent.policy_frac": 0.04357293030118325, "timer/agent.policy_avg": 0.00983859464761635, "timer/agent.policy_min": 0.008075952529907227, "timer/agent.policy_max": 0.08098816871643066, "timer/dataset_train_count": 1969.0, "timer/dataset_train_total": 0.20462346076965332, "timer/dataset_train_frac": 0.00020456691645600973, "timer/dataset_train_avg": 0.00010392252959352631, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.0002980232238769531, "timer/agent.train_count": 1969.0, "timer/agent.train_total": 873.9307973384857, "timer/agent.train_frac": 0.873689300997247, "timer/agent.train_avg": 0.4438449961089313, "timer/agent.train_min": 0.43053102493286133, "timer/agent.train_max": 1.9225752353668213, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4790632724761963, "timer/agent.report_frac": 0.00047893089125347567, "timer/agent.report_avg": 0.23953163623809814, "timer/agent.report_min": 0.23311710357666016, "timer/agent.report_max": 0.24594616889953613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.81256181356886e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 31.486768514374887}
{"step": 563240, "time": 18256.25952577591, "episode/length": 91.0, "episode/score": 0.7375856771650433, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.021960665744700236}
{"step": 563384, "time": 18260.74072623253, "episode/length": 17.0, "episode/score": 0.9555293226216008, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.008654323122186725}
{"step": 563504, "time": 18264.70404934883, "episode/length": 288.0, "episode/score": 0.053410999703828566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053410999703828566}
{"step": 563584, "time": 18267.181232452393, "episode/length": 85.0, "episode/score": 0.757443635388654, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.023068612047381976}
{"step": 563624, "time": 18268.198621034622, "episode/length": 136.0, "episode/score": 0.6162938849296324, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.04129387350928937}
{"step": 563688, "time": 18270.190183401108, "episode/length": 37.0, "episode/score": 0.899970455048674, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.01559544949566316}
{"step": 564032, "time": 18281.101145982742, "episode/length": 65.0, "episode/score": 0.814306975462614, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.017431967284437633}
{"step": 564120, "time": 18283.710654973984, "episode/length": 288.0, "episode/score": 0.0367149636567774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0367149636567774}
{"step": 564200, "time": 18286.191260814667, "episode/length": 71.0, "episode/score": 0.7991593278896971, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.021034310415757318}
{"step": 564320, "time": 18290.152215242386, "episode/length": 288.0, "episode/score": 0.054747475646649946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054747475646649946}
{"step": 564328, "time": 18290.188575983047, "episode/length": 288.0, "episode/score": 0.03606739886743071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03606739886743071}
{"step": 564392, "time": 18292.173662662506, "episode/length": 100.0, "episode/score": 0.7158207364301461, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.028320756569996774}
{"step": 564656, "time": 18300.57430243492, "episode/length": 66.0, "episode/score": 0.8134907947185184, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.019740824771133703}
{"step": 564664, "time": 18300.61070537567, "episode/length": 121.0, "episode/score": 0.6584152499304992, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.036540253673251755}
{"step": 564664, "time": 18300.616631269455, "episode/length": 57.0, "episode/score": 0.8365726530053053, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.014697668668986807}
{"step": 564712, "time": 18302.103364229202, "episode/length": 84.0, "episode/score": 0.7670343002318987, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.02953430644265609}
{"step": 564784, "time": 18304.574612379074, "episode/length": 57.0, "episode/score": 0.8397555652901474, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.017880574812920713}
{"step": 564896, "time": 18308.05850315094, "episode/length": 288.0, "episode/score": 0.037322917163919556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037322917163919556}
{"step": 565024, "time": 18312.103065490723, "episode/length": 38.0, "episode/score": 0.8908684119442114, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.009618411210794875}
{"step": 565096, "time": 18314.128091335297, "episode/length": 38.0, "episode/score": 0.890693594156005, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.00944356622505893}
{"step": 565296, "time": 18321.051436662674, "episode/length": 112.0, "episode/score": 0.6710084155741924, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.02100841002118159}
{"step": 565312, "time": 18321.553917646408, "episode/length": 80.0, "episode/score": 0.7615355428432622, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.011535562983112868}
{"step": 565704, "time": 18333.52584171295, "episode/length": 50.0, "episode/score": 0.8507461017716196, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.00699609359344322}
{"step": 565744, "time": 18335.015859365463, "episode/length": 53.0, "episode/score": 0.8496276068260045, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.015252574805970198}
{"step": 566624, "time": 18362.464287281036, "episode/length": 114.0, "episode/score": 0.663571051930262, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.01982105814101942}
{"step": 566640, "time": 18362.96831393242, "episode/length": 288.0, "episode/score": 0.029901686752168644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029901686752168644}
{"step": 566744, "time": 18365.983546972275, "episode/length": 124.0, "episode/score": 0.6510886718633628, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.03858867202052352}
{"step": 566848, "time": 18369.452301740646, "episode/length": 218.0, "episode/score": 0.365916017613074, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.04716601539536214}
{"step": 566968, "time": 18373.065711021423, "episode/length": 288.0, "episode/score": 0.008822193004164092, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008822193004164092}
{"step": 566976, "time": 18373.540692567825, "episode/length": 288.0, "episode/score": 0.038766061685180375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038766061685180375}
{"step": 567128, "time": 18378.06907248497, "episode/length": 62.0, "episode/score": 0.8216042701914716, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.015354314173180228}
{"step": 567208, "time": 18380.571496248245, "episode/length": 288.0, "episode/score": 0.03497830708568017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03497830708568017}
{"step": 567232, "time": 18381.53822660446, "episode/length": 60.0, "episode/score": 0.825964407145193, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.01346442527687941}
{"step": 567336, "time": 18384.543367147446, "episode/length": 288.0, "episode/score": 0.04093719324043832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04093719324043832}
{"step": 567376, "time": 18386.006921052933, "episode/length": 65.0, "episode/score": 0.8146990651108581, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.017824083242544475}
{"step": 567480, "time": 18389.086549282074, "episode/length": 12.0, "episode/score": 0.9678492637063414, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.005349273229114715}
{"step": 567552, "time": 18391.52601623535, "episode/length": 39.0, "episode/score": 0.8955278917954956, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.017402880689473932}
{"step": 567552, "time": 18391.533900022507, "episode/length": 72.0, "episode/score": 0.794389996351299, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.019390005874072358}
{"step": 567936, "time": 18403.549839258194, "episode/length": 100.0, "episode/score": 0.7253492602209235, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03784926103583075}
{"step": 568064, "time": 18407.52612042427, "episode/length": 63.0, "episode/score": 0.8175376730714561, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.014412634910513589}
{"step": 568112, "time": 18409.04308104515, "episode/length": 112.0, "episode/score": 0.671670900268964, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.02167089471595318}
{"step": 568200, "time": 18411.574626922607, "episode/length": 32.0, "episode/score": 0.9084649715709929, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.008464966017982078}
{"step": 568232, "time": 18412.580098867416, "episode/length": 93.0, "episode/score": 0.7371593382511037, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.027784291067973754}
{"step": 568336, "time": 18416.06775355339, "episode/length": 12.0, "episode/score": 0.9670521488351369, "episode/reward_rate": 0.07692307692307693, "episode/intrinsic_return": 0.004552192816845491}
{"step": 568440, "time": 18419.10736846924, "episode/length": 137.0, "episode/score": 0.5870098727071422, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.015134888370823774}
{"step": 568712, "time": 18427.57475543022, "episode/length": 144.0, "episode/score": 0.5720385804684156, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.02203854520621462}
{"step": 568776, "time": 18429.601200819016, "episode/length": 88.0, "episode/score": 0.7491064490691315, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.02410642604218083}
{"step": 568952, "time": 18435.153247117996, "episode/length": 288.0, "episode/score": 0.029445155729035832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029445155729035832}
{"step": 569008, "time": 18437.101426124573, "episode/length": 83.0, "episode/score": 0.7730769693241655, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.03245193116322298}
{"step": 569128, "time": 18440.629618644714, "episode/length": 85.0, "episode/score": 0.757068916662547, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.022693893321275027}
{"step": 569144, "time": 18441.133317232132, "episode/length": 23.0, "episode/score": 0.9425343731104476, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.014409334949505137}
{"step": 569144, "time": 18441.14085483551, "episode/length": 117.0, "episode/score": 0.6738940237239603, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.03951902422454623}
{"step": 569288, "time": 18445.650542974472, "episode/length": 288.0, "episode/score": 0.0569519295693226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0569519295693226}
{"step": 569312, "time": 18446.627574443817, "episode/length": 149.0, "episode/score": 0.566828282196866, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.03245326209776067}
{"step": 569536, "time": 18453.577654361725, "episode/length": 48.0, "episode/score": 0.8639833356348845, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.013983304633484295}
{"step": 569592, "time": 18455.1193857193, "episode/length": 57.0, "episode/score": 0.844800596694995, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.022925591141984114}
{"step": 569784, "time": 18461.102709293365, "episode/length": 79.0, "episode/score": 0.7841529715951765, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.031027936332975514}
{"step": 569888, "time": 18464.658618450165, "episode/length": 43.0, "episode/score": 0.8775750798888566, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.011950047868822367}
{"step": 570024, "time": 18469.80675983429, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 570024, "time": 18470.611785411835, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 570024, "time": 18471.06378674507, "eval_episode/length": 136.0, "eval_episode/score": 0.574999988079071, "eval_episode/reward_rate": 0.0072992700729927005}
{"step": 570024, "time": 18471.128612041473, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 570024, "time": 18471.48064184189, "eval_episode/length": 158.0, "eval_episode/score": 0.5062500238418579, "eval_episode/reward_rate": 0.006289308176100629}
{"step": 570024, "time": 18471.946194648743, "eval_episode/length": 117.0, "eval_episode/score": 0.6343749761581421, "eval_episode/reward_rate": 0.00847457627118644}
{"step": 570024, "time": 18471.988224744797, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 570024, "time": 18472.387655973434, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 570080, "time": 18474.379576921463, "episode/length": 98.0, "episode/score": 0.7295053244877181, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.035755293486317896}
{"step": 570168, "time": 18476.898453950882, "episode/length": 106.0, "episode/score": 0.693797023288198, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.025047055348977665}
{"step": 570248, "time": 18479.396021604538, "episode/length": 81.0, "episode/score": 0.77095946618374, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.0240844487098002}
{"step": 570472, "time": 18486.37453198433, "episode/length": 37.0, "episode/score": 0.8933883019961968, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.009013343969741072}
{"step": 570576, "time": 18489.86645245552, "episode/length": 98.0, "episode/score": 0.7322152336240606, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.038465227913889066}
{"step": 570968, "time": 18501.940321207047, "episode/length": 89.0, "episode/score": 0.7509790864810384, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.029104089664997446}
{"step": 571024, "time": 18503.92376923561, "episode/length": 288.0, "episode/score": 0.0402383793602894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0402383793602894}
{"step": 571088, "time": 18505.90820479393, "episode/length": 288.0, "episode/score": 0.04897942854665871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04897942854665871}
{"step": 571240, "time": 18510.41808438301, "episode/length": 95.0, "episode/score": 0.7211478386315093, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.01802283454242115}
{"step": 571320, "time": 18512.94543504715, "episode/length": 288.0, "episode/score": 0.044209519051037205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044209519051037205}
{"step": 571416, "time": 18515.933520317078, "episode/length": 104.0, "episode/score": 0.709037978736319, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03403798494707644}
{"step": 571576, "time": 18520.906098604202, "episode/length": 186.0, "episode/score": 0.46376930022324814, "episode/reward_rate": 0.0053475935828877, "episode/intrinsic_return": 0.045019303966000734}
{"step": 571768, "time": 18526.96213078499, "episode/length": 99.0, "episode/score": 0.727907431489939, "episode/reward_rate": 0.01, "episode/intrinsic_return": 0.03728241139083366}
{"step": 571792, "time": 18527.951307058334, "episode/length": 95.0, "episode/score": 0.7310645629580677, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.027939558868979475}
{"step": 571904, "time": 18531.419323444366, "episode/length": 101.0, "episode/score": 0.7265715476431751, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.04219655240456177}
