{"step": 1560, "time": 119.14721131324768, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 1560, "time": 139.49727392196655, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 1560, "time": 142.81016063690186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 142.81940293312073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 142.8259847164154, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 142.8322467803955, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 142.83833003044128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 142.844322681427, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 142.85039710998535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 267.46874141693115, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.81085205078125, "train/action_min": 0.0, "train/action_std": 2.1745548248291016, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019850984681397676, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -2.8884811401367188, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.48725375533103943, "train/cont_loss_std": 0.2271682173013687, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.8271484375, "train/cont_pos_loss": 0.48725375533103943, "train/cont_pred": 0.6292036771774292, "train/cont_rate": 1.0, "train/dyn_loss_mean": 10.004053115844727, "train/dyn_loss_std": 0.4046754539012909, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 16.286163330078125, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 65189.46484375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5038.29541015625, "train/image_loss_std": 36.71002197265625, "train/model_loss_mean": 5050.3271484375, "train/model_loss_std": 36.69005584716797, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 50503272.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9401047229766846, "train/policy_entropy_max": 1.9401047229766846, "train/policy_entropy_mean": 1.6342231035232544, "train/policy_entropy_min": 0.7301688194274902, "train/policy_entropy_std": 0.18229885399341583, "train/policy_logprob_mag": 4.973257064819336, "train/policy_logprob_max": -0.18938004970550537, "train/policy_logprob_mean": -1.6226115226745605, "train/policy_logprob_min": -4.973257064819336, "train/policy_logprob_std": 0.7634639739990234, "train/policy_randomness_mag": 0.9970166683197021, "train/policy_randomness_max": 0.9970166683197021, "train/policy_randomness_mean": 0.8398246169090271, "train/policy_randomness_min": 0.3752325773239136, "train/policy_randomness_std": 0.09368308633565903, "train/post_ent_mag": 106.53484344482422, "train/post_ent_max": 106.53484344482422, "train/post_ent_mean": 106.17471313476562, "train/post_ent_min": 105.81304168701172, "train/post_ent_std": 0.10436839610338211, "train/prior_ent_mag": 106.76089477539062, "train/prior_ent_max": 106.76089477539062, "train/prior_ent_mean": 105.86746978759766, "train/prior_ent_min": 104.63320922851562, "train/prior_ent_std": 0.262564480304718, "train/rep_loss_mean": 10.004053115844727, "train/rep_loss_std": 0.4046754539012909, "train/reward_avg": 0.00023906107526272535, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.6193850999334245e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.4729369580745697, "report/cont_loss_std": 0.24119624495506287, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.837890625, "report/cont_pos_loss": 0.4729369580745697, "report/cont_pred": 0.6397169828414917, "report/cont_rate": 1.0, "report/dyn_loss_mean": 10.048946380615234, "report/dyn_loss_std": 0.38796478509902954, "report/image_loss_mean": 5041.828125, "report/image_loss_std": 38.34817123413086, "report/model_loss_mean": 5053.87158203125, "report/model_loss_std": 38.295230865478516, "report/post_ent_mag": 106.4350357055664, "report/post_ent_max": 106.4350357055664, "report/post_ent_mean": 106.15010833740234, "report/post_ent_min": 105.87149810791016, "report/post_ent_std": 0.10319137573242188, "report/prior_ent_mag": 106.6346664428711, "report/prior_ent_max": 106.6346664428711, "report/prior_ent_mean": 105.82267761230469, "report/prior_ent_min": 104.80868530273438, "report/prior_ent_std": 0.28259626030921936, "report/rep_loss_mean": 10.048946380615234, "report/rep_loss_std": 0.38796478509902954, "report/reward_avg": 0.00023906107526272535, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.6193850999334245e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.4530157744884491, "eval/cont_loss_std": 0.22105486690998077, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 1.0344010591506958, "eval/cont_pos_acc": 0.8826979398727417, "eval/cont_pos_loss": 0.45244747400283813, "eval/cont_pred": 0.6502342224121094, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 10.03687858581543, "eval/dyn_loss_std": 0.4112222492694855, "eval/image_loss_mean": 5043.439453125, "eval/image_loss_std": 35.25752639770508, "eval/model_loss_mean": 5055.45654296875, "eval/model_loss_std": 35.25187301635742, "eval/post_ent_mag": 106.4598159790039, "eval/post_ent_max": 106.4598159790039, "eval/post_ent_mean": 106.17825317382812, "eval/post_ent_min": 105.8507308959961, "eval/post_ent_std": 0.10221058875322342, "eval/prior_ent_mag": 106.72075653076172, "eval/prior_ent_max": 106.72075653076172, "eval/prior_ent_mean": 105.84788513183594, "eval/prior_ent_min": 105.00580596923828, "eval/prior_ent_std": 0.2880830764770508, "eval/rep_loss_mean": 10.03687858581543, "eval/rep_loss_std": 0.4112222492694855, "eval/reward_avg": 0.0005706787342205644, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 0.5843750238418579, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541264057159424, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0009765625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 7.539621026536261e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.471867970057897e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.2412207143606878e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.834259850638253e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 152.6536626815796, "timer/env.step_count": 196.0, "timer/env.step_total": 1.3917250633239746, "timer/env.step_frac": 0.009116879601028475, "timer/env.step_avg": 0.007100638078183544, "timer/env.step_min": 0.0062885284423828125, "timer/env.step_max": 0.015353918075561523, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.09232401847839355, "timer/replay._sample_frac": 0.0006047939948284917, "timer/replay._sample_avg": 0.0008243215935570854, "timer/replay._sample_min": 0.00033283233642578125, "timer/replay._sample_max": 0.005023479461669922, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.0852949619293213, "timer/agent.save_frac": 0.013660300875184632, "timer/agent.save_avg": 2.0852949619293213, "timer/agent.save_min": 2.0852949619293213, "timer/agent.save_max": 2.0852949619293213, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.081592082977295, "timer/agent.policy_frac": 0.14465157071951368, "timer/agent.policy_avg": 0.07614342097578378, "timer/agent.policy_min": 0.009250164031982422, "timer/agent.policy_max": 16.80923080444336, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.266334533691406e-05, "timer/dataset_train_frac": 2.139702694526666e-07, "timer/dataset_train_avg": 3.266334533691406e-05, "timer/dataset_train_min": 3.266334533691406e-05, "timer/dataset_train_max": 3.266334533691406e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.05174374580383, "timer/agent.train_frac": 0.5964596076265052, "timer/agent.train_avg": 91.05174374580383, "timer/agent.train_min": 91.05174374580383, "timer/agent.train_max": 91.05174374580383, "timer/agent.report_count": 2.0, "timer/agent.report_total": 31.341216325759888, "timer/agent.report_frac": 0.2053092980227704, "timer/agent.report_avg": 15.670608162879944, "timer/agent.report_min": 7.461299896240234, "timer/agent.report_max": 23.879916429519653, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 2.3427401764890504e-07, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05}
{"step": 2312, "time": 291.15516114234924, "episode/length": 288.0, "episode/score": 0.06284977426969363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06284977426969363}
{"step": 2312, "time": 291.1630094051361, "episode/length": 288.0, "episode/score": 0.08495135834220946, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08495135834220946}
{"step": 2312, "time": 291.169842004776, "episode/length": 288.0, "episode/score": 0.05153469962976942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05153469962976942}
{"step": 2312, "time": 291.17645835876465, "episode/length": 288.0, "episode/score": 0.06126053361731465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06126053361731465}
{"step": 2312, "time": 291.18274188041687, "episode/length": 288.0, "episode/score": 0.08491791103972446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08491791103972446}
{"step": 2312, "time": 291.1891875267029, "episode/length": 288.0, "episode/score": 0.060277476400756314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060277476400756314}
{"step": 2312, "time": 291.19563341140747, "episode/length": 288.0, "episode/score": 0.05835794410904782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05835794410904782}
{"step": 2312, "time": 291.2021734714508, "episode/length": 288.0, "episode/score": 0.06452383983878462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06452383983878462}
{"step": 4624, "time": 365.38577818870544, "episode/length": 288.0, "episode/score": 0.0512781200696395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0512781200696395}
{"step": 4624, "time": 365.3935286998749, "episode/length": 288.0, "episode/score": 0.0520952141955604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0520952141955604}
{"step": 4624, "time": 365.4003939628601, "episode/length": 288.0, "episode/score": 0.03363468896441191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03363468896441191}
{"step": 4624, "time": 365.40742564201355, "episode/length": 288.0, "episode/score": 0.04416327587790647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04416327587790647}
{"step": 4624, "time": 365.4147148132324, "episode/length": 288.0, "episode/score": 0.06705104758498237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06705104758498237}
{"step": 4624, "time": 365.4224143028259, "episode/length": 288.0, "episode/score": 0.0311769649642315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0311769649642315}
{"step": 4624, "time": 365.429141998291, "episode/length": 288.0, "episode/score": 0.05006544219833131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05006544219833131}
{"step": 4624, "time": 365.43584632873535, "episode/length": 288.0, "episode/score": 0.05461873155138619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05461873155138619}
{"step": 6584, "time": 427.8289420604706, "episode/length": 244.0, "episode/score": 0.3019095946552852, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.06440959879967068}
{"step": 6936, "time": 438.88147807121277, "episode/length": 288.0, "episode/score": 0.06021006877853097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06021006877853097}
{"step": 6936, "time": 438.8895335197449, "episode/length": 288.0, "episode/score": 0.04095670771636151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04095670771636151}
{"step": 6936, "time": 438.89632630348206, "episode/length": 288.0, "episode/score": 0.06988082282737196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06988082282737196}
{"step": 6936, "time": 438.90290808677673, "episode/length": 288.0, "episode/score": 0.06496805408175987, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06496805408175987}
{"step": 6936, "time": 438.90946197509766, "episode/length": 288.0, "episode/score": 0.0531082106877534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0531082106877534}
{"step": 6936, "time": 438.9156656265259, "episode/length": 288.0, "episode/score": 0.0582963633773943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0582963633773943}
{"step": 6936, "time": 438.9223084449768, "episode/length": 288.0, "episode/score": 0.06940729586051475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06940729586051475}
{"step": 8896, "time": 501.92802476882935, "episode/length": 288.0, "episode/score": 0.06025850884151396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06025850884151396}
{"step": 9248, "time": 513.2187774181366, "episode/length": 288.0, "episode/score": 0.042806085956840434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042806085956840434}
{"step": 9248, "time": 513.2266321182251, "episode/length": 288.0, "episode/score": 0.056312483653357503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056312483653357503}
{"step": 9248, "time": 513.2335708141327, "episode/length": 288.0, "episode/score": 0.051944315662240115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051944315662240115}
{"step": 9248, "time": 513.2404346466064, "episode/length": 288.0, "episode/score": 0.04634678877397391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04634678877397391}
{"step": 9248, "time": 513.247599363327, "episode/length": 288.0, "episode/score": 0.059730836814196664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059730836814196664}
{"step": 9248, "time": 513.2545049190521, "episode/length": 288.0, "episode/score": 0.03929975996879875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03929975996879875}
{"step": 9248, "time": 513.2610623836517, "episode/length": 288.0, "episode/score": 0.06585343237543384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06585343237543384}
{"step": 10088, "time": 541.2958474159241, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 10088, "time": 545.1773648262024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 545.1867115497589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 545.1931419372559, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 545.1993358135223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 545.2061247825623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 545.21586561203, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 545.2234582901001, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11208, "time": 580.7252876758575, "episode/length": 288.0, "episode/score": 0.05218544172834072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05218544172834072}
{"step": 11560, "time": 591.8062405586243, "episode/length": 288.0, "episode/score": 0.06087664644456936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06087664644456936}
{"step": 11560, "time": 591.8140947818756, "episode/length": 288.0, "episode/score": 0.06187511690040992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06187511690040992}
{"step": 11560, "time": 591.8208520412445, "episode/length": 288.0, "episode/score": 0.06674281575322993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06674281575322993}
{"step": 11560, "time": 591.8278119564056, "episode/length": 288.0, "episode/score": 0.05860376457331995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05860376457331995}
{"step": 11560, "time": 591.8346495628357, "episode/length": 288.0, "episode/score": 0.06502447491959629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06502447491959629}
{"step": 11560, "time": 591.8413162231445, "episode/length": 288.0, "episode/score": 0.04541678780469738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04541678780469738}
{"step": 11560, "time": 591.8481268882751, "episode/length": 288.0, "episode/score": 0.05209930704842236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05209930704842236}
{"step": 13520, "time": 654.0647480487823, "episode/length": 288.0, "episode/score": 0.06338150190222791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06338150190222791}
{"step": 13872, "time": 665.2801578044891, "episode/length": 288.0, "episode/score": 0.0558989617176735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0558989617176735}
{"step": 13872, "time": 665.2876665592194, "episode/length": 288.0, "episode/score": 0.058137387608098834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058137387608098834}
{"step": 13872, "time": 665.2951745986938, "episode/length": 288.0, "episode/score": 0.06515475690957828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06515475690957828}
{"step": 13872, "time": 665.3020298480988, "episode/length": 288.0, "episode/score": 0.05058621865791224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05058621865791224}
{"step": 13872, "time": 665.3087685108185, "episode/length": 288.0, "episode/score": 0.030088511702103915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030088511702103915}
{"step": 13872, "time": 665.315271615982, "episode/length": 288.0, "episode/score": 0.03025090778251638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03025090778251638}
{"step": 13872, "time": 665.3218989372253, "episode/length": 288.0, "episode/score": 0.050890590892606724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050890590892606724}
{"step": 14960, "time": 699.7675492763519, "episode/length": 135.0, "episode/score": 0.5921354050643686, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.0140103764261994}
{"step": 15832, "time": 727.3435125350952, "episode/length": 288.0, "episode/score": 0.043884683146046655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043884683146046655}
{"step": 16184, "time": 738.3912110328674, "episode/length": 288.0, "episode/score": 0.04275679859728143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04275679859728143}
{"step": 16184, "time": 738.3990375995636, "episode/length": 288.0, "episode/score": 0.060421554272693356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060421554272693356}
{"step": 16184, "time": 738.4065144062042, "episode/length": 288.0, "episode/score": 0.04719533536109566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04719533536109566}
{"step": 16184, "time": 738.4134855270386, "episode/length": 288.0, "episode/score": 0.0552253821439308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0552253821439308}
{"step": 16184, "time": 738.4208054542542, "episode/length": 288.0, "episode/score": 0.04565796736360994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04565796736360994}
{"step": 16184, "time": 738.4274673461914, "episode/length": 288.0, "episode/score": 0.01946050408170663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01946050408170663}
{"step": 17272, "time": 773.442417383194, "episode/length": 288.0, "episode/score": 0.03923270508946075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03923270508946075}
{"step": 18144, "time": 801.4686124324799, "episode/length": 288.0, "episode/score": 0.04229677403725418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04229677403725418}
{"step": 18496, "time": 812.8461270332336, "episode/length": 288.0, "episode/score": 0.05001926073339291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05001926073339291}
{"step": 18496, "time": 812.8545753955841, "episode/length": 288.0, "episode/score": 0.05906620818831243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05906620818831243}
{"step": 18496, "time": 812.8620567321777, "episode/length": 288.0, "episode/score": 0.04889476545042726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04889476545042726}
{"step": 18496, "time": 812.8699352741241, "episode/length": 288.0, "episode/score": 0.06493970700250884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06493970700250884}
{"step": 18496, "time": 812.8786351680756, "episode/length": 288.0, "episode/score": 0.048968456228067225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048968456228067225}
{"step": 18496, "time": 812.8860304355621, "episode/length": 288.0, "episode/score": 0.04835012899542335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04835012899542335}
{"step": 19584, "time": 847.5776920318604, "episode/length": 288.0, "episode/score": 0.05258155908478557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05258155908478557}
{"step": 20072, "time": 869.1192226409912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.1264324188232, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.1326818466187, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.1386909484863, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.1444928646088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.1506035327911, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.156821012497, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 869.1630308628082, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20456, "time": 881.3456180095673, "episode/length": 288.0, "episode/score": 0.06570337060406928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06570337060406928}
{"step": 20808, "time": 892.5171043872833, "episode/length": 288.0, "episode/score": 0.023967483185799665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023967483185799665}
{"step": 20808, "time": 892.5248970985413, "episode/length": 288.0, "episode/score": 0.038728099453862797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038728099453862797}
{"step": 20808, "time": 892.5317375659943, "episode/length": 288.0, "episode/score": 0.04423604936641823, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04423604936641823}
{"step": 20808, "time": 892.538467168808, "episode/length": 288.0, "episode/score": 0.04001146457039795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04001146457039795}
{"step": 20808, "time": 892.5450513362885, "episode/length": 288.0, "episode/score": 0.03400308295556442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03400308295556442}
{"step": 20808, "time": 892.5517873764038, "episode/length": 288.0, "episode/score": 0.041163417885115905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041163417885115905}
{"step": 21056, "time": 900.6788675785065, "episode/length": 74.0, "episode/score": 0.7908878947903872, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.022137883684365534}
{"step": 21896, "time": 927.0842804908752, "episode/length": 288.0, "episode/score": 0.06692719596725283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06692719596725283}
{"step": 23120, "time": 966.1014182567596, "episode/length": 288.0, "episode/score": 0.04126765202821048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04126765202821048}
{"step": 23120, "time": 966.109461069107, "episode/length": 288.0, "episode/score": 0.06958401297336536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06958401297336536}
{"step": 23120, "time": 966.1161713600159, "episode/length": 288.0, "episode/score": 0.05490820491309023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05490820491309023}
{"step": 23120, "time": 966.1229617595673, "episode/length": 288.0, "episode/score": 0.040291741223825284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040291741223825284}
{"step": 23120, "time": 966.1300473213196, "episode/length": 288.0, "episode/score": 0.022661827055344475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022661827055344475}
{"step": 23120, "time": 966.1371746063232, "episode/length": 288.0, "episode/score": 0.0386616038937575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0386616038937575}
{"step": 23368, "time": 973.7330980300903, "episode/length": 288.0, "episode/score": 0.042198913970565854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042198913970565854}
{"step": 23856, "time": 989.5022251605988, "episode/length": 91.0, "episode/score": 0.7305954613120491, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.014970444594808896}
{"step": 24208, "time": 1000.6319499015808, "episode/length": 288.0, "episode/score": 0.05609065606739705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05609065606739705}
{"step": 25432, "time": 1039.8050100803375, "episode/length": 288.0, "episode/score": 0.039389789613665016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039389789613665016}
{"step": 25432, "time": 1039.8129889965057, "episode/length": 288.0, "episode/score": 0.0337001769374865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0337001769374865}
{"step": 25432, "time": 1039.819697380066, "episode/length": 288.0, "episode/score": 0.03894669794473771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03894669794473771}
{"step": 25432, "time": 1039.8265101909637, "episode/length": 288.0, "episode/score": 0.03503088080307748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03503088080307748}
{"step": 25432, "time": 1039.8339745998383, "episode/length": 288.0, "episode/score": 0.03763957493023895, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03763957493023895}
{"step": 25680, "time": 1047.832700252533, "episode/length": 288.0, "episode/score": 0.03774174582983392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03774174582983392}
{"step": 26168, "time": 1063.1040461063385, "episode/length": 288.0, "episode/score": 0.03776072179149992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03776072179149992}
{"step": 26520, "time": 1074.1892058849335, "episode/length": 288.0, "episode/score": 0.03815350873657053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03815350873657053}
{"step": 27744, "time": 1113.396178483963, "episode/length": 288.0, "episode/score": 0.03967379354804734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03967379354804734}
{"step": 27744, "time": 1113.4044620990753, "episode/length": 288.0, "episode/score": 0.02324621092321877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02324621092321877}
{"step": 27744, "time": 1113.4117517471313, "episode/length": 288.0, "episode/score": 0.05066109378012129, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05066109378012129}
{"step": 27744, "time": 1113.419088602066, "episode/length": 288.0, "episode/score": 0.045164000904236445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045164000904236445}
{"step": 27744, "time": 1113.4267811775208, "episode/length": 288.0, "episode/score": 0.04184901152632392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04184901152632392}
{"step": 27992, "time": 1121.1543493270874, "episode/length": 288.0, "episode/score": 0.04053252076806757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04053252076806757}
{"step": 28480, "time": 1136.8842170238495, "episode/length": 288.0, "episode/score": 0.04064995499066981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04064995499066981}
{"step": 28592, "time": 1140.5289537906647, "episode/length": 258.0, "episode/score": 0.2407487490412734, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.04699875616589111}
{"step": 30056, "time": 1186.7932271957397, "episode/length": 288.0, "episode/score": 0.05275320119136495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05275320119136495}
{"step": 30056, "time": 1186.8021893501282, "episode/length": 288.0, "episode/score": 0.06057213272185891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06057213272185891}
{"step": 30056, "time": 1186.8089580535889, "episode/length": 288.0, "episode/score": 0.04363311303484352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04363311303484352}
{"step": 30056, "time": 1186.8155193328857, "episode/length": 288.0, "episode/score": 0.05419682719994512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05419682719994512}
{"step": 30056, "time": 1186.8220131397247, "episode/length": 288.0, "episode/score": 0.04268822184374699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04268822184374699}
{"step": 30056, "time": 1192.4517562389374, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.458912372589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.4651591777802, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.471268415451, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.4776525497437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.4840626716614, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.4907257556915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1192.4969308376312, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30304, "time": 1200.7024958133698, "episode/length": 288.0, "episode/score": 0.05196859472147253, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05196859472147253}
{"step": 30792, "time": 1216.314738035202, "episode/length": 288.0, "episode/score": 0.05540183301343404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05540183301343404}
{"step": 30904, "time": 1219.8739337921143, "episode/length": 288.0, "episode/score": 0.052341057290277604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052341057290277604}
{"step": 31401, "time": 1236.843130350113, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.00114260437668, "train/action_min": 0.0, "train/action_std": 1.9982115068743307, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0005434803908467994, "train/actor_opt_grad_steps": 935.0, "train/actor_opt_loss": 12.273211293323065, "train/adv_mag": 0.0016064035710608169, "train/adv_max": 0.0016064035710608169, "train/adv_mean": 0.0009412903623085552, "train/adv_min": 0.00011719773291455719, "train/adv_std": 0.00043742766338978554, "train/cont_avg": 0.9969285534274194, "train/cont_loss_mean": 0.02335113577699209, "train/cont_loss_std": 0.301260408445765, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.7959138634561125, "train/cont_pos_acc": 0.9992071877243698, "train/cont_pos_loss": 0.005599230770114815, "train/cont_pred": 0.9949991683806142, "train/cont_rate": 0.9969285534274194, "train/dyn_loss_mean": 1.062368526894559, "train/dyn_loss_std": 0.004553133712135448, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.632920125879908, "train/extr_critic_critic_opt_grad_steps": 935.0, "train/extr_critic_critic_opt_loss": 10718.572473013273, "train/extr_critic_mag": 0.013926366324065834, "train/extr_critic_max": 0.013926360555874404, "train/extr_critic_mean": 0.01389262789845069, "train/extr_critic_min": 0.01385684359458185, "train/extr_critic_std": 9.018188243205197e-06, "train/extr_return_normed_mag": 0.0029356855905202078, "train/extr_return_normed_max": 0.0029356844171439774, "train/extr_return_normed_mean": 0.00229590111742888, "train/extr_return_normed_min": 0.001485213091180786, "train/extr_return_normed_std": 0.00043717889671269735, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.015473698955048423, "train/extr_return_raw_max": 0.015473697677077413, "train/extr_return_raw_mean": 0.01483391503934979, "train/extr_return_raw_min": 0.01402322634701277, "train/extr_return_raw_std": 0.0004371788987266849, "train/extr_reward_mag": 0.0001907784451720535, "train/extr_reward_max": 0.0001907784451720535, "train/extr_reward_mean": 0.00019048881739294247, "train/extr_reward_min": 0.00019000550752045007, "train/extr_reward_std": 9.757256538516558e-08, "train/image_loss_mean": 28.194143028108662, "train/image_loss_std": 0.36623194725603186, "train/model_loss_mean": 28.975997626140554, "train/model_loss_std": 0.6197716609364555, "train/model_opt_grad_norm": 101.15612909987166, "train/model_opt_grad_steps": 925.0, "train/model_opt_loss": 552.4864211697733, "train/model_opt_model_opt_grad_overflow": 0.005376344086021506, "train/model_opt_model_opt_grad_scale": 14.22841061827957, "train/policy_entropy_mag": 1.945772882430784, "train/policy_entropy_max": 1.945772882430784, "train/policy_entropy_mean": 1.940435544777942, "train/policy_entropy_min": 1.8663306511858457, "train/policy_entropy_std": 0.0035316120246074775, "train/policy_logprob_mag": 2.421176729663726, "train/policy_logprob_max": -1.4578516145226776, "train/policy_logprob_mean": -1.9403989814942884, "train/policy_logprob_min": -2.421176729663726, "train/policy_logprob_std": 0.09429975176450386, "train/policy_randomness_mag": 0.9999295178280082, "train/policy_randomness_max": 0.9999295178280082, "train/policy_randomness_mean": 0.997186666855248, "train/policy_randomness_min": 0.9591042835225341, "train/policy_randomness_std": 0.0018148896633647382, "train/post_ent_mag": 84.75750847272975, "train/post_ent_max": 84.75750847272975, "train/post_ent_mean": 84.7020867050335, "train/post_ent_min": 84.6229711553102, "train/post_ent_std": 0.019118670874866107, "train/prior_ent_mag": 89.45783623315955, "train/prior_ent_max": 89.45783623315955, "train/prior_ent_mean": 89.34441822831349, "train/prior_ent_min": 89.13007256292528, "train/prior_ent_std": 0.047165092801855456, "train/rep_loss_mean": 1.062368526894559, "train/rep_loss_std": 0.004553133712135448, "train/reward_avg": 0.0002278843963448639, "train/reward_loss_mean": 0.1210785080448434, "train/reward_loss_std": 0.040159574546960536, "train/reward_max_data": 0.03938396125080525, "train/reward_max_pred": 0.0001906547495113906, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.1202025844600372, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.171499162912369, "train/reward_pred": 0.00019043226355826984, "train/reward_rate": 9.450604838709677e-05, "train_stats/mean_log_entropy": 1.9263279449159854, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014135606586933136, "report/cont_loss_std": 0.2745640277862549, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.220739841461182, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0019896081648766994, "report/cont_pred": 0.9980124235153198, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2604813277721405, "report/image_loss_std": 0.08043304085731506, "report/model_loss_mean": 0.8837423324584961, "report/model_loss_std": 0.28468504548072815, "report/post_ent_mag": 73.16084289550781, "report/post_ent_max": 73.16084289550781, "report/post_ent_mean": 72.9937744140625, "report/post_ent_min": 72.96978759765625, "report/post_ent_std": 0.02664784900844097, "report/prior_ent_mag": 78.13134002685547, "report/prior_ent_max": 78.13134002685547, "report/prior_ent_mean": 78.04255676269531, "report/prior_ent_min": 77.64578247070312, "report/prior_ent_std": 0.06234064698219299, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001729867944959551, "report/reward_loss_mean": 0.009125366806983948, "report/reward_loss_std": 0.015831513330340385, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00020372867584228516, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009125366806983948, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00020372611470520496, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.001989646116271615, "eval/cont_loss_std": 8.999669489639928e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.001989646116271615, "eval/cont_pred": 0.9980124235153198, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.262031614780426, "eval/image_loss_std": 0.08229927718639374, "eval/model_loss_mean": 0.8656219840049744, "eval/model_loss_std": 0.08229924738407135, "eval/post_ent_mag": 73.16084289550781, "eval/post_ent_max": 73.16084289550781, "eval/post_ent_mean": 72.99323272705078, "eval/post_ent_min": 72.97250366210938, "eval/post_ent_std": 0.02524053119122982, "eval/prior_ent_mag": 78.1417236328125, "eval/prior_ent_max": 78.1417236328125, "eval/prior_ent_mean": 78.04121398925781, "eval/prior_ent_min": 77.64578247070312, "eval/prior_ent_std": 0.05854802206158638, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001600733958184719, "eval/reward_loss_std": 6.266215990535784e-08, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00020372867584228516, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001600733958184719, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00020372658036649227, "eval/reward_rate": 0.0, "replay/size": 30897.0, "replay/inserts": 29840.0, "replay/samples": 29840.0, "replay/insert_wait_avg": 1.2542383280899825e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.598025687578216e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1304601803507909e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 969.3612284660339, "timer/env.step_count": 3730.0, "timer/env.step_total": 36.87423920631409, "timer/env.step_frac": 0.03803972979677116, "timer/env.step_avg": 0.00988585501509761, "timer/env.step_min": 0.008063316345214844, "timer/env.step_max": 0.05076861381530762, "timer/replay._sample_count": 29840.0, "timer/replay._sample_total": 15.255282402038574, "timer/replay._sample_frac": 0.015737458806949916, "timer/replay._sample_avg": 0.0005112360054302472, "timer/replay._sample_min": 0.0003376007080078125, "timer/replay._sample_max": 0.02877044677734375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4597.0, "timer/agent.policy_total": 47.84054231643677, "timer/agent.policy_frac": 0.04935264678590669, "timer/agent.policy_avg": 0.01040690500683854, "timer/agent.policy_min": 0.008844614028930664, "timer/agent.policy_max": 0.0971066951751709, "timer/dataset_train_count": 1865.0, "timer/dataset_train_total": 0.2045748233795166, "timer/dataset_train_frac": 0.0002110408559492792, "timer/dataset_train_avg": 0.00010969159430537083, "timer/dataset_train_min": 7.605552673339844e-05, "timer/dataset_train_max": 0.00031375885009765625, "timer/agent.train_count": 1865.0, "timer/agent.train_total": 833.3818407058716, "timer/agent.train_frac": 0.8597226877174127, "timer/agent.train_avg": 0.44685353389054777, "timer/agent.train_min": 0.4362146854400635, "timer/agent.train_max": 0.8410890102386475, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4813570976257324, "timer/agent.report_frac": 0.0004965714364163875, "timer/agent.report_avg": 0.2406785488128662, "timer/agent.report_min": 0.23465371131896973, "timer/agent.report_max": 0.2467033863067627, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.320383282674147e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 30.782687618748035}
{"step": 32368, "time": 1267.793773174286, "episode/length": 288.0, "episode/score": 0.07041594591431988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07041594591431988}
{"step": 32368, "time": 1267.802755355835, "episode/length": 288.0, "episode/score": 0.06236001216727516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06236001216727516}
{"step": 32368, "time": 1267.8097875118256, "episode/length": 288.0, "episode/score": 0.06695134808293801, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06695134808293801}
{"step": 32368, "time": 1267.8167543411255, "episode/length": 288.0, "episode/score": 0.0812413789577704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0812413789577704}
{"step": 32368, "time": 1267.824054479599, "episode/length": 288.0, "episode/score": 0.07093137769741986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07093137769741986}
{"step": 32616, "time": 1275.4360299110413, "episode/length": 288.0, "episode/score": 0.053829156694888525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053829156694888525}
{"step": 33104, "time": 1291.6651151180267, "episode/length": 288.0, "episode/score": 0.06496673032366118, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06496673032366118}
{"step": 33216, "time": 1295.1844387054443, "episode/length": 288.0, "episode/score": 0.051724421027330436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051724421027330436}
{"step": 34680, "time": 1341.3586485385895, "episode/length": 288.0, "episode/score": 0.05303070101876983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05303070101876983}
{"step": 34680, "time": 1341.367086648941, "episode/length": 288.0, "episode/score": 0.055912142878398186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055912142878398186}
{"step": 34680, "time": 1341.3764922618866, "episode/length": 288.0, "episode/score": 0.050475760782532575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050475760782532575}
{"step": 34680, "time": 1341.3841784000397, "episode/length": 288.0, "episode/score": 0.05097632967206778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05097632967206778}
{"step": 34680, "time": 1341.3922038078308, "episode/length": 288.0, "episode/score": 0.04861026576469385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04861026576469385}
{"step": 34928, "time": 1349.6202120780945, "episode/length": 288.0, "episode/score": 0.04326530647460913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04326530647460913}
{"step": 35000, "time": 1351.692465543747, "episode/length": 39.0, "episode/score": 0.8916557150390929, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.013530703933071209}
{"step": 35416, "time": 1364.823302268982, "episode/length": 288.0, "episode/score": 0.053169579859272176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053169579859272176}
{"step": 35528, "time": 1368.3597331047058, "episode/length": 288.0, "episode/score": 0.06416134706879006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06416134706879006}
{"step": 36280, "time": 1392.224437713623, "episode/length": 168.0, "episode/score": 0.5228818246970377, "episode/reward_rate": 0.005917159763313609, "episode/intrinsic_return": 0.04788183147240943}
{"step": 36992, "time": 1415.2064757347107, "episode/length": 288.0, "episode/score": 0.051509225392038616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051509225392038616}
{"step": 36992, "time": 1415.215529203415, "episode/length": 288.0, "episode/score": 0.024711147395720445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024711147395720445}
{"step": 36992, "time": 1415.2227115631104, "episode/length": 288.0, "episode/score": 0.05726338370253359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05726338370253359}
{"step": 36992, "time": 1415.2304253578186, "episode/length": 288.0, "episode/score": 0.03668768903682462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03668768903682462}
{"step": 37312, "time": 1425.4535217285156, "episode/length": 288.0, "episode/score": 0.03299674787791673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03299674787791673}
{"step": 37728, "time": 1438.7268013954163, "episode/length": 288.0, "episode/score": 0.04994859808843444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04994859808843444}
{"step": 37840, "time": 1442.272388935089, "episode/length": 288.0, "episode/score": 0.05359976008425349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05359976008425349}
{"step": 38592, "time": 1466.0949459075928, "episode/length": 288.0, "episode/score": 0.053696711895099725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053696711895099725}
{"step": 39304, "time": 1488.4542112350464, "episode/length": 288.0, "episode/score": 0.03545555861641958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03545555861641958}
{"step": 39304, "time": 1488.4627635478973, "episode/length": 288.0, "episode/score": 0.06100865471030659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06100865471030659}
{"step": 39304, "time": 1488.4699358940125, "episode/length": 288.0, "episode/score": 0.0632183862968958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0632183862968958}
{"step": 39304, "time": 1488.4769403934479, "episode/length": 288.0, "episode/score": 0.05665456692580051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05665456692580051}
{"step": 39624, "time": 1498.665199995041, "episode/length": 288.0, "episode/score": 0.032727241631391735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032727241631391735}
{"step": 40040, "time": 1511.9102993011475, "episode/length": 288.0, "episode/score": 0.04750009859364468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04750009859364468}
{"step": 40040, "time": 1517.2014396190643, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.2103514671326, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.2168946266174, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.2233369350433, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.2296290397644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.235923051834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.242432832718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1517.2489326000214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40152, "time": 1520.830349445343, "episode/length": 288.0, "episode/score": 0.06984819228438255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06984819228438255}
{"step": 40816, "time": 1542.1401212215424, "episode/length": 188.0, "episode/score": 0.45025417956382796, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.03775418633919969}
{"step": 40904, "time": 1544.691234588623, "episode/length": 288.0, "episode/score": 0.06799174424752152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06799174424752152}
{"step": 40936, "time": 1545.7166407108307, "episode/length": 97.0, "episode/score": 0.7163027151381982, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.019427724660971535}
{"step": 41616, "time": 1568.1429424285889, "episode/length": 288.0, "episode/score": 0.05124294207446667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05124294207446667}
{"step": 41616, "time": 1568.1532802581787, "episode/length": 288.0, "episode/score": 0.028444378159505845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028444378159505845}
{"step": 41616, "time": 1568.1602308750153, "episode/length": 288.0, "episode/score": 0.018623907113124005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018623907113124005}
{"step": 41936, "time": 1578.420080423355, "episode/length": 288.0, "episode/score": 0.0438438251602804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0438438251602804}
{"step": 42352, "time": 1591.7165398597717, "episode/length": 288.0, "episode/score": 0.05320951764403503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05320951764403503}
{"step": 43128, "time": 1616.1209106445312, "episode/length": 288.0, "episode/score": 0.05180507905782861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05180507905782861}
{"step": 43216, "time": 1619.2290298938751, "episode/length": 288.0, "episode/score": 0.03373281034969011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03373281034969011}
{"step": 43248, "time": 1620.262638092041, "episode/length": 288.0, "episode/score": 0.06454194317859674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06454194317859674}
{"step": 43928, "time": 1641.6243131160736, "episode/length": 288.0, "episode/score": 0.05752532120527576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05752532120527576}
{"step": 43928, "time": 1641.632708787918, "episode/length": 288.0, "episode/score": 0.057276969759215035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057276969759215035}
{"step": 43928, "time": 1641.6401760578156, "episode/length": 288.0, "episode/score": 0.052783862790093394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052783862790093394}
{"step": 44248, "time": 1651.9135262966156, "episode/length": 288.0, "episode/score": 0.04752857475489236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04752857475489236}
{"step": 44664, "time": 1665.1734819412231, "episode/length": 288.0, "episode/score": 0.03372610354176686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03372610354176686}
{"step": 45440, "time": 1690.183420419693, "episode/length": 288.0, "episode/score": 0.04400666034473488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04400666034473488}
{"step": 45528, "time": 1692.775449514389, "episode/length": 288.0, "episode/score": 0.030755092390563732, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030755092390563732}
{"step": 45560, "time": 1693.8266339302063, "episode/length": 288.0, "episode/score": 0.04011981217138327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04011981217138327}
{"step": 46240, "time": 1715.7770910263062, "episode/length": 288.0, "episode/score": 0.04474095121713617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04474095121713617}
{"step": 46240, "time": 1715.7908382415771, "episode/length": 288.0, "episode/score": 0.05800711746474008, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05800711746474008}
{"step": 46240, "time": 1715.802176475525, "episode/length": 288.0, "episode/score": 0.032081530961818316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032081530961818316}
{"step": 46560, "time": 1725.8910851478577, "episode/length": 288.0, "episode/score": 0.06196407839979656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06196407839979656}
{"step": 46976, "time": 1739.1160714626312, "episode/length": 288.0, "episode/score": 0.03025539491784457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03025539491784457}
{"step": 47752, "time": 1763.417881011963, "episode/length": 288.0, "episode/score": 0.05068774096287143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05068774096287143}
{"step": 47840, "time": 1766.427582025528, "episode/length": 288.0, "episode/score": 0.048200124246022824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048200124246022824}
{"step": 47872, "time": 1767.438132762909, "episode/length": 288.0, "episode/score": 0.04859641499058398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04859641499058398}
{"step": 48552, "time": 1788.8081600666046, "episode/length": 288.0, "episode/score": 0.040321620586325935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040321620586325935}
{"step": 48552, "time": 1788.8159382343292, "episode/length": 288.0, "episode/score": 0.04908967237901152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04908967237901152}
{"step": 48552, "time": 1788.8229911327362, "episode/length": 288.0, "episode/score": 0.06875624301954986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06875624301954986}
{"step": 48872, "time": 1799.047951221466, "episode/length": 288.0, "episode/score": 0.0414944632480001, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0414944632480001}
{"step": 49288, "time": 1812.7234914302826, "episode/length": 288.0, "episode/score": 0.04763490308744167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04763490308744167}
{"step": 50024, "time": 1841.8292925357819, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.836642742157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.843162059784, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.849450826645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.8556792736053, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.861885547638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.8679976463318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1841.874580860138, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50064, "time": 1843.381153345108, "episode/length": 288.0, "episode/score": 0.041147605633739204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041147605633739204}
{"step": 50152, "time": 1845.9626502990723, "episode/length": 288.0, "episode/score": 0.021877448793247822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021877448793247822}
{"step": 50184, "time": 1846.972650051117, "episode/length": 288.0, "episode/score": 0.04379970877374717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04379970877374717}
{"step": 50848, "time": 1868.5469377040863, "episode/length": 246.0, "episode/score": 0.2882790488670821, "episode/reward_rate": 0.004048582995951417, "episode/intrinsic_return": 0.05702904705100309}
{"step": 50864, "time": 1869.0591175556183, "episode/length": 288.0, "episode/score": 0.04241746418136927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04241746418136927}
{"step": 50864, "time": 1869.0673484802246, "episode/length": 288.0, "episode/score": 0.026751891914102544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026751891914102544}
{"step": 50864, "time": 1869.0743641853333, "episode/length": 288.0, "episode/score": 0.0555833877062355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0555833877062355}
{"step": 51600, "time": 1892.4276685714722, "episode/length": 288.0, "episode/score": 0.0497613790809055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0497613790809055}
{"step": 52376, "time": 1916.7460610866547, "episode/length": 288.0, "episode/score": 0.04340300612071246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04340300612071246}
{"step": 52464, "time": 1919.9283442497253, "episode/length": 288.0, "episode/score": 0.03529040804454553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03529040804454553}
{"step": 52496, "time": 1920.940150976181, "episode/length": 288.0, "episode/score": 0.04954687846512229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04954687846512229}
{"step": 53160, "time": 1941.645530462265, "episode/length": 288.0, "episode/score": 0.06086384917281862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06086384917281862}
{"step": 53176, "time": 1942.1602640151978, "episode/length": 288.0, "episode/score": 0.03710919684772307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03710919684772307}
{"step": 53176, "time": 1942.1681668758392, "episode/length": 288.0, "episode/score": 0.057889243306220806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057889243306220806}
{"step": 53176, "time": 1942.1752865314484, "episode/length": 288.0, "episode/score": 0.06945918004902296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06945918004902296}
{"step": 53576, "time": 1954.9607992172241, "episode/length": 134.0, "episode/score": 0.5995013531027098, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.01825132686269626}
{"step": 53912, "time": 1965.6356091499329, "episode/length": 288.0, "episode/score": 0.03174601443615188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03174601443615188}
{"step": 54688, "time": 1990.533192396164, "episode/length": 288.0, "episode/score": 0.02206830459061848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02206830459061848}
{"step": 54776, "time": 1993.0713710784912, "episode/length": 288.0, "episode/score": 0.04360724455790432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04360724455790432}
{"step": 55472, "time": 2015.3582365512848, "episode/length": 288.0, "episode/score": 0.031202076359534203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031202076359534203}
{"step": 55488, "time": 2015.8770577907562, "episode/length": 288.0, "episode/score": 0.040398497416362034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040398497416362034}
{"step": 55488, "time": 2015.8851029872894, "episode/length": 288.0, "episode/score": 0.04283067287354925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04283067287354925}
{"step": 55488, "time": 2015.8928849697113, "episode/length": 288.0, "episode/score": 0.040106607684066375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040106607684066375}
{"step": 55888, "time": 2028.5371458530426, "episode/length": 288.0, "episode/score": 0.04831728059713214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04831728059713214}
{"step": 56224, "time": 2039.313390493393, "episode/length": 288.0, "episode/score": 0.02846888328539876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02846888328539876}
{"step": 57000, "time": 2063.6574165821075, "episode/length": 288.0, "episode/score": 0.06317521403062187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06317521403062187}
{"step": 57088, "time": 2066.671266555786, "episode/length": 288.0, "episode/score": 0.047903838249084174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047903838249084174}
{"step": 57784, "time": 2089.0733473300934, "episode/length": 288.0, "episode/score": 0.04740000915231235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04740000915231235}
{"step": 57800, "time": 2089.5894918441772, "episode/length": 288.0, "episode/score": 0.05604043720734353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05604043720734353}
{"step": 57800, "time": 2089.598844766617, "episode/length": 288.0, "episode/score": 0.05675737007885573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05675737007885573}
{"step": 57800, "time": 2089.6068527698517, "episode/length": 288.0, "episode/score": 0.08342345657629835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08342345657629835}
{"step": 58200, "time": 2102.4324836730957, "episode/length": 288.0, "episode/score": 0.0586615917957829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0586615917957829}
{"step": 58536, "time": 2113.0264501571655, "episode/length": 288.0, "episode/score": 0.0622511682815059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0622511682815059}
{"step": 59312, "time": 2137.9002499580383, "episode/length": 288.0, "episode/score": 0.0841941802768531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0841941802768531}
{"step": 59400, "time": 2140.4600439071655, "episode/length": 288.0, "episode/score": 0.05955877584884206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05955877584884206}
{"step": 60008, "time": 2166.056480884552, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.064067840576, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.07071685791, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.0770106315613, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.083074569702, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.089436531067, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.095936059952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2166.10284781456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60096, "time": 2169.120093345642, "episode/length": 288.0, "episode/score": 0.07677538019129315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07677538019129315}
{"step": 60112, "time": 2169.6514506340027, "episode/length": 288.0, "episode/score": 0.05194759990621378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05194759990621378}
{"step": 60112, "time": 2169.6598558425903, "episode/length": 288.0, "episode/score": 0.04636256658901061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04636256658901061}
{"step": 60112, "time": 2169.6675612926483, "episode/length": 288.0, "episode/score": 0.0445376995040192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0445376995040192}
{"step": 60512, "time": 2182.4297943115234, "episode/length": 288.0, "episode/score": 0.042195433959278716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042195433959278716}
{"step": 60848, "time": 2193.2389857769012, "episode/length": 288.0, "episode/score": 0.043462036202640775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043462036202640775}
{"step": 61624, "time": 2217.6652538776398, "episode/length": 288.0, "episode/score": 0.057152205379765064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057152205379765064}
{"step": 61712, "time": 2220.7757568359375, "episode/length": 288.0, "episode/score": 0.08293552945741567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08293552945741567}
{"step": 62201, "time": 2236.947036266327, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.000426297360751, "train/action_min": 0.0, "train/action_std": 1.9992761253692943, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00031614683084720696, "train/actor_opt_grad_steps": 2830.0, "train/actor_opt_loss": 7.7256195233661895, "train/adv_mag": 0.0012608012425775973, "train/adv_max": 0.0012608012425775973, "train/adv_mean": 0.0007029837226601308, "train/adv_min": 1.8659235977138263e-05, "train/adv_std": 0.0003288340633566168, "train/cont_avg": 0.996366985103627, "train/cont_loss_mean": 0.024174245191409875, "train/cont_loss_std": 0.32883495410364744, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.688992261886597, "train/cont_pos_acc": 0.9999999857937116, "train/cont_pos_loss": 0.0034969254110944624, "train/cont_pred": 0.9965094914708112, "train/cont_rate": 0.996366985103627, "train/dyn_loss_mean": 1.0000000185299414, "train/dyn_loss_std": 2.778140442576163e-07, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.0877199412318709, "train/extr_critic_critic_opt_grad_steps": 2830.0, "train/extr_critic_critic_opt_loss": 11446.473582213406, "train/extr_critic_mag": 0.04480256688409519, "train/extr_critic_max": 0.04480256688409519, "train/extr_critic_mean": 0.044711858979933, "train/extr_critic_min": 0.04464457195657522, "train/extr_critic_std": 2.3432660655993615e-05, "train/extr_return_normed_mag": 0.002494890899083775, "train/extr_return_normed_max": 0.002494890899083775, "train/extr_return_normed_mean": 0.0019941198448964197, "train/extr_return_normed_min": 0.0013559992507177314, "train/extr_return_normed_std": 0.0003274789691807393, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.04591561355893476, "train/extr_return_raw_max": 0.04591561355893476, "train/extr_return_raw_mean": 0.04541484454714264, "train/extr_return_raw_min": 0.044776721910568716, "train/extr_return_raw_std": 0.00032747896978392756, "train/extr_reward_mag": 0.00024561004935150937, "train/extr_reward_max": 0.00024561004935150937, "train/extr_reward_mean": 0.00024541822577877346, "train/extr_reward_min": 0.0002451159175813507, "train/extr_reward_std": 7.294718588649958e-08, "train/image_loss_mean": 0.26935496324084585, "train/image_loss_std": 0.08421539457350814, "train/model_loss_mean": 0.9047850351877164, "train/model_loss_std": 0.39173776915036335, "train/model_opt_grad_norm": 81.5881898119042, "train/model_opt_grad_steps": 2820.0, "train/model_opt_loss": 48.19907241781758, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 53.331444300518136, "train/policy_entropy_mag": 1.9458819553642075, "train/policy_entropy_max": 1.9458819553642075, "train/policy_entropy_mean": 1.9445758261211177, "train/policy_entropy_min": 1.9248106597001071, "train/policy_entropy_std": 0.0008614215848441452, "train/policy_logprob_mag": 2.207162685344874, "train/policy_logprob_max": -1.6787983012322936, "train/policy_logprob_mean": -1.9446084647598663, "train/policy_logprob_min": -2.207162685344874, "train/policy_logprob_std": 0.051263892762555975, "train/policy_randomness_mag": 0.9999855704258143, "train/policy_randomness_max": 0.9999855704258143, "train/policy_randomness_mean": 0.9993143495500396, "train/policy_randomness_min": 0.9891570655175441, "train/policy_randomness_std": 0.0004426831470915826, "train/post_ent_mag": 64.36886912924021, "train/post_ent_max": 64.36886912924021, "train/post_ent_mean": 64.1806375177413, "train/post_ent_min": 64.15614263504898, "train/post_ent_std": 0.03100597917300123, "train/prior_ent_mag": 71.11559602015994, "train/prior_ent_max": 71.11559602015994, "train/prior_ent_mean": 70.9431880101021, "train/prior_ent_min": 70.81784668364055, "train/prior_ent_std": 0.04909999045142856, "train/rep_loss_mean": 1.0000000185299414, "train/rep_loss_std": 2.778140442576163e-07, "train/reward_avg": 0.0003128923817146859, "train/reward_loss_mean": 0.01125579988197882, "train/reward_loss_std": 0.07901117843069097, "train/reward_max_data": 0.12906735926055846, "train/reward_max_pred": 0.00024531789394240306, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009025944104910361, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.581049930758592, "train/reward_pred": 0.00024513890146437087, "train/reward_rate": 0.00023275582901554403, "train_stats/mean_log_entropy": 1.9372144562226754, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025561543181538582, "report/cont_loss_std": 0.3477075695991516, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.578005790710449, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0037872574757784605, "report/cont_pred": 0.9962196946144104, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2708287239074707, "report/image_loss_std": 0.08273189514875412, "report/model_loss_mean": 0.9056955575942993, "report/model_loss_std": 0.35910454392433167, "report/post_ent_mag": 56.91615676879883, "report/post_ent_max": 56.91615676879883, "report/post_ent_mean": 56.74124526977539, "report/post_ent_min": 56.71459197998047, "report/post_ent_std": 0.027770863845944405, "report/prior_ent_mag": 63.72178649902344, "report/prior_ent_max": 63.72178649902344, "report/prior_ent_mean": 63.416046142578125, "report/prior_ent_min": 63.34653854370117, "report/prior_ent_std": 0.0706280842423439, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018340138194616884, "report/reward_loss_mean": 0.009305271320044994, "report/reward_loss_std": 0.015423823148012161, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002772808074951172, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009305271320044994, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00027705682441592216, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.009230829775333405, "eval/cont_loss_std": 0.17410926520824432, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.578005790710449, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003787257708609104, "eval/cont_pred": 0.9962196946144104, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2402373105287552, "eval/image_loss_std": 0.08071303367614746, "eval/model_loss_mean": 0.8600994348526001, "eval/model_loss_std": 0.48547542095184326, "eval/post_ent_mag": 56.91508483886719, "eval/post_ent_max": 56.91508483886719, "eval/post_ent_mean": 56.740074157714844, "eval/post_ent_min": 56.717613220214844, "eval/post_ent_std": 0.025670483708381653, "eval/prior_ent_mag": 63.72178649902344, "eval/prior_ent_max": 63.72178649902344, "eval/prior_ent_mean": 63.412200927734375, "eval/prior_ent_min": 63.35036087036133, "eval/prior_ent_std": 0.06626681238412857, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005706787342205644, "eval/reward_loss_mean": 0.010631335899233818, "eval/reward_loss_std": 0.2919352352619171, "eval/reward_max_data": 0.5843750238418579, "eval/reward_max_pred": 0.0002772808074951172, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015039020217955112, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 9.347996711730957, "eval/reward_pred": 0.000277056940831244, "eval/reward_rate": 0.0009765625, "replay/size": 61697.0, "replay/inserts": 30800.0, "replay/samples": 30800.0, "replay/insert_wait_avg": 1.2594771075558353e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.877418542837167e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1362006507530344e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0903012752533, "timer/env.step_count": 3850.0, "timer/env.step_total": 37.637741804122925, "timer/env.step_frac": 0.03763434337492285, "timer/env.step_avg": 0.00977603683223972, "timer/env.step_min": 0.008057355880737305, "timer/env.step_max": 0.0395658016204834, "timer/replay._sample_count": 30800.0, "timer/replay._sample_total": 16.169091939926147, "timer/replay._sample_frac": 0.016167631982140333, "timer/replay._sample_avg": 0.0005249705175300697, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.02891850471496582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4717.0, "timer/agent.policy_total": 49.12358784675598, "timer/agent.policy_frac": 0.049119152324661706, "timer/agent.policy_avg": 0.0104141589668764, "timer/agent.policy_min": 0.008934974670410156, "timer/agent.policy_max": 0.09291315078735352, "timer/dataset_train_count": 1925.0, "timer/dataset_train_total": 0.20719647407531738, "timer/dataset_train_frac": 0.00020717776565887426, "timer/dataset_train_avg": 0.00010763453198717787, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0004830360412597656, "timer/agent.train_count": 1925.0, "timer/agent.train_total": 860.8705472946167, "timer/agent.train_frac": 0.8607928166055483, "timer/agent.train_avg": 0.4472054791140866, "timer/agent.train_min": 0.43736934661865234, "timer/agent.train_max": 0.6108386516571045, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4753270149230957, "timer/agent.report_frac": 0.0004752840961631046, "timer/agent.report_avg": 0.23766350746154785, "timer/agent.report_min": 0.23064875602722168, "timer/agent.report_max": 0.24467825889587402, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.05718994140625e-05, "timer/dataset_eval_frac": 7.056552725696227e-08, "timer/dataset_eval_avg": 7.05718994140625e-05, "timer/dataset_eval_min": 7.05718994140625e-05, "timer/dataset_eval_max": 7.05718994140625e-05, "fps": 30.796700285360444}
{"step": 62408, "time": 2243.372538328171, "episode/length": 288.0, "episode/score": 0.07164969663169529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07164969663169529}
{"step": 62424, "time": 2243.896369934082, "episode/length": 288.0, "episode/score": 0.06297343619986862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06297343619986862}
{"step": 62424, "time": 2243.905387401581, "episode/length": 288.0, "episode/score": 0.04911282615829293, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04911282615829293}
{"step": 62424, "time": 2243.91322183609, "episode/length": 288.0, "episode/score": 0.05689985108182327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05689985108182327}
{"step": 62824, "time": 2256.7816150188446, "episode/length": 288.0, "episode/score": 0.05805389023448981, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05805389023448981}
{"step": 63160, "time": 2267.4153463840485, "episode/length": 288.0, "episode/score": 0.04683379434594315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04683379434594315}
{"step": 63936, "time": 2292.3612554073334, "episode/length": 288.0, "episode/score": 0.046501343761249814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046501343761249814}
{"step": 64024, "time": 2294.929980278015, "episode/length": 288.0, "episode/score": 0.05187343060829619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05187343060829619}
{"step": 64720, "time": 2317.293390750885, "episode/length": 288.0, "episode/score": 0.05488718684789262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05488718684789262}
{"step": 64736, "time": 2317.8069903850555, "episode/length": 288.0, "episode/score": 0.05945450779786654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05945450779786654}
{"step": 64736, "time": 2317.8147296905518, "episode/length": 288.0, "episode/score": 0.04241060542095454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04241060542095454}
{"step": 64736, "time": 2317.8216190338135, "episode/length": 288.0, "episode/score": 0.044461023980261416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044461023980261416}
{"step": 65136, "time": 2330.5385897159576, "episode/length": 288.0, "episode/score": 0.05913973436362596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05913973436362596}
{"step": 65472, "time": 2341.4180450439453, "episode/length": 288.0, "episode/score": 0.052086303572252746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052086303572252746}
{"step": 66248, "time": 2366.3168222904205, "episode/length": 288.0, "episode/score": 0.07186276035454853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07186276035454853}
{"step": 66336, "time": 2369.444354534149, "episode/length": 288.0, "episode/score": 0.06410224939519082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06410224939519082}
{"step": 67032, "time": 2391.4477903842926, "episode/length": 288.0, "episode/score": 0.07106607040211088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106607040211088}
{"step": 67048, "time": 2391.965223789215, "episode/length": 288.0, "episode/score": 0.060493133954636846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060493133954636846}
{"step": 67048, "time": 2391.9732053279877, "episode/length": 288.0, "episode/score": 0.07020773401825409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07020773401825409}
{"step": 67048, "time": 2391.9810864925385, "episode/length": 288.0, "episode/score": 0.08055212110916443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08055212110916443}
{"step": 67448, "time": 2404.729591846466, "episode/length": 288.0, "episode/score": 0.04926012575964478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04926012575964478}
{"step": 67784, "time": 2415.3380620479584, "episode/length": 288.0, "episode/score": 0.06460359507246949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06460359507246949}
{"step": 68560, "time": 2440.1817321777344, "episode/length": 288.0, "episode/score": 0.06147291012976552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06147291012976552}
{"step": 68648, "time": 2442.7514979839325, "episode/length": 288.0, "episode/score": 0.07077054238942537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07077054238942537}
{"step": 69344, "time": 2465.1820418834686, "episode/length": 288.0, "episode/score": 0.06232762160279037, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06232762160279037}
{"step": 69360, "time": 2465.6973423957825, "episode/length": 288.0, "episode/score": 0.0447324882995872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0447324882995872}
{"step": 69360, "time": 2465.705260515213, "episode/length": 288.0, "episode/score": 0.049680853338117004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049680853338117004}
{"step": 69360, "time": 2465.71329164505, "episode/length": 288.0, "episode/score": 0.04610238670424849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04610238670424849}
{"step": 69760, "time": 2478.3653297424316, "episode/length": 288.0, "episode/score": 0.04776805093004555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04776805093004555}
{"step": 70096, "time": 2489.1803336143494, "episode/length": 288.0, "episode/score": 0.0598955896035136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0598955896035136}
{"step": 70096, "time": 2494.50004029274, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.5084517002106, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.514941215515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.521066427231, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.5272789001465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.533638715744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.539997816086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2494.54624915123, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70872, "time": 2519.0797595977783, "episode/length": 288.0, "episode/score": 0.056829003264553535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056829003264553535}
{"step": 70960, "time": 2522.1030564308167, "episode/length": 288.0, "episode/score": 0.033052904456070564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033052904456070564}
{"step": 71656, "time": 2543.872421503067, "episode/length": 288.0, "episode/score": 0.07512406499697022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07512406499697022}
{"step": 71672, "time": 2544.382401227951, "episode/length": 288.0, "episode/score": 0.06761707899799774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06761707899799774}
{"step": 71672, "time": 2544.390290260315, "episode/length": 288.0, "episode/score": 0.07416935157300486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07416935157300486}
{"step": 71672, "time": 2544.397327184677, "episode/length": 288.0, "episode/score": 0.06116636396056663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06116636396056663}
{"step": 72072, "time": 2557.149170398712, "episode/length": 288.0, "episode/score": 0.07023333349879124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07023333349879124}
{"step": 72408, "time": 2567.9068732261658, "episode/length": 288.0, "episode/score": 0.07478830714353535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07478830714353535}
{"step": 72544, "time": 2572.493764400482, "episode/length": 110.0, "episode/score": 0.6899692482724049, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.03371921963423574}
{"step": 73184, "time": 2592.8562531471252, "episode/length": 288.0, "episode/score": 0.060998777613122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060998777613122}
{"step": 73216, "time": 2593.8645236492157, "episode/length": 192.0, "episode/score": 0.4566748648560406, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.056674860059729326}
{"step": 73272, "time": 2595.523319721222, "episode/length": 288.0, "episode/score": 0.05999356207234996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999356207234996}
{"step": 73984, "time": 2618.9056940078735, "episode/length": 288.0, "episode/score": 0.06268663768332772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06268663768332772}
{"step": 73984, "time": 2618.9142320156097, "episode/length": 288.0, "episode/score": 0.07391973729659185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07391973729659185}
{"step": 74384, "time": 2631.623836040497, "episode/length": 288.0, "episode/score": 0.04159488962488922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04159488962488922}
{"step": 74720, "time": 2642.272162437439, "episode/length": 288.0, "episode/score": 0.036145193536981424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036145193536981424}
{"step": 74856, "time": 2646.3435497283936, "episode/length": 288.0, "episode/score": 0.06981194624177078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06981194624177078}
{"step": 75496, "time": 2666.6876287460327, "episode/length": 288.0, "episode/score": 0.06672855313297532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06672855313297532}
{"step": 75528, "time": 2667.6985247135162, "episode/length": 288.0, "episode/score": 0.038002006131023336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038002006131023336}
{"step": 75584, "time": 2669.7911479473114, "episode/length": 288.0, "episode/score": 0.04379865502289704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04379865502289704}
{"step": 76296, "time": 2692.114509344101, "episode/length": 288.0, "episode/score": 0.041278508162577054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041278508162577054}
{"step": 76296, "time": 2692.1224660873413, "episode/length": 288.0, "episode/score": 0.030563108129626926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030563108129626926}
{"step": 76696, "time": 2704.8447782993317, "episode/length": 288.0, "episode/score": 0.07146336527239328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07146336527239328}
{"step": 77032, "time": 2715.5564336776733, "episode/length": 288.0, "episode/score": 0.05999035119452856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999035119452856}
{"step": 77168, "time": 2720.105479955673, "episode/length": 288.0, "episode/score": 0.01143556749104846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01143556749104846}
{"step": 77448, "time": 2728.8483991622925, "episode/length": 239.0, "episode/score": 0.2882668262751622, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.035141815518386466}
{"step": 77808, "time": 2740.488323688507, "episode/length": 288.0, "episode/score": 0.05055019803523919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05055019803523919}
{"step": 77896, "time": 2743.0666513442993, "episode/length": 288.0, "episode/score": 0.030352137957436298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030352137957436298}
{"step": 78608, "time": 2766.021947622299, "episode/length": 288.0, "episode/score": 0.05054092508191843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05054092508191843}
{"step": 78608, "time": 2766.030515432358, "episode/length": 288.0, "episode/score": 0.05253162886060636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05253162886060636}
{"step": 79008, "time": 2778.7488384246826, "episode/length": 288.0, "episode/score": 0.055690497117211635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055690497117211635}
{"step": 79128, "time": 2782.3229715824127, "episode/length": 64.0, "episode/score": 0.8236336263735211, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.023633585814422986}
{"step": 79344, "time": 2789.4997379779816, "episode/length": 288.0, "episode/score": 0.027726443266942624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027726443266942624}
{"step": 79480, "time": 2793.5992181301117, "episode/length": 288.0, "episode/score": 0.03248763596582194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03248763596582194}
{"step": 79760, "time": 2802.7544317245483, "episode/length": 288.0, "episode/score": 0.050648004350136944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050648004350136944}
{"step": 80080, "time": 2818.862478494644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.8708186149597, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.877413749695, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.8837118148804, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.889873981476, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.8961300849915, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.9021995067596, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2818.90833234787, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80120, "time": 2819.972329854965, "episode/length": 288.0, "episode/score": 0.06040781639921988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06040781639921988}
{"step": 80208, "time": 2822.968193054199, "episode/length": 288.0, "episode/score": 0.049910934497177095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049910934497177095}
{"step": 80920, "time": 2845.1581552028656, "episode/length": 288.0, "episode/score": 0.03696346147575014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03696346147575014}
{"step": 81320, "time": 2857.8465342521667, "episode/length": 288.0, "episode/score": 0.04268646826761824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04268646826761824}
{"step": 81440, "time": 2861.881100654602, "episode/length": 288.0, "episode/score": 0.0637987781431093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0637987781431093}
{"step": 81656, "time": 2868.4727096557617, "episode/length": 288.0, "episode/score": 0.04641077947832173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04641077947832173}
{"step": 81792, "time": 2872.9860928058624, "episode/length": 288.0, "episode/score": 0.049668059930240815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049668059930240815}
{"step": 82072, "time": 2882.2091035842896, "episode/length": 288.0, "episode/score": 0.027956098148990804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027956098148990804}
{"step": 82432, "time": 2893.7917816638947, "episode/length": 288.0, "episode/score": 0.04833621937046928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04833621937046928}
{"step": 82520, "time": 2896.3622727394104, "episode/length": 288.0, "episode/score": 0.06972672777874322, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06972672777874322}
{"step": 83232, "time": 2919.214779615402, "episode/length": 288.0, "episode/score": 0.03154787743170573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03154787743170573}
{"step": 83632, "time": 2931.8715600967407, "episode/length": 288.0, "episode/score": 0.07876064018290663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07876064018290663}
{"step": 83752, "time": 2935.444702386856, "episode/length": 288.0, "episode/score": 0.044143698209467175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044143698209467175}
{"step": 83968, "time": 2942.694262742996, "episode/length": 288.0, "episode/score": 0.04498828461476023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04498828461476023}
{"step": 84104, "time": 2946.769288301468, "episode/length": 288.0, "episode/score": 0.046974639998495604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046974639998495604}
{"step": 84384, "time": 2955.901466846466, "episode/length": 288.0, "episode/score": 0.06385396726301451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06385396726301451}
{"step": 84640, "time": 2964.0230848789215, "episode/length": 175.0, "episode/score": 0.49356673684511065, "episode/reward_rate": 0.005681818181818182, "episode/intrinsic_return": 0.04044173800926387}
{"step": 84744, "time": 2967.104252099991, "episode/length": 288.0, "episode/score": 0.03860549793895984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03860549793895984}
{"step": 84832, "time": 2970.198295354843, "episode/length": 288.0, "episode/score": 0.040671311898080376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040671311898080376}
{"step": 85944, "time": 3005.233704805374, "episode/length": 288.0, "episode/score": 0.04599687826095078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04599687826095078}
{"step": 86064, "time": 3009.320065021515, "episode/length": 288.0, "episode/score": 0.05350157085200635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05350157085200635}
{"step": 86280, "time": 3015.902045726776, "episode/length": 288.0, "episode/score": 0.05659115328012376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05659115328012376}
{"step": 86416, "time": 3020.4285748004913, "episode/length": 288.0, "episode/score": 0.0386363597404511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0386363597404511}
{"step": 86696, "time": 3029.1815464496613, "episode/length": 288.0, "episode/score": 0.025154340013642695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025154340013642695}
{"step": 86952, "time": 3037.2576982975006, "episode/length": 288.0, "episode/score": 0.05120985348722229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05120985348722229}
{"step": 87056, "time": 3040.7844743728638, "episode/length": 288.0, "episode/score": 0.04842211727932977, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04842211727932977}
{"step": 87144, "time": 3043.343604326248, "episode/length": 288.0, "episode/score": 0.045552389445532526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045552389445532526}
{"step": 87560, "time": 3056.494422197342, "episode/length": 142.0, "episode/score": 0.589820713739698, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.033570738396463184}
{"step": 87864, "time": 3066.2309494018555, "episode/length": 37.0, "episode/score": 0.8931404152184541, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.00876541042214285}
{"step": 88256, "time": 3078.8068203926086, "episode/length": 288.0, "episode/score": 0.05710773760731058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05710773760731058}
{"step": 88376, "time": 3082.36714887619, "episode/length": 288.0, "episode/score": 0.05260310945325841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05260310945325841}
{"step": 88592, "time": 3089.5271286964417, "episode/length": 288.0, "episode/score": 0.043820448491317165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043820448491317165}
{"step": 89008, "time": 3102.7017641067505, "episode/length": 288.0, "episode/score": 0.03917152399509405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03917152399509405}
{"step": 89264, "time": 3110.8259336948395, "episode/length": 288.0, "episode/score": 0.022691318197871624, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022691318197871624}
{"step": 89368, "time": 3113.9069612026215, "episode/length": 288.0, "episode/score": 0.028424316129104454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028424316129104454}
{"step": 89456, "time": 3116.917650461197, "episode/length": 288.0, "episode/score": 0.03052187681531393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03052187681531393}
{"step": 90064, "time": 3142.158898115158, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.1660549640656, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.1722617149353, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.1784904003143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.1843297481537, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.19012093544, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.1957910060883, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3142.2017579078674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90176, "time": 3146.2177600860596, "episode/length": 288.0, "episode/score": 0.05231429269866794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05231429269866794}
{"step": 90568, "time": 3158.5215718746185, "episode/length": 288.0, "episode/score": 0.022450830497319885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022450830497319885}
{"step": 90688, "time": 3162.5157334804535, "episode/length": 288.0, "episode/score": 0.032711359634348014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032711359634348014}
{"step": 90904, "time": 3169.0483796596527, "episode/length": 288.0, "episode/score": 0.040209016952729826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040209016952729826}
{"step": 91320, "time": 3182.3067338466644, "episode/length": 288.0, "episode/score": 0.02217912553935264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02217912553935264}
{"step": 91576, "time": 3190.3747487068176, "episode/length": 288.0, "episode/score": 0.045495091345074457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045495091345074457}
{"step": 91680, "time": 3193.9055168628693, "episode/length": 288.0, "episode/score": 0.03685888454420194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03685888454420194}
{"step": 91768, "time": 3196.492087125778, "episode/length": 288.0, "episode/score": 0.045287310175069706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045287310175069706}
{"step": 92488, "time": 3219.396724462509, "episode/length": 288.0, "episode/score": 0.024939960129472638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024939960129472638}
{"step": 92880, "time": 3231.939038991928, "episode/length": 288.0, "episode/score": 0.04627317129762787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04627317129762787}
{"step": 93000, "time": 3235.5156795978546, "episode/length": 288.0, "episode/score": 0.041270614627933355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041270614627933355}
{"step": 93017, "time": 3237.0300283432007, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9999173482259116, "train/action_min": 0.0, "train/action_std": 2.0007222505907216, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001493922191002639, "train/actor_opt_grad_steps": 4755.0, "train/actor_opt_loss": 0.6020817247784483, "train/adv_mag": 0.0006520773167721927, "train/adv_max": 0.0006520773167721927, "train/adv_mean": 0.0003297316729155379, "train/adv_min": -5.878251977264881e-05, "train/adv_std": 0.00016114412143982312, "train/cont_avg": 0.9965260823567709, "train/cont_loss_mean": 0.023196820779655052, "train/cont_loss_std": 0.3176196393906139, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.666681359265302, "train/cont_pos_acc": 0.9999999906867743, "train/cont_pos_loss": 0.003503367170196725, "train/cont_pred": 0.996502920674781, "train/cont_rate": 0.9965260823567709, "train/dyn_loss_mean": 1.0090619139373302, "train/dyn_loss_std": 0.0003566791626023284, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.036994615831645206, "train/extr_critic_critic_opt_grad_steps": 4755.0, "train/extr_critic_critic_opt_loss": 13050.144704182943, "train/extr_critic_mag": 0.06361667501429717, "train/extr_critic_max": 0.06361667501429717, "train/extr_critic_mean": 0.06349220231641084, "train/extr_critic_min": 0.06341434766848882, "train/extr_critic_std": 2.930293041037794e-05, "train/extr_return_normed_mag": 0.0012172338902018964, "train/extr_return_normed_max": 0.0012172338902018964, "train/extr_return_normed_mean": 0.0009575365234013589, "train/extr_return_normed_min": 0.0006224572619733711, "train/extr_return_normed_std": 0.0001567878100937984, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06408164302896087, "train/extr_return_raw_max": 0.06408164302896087, "train/extr_return_raw_mean": 0.06382194925875713, "train/extr_return_raw_min": 0.06348686640073235, "train/extr_return_raw_std": 0.00015678781047275456, "train/extr_reward_mag": 0.0002430646369854609, "train/extr_reward_max": 0.0002430646369854609, "train/extr_reward_mean": 0.0002429370316197795, "train/extr_reward_min": 0.00024274115761121115, "train/extr_reward_std": 6.396865538139951e-08, "train/image_loss_mean": 0.25905100884847343, "train/image_loss_std": 0.08331569171665858, "train/model_loss_mean": 0.898790491434435, "train/model_loss_std": 0.3814830807968974, "train/model_opt_grad_norm": 64.80720939238866, "train/model_opt_grad_steps": 4745.0, "train/model_opt_loss": 183.20421079794565, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 204.26432291666666, "train/policy_entropy_mag": 1.9458963169405858, "train/policy_entropy_max": 1.9458963169405858, "train/policy_entropy_mean": 1.9452358229706685, "train/policy_entropy_min": 1.9329269714653492, "train/policy_entropy_std": 0.0004697514953780531, "train/policy_logprob_mag": 2.158303835739692, "train/policy_logprob_max": -1.750188025335471, "train/policy_logprob_mean": -1.9452508029838402, "train/policy_logprob_min": -2.158303835739692, "train/policy_logprob_std": 0.03659865172812715, "train/policy_randomness_mag": 0.9999929514403144, "train/policy_randomness_max": 0.9999929514403144, "train/policy_randomness_mean": 0.9996535247191787, "train/policy_randomness_min": 0.9933280249436697, "train/policy_randomness_std": 0.00024140453539682008, "train/post_ent_mag": 55.0365686416626, "train/post_ent_max": 55.0365686416626, "train/post_ent_mean": 54.98625751336416, "train/post_ent_min": 54.96389611562093, "train/post_ent_std": 0.010442674937318467, "train/prior_ent_mag": 55.951282024383545, "train/prior_ent_max": 55.951282024383545, "train/prior_ent_mean": 55.867837150891624, "train/prior_ent_min": 55.819897989432015, "train/prior_ent_std": 0.022451746067721007, "train/rep_loss_mean": 1.0090619139373302, "train/rep_loss_std": 0.0003566791626023284, "train/reward_avg": 0.00030690911307829083, "train/reward_loss_mean": 0.011105494258420853, "train/reward_loss_std": 0.07840004179646105, "train/reward_max_data": 0.12664605271978266, "train/reward_max_pred": 0.00024297026296456656, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008951605472248048, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.625008117861864, "train/reward_pred": 0.00024285891655987749, "train/reward_rate": 0.00022379557291666666, "train_stats/mean_log_entropy": 1.9376455428344863, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.031115099787712097, "report/cont_loss_std": 0.3946031332015991, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6644110679626465, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034738013055175543, "report/cont_pred": 0.9965324401855469, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2607087194919586, "report/image_loss_std": 0.0778941810131073, "report/model_loss_mean": 0.9008973836898804, "report/model_loss_std": 0.40584704279899597, "report/post_ent_mag": 54.52029800415039, "report/post_ent_max": 54.52029800415039, "report/post_ent_mean": 54.51176071166992, "report/post_ent_min": 54.48313522338867, "report/post_ent_std": 0.006284242961555719, "report/prior_ent_mag": 53.48126983642578, "report/prior_ent_max": 53.48126983642578, "report/prior_ent_mean": 53.46323013305664, "report/prior_ent_min": 53.445404052734375, "report/prior_ent_std": 0.004721659701317549, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001797518925741315, "report/reward_loss_mean": 0.009073594585061073, "report/reward_loss_std": 0.015593231655657291, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00027632713317871094, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009073594585061073, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00027516577392816544, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0034742611460387707, "eval/cont_loss_std": 4.443802026798949e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034742611460387707, "eval/cont_pred": 0.9965319633483887, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2545278072357178, "eval/image_loss_std": 0.07646065950393677, "eval/model_loss_mean": 0.8595128059387207, "eval/model_loss_std": 0.0764605775475502, "eval/post_ent_mag": 54.52104949951172, "eval/post_ent_max": 54.52104949951172, "eval/post_ent_mean": 54.51226043701172, "eval/post_ent_min": 54.483848571777344, "eval/post_ent_std": 0.005907746497541666, "eval/prior_ent_mag": 53.480712890625, "eval/prior_ent_max": 53.480712890625, "eval/prior_ent_mean": 53.463287353515625, "eval/prior_ent_min": 53.445335388183594, "eval/prior_ent_std": 0.004780901130288839, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015107411891222, "eval/reward_loss_std": 8.578183496865677e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00027632713317871094, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015107411891222, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00027515669353306293, "eval/reward_rate": 0.0, "replay/size": 92513.0, "replay/inserts": 30816.0, "replay/samples": 30816.0, "replay/insert_wait_avg": 1.2623511742208606e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0148340667890984e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1078764135587312e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0668122768402, "timer/env.step_count": 3852.0, "timer/env.step_total": 37.25733542442322, "timer/env.step_frac": 0.03725484634331569, "timer/env.step_avg": 0.009672205458053794, "timer/env.step_min": 0.007816076278686523, "timer/env.step_max": 0.0970146656036377, "timer/replay._sample_count": 30816.0, "timer/replay._sample_total": 16.28771996498108, "timer/replay._sample_frac": 0.01628663181802726, "timer/replay._sample_avg": 0.0005285475066517743, "timer/replay._sample_min": 0.0003974437713623047, "timer/replay._sample_max": 0.011220455169677734, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4719.0, "timer/agent.policy_total": 49.10250544548035, "timer/agent.policy_frac": 0.04909922501446604, "timer/agent.policy_avg": 0.010405277695588121, "timer/agent.policy_min": 0.008934497833251953, "timer/agent.policy_max": 0.09198832511901855, "timer/dataset_train_count": 1926.0, "timer/dataset_train_total": 0.21081161499023438, "timer/dataset_train_frac": 0.00021079753112722747, "timer/dataset_train_avg": 0.00010945566718080705, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0004153251647949219, "timer/agent.train_count": 1926.0, "timer/agent.train_total": 861.7226066589355, "timer/agent.train_frac": 0.8616650368559496, "timer/agent.train_avg": 0.44741568362353873, "timer/agent.train_min": 0.43554091453552246, "timer/agent.train_max": 0.9684031009674072, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4734025001525879, "timer/agent.report_frac": 0.0004733708731667618, "timer/agent.report_avg": 0.23670125007629395, "timer/agent.report_min": 0.22598743438720703, "timer/agent.report_max": 0.24741506576538086, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4091579075504325e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 30.813425685942576}
{"step": 93216, "time": 3243.4266016483307, "episode/length": 288.0, "episode/score": 0.05713608362822242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05713608362822242}
{"step": 93632, "time": 3256.542219877243, "episode/length": 288.0, "episode/score": 0.058735544136482076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058735544136482076}
{"step": 93888, "time": 3264.6132690906525, "episode/length": 288.0, "episode/score": 0.027796034738571507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027796034738571507}
{"step": 93992, "time": 3267.6602444648743, "episode/length": 288.0, "episode/score": 0.03421107835555404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03421107835555404}
{"step": 94072, "time": 3270.3244693279266, "episode/length": 106.0, "episode/score": 0.6948817845974418, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.02613176788020155}
{"step": 94080, "time": 3270.8093054294586, "episode/length": 288.0, "episode/score": 0.05480614521195548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05480614521195548}
{"step": 94800, "time": 3293.536948442459, "episode/length": 288.0, "episode/score": 0.034404931496226254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034404931496226254}
{"step": 95192, "time": 3305.8374841213226, "episode/length": 288.0, "episode/score": 0.0463841203502966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0463841203502966}
{"step": 95312, "time": 3309.9449667930603, "episode/length": 288.0, "episode/score": 0.05407876422123081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05407876422123081}
{"step": 95816, "time": 3325.666328430176, "episode/length": 216.0, "episode/score": 0.35297136916915406, "episode/reward_rate": 0.004608294930875576, "episode/intrinsic_return": 0.02797136677099843}
{"step": 95944, "time": 3329.7794172763824, "episode/length": 288.0, "episode/score": 0.02056986893779822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02056986893779822}
{"step": 96064, "time": 3333.8232851028442, "episode/length": 108.0, "episode/score": 0.6845283054803417, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.022028253000314635}
{"step": 96200, "time": 3337.9245834350586, "episode/length": 288.0, "episode/score": 0.02488081442697876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02488081442697876}
{"step": 96304, "time": 3341.4406900405884, "episode/length": 288.0, "episode/score": 0.05552969419301235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05552969419301235}
{"step": 96384, "time": 3343.9609246253967, "episode/length": 288.0, "episode/score": 0.039173893320537445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039173893320537445}
{"step": 97112, "time": 3366.8019037246704, "episode/length": 288.0, "episode/score": 0.03798852074123715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03798852074123715}
{"step": 97624, "time": 3382.9602761268616, "episode/length": 288.0, "episode/score": 0.05444705971504504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05444705971504504}
{"step": 98128, "time": 3399.1763372421265, "episode/length": 288.0, "episode/score": 0.03540762469992842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03540762469992842}
{"step": 98256, "time": 3403.274152994156, "episode/length": 288.0, "episode/score": 0.03772040602547122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03772040602547122}
{"step": 98376, "time": 3407.3249340057373, "episode/length": 288.0, "episode/score": 0.05155366664041594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05155366664041594}
{"step": 98512, "time": 3411.8777701854706, "episode/length": 288.0, "episode/score": 0.04238451388641806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04238451388641806}
{"step": 98616, "time": 3414.930937767029, "episode/length": 288.0, "episode/score": 0.033368956018023255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033368956018023255}
{"step": 98680, "time": 3416.9664340019226, "episode/length": 52.0, "episode/score": 0.8493903812461667, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.011890405902931889}
{"step": 98696, "time": 3417.479583501816, "episode/length": 288.0, "episode/score": 0.03940257702285521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03940257702285521}
{"step": 99424, "time": 3440.759448289871, "episode/length": 288.0, "episode/score": 0.03705819629067264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03705819629067264}
{"step": 99936, "time": 3457.0413410663605, "episode/length": 288.0, "episode/score": 0.04573002750589694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04573002750589694}
{"step": 100048, "time": 3464.436266183853, "eval_episode/length": 213.0, "eval_episode/score": 0.3343749940395355, "eval_episode/reward_rate": 0.004672897196261682}
{"step": 100048, "time": 3465.8056218624115, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3465.812701702118, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3465.818879365921, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3465.82492518425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3465.8317255973816, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3465.8384857177734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3465.844468355179, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100440, "time": 3478.0152995586395, "episode/length": 288.0, "episode/score": 0.027105103626269056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027105103626269056}
{"step": 100688, "time": 3486.17085981369, "episode/length": 288.0, "episode/score": 0.020901344444780534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020901344444780534}
{"step": 100824, "time": 3490.2337164878845, "episode/length": 288.0, "episode/score": 0.04456939667917936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04456939667917936}
{"step": 100928, "time": 3493.7843132019043, "episode/length": 288.0, "episode/score": 0.036348112416419553, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036348112416419553}
{"step": 100992, "time": 3495.847223997116, "episode/length": 288.0, "episode/score": 0.04374610456144978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04374610456144978}
{"step": 101008, "time": 3496.3627207279205, "episode/length": 288.0, "episode/score": 0.031621931121947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031621931121947}
{"step": 101736, "time": 3519.332718849182, "episode/length": 288.0, "episode/score": 0.019394617973546247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019394617973546247}
{"step": 102248, "time": 3535.4966382980347, "episode/length": 288.0, "episode/score": 0.028379700281789155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028379700281789155}
{"step": 102752, "time": 3551.796717405319, "episode/length": 288.0, "episode/score": 0.03797258380984658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03797258380984658}
{"step": 103000, "time": 3559.4340040683746, "episode/length": 288.0, "episode/score": 0.029425645502669795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029425645502669795}
{"step": 103136, "time": 3563.931229352951, "episode/length": 288.0, "episode/score": 0.03485395568225158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03485395568225158}
{"step": 103240, "time": 3567.016570329666, "episode/length": 288.0, "episode/score": 0.0381961163195399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0381961163195399}
{"step": 103304, "time": 3569.150411128998, "episode/length": 288.0, "episode/score": 0.03386542623459832, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03386542623459832}
{"step": 103320, "time": 3569.6825869083405, "episode/length": 288.0, "episode/score": 0.037286201555986054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037286201555986054}
{"step": 103392, "time": 3572.192042827606, "episode/length": 31.0, "episode/score": 0.9129554602693872, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.009830443552147017}
{"step": 104048, "time": 3592.8900871276855, "episode/length": 288.0, "episode/score": 0.028223641751310424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028223641751310424}
{"step": 104560, "time": 3609.124645471573, "episode/length": 288.0, "episode/score": 0.03410155453880748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03410155453880748}
{"step": 105064, "time": 3624.782912492752, "episode/length": 288.0, "episode/score": 0.030027668798311424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030027668798311424}
{"step": 105312, "time": 3632.9925169944763, "episode/length": 288.0, "episode/score": 0.04183596899706288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04183596899706288}
{"step": 105552, "time": 3640.618228673935, "episode/length": 288.0, "episode/score": 0.0365987516464088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0365987516464088}
{"step": 105616, "time": 3642.6550390720367, "episode/length": 288.0, "episode/score": 0.04311043806615089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04311043806615089}
{"step": 105632, "time": 3643.165476322174, "episode/length": 288.0, "episode/score": 0.038927247270294174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038927247270294174}
{"step": 105704, "time": 3645.2168736457825, "episode/length": 288.0, "episode/score": 0.036100461929038374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036100461929038374}
{"step": 106360, "time": 3666.042849302292, "episode/length": 288.0, "episode/score": 0.028995132269528767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028995132269528767}
{"step": 106872, "time": 3682.7294404506683, "episode/length": 288.0, "episode/score": 0.037416456985383206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037416456985383206}
{"step": 107376, "time": 3698.9646673202515, "episode/length": 288.0, "episode/score": 0.028365622672438917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028365622672438917}
{"step": 107624, "time": 3706.5126361846924, "episode/length": 288.0, "episode/score": 0.025175605252186983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025175605252186983}
{"step": 107864, "time": 3714.1035108566284, "episode/length": 288.0, "episode/score": 0.0416655411949165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0416655411949165}
{"step": 107928, "time": 3716.1155099868774, "episode/length": 288.0, "episode/score": 0.028896773789838903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028896773789838903}
{"step": 107944, "time": 3716.6240694522858, "episode/length": 288.0, "episode/score": 0.02033176365091549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02033176365091549}
{"step": 108016, "time": 3719.2409749031067, "episode/length": 288.0, "episode/score": 0.02553161575437457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02553161575437457}
{"step": 108672, "time": 3740.140481233597, "episode/length": 288.0, "episode/score": 0.04285173536993625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04285173536993625}
{"step": 109184, "time": 3756.328366279602, "episode/length": 288.0, "episode/score": 0.03250277755745401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03250277755745401}
{"step": 109688, "time": 3771.9260425567627, "episode/length": 288.0, "episode/score": 0.03841658120998659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03841658120998659}
{"step": 109936, "time": 3780.132246494293, "episode/length": 288.0, "episode/score": 0.05199068036078813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05199068036078813}
{"step": 110032, "time": 3788.271164894104, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.2843658924103, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.290940761566, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.2974936962128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.3034751415253, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.3092761039734, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.31525850296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3788.321090221405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110176, "time": 3792.8743782043457, "episode/length": 288.0, "episode/score": 0.03652619305918847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03652619305918847}
{"step": 110240, "time": 3794.895154953003, "episode/length": 288.0, "episode/score": 0.05230346086274551, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05230346086274551}
{"step": 110256, "time": 3795.4064457416534, "episode/length": 288.0, "episode/score": 0.0241217322696059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0241217322696059}
{"step": 110328, "time": 3797.44544506073, "episode/length": 288.0, "episode/score": 0.02233913221114392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02233913221114392}
{"step": 110984, "time": 3818.2430398464203, "episode/length": 288.0, "episode/score": 0.026998679123281022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026998679123281022}
{"step": 111496, "time": 3834.4037747383118, "episode/length": 288.0, "episode/score": 0.03831996094700685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03831996094700685}
{"step": 112000, "time": 3850.5994997024536, "episode/length": 288.0, "episode/score": 0.018413200834942245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018413200834942245}
{"step": 112248, "time": 3858.1997628211975, "episode/length": 288.0, "episode/score": 0.04332303518640401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04332303518640401}
{"step": 112488, "time": 3865.7683384418488, "episode/length": 288.0, "episode/score": 0.038192244584706714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038192244584706714}
{"step": 112552, "time": 3867.783121585846, "episode/length": 288.0, "episode/score": 0.028705293982170588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028705293982170588}
{"step": 112568, "time": 3868.2921595573425, "episode/length": 288.0, "episode/score": 0.04103572630430108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04103572630430108}
{"step": 112640, "time": 3870.9250333309174, "episode/length": 288.0, "episode/score": 0.041682453250530216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041682453250530216}
{"step": 113296, "time": 3891.621306180954, "episode/length": 288.0, "episode/score": 0.044890842917880036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044890842917880036}
{"step": 113808, "time": 3907.7764666080475, "episode/length": 288.0, "episode/score": 0.026332018125401646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026332018125401646}
{"step": 114280, "time": 3922.4057183265686, "episode/length": 213.0, "episode/score": 0.3539599172954695, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.019584924070841225}
{"step": 114312, "time": 3923.4079270362854, "episode/length": 288.0, "episode/score": 0.05650509406217452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05650509406217452}
{"step": 114560, "time": 3931.537561893463, "episode/length": 288.0, "episode/score": 0.024646360025997183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024646360025997183}
{"step": 114800, "time": 3939.5765540599823, "episode/length": 288.0, "episode/score": 0.024102897753323305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024102897753323305}
{"step": 114864, "time": 3941.5999937057495, "episode/length": 288.0, "episode/score": 0.04317026479799324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04317026479799324}
{"step": 114928, "time": 3943.604774951935, "episode/length": 139.0, "episode/score": 0.5998260316493997, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.03420099109030161}
{"step": 114952, "time": 3944.141424179077, "episode/length": 288.0, "episode/score": 0.028204394150350254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028204394150350254}
{"step": 115608, "time": 3964.897316455841, "episode/length": 288.0, "episode/score": 0.043334919941969474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043334919941969474}
{"step": 116592, "time": 3996.3223435878754, "episode/length": 288.0, "episode/score": 0.025865654835513396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025865654835513396}
{"step": 116624, "time": 3997.350846529007, "episode/length": 288.0, "episode/score": 0.034093172233383484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034093172233383484}
{"step": 116872, "time": 4005.030980825424, "episode/length": 288.0, "episode/score": 0.021066072071789677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021066072071789677}
{"step": 117112, "time": 4012.722645044327, "episode/length": 288.0, "episode/score": 0.02837420866313778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02837420866313778}
{"step": 117176, "time": 4014.7480385303497, "episode/length": 288.0, "episode/score": 0.02749426882479611, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02749426882479611}
{"step": 117240, "time": 4016.769051551819, "episode/length": 288.0, "episode/score": 0.028584261656419585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028584261656419585}
{"step": 117264, "time": 4017.744097471237, "episode/length": 288.0, "episode/score": 0.038330479384626415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038330479384626415}
{"step": 117544, "time": 4026.4516820907593, "episode/length": 37.0, "episode/score": 0.8961116632368658, "episode/reward_rate": 0.02631578947368421, "episode/intrinsic_return": 0.011736687893630915}
{"step": 117920, "time": 4038.486362218857, "episode/length": 288.0, "episode/score": 0.036009597770771506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036009597770771506}
{"step": 118592, "time": 4059.8176624774933, "episode/length": 176.0, "episode/score": 0.46708583551486527, "episode/reward_rate": 0.005649717514124294, "episode/intrinsic_return": 0.017085853896844583}
{"step": 118904, "time": 4069.4438309669495, "episode/length": 288.0, "episode/score": 0.03987871085496408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03987871085496408}
{"step": 118936, "time": 4070.4648859500885, "episode/length": 288.0, "episode/score": 0.03217723660364413, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03217723660364413}
{"step": 119184, "time": 4078.542414665222, "episode/length": 288.0, "episode/score": 0.02904318215681201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02904318215681201}
{"step": 119424, "time": 4086.2468073368073, "episode/length": 288.0, "episode/score": 0.02717044427890869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02717044427890869}
{"step": 119576, "time": 4090.8204555511475, "episode/length": 288.0, "episode/score": 0.0401116773721526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0401116773721526}
{"step": 119856, "time": 4099.84970164299, "episode/length": 288.0, "episode/score": 0.036288495958103795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036288495958103795}
{"step": 120016, "time": 4110.097798347473, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.105134963989, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.111736774445, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.117956876755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.124921798706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.13158249855, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.137830495834, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4110.144100666046, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120232, "time": 4116.691430091858, "episode/length": 288.0, "episode/score": 0.051920647975350676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051920647975350676}
{"step": 120904, "time": 4137.756286382675, "episode/length": 288.0, "episode/score": 0.07844991941246349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07844991941246349}
{"step": 121216, "time": 4148.0053107738495, "episode/length": 288.0, "episode/score": 0.0767968499804681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0767968499804681}
{"step": 121248, "time": 4149.034722805023, "episode/length": 288.0, "episode/score": 0.08610403069897643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08610403069897643}
{"step": 121496, "time": 4156.656051158905, "episode/length": 288.0, "episode/score": 0.058174428029303726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058174428029303726}
{"step": 121736, "time": 4164.217732667923, "episode/length": 288.0, "episode/score": 0.07461491100787043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07461491100787043}
{"step": 121888, "time": 4169.300272703171, "episode/length": 288.0, "episode/score": 0.05588706895235873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05588706895235873}
{"step": 122168, "time": 4177.825858592987, "episode/length": 288.0, "episode/score": 0.045433128932813815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045433128932813815}
{"step": 122544, "time": 4189.874205112457, "episode/length": 288.0, "episode/score": 0.06634931068819583, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06634931068819583}
{"step": 123216, "time": 4211.517663240433, "episode/length": 288.0, "episode/score": 0.04748545054934539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04748545054934539}
{"step": 123528, "time": 4221.030139923096, "episode/length": 288.0, "episode/score": 0.0685430619356282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0685430619356282}
{"step": 123560, "time": 4222.033042907715, "episode/length": 288.0, "episode/score": 0.031968884034455414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031968884034455414}
{"step": 123808, "time": 4230.139938831329, "episode/length": 288.0, "episode/score": 0.07291659457237643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07291659457237643}
{"step": 124009, "time": 4237.171838760376, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999941167143202, "train/action_min": 0.0, "train/action_std": 1.9993118397968332, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010262980248223085, "train/actor_opt_grad_steps": 6685.0, "train/actor_opt_loss": -1.2158034508567803, "train/adv_mag": 0.0005090689843462914, "train/adv_max": 0.0005036518361765085, "train/adv_mean": 0.00023453328334578625, "train/adv_min": -8.971082795526563e-05, "train/adv_std": 0.0001249381510290535, "train/cont_avg": 0.9964612193943299, "train/cont_loss_mean": 0.023541246462834172, "train/cont_loss_std": 0.3236386567477226, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.656440824738348, "train/cont_pos_acc": 0.9999999855596995, "train/cont_pos_loss": 0.003544033611836584, "train/cont_pred": 0.996462394281761, "train/cont_rate": 0.9964612193943299, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.022263051208694342, "train/extr_critic_critic_opt_grad_steps": 6685.0, "train/extr_critic_critic_opt_loss": 13445.553872019975, "train/extr_critic_mag": 0.07460770779049274, "train/extr_critic_max": 0.07460770779049274, "train/extr_critic_mean": 0.07447904759307497, "train/extr_critic_min": 0.0743991357764018, "train/extr_critic_std": 3.082349909494863e-05, "train/extr_return_normed_mag": 0.0008903670019095706, "train/extr_return_normed_max": 0.0008894087573916642, "train/extr_return_normed_mean": 0.0006869686744534023, "train/extr_return_normed_min": 0.0004253519564559779, "train/extr_return_normed_std": 0.00011752193508935718, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07491604119692881, "train/extr_return_raw_max": 0.07491604119692881, "train/extr_return_raw_mean": 0.07471360508160493, "train/extr_return_raw_min": 0.07445198439599313, "train/extr_return_raw_std": 0.00011752193582070344, "train/extr_reward_mag": 0.00026109046542767395, "train/extr_reward_max": 0.00026109046542767395, "train/extr_reward_mean": 0.00026096153245835576, "train/extr_reward_min": 0.00026082378072836963, "train/extr_reward_std": 6.896520554003904e-08, "train/image_loss_mean": 0.2536129671888253, "train/image_loss_std": 0.08436874277198438, "train/model_loss_mean": 0.8879443330248606, "train/model_loss_std": 0.3870191639001222, "train/model_opt_grad_norm": 55.77004836760845, "train/model_opt_grad_steps": 6675.0, "train/model_opt_loss": 695.411235848653, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 782.860824742268, "train/policy_entropy_mag": 1.9458993095712565, "train/policy_entropy_max": 1.9458993095712565, "train/policy_entropy_mean": 1.9454006749330108, "train/policy_entropy_min": 1.9365431082617377, "train/policy_entropy_std": 0.0003512826710387335, "train/policy_logprob_mag": 2.131786062545383, "train/policy_logprob_max": -1.7756471412698018, "train/policy_logprob_mean": -1.9453794483057003, "train/policy_logprob_min": -2.131786062545383, "train/policy_logprob_std": 0.03186716459038639, "train/policy_randomness_mag": 0.9999944893355223, "train/policy_randomness_max": 0.9999944893355223, "train/policy_randomness_mean": 0.9997382375997367, "train/policy_randomness_min": 0.9951863519309723, "train/policy_randomness_std": 0.0001805235963157551, "train/post_ent_mag": 54.36770344763687, "train/post_ent_max": 54.36770344763687, "train/post_ent_mean": 54.3574694210721, "train/post_ent_min": 54.325832543913855, "train/post_ent_std": 0.00711074937855076, "train/prior_ent_mag": 53.523607077057825, "train/prior_ent_max": 53.523607077057825, "train/prior_ent_mean": 53.5074479211237, "train/prior_ent_min": 53.486872486232485, "train/prior_ent_std": 0.004552618282386246, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0003007415136155557, "train/reward_loss_mean": 0.010790097344781934, "train/reward_loss_std": 0.0777163342764774, "train/reward_max_data": 0.12119738204817566, "train/reward_max_pred": 0.00026121704848771244, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00848505758565188, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.366736948490143, "train/reward_pred": 0.00026108299924502363, "train/reward_rate": 0.0002466575386597938, "train_stats/mean_log_entropy": 1.9371540865727834, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.0036995909176766872, "report/cont_loss_std": 1.186272015729628e-06, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036995909176766872, "report/cont_pred": 0.9963072538375854, "report/cont_rate": 1.0, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25090497732162476, "report/image_loss_std": 0.08217290788888931, "report/model_loss_mean": 0.8625491261482239, "report/model_loss_std": 0.08677004277706146, "report/post_ent_mag": 54.249046325683594, "report/post_ent_max": 54.249046325683594, "report/post_ent_mean": 54.238922119140625, "report/post_ent_min": 54.20133972167969, "report/post_ent_std": 0.007997010834515095, "report/prior_ent_mag": 53.56188201904297, "report/prior_ent_max": 53.56188201904297, "report/prior_ent_mean": 53.55126190185547, "report/prior_ent_min": 53.52708435058594, "report/prior_ent_std": 0.0049887229688465595, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015481628361158073, "report/reward_loss_mean": 0.007944594137370586, "report/reward_loss_std": 0.01456478051841259, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002288818359375, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007944594137370586, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00022886740043759346, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0036996188573539257, "eval/cont_loss_std": 1.0035680588771356e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0036996188573539257, "eval/cont_pred": 0.9963072538375854, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.26121237874031067, "eval/image_loss_std": 0.08687768876552582, "eval/model_loss_mean": 0.8660928010940552, "eval/model_loss_std": 0.08687765151262283, "eval/post_ent_mag": 54.2503776550293, "eval/post_ent_max": 54.2503776550293, "eval/post_ent_mean": 54.23889923095703, "eval/post_ent_min": 54.20275115966797, "eval/post_ent_std": 0.007808052934706211, "eval/prior_ent_mag": 53.56376647949219, "eval/prior_ent_max": 53.56376647949219, "eval/prior_ent_mean": 53.55113983154297, "eval/prior_ent_min": 53.52708435058594, "eval/prior_ent_std": 0.005085310433059931, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011807959526777267, "eval/reward_loss_std": 3.444987157763535e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002288818359375, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011807959526777267, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00022886809892952442, "eval/reward_rate": 0.0, "replay/size": 123505.0, "replay/inserts": 30992.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.2633907591859643e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.053374393366635e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0965329690513038e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.087784767150879e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.124189376831, "timer/env.step_count": 3874.0, "timer/env.step_total": 36.880534410476685, "timer/env.step_frac": 0.03687595480862895, "timer/env.step_avg": 0.009520014045037864, "timer/env.step_min": 0.007719993591308594, "timer/env.step_max": 0.03917860984802246, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 16.335853815078735, "timer/replay._sample_frac": 0.01633382532749005, "timer/replay._sample_avg": 0.0005270990518546313, "timer/replay._sample_min": 0.00037550926208496094, "timer/replay._sample_max": 0.01185917854309082, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4741.0, "timer/agent.policy_total": 47.80703020095825, "timer/agent.policy_frac": 0.04780109381290579, "timer/agent.policy_avg": 0.01008374397826582, "timer/agent.policy_min": 0.008829593658447266, "timer/agent.policy_max": 0.09021258354187012, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.20807337760925293, "timer/dataset_train_frac": 0.00020804754031487, "timer/dataset_train_avg": 0.00010742043242604694, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0010783672332763672, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 864.0093846321106, "timer/agent.train_frac": 0.8639020971690201, "timer/agent.train_avg": 0.4460554386329946, "timer/agent.train_min": 0.43449974060058594, "timer/agent.train_max": 0.591742992401123, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744606018066406, "timer/agent.report_frac": 0.0004744016861568692, "timer/agent.report_avg": 0.2372303009033203, "timer/agent.report_min": 0.2299213409423828, "timer/agent.report_max": 0.2445392608642578, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.19441224789453e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 30.98762102179082}
{"step": 124048, "time": 4238.383255243301, "episode/length": 288.0, "episode/score": 0.04084495294955559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04084495294955559}
{"step": 124200, "time": 4242.933410167694, "episode/length": 288.0, "episode/score": 0.06594237586702434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06594237586702434}
{"step": 124480, "time": 4251.977577447891, "episode/length": 288.0, "episode/score": 0.060093614457827016, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060093614457827016}
{"step": 124856, "time": 4263.74364566803, "episode/length": 288.0, "episode/score": 0.040897016615531356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040897016615531356}
{"step": 125528, "time": 4284.878102302551, "episode/length": 288.0, "episode/score": 0.08150428684214717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08150428684214717}
{"step": 125840, "time": 4294.91898393631, "episode/length": 288.0, "episode/score": 0.05461597554526065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05461597554526065}
{"step": 125872, "time": 4295.939896583557, "episode/length": 288.0, "episode/score": 0.04537045607000323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04537045607000323}
{"step": 126120, "time": 4303.539606332779, "episode/length": 288.0, "episode/score": 0.07336177704945612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07336177704945612}
{"step": 126360, "time": 4311.088165044785, "episode/length": 288.0, "episode/score": 0.06618527974285371, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06618527974285371}
{"step": 126512, "time": 4316.087344169617, "episode/length": 288.0, "episode/score": 0.0640140997343508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0640140997343508}
{"step": 126792, "time": 4324.770366668701, "episode/length": 288.0, "episode/score": 0.02908610997553751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02908610997553751}
{"step": 127168, "time": 4336.748029708862, "episode/length": 288.0, "episode/score": 0.058917138396878954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058917138396878954}
{"step": 127840, "time": 4357.856310844421, "episode/length": 288.0, "episode/score": 0.06461675070349315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06461675070349315}
{"step": 128152, "time": 4367.396136045456, "episode/length": 288.0, "episode/score": 0.04827310941860219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04827310941860219}
{"step": 128184, "time": 4368.400905132294, "episode/length": 288.0, "episode/score": 0.0492722799652654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0492722799652654}
{"step": 128432, "time": 4376.416280508041, "episode/length": 288.0, "episode/score": 0.050811536359418596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050811536359418596}
{"step": 128672, "time": 4384.028389215469, "episode/length": 288.0, "episode/score": 0.057235910641992405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057235910641992405}
{"step": 128824, "time": 4388.561089038849, "episode/length": 288.0, "episode/score": 0.050011366494658205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050011366494658205}
{"step": 129104, "time": 4397.567508459091, "episode/length": 288.0, "episode/score": 0.056387704271941175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056387704271941175}
{"step": 129480, "time": 4409.2421634197235, "episode/length": 288.0, "episode/score": 0.04483112869496608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04483112869496608}
{"step": 130000, "time": 4431.548351764679, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.55609536171, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.562605142593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.569042682648, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.575578689575, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.582727193832, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.593944311142, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4431.603723287582, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130152, "time": 4436.155803203583, "episode/length": 288.0, "episode/score": 0.0629902283664876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0629902283664876}
{"step": 130464, "time": 4446.265315771103, "episode/length": 288.0, "episode/score": 0.04707719524910203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04707719524910203}
{"step": 130496, "time": 4447.268337965012, "episode/length": 288.0, "episode/score": 0.04732647094003539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04732647094003539}
{"step": 130744, "time": 4454.8332686424255, "episode/length": 288.0, "episode/score": 0.06568804728793509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06568804728793509}
{"step": 130984, "time": 4462.458116769791, "episode/length": 288.0, "episode/score": 0.06934390076551722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06934390076551722}
{"step": 131136, "time": 4468.003560781479, "episode/length": 288.0, "episode/score": 0.05142852208524573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05142852208524573}
{"step": 131416, "time": 4476.652731895447, "episode/length": 288.0, "episode/score": 0.048123612081468536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048123612081468536}
{"step": 131792, "time": 4488.634473085403, "episode/length": 288.0, "episode/score": 0.04563541241581959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04563541241581959}
{"step": 131920, "time": 4492.644045114517, "episode/length": 220.0, "episode/score": 0.35401402620124145, "episode/reward_rate": 0.004524886877828055, "episode/intrinsic_return": 0.0415140270161487}
{"step": 132776, "time": 4519.413060903549, "episode/length": 288.0, "episode/score": 0.0490266752959343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0490266752959343}
{"step": 132808, "time": 4520.41782951355, "episode/length": 288.0, "episode/score": 0.05551583049538067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05551583049538067}
{"step": 133056, "time": 4528.397181510925, "episode/length": 288.0, "episode/score": 0.04271412780808248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04271412780808248}
{"step": 133296, "time": 4535.987273931503, "episode/length": 288.0, "episode/score": 0.036803235573245274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036803235573245274}
{"step": 133448, "time": 4540.571492195129, "episode/length": 288.0, "episode/score": 0.053998415273099454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053998415273099454}
{"step": 133728, "time": 4549.583358287811, "episode/length": 288.0, "episode/score": 0.06337234521153334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06337234521153334}
{"step": 134104, "time": 4561.253386735916, "episode/length": 288.0, "episode/score": 0.04427542413107233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04427542413107233}
{"step": 134232, "time": 4565.2770664691925, "episode/length": 288.0, "episode/score": 0.05233450577479459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05233450577479459}
{"step": 135088, "time": 4592.914617300034, "episode/length": 288.0, "episode/score": 0.02865240194196872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02865240194196872}
{"step": 135120, "time": 4593.922204732895, "episode/length": 288.0, "episode/score": 0.03953495049427147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03953495049427147}
{"step": 135368, "time": 4601.490004777908, "episode/length": 288.0, "episode/score": 0.0386145743673012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0386145743673012}
{"step": 135608, "time": 4609.139351129532, "episode/length": 288.0, "episode/score": 0.06764356276725891, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06764356276725891}
{"step": 135760, "time": 4614.182519674301, "episode/length": 288.0, "episode/score": 0.04821596483539281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04821596483539281}
{"step": 136040, "time": 4622.921177625656, "episode/length": 288.0, "episode/score": 0.0399008862182626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0399008862182626}
{"step": 136416, "time": 4634.921013355255, "episode/length": 288.0, "episode/score": 0.0488193708403486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0488193708403486}
{"step": 136544, "time": 4638.98051738739, "episode/length": 288.0, "episode/score": 0.08199046026311407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08199046026311407}
{"step": 137400, "time": 4665.696950912476, "episode/length": 288.0, "episode/score": 0.08074711248893607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08074711248893607}
{"step": 137432, "time": 4666.702334165573, "episode/length": 288.0, "episode/score": 0.06539182403656696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06539182403656696}
{"step": 137680, "time": 4674.693728208542, "episode/length": 288.0, "episode/score": 0.0708484124044162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0708484124044162}
{"step": 137920, "time": 4682.375061750412, "episode/length": 288.0, "episode/score": 0.044331842489512496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044331842489512496}
{"step": 138072, "time": 4686.950614452362, "episode/length": 288.0, "episode/score": 0.06117212772518599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06117212772518599}
{"step": 138352, "time": 4696.003475427628, "episode/length": 288.0, "episode/score": 0.061867173284397836, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061867173284397836}
{"step": 138728, "time": 4707.610516548157, "episode/length": 288.0, "episode/score": 0.06674168614763687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06674168614763687}
{"step": 138800, "time": 4710.148437976837, "episode/length": 174.0, "episode/score": 0.49288244151480853, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.036632415274794994}
{"step": 138856, "time": 4711.714955568314, "episode/length": 288.0, "episode/score": 0.06868097381789084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06868097381789084}
{"step": 139744, "time": 4740.416365146637, "episode/length": 288.0, "episode/score": 0.05578637645660933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05578637645660933}
{"step": 139992, "time": 4747.993159294128, "episode/length": 288.0, "episode/score": 0.0408244600325105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0408244600325105}
{"step": 140088, "time": 4756.087903261185, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.095487356186, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.102011680603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.10826253891, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.11513209343, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.121389627457, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.127749204636, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4756.133941411972, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140232, "time": 4760.638036489487, "episode/length": 288.0, "episode/score": 0.06514289209897584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06514289209897584}
{"step": 140384, "time": 4765.589721918106, "episode/length": 288.0, "episode/score": 0.05607686825035785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05607686825035785}
{"step": 140664, "time": 4774.189602851868, "episode/length": 288.0, "episode/score": 0.05220368136579623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05220368136579623}
{"step": 141040, "time": 4786.134900331497, "episode/length": 288.0, "episode/score": 0.04985699001703381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04985699001703381}
{"step": 141112, "time": 4788.18405175209, "episode/length": 288.0, "episode/score": 0.041267671434837894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041267671434837894}
{"step": 141168, "time": 4790.171613931656, "episode/length": 288.0, "episode/score": 0.06581384085667707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06581384085667707}
{"step": 142056, "time": 4817.808242559433, "episode/length": 288.0, "episode/score": 0.040910394872057054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040910394872057054}
{"step": 142304, "time": 4825.824524402618, "episode/length": 288.0, "episode/score": 0.05666923393968659, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05666923393968659}
{"step": 142544, "time": 4833.464263916016, "episode/length": 288.0, "episode/score": 0.0327851912982311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0327851912982311}
{"step": 142696, "time": 4838.003875255585, "episode/length": 288.0, "episode/score": 0.058629076895002186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058629076895002186}
{"step": 142976, "time": 4846.989096164703, "episode/length": 288.0, "episode/score": 0.0727851703368998, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0727851703368998}
{"step": 143352, "time": 4858.616271495819, "episode/length": 288.0, "episode/score": 0.05209051662842512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05209051662842512}
{"step": 143424, "time": 4861.1430287361145, "episode/length": 288.0, "episode/score": 0.04669722810282906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04669722810282906}
{"step": 143480, "time": 4862.706997871399, "episode/length": 288.0, "episode/score": 0.03403977415466386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03403977415466386}
{"step": 144368, "time": 4890.861728191376, "episode/length": 288.0, "episode/score": 0.043767907215709556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043767907215709556}
{"step": 144616, "time": 4898.417412996292, "episode/length": 288.0, "episode/score": 0.057006558582429534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057006558582429534}
{"step": 144856, "time": 4905.977519989014, "episode/length": 288.0, "episode/score": 0.038212937875243824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038212937875243824}
{"step": 145008, "time": 4911.01554274559, "episode/length": 288.0, "episode/score": 0.029018349766573692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029018349766573692}
{"step": 145288, "time": 4919.69181895256, "episode/length": 288.0, "episode/score": 0.02953280525113655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02953280525113655}
{"step": 145664, "time": 4931.682689905167, "episode/length": 288.0, "episode/score": 0.029411513362077812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029411513362077812}
{"step": 145736, "time": 4933.719631195068, "episode/length": 288.0, "episode/score": 0.028431480627929773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028431480627929773}
{"step": 145792, "time": 4935.688027620316, "episode/length": 288.0, "episode/score": 0.028175977924917106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028175977924917106}
{"step": 145792, "time": 4935.695668697357, "episode/length": 177.0, "episode/score": 0.47379339321996383, "episode/reward_rate": 0.0056179775280898875, "episode/intrinsic_return": 0.02691838766695298}
{"step": 146928, "time": 4971.487735271454, "episode/length": 288.0, "episode/score": 0.03472918474705011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03472918474705011}
{"step": 147168, "time": 4979.157487154007, "episode/length": 288.0, "episode/score": 0.04726087695297565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04726087695297565}
{"step": 147320, "time": 4983.712851762772, "episode/length": 288.0, "episode/score": 0.04777949342911825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04777949342911825}
{"step": 147600, "time": 4993.255676269531, "episode/length": 288.0, "episode/score": 0.05005841572183556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05005841572183556}
{"step": 147976, "time": 5004.907452344894, "episode/length": 288.0, "episode/score": 0.04379508352677419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04379508352677419}
{"step": 147984, "time": 5005.3848214149475, "episode/length": 101.0, "episode/score": 0.7052965269093008, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.02092153964513699}
{"step": 148048, "time": 5007.396558523178, "episode/length": 288.0, "episode/score": 0.06023535222657017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06023535222657017}
{"step": 148104, "time": 5009.022413253784, "episode/length": 288.0, "episode/score": 0.06448055007635389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06448055007635389}
{"step": 148104, "time": 5009.03095126152, "episode/length": 288.0, "episode/score": 0.06098502709131992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06098502709131992}
{"step": 149240, "time": 5044.7427546978, "episode/length": 288.0, "episode/score": 0.03745397648825133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03745397648825133}
{"step": 149632, "time": 5057.261785507202, "episode/length": 288.0, "episode/score": 0.058855427297721974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058855427297721974}
{"step": 149912, "time": 5065.813599348068, "episode/length": 288.0, "episode/score": 0.07730851798806526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07730851798806526}
{"step": 150072, "time": 5076.175342321396, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.183580875397, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.190053462982, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.196427345276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.202504396439, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.208582639694, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.214739561081, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5076.221032381058, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150288, "time": 5083.176013946533, "episode/length": 288.0, "episode/score": 0.04721194988302102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04721194988302102}
{"step": 150296, "time": 5083.213518857956, "episode/length": 288.0, "episode/score": 0.06640335517349172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06640335517349172}
{"step": 150360, "time": 5085.226557731628, "episode/length": 288.0, "episode/score": 0.05236795006387496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05236795006387496}
{"step": 150416, "time": 5087.194615840912, "episode/length": 288.0, "episode/score": 0.05339406365790467, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05339406365790467}
{"step": 150416, "time": 5087.202822685242, "episode/length": 288.0, "episode/score": 0.06011281066080443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06011281066080443}
{"step": 151552, "time": 5123.010546445847, "episode/length": 288.0, "episode/score": 0.060998037344390355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060998037344390355}
{"step": 151944, "time": 5135.143850803375, "episode/length": 288.0, "episode/score": 0.050067983164844065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050067983164844065}
{"step": 152224, "time": 5144.214785575867, "episode/length": 288.0, "episode/score": 0.05065906938008169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05065906938008169}
{"step": 152528, "time": 5153.750916719437, "episode/length": 72.0, "episode/score": 0.7970212356489057, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.022021245171679027}
{"step": 152600, "time": 5155.821733951569, "episode/length": 288.0, "episode/score": 0.0625848813333505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0625848813333505}
{"step": 152608, "time": 5156.305520057678, "episode/length": 288.0, "episode/score": 0.05698159349694265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05698159349694265}
{"step": 152672, "time": 5158.312000513077, "episode/length": 288.0, "episode/score": 0.052477269774790614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052477269774790614}
{"step": 152728, "time": 5159.941466093063, "episode/length": 288.0, "episode/score": 0.05204403695942972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05204403695942972}
{"step": 152728, "time": 5159.9502873420715, "episode/length": 288.0, "episode/score": 0.05553534840875329, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05553534840875329}
{"step": 153864, "time": 5195.687776088715, "episode/length": 288.0, "episode/score": 0.05756772740862459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05756772740862459}
{"step": 154536, "time": 5216.764853000641, "episode/length": 288.0, "episode/score": 0.03820659796404158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03820659796404158}
{"step": 154840, "time": 5226.497423648834, "episode/length": 288.0, "episode/score": 0.045041600453544106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045041600453544106}
{"step": 154912, "time": 5229.0013818740845, "episode/length": 288.0, "episode/score": 0.04280166904034388, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04280166904034388}
{"step": 154920, "time": 5229.039583444595, "episode/length": 288.0, "episode/score": 0.06999202543891414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06999202543891414}
{"step": 154984, "time": 5231.0505356788635, "episode/length": 288.0, "episode/score": 0.05840495921628985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05840495921628985}
{"step": 155040, "time": 5233.040362596512, "episode/length": 288.0, "episode/score": 0.08308708471954418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08308708471954418}
{"step": 155040, "time": 5233.048662662506, "episode/length": 288.0, "episode/score": 0.04210488021166725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04210488021166725}
{"step": 155161, "time": 5237.600429058075, "train_stats/mean_log_entropy": 1.9381894147501582, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0006350786258014, "train/action_min": 0.0, "train/action_std": 1.9987329739790696, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.943435968983416e-05, "train/actor_opt_grad_steps": 8630.0, "train/actor_opt_loss": -4.3306780530951725, "train/adv_mag": 0.00034085397536938005, "train/adv_max": 0.0002885079154601464, "train/adv_mean": 7.137343334161182e-05, "train/adv_min": -0.00018227539765529143, "train/adv_std": 7.83297091075861e-05, "train/cont_avg": 0.9963141025641026, "train/cont_loss_mean": 0.02438227719603441, "train/cont_loss_std": 0.33272745299366774, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.660301402211189, "train/cont_pos_acc": 0.9999999813544445, "train/cont_pos_loss": 0.003529537731829362, "train/cont_pred": 0.9964768146857237, "train/cont_rate": 0.9963141025641026, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.018654603634674388, "train/extr_critic_critic_opt_grad_steps": 8630.0, "train/extr_critic_critic_opt_loss": 13517.687840544872, "train/extr_critic_mag": 0.07962544881380522, "train/extr_critic_max": 0.07962544881380522, "train/extr_critic_mean": 0.07949753888906577, "train/extr_critic_min": 0.07940937616886237, "train/extr_critic_std": 3.544469782996319e-05, "train/extr_return_normed_mag": 0.00045457233985265094, "train/extr_return_normed_max": 0.0003920097381640703, "train/extr_return_normed_mean": 0.0002541518637162181, "train/extr_return_normed_min": 8.833247881669264e-05, "train/extr_return_normed_std": 6.58735048954184e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07970679681270551, "train/extr_return_raw_max": 0.07970679681270551, "train/extr_return_raw_mean": 0.07956894353414193, "train/extr_return_raw_min": 0.07940311955335813, "train/extr_return_raw_std": 6.587350587195919e-05, "train/extr_reward_mag": 0.0002503847464537009, "train/extr_reward_max": 0.0002503847464537009, "train/extr_reward_mean": 0.000250227688304268, "train/extr_reward_min": 0.0002500613530476888, "train/extr_reward_std": 7.931840600225661e-08, "train/image_loss_mean": 0.250784290371797, "train/image_loss_std": 0.08381801765316572, "train/model_loss_mean": 0.8853122234344483, "train/model_loss_std": 0.3840243875216215, "train/model_opt_grad_norm": 49.29139968676445, "train/model_opt_grad_steps": 8619.846153846154, "train/model_opt_loss": 2335.761378205128, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2641.025641025641, "train/policy_entropy_mag": 1.9458974440892538, "train/policy_entropy_max": 1.9458974440892538, "train/policy_entropy_mean": 1.945308388196505, "train/policy_entropy_min": 1.9372285518890773, "train/policy_entropy_std": 0.0004002038853613134, "train/policy_logprob_mag": 2.122657668284881, "train/policy_logprob_max": -1.7756997004533426, "train/policy_logprob_mean": -1.9453069136692926, "train/policy_logprob_min": -2.122657668284881, "train/policy_logprob_std": 0.03399703522714285, "train/policy_randomness_mag": 0.9999935309092204, "train/policy_randomness_max": 0.9999935309092204, "train/policy_randomness_mean": 0.9996908086996812, "train/policy_randomness_min": 0.995538600285848, "train/policy_randomness_std": 0.0002056641272084119, "train/post_ent_mag": 55.7848630856245, "train/post_ent_max": 55.7848630856245, "train/post_ent_mean": 55.76077292026618, "train/post_ent_min": 55.70953484559671, "train/post_ent_std": 0.014342943041657025, "train/prior_ent_mag": 54.02217428745367, "train/prior_ent_max": 54.02217428745367, "train/prior_ent_mean": 53.99055797870343, "train/prior_ent_min": 53.92423645410782, "train/prior_ent_std": 0.01615372647602971, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0002606718021128565, "train/reward_loss_mean": 0.010145636812712137, "train/reward_loss_std": 0.061856182631200705, "train/reward_max_data": 0.08581495811470236, "train/reward_max_pred": 0.00025051251435891173, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00846418018381183, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.54921226501465, "train/reward_pred": 0.0002503448345053654, "train/reward_rate": 0.00017528044871794872, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.03100946545600891, "report/cont_loss_std": 0.3888305723667145, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.581897735595703, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037725206930190325, "report/cont_pred": 0.996234655380249, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2430913746356964, "report/image_loss_std": 0.08474187552928925, "report/model_loss_mean": 0.8834838271141052, "report/model_loss_std": 0.3961750864982605, "report/post_ent_mag": 55.19287872314453, "report/post_ent_max": 55.19287872314453, "report/post_ent_mean": 55.01404571533203, "report/post_ent_min": 54.89453887939453, "report/post_ent_std": 0.06638430058956146, "report/prior_ent_mag": 59.84115982055664, "report/prior_ent_max": 59.84115982055664, "report/prior_ent_mean": 59.73277282714844, "report/prior_ent_min": 59.280155181884766, "report/prior_ent_std": 0.09673560410737991, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001862549688667059, "report/reward_loss_mean": 0.009382964111864567, "report/reward_loss_std": 0.01662878505885601, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002589225769042969, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009382963180541992, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00025872071273624897, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003772520460188389, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003772520460188389, "eval/cont_pred": 0.996234655380249, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24565190076828003, "eval/image_loss_std": 0.08795527368783951, "eval/model_loss_mean": 0.8506641387939453, "eval/model_loss_std": 0.08795533329248428, "eval/post_ent_mag": 55.19614028930664, "eval/post_ent_max": 55.19614028930664, "eval/post_ent_mean": 55.014041900634766, "eval/post_ent_min": 54.895835876464844, "eval/post_ent_std": 0.06674480438232422, "eval/prior_ent_mag": 59.84366989135742, "eval/prior_ent_max": 59.84366989135742, "eval/prior_ent_mean": 59.73939895629883, "eval/prior_ent_min": 59.280155181884766, "eval/prior_ent_std": 0.08810354024171829, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001239716075360775, "eval/reward_loss_std": 3.1001395655039232e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002589225769042969, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001239716075360775, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025872664991766214, "eval/reward_rate": 0.0, "replay/size": 154657.0, "replay/inserts": 31152.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.2685962377233755e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0237258461480516e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0977704357248414e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4107320308685, "timer/env.step_count": 3894.0, "timer/env.step_total": 36.97224497795105, "timer/env.step_frac": 0.03695706552737205, "timer/env.step_avg": 0.009494669999473819, "timer/env.step_min": 0.007712602615356445, "timer/env.step_max": 0.044632673263549805, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.728620290756226, "timer/replay._sample_frac": 0.015722162694942886, "timer/replay._sample_avg": 0.0005048992132369102, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.011080503463745117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4761.0, "timer/agent.policy_total": 47.55314254760742, "timer/agent.policy_frac": 0.047533618967754265, "timer/agent.policy_avg": 0.00998805766595409, "timer/agent.policy_min": 0.008562564849853516, "timer/agent.policy_max": 0.08590316772460938, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.20101046562194824, "timer/dataset_train_frac": 0.00020092793808188165, "timer/dataset_train_avg": 0.00010324112255878185, "timer/dataset_train_min": 8.893013000488281e-05, "timer/dataset_train_max": 0.0003342628479003906, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 864.618222951889, "timer/agent.train_frac": 0.8642632423551515, "timer/agent.train_avg": 0.44407715611293735, "timer/agent.train_min": 0.43346405029296875, "timer/agent.train_max": 1.0349318981170654, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47468018531799316, "timer/agent.report_frac": 0.00047448529900751457, "timer/agent.report_avg": 0.23734009265899658, "timer/agent.report_min": 0.23134779930114746, "timer/agent.report_max": 0.2433323860168457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.193497288334127e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.138683461137376}
{"step": 156176, "time": 5270.2329018116, "episode/length": 288.0, "episode/score": 0.06279723629356226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06279723629356226}
{"step": 156200, "time": 5270.77392911911, "episode/length": 160.0, "episode/score": 0.5391656434423666, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.03916562010109459}
{"step": 156848, "time": 5291.400616168976, "episode/length": 288.0, "episode/score": 0.08065998377358596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08065998377358596}
{"step": 157152, "time": 5301.096529960632, "episode/length": 288.0, "episode/score": 0.05749535640195802, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05749535640195802}
{"step": 157232, "time": 5303.6421048641205, "episode/length": 288.0, "episode/score": 0.07208272981325337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07208272981325337}
{"step": 157296, "time": 5305.659100532532, "episode/length": 288.0, "episode/score": 0.0794655912633715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0794655912633715}
{"step": 157352, "time": 5307.205523490906, "episode/length": 288.0, "episode/score": 0.03979983669133702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03979983669133702}
{"step": 157352, "time": 5307.213927268982, "episode/length": 288.0, "episode/score": 0.055994361471874754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055994361471874754}
{"step": 158488, "time": 5343.053389787674, "episode/length": 288.0, "episode/score": 0.06948239794462552, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06948239794462552}
{"step": 158512, "time": 5344.056260108948, "episode/length": 288.0, "episode/score": 0.07618211511110928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07618211511110928}
{"step": 159160, "time": 5364.185770750046, "episode/length": 288.0, "episode/score": 0.0812912523118996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0812912523118996}
{"step": 159464, "time": 5373.785566806793, "episode/length": 288.0, "episode/score": 0.07313238030781122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07313238030781122}
{"step": 159544, "time": 5376.332846879959, "episode/length": 288.0, "episode/score": 0.04476618647242958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04476618647242958}
{"step": 159608, "time": 5378.344039678574, "episode/length": 288.0, "episode/score": 0.06517194525520154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06517194525520154}
{"step": 159664, "time": 5380.344646930695, "episode/length": 288.0, "episode/score": 0.07580391464659897, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07580391464659897}
{"step": 159664, "time": 5380.3528175354, "episode/length": 288.0, "episode/score": 0.07543045755289768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07543045755289768}
{"step": 160056, "time": 5394.277984619141, "eval_episode/length": 106.0, "eval_episode/score": 0.668749988079071, "eval_episode/reward_rate": 0.009345794392523364}
{"step": 160056, "time": 5397.435720920563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5397.449355602264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5397.4571278095245, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5397.464328050613, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5397.472029924393, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5397.478272676468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5397.484834432602, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160800, "time": 5421.1436903476715, "episode/length": 288.0, "episode/score": 0.056979414177249055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056979414177249055}
{"step": 160824, "time": 5421.691912412643, "episode/length": 288.0, "episode/score": 0.0798648593828375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0798648593828375}
{"step": 161472, "time": 5442.5129318237305, "episode/length": 288.0, "episode/score": 0.08530571221336913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08530571221336913}
{"step": 161776, "time": 5452.057993888855, "episode/length": 288.0, "episode/score": 0.07067664025424847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07067664025424847}
{"step": 161856, "time": 5454.577590465546, "episode/length": 288.0, "episode/score": 0.04660399006490934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04660399006490934}
{"step": 161920, "time": 5456.609589576721, "episode/length": 288.0, "episode/score": 0.06244378487156155, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06244378487156155}
{"step": 161976, "time": 5458.161457538605, "episode/length": 288.0, "episode/score": 0.06593600535762789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06593600535762789}
{"step": 161976, "time": 5458.170533895493, "episode/length": 288.0, "episode/score": 0.06431611973721374, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06431611973721374}
{"step": 163112, "time": 5494.2258088588715, "episode/length": 288.0, "episode/score": 0.08543152641584584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08543152641584584}
{"step": 163136, "time": 5495.208941221237, "episode/length": 288.0, "episode/score": 0.042349222461041336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042349222461041336}
{"step": 163784, "time": 5515.313138723373, "episode/length": 288.0, "episode/score": 0.07903411119531256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07903411119531256}
{"step": 163952, "time": 5521.420214653015, "episode/length": 101.0, "episode/score": 0.7214548719265395, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.03707985520929924}
{"step": 164088, "time": 5525.476391792297, "episode/length": 288.0, "episode/score": 0.07801556514158392, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07801556514158392}
{"step": 164168, "time": 5528.015576124191, "episode/length": 288.0, "episode/score": 0.06291214101526066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06291214101526066}
{"step": 164232, "time": 5530.031898736954, "episode/length": 288.0, "episode/score": 0.06836295941172921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06836295941172921}
{"step": 164288, "time": 5532.044098615646, "episode/length": 288.0, "episode/score": 0.05367513098286736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05367513098286736}
{"step": 164288, "time": 5532.052031755447, "episode/length": 288.0, "episode/score": 0.07394147048205468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07394147048205468}
{"step": 165424, "time": 5568.211273193359, "episode/length": 288.0, "episode/score": 0.08919959160613189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08919959160613189}
{"step": 166096, "time": 5589.476258516312, "episode/length": 288.0, "episode/score": 0.05941020051423607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05941020051423607}
{"step": 166264, "time": 5594.519738674164, "episode/length": 288.0, "episode/score": 0.07089288121304094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07089288121304094}
{"step": 166400, "time": 5599.003885984421, "episode/length": 288.0, "episode/score": 0.06892255975276385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06892255975276385}
{"step": 166480, "time": 5601.4955859184265, "episode/length": 288.0, "episode/score": 0.07604116208483447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07604116208483447}
{"step": 166544, "time": 5603.51914358139, "episode/length": 288.0, "episode/score": 0.0603083691376014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0603083691376014}
{"step": 166600, "time": 5605.047140598297, "episode/length": 288.0, "episode/score": 0.083988674246541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.083988674246541}
{"step": 166600, "time": 5605.055026769638, "episode/length": 288.0, "episode/score": 0.07203902348331326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07203902348331326}
{"step": 167080, "time": 5620.1798050403595, "episode/length": 101.0, "episode/score": 0.7121763685443909, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.02780135182715071}
{"step": 167736, "time": 5640.939167261124, "episode/length": 288.0, "episode/score": 0.06536880667331957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06536880667331957}
{"step": 168408, "time": 5662.039620399475, "episode/length": 288.0, "episode/score": 0.06220033279288373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06220033279288373}
{"step": 168712, "time": 5671.77348780632, "episode/length": 288.0, "episode/score": 0.04781067777000203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04781067777000203}
{"step": 168792, "time": 5674.297477245331, "episode/length": 288.0, "episode/score": 0.0745296498190271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0745296498190271}
{"step": 168856, "time": 5676.304493188858, "episode/length": 288.0, "episode/score": 0.05800187573137805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05800187573137805}
{"step": 168912, "time": 5678.297248125076, "episode/length": 288.0, "episode/score": 0.05067703498332321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05067703498332321}
{"step": 168912, "time": 5678.30571436882, "episode/length": 288.0, "episode/score": 0.08404600792638917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08404600792638917}
{"step": 169392, "time": 5693.410311698914, "episode/length": 288.0, "episode/score": 0.055078941603312614, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055078941603312614}
{"step": 170040, "time": 5719.48503947258, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.492638587952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.501022815704, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.507622003555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.514196157455, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.520813941956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.528002500534, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5719.535696983337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170048, "time": 5720.017610311508, "episode/length": 288.0, "episode/score": 0.03460603523265604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03460603523265604}
{"step": 170720, "time": 5741.236787319183, "episode/length": 288.0, "episode/score": 0.055292005602268546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055292005602268546}
{"step": 171024, "time": 5750.800547122955, "episode/length": 288.0, "episode/score": 0.06429644816887503, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06429644816887503}
{"step": 171104, "time": 5753.312440633774, "episode/length": 288.0, "episode/score": 0.04798170536332691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04798170536332691}
{"step": 171168, "time": 5755.339364290237, "episode/length": 288.0, "episode/score": 0.049002811888271935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049002811888271935}
{"step": 171224, "time": 5756.871058940887, "episode/length": 288.0, "episode/score": 0.06268997326185399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06268997326185399}
{"step": 171224, "time": 5756.878917455673, "episode/length": 288.0, "episode/score": 0.05759357211866245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05759357211866245}
{"step": 171704, "time": 5772.025534391403, "episode/length": 288.0, "episode/score": 0.04053809859294688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04053809859294688}
{"step": 172360, "time": 5793.176458358765, "episode/length": 288.0, "episode/score": 0.04912501380715639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04912501380715639}
{"step": 173032, "time": 5814.229303598404, "episode/length": 288.0, "episode/score": 0.053575439522944635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053575439522944635}
{"step": 173336, "time": 5823.916753530502, "episode/length": 288.0, "episode/score": 0.05915542503095139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05915542503095139}
{"step": 173416, "time": 5826.455001831055, "episode/length": 288.0, "episode/score": 0.06943770722659792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06943770722659792}
{"step": 173480, "time": 5828.452778100967, "episode/length": 288.0, "episode/score": 0.056400886133587846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056400886133587846}
{"step": 173536, "time": 5830.431816577911, "episode/length": 288.0, "episode/score": 0.06105579982755671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06105579982755671}
{"step": 173536, "time": 5830.440605163574, "episode/length": 288.0, "episode/score": 0.0607052530792771, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0607052530792771}
{"step": 174016, "time": 5845.476624488831, "episode/length": 288.0, "episode/score": 0.047621495055693686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047621495055693686}
{"step": 174672, "time": 5866.287334442139, "episode/length": 288.0, "episode/score": 0.020312250204369775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020312250204369775}
{"step": 175344, "time": 5887.461404323578, "episode/length": 288.0, "episode/score": 0.07962387399766158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07962387399766158}
{"step": 175648, "time": 5896.994239091873, "episode/length": 288.0, "episode/score": 0.0468157667700666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0468157667700666}
{"step": 175728, "time": 5899.494554281235, "episode/length": 288.0, "episode/score": 0.061856376790103695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061856376790103695}
{"step": 175792, "time": 5901.5306231975555, "episode/length": 288.0, "episode/score": 0.057628489957153306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057628489957153306}
{"step": 175848, "time": 5903.069738149643, "episode/length": 288.0, "episode/score": 0.03408352615048216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03408352615048216}
{"step": 175848, "time": 5903.077569723129, "episode/length": 288.0, "episode/score": 0.04047112561056565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04047112561056565}
{"step": 176328, "time": 5918.208297252655, "episode/length": 288.0, "episode/score": 0.03440052591625431, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03440052591625431}
{"step": 176984, "time": 5938.933526277542, "episode/length": 288.0, "episode/score": 0.04939446497581912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04939446497581912}
{"step": 177656, "time": 5960.137076854706, "episode/length": 288.0, "episode/score": 0.05497211793218071, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05497211793218071}
{"step": 177960, "time": 5969.789837360382, "episode/length": 288.0, "episode/score": 0.05284268641131007, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05284268641131007}
{"step": 178040, "time": 5972.374413013458, "episode/length": 288.0, "episode/score": 0.04331966410271093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04331966410271093}
{"step": 178104, "time": 5974.408962726593, "episode/length": 288.0, "episode/score": 0.04490460572122856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04490460572122856}
{"step": 178160, "time": 5976.399786949158, "episode/length": 288.0, "episode/score": 0.05147028499905559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05147028499905559}
{"step": 178160, "time": 5976.40908408165, "episode/length": 288.0, "episode/score": 0.057513186187918564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057513186187918564}
{"step": 178640, "time": 5991.534084558487, "episode/length": 288.0, "episode/score": 0.07104847928079039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07104847928079039}
{"step": 179232, "time": 6010.267263650894, "episode/length": 280.0, "episode/score": 0.166254984716943, "episode/reward_rate": 0.0035587188612099642, "episode/intrinsic_return": 0.04125498588109622}
{"step": 179968, "time": 6033.432900428772, "episode/length": 288.0, "episode/score": 0.05146547710057803, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05146547710057803}
{"step": 180024, "time": 6040.12720990181, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.135127782822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.142129421234, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.149493694305, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.156632184982, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.163093090057, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.169499635696, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6040.176077842712, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180272, "time": 6048.649431467056, "episode/length": 288.0, "episode/score": 0.05246516596901074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05246516596901074}
{"step": 180352, "time": 6051.1674292087555, "episode/length": 288.0, "episode/score": 0.04239384894458453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04239384894458453}
{"step": 180416, "time": 6053.193512201309, "episode/length": 288.0, "episode/score": 0.0640537882981107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0640537882981107}
{"step": 180472, "time": 6054.760176181793, "episode/length": 288.0, "episode/score": 0.05069428420085842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05069428420085842}
{"step": 180472, "time": 6054.768234729767, "episode/length": 288.0, "episode/score": 0.037906065923891674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037906065923891674}
{"step": 180952, "time": 6070.048581838608, "episode/length": 288.0, "episode/score": 0.03301163634847626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03301163634847626}
{"step": 181544, "time": 6088.730437040329, "episode/length": 288.0, "episode/score": 0.04405138077771653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04405138077771653}
{"step": 182280, "time": 6111.890233039856, "episode/length": 288.0, "episode/score": 0.06509551086020338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06509551086020338}
{"step": 182584, "time": 6121.5188817977905, "episode/length": 288.0, "episode/score": 0.03893503541314658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03893503541314658}
{"step": 182664, "time": 6124.028774261475, "episode/length": 288.0, "episode/score": 0.05358019648940626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05358019648940626}
{"step": 182728, "time": 6126.050790309906, "episode/length": 288.0, "episode/score": 0.05888717498129381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05888717498129381}
{"step": 182784, "time": 6128.02166891098, "episode/length": 288.0, "episode/score": 0.06393020753773726, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06393020753773726}
{"step": 182784, "time": 6128.029891490936, "episode/length": 288.0, "episode/score": 0.03223217233687592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03223217233687592}
{"step": 183264, "time": 6143.102254867554, "episode/length": 288.0, "episode/score": 0.05087188869111969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05087188869111969}
{"step": 183856, "time": 6161.78427195549, "episode/length": 288.0, "episode/score": 0.09830947952451652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09830947952451652}
{"step": 184592, "time": 6184.973701715469, "episode/length": 288.0, "episode/score": 0.07674371150062598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07674371150062598}
{"step": 184896, "time": 6194.511722564697, "episode/length": 288.0, "episode/score": 0.06946865798619228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06946865798619228}
{"step": 184976, "time": 6197.033717632294, "episode/length": 288.0, "episode/score": 0.06519952435070309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06519952435070309}
{"step": 185040, "time": 6199.044208049774, "episode/length": 288.0, "episode/score": 0.0893389485176499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0893389485176499}
{"step": 185096, "time": 6200.612003564835, "episode/length": 288.0, "episode/score": 0.04484188481455931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04484188481455931}
{"step": 185096, "time": 6200.619963169098, "episode/length": 288.0, "episode/score": 0.07103894091477514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07103894091477514}
{"step": 185576, "time": 6215.708933353424, "episode/length": 288.0, "episode/score": 0.057339645540707807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057339645540707807}
{"step": 186168, "time": 6234.316840648651, "episode/length": 288.0, "episode/score": 0.0550091876717147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0550091876717147}
{"step": 186249, "time": 6237.852790355682, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.883015426163821, "train/action_min": 0.0, "train/action_std": 1.9887876584357822, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00029779163393409223, "train/actor_opt_grad_steps": 10575.0, "train/actor_opt_loss": -1.6553272950683826, "train/adv_mag": 0.0010545335940479004, "train/adv_max": 0.0010317861265742901, "train/adv_mean": 0.00022855712142627548, "train/adv_min": -0.0004755247038664277, "train/adv_std": 0.00021253235560656433, "train/cont_avg": 0.996350475193299, "train/cont_loss_mean": 0.024178065124361478, "train/cont_loss_std": 0.3319006438568695, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6355363732760715, "train/cont_pos_acc": 0.9999999827945355, "train/cont_pos_loss": 0.0036117732296841814, "train/cont_pred": 0.9963948597613069, "train/cont_rate": 0.996350475193299, "train/dyn_loss_mean": 1.0037789301773936, "train/dyn_loss_std": 3.823979527295865e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.02582654305889761, "train/extr_critic_critic_opt_grad_steps": 10575.0, "train/extr_critic_critic_opt_loss": 13518.251057103736, "train/extr_critic_mag": 0.08380009218589547, "train/extr_critic_max": 0.08380009218589547, "train/extr_critic_mean": 0.08351973716899291, "train/extr_critic_min": 0.08299557634235658, "train/extr_critic_std": 0.00010250670793445267, "train/extr_return_normed_mag": 0.001253813966033385, "train/extr_return_normed_max": 0.0012120717425936275, "train/extr_return_normed_mean": 0.000641033762335188, "train/extr_return_normed_min": 2.854298224154207e-05, "train/extr_return_normed_std": 0.00018794879997116856, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08431933094392118, "train/extr_return_raw_max": 0.08431933094392118, "train/extr_return_raw_mean": 0.08374829701695245, "train/extr_return_raw_min": 0.08313580218356909, "train/extr_return_raw_std": 0.00018794880024307933, "train/extr_reward_mag": 0.00035555645362618044, "train/extr_reward_max": 0.00035555645362618044, "train/extr_reward_mean": 0.0002869997578150996, "train/extr_reward_min": 0.00024965190395866474, "train/extr_reward_std": 2.5917903394844198e-05, "train/image_loss_mean": 0.23260713092137858, "train/image_loss_std": 0.08680127495803784, "train/model_loss_mean": 0.8703298120154548, "train/model_loss_std": 0.40128991599242714, "train/model_opt_grad_norm": 44.05675424988737, "train/model_opt_grad_steps": 10563.515463917525, "train/model_opt_loss": 2514.440470587347, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2886.59793814433, "train/policy_entropy_mag": 1.940903600343724, "train/policy_entropy_max": 1.940903600343724, "train/policy_entropy_mean": 1.9098974030042433, "train/policy_entropy_min": 1.786972343614421, "train/policy_entropy_std": 0.014590404952033759, "train/policy_logprob_mag": 2.6349218887152133, "train/policy_logprob_max": -1.2912612403790975, "train/policy_logprob_mean": -1.9100122851194794, "train/policy_logprob_min": -2.6349218887152133, "train/policy_logprob_std": 0.1819370603284885, "train/policy_randomness_mag": 0.997427201148161, "train/policy_randomness_max": 0.997427201148161, "train/policy_randomness_mean": 0.9814931655053011, "train/policy_randomness_min": 0.9183221801961821, "train/policy_randomness_std": 0.007497985437740428, "train/post_ent_mag": 62.668930250344815, "train/post_ent_max": 62.668930250344815, "train/post_ent_mean": 62.158509618228244, "train/post_ent_min": 61.88971718070433, "train/post_ent_std": 0.17426242683198034, "train/prior_ent_mag": 61.498785628485926, "train/prior_ent_max": 61.498785628485926, "train/prior_ent_mean": 60.40375493236424, "train/prior_ent_min": 59.87989986065737, "train/prior_ent_std": 0.27210838203654464, "train/rep_loss_mean": 1.0037789301773936, "train/rep_loss_std": 3.823979527295865e-05, "train/reward_avg": 0.00032846979773183324, "train/reward_loss_mean": 0.011277237160553791, "train/reward_loss_std": 0.09050003141068767, "train/reward_max_data": 0.1502225113415745, "train/reward_max_pred": 0.00034246801101055343, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00869047635513329, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.348747318866206, "train/reward_pred": 0.0002687744779473881, "train/reward_rate": 0.0002768605025773196, "train_stats/mean_log_entropy": 1.9105176190349544, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0368170440196991, "report/cont_loss_std": 0.4373607635498047, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.73370885848999, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032400889322161674, "report/cont_pred": 0.9967652559280396, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.215989887714386, "report/image_loss_std": 0.0894666537642479, "report/model_loss_mean": 0.8687878251075745, "report/model_loss_std": 0.5841272473335266, "report/post_ent_mag": 65.44099426269531, "report/post_ent_max": 65.44099426269531, "report/post_ent_mean": 65.15773010253906, "report/post_ent_min": 64.88700866699219, "report/post_ent_std": 0.11022942513227463, "report/prior_ent_mag": 65.57477569580078, "report/prior_ent_max": 65.57477569580078, "report/prior_ent_mean": 60.63902282714844, "report/prior_ent_min": 59.78356170654297, "report/prior_ent_std": 0.6848534941673279, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0003899702278431505, "report/reward_loss_mean": 0.015980899333953857, "report/reward_loss_std": 0.22317898273468018, "report/reward_max_data": 0.19499999284744263, "report/reward_max_pred": 0.0008159875869750977, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009018721990287304, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.138288497924805, "report/reward_pred": 0.00028461357578635216, "report/reward_rate": 0.0009765625, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003240163903683424, "eval/cont_loss_std": 1.3001939578316524e-06, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003240163903683424, "eval/cont_pred": 0.9967652559280396, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24458636343479156, "eval/image_loss_std": 0.08303502947092056, "eval/model_loss_mean": 0.8492696285247803, "eval/model_loss_std": 0.08311436325311661, "eval/post_ent_mag": 65.42723846435547, "eval/post_ent_max": 65.42723846435547, "eval/post_ent_mean": 65.13584899902344, "eval/post_ent_min": 64.87322998046875, "eval/post_ent_std": 0.10264375805854797, "eval/prior_ent_mag": 62.581111907958984, "eval/prior_ent_max": 62.581111907958984, "eval/prior_ent_mean": 60.427757263183594, "eval/prior_ent_min": 59.76982498168945, "eval/prior_ent_std": 0.46465399861335754, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001443101093173027, "eval/reward_loss_std": 0.0013359872391447425, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008159875869750977, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001443101093173027, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.000267025432549417, "eval/reward_rate": 0.0, "replay/size": 185745.0, "replay/inserts": 31088.0, "replay/samples": 31088.0, "replay/insert_wait_avg": 1.261659767967613e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0158634652075421e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0947455171895276e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.23415184021, "timer/env.step_count": 3886.0, "timer/env.step_total": 36.87317180633545, "timer/env.step_frac": 0.03686453990647785, "timer/env.step_avg": 0.009488721514754361, "timer/env.step_min": 0.007782697677612305, "timer/env.step_max": 0.03594708442687988, "timer/replay._sample_count": 31088.0, "timer/replay._sample_total": 15.62539029121399, "timer/replay._sample_frac": 0.015621732433817342, "timer/replay._sample_avg": 0.0005026180613488802, "timer/replay._sample_min": 0.00036525726318359375, "timer/replay._sample_max": 0.009972333908081055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4753.0, "timer/agent.policy_total": 47.873472690582275, "timer/agent.policy_frac": 0.04786226565300301, "timer/agent.policy_avg": 0.010072264399449247, "timer/agent.policy_min": 0.00847482681274414, "timer/agent.policy_max": 0.08619356155395508, "timer/dataset_train_count": 1943.0, "timer/dataset_train_total": 0.21545791625976562, "timer/dataset_train_frac": 0.00021540747820234955, "timer/dataset_train_avg": 0.00011088930327316811, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 1943.0, "timer/agent.train_total": 864.3296110630035, "timer/agent.train_frac": 0.8641272740716041, "timer/agent.train_avg": 0.44484282607462866, "timer/agent.train_min": 0.4339749813079834, "timer/agent.train_max": 0.5828502178192139, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4795997142791748, "timer/agent.report_frac": 0.00047948744141241054, "timer/agent.report_avg": 0.2397998571395874, "timer/agent.report_min": 0.23282933235168457, "timer/agent.report_max": 0.24677038192749023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.2178973412870243e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.080192545702275}
{"step": 186904, "time": 6258.413539648056, "episode/length": 288.0, "episode/score": 0.07844262307386884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07844262307386884}
{"step": 187208, "time": 6267.979177474976, "episode/length": 288.0, "episode/score": 0.0652139298495058, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0652139298495058}
{"step": 187288, "time": 6270.619275569916, "episode/length": 288.0, "episode/score": 0.07548093552378532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07548093552378532}
{"step": 187352, "time": 6272.6427891254425, "episode/length": 288.0, "episode/score": 0.09741003087034983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09741003087034983}
{"step": 187408, "time": 6274.622802019119, "episode/length": 288.0, "episode/score": 0.0691044861511898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0691044861511898}
{"step": 187408, "time": 6274.631099224091, "episode/length": 288.0, "episode/score": 0.05745174097648942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05745174097648942}
{"step": 187888, "time": 6289.760356664658, "episode/length": 288.0, "episode/score": 0.0915015318587109, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0915015318587109}
{"step": 188480, "time": 6308.977356672287, "episode/length": 288.0, "episode/score": 0.08707451367826025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08707451367826025}
{"step": 189216, "time": 6332.3171627521515, "episode/length": 288.0, "episode/score": 0.1148771800733357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1148771800733357}
{"step": 189520, "time": 6341.890230178833, "episode/length": 288.0, "episode/score": 0.07580973695144166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07580973695144166}
{"step": 189600, "time": 6344.41555762291, "episode/length": 288.0, "episode/score": 0.08065311112181917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08065311112181917}
{"step": 189664, "time": 6346.428197145462, "episode/length": 288.0, "episode/score": 0.08862164343076984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08862164343076984}
{"step": 189720, "time": 6347.984810352325, "episode/length": 288.0, "episode/score": 0.07532752198142134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07532752198142134}
{"step": 189720, "time": 6347.993030309677, "episode/length": 288.0, "episode/score": 0.06171635549219445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06171635549219445}
{"step": 190008, "time": 6362.252456665039, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.260182619095, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.266640424728, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.272960424423, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.279034614563, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.285227060318, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.2913501262665, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6362.297545909882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190200, "time": 6368.318227052689, "episode/length": 288.0, "episode/score": 0.07674104949398952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07674104949398952}
{"step": 190792, "time": 6386.934436798096, "episode/length": 288.0, "episode/score": 0.05729175436567857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05729175436567857}
{"step": 191528, "time": 6410.115420341492, "episode/length": 288.0, "episode/score": 0.07813268935348106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07813268935348106}
{"step": 191832, "time": 6419.750565290451, "episode/length": 288.0, "episode/score": 0.06836176636596747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06836176636596747}
{"step": 191912, "time": 6422.2554297447205, "episode/length": 288.0, "episode/score": 0.07350361506297531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07350361506297531}
{"step": 191976, "time": 6424.281656265259, "episode/length": 288.0, "episode/score": 0.08848299825342565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08848299825342565}
{"step": 192032, "time": 6426.262774705887, "episode/length": 288.0, "episode/score": 0.07756358235599237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07756358235599237}
{"step": 192032, "time": 6426.271689891815, "episode/length": 288.0, "episode/score": 0.06640418134833226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06640418134833226}
{"step": 192512, "time": 6441.388478040695, "episode/length": 288.0, "episode/score": 0.07619120921793865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07619120921793865}
{"step": 193104, "time": 6460.057991743088, "episode/length": 288.0, "episode/score": 0.05233809525776678, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05233809525776678}
{"step": 193840, "time": 6483.287738084793, "episode/length": 288.0, "episode/score": 0.09492557373295085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09492557373295085}
{"step": 194144, "time": 6492.820031404495, "episode/length": 288.0, "episode/score": 0.08286960081079542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08286960081079542}
{"step": 194224, "time": 6495.337595701218, "episode/length": 288.0, "episode/score": 0.09448865659459216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09448865659459216}
{"step": 194264, "time": 6496.3727905750275, "episode/length": 218.0, "episode/score": 0.3922104540892519, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.07346046121386962}
{"step": 194288, "time": 6497.349415779114, "episode/length": 288.0, "episode/score": 0.08252260659816102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08252260659816102}
{"step": 194344, "time": 6498.894763708115, "episode/length": 288.0, "episode/score": 0.10002771274474753, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10002771274474753}
{"step": 194344, "time": 6498.903147697449, "episode/length": 288.0, "episode/score": 0.09395666970317507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09395666970317507}
{"step": 195416, "time": 6532.70889544487, "episode/length": 288.0, "episode/score": 0.1152800214705394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1152800214705394}
{"step": 196152, "time": 6556.030104875565, "episode/length": 288.0, "episode/score": 0.12190597407902715, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12190597407902715}
{"step": 196456, "time": 6565.61066198349, "episode/length": 288.0, "episode/score": 0.11677820136105765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11677820136105765}
{"step": 196536, "time": 6568.123002529144, "episode/length": 288.0, "episode/score": 0.10537739716278338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10537739716278338}
{"step": 196576, "time": 6569.686271905899, "episode/length": 288.0, "episode/score": 0.10086120914775165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10086120914775165}
{"step": 196600, "time": 6570.243929862976, "episode/length": 288.0, "episode/score": 0.09593479779664449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09593479779664449}
{"step": 196656, "time": 6572.783634901047, "episode/length": 288.0, "episode/score": 0.08525455786980274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08525455786980274}
{"step": 196656, "time": 6572.79222035408, "episode/length": 288.0, "episode/score": 0.10827339032630334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10827339032630334}
{"step": 197728, "time": 6607.4879155159, "episode/length": 288.0, "episode/score": 0.1362936317899539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1362936317899539}
{"step": 198464, "time": 6630.665884256363, "episode/length": 288.0, "episode/score": 0.11699686416966415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11699686416966415}
{"step": 198768, "time": 6640.332149267197, "episode/length": 288.0, "episode/score": 0.07605271645707035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07605271645707035}
{"step": 198848, "time": 6642.850743532181, "episode/length": 288.0, "episode/score": 0.1237656322497287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1237656322497287}
{"step": 198888, "time": 6643.888844966888, "episode/length": 288.0, "episode/score": 0.10859625142745699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10859625142745699}
{"step": 198912, "time": 6644.866228103638, "episode/length": 288.0, "episode/score": 0.12525628084881646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12525628084881646}
{"step": 198968, "time": 6646.403939008713, "episode/length": 288.0, "episode/score": 0.12693941608006298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12693941608006298}
{"step": 198968, "time": 6646.412041425705, "episode/length": 288.0, "episode/score": 0.10583234677960718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10583234677960718}
{"step": 200040, "time": 6680.187498807907, "episode/length": 288.0, "episode/score": 0.09229590294830814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09229590294830814}
{"step": 200096, "time": 6682.443422794342, "eval_episode/length": 14.0, "eval_episode/score": 0.956250011920929, "eval_episode/reward_rate": 0.06666666666666667}
{"step": 200096, "time": 6687.85560297966, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6687.862687826157, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6687.870528459549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6687.876815080643, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6687.8832314014435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6687.889582872391, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6687.896478652954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200776, "time": 6709.299568653107, "episode/length": 288.0, "episode/score": 0.11848922304375265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11848922304375265}
{"step": 201080, "time": 6719.044348239899, "episode/length": 288.0, "episode/score": 0.09909195841260043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09909195841260043}
{"step": 201160, "time": 6721.559554576874, "episode/length": 288.0, "episode/score": 0.10443721527326488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10443721527326488}
{"step": 201200, "time": 6723.054415941238, "episode/length": 288.0, "episode/score": 0.07173541332679179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07173541332679179}
{"step": 201224, "time": 6723.5969071388245, "episode/length": 288.0, "episode/score": 0.10136352471306509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10136352471306509}
{"step": 201280, "time": 6725.62064409256, "episode/length": 288.0, "episode/score": 0.09715091405030307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09715091405030307}
{"step": 201280, "time": 6725.629021883011, "episode/length": 288.0, "episode/score": 0.11520049700482105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11520049700482105}
{"step": 202352, "time": 6759.515368461609, "episode/length": 288.0, "episode/score": 0.10674692520012741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10674692520012741}
{"step": 203088, "time": 6782.950258731842, "episode/length": 288.0, "episode/score": 0.11157734988603352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11157734988603352}
{"step": 203392, "time": 6792.623579978943, "episode/length": 288.0, "episode/score": 0.08601271175507463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08601271175507463}
{"step": 203472, "time": 6795.194133043289, "episode/length": 288.0, "episode/score": 0.09945490257314304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09945490257314304}
{"step": 203512, "time": 6796.252740383148, "episode/length": 288.0, "episode/score": 0.10818841627445863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10818841627445863}
{"step": 203536, "time": 6797.251880168915, "episode/length": 288.0, "episode/score": 0.10459961075366664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10459961075366664}
{"step": 203592, "time": 6798.801025390625, "episode/length": 288.0, "episode/score": 0.08154583434838969, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08154583434838969}
{"step": 203592, "time": 6798.809780597687, "episode/length": 288.0, "episode/score": 0.0912549031470462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0912549031470462}
{"step": 204424, "time": 6825.157136917114, "episode/length": 128.0, "episode/score": 0.6519639432278268, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.051963890747799724}
{"step": 204664, "time": 6832.742019414902, "episode/length": 288.0, "episode/score": 0.05927713904054599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05927713904054599}
{"step": 205400, "time": 6856.6496322155, "episode/length": 288.0, "episode/score": 0.0744013446013696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0744013446013696}
{"step": 205784, "time": 6868.843147754669, "episode/length": 288.0, "episode/score": 0.06453543744987655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06453543744987655}
{"step": 205824, "time": 6870.3325872421265, "episode/length": 288.0, "episode/score": 0.10070957333306296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10070957333306296}
{"step": 205848, "time": 6870.872819900513, "episode/length": 288.0, "episode/score": 0.08303490184897555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08303490184897555}
{"step": 205904, "time": 6872.875663995743, "episode/length": 288.0, "episode/score": 0.08252978987519555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08252978987519555}
{"step": 205904, "time": 6872.884927988052, "episode/length": 288.0, "episode/score": 0.07317578396157387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07317578396157387}
{"step": 206736, "time": 6899.164504528046, "episode/length": 288.0, "episode/score": 0.04410353901386088, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04410353901386088}
{"step": 206976, "time": 6906.691323518753, "episode/length": 288.0, "episode/score": 0.04889534499085357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04889534499085357}
{"step": 207712, "time": 6929.916973590851, "episode/length": 288.0, "episode/score": 0.02637015363785622, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02637015363785622}
{"step": 208096, "time": 6941.984912395477, "episode/length": 288.0, "episode/score": 0.01561095997180928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01561095997180928}
{"step": 208136, "time": 6943.0433168411255, "episode/length": 288.0, "episode/score": 0.027300759528429808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027300759528429808}
{"step": 208160, "time": 6944.024277687073, "episode/length": 288.0, "episode/score": 0.022038256559426372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022038256559426372}
{"step": 208216, "time": 6945.564390659332, "episode/length": 288.0, "episode/score": 0.012887187391129373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012887187391129373}
{"step": 208216, "time": 6945.572698354721, "episode/length": 288.0, "episode/score": 0.014111250917210327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014111250917210327}
{"step": 209048, "time": 6971.76674413681, "episode/length": 288.0, "episode/score": 0.02028002923520944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02028002923520944}
{"step": 209288, "time": 6979.310608625412, "episode/length": 288.0, "episode/score": 0.028376323552180338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028376323552180338}
{"step": 210024, "time": 7002.574460029602, "episode/length": 288.0, "episode/score": 0.007456507498716292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007456507498716292}
{"step": 210080, "time": 7009.640887498856, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.648266553879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.654842615128, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.661379814148, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.667694568634, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.674608945847, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.68085193634, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7009.689559221268, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210408, "time": 7019.90914273262, "episode/length": 288.0, "episode/score": 0.010660668133937179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010660668133937179}
{"step": 210448, "time": 7021.39268040657, "episode/length": 288.0, "episode/score": 0.01909965734813568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01909965734813568}
{"step": 210472, "time": 7021.932250738144, "episode/length": 288.0, "episode/score": 0.02116259428797207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02116259428797207}
{"step": 210528, "time": 7023.942337751389, "episode/length": 288.0, "episode/score": 0.016711348032458773, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016711348032458773}
{"step": 210528, "time": 7023.950954914093, "episode/length": 288.0, "episode/score": 0.02964793876876115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02964793876876115}
{"step": 211360, "time": 7050.2217791080475, "episode/length": 288.0, "episode/score": 0.03657688314905272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03657688314905272}
{"step": 211600, "time": 7057.739349603653, "episode/length": 288.0, "episode/score": 0.026737056279785065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026737056279785065}
{"step": 212336, "time": 7081.03595161438, "episode/length": 288.0, "episode/score": 0.0196603842768468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0196603842768468}
{"step": 212720, "time": 7093.112304210663, "episode/length": 288.0, "episode/score": 0.026822327890840825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026822327890840825}
{"step": 212760, "time": 7094.169238328934, "episode/length": 288.0, "episode/score": 0.014374212141518683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014374212141518683}
{"step": 212784, "time": 7095.149558067322, "episode/length": 288.0, "episode/score": 0.012976051116453391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012976051116453391}
{"step": 212840, "time": 7096.680411338806, "episode/length": 288.0, "episode/score": 0.02352238126661632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02352238126661632}
{"step": 212840, "time": 7096.688362121582, "episode/length": 288.0, "episode/score": 0.024590693626038274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024590693626038274}
{"step": 213672, "time": 7123.407680511475, "episode/length": 288.0, "episode/score": 0.01724041964519074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01724041964519074}
{"step": 213912, "time": 7130.975180864334, "episode/length": 288.0, "episode/score": 0.040915962717747334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040915962717747334}
{"step": 214648, "time": 7154.170095682144, "episode/length": 288.0, "episode/score": 0.048463689795596565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048463689795596565}
{"step": 215032, "time": 7166.256972312927, "episode/length": 288.0, "episode/score": 0.07178514872279607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07178514872279607}
{"step": 215072, "time": 7167.729225635529, "episode/length": 288.0, "episode/score": 0.04502600945986046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04502600945986046}
{"step": 215096, "time": 7168.260815143585, "episode/length": 288.0, "episode/score": 0.05364558826232724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05364558826232724}
{"step": 215152, "time": 7170.399548768997, "episode/length": 288.0, "episode/score": 0.054354954529770794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054354954529770794}
{"step": 215152, "time": 7170.418901205063, "episode/length": 288.0, "episode/score": 0.05865053043217472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05865053043217472}
{"step": 215984, "time": 7196.610220193863, "episode/length": 288.0, "episode/score": 0.0618842650049487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0618842650049487}
{"step": 216224, "time": 7204.201622009277, "episode/length": 288.0, "episode/score": 0.07136102486481377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07136102486481377}
{"step": 216960, "time": 7227.383713006973, "episode/length": 288.0, "episode/score": 0.08618585093179831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08618585093179831}
{"step": 217152, "time": 7233.483367919922, "episode/length": 23.0, "episode/score": 0.9424426426234334, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.0143176195964827}
{"step": 217273, "time": 7238.027245283127, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.446942516208924, "train/action_min": 0.0, "train/action_std": 1.8367795716855944, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0014055474336797937, "train/actor_opt_grad_steps": 12515.0, "train/actor_opt_loss": 6.476164785962667, "train/adv_mag": 0.0076188504619082225, "train/adv_max": 0.007609997981602384, "train/adv_mean": 0.001526599740860036, "train/adv_min": -0.00164723042974767, "train/adv_std": 0.0012981709016045345, "train/cont_avg": 0.9965014900128866, "train/cont_loss_mean": 0.023268854189136056, "train/cont_loss_std": 0.321001536079644, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.663934461694015, "train/cont_pos_acc": 0.9999999861741803, "train/cont_pos_loss": 0.003493974915436786, "train/cont_pred": 0.996512187817662, "train/cont_rate": 0.9965014900128866, "train/dyn_loss_mean": 1.000008259851908, "train/dyn_loss_std": 0.000225494549649926, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.12930197715603256, "train/extr_critic_critic_opt_grad_steps": 12515.0, "train/extr_critic_critic_opt_loss": 11645.33223763692, "train/extr_critic_mag": 0.11115695705118868, "train/extr_critic_max": 0.11115695705118868, "train/extr_critic_mean": 0.1102670926178239, "train/extr_critic_min": 0.10824365714161667, "train/extr_critic_std": 0.000367518330020494, "train/extr_return_normed_mag": 0.011461151859809443, "train/extr_return_normed_max": 0.01145807165921349, "train/extr_return_normed_mean": 0.005271344758146314, "train/extr_return_normed_min": 0.0020496276466502356, "train/extr_return_normed_std": 0.0013515665120872448, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.11798039362909868, "train/extr_return_raw_max": 0.11798039362909868, "train/extr_return_raw_mean": 0.11179367160981464, "train/extr_return_raw_min": 0.10857194961653542, "train/extr_return_raw_std": 0.0013515665170378964, "train/extr_reward_mag": 0.002660099993047026, "train/extr_reward_max": 0.002660099993047026, "train/extr_reward_mean": 0.000542141094332148, "train/extr_reward_min": 5.037637101006262e-05, "train/extr_reward_std": 0.0004729609137995663, "train/image_loss_mean": 0.20191930418776483, "train/image_loss_std": 0.09665431493182772, "train/model_loss_mean": 0.83489656970673, "train/model_loss_std": 0.36896499457586673, "train/model_opt_grad_norm": 40.5315029596545, "train/model_opt_grad_steps": 12501.768041237114, "train/model_opt_loss": 2409.0962480368075, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2886.59793814433, "train/policy_entropy_mag": 1.8050442608361392, "train/policy_entropy_max": 1.8050442608361392, "train/policy_entropy_mean": 1.3241359817305791, "train/policy_entropy_min": 0.80100966602103, "train/policy_entropy_std": 0.18128967991809256, "train/policy_logprob_mag": 4.608862610207391, "train/policy_logprob_max": -0.2740358379189424, "train/policy_logprob_mean": -1.3242229461362682, "train/policy_logprob_min": -4.608862610207391, "train/policy_logprob_std": 0.7691620308713815, "train/policy_randomness_mag": 0.9276093090932394, "train/policy_randomness_max": 0.9276093090932394, "train/policy_randomness_mean": 0.68047132473631, "train/policy_randomness_min": 0.41163756441056115, "train/policy_randomness_std": 0.09316447175578359, "train/post_ent_mag": 65.44867562756096, "train/post_ent_max": 65.44867562756096, "train/post_ent_mean": 65.11241610025623, "train/post_ent_min": 64.7813925005726, "train/post_ent_std": 0.1287835151264348, "train/prior_ent_mag": 64.73724141071752, "train/prior_ent_max": 64.73724141071752, "train/prior_ent_mean": 60.97181798010757, "train/prior_ent_min": 59.75292107493607, "train/prior_ent_std": 0.8559524174203578, "train/rep_loss_mean": 1.000008259851908, "train/rep_loss_std": 0.000225494549649926, "train/reward_avg": 0.0002759624331542675, "train/reward_loss_mean": 0.009703432272197967, "train/reward_loss_std": 0.0551786505060328, "train/reward_max_data": 0.09059450220911927, "train/reward_max_pred": 0.0016897916793823242, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008289207663559882, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.564967854817708, "train/reward_pred": 0.0002563760919525221, "train/reward_rate": 0.00016611630154639176, "train_stats/mean_log_entropy": 1.3551276298326866, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020138965919613838, "report/cont_loss_std": 0.2997934818267822, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.550767421722412, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0038883471861481667, "report/cont_pred": 0.9961192607879639, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2082546353340149, "report/image_loss_std": 0.10297803580760956, "report/model_loss_mean": 0.8449327349662781, "report/model_loss_std": 0.4778039753437042, "report/post_ent_mag": 66.57778930664062, "report/post_ent_max": 66.57778930664062, "report/post_ent_mean": 66.0946044921875, "report/post_ent_min": 65.67356872558594, "report/post_ent_std": 0.16461822390556335, "report/prior_ent_mag": 64.0973129272461, "report/prior_ent_max": 64.0973129272461, "report/prior_ent_mean": 61.048492431640625, "report/prior_ent_min": 59.731590270996094, "report/prior_ent_std": 0.7543928623199463, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0006077004363760352, "report/reward_loss_mean": 0.016539087519049644, "report/reward_loss_std": 0.2194892317056656, "report/reward_max_data": 0.4012500047683716, "report/reward_max_pred": 0.0018455982208251953, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009693579748272896, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 7.01949405670166, "report/reward_pred": 0.0002405368722975254, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014725778251886368, "eval/cont_loss_std": 0.2449861466884613, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.552712440490723, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0038882324006408453, "eval/cont_pred": 0.9961193799972534, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23296242952346802, "eval/image_loss_std": 0.10610697418451309, "eval/model_loss_mean": 0.8487882614135742, "eval/model_loss_std": 0.2666393518447876, "eval/post_ent_mag": 66.48258972167969, "eval/post_ent_max": 66.48258972167969, "eval/post_ent_mean": 66.08988952636719, "eval/post_ent_min": 65.65953826904297, "eval/post_ent_std": 0.1590614914894104, "eval/prior_ent_mag": 64.65646362304688, "eval/prior_ent_max": 64.65646362304688, "eval/prior_ent_mean": 61.182106018066406, "eval/prior_ent_min": 59.77662658691406, "eval/prior_ent_std": 0.9065194129943848, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010999790392816067, "eval/reward_loss_std": 0.0011046590516343713, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0033048391342163086, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010999790392816067, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021186284720897675, "eval/reward_rate": 0.0, "replay/size": 216769.0, "replay/inserts": 31024.0, "replay/samples": 31024.0, "replay/insert_wait_avg": 1.2632711084925556e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0098591485301388e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0746366837445428e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.685754776000977e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1608974933624, "timer/env.step_count": 3878.0, "timer/env.step_total": 36.72512626647949, "timer/env.step_frac": 0.03671921823630704, "timer/env.step_avg": 0.009470120233749225, "timer/env.step_min": 0.007729053497314453, "timer/env.step_max": 0.037979841232299805, "timer/replay._sample_count": 31024.0, "timer/replay._sample_total": 15.681447267532349, "timer/replay._sample_frac": 0.01567892456787076, "timer/replay._sample_avg": 0.0005054618123882268, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.011138916015625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4745.0, "timer/agent.policy_total": 48.01292014122009, "timer/agent.policy_frac": 0.048005196225479045, "timer/agent.policy_avg": 0.010118634381711294, "timer/agent.policy_min": 0.00868082046508789, "timer/agent.policy_max": 0.0961904525756836, "timer/dataset_train_count": 1939.0, "timer/dataset_train_total": 0.2150566577911377, "timer/dataset_train_frac": 0.00021502206128046005, "timer/dataset_train_avg": 0.00011091111799439798, "timer/dataset_train_min": 9.465217590332031e-05, "timer/dataset_train_max": 0.00043487548828125, "timer/agent.train_count": 1939.0, "timer/agent.train_total": 864.4321894645691, "timer/agent.train_frac": 0.8642931268669258, "timer/agent.train_avg": 0.44581340354026255, "timer/agent.train_min": 0.43273353576660156, "timer/agent.train_max": 1.3306965827941895, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4735586643218994, "timer/agent.report_frac": 0.00047348248217736607, "timer/agent.report_avg": 0.2367793321609497, "timer/agent.report_min": 0.23186421394348145, "timer/agent.report_max": 0.24169445037841797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1942950059014275e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 31.018468862725527}
{"step": 217344, "time": 7240.242607116699, "episode/length": 288.0, "episode/score": 0.06403179354433064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06403179354433064}
{"step": 217384, "time": 7241.28023147583, "episode/length": 288.0, "episode/score": 0.05653070024288809, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05653070024288809}
{"step": 217408, "time": 7242.277257442474, "episode/length": 288.0, "episode/score": 0.0810328466649679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0810328466649679}
{"step": 217464, "time": 7243.893544435501, "episode/length": 288.0, "episode/score": 0.08062392012607233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08062392012607233}
{"step": 217464, "time": 7243.902131557465, "episode/length": 288.0, "episode/score": 0.0694051840209795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0694051840209795}
{"step": 218296, "time": 7270.276770353317, "episode/length": 288.0, "episode/score": 0.06333176508275074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06333176508275074}
{"step": 218536, "time": 7277.834569454193, "episode/length": 288.0, "episode/score": 0.06579005829546247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06579005829546247}
{"step": 219464, "time": 7307.017953634262, "episode/length": 288.0, "episode/score": 0.04542899537918288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04542899537918288}
{"step": 219656, "time": 7313.160473585129, "episode/length": 288.0, "episode/score": 0.030811906696641245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030811906696641245}
{"step": 219696, "time": 7314.650094985962, "episode/length": 288.0, "episode/score": 0.036822653495420354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036822653495420354}
{"step": 219720, "time": 7315.19012761116, "episode/length": 288.0, "episode/score": 0.04155591853221097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04155591853221097}
{"step": 219776, "time": 7317.174415111542, "episode/length": 288.0, "episode/score": 0.029665305245998752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029665305245998752}
{"step": 219776, "time": 7317.183216810226, "episode/length": 288.0, "episode/score": 0.03888466263538248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03888466263538248}
{"step": 220064, "time": 7331.460022687912, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.467840194702, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.47434091568, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.480694532394, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.4869973659515, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.493223190308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.4994513988495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7331.505685329437, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220608, "time": 7348.690553426743, "episode/length": 288.0, "episode/score": 0.031207223774913473, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031207223774913473}
{"step": 220848, "time": 7356.250434398651, "episode/length": 288.0, "episode/score": 0.07921716178304905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07921716178304905}
{"step": 221776, "time": 7386.166610240936, "episode/length": 288.0, "episode/score": 0.06142054808844932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06142054808844932}
{"step": 221968, "time": 7392.22828412056, "episode/length": 288.0, "episode/score": 0.06202846498126746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06202846498126746}
{"step": 222008, "time": 7393.264534711838, "episode/length": 288.0, "episode/score": 0.06244153556542642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06244153556542642}
{"step": 222032, "time": 7394.264828681946, "episode/length": 288.0, "episode/score": 0.03334808793806587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03334808793806587}
{"step": 222088, "time": 7395.812977313995, "episode/length": 288.0, "episode/score": 0.0597250510989511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0597250510989511}
{"step": 222088, "time": 7395.826544761658, "episode/length": 288.0, "episode/score": 0.055429433818574125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055429433818574125}
{"step": 222920, "time": 7422.03310418129, "episode/length": 288.0, "episode/score": 0.02902886108859093, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02902886108859093}
{"step": 223160, "time": 7429.5705988407135, "episode/length": 288.0, "episode/score": 0.038954246954290284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038954246954290284}
{"step": 224088, "time": 7458.846082210541, "episode/length": 288.0, "episode/score": 0.06548758569545043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06548758569545043}
{"step": 224240, "time": 7463.848261117935, "episode/length": 134.0, "episode/score": 0.6300605545063149, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.048810513947216805}
{"step": 224280, "time": 7464.907240390778, "episode/length": 288.0, "episode/score": 0.05534388941521229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05534388941521229}
{"step": 224320, "time": 7466.399138212204, "episode/length": 288.0, "episode/score": 0.06486608716608089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06486608716608089}
{"step": 224344, "time": 7466.935188293457, "episode/length": 288.0, "episode/score": 0.05716648123490131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05716648123490131}
{"step": 224400, "time": 7469.010949611664, "episode/length": 288.0, "episode/score": 0.08213110045562644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08213110045562644}
{"step": 224400, "time": 7469.020043849945, "episode/length": 288.0, "episode/score": 0.0600638590744893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0600638590744893}
{"step": 225232, "time": 7495.227245330811, "episode/length": 288.0, "episode/score": 0.10214373803563603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10214373803563603}
{"step": 226400, "time": 7532.316936969757, "episode/length": 288.0, "episode/score": 0.08247242736922544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08247242736922544}
{"step": 226552, "time": 7536.868470907211, "episode/length": 288.0, "episode/score": 0.10157527946978462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10157527946978462}
{"step": 226592, "time": 7538.347997188568, "episode/length": 288.0, "episode/score": 0.1105574381730321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1105574381730321}
{"step": 226632, "time": 7539.383102178574, "episode/length": 288.0, "episode/score": 0.20930466580483653, "episode/reward_rate": 0.0034602076124567475, "episode/intrinsic_return": 0.10930466547887363}
{"step": 226656, "time": 7540.366530179977, "episode/length": 288.0, "episode/score": 0.0741969149353281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0741969149353281}
{"step": 226712, "time": 7541.919145584106, "episode/length": 288.0, "episode/score": 0.07874084248601321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07874084248601321}
{"step": 226712, "time": 7541.9271948337555, "episode/length": 288.0, "episode/score": 0.06788538673623634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06788538673623634}
{"step": 227176, "time": 7556.4875228405, "episode/length": 57.0, "episode/score": 0.8455996532767927, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.023724648480481392}
{"step": 227544, "time": 7568.157251596451, "episode/length": 288.0, "episode/score": 0.0925016643347476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0925016643347476}
{"step": 228264, "time": 7590.905495882034, "episode/length": 208.0, "episode/score": 0.44725251696343093, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.09725252373880267}
{"step": 228576, "time": 7600.998757600784, "episode/length": 242.0, "episode/score": 0.3169421874547993, "episode/reward_rate": 0.00411522633744856, "episode/intrinsic_return": 0.07319218230924207}
{"step": 228696, "time": 7604.560609340668, "episode/length": 143.0, "episode/score": 0.6288021890080131, "episode/reward_rate": 0.006944444444444444, "episode/intrinsic_return": 0.0756771508470706}
{"step": 228712, "time": 7605.068484067917, "episode/length": 288.0, "episode/score": 0.06772886842529147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06772886842529147}
{"step": 228864, "time": 7610.08620595932, "episode/length": 288.0, "episode/score": 0.06169211735164026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06169211735164026}
{"step": 228968, "time": 7613.180914402008, "episode/length": 288.0, "episode/score": 0.07255849008120663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07255849008120663}
{"step": 229024, "time": 7615.162582874298, "episode/length": 288.0, "episode/score": 0.06954175076822366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06954175076822366}
{"step": 229296, "time": 7623.813917636871, "episode/length": 33.0, "episode/score": 0.9132149551351176, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.016339932108166977}
{"step": 229488, "time": 7630.323797702789, "episode/length": 288.0, "episode/score": 0.08006634892129227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08006634892129227}
{"step": 230048, "time": 7650.305047273636, "eval_episode/length": 128.0, "eval_episode/score": 0.6000000238418579, "eval_episode/reward_rate": 0.007751937984496124}
{"step": 230048, "time": 7653.138915777206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7653.146272182465, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7653.152724981308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7653.158836603165, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7653.164884567261, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7653.170996427536, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7653.177231311798, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230336, "time": 7662.156306505203, "episode/length": 258.0, "episode/score": 0.2594795916006376, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.0657295987252553}
{"step": 230888, "time": 7679.416615486145, "episode/length": 288.0, "episode/score": 0.05821993596268271, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05821993596268271}
{"step": 231008, "time": 7683.419761657715, "episode/length": 288.0, "episode/score": 0.044303939021176575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044303939021176575}
{"step": 231024, "time": 7683.929557561874, "episode/length": 288.0, "episode/score": 0.049842801936335945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049842801936335945}
{"step": 231176, "time": 7688.516960859299, "episode/length": 288.0, "episode/score": 0.051663919569534755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051663919569534755}
{"step": 231280, "time": 7692.007161617279, "episode/length": 288.0, "episode/score": 0.06370572931098195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06370572931098195}
{"step": 231608, "time": 7702.109477043152, "episode/length": 288.0, "episode/score": 0.05031437069501976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05031437069501976}
{"step": 231800, "time": 7708.171800374985, "episode/length": 288.0, "episode/score": 0.050617954156706446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050617954156706446}
{"step": 232648, "time": 7734.924085617065, "episode/length": 288.0, "episode/score": 0.05111580045149822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05111580045149822}
{"step": 232816, "time": 7740.580811262131, "episode/length": 204.0, "episode/score": 0.4165719112950228, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.05407188505500926}
{"step": 233200, "time": 7752.625510215759, "episode/length": 288.0, "episode/score": 0.07526213684406002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07526213684406002}
{"step": 233320, "time": 7756.191095590591, "episode/length": 288.0, "episode/score": 0.09074097762749034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09074097762749034}
{"step": 233336, "time": 7756.707095384598, "episode/length": 288.0, "episode/score": 0.06395446705550967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06395446705550967}
{"step": 233592, "time": 7764.791095495224, "episode/length": 288.0, "episode/score": 0.04913112766868721, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04913112766868721}
{"step": 233736, "time": 7769.421833992004, "episode/length": 265.0, "episode/score": 0.2319518870192212, "episode/reward_rate": 0.0037593984962406013, "episode/intrinsic_return": 0.060076893480271565}
{"step": 234112, "time": 7781.410544872284, "episode/length": 288.0, "episode/score": 0.05518556372862804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05518556372862804}
{"step": 234960, "time": 7808.171566724777, "episode/length": 288.0, "episode/score": 0.06565106441161106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06565106441161106}
{"step": 235128, "time": 7813.238858222961, "episode/length": 288.0, "episode/score": 0.05136518824616587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05136518824616587}
{"step": 235336, "time": 7819.793102502823, "episode/length": 249.0, "episode/score": 0.25950891624097494, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.03763392003611443}
{"step": 235512, "time": 7825.32053899765, "episode/length": 288.0, "episode/score": 0.0605954140688425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0605954140688425}
{"step": 235632, "time": 7829.412800312042, "episode/length": 288.0, "episode/score": 0.07318873807361115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07318873807361115}
{"step": 235904, "time": 7837.960484266281, "episode/length": 288.0, "episode/score": 0.07920584656869778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07920584656869778}
{"step": 236048, "time": 7842.47308921814, "episode/length": 288.0, "episode/score": 0.047487684209187364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047487684209187364}
{"step": 236272, "time": 7849.510182857513, "episode/length": 269.0, "episode/score": 0.2107105793685946, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.05133558880987721}
{"step": 237272, "time": 7880.79003405571, "episode/length": 288.0, "episode/score": 0.06949838132183572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06949838132183572}
{"step": 237440, "time": 7886.25675034523, "episode/length": 288.0, "episode/score": 0.06311932808833376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06311932808833376}
{"step": 237648, "time": 7893.387935400009, "episode/length": 288.0, "episode/score": 0.0786416468285438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0786416468285438}
{"step": 237824, "time": 7898.8878610134125, "episode/length": 288.0, "episode/score": 0.04982735193905796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04982735193905796}
{"step": 237920, "time": 7901.955279827118, "episode/length": 233.0, "episode/score": 0.3282142749701791, "episode/reward_rate": 0.004273504273504274, "episode/intrinsic_return": 0.056339287391693915}
{"step": 237944, "time": 7902.495997428894, "episode/length": 288.0, "episode/score": 0.06853092862843368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06853092862843368}
{"step": 238216, "time": 7911.094064712524, "episode/length": 288.0, "episode/score": 0.08952982885105598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08952982885105598}
{"step": 238584, "time": 7922.740041255951, "episode/length": 288.0, "episode/score": 0.036556191134224036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036556191134224036}
{"step": 239360, "time": 7947.452905654907, "episode/length": 96.0, "episode/score": 0.7362760151341945, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03627599766025469}
{"step": 239584, "time": 7954.625893831253, "episode/length": 288.0, "episode/score": 0.04538104752789707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04538104752789707}
{"step": 239752, "time": 7959.689160585403, "episode/length": 288.0, "episode/score": 0.04315221615895837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04315221615895837}
{"step": 239848, "time": 7962.722796678543, "episode/length": 11.0, "episode/score": 0.9733322118478895, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.007707200427546468}
{"step": 239960, "time": 7966.246749162674, "episode/length": 288.0, "episode/score": 0.03962119968167599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03962119968167599}
{"step": 240032, "time": 7973.172356843948, "eval_episode/length": 221.0, "eval_episode/score": 0.30937498807907104, "eval_episode/reward_rate": 0.0045045045045045045}
{"step": 240032, "time": 7973.3833656311035, "eval_episode/length": 233.0, "eval_episode/score": 0.2718749940395355, "eval_episode/reward_rate": 0.004273504273504274}
{"step": 240032, "time": 7974.352528810501, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7974.359841108322, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7974.36669754982, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7974.373404741287, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7974.3796372413635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 7974.385982513428, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240136, "time": 7977.42323756218, "episode/length": 288.0, "episode/score": 0.05035666986442777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05035666986442777}
{"step": 240232, "time": 7980.512922048569, "episode/length": 288.0, "episode/score": 0.0526942165554658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0526942165554658}
{"step": 240256, "time": 7981.495885133743, "episode/length": 288.0, "episode/score": 0.04772431253066145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04772431253066145}
{"step": 240528, "time": 7990.063117027283, "episode/length": 288.0, "episode/score": 0.0431383103837959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0431383103837959}
{"step": 240544, "time": 7990.571509599686, "episode/length": 147.0, "episode/score": 0.5686618691772622, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.028036863624251396}
{"step": 240832, "time": 7999.579295396805, "episode/length": 74.0, "episode/score": 0.7905338048958583, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.0217837786558448}
{"step": 241816, "time": 8030.467224359512, "episode/length": 231.0, "episode/score": 0.33159559891291224, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.05347061199799441}
{"step": 241896, "time": 8033.006984949112, "episode/length": 288.0, "episode/score": 0.051901729424557175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051901729424557175}
{"step": 241896, "time": 8033.018391132355, "episode/length": 170.0, "episode/score": 0.5349117664494543, "episode/reward_rate": 0.005847953216374269, "episode/intrinsic_return": 0.06616176761360748}
{"step": 241944, "time": 8034.532986164093, "episode/length": 261.0, "episode/score": 0.2565708102253268, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.07219580782717117}
{"step": 242448, "time": 8050.834059715271, "episode/length": 288.0, "episode/score": 0.09922715213372157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09922715213372157}
{"step": 242568, "time": 8054.392168998718, "episode/length": 288.0, "episode/score": 0.07062733677007316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07062733677007316}
{"step": 242752, "time": 8060.397425413132, "episode/length": 275.0, "episode/score": 0.21534191630996702, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.07471691689204363}
{"step": 242856, "time": 8063.480534076691, "episode/length": 252.0, "episode/score": 0.27203241424061275, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.05953240944430149}
{"step": 243888, "time": 8096.323271989822, "episode/length": 179.0, "episode/score": 0.49021085860158564, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.04958584749556394}
{"step": 244128, "time": 8103.993547201157, "episode/length": 288.0, "episode/score": 0.07989596523725595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07989596523725595}
{"step": 244208, "time": 8106.499645233154, "episode/length": 288.0, "episode/score": 0.08909259125834978, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08909259125834978}
{"step": 244208, "time": 8106.508441448212, "episode/length": 288.0, "episode/score": 0.07375514115437909, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07375514115437909}
{"step": 244256, "time": 8108.011971712112, "episode/length": 288.0, "episode/score": 0.09982349140818769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09982349140818769}
{"step": 244744, "time": 8123.108224868774, "episode/length": 106.0, "episode/score": 0.705510046170275, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.03676002869633521}
{"step": 244880, "time": 8127.615267753601, "episode/length": 288.0, "episode/score": 0.07046513409648014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07046513409648014}
{"step": 245064, "time": 8133.263258218765, "episode/length": 288.0, "episode/score": 0.07485056427083236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07485056427083236}
{"step": 245168, "time": 8136.757777452469, "episode/length": 288.0, "episode/score": 0.06780518334664976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06780518334664976}
{"step": 245736, "time": 8154.502980709076, "episode/length": 106.0, "episode/score": 0.7014282699037722, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.03267828263960837}
{"step": 245800, "time": 8157.011392116547, "episode/length": 131.0, "episode/score": 0.6311629568548369, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.04053796059758952}
{"step": 246024, "time": 8164.195755958557, "episode/length": 226.0, "episode/score": 0.3487442919044952, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.05499430464033139}
{"step": 246336, "time": 8174.313353061676, "episode/length": 38.0, "episode/score": 0.8995435910330798, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.018293552872137298}
{"step": 246440, "time": 8177.380279541016, "episode/length": 288.0, "episode/score": 0.08848986147791038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08848986147791038}
{"step": 246496, "time": 8179.360900640488, "episode/length": 94.0, "episode/score": 0.7411016603396092, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.034851634099595685}
{"step": 246520, "time": 8179.921687602997, "episode/length": 288.0, "episode/score": 0.05853996917329596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05853996917329596}
{"step": 246568, "time": 8181.4429540634155, "episode/length": 288.0, "episode/score": 0.04961038560719544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04961038560719544}
{"step": 247032, "time": 8196.140909910202, "episode/length": 73.0, "episode/score": 0.7928242530152829, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.02094919977855625}
{"step": 247376, "time": 8207.200974702835, "episode/length": 288.0, "episode/score": 0.0402801824923813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0402801824923813}
{"step": 247480, "time": 8210.273401737213, "episode/length": 288.0, "episode/score": 0.04793581885041931, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04793581885041931}
{"step": 247992, "time": 8226.481511116028, "episode/length": 119.0, "episode/score": 0.6730230371784955, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.04489800191629456}
{"step": 248112, "time": 8230.476640701294, "episode/length": 288.0, "episode/score": 0.04652054810696882, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04652054810696882}
{"step": 248329, "time": 8238.104311227798, "train_stats/mean_log_entropy": 0.8957224483372735, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2680195287330864, "train/action_min": 0.0, "train/action_std": 1.831349039200655, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0019053842745764547, "train/actor_opt_grad_steps": 14455.0, "train/actor_opt_loss": 8.816396944244037, "train/adv_mag": 0.011174914379095294, "train/adv_max": 0.010838902411387139, "train/adv_mean": 0.0019263203637904355, "train/adv_min": -0.0035202964065001183, "train/adv_std": 0.0019815436785815036, "train/cont_avg": 0.99658203125, "train/cont_loss_mean": 0.02285156837309298, "train/cont_loss_std": 0.31950590786862954, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.667208899949726, "train/cont_pos_acc": 0.9999999858669399, "train/cont_pos_loss": 0.0034959259978255505, "train/cont_pred": 0.9965103062772259, "train/cont_rate": 0.99658203125, "train/dyn_loss_mean": 1.000004393538249, "train/dyn_loss_std": 0.00010523194139319251, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.22966527468860917, "train/extr_critic_critic_opt_grad_steps": 14455.0, "train/extr_critic_critic_opt_loss": 4820.770918698655, "train/extr_critic_mag": 0.18444228971127383, "train/extr_critic_max": 0.18444228971127383, "train/extr_critic_mean": 0.1825523709052617, "train/extr_critic_min": 0.1798740268982563, "train/extr_critic_std": 0.0007653003336299755, "train/extr_return_normed_mag": 0.015482528768863874, "train/extr_return_normed_max": 0.015437666365166301, "train/extr_return_normed_mean": 0.005684708028920139, "train/extr_return_normed_min": 0.00020152883431346147, "train/extr_return_normed_std": 0.0021530117109878778, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.19423164934227147, "train/extr_return_raw_max": 0.19423164934227147, "train/extr_return_raw_mean": 0.18447870023779034, "train/extr_return_raw_min": 0.17899551181141862, "train/extr_return_raw_std": 0.0021530117115879568, "train/extr_reward_mag": 0.005783654979823791, "train/extr_reward_max": 0.005783654979823791, "train/extr_reward_mean": 0.0008194937546840706, "train/extr_reward_min": 1.7587057093984074e-05, "train/extr_reward_std": 0.0010883667056668387, "train/image_loss_mean": 0.18671021072827665, "train/image_loss_std": 0.10403464331301217, "train/model_loss_mean": 0.8195416070136827, "train/model_loss_std": 0.36985018876256404, "train/model_opt_grad_norm": 37.36073030884733, "train/model_opt_grad_steps": 14440.170103092783, "train/model_opt_loss": 2502.0674060939514, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3054.1237113402062, "train/policy_entropy_mag": 1.7783845534029694, "train/policy_entropy_max": 1.7783845534029694, "train/policy_entropy_mean": 0.8998707379262472, "train/policy_entropy_min": 0.07944935049439214, "train/policy_entropy_std": 0.39645875237651707, "train/policy_logprob_mag": 6.365550137057747, "train/policy_logprob_max": -0.011004835189579381, "train/policy_logprob_mean": -0.900134716759023, "train/policy_logprob_min": -6.365550137057747, "train/policy_logprob_std": 1.0407217467568584, "train/policy_randomness_mag": 0.9139089289399767, "train/policy_randomness_max": 0.9139089289399767, "train/policy_randomness_mean": 0.4624421107246704, "train/policy_randomness_min": 0.04082889203942314, "train/policy_randomness_std": 0.20373950691260012, "train/post_ent_mag": 63.378146397698785, "train/post_ent_max": 63.378146397698785, "train/post_ent_mean": 62.8190847770455, "train/post_ent_min": 62.31133559315475, "train/post_ent_std": 0.16923521774024078, "train/prior_ent_mag": 64.06816195458481, "train/prior_ent_max": 64.06816195458481, "train/prior_ent_mean": 61.02138285292793, "train/prior_ent_min": 59.14243308785036, "train/prior_ent_std": 0.7925307990349445, "train/rep_loss_mean": 1.000004393538249, "train/rep_loss_std": 0.00010523194139319251, "train/reward_avg": 0.00028245254121504764, "train/reward_loss_mean": 0.009977171920028697, "train/reward_loss_std": 0.05330185457756839, "train/reward_max_data": 0.0836370287645493, "train/reward_max_pred": 0.0040178151474785555, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008571687872166332, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 7.95980102221171, "train/reward_pred": 0.00027767999323334585, "train/reward_rate": 0.000176183956185567, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.014135418459773064, "report/cont_loss_std": 0.23685452342033386, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.364171981811523, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0036656800657510757, "report/cont_pred": 0.9963390827178955, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1709110140800476, "report/image_loss_std": 0.10629519075155258, "report/model_loss_mean": 0.796352744102478, "report/model_loss_std": 0.2623678743839264, "report/post_ent_mag": 59.168601989746094, "report/post_ent_max": 59.168601989746094, "report/post_ent_mean": 58.62262725830078, "report/post_ent_min": 58.12443542480469, "report/post_ent_std": 0.1672033816576004, "report/prior_ent_mag": 61.81379318237305, "report/prior_ent_max": 61.81379318237305, "report/prior_ent_mean": 59.34272766113281, "report/prior_ent_min": 57.39344787597656, "report/prior_ent_std": 0.7235879302024841, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002543876471463591, "report/reward_loss_mean": 0.011306282132863998, "report/reward_loss_std": 0.01649816706776619, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0045473575592041016, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01130628027021885, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003302189288660884, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.014473102055490017, "eval/cont_loss_std": 0.24844110012054443, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6305460929870605, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034827447962015867, "eval/cont_pred": 0.9965232610702515, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2315661609172821, "eval/image_loss_std": 0.1249905377626419, "eval/model_loss_mean": 0.8472038507461548, "eval/model_loss_std": 0.28109249472618103, "eval/post_ent_mag": 59.06179428100586, "eval/post_ent_max": 59.06179428100586, "eval/post_ent_mean": 58.58009719848633, "eval/post_ent_min": 58.11470413208008, "eval/post_ent_std": 0.1426709145307541, "eval/prior_ent_mag": 61.115142822265625, "eval/prior_ent_max": 61.115142822265625, "eval/prior_ent_mean": 59.57179260253906, "eval/prior_ent_min": 57.770416259765625, "eval/prior_ent_std": 0.6219711303710938, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011645378544926643, "eval/reward_loss_std": 0.0013735487591475248, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0015822649002075195, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011645378544926643, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021066260524094105, "eval/reward_rate": 0.0, "replay/size": 247825.0, "replay/inserts": 31056.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.2566953022292076e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.72214401044654e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0607495577415106e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0589370727539, "timer/env.step_count": 3882.0, "timer/env.step_total": 36.54734992980957, "timer/env.step_frac": 0.036545196062930406, "timer/env.step_avg": 0.009414567215303857, "timer/env.step_min": 0.007722377777099609, "timer/env.step_max": 0.035192012786865234, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 15.689701557159424, "timer/replay._sample_frac": 0.01568877690657346, "timer/replay._sample_avg": 0.0005052067734788583, "timer/replay._sample_min": 0.0003898143768310547, "timer/replay._sample_max": 0.024600505828857422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4749.0, "timer/agent.policy_total": 47.99129891395569, "timer/agent.policy_frac": 0.04798847061397176, "timer/agent.policy_avg": 0.010105558836377277, "timer/agent.policy_min": 0.008725643157958984, "timer/agent.policy_max": 0.09206938743591309, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.2172541618347168, "timer/dataset_train_frac": 0.00021724135826497958, "timer/dataset_train_avg": 0.00011192898600449088, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0010809898376464844, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 864.2464253902435, "timer/agent.train_frac": 0.8641954922376439, "timer/agent.train_avg": 0.44525833353438615, "timer/agent.train_min": 0.43419814109802246, "timer/agent.train_max": 0.5852360725402832, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4704563617706299, "timer/agent.report_frac": 0.0004704286360838795, "timer/agent.report_avg": 0.23522818088531494, "timer/agent.report_min": 0.2249588966369629, "timer/agent.report_max": 0.245497465133667, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051577961427673e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 31.053636340986372}
{"step": 248648, "time": 8247.914255857468, "episode/length": 288.0, "episode/score": 0.05742228811584482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05742228811584482}
{"step": 248808, "time": 8253.075330018997, "episode/length": 288.0, "episode/score": 0.06169597305472507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06169597305472507}
{"step": 248832, "time": 8254.055156946182, "episode/length": 288.0, "episode/score": 0.050643509922508656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050643509922508656}
{"step": 248880, "time": 8255.581052064896, "episode/length": 288.0, "episode/score": 0.055554426393143785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055554426393143785}
{"step": 249688, "time": 8280.943481206894, "episode/length": 288.0, "episode/score": 0.06373476163059877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06373476163059877}
{"step": 249792, "time": 8284.445152282715, "episode/length": 288.0, "episode/score": 0.06363618654256697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06363618654256697}
{"step": 250016, "time": 8291.90353512764, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 250016, "time": 8292.181104421616, "eval_episode/length": 38.0, "eval_episode/score": 0.8812500238418579, "eval_episode/reward_rate": 0.02564102564102564}
{"step": 250016, "time": 8296.253610372543, "eval_episode/length": 269.0, "eval_episode/score": 0.15937499701976776, "eval_episode/reward_rate": 0.003703703703703704}
{"step": 250016, "time": 8296.621255874634, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8296.629131555557, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8296.636208295822, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8296.644488811493, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8296.651128530502, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250304, "time": 8305.792522668839, "episode/length": 288.0, "episode/score": 0.0712822829376023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0712822829376023}
{"step": 250424, "time": 8309.523850679398, "episode/length": 288.0, "episode/score": 0.05448751136094643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05448751136094643}
{"step": 250960, "time": 8326.659088611603, "episode/length": 288.0, "episode/score": 0.06820644383896024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06820644383896024}
{"step": 251120, "time": 8331.6969268322, "episode/length": 288.0, "episode/score": 0.036984102077610714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036984102077610714}
{"step": 251144, "time": 8332.240570545197, "episode/length": 288.0, "episode/score": 0.08033036090381529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08033036090381529}
{"step": 251192, "time": 8333.767608165741, "episode/length": 288.0, "episode/score": 0.06517061776213495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06517061776213495}
{"step": 252000, "time": 8359.609759569168, "episode/length": 288.0, "episode/score": 0.024689523563836246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024689523563836246}
{"step": 252104, "time": 8362.688527345657, "episode/length": 288.0, "episode/score": 0.06534932101482127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06534932101482127}
{"step": 252616, "time": 8378.925965309143, "episode/length": 288.0, "episode/score": 0.054390188375919024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054390188375919024}
{"step": 252704, "time": 8381.91161775589, "episode/length": 284.0, "episode/score": 0.17898808107264585, "episode/reward_rate": 0.0035087719298245615, "episode/intrinsic_return": 0.06648808521703131}
{"step": 253272, "time": 8399.664021730423, "episode/length": 288.0, "episode/score": 0.03522359908481576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03522359908481576}
{"step": 253432, "time": 8404.690546035767, "episode/length": 288.0, "episode/score": 0.048768507445743126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048768507445743126}
{"step": 253456, "time": 8405.668872356415, "episode/length": 288.0, "episode/score": 0.04357528252410248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04357528252410248}
{"step": 253504, "time": 8407.170354604721, "episode/length": 288.0, "episode/score": 0.04351182069137849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04351182069137849}
{"step": 254312, "time": 8432.935256004333, "episode/length": 288.0, "episode/score": 0.047144618240395175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047144618240395175}
{"step": 254416, "time": 8436.44720506668, "episode/length": 288.0, "episode/score": 0.028434117146730387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028434117146730387}
{"step": 254928, "time": 8452.474104881287, "episode/length": 288.0, "episode/score": 0.010337775481957578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010337775481957578}
{"step": 255016, "time": 8455.026802301407, "episode/length": 288.0, "episode/score": 0.027248396330264768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027248396330264768}
{"step": 255584, "time": 8473.194273471832, "episode/length": 288.0, "episode/score": 0.013611877999437638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013611877999437638}
{"step": 255744, "time": 8478.201960802078, "episode/length": 288.0, "episode/score": 0.030789639018280468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030789639018280468}
{"step": 255768, "time": 8478.739480495453, "episode/length": 288.0, "episode/score": 0.02326948666041062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02326948666041062}
{"step": 255816, "time": 8480.278162002563, "episode/length": 288.0, "episode/score": 0.010323879078100617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010323879078100617}
{"step": 256624, "time": 8505.958206653595, "episode/length": 288.0, "episode/score": 0.014579412124248847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014579412124248847}
{"step": 256728, "time": 8508.977748155594, "episode/length": 288.0, "episode/score": 0.018484314593365525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018484314593365525}
{"step": 257240, "time": 8525.25798535347, "episode/length": 288.0, "episode/score": 0.018078572918909686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018078572918909686}
{"step": 257328, "time": 8528.22569823265, "episode/length": 288.0, "episode/score": 0.005618851199301389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.005618851199301389}
{"step": 257384, "time": 8529.752820014954, "episode/length": 201.0, "episode/score": 0.40743249108982127, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.03555750417490344}
{"step": 257896, "time": 8545.822283029556, "episode/length": 288.0, "episode/score": 0.036578193891728006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036578193891728006}
{"step": 258056, "time": 8551.051869153976, "episode/length": 288.0, "episode/score": 0.040483802177050165, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040483802177050165}
{"step": 258128, "time": 8553.537088632584, "episode/length": 288.0, "episode/score": 0.038704570862591936, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038704570862591936}
{"step": 258936, "time": 8578.975302934647, "episode/length": 288.0, "episode/score": 0.037285026596237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037285026596237}
{"step": 259040, "time": 8582.458560466766, "episode/length": 288.0, "episode/score": 0.051641189113297514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051641189113297514}
{"step": 259160, "time": 8586.007536649704, "episode/length": 228.0, "episode/score": 0.3645689179801366, "episode/reward_rate": 0.004366812227074236, "episode/intrinsic_return": 0.07706892510475427}
{"step": 259488, "time": 8596.557271718979, "episode/length": 262.0, "episode/score": 0.24690091980482975, "episode/reward_rate": 0.0038022813688212928, "episode/intrinsic_return": 0.06565091465927253}
{"step": 259552, "time": 8598.567565917969, "episode/length": 288.0, "episode/score": 0.04292550453499189, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04292550453499189}
{"step": 260000, "time": 8614.502190113068, "eval_episode/length": 97.0, "eval_episode/score": 0.6968749761581421, "eval_episode/reward_rate": 0.01020408163265306}
{"step": 260000, "time": 8614.823350906372, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 260000, "time": 8616.465224981308, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 260000, "time": 8617.88406920433, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8617.905567646027, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8617.915776252747, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8617.932407617569, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8617.943950176239, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8617.953193426132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260208, "time": 8624.436874628067, "episode/length": 288.0, "episode/score": 0.05790392685128154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05790392685128154}
{"step": 260368, "time": 8629.445544242859, "episode/length": 288.0, "episode/score": 0.0598062798667911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0598062798667911}
{"step": 260440, "time": 8631.497005939484, "episode/length": 288.0, "episode/score": 0.055933969666170924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055933969666170924}
{"step": 261248, "time": 8657.157956838608, "episode/length": 288.0, "episode/score": 0.03960185840304575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03960185840304575}
{"step": 261352, "time": 8660.20736026764, "episode/length": 288.0, "episode/score": 0.048094324961709845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048094324961709845}
{"step": 261472, "time": 8664.206951618195, "episode/length": 288.0, "episode/score": 0.04826484488398819, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04826484488398819}
{"step": 261800, "time": 8674.490042448044, "episode/length": 288.0, "episode/score": 0.05029483672751667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05029483672751667}
{"step": 261864, "time": 8676.51568365097, "episode/length": 288.0, "episode/score": 0.0625434818202848, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0625434818202848}
{"step": 262520, "time": 8697.707332849503, "episode/length": 288.0, "episode/score": 0.06686356987461295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06686356987461295}
{"step": 262680, "time": 8702.90578866005, "episode/length": 288.0, "episode/score": 0.057099600955325513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057099600955325513}
{"step": 262752, "time": 8705.400561094284, "episode/length": 288.0, "episode/score": 0.06434581197186162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06434581197186162}
{"step": 263328, "time": 8723.576983213425, "episode/length": 100.0, "episode/score": 0.723053640004423, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.03555361136625379}
{"step": 263336, "time": 8723.614218473434, "episode/length": 232.0, "episode/score": 0.3381100888918809, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.06311008374632365}
{"step": 263544, "time": 8730.16287446022, "episode/length": 286.0, "episode/score": 0.1845869888749121, "episode/reward_rate": 0.003484320557491289, "episode/intrinsic_return": 0.07833698705883307}
{"step": 263608, "time": 8732.162920475006, "episode/length": 106.0, "episode/score": 0.6970613034546886, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.02831131619052485}
{"step": 263664, "time": 8734.148837804794, "episode/length": 288.0, "episode/score": 0.08627571076976892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08627571076976892}
{"step": 264112, "time": 8748.2321331501, "episode/length": 288.0, "episode/score": 0.06644465670626687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06644465670626687}
{"step": 264176, "time": 8750.239465713501, "episode/length": 288.0, "episode/score": 0.05843529035149686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05843529035149686}
{"step": 264496, "time": 8760.413602113724, "episode/length": 110.0, "episode/score": 0.6891722354710623, "episode/reward_rate": 0.009009009009009009, "episode/intrinsic_return": 0.03292222115197774}
{"step": 264992, "time": 8776.103446483612, "episode/length": 288.0, "episode/score": 0.04479160274024707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04479160274024707}
{"step": 265224, "time": 8783.18179345131, "episode/length": 28.0, "episode/score": 0.9275555502157999, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.015055503032670003}
{"step": 265640, "time": 8796.456563472748, "episode/length": 288.0, "episode/score": 0.035194012313183975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035194012313183975}
{"step": 265648, "time": 8796.936716556549, "episode/length": 288.0, "episode/score": 0.04440766119358841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04440766119358841}
{"step": 265728, "time": 8799.464497566223, "episode/length": 62.0, "episode/score": 0.8297227912040626, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.023472800726835885}
{"step": 265856, "time": 8803.476258277893, "episode/length": 288.0, "episode/score": 0.040448742194371334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040448742194371334}
{"step": 265976, "time": 8807.045768976212, "episode/length": 288.0, "episode/score": 0.047075060789779855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047075060789779855}
{"step": 266424, "time": 8821.358201026917, "episode/length": 288.0, "episode/score": 0.05119622820006953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05119622820006953}
{"step": 266488, "time": 8823.397195577621, "episode/length": 288.0, "episode/score": 0.018174156790905727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018174156790905727}
{"step": 266512, "time": 8824.421335935593, "episode/length": 81.0, "episode/score": 0.7776724019649919, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.030797390544648806}
{"step": 266808, "time": 8833.660566806793, "episode/length": 288.0, "episode/score": 0.03826339781664956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03826339781664956}
{"step": 266928, "time": 8837.710776090622, "episode/length": 149.0, "episode/score": 0.5828546541247874, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.048479612808989714}
{"step": 267392, "time": 8852.413051366806, "episode/length": 72.0, "episode/score": 0.7911446725493647, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.016144666996353862}
{"step": 267464, "time": 8854.441447496414, "episode/length": 66.0, "episode/score": 0.815368906420872, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.021618889703631794}
{"step": 267584, "time": 8858.436753511429, "episode/length": 136.0, "episode/score": 0.6116003235100038, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.03660032827139048}
{"step": 267952, "time": 8870.077267885208, "episode/length": 288.0, "episode/score": 0.040037673750191516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040037673750191516}
{"step": 267960, "time": 8870.114785671234, "episode/length": 288.0, "episode/score": 0.029611917648168173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029611917648168173}
{"step": 268088, "time": 8874.153250217438, "episode/length": 77.0, "episode/score": 0.7763350235662756, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.016960039229957147}
{"step": 268288, "time": 8881.739372968674, "episode/length": 288.0, "episode/score": 0.04400532231662169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04400532231662169}
{"step": 268736, "time": 8895.82818865776, "episode/length": 97.0, "episode/score": 0.728630431354361, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.031755448036676626}
{"step": 268736, "time": 8895.837239027023, "episode/length": 288.0, "episode/score": 0.035818352157122035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035818352157122035}
{"step": 268824, "time": 8898.446788072586, "episode/length": 288.0, "episode/score": 0.0492835509445797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0492835509445797}
{"step": 269704, "time": 8926.391006231308, "episode/length": 288.0, "episode/score": 0.031789725100111355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031789725100111355}
{"step": 269704, "time": 8926.40218091011, "episode/length": 264.0, "episode/score": 0.22661612624531813, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.051616130389703585}
{"step": 270088, "time": 8939.008603572845, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 270088, "time": 8939.63504576683, "eval_episode/length": 52.0, "eval_episode/score": 0.8374999761581421, "eval_episode/reward_rate": 0.018867924528301886}
{"step": 270088, "time": 8940.873079776764, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 270088, "time": 8941.560429573059, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 270088, "time": 8942.997306346893, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 270088, "time": 8943.266726970673, "eval_episode/length": 60.0, "eval_episode/score": 0.8125, "eval_episode/reward_rate": 0.01639344262295082}
{"step": 270088, "time": 8944.063820123672, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 270088, "time": 8944.525884866714, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8944.533092975616, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8944.540273666382, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8944.549390077591, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8944.55743265152, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270120, "time": 8945.571369886398, "episode/length": 172.0, "episode/score": 0.5193178277584707, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.05681782261291346}
{"step": 270272, "time": 8950.578924894333, "episode/length": 288.0, "episode/score": 0.05067575875489183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05067575875489183}
{"step": 270400, "time": 8955.074561595917, "episode/length": 288.0, "episode/score": 0.04765086161020804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04765086161020804}
{"step": 270600, "time": 8961.113290786743, "episode/length": 288.0, "episode/score": 0.04397007666341324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04397007666341324}
{"step": 270632, "time": 8962.119295835495, "episode/length": 28.0, "episode/score": 0.9294335075476283, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.016933484520677666}
{"step": 271048, "time": 8975.248786449432, "episode/length": 288.0, "episode/score": 0.05670658793982852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05670658793982852}
{"step": 271136, "time": 8978.233838796616, "episode/length": 288.0, "episode/score": 0.054753272597764635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054753272597764635}
{"step": 271256, "time": 8981.806272268295, "episode/length": 81.0, "episode/score": 0.7841523253217701, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03727731390142708}
{"step": 271400, "time": 8986.341622591019, "episode/length": 95.0, "episode/score": 0.734591697366227, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03146666797135822}
{"step": 271776, "time": 8998.409163951874, "episode/length": 79.0, "episode/score": 0.7864705085892183, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.03334546803012017}
{"step": 272016, "time": 9006.104356050491, "episode/length": 288.0, "episode/score": 0.014601225126057216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014601225126057216}
{"step": 272016, "time": 9006.114059448242, "episode/length": 288.0, "episode/score": 0.027888287056725858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027888287056725858}
{"step": 272432, "time": 9019.178937196732, "episode/length": 288.0, "episode/score": 0.043823552074627514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043823552074627514}
{"step": 272584, "time": 9023.732968568802, "episode/length": 288.0, "episode/score": 0.055773795172285645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055773795172285645}
{"step": 272936, "time": 9034.970274686813, "episode/length": 144.0, "episode/score": 0.5697628959036365, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.019762884797614788}
{"step": 273360, "time": 9048.549954652786, "episode/length": 288.0, "episode/score": 0.041209322183306085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041209322183306085}
{"step": 273432, "time": 9050.600746631622, "episode/length": 124.0, "episode/score": 0.6466144951752995, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.03411446893528591}
{"step": 273568, "time": 9055.12586259842, "episode/length": 288.0, "episode/score": 0.062328754817940535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062328754817940535}
{"step": 273712, "time": 9059.821890354156, "episode/length": 288.0, "episode/score": 0.0348584612038394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0348584612038394}
{"step": 274200, "time": 9074.967262506485, "episode/length": 95.0, "episode/score": 0.7393365658771813, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.03621153648231257}
{"step": 274328, "time": 9079.063590765, "episode/length": 288.0, "episode/score": 0.04238062645163154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04238062645163154}
{"step": 274328, "time": 9079.084142923355, "episode/length": 288.0, "episode/score": 0.04280350948403111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04280350948403111}
{"step": 274856, "time": 9095.962330818176, "episode/length": 65.0, "episode/score": 0.8123731168291215, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.015498136968972176}
{"step": 274896, "time": 9097.443143844604, "episode/length": 288.0, "episode/score": 0.01110766786109707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01110766786109707}
{"step": 275248, "time": 9108.526208639145, "episode/length": 288.0, "episode/score": 0.023686966440948254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023686966440948254}
{"step": 275616, "time": 9120.202667474747, "episode/length": 89.0, "episode/score": 0.7501989241218325, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.028323930332589953}
{"step": 275672, "time": 9121.76724600792, "episode/length": 288.0, "episode/score": 0.04010825407186758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04010825407186758}
{"step": 275880, "time": 9128.338047027588, "episode/length": 288.0, "episode/score": 0.04200571837850475, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04200571837850475}
{"step": 275960, "time": 9130.880328893661, "episode/length": 137.0, "episode/score": 0.6017036348935676, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.029828629340556745}
{"step": 276024, "time": 9132.889039039612, "episode/length": 288.0, "episode/score": 0.016118608144495283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016118608144495283}
{"step": 276048, "time": 9133.871103525162, "episode/length": 53.0, "episode/score": 0.8400929663854413, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.0057179576484713834}
{"step": 276256, "time": 9140.48939538002, "episode/length": 25.0, "episode/score": 0.9259041494880762, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.004029172596517583}
{"step": 276496, "time": 9148.07240819931, "episode/length": 66.0, "episode/score": 0.8118943658193984, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.01814434834545864}
{"step": 276512, "time": 9148.59616613388, "episode/length": 288.0, "episode/score": 0.051022583374617625, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051022583374617625}
{"step": 276640, "time": 9152.724083423615, "episode/length": 288.0, "episode/score": 0.04978092158540903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04978092158540903}
{"step": 276792, "time": 9157.296951055527, "episode/length": 36.0, "episode/score": 0.8974715455291857, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.00997154927193833}
{"step": 277104, "time": 9167.376912355423, "episode/length": 57.0, "episode/score": 0.837678629856839, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.015803676807138345}
{"step": 277392, "time": 9176.48759508133, "episode/length": 109.0, "episode/score": 0.698283369593014, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.03890837277697301}
{"step": 277560, "time": 9181.742483377457, "episode/length": 288.0, "episode/score": 0.03074555792187539, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03074555792187539}
{"step": 277776, "time": 9188.818199396133, "episode/length": 26.0, "episode/score": 0.9320831437365769, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.01333314849796352}
{"step": 277832, "time": 9190.385693311691, "episode/length": 90.0, "episode/score": 0.7422315444993046, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.023481562630990993}
{"step": 277984, "time": 9195.500558137894, "episode/length": 288.0, "episode/score": 0.03877080617564843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03877080617564843}
{"step": 278112, "time": 9199.588569402695, "episode/length": 41.0, "episode/score": 0.8844272824671862, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.012552290299026936}
{"step": 278192, "time": 9202.130836725235, "episode/length": 288.0, "episode/score": 0.03226396035285006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03226396035285006}
{"step": 278216, "time": 9202.669800519943, "episode/length": 102.0, "episode/score": 0.7161938821960234, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.034943932260432575}
{"step": 278336, "time": 9206.71427154541, "episode/length": 288.0, "episode/score": 0.028158119750230526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028158119750230526}
{"step": 278392, "time": 9208.31683063507, "episode/length": 34.0, "episode/score": 0.9083465734925653, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.014596571641561695}
{"step": 278536, "time": 9213.30302643776, "episode/length": 39.0, "episode/score": 0.8894563070622894, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.011331267027060221}
{"step": 278568, "time": 9214.529350280762, "episode/length": 288.0, "episode/score": 0.030586373750452367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030586373750452367}
{"step": 278576, "time": 9215.004780769348, "episode/length": 73.0, "episode/score": 0.794980377014781, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.0231053703150792}
{"step": 279104, "time": 9231.540995121002, "episode/length": 288.0, "episode/score": 0.03914672904397776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03914672904397776}
{"step": 279289, "time": 9238.122769355774, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.411795660621762, "train/action_min": 0.0, "train/action_std": 1.5015856379672035, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002748229074318425, "train/actor_opt_grad_steps": 16390.0, "train/actor_opt_loss": 12.057655686020388, "train/adv_mag": 0.02066939243072055, "train/adv_max": 0.02006550125507493, "train/adv_mean": 0.0034888911248467333, "train/adv_min": -0.007419773720089018, "train/adv_std": 0.003542818838411971, "train/cont_avg": 0.9963467454663213, "train/cont_loss_mean": 0.02390915539159097, "train/cont_loss_std": 0.32440862738662474, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.547669103805055, "train/cont_pos_acc": 0.9999999820877233, "train/cont_pos_loss": 0.0036177590448370715, "train/cont_pred": 0.996387328199772, "train/cont_rate": 0.9963467454663213, "train/dyn_loss_mean": 1.0000041099409982, "train/dyn_loss_std": 0.000118772818312143, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.29062882446746674, "train/extr_critic_critic_opt_grad_steps": 16390.0, "train/extr_critic_critic_opt_loss": 11308.29665236399, "train/extr_critic_mag": 0.2825047253327049, "train/extr_critic_max": 0.2825047253327049, "train/extr_critic_mean": 0.27591231009811934, "train/extr_critic_min": 0.2686680394750803, "train/extr_critic_std": 0.0025112368139303216, "train/extr_return_normed_mag": 0.03376493413831286, "train/extr_return_normed_max": 0.033712344466095764, "train/extr_return_normed_mean": 0.0136835508201141, "train/extr_return_normed_min": 0.0025956124221722695, "train/extr_return_normed_std": 0.004412091635722532, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.2994299589661119, "train/extr_return_raw_max": 0.2994299589661119, "train/extr_return_raw_mean": 0.27940118058049, "train/extr_return_raw_min": 0.2683132269221884, "train/extr_return_raw_std": 0.004412091632706591, "train/extr_reward_mag": 0.013522140720347667, "train/extr_reward_max": 0.013522140720347667, "train/extr_reward_mean": 0.0012568078983099793, "train/extr_reward_min": 1.0749836659802056e-05, "train/extr_reward_std": 0.002430747337325674, "train/image_loss_mean": 0.16974414888904502, "train/image_loss_std": 0.10736332436145278, "train/model_loss_mean": 0.8045870297313354, "train/model_loss_std": 0.3887849298011454, "train/model_opt_grad_norm": 35.333902966790866, "train/model_opt_grad_steps": 16373.512953367876, "train/model_opt_loss": 2095.369840789953, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2603.626943005181, "train/policy_entropy_mag": 1.6685727198506883, "train/policy_entropy_max": 1.6685727198506883, "train/policy_entropy_mean": 0.5664267187909141, "train/policy_entropy_min": 0.06607012280837242, "train/policy_entropy_std": 0.3469343392342483, "train/policy_logprob_mag": 6.537939081537909, "train/policy_logprob_max": -0.008823709036440738, "train/policy_logprob_mean": -0.5674413657250182, "train/policy_logprob_min": -6.537939081537909, "train/policy_logprob_std": 0.9298725177587005, "train/policy_randomness_mag": 0.8574768079377209, "train/policy_randomness_max": 0.8574768079377209, "train/policy_randomness_mean": 0.2910857656150284, "train/policy_randomness_min": 0.03395332872790376, "train/policy_randomness_std": 0.17828899197319012, "train/post_ent_mag": 56.78732329452594, "train/post_ent_max": 56.78732329452594, "train/post_ent_mean": 56.31511292927006, "train/post_ent_min": 55.83629210872353, "train/post_ent_std": 0.16241687613447714, "train/prior_ent_mag": 59.03901887804733, "train/prior_ent_max": 59.03901887804733, "train/prior_ent_mean": 56.632907491891494, "train/prior_ent_min": 54.596261671787715, "train/prior_ent_std": 0.8365286347779586, "train/rep_loss_mean": 1.0000041099409982, "train/rep_loss_std": 0.000118772818312143, "train/reward_avg": 0.0003701562634633053, "train/reward_loss_mean": 0.010931234413497344, "train/reward_loss_std": 0.07595293381169362, "train/reward_max_data": 0.1669133492815429, "train/reward_max_pred": 0.008058953779349055, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008686047645739324, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.572100779105877, "train/reward_pred": 0.0003161388744933077, "train/reward_rate": 0.00034407383419689117, "train_stats/mean_log_entropy": 0.5230998308570297, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02090517058968544, "report/cont_loss_std": 0.32855933904647827, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.080437660217285, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0031004741322249174, "report/cont_pred": 0.9969093799591064, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.14889395236968994, "report/image_loss_std": 0.11468800902366638, "report/model_loss_mean": 0.7774409055709839, "report/model_loss_std": 0.34470757842063904, "report/post_ent_mag": 53.48137664794922, "report/post_ent_max": 53.48137664794922, "report/post_ent_mean": 52.97114181518555, "report/post_ent_min": 52.55002212524414, "report/post_ent_std": 0.16458721458911896, "report/prior_ent_mag": 56.35693359375, "report/prior_ent_max": 56.35693359375, "report/prior_ent_mean": 53.910240173339844, "report/prior_ent_min": 52.168460845947266, "report/prior_ent_std": 0.6978251934051514, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015853412332944572, "report/reward_loss_mean": 0.00764174060896039, "report/reward_loss_std": 0.013208956457674503, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00704646110534668, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00764174060896039, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0003464099718257785, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.02081490308046341, "eval/cont_loss_std": 0.34097224473953247, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.3091349601745605, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.002337958663702011, "eval/cont_pred": 0.9976668357849121, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.18911030888557434, "eval/image_loss_std": 0.1007130816578865, "eval/model_loss_mean": 0.8109180927276611, "eval/model_loss_std": 0.3581111431121826, "eval/post_ent_mag": 53.446502685546875, "eval/post_ent_max": 53.446502685546875, "eval/post_ent_mean": 52.99562072753906, "eval/post_ent_min": 52.554168701171875, "eval/post_ent_std": 0.16022492945194244, "eval/prior_ent_mag": 56.18037033081055, "eval/prior_ent_max": 56.18037033081055, "eval/prior_ent_mean": 54.04735565185547, "eval/prior_ent_min": 52.19086456298828, "eval/prior_ent_std": 0.7697240710258484, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0009929053485393524, "eval/reward_loss_std": 0.0012923030881211162, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006637454032897949, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0009929053485393524, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00017722032498568296, "eval/reward_rate": 0.0, "replay/size": 278785.0, "replay/inserts": 30960.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.2574654832982893e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.661112028807016e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65792.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0726429874371767e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0006806850433, "timer/env.step_count": 3870.0, "timer/env.step_total": 36.74788045883179, "timer/env.step_frac": 0.03674785544511621, "timer/env.step_avg": 0.009495576345951367, "timer/env.step_min": 0.007742881774902344, "timer/env.step_max": 0.0357666015625, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.769351482391357, "timer/replay._sample_frac": 0.01576934074843697, "timer/replay._sample_avg": 0.0005093459781134159, "timer/replay._sample_min": 0.00038313865661621094, "timer/replay._sample_max": 0.011281013488769531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4737.0, "timer/agent.policy_total": 48.00640869140625, "timer/agent.policy_frac": 0.048006376014184116, "timer/agent.policy_avg": 0.010134348467681286, "timer/agent.policy_min": 0.008776426315307617, "timer/agent.policy_max": 0.08138036727905273, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.2191603183746338, "timer/dataset_train_frac": 0.00021916016919558453, "timer/dataset_train_avg": 0.00011326114644683916, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.00046634674072265625, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 863.6857776641846, "timer/agent.train_frac": 0.8636851897665937, "timer/agent.train_avg": 0.4463492391029378, "timer/agent.train_min": 0.4345583915710449, "timer/agent.train_max": 1.4003839492797852, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.468839168548584, "timer/agent.report_frac": 0.00046883884941699146, "timer/agent.report_avg": 0.234419584274292, "timer/agent.report_min": 0.22434449195861816, "timer/agent.report_max": 0.24449467658996582, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.123281260259629e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 30.959457473725244}
{"step": 279488, "time": 9244.545361757278, "episode/length": 118.0, "episode/score": 0.6745592399070688, "episode/reward_rate": 0.008403361344537815, "episode/intrinsic_return": 0.04330918742704171}
{"step": 279848, "time": 9255.679751873016, "episode/length": 92.0, "episode/score": 0.7293616518391559, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.01686164628614506}
{"step": 280072, "time": 9263.462237358093, "eval_episode/length": 40.0, "eval_episode/score": 0.875, "eval_episode/reward_rate": 0.024390243902439025}
{"step": 280072, "time": 9263.629926204681, "eval_episode/length": 49.0, "eval_episode/score": 0.846875011920929, "eval_episode/reward_rate": 0.02}
{"step": 280072, "time": 9263.927891731262, "eval_episode/length": 65.0, "eval_episode/score": 0.796875, "eval_episode/reward_rate": 0.015151515151515152}
{"step": 280072, "time": 9264.271385192871, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 280072, "time": 9264.780093669891, "eval_episode/length": 112.0, "eval_episode/score": 0.6499999761581421, "eval_episode/reward_rate": 0.008849557522123894}
{"step": 280072, "time": 9265.519743919373, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 280072, "time": 9266.385244607925, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 280072, "time": 9267.901030302048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9267.909442901611, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9267.91665482521, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280144, "time": 9270.50251030922, "episode/length": 288.0, "episode/score": 0.017901612046642867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017901612046642867}
{"step": 280504, "time": 9281.597979068756, "episode/length": 288.0, "episode/score": 0.053834170153379546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053834170153379546}
{"step": 280648, "time": 9286.156533956528, "episode/length": 288.0, "episode/score": 0.046644608990050074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046644608990050074}
{"step": 280704, "time": 9288.150069713593, "episode/length": 288.0, "episode/score": 0.047729334569424964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047729334569424964}
{"step": 280880, "time": 9293.667225122452, "episode/length": 288.0, "episode/score": 0.03706982918973267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03706982918973267}
{"step": 280888, "time": 9293.705513715744, "episode/length": 288.0, "episode/score": 0.03246828980886107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03246828980886107}
{"step": 281704, "time": 9319.66576886177, "episode/length": 101.0, "episode/score": 0.708743298134209, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.024368281416968784}
{"step": 281800, "time": 9322.680067300797, "episode/length": 288.0, "episode/score": 0.04942981683350922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04942981683350922}
{"step": 281912, "time": 9326.19417667389, "episode/length": 128.0, "episode/score": 0.6354491558354312, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.0354491328084805}
{"step": 282160, "time": 9334.26678442955, "episode/length": 288.0, "episode/score": 0.024772099983124463, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024772099983124463}
{"step": 282320, "time": 9339.27070260048, "episode/length": 76.0, "episode/score": 0.79963516649741, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.037135155077066884}
{"step": 282456, "time": 9343.347790956497, "episode/length": 288.0, "episode/score": 0.02215181149460932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02215181149460932}
{"step": 282816, "time": 9354.86226272583, "episode/length": 288.0, "episode/score": 0.026887597263794305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026887597263794305}
{"step": 282960, "time": 9359.461695671082, "episode/length": 288.0, "episode/score": 0.061224680069813076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061224680069813076}
{"step": 283016, "time": 9361.032343387604, "episode/length": 288.0, "episode/score": 0.025855952279584926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025855952279584926}
{"step": 283096, "time": 9363.55703163147, "episode/length": 96.0, "episode/score": 0.754390774202875, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.054390762782531965}
{"step": 283472, "time": 9375.599421024323, "episode/length": 126.0, "episode/score": 0.6431055024249872, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.03685548570774699}
{"step": 283824, "time": 9386.696653366089, "episode/length": 43.0, "episode/score": 0.8837654697534845, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.018140431592541972}
{"step": 283920, "time": 9389.820986032486, "episode/length": 264.0, "episode/score": 0.23742478020824365, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.062424784352629104}
{"step": 284224, "time": 9399.342917919159, "episode/length": 288.0, "episode/score": 0.08889903038391367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08889903038391367}
{"step": 284472, "time": 9406.889050722122, "episode/length": 288.0, "episode/score": 0.04133010454620489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04133010454620489}
{"step": 284568, "time": 9409.89094376564, "episode/length": 80.0, "episode/score": 0.7952134404163189, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.04521341177814975}
{"step": 284664, "time": 9412.93538737297, "episode/length": 104.0, "episode/score": 0.7101392094168659, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.035139183176852384}
{"step": 285128, "time": 9427.581934213638, "episode/length": 288.0, "episode/score": 0.033987345079367515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033987345079367515}
{"step": 285272, "time": 9432.115473985672, "episode/length": 288.0, "episode/score": 0.055181256175046656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055181256175046656}
{"step": 285328, "time": 9434.104656934738, "episode/length": 288.0, "episode/score": 0.03599783495894826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03599783495894826}
{"step": 285408, "time": 9436.625173091888, "episode/length": 288.0, "episode/score": 0.06635720585541094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06635720585541094}
{"step": 285648, "time": 9444.121879339218, "episode/length": 64.0, "episode/score": 0.8123888266993617, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.012388786140263619}
{"step": 285848, "time": 9450.22730922699, "episode/length": 71.0, "episode/score": 0.8026793832918884, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.024554365817948565}
{"step": 285984, "time": 9454.698191404343, "episode/length": 41.0, "episode/score": 0.8927394319723589, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.02086444470819515}
{"step": 286536, "time": 9471.748754739761, "episode/length": 288.0, "episode/score": 0.05477651421745122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05477651421745122}
{"step": 286760, "time": 9479.319588184357, "episode/length": 27.0, "episode/score": 0.9302225624140874, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.014597587070852569}
{"step": 286784, "time": 9480.291287660599, "episode/length": 288.0, "episode/score": 0.052411745631957274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052411745631957274}
{"step": 286880, "time": 9483.303009033203, "episode/length": 288.0, "episode/score": 0.044703766048087346, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044703766048087346}
{"step": 286976, "time": 9486.28886437416, "episode/length": 288.0, "episode/score": 0.05435154936310482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05435154936310482}
{"step": 287152, "time": 9491.857600450516, "episode/length": 33.0, "episode/score": 0.9075838892924821, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.010708836055755455}
{"step": 287504, "time": 9502.953794717789, "episode/length": 65.0, "episode/score": 0.8233314425719982, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.02645642825291361}
{"step": 287640, "time": 9506.985072612762, "episode/length": 288.0, "episode/score": 0.028607782009657967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028607782009657967}
{"step": 287720, "time": 9509.621971845627, "episode/length": 288.0, "episode/score": 0.05697739173433547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05697739173433547}
{"step": 288160, "time": 9523.711260080338, "episode/length": 288.0, "episode/score": 0.049852219406830045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049852219406830045}
{"step": 288200, "time": 9524.751186847687, "episode/length": 69.0, "episode/score": 0.8034696334955242, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.019094592179726533}
{"step": 288232, "time": 9525.76011967659, "episode/length": 63.0, "episode/score": 0.8262540638261271, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.023129031806092826}
{"step": 288296, "time": 9527.785450696945, "episode/length": 288.0, "episode/score": 0.04461911160933596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04461911160933596}
{"step": 288440, "time": 9532.293347120285, "episode/length": 17.0, "episode/score": 0.9526144472081342, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.005739491189842738}
{"step": 288672, "time": 9539.88340806961, "episode/length": 54.0, "episode/score": 0.8483445935220288, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.017094601740950566}
{"step": 289000, "time": 9550.012061357498, "episode/length": 104.0, "episode/score": 0.7039934848932035, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.02899347319055323}
{"step": 289072, "time": 9552.549235582352, "episode/length": 288.0, "episode/score": 0.08384651123213871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08384651123213871}
{"step": 289096, "time": 9553.092915058136, "episode/length": 288.0, "episode/score": 0.012465886694769779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012465886694769779}
{"step": 289464, "time": 9564.695905447006, "episode/length": 288.0, "episode/score": 0.029059705132453928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029059705132453928}
{"step": 289480, "time": 9565.198682308197, "episode/length": 129.0, "episode/score": 0.6404110827961631, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.04353606371569185}
{"step": 289680, "time": 9571.720372915268, "episode/length": 84.0, "episode/score": 0.7756236233226446, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.03812363154156628}
{"step": 289816, "time": 9575.740863800049, "episode/length": 288.0, "episode/score": 0.03352000136112565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03352000136112565}
{"step": 290056, "time": 9583.716412782669, "eval_episode/length": 24.0, "eval_episode/score": 0.925000011920929, "eval_episode/reward_rate": 0.04}
{"step": 290056, "time": 9584.599632263184, "eval_episode/length": 74.0, "eval_episode/score": 0.768750011920929, "eval_episode/reward_rate": 0.013333333333333334}
{"step": 290056, "time": 9584.750579357147, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 290056, "time": 9585.217646837234, "eval_episode/length": 84.0, "eval_episode/score": 0.737500011920929, "eval_episode/reward_rate": 0.011764705882352941}
{"step": 290056, "time": 9585.85023856163, "eval_episode/length": 62.0, "eval_episode/score": 0.8062499761581421, "eval_episode/reward_rate": 0.015873015873015872}
{"step": 290056, "time": 9587.119614124298, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 290056, "time": 9587.22188091278, "eval_episode/length": 149.0, "eval_episode/score": 0.534375011920929, "eval_episode/reward_rate": 0.006666666666666667}
{"step": 290056, "time": 9587.534521102905, "eval_episode/length": 241.0, "eval_episode/score": 0.24687500298023224, "eval_episode/reward_rate": 0.004132231404958678}
{"step": 290064, "time": 9588.011837482452, "episode/length": 232.0, "episode/score": 0.3156838920584164, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.04068387177886734}
{"step": 290208, "time": 9592.51446723938, "episode/length": 48.0, "episode/score": 0.8600162704223067, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.01001624679872748}
{"step": 290232, "time": 9593.053179979324, "episode/length": 194.0, "episode/score": 0.447832165742966, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.054082147128156066}
{"step": 290568, "time": 9603.665449857712, "episode/length": 62.0, "episode/score": 0.8306108550480076, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.024360871730323197}
{"step": 290784, "time": 9610.626007795334, "episode/length": 71.0, "episode/score": 0.7847195788075396, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.006594602806558214}
{"step": 290896, "time": 9614.153821468353, "episode/length": 82.0, "episode/score": 0.7768512676647674, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.033101309638311704}
{"step": 291000, "time": 9617.21770453453, "episode/length": 53.0, "episode/score": 0.8551438567063201, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.020768833679369436}
{"step": 291376, "time": 9629.29521226883, "episode/length": 287.0, "episode/score": 0.136600045481714, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.03347504737928375}
{"step": 291408, "time": 9630.306685686111, "episode/length": 288.0, "episode/score": 0.04048115922881834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04048115922881834}
{"step": 291472, "time": 9632.321034193039, "episode/length": 11.0, "episode/score": 0.9720217526955821, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.0063967605274228845}
{"step": 291632, "time": 9637.326699733734, "episode/length": 268.0, "episode/score": 0.22607202615654387, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.06357203883999318}
{"step": 291776, "time": 9641.811141490936, "episode/length": 288.0, "episode/score": 0.05443237870690609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05443237870690609}
{"step": 291992, "time": 9648.349021196365, "episode/length": 288.0, "episode/score": 0.0552281025113075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0552281025113075}
{"step": 292720, "time": 9671.446913957596, "episode/length": 241.0, "episode/score": 0.2851846973239276, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.03830970106668019}
{"step": 293184, "time": 9685.944866895676, "episode/length": 272.0, "episode/score": 0.20443569458251432, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.0544356950831002}
{"step": 293208, "time": 9686.479112148285, "episode/length": 288.0, "episode/score": 0.04891032217420843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04891032217420843}
{"step": 293376, "time": 9692.072389602661, "episode/length": 172.0, "episode/score": 0.49107688344781764, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.028576867824881447}
{"step": 293720, "time": 9702.626145601273, "episode/length": 288.0, "episode/score": 0.054641522140627785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054641522140627785}
{"step": 293784, "time": 9704.61934041977, "episode/length": 288.0, "episode/score": 0.05010663809605376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05010663809605376}
{"step": 293784, "time": 9704.626318216324, "episode/length": 74.0, "episode/score": 0.7893824741843218, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.02063246248167161}
{"step": 293944, "time": 9709.642440795898, "episode/length": 288.0, "episode/score": 0.051921692432131294, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051921692432131294}
{"step": 294088, "time": 9714.166983366013, "episode/length": 288.0, "episode/score": 0.06310122253898953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06310122253898953}
{"step": 294448, "time": 9725.733517408371, "episode/length": 215.0, "episode/score": 0.4004540698354617, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.07232907629651208}
{"step": 294712, "time": 9733.794408798218, "episode/length": 187.0, "episode/score": 0.4684896451798295, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.052864627548729004}
{"step": 294848, "time": 9738.285796642303, "episode/length": 132.0, "episode/score": 0.6146676539247551, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.02716770087505438}
{"step": 295528, "time": 9759.970832109451, "episode/length": 268.0, "episode/score": 0.22984546694655705, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.06734547312530026}
{"step": 295704, "time": 9765.487120389938, "episode/length": 219.0, "episode/score": 0.3550895032601318, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.03946449174665645}
{"step": 295936, "time": 9772.976016998291, "episode/length": 276.0, "episode/score": 0.20852481697448866, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.07102481117118487}
{"step": 296096, "time": 9778.002987146378, "episode/length": 288.0, "episode/score": 0.041670525671293035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041670525671293035}
{"step": 296400, "time": 9787.711725473404, "episode/length": 288.0, "episode/score": 0.07620451313130161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07620451313130161}
{"step": 296632, "time": 9794.802734136581, "episode/length": 86.0, "episode/score": 0.7567768376368633, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.025526872666233658}
{"step": 296760, "time": 9798.81782412529, "episode/length": 288.0, "episode/score": 0.07052538347994641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07052538347994641}
{"step": 297024, "time": 9807.293669700623, "episode/length": 288.0, "episode/score": 0.05926620152376927, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05926620152376927}
{"step": 297160, "time": 9811.442010879517, "episode/length": 288.0, "episode/score": 0.054576336797794056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054576336797794056}
{"step": 297840, "time": 9832.957403421402, "episode/length": 288.0, "episode/score": 0.03560611671304059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03560611671304059}
{"step": 298016, "time": 9838.504511594772, "episode/length": 288.0, "episode/score": 0.04872323115395716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04872323115395716}
{"step": 298408, "time": 9850.676795959473, "episode/length": 288.0, "episode/score": 0.014682015474761556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014682015474761556}
{"step": 298712, "time": 9860.25796866417, "episode/length": 288.0, "episode/score": 0.0396780434500954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0396780434500954}
{"step": 298944, "time": 9867.733028650284, "episode/length": 288.0, "episode/score": 0.02820015072271076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02820015072271076}
{"step": 299072, "time": 9871.893783807755, "episode/length": 288.0, "episode/score": 0.030454303989870368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030454303989870368}
{"step": 299336, "time": 9880.038716077805, "episode/length": 288.0, "episode/score": 0.015029110989189576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015029110989189576}
{"step": 299472, "time": 9884.556600093842, "episode/length": 288.0, "episode/score": 0.020483836160650526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020483836160650526}
{"step": 299528, "time": 9886.113003253937, "episode/length": 72.0, "episode/score": 0.7850092340018477, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.010009267913630993}
{"step": 300040, "time": 9902.446887016296, "eval_episode/length": 7.0, "eval_episode/score": 0.9781249761581421, "eval_episode/reward_rate": 0.125}
{"step": 300040, "time": 9908.05249786377, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9908.061085700989, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9908.06799697876, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9908.074528932571, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9908.083094596863, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9908.090946674347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9908.098249673843, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300152, "time": 9911.63939833641, "episode/length": 288.0, "episode/score": 0.01119697148132559, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01119697148132559}
{"step": 300328, "time": 9917.21158504486, "episode/length": 288.0, "episode/score": 0.02207152636449905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02207152636449905}
{"step": 300720, "time": 9929.886657714844, "episode/length": 288.0, "episode/score": 0.010998112899670787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010998112899670787}
{"step": 301024, "time": 9939.48744392395, "episode/length": 288.0, "episode/score": 0.01807463501737061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01807463501737061}
{"step": 301144, "time": 9943.074217319489, "episode/length": 14.0, "episode/score": 0.9618544842548431, "episode/reward_rate": 0.06666666666666667, "episode/intrinsic_return": 0.005604484412003785}
{"step": 301384, "time": 9950.596755981445, "episode/length": 288.0, "episode/score": 0.004844243754234867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.004844243754234867}
{"step": 301648, "time": 9959.276546478271, "episode/length": 288.0, "episode/score": 0.014901573332522844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014901573332522844}
{"step": 301784, "time": 9963.389735460281, "episode/length": 288.0, "episode/score": 0.012834374156014405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012834374156014405}
{"step": 301840, "time": 9965.38700723648, "episode/length": 288.0, "episode/score": 0.015227832946635544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015227832946635544}
{"step": 302464, "time": 9984.96630358696, "episode/length": 288.0, "episode/score": 0.008528402221898546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008528402221898546}
{"step": 302640, "time": 9990.622060537338, "episode/length": 288.0, "episode/score": 0.014291853715093339, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014291853715093339}
{"step": 303032, "time": 10002.72466635704, "episode/length": 288.0, "episode/score": 0.006582888487173477, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006582888487173477}
{"step": 303456, "time": 10016.692623615265, "episode/length": 288.0, "episode/score": 0.007735213435964283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007735213435964283}
{"step": 303696, "time": 10024.303496360779, "episode/length": 288.0, "episode/score": 0.008648865542241424, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008648865542241424}
{"step": 303960, "time": 10032.363005638123, "episode/length": 288.0, "episode/score": 0.0252972271418912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0252972271418912}
{"step": 304096, "time": 10036.83291053772, "episode/length": 288.0, "episode/score": 0.006238538884659306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006238538884659306}
{"step": 304152, "time": 10038.392016172409, "episode/length": 288.0, "episode/score": 0.005227070014029778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.005227070014029778}
{"step": 304688, "time": 10055.426988840103, "episode/length": 255.0, "episode/score": 0.22536450175876155, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.022239508481746384}
{"step": 304776, "time": 10057.963642835617, "episode/length": 288.0, "episode/score": 0.014433139201941003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014433139201941003}
{"step": 305344, "time": 10075.880256175995, "episode/length": 288.0, "episode/score": 0.012505993343253863, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012505993343253863}
{"step": 305768, "time": 10089.015633821487, "episode/length": 288.0, "episode/score": 0.0031471755170713323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0031471755170713323}
{"step": 306008, "time": 10096.557184457779, "episode/length": 288.0, "episode/score": 0.0144440806170536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0144440806170536}
{"step": 306264, "time": 10104.606482028961, "episode/length": 196.0, "episode/score": 0.40498317192096067, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.017483169522805042}
{"step": 306272, "time": 10105.081869363785, "episode/length": 288.0, "episode/score": 0.013013607629090984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013013607629090984}
{"step": 306408, "time": 10109.191103696823, "episode/length": 288.0, "episode/score": 0.008145297063080648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008145297063080648}
{"step": 306464, "time": 10111.155200242996, "episode/length": 288.0, "episode/score": 0.018285830187764418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018285830187764418}
{"step": 306800, "time": 10121.644546031952, "episode/length": 181.0, "episode/score": 0.46290458612733687, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.02852958372918124}
{"step": 307088, "time": 10130.656378746033, "episode/length": 288.0, "episode/score": 0.022603549214920804, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022603549214920804}
{"step": 307536, "time": 10144.79709815979, "episode/length": 91.0, "episode/score": 0.7354266193819967, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.019801632117832924}
{"step": 307544, "time": 10144.834335565567, "episode/length": 141.0, "episode/score": 0.57593213301368, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.016557121593336888}
{"step": 308080, "time": 10161.861199855804, "episode/length": 288.0, "episode/score": 0.03957916430795194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03957916430795194}
{"step": 308320, "time": 10169.650171995163, "episode/length": 288.0, "episode/score": 0.030646247603741017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030646247603741017}
{"step": 308576, "time": 10177.698192596436, "episode/length": 288.0, "episode/score": 0.07192024766635541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07192024766635541}
{"step": 308584, "time": 10177.74665093422, "episode/length": 288.0, "episode/score": 0.03166411356858134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03166411356858134}
{"step": 308696, "time": 10181.254240989685, "episode/length": 76.0, "episode/score": 0.7828325666287128, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.02033257936454902}
{"step": 308776, "time": 10183.772259235382, "episode/length": 288.0, "episode/score": 0.043251409503000104, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043251409503000104}
{"step": 309072, "time": 10193.283949613571, "episode/length": 60.0, "episode/score": 0.8335498368218168, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.0210498134805448}
{"step": 309248, "time": 10198.913455963135, "episode/length": 83.0, "episode/score": 0.7608696191825857, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.020244587162551397}
{"step": 309400, "time": 10203.582561016083, "episode/length": 288.0, "episode/score": 0.02628644753701792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02628644753701792}
{"step": 309456, "time": 10205.608847379684, "episode/length": 239.0, "episode/score": 0.300980693162046, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.04785568164857068}
{"step": 309856, "time": 10218.194541692734, "episode/length": 288.0, "episode/score": 0.05628616868989411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05628616868989411}
{"step": 310024, "time": 10229.122024059296, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.130153417587, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.137732982635, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.144548416138, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.151283979416, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.15817117691, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.164548873901, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10229.171436309814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310281, "time": 10238.22764825821, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.359673568882893, "train/action_min": 0.0, "train/action_std": 1.324089018954444, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004497029974915029, "train/actor_opt_grad_steps": 18325.0, "train/actor_opt_loss": 8.311964990551939, "train/adv_mag": 0.07028615536149015, "train/adv_max": 0.055890644026785785, "train/adv_mean": 0.004946232957002408, "train/adv_min": -0.03397839846684761, "train/adv_std": 0.009084167959859845, "train/cont_avg": 0.996325306056701, "train/cont_loss_mean": 0.023238518630567286, "train/cont_loss_std": 0.31668240052753505, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.339379641676196, "train/cont_pos_acc": 0.9999999834090164, "train/cont_pos_loss": 0.003646219457672506, "train/cont_pred": 0.9963517222822327, "train/cont_rate": 0.996325306056701, "train/dyn_loss_mean": 1.0000066972270454, "train/dyn_loss_std": 0.00017830723453764373, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8973488295258781, "train/extr_critic_critic_opt_grad_steps": 18325.0, "train/extr_critic_critic_opt_loss": 7316.1319718508375, "train/extr_critic_mag": 0.40821214004890205, "train/extr_critic_max": 0.40821214004890205, "train/extr_critic_mean": 0.39960843462919454, "train/extr_critic_min": 0.386007425711327, "train/extr_critic_std": 0.0049190981488809295, "train/extr_return_normed_mag": 0.08706800255578817, "train/extr_return_normed_max": 0.07637797465029451, "train/extr_return_normed_mean": 0.020345046379307608, "train/extr_return_normed_min": -0.017933907121727148, "train/extr_return_normed_std": 0.010842207670403817, "train/extr_return_rate": 0.03952192239979847, "train/extr_return_raw_mag": 0.46058760890641165, "train/extr_return_raw_max": 0.46058760890641165, "train/extr_return_raw_mean": 0.4045546978097601, "train/extr_return_raw_min": 0.36627572713439, "train/extr_return_raw_std": 0.010842207675804528, "train/extr_reward_mag": 0.0563394015597314, "train/extr_reward_max": 0.0563394015597314, "train/extr_reward_mean": 0.0018344864386647516, "train/extr_reward_min": -0.00018296905399597797, "train/extr_reward_std": 0.005772088103466811, "train/image_loss_mean": 0.15247983904075377, "train/image_loss_std": 0.10950238000332695, "train/model_loss_mean": 0.7869994483657718, "train/model_loss_std": 0.3854972461296111, "train/model_opt_grad_norm": 32.53651021190525, "train/model_opt_grad_steps": 18307.092783505155, "train/model_opt_loss": 2854.0762379439834, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3634.020618556701, "train/policy_entropy_mag": 1.5814013321375109, "train/policy_entropy_max": 1.5814013321375109, "train/policy_entropy_mean": 0.38448812397792165, "train/policy_entropy_min": 0.0648108650498169, "train/policy_entropy_std": 0.3145578658765124, "train/policy_logprob_mag": 6.55041352006578, "train/policy_logprob_max": -0.008627535348047609, "train/policy_logprob_mean": -0.38352739165738686, "train/policy_logprob_min": -6.55041352006578, "train/policy_logprob_std": 0.8488613932403093, "train/policy_randomness_mag": 0.8126795697458011, "train/policy_randomness_max": 0.8126795697458011, "train/policy_randomness_mean": 0.197587820442067, "train/policy_randomness_min": 0.03330619809861036, "train/policy_randomness_std": 0.1616507752116808, "train/post_ent_mag": 51.23645489486223, "train/post_ent_max": 51.23645489486223, "train/post_ent_mean": 50.73903227344002, "train/post_ent_min": 50.3649755261608, "train/post_ent_std": 0.15282638947066574, "train/prior_ent_mag": 53.343291646426486, "train/prior_ent_max": 53.343291646426486, "train/prior_ent_mean": 50.98734900877648, "train/prior_ent_min": 49.138062349299794, "train/prior_ent_std": 0.7378477401954612, "train/rep_loss_mean": 1.0000066972270454, "train/rep_loss_std": 0.00017830723453764373, "train/reward_avg": 0.0004441562927728303, "train/reward_loss_mean": 0.01127704822688757, "train/reward_loss_std": 0.0813864399054923, "train/reward_max_data": 0.22093465514769106, "train/reward_max_pred": 0.017619818756260824, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.008714997677670158, "train/reward_pos_acc": 0.014285714285714285, "train/reward_pos_loss": 5.742516558510917, "train/reward_pred": 0.00039267213175015657, "train/reward_rate": 0.00044801063144329895, "train_stats/mean_log_entropy": 0.3800771389750467, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.03805513307452202, "report/cont_loss_std": 0.43238410353660583, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.100405693054199, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0032110309693962336, "report/cont_pred": 0.9967275857925415, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 1.0000174045562744, "report/dyn_loss_std": 0.00039463862776756287, "report/image_loss_mean": 0.13987138867378235, "report/image_loss_std": 0.10392952710390091, "report/model_loss_mean": 0.7959253787994385, "report/model_loss_std": 0.549781858921051, "report/post_ent_mag": 49.516571044921875, "report/post_ent_max": 49.516571044921875, "report/post_ent_mean": 49.001380920410156, "report/post_ent_min": 48.696746826171875, "report/post_ent_std": 0.14612174034118652, "report/prior_ent_mag": 50.439266204833984, "report/prior_ent_max": 50.439266204833984, "report/prior_ent_mean": 47.91404724121094, "report/prior_ent_min": 45.378055572509766, "report/prior_ent_std": 0.774482786655426, "report/rep_loss_mean": 1.0000174045562744, "report/rep_loss_std": 0.00039463862776756287, "report/reward_avg": 0.0014254713896661997, "report/reward_loss_mean": 0.017988376319408417, "report/reward_loss_std": 0.19667378067970276, "report/reward_max_data": 0.7719940543174744, "report/reward_max_pred": 0.029676437377929688, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009330357424914837, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.442234992980957, "report/reward_pred": 0.0003920861054211855, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03962051495909691, "eval/cont_loss_std": 0.4771604537963867, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.240403175354004, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00307366531342268, "eval/cont_pred": 0.9969502687454224, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0000107288360596, "eval/dyn_loss_std": 0.00034204547409899533, "eval/image_loss_mean": 0.19679811596870422, "eval/image_loss_std": 0.10660790652036667, "eval/model_loss_mean": 0.8375994563102722, "eval/model_loss_std": 0.48391643166542053, "eval/post_ent_mag": 49.51705551147461, "eval/post_ent_max": 49.51705551147461, "eval/post_ent_mean": 48.997947692871094, "eval/post_ent_min": 48.674102783203125, "eval/post_ent_std": 0.14631925523281097, "eval/prior_ent_mag": 50.439266204833984, "eval/prior_ent_max": 50.439266204833984, "eval/prior_ent_mean": 47.80562973022461, "eval/prior_ent_min": 45.61390686035156, "eval/prior_ent_std": 0.8072879314422607, "eval/rep_loss_mean": 1.0000107288360596, "eval/rep_loss_std": 0.00034204547409899533, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011743572540581226, "eval/reward_loss_std": 0.0016100580105558038, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007856488227844238, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011743572540581226, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00021731096785515547, "eval/reward_rate": 0.0, "replay/size": 309777.0, "replay/inserts": 30992.0, "replay/samples": 30992.0, "replay/insert_wait_avg": 1.2661986703040616e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.63559702123387e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74664.0, "eval_replay/inserts": 8872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1080874313203143e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0838580131531, "timer/env.step_count": 3874.0, "timer/env.step_total": 36.77015495300293, "timer/env.step_frac": 0.03676707173941741, "timer/env.step_avg": 0.009491521670883565, "timer/env.step_min": 0.007752180099487305, "timer/env.step_max": 0.03988909721374512, "timer/replay._sample_count": 30992.0, "timer/replay._sample_total": 15.70982575416565, "timer/replay._sample_frac": 0.01570850846985577, "timer/replay._sample_avg": 0.0005068993854596557, "timer/replay._sample_min": 0.00037980079650878906, "timer/replay._sample_max": 0.010641098022460938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4983.0, "timer/agent.policy_total": 50.5158576965332, "timer/agent.policy_frac": 0.05051162189228018, "timer/agent.policy_avg": 0.010137639513653061, "timer/agent.policy_min": 0.008525848388671875, "timer/agent.policy_max": 0.08577394485473633, "timer/dataset_train_count": 1937.0, "timer/dataset_train_total": 0.22059845924377441, "timer/dataset_train_frac": 0.0002205799618464326, "timer/dataset_train_avg": 0.00011388665939275912, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0005795955657958984, "timer/agent.train_count": 1937.0, "timer/agent.train_total": 859.0832080841064, "timer/agent.train_frac": 0.8590111731138528, "timer/agent.train_avg": 0.4435122395891102, "timer/agent.train_min": 0.4313681125640869, "timer/agent.train_max": 0.73061203956604, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4829132556915283, "timer/agent.report_frac": 0.00048287276294102234, "timer/agent.report_avg": 0.24145662784576416, "timer/agent.report_min": 0.23497986793518066, "timer/agent.report_max": 0.24793338775634766, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.456779518310342e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 30.988866945273287}
{"step": 310632, "time": 10249.045783042908, "episode/length": 288.0, "episode/score": 0.04493786815129397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04493786815129397}
{"step": 311008, "time": 10261.17302775383, "episode/length": 288.0, "episode/score": 0.05425022716690364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05425022716690364}
{"step": 311088, "time": 10263.671223163605, "episode/length": 288.0, "episode/score": 0.0398464200327453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0398464200327453}
{"step": 311384, "time": 10273.264986753464, "episode/length": 288.0, "episode/score": 0.04359204541037798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04359204541037798}
{"step": 311560, "time": 10278.811045408249, "episode/length": 288.0, "episode/score": 0.06544815985603236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06544815985603236}
{"step": 311712, "time": 10283.82304096222, "episode/length": 288.0, "episode/score": 0.06908214895526044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06908214895526044}
{"step": 311768, "time": 10285.36462688446, "episode/length": 288.0, "episode/score": 0.043801552960303525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043801552960303525}
{"step": 312168, "time": 10298.037916898727, "episode/length": 288.0, "episode/score": 0.07075870353548908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07075870353548908}
{"step": 312536, "time": 10309.558446645737, "episode/length": 190.0, "episode/score": 0.4217821189561164, "episode/reward_rate": 0.005235602094240838, "episode/intrinsic_return": 0.015532125417166753}
{"step": 312656, "time": 10313.593519210815, "episode/length": 195.0, "episode/score": 0.43481830466555493, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.04419330507300856}
{"step": 312944, "time": 10322.735982894897, "episode/length": 288.0, "episode/score": 0.050353876582676094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050353876582676094}
{"step": 313288, "time": 10333.309153795242, "episode/length": 215.0, "episode/score": 0.3653872825555027, "episode/reward_rate": 0.004629629629629629, "episode/intrinsic_return": 0.037262282962956306}
{"step": 313696, "time": 10346.339480400085, "episode/length": 288.0, "episode/score": 0.05380285195474244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05380285195474244}
{"step": 313840, "time": 10350.921557188034, "episode/length": 111.0, "episode/score": 0.6957267563909681, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.04260173891702834}
{"step": 314024, "time": 10356.453926563263, "episode/length": 288.0, "episode/score": 0.058650060387208214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058650060387208214}
{"step": 314080, "time": 10358.43767952919, "episode/length": 288.0, "episode/score": 0.057335578358333805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057335578358333805}
{"step": 314480, "time": 10371.09519290924, "episode/length": 288.0, "episode/score": 0.04968731870121701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04968731870121701}
{"step": 314576, "time": 10374.153214931488, "episode/length": 91.0, "episode/score": 0.7428196589163463, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.0271946909771259}
{"step": 314848, "time": 10383.009996414185, "episode/length": 288.0, "episode/score": 0.049510096585549945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049510096585549945}
{"step": 314872, "time": 10383.55105471611, "episode/length": 197.0, "episode/score": 0.4187747257322485, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.034399720586691274}
{"step": 314968, "time": 10386.588735818863, "episode/length": 288.0, "episode/score": 0.02673089692427766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02673089692427766}
{"step": 315384, "time": 10399.687717914581, "episode/length": 100.0, "episode/score": 0.7198080596095906, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.032308036268318574}
{"step": 315568, "time": 10405.67319560051, "episode/length": 86.0, "episode/score": 0.7450333866313485, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.013783390374101145}
{"step": 316008, "time": 10419.359484434128, "episode/length": 288.0, "episode/score": 0.014660441069054286, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014660441069054286}
{"step": 316280, "time": 10427.896359205246, "episode/length": 33.0, "episode/score": 0.9031760453517563, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.006301041649749095}
{"step": 316336, "time": 10429.873824357986, "episode/length": 288.0, "episode/score": 0.035292993933239813, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035292993933239813}
{"step": 316392, "time": 10431.417247056961, "episode/length": 288.0, "episode/score": 0.015384593893372767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015384593893372767}
{"step": 316792, "time": 10444.294521570206, "episode/length": 288.0, "episode/score": 0.03756672449623011, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03756672449623011}
{"step": 317160, "time": 10455.926147460938, "episode/length": 288.0, "episode/score": 0.03200951492135573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03200951492135573}
{"step": 317280, "time": 10459.919139146805, "episode/length": 288.0, "episode/score": 0.045568165859776855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045568165859776855}
{"step": 317696, "time": 10473.07034611702, "episode/length": 288.0, "episode/score": 0.03315807597618914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03315807597618914}
{"step": 317880, "time": 10478.62741112709, "episode/length": 288.0, "episode/score": 0.030067576912301774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030067576912301774}
{"step": 318592, "time": 10501.391920566559, "episode/length": 288.0, "episode/score": 0.013523643435974009, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013523643435974009}
{"step": 318648, "time": 10502.93070936203, "episode/length": 288.0, "episode/score": 0.025798860176507787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025798860176507787}
{"step": 318704, "time": 10504.923753261566, "episode/length": 288.0, "episode/score": 0.01993315686081587, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01993315686081587}
{"step": 319104, "time": 10517.465505838394, "episode/length": 288.0, "episode/score": 0.010783719549465332, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010783719549465332}
{"step": 319472, "time": 10529.162664175034, "episode/length": 288.0, "episode/score": 0.009176647225899615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.009176647225899615}
{"step": 319592, "time": 10533.23878788948, "episode/length": 288.0, "episode/score": 0.02058794876296588, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02058794876296588}
{"step": 320008, "time": 10546.275141716003, "episode/length": 288.0, "episode/score": 0.025209762934480295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025209762934480295}
{"step": 320008, "time": 10551.526415109634, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.53375530243, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.544271707535, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.554171085358, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.56357049942, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.576411485672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.583005905151, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320008, "time": 10551.589606523514, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 320192, "time": 10557.592158555984, "episode/length": 288.0, "episode/score": 0.03558012632475993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03558012632475993}
{"step": 320904, "time": 10579.713770627975, "episode/length": 288.0, "episode/score": 0.01807684844141022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01807684844141022}
{"step": 320960, "time": 10581.702358722687, "episode/length": 288.0, "episode/score": 0.018011601783342712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018011601783342712}
{"step": 321016, "time": 10583.240603923798, "episode/length": 288.0, "episode/score": 0.016756563195087892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016756563195087892}
{"step": 321416, "time": 10595.91912651062, "episode/length": 288.0, "episode/score": 0.035451544067740315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035451544067740315}
{"step": 321784, "time": 10607.485431909561, "episode/length": 288.0, "episode/score": 0.025130208242387653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025130208242387653}
{"step": 321904, "time": 10611.482665538788, "episode/length": 288.0, "episode/score": 0.03816345360493756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03816345360493756}
{"step": 322320, "time": 10624.623098134995, "episode/length": 288.0, "episode/score": 0.04125747002791513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04125747002791513}
{"step": 322504, "time": 10630.153391361237, "episode/length": 288.0, "episode/score": 0.04757926008119284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04757926008119284}
{"step": 323216, "time": 10652.83062672615, "episode/length": 288.0, "episode/score": 0.06757446630814457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06757446630814457}
{"step": 323272, "time": 10654.359326601028, "episode/length": 288.0, "episode/score": 0.07215906886472112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07215906886472112}
{"step": 323328, "time": 10656.349612236023, "episode/length": 288.0, "episode/score": 0.06999940679233418, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06999940679233418}
{"step": 323728, "time": 10668.870900154114, "episode/length": 288.0, "episode/score": 0.09414725384419853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09414725384419853}
{"step": 324096, "time": 10680.513401985168, "episode/length": 288.0, "episode/score": 0.07558710491434795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07558710491434795}
{"step": 324216, "time": 10684.059159040451, "episode/length": 288.0, "episode/score": 0.06465008017812579, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06465008017812579}
{"step": 324632, "time": 10697.1148686409, "episode/length": 288.0, "episode/score": 0.06841526078210336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06841526078210336}
{"step": 324816, "time": 10703.088419914246, "episode/length": 288.0, "episode/score": 0.0675453614652497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0675453614652497}
{"step": 325528, "time": 10725.263567209244, "episode/length": 288.0, "episode/score": 0.06221428127867057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06221428127867057}
{"step": 325584, "time": 10727.248347997665, "episode/length": 288.0, "episode/score": 0.04200464876203114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04200464876203114}
{"step": 325640, "time": 10728.779465436935, "episode/length": 288.0, "episode/score": 0.059708951259835885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059708951259835885}
{"step": 326040, "time": 10741.45515537262, "episode/length": 288.0, "episode/score": 0.0472516080569676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0472516080569676}
{"step": 326408, "time": 10752.954464197159, "episode/length": 288.0, "episode/score": 0.048281875928410045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048281875928410045}
{"step": 326528, "time": 10756.941913604736, "episode/length": 288.0, "episode/score": 0.03932575738105015, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03932575738105015}
{"step": 326944, "time": 10770.068019628525, "episode/length": 288.0, "episode/score": 0.039804543412572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039804543412572}
{"step": 327128, "time": 10775.615508794785, "episode/length": 288.0, "episode/score": 0.04043843106910572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04043843106910572}
{"step": 327840, "time": 10798.807960033417, "episode/length": 288.0, "episode/score": 0.03987637986477921, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03987637986477921}
{"step": 327896, "time": 10800.354842424393, "episode/length": 288.0, "episode/score": 0.0382169749593686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0382169749593686}
{"step": 327952, "time": 10802.360634565353, "episode/length": 288.0, "episode/score": 0.02759499052206138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02759499052206138}
{"step": 328352, "time": 10814.910425662994, "episode/length": 288.0, "episode/score": 0.03299913942680632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03299913942680632}
{"step": 328720, "time": 10826.467413663864, "episode/length": 288.0, "episode/score": 0.034859765704140955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034859765704140955}
{"step": 328840, "time": 10830.155279874802, "episode/length": 288.0, "episode/score": 0.024626572731335727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024626572731335727}
{"step": 329256, "time": 10843.257526397705, "episode/length": 288.0, "episode/score": 0.03616623135809505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03616623135809505}
{"step": 329440, "time": 10849.247742652893, "episode/length": 288.0, "episode/score": 0.026400973856482324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026400973856482324}
{"step": 330096, "time": 10875.063179731369, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.080099582672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.09244632721, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.099514722824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.106538534164, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.11474275589, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.125219345093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10875.132343769073, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330152, "time": 10876.668177127838, "episode/length": 288.0, "episode/score": 0.02071421874111934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02071421874111934}
{"step": 330208, "time": 10878.66264295578, "episode/length": 288.0, "episode/score": 0.037335625507211034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037335625507211034}
{"step": 330264, "time": 10880.190631866455, "episode/length": 288.0, "episode/score": 0.017501273917389426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017501273917389426}
{"step": 330664, "time": 10892.789269924164, "episode/length": 288.0, "episode/score": 0.050137021308216845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050137021308216845}
{"step": 331032, "time": 10904.307837963104, "episode/length": 288.0, "episode/score": 0.03466818125349391, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03466818125349391}
{"step": 331152, "time": 10908.309028148651, "episode/length": 288.0, "episode/score": 0.03948910578384357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03948910578384357}
{"step": 331568, "time": 10921.411491394043, "episode/length": 288.0, "episode/score": 0.04140585788502449, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04140585788502449}
{"step": 331752, "time": 10926.950152635574, "episode/length": 288.0, "episode/score": 0.031237126949463345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031237126949463345}
{"step": 332464, "time": 10949.645240545273, "episode/length": 288.0, "episode/score": 0.04211774809311919, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04211774809311919}
{"step": 332520, "time": 10951.217575788498, "episode/length": 288.0, "episode/score": 0.03367858820502079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03367858820502079}
{"step": 332576, "time": 10953.200079917908, "episode/length": 288.0, "episode/score": 0.032256249570195905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032256249570195905}
{"step": 332976, "time": 10965.785562038422, "episode/length": 288.0, "episode/score": 0.03432450873617654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03432450873617654}
{"step": 333344, "time": 10977.370546340942, "episode/length": 288.0, "episode/score": 0.04577576185079124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04577576185079124}
{"step": 333464, "time": 10981.048404455185, "episode/length": 288.0, "episode/score": 0.025120052059833142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025120052059833142}
{"step": 333880, "time": 10994.086154699326, "episode/length": 288.0, "episode/score": 0.038676292065702, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038676292065702}
{"step": 334064, "time": 11000.094270467758, "episode/length": 288.0, "episode/score": 0.038342318138347764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038342318138347764}
{"step": 334776, "time": 11022.278750658035, "episode/length": 288.0, "episode/score": 0.03749045972983822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03749045972983822}
{"step": 334832, "time": 11024.274662971497, "episode/length": 288.0, "episode/score": 0.03463785604537861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03463785604537861}
{"step": 334888, "time": 11025.810626506805, "episode/length": 288.0, "episode/score": 0.03836444167313857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03836444167313857}
{"step": 335288, "time": 11038.351951122284, "episode/length": 288.0, "episode/score": 0.04690683022511166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04690683022511166}
{"step": 335656, "time": 11050.009038686752, "episode/length": 288.0, "episode/score": 0.03732467159306907, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03732467159306907}
{"step": 335776, "time": 11053.991983652115, "episode/length": 288.0, "episode/score": 0.0500120766149621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0500120766149621}
{"step": 336192, "time": 11067.723205327988, "episode/length": 288.0, "episode/score": 0.041516686679756276, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041516686679756276}
{"step": 336376, "time": 11073.398823976517, "episode/length": 288.0, "episode/score": 0.058991377144479884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058991377144479884}
{"step": 337088, "time": 11095.895011663437, "episode/length": 288.0, "episode/score": 0.06463413513165506, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06463413513165506}
{"step": 337144, "time": 11097.445748329163, "episode/length": 288.0, "episode/score": 0.05479961793946586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05479961793946586}
{"step": 337200, "time": 11099.507495164871, "episode/length": 288.0, "episode/score": 0.06298056068874303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06298056068874303}
{"step": 337600, "time": 11112.046474695206, "episode/length": 288.0, "episode/score": 0.06592152705343324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06592152705343324}
{"step": 337968, "time": 11123.56349492073, "episode/length": 288.0, "episode/score": 0.05476522880530865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05476522880530865}
{"step": 338088, "time": 11127.101239204407, "episode/length": 288.0, "episode/score": 0.04982161392194939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04982161392194939}
{"step": 338504, "time": 11140.251579523087, "episode/length": 288.0, "episode/score": 0.06373552839284002, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06373552839284002}
{"step": 338688, "time": 11146.278503417969, "episode/length": 288.0, "episode/score": 0.050777936237523136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050777936237523136}
{"step": 339400, "time": 11168.439720153809, "episode/length": 288.0, "episode/score": 0.05692699605742746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05692699605742746}
{"step": 339456, "time": 11170.409240484238, "episode/length": 288.0, "episode/score": 0.06421526523229204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06421526523229204}
{"step": 339512, "time": 11171.957941055298, "episode/length": 288.0, "episode/score": 0.051147600036529184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051147600036529184}
{"step": 339912, "time": 11184.458177804947, "episode/length": 288.0, "episode/score": 0.054395962541548215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054395962541548215}
{"step": 340080, "time": 11195.848828077316, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.856101512909, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.863318443298, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.870665073395, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.877125740051, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.88601899147, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.893321037292, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11195.89981508255, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340280, "time": 11201.95261669159, "episode/length": 288.0, "episode/score": 0.054221547033307615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054221547033307615}
{"step": 340400, "time": 11205.941866159439, "episode/length": 288.0, "episode/score": 0.0647976381137596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0647976381137596}
{"step": 340816, "time": 11219.132974624634, "episode/length": 288.0, "episode/score": 0.030427924826426533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030427924826426533}
{"step": 341000, "time": 11224.723895311356, "episode/length": 288.0, "episode/score": 0.07781707058057918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07781707058057918}
{"step": 341401, "time": 11238.314384698868, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4736713115985576, "train/action_min": 0.0, "train/action_std": 1.5453663972707896, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0033319448640283483, "train/actor_opt_grad_steps": 20270.0, "train/actor_opt_loss": -32.30505223534046, "train/adv_mag": 0.19477826861234812, "train/adv_max": 0.051491179985877794, "train/adv_mean": -0.002787729859417782, "train/adv_min": -0.17165970175694198, "train/adv_std": 0.007608503693690858, "train/cont_avg": 0.9964042467948718, "train/cont_loss_mean": 0.02032166402070568, "train/cont_loss_std": 0.28843766201574067, "train/cont_neg_acc": 0.0656296033988294, "train/cont_neg_loss": 4.6749346136432335, "train/cont_pos_acc": 0.9999044687320024, "train/cont_pos_loss": 0.0035910116490693047, "train/cont_pred": 0.9962297396782117, "train/cont_rate": 0.9964042467948718, "train/dyn_loss_mean": 1.0000055141938038, "train/dyn_loss_std": 0.00016903690428499922, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.2559133092419077, "train/extr_critic_critic_opt_grad_steps": 20270.0, "train/extr_critic_critic_opt_loss": 11375.212366035657, "train/extr_critic_mag": 0.4709992793890146, "train/extr_critic_max": 0.4709992793890146, "train/extr_critic_mean": 0.4573552668094635, "train/extr_critic_min": 0.44398954587104994, "train/extr_critic_std": 0.004576544963921874, "train/extr_return_normed_mag": 0.19555996121504368, "train/extr_return_normed_max": 0.062442202292955835, "train/extr_return_normed_mean": 0.0051168135942985735, "train/extr_return_normed_min": -0.16094594307434865, "train/extr_return_normed_std": 0.008946221754050408, "train/extr_return_rate": 0.19188836341125307, "train/extr_return_raw_mag": 0.5118929109512231, "train/extr_return_raw_max": 0.5118929109512231, "train/extr_return_raw_mean": 0.4545675459580544, "train/extr_return_raw_min": 0.28850476558391863, "train/extr_return_raw_std": 0.008946221777930474, "train/extr_reward_mag": 0.06967292565565843, "train/extr_reward_max": 0.06967292565565843, "train/extr_reward_mean": 0.0006767338746263144, "train/extr_reward_min": 5.840032528608273e-06, "train/extr_reward_std": 0.002455052564619109, "train/image_loss_mean": 0.1379363204424198, "train/image_loss_std": 0.10974736408545421, "train/model_loss_mean": 0.7690178443224002, "train/model_loss_std": 0.35250359639907497, "train/model_opt_grad_norm": 30.948574726398174, "train/model_opt_grad_steps": 20250.62051282051, "train/model_opt_loss": 3583.8773193359375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 4653.846153846154, "train/policy_entropy_mag": 1.5269691491738344, "train/policy_entropy_max": 1.5269691491738344, "train/policy_entropy_mean": 0.7068814043051157, "train/policy_entropy_min": 0.06577053475074279, "train/policy_entropy_std": 0.3576544321500338, "train/policy_logprob_mag": 6.55075894624759, "train/policy_logprob_max": -0.008777966464941318, "train/policy_logprob_mean": -0.7067737138424164, "train/policy_logprob_min": -6.55075894624759, "train/policy_logprob_std": 0.8797757429954333, "train/policy_randomness_mag": 0.7847069596632933, "train/policy_randomness_max": 0.7847069596632933, "train/policy_randomness_mean": 0.36326520202251583, "train/policy_randomness_min": 0.03379937074123285, "train/policy_randomness_std": 0.18379803154713067, "train/post_ent_mag": 46.71360477545323, "train/post_ent_max": 46.71360477545323, "train/post_ent_mean": 46.188554225823815, "train/post_ent_min": 45.82719591580904, "train/post_ent_std": 0.15113898248244553, "train/prior_ent_mag": 48.32326916425656, "train/prior_ent_max": 48.32326916425656, "train/prior_ent_mean": 45.89935294909355, "train/prior_ent_min": 44.00744407849434, "train/prior_ent_std": 0.7199926009544959, "train/rep_loss_mean": 1.0000055141938038, "train/rep_loss_std": 0.00016903690428499922, "train/reward_avg": 0.000442085680566752, "train/reward_loss_mean": 0.010756527207409725, "train/reward_loss_std": 0.07189032902033665, "train/reward_max_data": 0.23441075128264344, "train/reward_max_pred": 0.05198537875444461, "train/reward_neg_acc": 0.9999499003092448, "train/reward_neg_loss": 0.008624551196893057, "train/reward_pos_acc": 0.1891891891891892, "train/reward_pos_loss": 4.865973297003153, "train/reward_pred": 0.00042790499372551073, "train/reward_rate": 0.0004356971153846154, "train_stats/mean_log_entropy": 0.7668403002566525, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.022180575877428055, "report/cont_loss_std": 0.369402140378952, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 6.772618293762207, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002345795975998044, "report/cont_pred": 0.9976783990859985, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.12643343210220337, "report/image_loss_std": 0.10939663648605347, "report/model_loss_mean": 0.7574031949043274, "report/model_loss_std": 0.38297852873802185, "report/post_ent_mag": 44.629600524902344, "report/post_ent_max": 44.629600524902344, "report/post_ent_mean": 43.985450744628906, "report/post_ent_min": 43.53364562988281, "report/post_ent_std": 0.17925028502941132, "report/prior_ent_mag": 46.324363708496094, "report/prior_ent_max": 46.324363708496094, "report/prior_ent_mean": 43.868995666503906, "report/prior_ent_min": 41.8592643737793, "report/prior_ent_std": 0.7831352949142456, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018903764430433512, "report/reward_loss_mean": 0.00878918170928955, "report/reward_loss_std": 0.018115069717168808, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.1302870512008667, "report/reward_neg_acc": 0.9990234375, "report/reward_neg_loss": 0.008789182640612125, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00039763771928846836, "report/reward_rate": 0.0, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.010797739028930664, "eval/cont_loss_std": 0.23433150351047516, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.481032371520996, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034954564180225134, "eval/cont_pred": 0.9966791868209839, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20572364330291748, "eval/image_loss_std": 0.12604184448719025, "eval/model_loss_mean": 0.8176941275596619, "eval/model_loss_std": 0.2673478424549103, "eval/post_ent_mag": 44.62569808959961, "eval/post_ent_max": 44.62569808959961, "eval/post_ent_mean": 43.97369384765625, "eval/post_ent_min": 43.54866027832031, "eval/post_ent_std": 0.17057132720947266, "eval/prior_ent_mag": 46.324363708496094, "eval/prior_ent_max": 46.324363708496094, "eval/prior_ent_mean": 43.733585357666016, "eval/prior_ent_min": 41.65965270996094, "eval/prior_ent_std": 0.7598584890365601, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011727502569556236, "eval/reward_loss_std": 0.0015810790937393904, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0026297569274902344, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011727502569556236, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00019723991863429546, "eval/reward_rate": 0.0, "replay/size": 340897.0, "replay/inserts": 31120.0, "replay/samples": 31120.0, "replay/insert_wait_avg": 1.2635188727881425e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0006302120140096e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81600.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0903456356836164e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0730972290039, "timer/env.step_count": 3890.0, "timer/env.step_total": 36.94882416725159, "timer/env.step_frac": 0.036946123508000715, "timer/env.step_avg": 0.009498412382326887, "timer/env.step_min": 0.0077440738677978516, "timer/env.step_max": 0.03479599952697754, "timer/replay._sample_count": 31120.0, "timer/replay._sample_total": 15.956795454025269, "timer/replay._sample_frac": 0.015955629141747994, "timer/replay._sample_avg": 0.0005127504965946423, "timer/replay._sample_min": 0.00037479400634765625, "timer/replay._sample_max": 0.032195329666137695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4757.0, "timer/agent.policy_total": 48.434465169906616, "timer/agent.policy_frac": 0.04843092500349076, "timer/agent.policy_avg": 0.010181724862288546, "timer/agent.policy_min": 0.008844614028930664, "timer/agent.policy_max": 0.09227323532104492, "timer/dataset_train_count": 1945.0, "timer/dataset_train_total": 0.22240567207336426, "timer/dataset_train_frac": 0.00022238941602329315, "timer/dataset_train_avg": 0.00011434738924080424, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.00040459632873535156, "timer/agent.train_count": 1945.0, "timer/agent.train_total": 862.679940700531, "timer/agent.train_frac": 0.8626168857964873, "timer/agent.train_avg": 0.4435372445761085, "timer/agent.train_min": 0.43084239959716797, "timer/agent.train_max": 0.5977368354797363, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47867608070373535, "timer/agent.report_frac": 0.0004786410933661229, "timer/agent.report_avg": 0.23933804035186768, "timer/agent.report_min": 0.23382043838500977, "timer/agent.report_max": 0.24485564231872559, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2422556758756215e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 31.11718488528206}
{"step": 341712, "time": 11248.103536605835, "episode/length": 288.0, "episode/score": 0.04989433016424982, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04989433016424982}
{"step": 341768, "time": 11249.729233503342, "episode/length": 288.0, "episode/score": 0.05092863022338179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05092863022338179}
{"step": 341824, "time": 11251.726356744766, "episode/length": 288.0, "episode/score": 0.06659701242659821, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06659701242659821}
{"step": 342224, "time": 11264.30428147316, "episode/length": 288.0, "episode/score": 0.06969573089673986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06969573089673986}
{"step": 342592, "time": 11275.87046122551, "episode/length": 288.0, "episode/score": 0.06761909510800024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06761909510800024}
{"step": 342712, "time": 11279.527723312378, "episode/length": 288.0, "episode/score": 0.026343292020442277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026343292020442277}
{"step": 343128, "time": 11292.687741041183, "episode/length": 288.0, "episode/score": 0.08848309109401953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08848309109401953}
{"step": 343312, "time": 11298.73737168312, "episode/length": 288.0, "episode/score": 0.06732937263717531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06732937263717531}
{"step": 344024, "time": 11321.060129880905, "episode/length": 288.0, "episode/score": 0.08898636917382419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08898636917382419}
{"step": 344080, "time": 11323.547574281693, "episode/length": 288.0, "episode/score": 0.06060928325604209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06060928325604209}
{"step": 344136, "time": 11325.122072458267, "episode/length": 288.0, "episode/score": 0.08376143847743833, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08376143847743833}
{"step": 344536, "time": 11337.755449056625, "episode/length": 288.0, "episode/score": 0.08586536874190642, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08586536874190642}
{"step": 344904, "time": 11349.526739120483, "episode/length": 288.0, "episode/score": 0.07641849994882932, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07641849994882932}
{"step": 345024, "time": 11353.527391910553, "episode/length": 288.0, "episode/score": 0.07827708863658245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07827708863658245}
{"step": 345440, "time": 11366.660994291306, "episode/length": 288.0, "episode/score": 0.08653995110915957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08653995110915957}
{"step": 345624, "time": 11372.3115670681, "episode/length": 288.0, "episode/score": 0.08892577011329195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08892577011329195}
{"step": 346336, "time": 11394.939484834671, "episode/length": 288.0, "episode/score": 0.07396823587237122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07396823587237122}
{"step": 346392, "time": 11396.503968715668, "episode/length": 288.0, "episode/score": 0.0540898414724893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0540898414724893}
{"step": 346448, "time": 11398.523123502731, "episode/length": 288.0, "episode/score": 0.08060850653924945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08060850653924945}
{"step": 346848, "time": 11412.327184438705, "episode/length": 288.0, "episode/score": 0.056956053973237886, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056956053973237886}
{"step": 347216, "time": 11424.103722333908, "episode/length": 288.0, "episode/score": 0.03301545343128964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03301545343128964}
{"step": 347336, "time": 11427.696917772293, "episode/length": 288.0, "episode/score": 0.03630575269426117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03630575269426117}
{"step": 347752, "time": 11440.864704608917, "episode/length": 288.0, "episode/score": 0.024273590555026203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024273590555026203}
{"step": 347936, "time": 11446.863082885742, "episode/length": 288.0, "episode/score": 0.052739939868843067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052739939868843067}
{"step": 348648, "time": 11469.22854065895, "episode/length": 288.0, "episode/score": 0.021660447226054202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021660447226054202}
{"step": 348704, "time": 11471.250267982483, "episode/length": 288.0, "episode/score": 0.022510214405770057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022510214405770057}
{"step": 348760, "time": 11472.816965818405, "episode/length": 288.0, "episode/score": 0.01803038096375076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01803038096375076}
{"step": 349160, "time": 11485.381392002106, "episode/length": 288.0, "episode/score": 0.028176494221952453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028176494221952453}
{"step": 349528, "time": 11497.132094621658, "episode/length": 288.0, "episode/score": 0.023791769439185373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023791769439185373}
{"step": 349648, "time": 11501.141787052155, "episode/length": 288.0, "episode/score": 0.035850712041110455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035850712041110455}
{"step": 350064, "time": 11514.264824867249, "episode/length": 288.0, "episode/score": 0.03182221688746267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03182221688746267}
{"step": 350064, "time": 11516.8745470047, "eval_episode/length": 142.0, "eval_episode/score": 0.5562499761581421, "eval_episode/reward_rate": 0.006993006993006993}
{"step": 350064, "time": 11519.633129835129, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11519.640497922897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11519.647099256516, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11519.653634548187, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11519.660245418549, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11519.667174816132, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11519.673598527908, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350248, "time": 11525.278183460236, "episode/length": 288.0, "episode/score": 0.03482626048463544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03482626048463544}
{"step": 350960, "time": 11547.921552658081, "episode/length": 288.0, "episode/score": 0.04335652930512879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04335652930512879}
{"step": 351016, "time": 11549.58032822609, "episode/length": 288.0, "episode/score": 0.037137176059445665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037137176059445665}
{"step": 351072, "time": 11551.564134597778, "episode/length": 288.0, "episode/score": 0.041317415205412544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041317415205412544}
{"step": 351472, "time": 11564.13793849945, "episode/length": 288.0, "episode/score": 0.03315406467845605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03315406467845605}
{"step": 351840, "time": 11575.705564498901, "episode/length": 288.0, "episode/score": 0.04574153203941478, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04574153203941478}
{"step": 351960, "time": 11579.406793117523, "episode/length": 288.0, "episode/score": 0.04187794840521519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04187794840521519}
{"step": 352376, "time": 11593.03555226326, "episode/length": 288.0, "episode/score": 0.048209316243827516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048209316243827516}
{"step": 352400, "time": 11594.0195145607, "episode/length": 69.0, "episode/score": 0.8091038487351625, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.024728808176064376}
{"step": 352560, "time": 11599.047159671783, "episode/length": 288.0, "episode/score": 0.03515093481519216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03515093481519216}
{"step": 352952, "time": 11611.248756408691, "episode/length": 248.0, "episode/score": 0.2939514617604573, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.06895146853582901}
{"step": 353224, "time": 11619.819171667099, "episode/length": 102.0, "episode/score": 0.7095394244883266, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.028289419692015372}
{"step": 353328, "time": 11623.32742190361, "episode/length": 288.0, "episode/score": 0.0668880174050912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0668880174050912}
{"step": 353384, "time": 11624.879490852356, "episode/length": 288.0, "episode/score": 0.05965683867032112, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05965683867032112}
{"step": 353784, "time": 11637.50820183754, "episode/length": 288.0, "episode/score": 0.07666953963587275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07666953963587275}
{"step": 354120, "time": 11648.228085279465, "episode/length": 91.0, "episode/score": 0.747277727654307, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.03165274039014321}
{"step": 354272, "time": 11653.281324863434, "episode/length": 288.0, "episode/score": 0.06679579514241141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06679579514241141}
{"step": 354688, "time": 11666.40832901001, "episode/length": 288.0, "episode/score": 0.05497013350066027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05497013350066027}
{"step": 354872, "time": 11672.076263427734, "episode/length": 288.0, "episode/score": 0.07437700727092533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07437700727092533}
{"step": 355264, "time": 11684.73564505577, "episode/length": 288.0, "episode/score": 0.03936165757968979, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03936165757968979}
{"step": 355536, "time": 11693.425325393677, "episode/length": 288.0, "episode/score": 0.06977559559760493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06977559559760493}
{"step": 355640, "time": 11696.498747110367, "episode/length": 288.0, "episode/score": 0.08564447632960537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08564447632960537}
{"step": 355664, "time": 11697.498448848724, "episode/length": 173.0, "episode/score": 0.5096393105264383, "episode/reward_rate": 0.005747126436781609, "episode/intrinsic_return": 0.05026430216781819}
{"step": 356096, "time": 11711.27751660347, "episode/length": 288.0, "episode/score": 0.03933670356008179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03933670356008179}
{"step": 356128, "time": 11712.298213481903, "episode/length": 73.0, "episode/score": 0.803190904850652, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.031315857667522096}
{"step": 356352, "time": 11719.318126916885, "episode/length": 85.0, "episode/score": 0.7567897338189482, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.022414719499863622}
{"step": 356432, "time": 11721.842425346375, "episode/length": 288.0, "episode/score": 0.05415086659155577, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05415086659155577}
{"step": 357000, "time": 11739.534868001938, "episode/length": 288.0, "episode/score": 0.08767948421348137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08767948421348137}
{"step": 357184, "time": 11745.540228366852, "episode/length": 288.0, "episode/score": 0.03289648601909789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03289648601909789}
{"step": 357576, "time": 11757.651131391525, "episode/length": 288.0, "episode/score": 0.07910583244259328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07910583244259328}
{"step": 357952, "time": 11769.776156187057, "episode/length": 288.0, "episode/score": 0.08556782582866163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08556782582866163}
{"step": 358192, "time": 11777.369982719421, "episode/length": 257.0, "episode/score": 0.24548262925813447, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.04860762446182321}
{"step": 358408, "time": 11783.938229560852, "episode/length": 288.0, "episode/score": 0.06433841924231842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06433841924231842}
{"step": 358552, "time": 11788.552281618118, "episode/length": 264.0, "episode/score": 0.23092279293936713, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.055922797083752585}
{"step": 358664, "time": 11792.15651512146, "episode/length": 288.0, "episode/score": 0.0387966064615739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0387966064615739}
{"step": 359312, "time": 11812.832165956497, "episode/length": 288.0, "episode/score": 0.06929807419876965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06929807419876965}
{"step": 359480, "time": 11817.905406951904, "episode/length": 160.0, "episode/score": 0.5289078914498191, "episode/reward_rate": 0.006211180124223602, "episode/intrinsic_return": 0.02890786281164992}
{"step": 359496, "time": 11818.426171779633, "episode/length": 288.0, "episode/score": 0.035045405834864596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035045405834864596}
{"step": 359888, "time": 11831.10646700859, "episode/length": 288.0, "episode/score": 0.04028368941627036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04028368941627036}
{"step": 360048, "time": 11841.526041030884, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.533848047256, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.540675163269, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.549730539322, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.556892156601, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.56366276741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.570885896683, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11841.57746720314, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360264, "time": 11848.166353940964, "episode/length": 288.0, "episode/score": 0.07212879947834949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07212879947834949}
{"step": 360720, "time": 11863.468773841858, "episode/length": 288.0, "episode/score": 0.06539598256088652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06539598256088652}
{"step": 360864, "time": 11868.029038906097, "episode/length": 288.0, "episode/score": 0.058955518571735865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058955518571735865}
{"step": 360976, "time": 11871.578988552094, "episode/length": 288.0, "episode/score": 0.0710974566999596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0710974566999596}
{"step": 361624, "time": 11891.826164722443, "episode/length": 288.0, "episode/score": 0.07537694717757404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07537694717757404}
{"step": 361792, "time": 11897.359961271286, "episode/length": 288.0, "episode/score": 0.08981074630730745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08981074630730745}
{"step": 361808, "time": 11897.875982761383, "episode/length": 288.0, "episode/score": 0.06396207485965988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06396207485965988}
{"step": 362200, "time": 11910.117092132568, "episode/length": 288.0, "episode/score": 0.09413775000518854, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09413775000518854}
{"step": 362576, "time": 11922.171395778656, "episode/length": 288.0, "episode/score": 0.08272918747354652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08272918747354652}
{"step": 363000, "time": 11935.33551454544, "episode/length": 252.0, "episode/score": 0.2883898412043209, "episode/reward_rate": 0.003952569169960474, "episode/intrinsic_return": 0.07588983640800961}
{"step": 363032, "time": 11936.354710578918, "episode/length": 288.0, "episode/score": 0.10429524612595742, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10429524612595742}
{"step": 363176, "time": 11940.964698076248, "episode/length": 288.0, "episode/score": 0.08207242153059724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08207242153059724}
{"step": 363936, "time": 11965.031896591187, "episode/length": 288.0, "episode/score": 0.08828265672764246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08828265672764246}
{"step": 364104, "time": 11970.195045232773, "episode/length": 288.0, "episode/score": 0.08083857771964631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08083857771964631}
{"step": 364120, "time": 11970.725671768188, "episode/length": 288.0, "episode/score": 0.07126382850879054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07126382850879054}
{"step": 364512, "time": 11983.233347415924, "episode/length": 288.0, "episode/score": 0.0756121156645122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0756121156645122}
{"step": 364888, "time": 11994.828023672104, "episode/length": 288.0, "episode/score": 0.07040954077876904, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07040954077876904}
{"step": 365312, "time": 12008.497284650803, "episode/length": 288.0, "episode/score": 0.05593150953222903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05593150953222903}
{"step": 365344, "time": 12009.52737569809, "episode/length": 288.0, "episode/score": 0.07877377683797704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07877377683797704}
{"step": 365488, "time": 12014.109148979187, "episode/length": 288.0, "episode/score": 0.0546528984843917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0546528984843917}
{"step": 366248, "time": 12038.113500833511, "episode/length": 288.0, "episode/score": 0.0786086068151235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0786086068151235}
{"step": 366416, "time": 12043.615975379944, "episode/length": 288.0, "episode/score": 0.0565347332874353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0565347332874353}
{"step": 366432, "time": 12044.126057386398, "episode/length": 288.0, "episode/score": 0.08278073924145701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08278073924145701}
{"step": 366824, "time": 12056.232605218887, "episode/length": 288.0, "episode/score": 0.05047128313447047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05047128313447047}
{"step": 367200, "time": 12068.524168491364, "episode/length": 288.0, "episode/score": 0.05849915623127799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05849915623127799}
{"step": 367624, "time": 12081.686376571655, "episode/length": 288.0, "episode/score": 0.07115539835422169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07115539835422169}
{"step": 367656, "time": 12082.711383342743, "episode/length": 288.0, "episode/score": 0.05773782289520568, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05773782289520568}
{"step": 367800, "time": 12087.248415231705, "episode/length": 288.0, "episode/score": 0.050040315508113054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050040315508113054}
{"step": 368560, "time": 12111.5956761837, "episode/length": 288.0, "episode/score": 0.06371189576884717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06371189576884717}
{"step": 368728, "time": 12117.173642635345, "episode/length": 288.0, "episode/score": 0.08251788305960872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08251788305960872}
{"step": 368744, "time": 12117.680087804794, "episode/length": 288.0, "episode/score": 0.06729122792398812, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06729122792398812}
{"step": 369136, "time": 12130.358046770096, "episode/length": 288.0, "episode/score": 0.09390680288697695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09390680288697695}
{"step": 369512, "time": 12141.9734852314, "episode/length": 288.0, "episode/score": 0.06507459367458068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06507459367458068}
{"step": 369936, "time": 12155.701159238815, "episode/length": 288.0, "episode/score": 0.0763727041603488, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0763727041603488}
{"step": 369968, "time": 12156.70812869072, "episode/length": 288.0, "episode/score": 0.05769682756317707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05769682756317707}
{"step": 370032, "time": 12163.915549755096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.923021793365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.929557323456, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.935924768448, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.94334769249, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.950056552887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.956597566605, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370032, "time": 12163.963468551636, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 370112, "time": 12166.466624498367, "episode/length": 288.0, "episode/score": 0.06281583608233632, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06281583608233632}
{"step": 370872, "time": 12190.42433643341, "episode/length": 288.0, "episode/score": 0.0825262977211878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0825262977211878}
{"step": 371040, "time": 12195.955686569214, "episode/length": 288.0, "episode/score": 0.06768099795817761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06768099795817761}
{"step": 371056, "time": 12196.462468624115, "episode/length": 288.0, "episode/score": 0.02949613086889258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02949613086889258}
{"step": 371448, "time": 12208.689035654068, "episode/length": 288.0, "episode/score": 0.08307182736018603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08307182736018603}
{"step": 371824, "time": 12220.80584526062, "episode/length": 288.0, "episode/score": 0.09486420894052117, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09486420894052117}
{"step": 372248, "time": 12234.022802114487, "episode/length": 288.0, "episode/score": 0.09186002745627775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09186002745627775}
{"step": 372280, "time": 12235.057282686234, "episode/length": 288.0, "episode/score": 0.10467095807848636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10467095807848636}
{"step": 372361, "time": 12238.649725437164, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.178788101117228, "train/action_min": 0.0, "train/action_std": 1.5777607838106897, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009534432201096161, "train/actor_opt_grad_steps": 22210.0, "train/actor_opt_loss": 0.7163761820200194, "train/adv_mag": 0.4132519270163126, "train/adv_max": 0.25270886155607786, "train/adv_mean": 0.005873360171366293, "train/adv_min": -0.3673804902659797, "train/adv_std": 0.03188568306724913, "train/cont_avg": 0.9962759067357513, "train/cont_loss_mean": 0.01657220582511527, "train/cont_loss_std": 0.24442050062901693, "train/cont_neg_acc": 0.22636054732181407, "train/cont_neg_loss": 3.482118805348085, "train/cont_pos_acc": 0.9998069597031786, "train/cont_pos_loss": 0.0031137379659026128, "train/cont_pred": 0.9963044240067043, "train/cont_rate": 0.9962759067357513, "train/dyn_loss_mean": 1.000005396536595, "train/dyn_loss_std": 0.00014753339408325042, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.6481060700906064, "train/extr_critic_critic_opt_grad_steps": 22210.0, "train/extr_critic_critic_opt_loss": 11613.944148088367, "train/extr_critic_mag": 0.5012494603586938, "train/extr_critic_max": 0.5012494603586938, "train/extr_critic_mean": 0.48105756204980643, "train/extr_critic_min": 0.46229505415407485, "train/extr_critic_std": 0.007276701435707317, "train/extr_return_normed_mag": 0.41246931185376456, "train/extr_return_normed_max": 0.28853263848803823, "train/extr_return_normed_mean": 0.030100392575805206, "train/extr_return_normed_min": -0.3382196275063747, "train/extr_return_normed_std": 0.03338490610633412, "train/extr_return_rate": 0.5411347282265218, "train/extr_return_raw_mag": 0.745363126455811, "train/extr_return_raw_max": 0.745363126455811, "train/extr_return_raw_mean": 0.48693090244896053, "train/extr_return_raw_min": 0.1186108598437334, "train/extr_return_raw_std": 0.033384906165446565, "train/extr_reward_mag": 0.2984506095629282, "train/extr_reward_max": 0.2984506095629282, "train/extr_reward_mean": 0.0023498681501581617, "train/extr_reward_min": 3.835697865856744e-06, "train/extr_reward_std": 0.01427070281020163, "train/image_loss_mean": 0.12433801205355886, "train/image_loss_std": 0.10729505870626381, "train/model_loss_mean": 0.7516090604307738, "train/model_loss_std": 0.31589000031274833, "train/model_opt_grad_norm": 29.613926887512207, "train/model_opt_grad_steps": 22188.336787564767, "train/model_opt_loss": 1987.3624963315658, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2642.4870466321245, "train/policy_entropy_mag": 1.5094507765893492, "train/policy_entropy_max": 1.5094507765893492, "train/policy_entropy_mean": 0.2691862872304694, "train/policy_entropy_min": 0.06501036538824516, "train/policy_entropy_std": 0.2524112725118899, "train/policy_logprob_mag": 6.551016765554952, "train/policy_logprob_max": -0.008658672470618715, "train/policy_logprob_mean": -0.269221647338546, "train/policy_logprob_min": -6.551016765554952, "train/policy_logprob_std": 0.75944035318849, "train/policy_randomness_mag": 0.7757042976858702, "train/policy_randomness_max": 0.7757042976858702, "train/policy_randomness_mean": 0.13833439583682644, "train/policy_randomness_min": 0.03340872076045664, "train/policy_randomness_std": 0.1297137428827854, "train/post_ent_mag": 43.40577695777379, "train/post_ent_max": 43.40577695777379, "train/post_ent_mean": 42.71347077522871, "train/post_ent_min": 42.23677723148326, "train/post_ent_std": 0.2018436870581128, "train/prior_ent_mag": 44.37567856151205, "train/prior_ent_max": 44.37567856151205, "train/prior_ent_mean": 41.87509930072053, "train/prior_ent_min": 39.65649388367648, "train/prior_ent_std": 0.8071794528417636, "train/rep_loss_mean": 1.000005396536595, "train/rep_loss_std": 0.00014753339408325042, "train/reward_avg": 0.0004689296599464863, "train/reward_loss_mean": 0.010695584128017252, "train/reward_loss_std": 0.06989265683497944, "train/reward_max_data": 0.23471823029360045, "train/reward_max_pred": 0.07820981339469475, "train/reward_neg_acc": 0.9999493808326326, "train/reward_neg_loss": 0.008488554543685264, "train/reward_pos_acc": 0.25, "train/reward_pos_loss": 4.364132281806734, "train/reward_pred": 0.0004164041526654224, "train/reward_rate": 0.00048575129533678756, "train_stats/mean_log_entropy": 0.2819639490505235, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.009694922715425491, "report/cont_loss_std": 0.16143591701984406, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.161996841430664, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004658457823097706, "report/cont_pred": 0.9954054355621338, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.0903385803103447, "report/image_loss_std": 0.08647501468658447, "report/model_loss_mean": 0.7067838907241821, "report/model_loss_std": 0.1908334642648697, "report/post_ent_mag": 41.73889923095703, "report/post_ent_max": 41.73889923095703, "report/post_ent_mean": 40.925453186035156, "report/post_ent_min": 40.34077453613281, "report/post_ent_std": 0.23750288784503937, "report/prior_ent_mag": 42.778167724609375, "report/prior_ent_max": 42.778167724609375, "report/prior_ent_mean": 40.54200744628906, "report/prior_ent_min": 37.60089111328125, "report/prior_ent_std": 0.8056157827377319, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00013423514610622078, "report/reward_loss_mean": 0.0067503307946026325, "report/reward_loss_std": 0.012083408422768116, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.05184006690979004, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.0067503307946026325, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00040800345595926046, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.031807199120521545, "eval/cont_loss_std": 0.44851288199424744, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.125161170959473, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.003990121651440859, "eval/cont_pred": 0.9962028861045837, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22506465017795563, "eval/image_loss_std": 0.12781324982643127, "eval/model_loss_mean": 0.8580310344696045, "eval/model_loss_std": 0.4739373028278351, "eval/post_ent_mag": 41.72526550292969, "eval/post_ent_max": 41.72526550292969, "eval/post_ent_mean": 40.91750717163086, "eval/post_ent_min": 40.397335052490234, "eval/post_ent_std": 0.22127842903137207, "eval/prior_ent_mag": 43.28601837158203, "eval/prior_ent_max": 43.28601837158203, "eval/prior_ent_mean": 40.36344528198242, "eval/prior_ent_min": 38.30129623413086, "eval/prior_ent_std": 0.8069806098937988, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001159138511866331, "eval/reward_loss_std": 0.0015946764033287764, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.007779717445373535, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001159138511866331, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00019840081222355366, "eval/reward_rate": 0.0, "replay/size": 371857.0, "replay/inserts": 30960.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.2694403182628542e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.88928846610609e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 88536.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1171230395359977e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2678542137146, "timer/env.step_count": 3870.0, "timer/env.step_total": 36.66013169288635, "timer/env.step_frac": 0.03665031475164616, "timer/env.step_avg": 0.009472902246223864, "timer/env.step_min": 0.007769584655761719, "timer/env.step_max": 0.044246673583984375, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.8174467086792, "timer/replay._sample_frac": 0.015813211073460814, "timer/replay._sample_avg": 0.0005108994414948062, "timer/replay._sample_min": 0.000385284423828125, "timer/replay._sample_max": 0.023850679397583008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4737.0, "timer/agent.policy_total": 47.72705602645874, "timer/agent.policy_frac": 0.047714275556696537, "timer/agent.policy_avg": 0.010075375981941892, "timer/agent.policy_min": 0.008832693099975586, "timer/agent.policy_max": 0.08495903015136719, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.22066211700439453, "timer/dataset_train_frac": 0.00022060302755390603, "timer/dataset_train_avg": 0.00011403726976971294, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.0003628730773925781, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 864.3585524559021, "timer/agent.train_frac": 0.864127092373025, "timer/agent.train_avg": 0.44669692633379954, "timer/agent.train_min": 0.4360616207122803, "timer/agent.train_max": 1.5567762851715088, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.501826286315918, "timer/agent.report_frac": 0.0005016919060249026, "timer/agent.report_avg": 0.250913143157959, "timer/agent.report_min": 0.2337181568145752, "timer/agent.report_max": 0.2681081295013428, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.313130813462745e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 30.95093855557279}
{"step": 372424, "time": 12240.395021677017, "episode/length": 288.0, "episode/score": 0.08756112463299814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08756112463299814}
{"step": 373184, "time": 12264.658041715622, "episode/length": 288.0, "episode/score": 0.09244223952691755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09244223952691755}
{"step": 373352, "time": 12269.83437204361, "episode/length": 288.0, "episode/score": 0.05701894776689187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05701894776689187}
{"step": 373368, "time": 12270.350017309189, "episode/length": 288.0, "episode/score": 0.07657457326172334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07657457326172334}
{"step": 373760, "time": 12282.943715810776, "episode/length": 288.0, "episode/score": 0.07799622684296992, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07799622684296992}
{"step": 374136, "time": 12294.566202878952, "episode/length": 288.0, "episode/score": 0.06173773778334635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06173773778334635}
{"step": 374360, "time": 12301.678453922272, "episode/length": 259.0, "episode/score": 0.26536316881913535, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.07473817296352081}
{"step": 374560, "time": 12308.166178941727, "episode/length": 288.0, "episode/score": 0.07532468591580255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07532468591580255}
{"step": 374736, "time": 12313.705622196198, "episode/length": 288.0, "episode/score": 0.05489723063334395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05489723063334395}
{"step": 375496, "time": 12337.520769357681, "episode/length": 288.0, "episode/score": 0.07871825180916403, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07871825180916403}
{"step": 375664, "time": 12343.084928035736, "episode/length": 288.0, "episode/score": 0.1060892587440776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1060892587440776}
{"step": 375680, "time": 12343.606145620346, "episode/length": 288.0, "episode/score": 0.09284272533108151, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09284272533108151}
{"step": 376072, "time": 12355.778490543365, "episode/length": 288.0, "episode/score": 0.11249992817562315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11249992817562315}
{"step": 376448, "time": 12367.972908258438, "episode/length": 288.0, "episode/score": 0.09797025914235746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09797025914235746}
{"step": 376672, "time": 12375.018453836441, "episode/length": 288.0, "episode/score": 0.09972703864167443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09972703864167443}
{"step": 376872, "time": 12381.582929849625, "episode/length": 288.0, "episode/score": 0.09794499111325194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09794499111325194}
{"step": 377048, "time": 12387.184118747711, "episode/length": 288.0, "episode/score": 0.08601180292504296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08601180292504296}
{"step": 377808, "time": 12411.512267112732, "episode/length": 288.0, "episode/score": 0.10694915768317514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10694915768317514}
{"step": 377976, "time": 12416.545139074326, "episode/length": 288.0, "episode/score": 0.07426217447039107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07426217447039107}
{"step": 377992, "time": 12417.05170583725, "episode/length": 288.0, "episode/score": 0.08645193837548959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08645193837548959}
{"step": 378384, "time": 12429.785653591156, "episode/length": 288.0, "episode/score": 0.0878463200934334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0878463200934334}
{"step": 378760, "time": 12441.562123298645, "episode/length": 288.0, "episode/score": 0.0650791345979087, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0650791345979087}
{"step": 378984, "time": 12448.748425722122, "episode/length": 288.0, "episode/score": 0.09563325460004535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09563325460004535}
{"step": 379184, "time": 12455.311909675598, "episode/length": 288.0, "episode/score": 0.10402822419604263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10402822419604263}
{"step": 379360, "time": 12460.870000600815, "episode/length": 288.0, "episode/score": 0.0938794155257483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0938794155257483}
{"step": 380016, "time": 12487.60421204567, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.612491846085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.61928319931, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.627210617065, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.635164499283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.641229629517, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.648806333542, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380016, "time": 12487.655306339264, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 380120, "time": 12490.759371519089, "episode/length": 288.0, "episode/score": 0.06616462940695556, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06616462940695556}
{"step": 380288, "time": 12496.318269491196, "episode/length": 288.0, "episode/score": 0.11928917251810844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11928917251810844}
{"step": 380304, "time": 12496.825654268265, "episode/length": 288.0, "episode/score": 0.08232865295730107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08232865295730107}
{"step": 380696, "time": 12508.956734657288, "episode/length": 288.0, "episode/score": 0.04364920466679223, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04364920466679223}
{"step": 381072, "time": 12521.087194681168, "episode/length": 288.0, "episode/score": 0.07331944265666834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07331944265666834}
{"step": 381296, "time": 12528.157906293869, "episode/length": 288.0, "episode/score": 0.08356274015437748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08356274015437748}
{"step": 381496, "time": 12534.229543447495, "episode/length": 288.0, "episode/score": 0.0857789033921108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0857789033921108}
{"step": 381672, "time": 12539.88037776947, "episode/length": 288.0, "episode/score": 0.11766995685178472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11766995685178472}
{"step": 382432, "time": 12564.085084199905, "episode/length": 288.0, "episode/score": 0.06367401583486298, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06367401583486298}
{"step": 382600, "time": 12569.238492250443, "episode/length": 288.0, "episode/score": 0.08352289745607777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08352289745607777}
{"step": 382616, "time": 12569.747871398926, "episode/length": 288.0, "episode/score": 0.08753190904275243, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08753190904275243}
{"step": 383008, "time": 12582.256294488907, "episode/length": 288.0, "episode/score": 0.08043320538450871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08043320538450871}
{"step": 383384, "time": 12593.851843357086, "episode/length": 288.0, "episode/score": 0.08327947996320972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08327947996320972}
{"step": 383608, "time": 12601.066843509674, "episode/length": 288.0, "episode/score": 0.05359927428685296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05359927428685296}
{"step": 383808, "time": 12607.60228896141, "episode/length": 288.0, "episode/score": 0.08401468970527048, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08401468970527048}
{"step": 383984, "time": 12613.117615938187, "episode/length": 288.0, "episode/score": 0.09459253862451078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09459253862451078}
{"step": 384744, "time": 12636.74244093895, "episode/length": 288.0, "episode/score": 0.0742393461638926, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0742393461638926}
{"step": 384912, "time": 12642.269473075867, "episode/length": 288.0, "episode/score": 0.08719511638332733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08719511638332733}
{"step": 384928, "time": 12642.79845905304, "episode/length": 288.0, "episode/score": 0.07714814702399053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07714814702399053}
{"step": 385320, "time": 12655.614461183548, "episode/length": 288.0, "episode/score": 0.09576819277521054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09576819277521054}
{"step": 385696, "time": 12667.737938165665, "episode/length": 288.0, "episode/score": 0.06754141499533262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06754141499533262}
{"step": 385920, "time": 12674.831004142761, "episode/length": 288.0, "episode/score": 0.0711101754873198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0711101754873198}
{"step": 386120, "time": 12680.881699562073, "episode/length": 288.0, "episode/score": 0.08022790628024268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08022790628024268}
{"step": 386296, "time": 12686.425915956497, "episode/length": 288.0, "episode/score": 0.06446470081755251, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06446470081755251}
{"step": 387056, "time": 12710.662962913513, "episode/length": 288.0, "episode/score": 0.07113751621454867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07113751621454867}
{"step": 387224, "time": 12715.7685110569, "episode/length": 288.0, "episode/score": 0.06837528625794675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06837528625794675}
{"step": 387240, "time": 12716.279272556305, "episode/length": 288.0, "episode/score": 0.08017894630324918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08017894630324918}
{"step": 387632, "time": 12729.016324996948, "episode/length": 288.0, "episode/score": 0.056629590900115545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056629590900115545}
{"step": 388008, "time": 12740.62018609047, "episode/length": 288.0, "episode/score": 0.09330068757265053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09330068757265053}
{"step": 388232, "time": 12747.622081756592, "episode/length": 288.0, "episode/score": 0.056544253342167394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056544253342167394}
{"step": 388432, "time": 12754.197916507721, "episode/length": 288.0, "episode/score": 0.038372206601309244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038372206601309244}
{"step": 388608, "time": 12759.749191045761, "episode/length": 288.0, "episode/score": 0.03091667823446187, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03091667823446187}
{"step": 389368, "time": 12783.477892637253, "episode/length": 288.0, "episode/score": 0.028683241177134278, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028683241177134278}
{"step": 389536, "time": 12788.968189001083, "episode/length": 288.0, "episode/score": 0.04961530660932567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04961530660932567}
{"step": 389552, "time": 12789.499599695206, "episode/length": 288.0, "episode/score": 0.07239934438553064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07239934438553064}
{"step": 389944, "time": 12801.532147884369, "episode/length": 288.0, "episode/score": 0.0714082364614228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0714082364614228}
{"step": 390000, "time": 12808.17563700676, "eval_episode/length": 261.0, "eval_episode/score": 0.18437500298023224, "eval_episode/reward_rate": 0.003816793893129771}
{"step": 390000, "time": 12808.802016735077, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12808.819584608078, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12808.826342105865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12808.832842111588, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12808.838970899582, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12808.845302343369, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390000, "time": 12808.851577281952, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 390320, "time": 12818.838138341904, "episode/length": 288.0, "episode/score": 0.07969839615361707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07969839615361707}
{"step": 390544, "time": 12825.926332712173, "episode/length": 288.0, "episode/score": 0.09879475011291561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09879475011291561}
{"step": 390744, "time": 12832.011687994003, "episode/length": 288.0, "episode/score": 0.0506735490112078, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0506735490112078}
{"step": 390920, "time": 12837.562057495117, "episode/length": 288.0, "episode/score": 0.07351382084743818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07351382084743818}
{"step": 391680, "time": 12861.98682808876, "episode/length": 288.0, "episode/score": 0.04390197640526594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04390197640526594}
{"step": 391848, "time": 12867.065017461777, "episode/length": 288.0, "episode/score": 0.08639388546288274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08639388546288274}
{"step": 391864, "time": 12867.578560590744, "episode/length": 288.0, "episode/score": 0.08712378792091613, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08712378792091613}
{"step": 392256, "time": 12880.242712020874, "episode/length": 288.0, "episode/score": 0.07858579174529723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07858579174529723}
{"step": 392608, "time": 12891.321722507477, "episode/length": 257.0, "episode/score": 0.2394320984569731, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.04255709366066185}
{"step": 392632, "time": 12891.859600067139, "episode/length": 288.0, "episode/score": 0.11937999276602795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11937999276602795}
{"step": 393056, "time": 12905.471212387085, "episode/length": 288.0, "episode/score": 0.1054398725085548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1054398725085548}
{"step": 393232, "time": 12911.542221069336, "episode/length": 288.0, "episode/score": 0.10388818703972902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10388818703972902}
{"step": 393992, "time": 12935.275936365128, "episode/length": 288.0, "episode/score": 0.07828351134048717, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07828351134048717}
{"step": 394160, "time": 12940.75086426735, "episode/length": 288.0, "episode/score": 0.08678186990698578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08678186990698578}
{"step": 394176, "time": 12941.258964776993, "episode/length": 288.0, "episode/score": 0.08486192069835852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08486192069835852}
{"step": 394568, "time": 12953.331031799316, "episode/length": 288.0, "episode/score": 0.1126916991690905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1126916991690905}
{"step": 394920, "time": 12964.421885251999, "episode/length": 288.0, "episode/score": 0.0654493167136252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0654493167136252}
{"step": 394944, "time": 12965.401768684387, "episode/length": 288.0, "episode/score": 0.07611140524761595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07611140524761595}
{"step": 395368, "time": 12978.702204227448, "episode/length": 288.0, "episode/score": 0.052243293708670535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052243293708670535}
{"step": 395544, "time": 12984.27657699585, "episode/length": 288.0, "episode/score": 0.060265563785492304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060265563785492304}
{"step": 395824, "time": 12993.405548334122, "episode/length": 112.0, "episode/score": 0.6800422858104866, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.030042281014175387}
{"step": 395832, "time": 12993.441941738129, "episode/length": 208.0, "episode/score": 0.389455734086539, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.039455740861910726}
{"step": 395976, "time": 12997.955851316452, "episode/length": 53.0, "episode/score": 0.8586371029338693, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.024262079906918643}
{"step": 396304, "time": 13008.44645857811, "episode/length": 288.0, "episode/score": 0.07060575177860073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07060575177860073}
{"step": 396488, "time": 13014.044342279434, "episode/length": 288.0, "episode/score": 0.06295302304675943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06295302304675943}
{"step": 396512, "time": 13015.02966761589, "episode/length": 25.0, "episode/score": 0.9289252340200278, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.007050210678755775}
{"step": 396880, "time": 13026.673424243927, "episode/length": 288.0, "episode/score": 0.06638784047527224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06638784047527224}
{"step": 397136, "time": 13034.84297323227, "episode/length": 31.0, "episode/score": 0.9154190539365459, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.012294036462606073}
{"step": 397256, "time": 13038.416440963745, "episode/length": 288.0, "episode/score": 0.06928675244341775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06928675244341775}
{"step": 397680, "time": 13052.148165464401, "episode/length": 288.0, "episode/score": 0.042272934826939945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042272934826939945}
{"step": 398136, "time": 13066.346705913544, "episode/length": 288.0, "episode/score": 0.04863471368668115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04863471368668115}
{"step": 398144, "time": 13066.825315952301, "episode/length": 288.0, "episode/score": 0.0569205756635256, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0569205756635256}
{"step": 398288, "time": 13071.340620279312, "episode/length": 288.0, "episode/score": 0.03667091566194358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03667091566194358}
{"step": 398304, "time": 13071.84958934784, "episode/length": 130.0, "episode/score": 0.6384875870598989, "episode/reward_rate": 0.007633587786259542, "episode/intrinsic_return": 0.04473755766503018}
{"step": 398536, "time": 13079.01160120964, "episode/length": 106.0, "episode/score": 0.7000960769559015, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.031346060238661266}
{"step": 398632, "time": 13082.032972574234, "episode/length": 42.0, "episode/score": 0.8845724265232775, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.015822443205593117}
{"step": 398800, "time": 13087.50100183487, "episode/length": 288.0, "episode/score": 0.036070903984693814, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036070903984693814}
{"step": 398808, "time": 13087.537287473679, "episode/length": 83.0, "episode/score": 0.7650481882624831, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.024423182552311573}
{"step": 398824, "time": 13088.041321277618, "episode/length": 288.0, "episode/score": 0.041198580889385994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041198580889385994}
{"step": 399048, "time": 13095.070936918259, "episode/length": 51.0, "episode/score": 0.8659917928390826, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.025366824899862195}
{"step": 399208, "time": 13100.079400777817, "episode/length": 19.0, "episode/score": 0.9476710850992163, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.007046058859202731}
{"step": 399232, "time": 13101.050274848938, "episode/length": 52.0, "episode/score": 0.8545484945707358, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.0170485335174817}
{"step": 399256, "time": 13101.586685180664, "episode/length": 53.0, "episode/score": 0.8517898204680137, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01741479253706757}
{"step": 399448, "time": 13107.616104841232, "episode/length": 288.0, "episode/score": 0.0399491657242379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0399491657242379}
{"step": 400088, "time": 13128.458095788956, "eval_episode/length": 39.0, "eval_episode/score": 0.878125011920929, "eval_episode/reward_rate": 0.025}
{"step": 400088, "time": 13129.335669517517, "eval_episode/length": 87.0, "eval_episode/score": 0.7281249761581421, "eval_episode/reward_rate": 0.011363636363636364}
{"step": 400088, "time": 13130.04920721054, "eval_episode/length": 125.0, "eval_episode/score": 0.609375, "eval_episode/reward_rate": 0.007936507936507936}
{"step": 400088, "time": 13130.336823940277, "eval_episode/length": 51.0, "eval_episode/score": 0.840624988079071, "eval_episode/reward_rate": 0.019230769230769232}
{"step": 400088, "time": 13131.90170431137, "eval_episode/length": 224.0, "eval_episode/score": 0.30000001192092896, "eval_episode/reward_rate": 0.0044444444444444444}
{"step": 400088, "time": 13133.0459690094, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13133.055430412292, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13133.06202840805, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400088, "time": 13133.06848025322, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 400456, "time": 13144.702940940857, "episode/length": 288.0, "episode/score": 0.0386491035539791, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0386491035539791}
{"step": 400616, "time": 13149.705801010132, "episode/length": 288.0, "episode/score": 0.047634270164905956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047634270164905956}
{"step": 400848, "time": 13157.193870544434, "episode/length": 288.0, "episode/score": 0.03818267196874103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03818267196874103}
{"step": 401112, "time": 13165.340815544128, "episode/length": 288.0, "episode/score": 0.046825444917288905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046825444917288905}
{"step": 401520, "time": 13179.058468818665, "episode/length": 288.0, "episode/score": 0.04364803234548731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04364803234548731}
{"step": 401544, "time": 13179.59991145134, "episode/length": 288.0, "episode/score": 0.06856317491369168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06856317491369168}
{"step": 401568, "time": 13180.599286556244, "episode/length": 288.0, "episode/score": 0.039703665187943216, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039703665187943216}
{"step": 401760, "time": 13186.62778878212, "episode/length": 288.0, "episode/score": 0.03572954446741505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03572954446741505}
{"step": 401832, "time": 13188.67094874382, "episode/length": 122.0, "episode/score": 0.6551847715406609, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.036434766744349645}
{"step": 402768, "time": 13218.514573335648, "episode/length": 288.0, "episode/score": 0.05451020313753929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05451020313753929}
{"step": 402928, "time": 13223.636276960373, "episode/length": 288.0, "episode/score": 0.06607899735968203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06607899735968203}
{"step": 403385, "time": 13239.047433376312, "train_stats/mean_log_entropy": 0.14212886533089752, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 1.9403655062016754, "train/action_min": 0.0, "train/action_std": 1.1383968825192796, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.004769060545908191, "train/actor_opt_grad_steps": 24145.0, "train/actor_opt_loss": -5.913895732118297, "train/adv_mag": 0.41316145458786757, "train/adv_max": 0.21625132167462222, "train/adv_mean": -0.0007702575234942901, "train/adv_min": -0.36423875468293415, "train/adv_std": 0.01661106448538947, "train/cont_avg": 0.9964058472938144, "train/cont_loss_mean": 0.012694140079493644, "train/cont_loss_std": 0.20759604194383954, "train/cont_neg_acc": 0.37793899335277575, "train/cont_neg_loss": 2.878408008053763, "train/cont_pos_acc": 0.9998028957352196, "train/cont_pos_loss": 0.002537844391160443, "train/cont_pred": 0.9963360699181704, "train/cont_rate": 0.9964058472938144, "train/dyn_loss_mean": 1.0000057423237674, "train/dyn_loss_std": 0.0001654281725293294, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.3248305561299407, "train/extr_critic_critic_opt_grad_steps": 24145.0, "train/extr_critic_critic_opt_loss": 12894.224342582153, "train/extr_critic_mag": 0.5202232623837658, "train/extr_critic_max": 0.5202232623837658, "train/extr_critic_mean": 0.48113776912394257, "train/extr_critic_min": 0.47072525122731, "train/extr_critic_std": 0.005702044319159822, "train/extr_return_normed_mag": 0.41312089900380555, "train/extr_return_normed_max": 0.24225703327311682, "train/extr_return_normed_mean": 0.010327485313169259, "train/extr_return_normed_min": -0.34429448382141664, "train/extr_return_normed_std": 0.01759000695262527, "train/extr_return_rate": 0.31752746452428293, "train/extr_return_raw_mag": 0.7122970352467802, "train/extr_return_raw_max": 0.7122970352467802, "train/extr_return_raw_mean": 0.4803675107427479, "train/extr_return_raw_min": 0.12574551723052546, "train/extr_return_raw_std": 0.017590006913020054, "train/extr_reward_mag": 0.27801686894033373, "train/extr_reward_max": 0.27801686894033373, "train/extr_reward_mean": 0.0010600542796196022, "train/extr_reward_min": 3.562145626422056e-06, "train/extr_reward_std": 0.0064289566269264435, "train/image_loss_mean": 0.11434071284440375, "train/image_loss_std": 0.10555911909059151, "train/model_loss_mean": 0.7381048101125304, "train/model_loss_std": 0.2847059089882472, "train/model_opt_grad_norm": 27.933451460808822, "train/model_opt_grad_steps": 24121.963917525773, "train/model_opt_loss": 2858.6601291931784, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3878.865979381443, "train/policy_entropy_mag": 1.3429756588542585, "train/policy_entropy_max": 1.3429756588542585, "train/policy_entropy_mean": 0.15233191913089802, "train/policy_entropy_min": 0.06468700698202419, "train/policy_entropy_std": 0.18935632790179596, "train/policy_logprob_mag": 6.551079541137538, "train/policy_logprob_max": -0.00860827142065487, "train/policy_logprob_mean": -0.15212263769863807, "train/policy_logprob_min": -6.551079541137538, "train/policy_logprob_std": 0.6843235578733621, "train/policy_randomness_mag": 0.6901530064258379, "train/policy_randomness_max": 0.6901530064258379, "train/policy_randomness_mean": 0.07828312432489444, "train/policy_randomness_min": 0.03324254738531776, "train/policy_randomness_std": 0.0973099089928509, "train/post_ent_mag": 40.59404597331568, "train/post_ent_max": 40.59404597331568, "train/post_ent_mean": 39.726033456546745, "train/post_ent_min": 39.12588217823776, "train/post_ent_std": 0.25759365394250633, "train/prior_ent_mag": 41.709281115187814, "train/prior_ent_max": 41.709281115187814, "train/prior_ent_mean": 38.753842402979274, "train/prior_ent_min": 36.36501288659794, "train/prior_ent_std": 0.9287772731682689, "train/rep_loss_mean": 1.0000057423237674, "train/rep_loss_std": 0.0001654281725293294, "train/reward_avg": 0.0005465840836269805, "train/reward_loss_mean": 0.01106648868881166, "train/reward_loss_std": 0.07174445866347895, "train/reward_max_data": 0.2807480114231309, "train/reward_max_pred": 0.11442158209908869, "train/reward_neg_acc": 0.9999193942423948, "train/reward_neg_loss": 0.008840926913256497, "train/reward_pos_acc": 0.382530121200056, "train/reward_pos_loss": 3.8833310769264955, "train/reward_pred": 0.0004546852439123484, "train/reward_rate": 0.0005839239690721649, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.004650593269616365, "report/cont_loss_std": 0.09308047592639923, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 1.4919945001602173, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0017399400239810348, "report/cont_pred": 0.9972687363624573, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.11612721532583237, "report/image_loss_std": 0.11002049595117569, "report/model_loss_mean": 0.7296905517578125, "report/model_loss_std": 0.14755681157112122, "report/post_ent_mag": 39.83681106567383, "report/post_ent_max": 39.83681106567383, "report/post_ent_mean": 38.88697814941406, "report/post_ent_min": 38.298648834228516, "report/post_ent_std": 0.2718483805656433, "report/prior_ent_mag": 40.76008605957031, "report/prior_ent_max": 40.76008605957031, "report/prior_ent_mean": 37.45070266723633, "report/prior_ent_min": 35.191001892089844, "report/prior_ent_std": 0.8739500641822815, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00020168692572042346, "report/reward_loss_mean": 0.00891274306923151, "report/reward_loss_std": 0.015057827346026897, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.005181550979614258, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00891274306923151, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002325443783774972, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03635384514927864, "eval/cont_loss_std": 0.6383209228515625, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 11.778656005859375, "eval/cont_pos_acc": 0.999020516872406, "eval/cont_pos_loss": 0.001851490931585431, "eval/cont_pred": 0.9983920454978943, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2108432650566101, "eval/image_loss_std": 0.14578546583652496, "eval/model_loss_mean": 0.860237717628479, "eval/model_loss_std": 0.944421112537384, "eval/post_ent_mag": 39.83580780029297, "eval/post_ent_max": 39.83580780029297, "eval/post_ent_mean": 38.871978759765625, "eval/post_ent_min": 38.27032470703125, "eval/post_ent_std": 0.2675599455833435, "eval/prior_ent_mag": 40.93421173095703, "eval/prior_ent_max": 40.93421173095703, "eval/prior_ent_mean": 37.386497497558594, "eval/prior_ent_min": 35.45674514770508, "eval/prior_ent_std": 0.9784480929374695, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0005889892345294356, "eval/reward_loss_mean": 0.013040631078183651, "eval/reward_loss_std": 0.3787919580936432, "eval/reward_max_data": 0.6031249761581421, "eval/reward_max_pred": 0.0015548467636108398, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001197697944007814, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 12.128361701965332, "eval/reward_pred": 0.00019592535682022572, "eval/reward_rate": 0.0009765625, "replay/size": 402881.0, "replay/inserts": 31024.0, "replay/samples": 31024.0, "replay/insert_wait_avg": 1.2632326836313029e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.639721792220086e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95472.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1160574432337848e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4187204837799, "timer/env.step_count": 3878.0, "timer/env.step_total": 36.657819509506226, "timer/env.step_frac": 0.03664247655399664, "timer/env.step_avg": 0.009452764185019656, "timer/env.step_min": 0.007732391357421875, "timer/env.step_max": 0.035746097564697266, "timer/replay._sample_count": 31024.0, "timer/replay._sample_total": 15.617778778076172, "timer/replay._sample_frac": 0.015611242031260438, "timer/replay._sample_avg": 0.0005034095789735744, "timer/replay._sample_min": 0.0003571510314941406, "timer/replay._sample_max": 0.02655792236328125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4745.0, "timer/agent.policy_total": 48.03273582458496, "timer/agent.policy_frac": 0.04801263195210643, "timer/agent.policy_avg": 0.010122810500439401, "timer/agent.policy_min": 0.00847005844116211, "timer/agent.policy_max": 0.08486151695251465, "timer/dataset_train_count": 1939.0, "timer/dataset_train_total": 0.22058796882629395, "timer/dataset_train_frac": 0.00022049564278407604, "timer/dataset_train_avg": 0.00011376377969380812, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.00045752525329589844, "timer/agent.train_count": 1939.0, "timer/agent.train_total": 864.1542327404022, "timer/agent.train_frac": 0.8637925451080292, "timer/agent.train_avg": 0.44567005298628276, "timer/agent.train_min": 0.4342689514160156, "timer/agent.train_max": 0.6046855449676514, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47797060012817383, "timer/agent.report_frac": 0.0004777705478132577, "timer/agent.report_avg": 0.23898530006408691, "timer/agent.report_min": 0.23361849784851074, "timer/agent.report_max": 0.24435210227966309, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.384126820022935e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 31.01039250369434}
{"step": 403424, "time": 13240.27640080452, "episode/length": 288.0, "episode/score": 0.041100826324282025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041100826324282025}
{"step": 403424, "time": 13240.283292770386, "episode/length": 61.0, "episode/score": 0.822167467402096, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.012792480137932216}
{"step": 403832, "time": 13252.86978650093, "episode/length": 288.0, "episode/score": 0.06225272154983941, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06225272154983941}
{"step": 403856, "time": 13253.84993314743, "episode/length": 288.0, "episode/score": 0.040510525881927606, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040510525881927606}
{"step": 403880, "time": 13254.38800406456, "episode/length": 288.0, "episode/score": 0.05094495979460589, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05094495979460589}
{"step": 404072, "time": 13260.499954223633, "episode/length": 288.0, "episode/score": 0.02134605915296106, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02134605915296106}
{"step": 404144, "time": 13262.984208583832, "episode/length": 288.0, "episode/score": 0.044508720854992134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044508720854992134}
{"step": 404424, "time": 13271.611783981323, "episode/length": 73.0, "episode/score": 0.7978569343165418, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.025981896155599316}
{"step": 404584, "time": 13276.70078086853, "episode/length": 63.0, "episode/score": 0.8232204622659083, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.02009540902918161}
{"step": 405080, "time": 13292.451960086823, "episode/length": 288.0, "episode/score": 0.03599957637948137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03599957637948137}
{"step": 405736, "time": 13313.070683002472, "episode/length": 288.0, "episode/score": 0.05228302936438922, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05228302936438922}
{"step": 405736, "time": 13313.079098463058, "episode/length": 288.0, "episode/score": 0.03012456740543712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03012456740543712}
{"step": 406168, "time": 13326.717797756195, "episode/length": 288.0, "episode/score": 0.03796997198310237, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03796997198310237}
{"step": 406192, "time": 13327.711960554123, "episode/length": 288.0, "episode/score": 0.031229087284032175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031229087284032175}
{"step": 406456, "time": 13335.76019692421, "episode/length": 288.0, "episode/score": 0.03354128452599525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03354128452599525}
{"step": 406608, "time": 13340.744390249252, "episode/length": 51.0, "episode/score": 0.8635400263442534, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.022915008870313613}
{"step": 406736, "time": 13344.763882398605, "episode/length": 288.0, "episode/score": 0.02814190413596407, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02814190413596407}
{"step": 406896, "time": 13349.889479160309, "episode/length": 288.0, "episode/score": 0.03985923489642573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03985923489642573}
{"step": 406984, "time": 13352.403795480728, "episode/length": 65.0, "episode/score": 0.8252813949633264, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.028406386785150062}
{"step": 407216, "time": 13359.904861688614, "episode/length": 75.0, "episode/score": 0.78675685429846, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.02113187443831066}
{"step": 407264, "time": 13361.406881332397, "episode/length": 65.0, "episode/score": 0.8197042320281867, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.02282925216803733}
{"step": 407392, "time": 13365.446426391602, "episode/length": 288.0, "episode/score": 0.06344559728540844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06344559728540844}
{"step": 407688, "time": 13374.517355680466, "episode/length": 58.0, "episode/score": 0.8406635720898521, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.02191356637968056}
{"step": 407768, "time": 13377.028532743454, "episode/length": 97.0, "episode/score": 0.7217887836108048, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.024913822557550702}
{"step": 408048, "time": 13386.180769443512, "episode/length": 288.0, "episode/score": 0.02286201484940875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02286201484940875}
{"step": 408048, "time": 13386.189218044281, "episode/length": 288.0, "episode/score": 0.06369016084312307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06369016084312307}
{"step": 408480, "time": 13399.715931653976, "episode/length": 288.0, "episode/score": 0.061963624865995826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061963624865995826}
{"step": 409208, "time": 13422.430937290192, "episode/length": 288.0, "episode/score": 0.03962917021630119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03962917021630119}
{"step": 409576, "time": 13434.031406402588, "episode/length": 288.0, "episode/score": 0.05329839825537874, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05329839825537874}
{"step": 409704, "time": 13438.577530145645, "episode/length": 288.0, "episode/score": 0.05558279525968146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05558279525968146}
{"step": 410000, "time": 13448.219830036163, "episode/length": 288.0, "episode/score": 0.027735405825580983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027735405825580983}
{"step": 410072, "time": 13450.698067426682, "eval_episode/length": 22.0, "eval_episode/score": 0.9312499761581421, "eval_episode/reward_rate": 0.043478260869565216}
{"step": 410072, "time": 13451.727944374084, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 410072, "time": 13451.867289304733, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 410072, "time": 13451.892462968826, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 410072, "time": 13453.0997672081, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 410072, "time": 13455.409413099289, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13455.418888568878, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13455.42584681511, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13455.432396888733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410072, "time": 13455.439173698425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 410080, "time": 13455.917505025864, "episode/length": 288.0, "episode/score": 0.01867391573250643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01867391573250643}
{"step": 410080, "time": 13455.925873994827, "episode/length": 253.0, "episode/score": 0.24642573211013996, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.03705073923475766}
{"step": 410224, "time": 13460.485603094101, "episode/length": 80.0, "episode/score": 0.7754699879865825, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.025470003091470517}
{"step": 410360, "time": 13464.562222957611, "episode/length": 288.0, "episode/score": 0.06019018310047386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06019018310047386}
{"step": 410568, "time": 13471.2223341465, "episode/length": 25.0, "episode/score": 0.9353405823130174, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.013465605421458804}
{"step": 410664, "time": 13474.254022598267, "episode/length": 72.0, "episode/score": 0.8016809901268402, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.026681014783605406}
{"step": 410712, "time": 13475.78872704506, "episode/length": 60.0, "episode/score": 0.8376654827060861, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.02516546838700151}
{"step": 410792, "time": 13478.326701164246, "episode/length": 288.0, "episode/score": 0.05346588768622951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05346588768622951}
{"step": 411520, "time": 13501.646042823792, "episode/length": 288.0, "episode/score": 0.02097460852507993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02097460852507993}
{"step": 412016, "time": 13517.301715373993, "episode/length": 288.0, "episode/score": 0.019133102040655103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019133102040655103}
{"step": 412312, "time": 13526.474069356918, "episode/length": 288.0, "episode/score": 0.023823882020536757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023823882020536757}
{"step": 412392, "time": 13529.09088897705, "episode/length": 288.0, "episode/score": 0.027176001146813178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027176001146813178}
{"step": 412608, "time": 13536.130240440369, "episode/length": 73.0, "episode/score": 0.7863786311652063, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.014503619401438073}
{"step": 412880, "time": 13544.607278108597, "episode/length": 288.0, "episode/score": 0.040100753655735843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040100753655735843}
{"step": 412976, "time": 13547.606595277786, "episode/length": 288.0, "episode/score": 0.030030827022869744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030030827022869744}
{"step": 412976, "time": 13547.614305973053, "episode/length": 72.0, "episode/score": 0.7896827054384232, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.014682741358370777}
{"step": 413024, "time": 13549.106922149658, "episode/length": 288.0, "episode/score": 0.01366812851321697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01366812851321697}
{"step": 413104, "time": 13551.617116212845, "episode/length": 288.0, "episode/score": 0.02120119869488235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02120119869488235}
{"step": 413168, "time": 13553.626759529114, "episode/length": 69.0, "episode/score": 0.8080408963287198, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.023665898566804344}
{"step": 413832, "time": 13574.27150797844, "episode/length": 288.0, "episode/score": 0.04682026793284422, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04682026793284422}
{"step": 414040, "time": 13580.758143663406, "episode/length": 126.0, "episode/score": 0.634958235666204, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.02870826174614649}
{"step": 414480, "time": 13594.841952562332, "episode/length": 163.0, "episode/score": 0.5266875481834745, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.036062564213864334}
{"step": 414592, "time": 13598.358637809753, "episode/length": 68.0, "episode/score": 0.8111897013015437, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.023689648064816993}
{"step": 414624, "time": 13599.36109828949, "episode/length": 288.0, "episode/score": 0.03444157722054797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03444157722054797}
{"step": 415128, "time": 13614.889962911606, "episode/length": 62.0, "episode/score": 0.8204195419758946, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.014169536422883766}
{"step": 415192, "time": 13616.911357879639, "episode/length": 288.0, "episode/score": 0.025757960552823533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025757960552823533}
{"step": 415288, "time": 13619.986900091171, "episode/length": 288.0, "episode/score": 0.018171993533428576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018171993533428576}
{"step": 415288, "time": 13619.995053768158, "episode/length": 288.0, "episode/score": 0.010284184398642537, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010284184398642537}
{"step": 415416, "time": 13623.994534492493, "episode/length": 288.0, "episode/score": 0.03449489325359423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03449489325359423}
{"step": 415560, "time": 13628.507249116898, "episode/length": 120.0, "episode/score": 0.6589189025098392, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.03391889535029691}
{"step": 415744, "time": 13634.516164302826, "episode/length": 56.0, "episode/score": 0.8418316490049449, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.016831669991717035}
{"step": 416144, "time": 13647.114033699036, "episode/length": 288.0, "episode/score": 0.017073801227297736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017073801227297736}
{"step": 416400, "time": 13655.22919178009, "episode/length": 104.0, "episode/score": 0.6996081419738118, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.024608115733798286}
{"step": 416400, "time": 13655.235653877258, "episode/length": 31.0, "episode/score": 0.9173731261516878, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.014248114731344685}
{"step": 416792, "time": 13667.394381046295, "episode/length": 288.0, "episode/score": 0.029340838159669147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029340838159669147}
{"step": 416896, "time": 13670.879313468933, "episode/length": 61.0, "episode/score": 0.8397698041485455, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.030394787431305303}
{"step": 417016, "time": 13674.464086532593, "episode/length": 76.0, "episode/score": 0.7945961411005555, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.03209612968021247}
{"step": 417440, "time": 13688.044543504715, "episode/length": 288.0, "episode/score": 0.01740803838029592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01740803838029592}
{"step": 417456, "time": 13688.54945230484, "episode/length": 54.0, "episode/score": 0.854100410752153, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.0228503845121395}
{"step": 417504, "time": 13690.050520420074, "episode/length": 288.0, "episode/score": 0.030880424303120435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030880424303120435}
{"step": 417600, "time": 13693.066050291061, "episode/length": 288.0, "episode/score": 0.04875972028654019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04875972028654019}
{"step": 417728, "time": 13697.064782857895, "episode/length": 288.0, "episode/score": 0.02210478415472039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02210478415472039}
{"step": 418056, "time": 13707.550198793411, "episode/length": 288.0, "episode/score": 0.04390914387425937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04390914387425937}
{"step": 418248, "time": 13713.663296937943, "episode/length": 80.0, "episode/score": 0.7706208583028911, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.020620850124714707}
{"step": 418576, "time": 13724.138760566711, "episode/length": 105.0, "episode/score": 0.6813027684396502, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.009427745098378182}
{"step": 418648, "time": 13726.17149233818, "episode/length": 231.0, "episode/score": 0.3199551014510007, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.0418301051937533}
{"step": 418920, "time": 13734.741336584091, "episode/length": 182.0, "episode/score": 0.4595155458117688, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.02826553269176202}
{"step": 419032, "time": 13738.263788938522, "episode/length": 97.0, "episode/score": 0.7334355006727264, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.03656049587641519}
{"step": 419208, "time": 13743.899389982224, "episode/length": 288.0, "episode/score": 0.029001505773976533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029001505773976533}
{"step": 419608, "time": 13756.407021045685, "episode/length": 270.0, "episode/score": 0.21759293986531247, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.061342940680219726}
{"step": 419616, "time": 13756.886114120483, "episode/length": 263.0, "episode/score": 0.2295097584690211, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.05138477089053595}
{"step": 419640, "time": 13757.440865516663, "episode/length": 75.0, "episode/score": 0.7763335620104499, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.01070853866917787}
{"step": 419664, "time": 13758.422125577927, "episode/length": 92.0, "episode/score": 0.7300279154637792, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.017527909910768358}
{"step": 419864, "time": 13764.475496530533, "episode/length": 31.0, "episode/score": 0.9115210105455844, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.008395993071644625}
{"step": 419944, "time": 13766.984115839005, "episode/length": 235.0, "episode/score": 0.32380458247428123, "episode/reward_rate": 0.00423728813559322, "episode/intrinsic_return": 0.058179588935331594}
{"step": 420056, "time": 13773.407362937927, "eval_episode/length": 119.0, "eval_episode/score": 0.628125011920929, "eval_episode/reward_rate": 0.008333333333333333}
{"step": 420056, "time": 13773.651770353317, "eval_episode/length": 132.0, "eval_episode/score": 0.5874999761581421, "eval_episode/reward_rate": 0.007518796992481203}
{"step": 420056, "time": 13775.419562578201, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 420056, "time": 13776.338993787766, "eval_episode/length": 50.0, "eval_episode/score": 0.84375, "eval_episode/reward_rate": 0.0196078431372549}
{"step": 420056, "time": 13776.418526172638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13776.426122665405, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13776.432842254639, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13776.439513206482, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13776.44847536087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420056, "time": 13776.453842163086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 420208, "time": 13781.418614149094, "episode/length": 42.0, "episode/score": 0.8763909431668253, "episode/reward_rate": 0.023255813953488372, "episode/intrinsic_return": 0.007640959849140927}
{"step": 420888, "time": 13802.64616727829, "episode/length": 288.0, "episode/score": 0.017658568638353245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017658568638353245}
{"step": 420960, "time": 13805.152349472046, "episode/length": 288.0, "episode/score": 0.03189805812985469, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03189805812985469}
{"step": 421088, "time": 13809.18670129776, "episode/length": 109.0, "episode/score": 0.6762446672523765, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.01686967547129825}
{"step": 421520, "time": 13822.698930740356, "episode/length": 288.0, "episode/score": 0.026698458557916638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026698458557916638}
{"step": 421928, "time": 13835.399840831757, "episode/length": 288.0, "episode/score": 0.033756062474367354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033756062474367354}
{"step": 421952, "time": 13836.379848480225, "episode/length": 288.0, "episode/score": 0.022942233188814498, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022942233188814498}
{"step": 421976, "time": 13836.91454911232, "episode/length": 288.0, "episode/score": 0.012262196816209325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012262196816209325}
{"step": 422256, "time": 13845.918979644775, "episode/length": 288.0, "episode/score": 0.04448368432724692, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04448368432724692}
{"step": 422584, "time": 13855.943168878555, "episode/length": 211.0, "episode/score": 0.3829266890006693, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.04230170208575146}
{"step": 423272, "time": 13877.58245253563, "episode/length": 288.0, "episode/score": 0.02874090415741648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02874090415741648}
{"step": 423400, "time": 13881.64726305008, "episode/length": 288.0, "episode/score": 0.054467352178676265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054467352178676265}
{"step": 423832, "time": 13895.241106271744, "episode/length": 288.0, "episode/score": 0.03621884458493696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03621884458493696}
{"step": 424240, "time": 13908.224542856216, "episode/length": 288.0, "episode/score": 0.03260592093630521, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03260592093630521}
{"step": 424264, "time": 13908.759499073029, "episode/length": 288.0, "episode/score": 0.02954316379981492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02954316379981492}
{"step": 424288, "time": 13909.752625226974, "episode/length": 288.0, "episode/score": 0.03074198025746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03074198025746}
{"step": 424568, "time": 13918.332993745804, "episode/length": 288.0, "episode/score": 0.022405244881724684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022405244881724684}
{"step": 424896, "time": 13928.902408361435, "episode/length": 288.0, "episode/score": 0.04069404860041459, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04069404860041459}
{"step": 425584, "time": 13950.64309000969, "episode/length": 288.0, "episode/score": 0.032206966883677524, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032206966883677524}
{"step": 425712, "time": 13954.669999837875, "episode/length": 288.0, "episode/score": 0.022384483330483818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022384483330483818}
{"step": 426144, "time": 13968.721468448639, "episode/length": 288.0, "episode/score": 0.018896682327635972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018896682327635972}
{"step": 426552, "time": 13981.446869373322, "episode/length": 288.0, "episode/score": 0.040740771125115316, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040740771125115316}
{"step": 426576, "time": 13982.422523498535, "episode/length": 288.0, "episode/score": 0.022903507315504612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022903507315504612}
{"step": 426600, "time": 13982.961417198181, "episode/length": 288.0, "episode/score": 0.0365351936069942, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0365351936069942}
{"step": 426880, "time": 13991.931378364563, "episode/length": 288.0, "episode/score": 0.03181864629482334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03181864629482334}
{"step": 427208, "time": 14002.056394338608, "episode/length": 288.0, "episode/score": 0.0425921565889098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0425921565889098}
{"step": 427896, "time": 14023.745239257812, "episode/length": 288.0, "episode/score": 0.04000327277503857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04000327277503857}
{"step": 427976, "time": 14026.272327661514, "episode/length": 9.0, "episode/score": 0.9778640790697182, "episode/reward_rate": 0.1, "episode/intrinsic_return": 0.005989038510620048}
{"step": 428024, "time": 14027.774502754211, "episode/length": 288.0, "episode/score": 0.03948246671666311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03948246671666311}
{"step": 428456, "time": 14041.439438581467, "episode/length": 288.0, "episode/score": 0.04215003109277404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04215003109277404}
{"step": 428864, "time": 14054.416692495346, "episode/length": 288.0, "episode/score": 0.04494425261134438, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04494425261134438}
{"step": 428888, "time": 14054.952683210373, "episode/length": 288.0, "episode/score": 0.026577511133780263, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026577511133780263}
{"step": 428912, "time": 14055.944735765457, "episode/length": 288.0, "episode/score": 0.044114111027397485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044114111027397485}
{"step": 429192, "time": 14064.48830294609, "episode/length": 288.0, "episode/score": 0.02412545125781662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02412545125781662}
{"step": 429520, "time": 14075.150157690048, "episode/length": 288.0, "episode/score": 0.04517847950455689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04517847950455689}
{"step": 429688, "time": 14080.198459386826, "episode/length": 102.0, "episode/score": 0.7096362651323034, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.02838626033599212}
{"step": 430040, "time": 14095.859987974167, "eval_episode/length": 261.0, "eval_episode/score": 0.18437500298023224, "eval_episode/reward_rate": 0.003816793893129771}
{"step": 430040, "time": 14096.347887277603, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14096.354984045029, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14096.361999034882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14096.368062019348, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14096.374294281006, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14096.380438804626, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430040, "time": 14096.386694192886, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 430288, "time": 14104.5155646801, "episode/length": 288.0, "episode/score": 0.02322971639722482, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02322971639722482}
{"step": 430336, "time": 14106.025362730026, "episode/length": 288.0, "episode/score": 0.03030857543848242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03030857543848242}
{"step": 430768, "time": 14119.553131103516, "episode/length": 288.0, "episode/score": 0.034355775743676986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034355775743676986}
{"step": 430920, "time": 14124.066241502762, "episode/length": 153.0, "episode/score": 0.5563182501726942, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.03444322714574355}
{"step": 431200, "time": 14133.180342912674, "episode/length": 288.0, "episode/score": 0.04440080036602012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04440080036602012}
{"step": 431224, "time": 14133.726066350937, "episode/length": 288.0, "episode/score": 0.027350324780456958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027350324780456958}
{"step": 431504, "time": 14142.735682725906, "episode/length": 288.0, "episode/score": 0.039188757674878616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039188757674878616}
{"step": 431832, "time": 14152.808587551117, "episode/length": 288.0, "episode/score": 0.03688558878496906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03688558878496906}
{"step": 432440, "time": 14171.91963481903, "episode/length": 151.0, "episode/score": 0.5590398734544237, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.03091488619025995}
{"step": 432600, "time": 14176.936326742172, "episode/length": 288.0, "episode/score": 0.031760121045238066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031760121045238066}
{"step": 432600, "time": 14176.943774223328, "episode/length": 136.0, "episode/score": 0.6143689642370305, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.03936896183887484}
{"step": 432648, "time": 14178.438709497452, "episode/length": 288.0, "episode/score": 0.03453546693805265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03453546693805265}
{"step": 433080, "time": 14192.020020961761, "episode/length": 288.0, "episode/score": 0.024746280160343304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024746280160343304}
{"step": 433232, "time": 14197.008756637573, "episode/length": 288.0, "episode/score": 0.03080094156180735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03080094156180735}
{"step": 433512, "time": 14205.567071199417, "episode/length": 288.0, "episode/score": 0.03247607473116432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03247607473116432}
{"step": 433608, "time": 14208.581928253174, "episode/length": 125.0, "episode/score": 0.6361326585175675, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.02675763517629548}
{"step": 433784, "time": 14214.104393005371, "episode/length": 147.0, "episode/score": 0.5624212179913002, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.021796233654981734}
{"step": 434144, "time": 14225.70658159256, "episode/length": 288.0, "episode/score": 0.023925630593907954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023925630593907954}
{"step": 434264, "time": 14229.729781866074, "episode/length": 81.0, "episode/score": 0.7666798925890816, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.019804881168738575}
{"step": 434537, "time": 14239.333936214447, "train_stats/mean_log_entropy": 0.11782019944689798, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4453854291866985, "train/action_min": 0.0, "train/action_std": 1.2327515568488683, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0094240312374985, "train/actor_opt_grad_steps": 26090.0, "train/actor_opt_loss": -2.3196572915770304, "train/adv_mag": 0.5431085928892478, "train/adv_max": 0.3094092662517841, "train/adv_mean": 0.005933583804215185, "train/adv_min": -0.5238769642817669, "train/adv_std": 0.03492702509945211, "train/cont_avg": 0.9961137820512821, "train/cont_loss_mean": 0.011947818703722591, "train/cont_loss_std": 0.19814172440196554, "train/cont_neg_acc": 0.489699166794722, "train/cont_neg_loss": 2.39515151579484, "train/cont_pos_acc": 0.9998089267657353, "train/cont_pos_loss": 0.002299699935918817, "train/cont_pred": 0.9961218133950844, "train/cont_rate": 0.9961137820512821, "train/dyn_loss_mean": 1.000009422424512, "train/dyn_loss_std": 0.00030133645650960554, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.694599168957808, "train/extr_critic_critic_opt_grad_steps": 26090.0, "train/extr_critic_critic_opt_loss": 9829.764095052084, "train/extr_critic_mag": 0.6123582540414272, "train/extr_critic_max": 0.6123582540414272, "train/extr_critic_mean": 0.5682956797954364, "train/extr_critic_min": 0.5461865290617332, "train/extr_critic_std": 0.01064789225705541, "train/extr_return_normed_mag": 0.5354994951150356, "train/extr_return_normed_max": 0.35910980365215206, "train/extr_return_normed_mean": 0.03183172288580607, "train/extr_return_normed_min": -0.4941130838333032, "train/extr_return_normed_std": 0.03766364039709935, "train/extr_return_rate": 0.7691036053123147, "train/extr_return_raw_mag": 0.9015073537826538, "train/extr_return_raw_max": 0.9015073537826538, "train/extr_return_raw_mean": 0.574229302467444, "train/extr_return_raw_min": 0.04828446629719856, "train/extr_return_raw_std": 0.037663640614407946, "train/extr_reward_mag": 0.38794067578438, "train/extr_reward_max": 0.38794067578438, "train/extr_reward_mean": 0.002366397288054801, "train/extr_reward_min": 2.7198057908278246e-06, "train/extr_reward_std": 0.014940076254499264, "train/image_loss_mean": 0.10803372103434343, "train/image_loss_std": 0.1056925267745287, "train/model_loss_mean": 0.7309212421759581, "train/model_loss_std": 0.2804354658493629, "train/model_opt_grad_norm": 27.42010520054744, "train/model_opt_grad_steps": 26065.48205128205, "train/model_opt_loss": 3690.8569849258815, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5051.282051282052, "train/policy_entropy_mag": 1.3470168633338733, "train/policy_entropy_max": 1.3470168633338733, "train/policy_entropy_mean": 0.1378224878739088, "train/policy_entropy_min": 0.0646870066340153, "train/policy_entropy_std": 0.17362518860743595, "train/policy_logprob_mag": 6.551079823420598, "train/policy_logprob_max": -0.008608298643659322, "train/policy_logprob_mean": -0.13825687296115435, "train/policy_logprob_min": -6.551079823420598, "train/policy_logprob_std": 0.6748707835490887, "train/policy_randomness_mag": 0.6922297752820529, "train/policy_randomness_max": 0.6922297752820529, "train/policy_randomness_mean": 0.07082675231190828, "train/policy_randomness_min": 0.033242547321013914, "train/policy_randomness_std": 0.0892257021405758, "train/post_ent_mag": 38.239820881378954, "train/post_ent_max": 38.239820881378954, "train/post_ent_mean": 37.26010980850611, "train/post_ent_min": 36.612645036746294, "train/post_ent_std": 0.2986147177525056, "train/prior_ent_mag": 39.667798594939406, "train/prior_ent_max": 39.667798594939406, "train/prior_ent_mean": 36.206941966521434, "train/prior_ent_min": 33.95632438659668, "train/prior_ent_std": 0.9658234779651348, "train/rep_loss_mean": 1.000009422424512, "train/rep_loss_std": 0.00030133645650960554, "train/reward_avg": 0.00049541265799258, "train/reward_loss_mean": 0.010934024301763528, "train/reward_loss_std": 0.06833939981670716, "train/reward_max_data": 0.23647192054643082, "train/reward_max_pred": 0.115609038181794, "train/reward_neg_acc": 0.9999148295475886, "train/reward_neg_loss": 0.008830769799458675, "train/reward_pos_acc": 0.37688888947168986, "train/reward_pos_loss": 3.9595579663912455, "train/reward_pred": 0.000451005899753326, "train/reward_rate": 0.0005308493589743589, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.006733673624694347, "report/cont_loss_std": 0.17128045856952667, "report/cont_neg_acc": 0.5, "report/cont_neg_loss": 2.843052387237549, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0011831477750092745, "report/cont_pred": 0.9980231523513794, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09965647757053375, "report/image_loss_std": 0.1058659553527832, "report/model_loss_mean": 0.713808536529541, "report/model_loss_std": 0.20800691843032837, "report/post_ent_mag": 36.38994598388672, "report/post_ent_max": 36.38994598388672, "report/post_ent_mean": 35.37977981567383, "report/post_ent_min": 34.71950149536133, "report/post_ent_std": 0.30241289734840393, "report/prior_ent_mag": 37.740535736083984, "report/prior_ent_max": 37.740535736083984, "report/prior_ent_mean": 34.123497009277344, "report/prior_ent_min": 31.679019927978516, "report/prior_ent_std": 1.051501750946045, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00015918219287414104, "report/reward_loss_mean": 0.007418351247906685, "report/reward_loss_std": 0.012686639092862606, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.011574864387512207, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.007418351247906685, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002813120372593403, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.027256375178694725, "eval/cont_loss_std": 0.5116313695907593, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.048824310302734, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0007483415538445115, "eval/cont_pred": 0.9992566704750061, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.2708262801170349, "eval/image_loss_std": 0.16216370463371277, "eval/model_loss_mean": 0.899649977684021, "eval/model_loss_std": 0.528928816318512, "eval/post_ent_mag": 36.391082763671875, "eval/post_ent_max": 36.391082763671875, "eval/post_ent_mean": 35.36000061035156, "eval/post_ent_min": 34.78843688964844, "eval/post_ent_std": 0.2845672070980072, "eval/prior_ent_mag": 37.740535736083984, "eval/prior_ent_max": 37.740535736083984, "eval/prior_ent_mean": 34.01215744018555, "eval/prior_ent_min": 31.37645721435547, "eval/prior_ent_std": 1.0262335538864136, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001567329280078411, "eval/reward_loss_std": 0.0017239974113181233, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00189208984375, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001567329280078411, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025659590028226376, "eval/reward_rate": 0.0, "replay/size": 434033.0, "replay/inserts": 31152.0, "replay/samples": 31152.0, "replay/insert_wait_avg": 1.2484984209308517e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.91076460604675e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0663181577724294e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2688076496124, "timer/env.step_count": 3894.0, "timer/env.step_total": 36.693482637405396, "timer/env.step_frac": 0.03668362179925027, "timer/env.step_avg": 0.009423082341398407, "timer/env.step_min": 0.007523298263549805, "timer/env.step_max": 0.03993868827819824, "timer/replay._sample_count": 31152.0, "timer/replay._sample_total": 15.79593801498413, "timer/replay._sample_frac": 0.01579169308708199, "timer/replay._sample_avg": 0.000507060157132259, "timer/replay._sample_min": 0.00038170814514160156, "timer/replay._sample_max": 0.029468536376953125, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4761.0, "timer/agent.policy_total": 47.85585856437683, "timer/agent.policy_frac": 0.0478429980005339, "timer/agent.policy_avg": 0.01005164011014006, "timer/agent.policy_min": 0.008591890335083008, "timer/agent.policy_max": 0.08883190155029297, "timer/dataset_train_count": 1947.0, "timer/dataset_train_total": 0.2200641632080078, "timer/dataset_train_frac": 0.0002200050241745565, "timer/dataset_train_avg": 0.0001130273051915808, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.00041794776916503906, "timer/agent.train_count": 1947.0, "timer/agent.train_total": 863.7735865116119, "timer/agent.train_frac": 0.8635414599614168, "timer/agent.train_avg": 0.4436433418138736, "timer/agent.train_min": 0.4324018955230713, "timer/agent.train_max": 0.5790493488311768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4711298942565918, "timer/agent.report_frac": 0.0004710032849705991, "timer/agent.report_avg": 0.2355649471282959, "timer/agent.report_min": 0.2275683879852295, "timer/agent.report_max": 0.2435615062713623, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.4084694584884316e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 31.143098219083143}
{"step": 434752, "time": 14246.10085940361, "episode/length": 288.0, "episode/score": 0.029202820959511655, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029202820959511655}
{"step": 434824, "time": 14248.133425474167, "episode/length": 84.0, "episode/score": 0.7483704194881682, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.010870378172370465}
{"step": 434960, "time": 14252.748863697052, "episode/length": 288.0, "episode/score": 0.02263697967578082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02263697967578082}
{"step": 435344, "time": 14264.812096357346, "episode/length": 73.0, "episode/score": 0.7920458388161933, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.02017080781479308}
{"step": 435392, "time": 14266.322730779648, "episode/length": 288.0, "episode/score": 0.009168521708659227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.009168521708659227}
{"step": 435544, "time": 14270.854015827179, "episode/length": 288.0, "episode/score": 0.013094538352959262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013094538352959262}
{"step": 435608, "time": 14272.850959777832, "episode/length": 26.0, "episode/score": 0.9299826235012745, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.011232627244027071}
{"step": 435824, "time": 14279.982353448868, "episode/length": 288.0, "episode/score": 0.03884318199044401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03884318199044401}
{"step": 436024, "time": 14286.037549495697, "episode/length": 84.0, "episode/score": 0.7524526348653922, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.014952615784920908}
{"step": 436096, "time": 14288.502698421478, "episode/length": 288.0, "episode/score": 0.024619171651721672, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024619171651721672}
{"step": 436576, "time": 14303.648240566254, "episode/length": 288.0, "episode/score": 0.04345590244682285, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04345590244682285}
{"step": 437136, "time": 14321.262741088867, "episode/length": 288.0, "episode/score": 0.0376498767232647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0376498767232647}
{"step": 437272, "time": 14325.343050718307, "episode/length": 288.0, "episode/score": 0.021578642427186878, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021578642427186878}
{"step": 437512, "time": 14334.201450109482, "episode/length": 116.0, "episode/score": 0.660881027346619, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.02338105739923435}
{"step": 437856, "time": 14345.314212322235, "episode/length": 288.0, "episode/score": 0.025235081305282847, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025235081305282847}
{"step": 437920, "time": 14347.332329511642, "episode/length": 288.0, "episode/score": 0.01981081149526176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01981081149526176}
{"step": 438136, "time": 14353.867981433868, "episode/length": 288.0, "episode/score": 0.020351610475813686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020351610475813686}
{"step": 438336, "time": 14360.357192516327, "episode/length": 288.0, "episode/score": 0.028009736763067394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028009736763067394}
{"step": 438408, "time": 14362.425238132477, "episode/length": 288.0, "episode/score": 0.020422427175930125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020422427175930125}
{"step": 438624, "time": 14369.520986557007, "episode/length": 26.0, "episode/score": 0.927705286774966, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.008955316827581328}
{"step": 438656, "time": 14370.52498793602, "episode/length": 39.0, "episode/score": 0.8869595124747036, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.008834523662216043}
{"step": 438872, "time": 14377.094774723053, "episode/length": 30.0, "episode/score": 0.9195812778824006, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.013331269704224269}
{"step": 439096, "time": 14384.125772476196, "episode/length": 119.0, "episode/score": 0.6510128011680649, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.022887812355577353}
{"step": 439248, "time": 14389.131205320358, "episode/length": 46.0, "episode/score": 0.8717344756947796, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.015484507755559207}
{"step": 439448, "time": 14395.23975777626, "episode/length": 288.0, "episode/score": 0.010769221511722549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010769221511722549}
{"step": 439584, "time": 14399.912601709366, "episode/length": 288.0, "episode/score": 0.03949779659380681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03949779659380681}
{"step": 439616, "time": 14400.940009593964, "episode/length": 64.0, "episode/score": 0.8250074199274877, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.025007420084648402}
{"step": 439648, "time": 14401.97979593277, "episode/length": 49.0, "episode/score": 0.854953363843336, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.00807836608142054}
{"step": 439800, "time": 14406.581774711609, "episode/length": 22.0, "episode/score": 0.9467798442101127, "episode/reward_rate": 0.043478260869565216, "episode/intrinsic_return": 0.015529886183657027}
{"step": 439824, "time": 14407.573169231415, "episode/length": 288.0, "episode/score": 0.02860075812463947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02860075812463947}
{"step": 439992, "time": 14412.605845928192, "episode/length": 23.0, "episode/score": 0.9393285084602354, "episode/reward_rate": 0.041666666666666664, "episode/intrinsic_return": 0.011203502750063876}
{"step": 440024, "time": 14414.181879758835, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 440024, "time": 14414.4855260849, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 440024, "time": 14415.096140384674, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 440024, "time": 14415.12114238739, "eval_episode/length": 83.0, "eval_episode/score": 0.7406250238418579, "eval_episode/reward_rate": 0.011904761904761904}
{"step": 440024, "time": 14415.214488267899, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 440024, "time": 14415.34860610962, "eval_episode/length": 95.0, "eval_episode/score": 0.703125, "eval_episode/reward_rate": 0.010416666666666666}
{"step": 440024, "time": 14416.961757183075, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 440024, "time": 14417.07760477066, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 440160, "time": 14421.552896261215, "episode/length": 20.0, "episode/score": 0.9484378840077881, "episode/reward_rate": 0.047619047619047616, "episode/intrinsic_return": 0.010937910230339298}
{"step": 440160, "time": 14421.560143709183, "episode/length": 63.0, "episode/score": 0.8187235278141856, "episode/reward_rate": 0.015625, "episode/intrinsic_return": 0.015598475858027427}
{"step": 440168, "time": 14421.600058317184, "episode/length": 288.0, "episode/score": 0.030151027908829064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030151027908829064}
{"step": 440232, "time": 14423.602923870087, "episode/length": 288.0, "episode/score": 0.030479571952227502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030479571952227502}
{"step": 440592, "time": 14435.203976631165, "episode/length": 53.0, "episode/score": 0.8491545378063705, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.01477952906940061}
{"step": 440936, "time": 14445.80235528946, "episode/length": 96.0, "episode/score": 0.716416911182506, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.01641694024559115}
{"step": 440968, "time": 14446.808306217194, "episode/length": 288.0, "episode/score": 0.044257730586991784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044257730586991784}
{"step": 441728, "time": 14470.989493846893, "episode/length": 194.0, "episode/score": 0.42485097476371436, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.03110096295192477}
{"step": 441760, "time": 14471.999461174011, "episode/length": 288.0, "episode/score": 0.007798322909565059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007798322909565059}
{"step": 441896, "time": 14476.059341430664, "episode/length": 288.0, "episode/score": 0.02039679298607666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02039679298607666}
{"step": 442136, "time": 14483.574576854706, "episode/length": 288.0, "episode/score": 0.032904834384154924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032904834384154924}
{"step": 442168, "time": 14484.581167697906, "episode/length": 50.0, "episode/score": 0.8546662451274472, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.010916254193290342}
{"step": 442544, "time": 14497.215805053711, "episode/length": 288.0, "episode/score": 0.03256069793542338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03256069793542338}
{"step": 442768, "time": 14504.201032161713, "episode/length": 74.0, "episode/score": 0.7806733035338738, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.01192328752385663}
{"step": 442856, "time": 14506.74837756157, "episode/length": 119.0, "episode/score": 0.643822554865551, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.015697519727041254}
{"step": 442896, "time": 14508.221472740173, "episode/length": 43.0, "episode/score": 0.8757057611570076, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.01008074939323933}
{"step": 442904, "time": 14508.258234977722, "episode/length": 288.0, "episode/score": 0.0385889207474861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0385889207474861}
{"step": 443248, "time": 14519.404240369797, "episode/length": 288.0, "episode/score": 0.031807595214885964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031807595214885964}
{"step": 443280, "time": 14520.407200813293, "episode/length": 288.0, "episode/score": 0.038957505231351774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038957505231351774}
{"step": 443336, "time": 14521.956144332886, "episode/length": 54.0, "episode/score": 0.8402022438262975, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.008952208687787788}
{"step": 443376, "time": 14523.429355621338, "episode/length": 75.0, "episode/score": 0.7836628870385312, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.018037913261082394}
{"step": 443800, "time": 14536.48155450821, "episode/length": 57.0, "episode/score": 0.8307435263064775, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.008868564307348947}
{"step": 444040, "time": 14543.970957040787, "episode/length": 288.0, "episode/score": 0.026055668761543416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026055668761543416}
{"step": 444448, "time": 14557.062920570374, "episode/length": 288.0, "episode/score": 0.008495104297907119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.008495104297907119}
{"step": 445168, "time": 14579.685344219208, "episode/length": 288.0, "episode/score": 0.020934242618849908, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020934242618849908}
{"step": 445216, "time": 14581.190236330032, "episode/length": 288.0, "episode/score": 0.016312620503498465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016312620503498465}
{"step": 445440, "time": 14588.218308448792, "episode/length": 123.0, "episode/score": 0.6455994480008087, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.029974401909072412}
{"step": 445560, "time": 14591.772984743118, "episode/length": 288.0, "episode/score": 0.0492409748459437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0492409748459437}
{"step": 445592, "time": 14592.785680294037, "episode/length": 288.0, "episode/score": 0.006073959358687375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006073959358687375}
{"step": 445688, "time": 14595.782405853271, "episode/length": 288.0, "episode/score": 0.051309801516453035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051309801516453035}
{"step": 445712, "time": 14596.77927660942, "episode/length": 208.0, "episode/score": 0.3990843275727798, "episode/reward_rate": 0.004784688995215311, "episode/intrinsic_return": 0.04908434769225778}
{"step": 446112, "time": 14609.41788649559, "episode/length": 83.0, "episode/score": 0.7529207324221971, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.012295680466039016}
{"step": 446112, "time": 14609.42612028122, "episode/length": 288.0, "episode/score": 0.028119193522030628, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028119193522030628}
{"step": 446232, "time": 14612.97565150261, "episode/length": 64.0, "episode/score": 0.8124912310013315, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.012491217035858426}
{"step": 446304, "time": 14615.44866490364, "episode/length": 88.0, "episode/score": 0.7369563114916104, "episode/reward_rate": 0.011235955056179775, "episode/intrinsic_return": 0.011956304791908678}
{"step": 447480, "time": 14652.281680107117, "episode/length": 288.0, "episode/score": 0.021168641338817906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021168641338817906}
{"step": 447528, "time": 14653.801139831543, "episode/length": 288.0, "episode/score": 0.029969968322177465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029969968322177465}
{"step": 447720, "time": 14659.83626961708, "episode/length": 269.0, "episode/score": 0.18759381871679182, "episode/reward_rate": 0.003703703703703704, "episode/intrinsic_return": 0.02821882210447768}
{"step": 448000, "time": 14668.94245839119, "episode/length": 288.0, "episode/score": 0.030100209025860636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030100209025860636}
{"step": 448424, "time": 14682.017281293869, "episode/length": 288.0, "episode/score": 0.0414119726166291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0414119726166291}
{"step": 448424, "time": 14682.037557125092, "episode/length": 288.0, "episode/score": 0.028159969097757198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028159969097757198}
{"step": 448544, "time": 14686.118067026138, "episode/length": 288.0, "episode/score": 0.03937858018188933, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03937858018188933}
{"step": 448616, "time": 14688.175475358963, "episode/length": 288.0, "episode/score": 0.030950743955628468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030950743955628468}
{"step": 448936, "time": 14698.184097528458, "episode/length": 116.0, "episode/score": 0.6803651178437349, "episode/reward_rate": 0.008547008547008548, "episode/intrinsic_return": 0.042865101126494665}
{"step": 449184, "time": 14706.238472700119, "episode/length": 70.0, "episode/score": 0.8081310103073065, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.02688101112221375}
{"step": 449264, "time": 14708.759404420853, "episode/length": 89.0, "episode/score": 0.7533064462592165, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.031431405700118376}
{"step": 449464, "time": 14714.788681983948, "episode/length": 247.0, "episode/score": 0.2694959968120543, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.04137099201574301}
{"step": 449752, "time": 14723.804540634155, "episode/length": 70.0, "episode/score": 0.7971107189561053, "episode/reward_rate": 0.014084507042253521, "episode/intrinsic_return": 0.015860704637020717}
{"step": 449840, "time": 14726.796098470688, "episode/length": 288.0, "episode/score": 0.06316720626011829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06316720626011829}
{"step": 450000, "time": 14731.959941864014, "episode/length": 196.0, "episode/score": 0.43768567302367956, "episode/reward_rate": 0.005076142131979695, "episode/intrinsic_return": 0.050185670625523926}
{"step": 450008, "time": 14734.386324167252, "eval_episode/length": 121.0, "eval_episode/score": 0.621874988079071, "eval_episode/reward_rate": 0.00819672131147541}
{"step": 450008, "time": 14735.09599685669, "eval_episode/length": 157.0, "eval_episode/score": 0.5093749761581421, "eval_episode/reward_rate": 0.006329113924050633}
{"step": 450008, "time": 14735.695838212967, "eval_episode/length": 187.0, "eval_episode/score": 0.4156250059604645, "eval_episode/reward_rate": 0.005319148936170213}
{"step": 450008, "time": 14735.741199493408, "eval_episode/length": 189.0, "eval_episode/score": 0.40937501192092896, "eval_episode/reward_rate": 0.005263157894736842}
{"step": 450008, "time": 14738.10534119606, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 450008, "time": 14738.312760591507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14738.320265769958, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14738.326786279678, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450008, "time": 14738.33332657814, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 450032, "time": 14739.331784963608, "episode/length": 288.0, "episode/score": 0.04000882375163428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04000882375163428}
{"step": 450608, "time": 14757.827161073685, "episode/length": 142.0, "episode/score": 0.5981065970104282, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.04185660653320156}
{"step": 450736, "time": 14761.920817375183, "episode/length": 288.0, "episode/score": 0.04431286857203531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04431286857203531}
{"step": 450896, "time": 14766.964701890945, "episode/length": 244.0, "episode/score": 0.28108755516927886, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.043587558731587706}
{"step": 451128, "time": 14774.07349562645, "episode/length": 140.0, "episode/score": 0.6143839745373612, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.05188395119608913}
{"step": 451552, "time": 14787.59934592247, "episode/length": 213.0, "episode/score": 0.35985233997240584, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.025477331613785736}
{"step": 451576, "time": 14788.154868841171, "episode/length": 288.0, "episode/score": 0.05906819089494775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05906819089494775}
{"step": 451856, "time": 14797.261200904846, "episode/length": 227.0, "episode/score": 0.33733938434448874, "episode/reward_rate": 0.0043859649122807015, "episode/intrinsic_return": 0.04671436406493967}
{"step": 452064, "time": 14803.748765707016, "episode/length": 288.0, "episode/score": 0.05983834332749893, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05983834332749893}
{"step": 452152, "time": 14806.303206920624, "episode/length": 192.0, "episode/score": 0.4328271678115243, "episode/reward_rate": 0.0051813471502590676, "episode/intrinsic_return": 0.03282714753197524}
{"step": 452240, "time": 14809.287603139877, "episode/length": 187.0, "episode/score": 0.45852725331332067, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.042902253813906555}
{"step": 452408, "time": 14814.395483732224, "episode/length": 159.0, "episode/score": 0.5516087817852622, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.04848376168615687}
{"step": 452512, "time": 14817.891708135605, "episode/length": 33.0, "episode/score": 0.9100070705608232, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.013132017324096523}
{"step": 453208, "time": 14839.558536291122, "episode/length": 288.0, "episode/score": 0.06896853015416582, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06896853015416582}
{"step": 453704, "time": 14855.249299764633, "episode/length": 61.0, "episode/score": 0.8244202486632162, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.0150452372428731}
{"step": 453768, "time": 14857.289002656937, "episode/length": 276.0, "episode/score": 0.19947170584504192, "episode/reward_rate": 0.0036101083032490976, "episode/intrinsic_return": 0.06197170327226331}
{"step": 453816, "time": 14858.803225278854, "episode/length": 207.0, "episode/score": 0.40294198450578733, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.04981697138578056}
{"step": 453824, "time": 14859.280287742615, "episode/length": 219.0, "episode/score": 0.36989911586488233, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.05427409576577702}
{"step": 453888, "time": 14861.298151731491, "episode/length": 288.0, "episode/score": 0.05169662338539638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05169662338539638}
{"step": 454168, "time": 14869.86340880394, "episode/length": 288.0, "episode/score": 0.040152294810411604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040152294810411604}
{"step": 454640, "time": 14885.018770217896, "episode/length": 102.0, "episode/score": 0.7016299343376318, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.02037995000131332}
{"step": 454720, "time": 14887.540704965591, "episode/length": 288.0, "episode/score": 0.05213901649148056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05213901649148056}
{"step": 454824, "time": 14890.554616451263, "episode/length": 288.0, "episode/score": 0.056428473064443097, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056428473064443097}
{"step": 454992, "time": 14896.063257694244, "episode/length": 145.0, "episode/score": 0.5807326578674861, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03385767599917244}
{"step": 455744, "time": 14919.702053546906, "episode/length": 127.0, "episode/score": 0.6502886887034549, "episode/reward_rate": 0.0078125, "episode/intrinsic_return": 0.04716370538577053}
{"step": 456016, "time": 14928.32091641426, "episode/length": 288.0, "episode/score": 0.05376139042260775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05376139042260775}
{"step": 456080, "time": 14930.319158315659, "episode/length": 288.0, "episode/score": 0.05023488298294865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05023488298294865}
{"step": 456200, "time": 14933.87501502037, "episode/length": 288.0, "episode/score": 0.02202348231907081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02202348231907081}
{"step": 456480, "time": 14942.95887541771, "episode/length": 288.0, "episode/score": 0.04642837264947275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04642837264947275}
{"step": 456952, "time": 14957.649911165237, "episode/length": 288.0, "episode/score": 0.049946919991867844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049946919991867844}
{"step": 457096, "time": 14962.164138317108, "episode/length": 283.0, "episode/score": 0.1464962193123256, "episode/reward_rate": 0.0035211267605633804, "episode/intrinsic_return": 0.030871218404286083}
{"step": 457304, "time": 14968.75531077385, "episode/length": 288.0, "episode/score": 0.07361362627077028, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07361362627077028}
{"step": 457680, "time": 14980.722601890564, "episode/length": 207.0, "episode/score": 0.38748638793390455, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.03436138313759329}
{"step": 458056, "time": 14992.3620262146, "episode/length": 288.0, "episode/score": 0.04450763201955965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04450763201955965}
{"step": 458336, "time": 15001.47049856186, "episode/length": 154.0, "episode/score": 0.5596038910009611, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.04085387989493938}
{"step": 458392, "time": 15003.031748056412, "episode/length": 288.0, "episode/score": 0.03738013249062533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03738013249062533}
{"step": 458512, "time": 15007.02549290657, "episode/length": 288.0, "episode/score": 0.03584762831849275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03584762831849275}
{"step": 458792, "time": 15016.077944755554, "episode/length": 288.0, "episode/score": 0.03455182415962099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03455182415962099}
{"step": 458984, "time": 15022.139981031418, "episode/length": 73.0, "episode/score": 0.7937515881628769, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.021876565135926285}
{"step": 459192, "time": 15028.770542860031, "episode/length": 141.0, "episode/score": 0.5918182323615611, "episode/reward_rate": 0.007042253521126761, "episode/intrinsic_return": 0.03244322996340543}
{"step": 459264, "time": 15031.257337808609, "episode/length": 288.0, "episode/score": 0.04253372281812062, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04253372281812062}
{"step": 459616, "time": 15042.338113546371, "episode/length": 288.0, "episode/score": 0.04509787092683837, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04509787092683837}
{"step": 459992, "time": 15053.983840942383, "episode/length": 288.0, "episode/score": 0.04267015997550061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04267015997550061}
{"step": 460096, "time": 15058.5819876194, "eval_episode/length": 55.0, "eval_episode/score": 0.828125, "eval_episode/reward_rate": 0.017857142857142856}
{"step": 460096, "time": 15058.98528432846, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 460096, "time": 15058.9911839962, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 460096, "time": 15060.669678211212, "eval_episode/length": 92.0, "eval_episode/score": 0.7124999761581421, "eval_episode/reward_rate": 0.010752688172043012}
{"step": 460096, "time": 15060.93727517128, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 460096, "time": 15062.881277799606, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15062.888672828674, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15062.894960641861, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15062.90112566948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460096, "time": 15062.907915115356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 460648, "time": 15079.977484226227, "episode/length": 288.0, "episode/score": 0.042467239075676844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042467239075676844}
{"step": 460824, "time": 15085.468148469925, "episode/length": 288.0, "episode/score": 0.010681967084281041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010681967084281041}
{"step": 461104, "time": 15094.651607513428, "episode/length": 288.0, "episode/score": 0.01565119871014531, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01565119871014531}
{"step": 461296, "time": 15100.67074751854, "episode/length": 288.0, "episode/score": 0.03537036487733758, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03537036487733758}
{"step": 461504, "time": 15107.218128442764, "episode/length": 288.0, "episode/score": 0.03895048548804425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03895048548804425}
{"step": 461576, "time": 15109.270269870758, "episode/length": 288.0, "episode/score": 0.029668616699041195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029668616699041195}
{"step": 461744, "time": 15114.779914855957, "episode/length": 55.0, "episode/score": 0.8379418175714477, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.009816788176578939}
{"step": 461928, "time": 15120.456405162811, "episode/length": 288.0, "episode/score": 0.018997451914174235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018997451914174235}
{"step": 461944, "time": 15120.959662675858, "episode/length": 104.0, "episode/score": 0.6984894480587513, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.02348942181873781}
{"step": 462016, "time": 15123.417474031448, "episode/length": 33.0, "episode/score": 0.9036053149678764, "episode/reward_rate": 0.029411764705882353, "episode/intrinsic_return": 0.00673028294784217}
{"step": 462232, "time": 15129.962233543396, "episode/length": 90.0, "episode/score": 0.7318041962100779, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.013054188031901504}
{"step": 462304, "time": 15132.434620141983, "episode/length": 288.0, "episode/score": 0.040538481977648644, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040538481977648644}
{"step": 462576, "time": 15140.975923538208, "episode/length": 124.0, "episode/score": 0.6387861696887853, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.026286177907707042}
{"step": 462728, "time": 15145.520406007767, "episode/length": 52.0, "episode/score": 0.8558166048680391, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.018316605368625005}
{"step": 462832, "time": 15149.128710746765, "episode/length": 101.0, "episode/score": 0.7098002245874682, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.02542523672667585}
{"step": 462960, "time": 15153.14951467514, "episode/length": 288.0, "episode/score": 0.03501058560215142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03501058560215142}
{"step": 463136, "time": 15158.652152776718, "episode/length": 288.0, "episode/score": 0.017716412459037656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017716412459037656}
{"step": 463224, "time": 15161.208364009857, "episode/length": 48.0, "episode/score": 0.8563657225769248, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.006365690556890513}
{"step": 463240, "time": 15161.72218799591, "episode/length": 82.0, "episode/score": 0.759063588466006, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.015313605148321585}
{"step": 463536, "time": 15171.234921455383, "episode/length": 71.0, "episode/score": 0.7920956387935121, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.013970650932719764}
{"step": 464200, "time": 15191.950450658798, "episode/length": 121.0, "episode/score": 0.655121265756236, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.033246270517622634}
{"step": 464240, "time": 15193.43303656578, "episode/length": 288.0, "episode/score": 0.025684464940724183, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025684464940724183}
{"step": 464256, "time": 15193.943434238434, "episode/length": 288.0, "episode/score": 0.04555710434553362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04555710434553362}
{"step": 464544, "time": 15203.057672977448, "episode/length": 288.0, "episode/score": 0.04381548734227181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04381548734227181}
{"step": 465040, "time": 15218.675679206848, "episode/length": 288.0, "episode/score": 0.041079482103071996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041079482103071996}
{"step": 465448, "time": 15231.376282930374, "episode/length": 288.0, "episode/score": 0.03457217966146686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03457217966146686}
{"step": 465552, "time": 15234.899167060852, "episode/length": 288.0, "episode/score": 0.028141055250159752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028141055250159752}
{"step": 465673, "time": 15239.526421308517, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.720231518302996, "train/action_min": 0.0, "train/action_std": 1.4883674358584218, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.014009980124795866, "train/actor_opt_grad_steps": 28035.0, "train/actor_opt_loss": -3.485064257569995, "train/adv_mag": 0.6632071954687846, "train/adv_max": 0.37695194273879845, "train/adv_mean": 0.006916347057835758, "train/adv_min": -0.637925505945363, "train/adv_std": 0.04813947147430526, "train/cont_avg": 0.9961390544458762, "train/cont_loss_mean": 0.01165129490479942, "train/cont_loss_std": 0.1963114252448389, "train/cont_neg_acc": 0.45359417035554844, "train/cont_neg_loss": 2.4084956179637325, "train/cont_pos_acc": 0.999823140729334, "train/cont_pos_loss": 0.002320047714279427, "train/cont_pred": 0.9961694337658047, "train/cont_rate": 0.9961390544458762, "train/dyn_loss_mean": 1.0000027915866105, "train/dyn_loss_std": 8.320963516058496e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7591805111271205, "train/extr_critic_critic_opt_grad_steps": 28035.0, "train/extr_critic_critic_opt_loss": 9800.843816698212, "train/extr_critic_mag": 0.7571426574716863, "train/extr_critic_max": 0.7571426574716863, "train/extr_critic_mean": 0.7013414849325553, "train/extr_critic_min": 0.6587481234491486, "train/extr_critic_std": 0.015420582414287882, "train/extr_return_normed_mag": 0.647653209794428, "train/extr_return_normed_max": 0.4512926444564898, "train/extr_return_normed_mean": 0.04735981602732995, "train/extr_return_normed_min": -0.5944738916515075, "train/extr_return_normed_std": 0.05197301303929428, "train/extr_return_rate": 0.9948692361718601, "train/extr_return_raw_mag": 1.1121906650435065, "train/extr_return_raw_max": 1.1121906650435065, "train/extr_return_raw_mean": 0.7082578684251333, "train/extr_return_raw_min": 0.06642412893550913, "train/extr_return_raw_std": 0.051973012962484175, "train/extr_reward_mag": 0.4797841408818038, "train/extr_reward_max": 0.4797841408818038, "train/extr_reward_mean": 0.003334109833885282, "train/extr_reward_min": 2.359606556056701e-06, "train/extr_reward_std": 0.02149101085336783, "train/image_loss_mean": 0.09868258333851382, "train/image_loss_std": 0.10190479042603798, "train/model_loss_mean": 0.721690480549311, "train/model_loss_std": 0.2830878752331758, "train/model_opt_grad_norm": 26.072849332671804, "train/model_opt_grad_steps": 28008.577319587628, "train/model_opt_loss": 3757.7478895678964, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5206.18556701031, "train/policy_entropy_mag": 1.3601842682386183, "train/policy_entropy_max": 1.3601842682386183, "train/policy_entropy_mean": 0.1356848903077165, "train/policy_entropy_min": 0.06468658648508112, "train/policy_entropy_std": 0.17256099047120085, "train/policy_logprob_mag": 6.55108022444027, "train/policy_logprob_max": -0.008608156800769345, "train/policy_logprob_mean": -0.13568278467378667, "train/policy_logprob_min": -6.55108022444027, "train/policy_logprob_std": 0.6702726434186562, "train/policy_randomness_mag": 0.69899648243619, "train/policy_randomness_max": 0.69899648243619, "train/policy_randomness_mean": 0.06972824409604073, "train/policy_randomness_min": 0.033242331011240016, "train/policy_randomness_std": 0.08867881255051524, "train/post_ent_mag": 36.54238594684404, "train/post_ent_max": 36.54238594684404, "train/post_ent_mean": 35.48897294899852, "train/post_ent_min": 34.79804998574798, "train/post_ent_std": 0.32770087500822914, "train/prior_ent_mag": 37.716719086637205, "train/prior_ent_max": 37.716719086637205, "train/prior_ent_mean": 34.33033799633537, "train/prior_ent_min": 32.24785587468098, "train/prior_ent_std": 0.895741733693585, "train/rep_loss_mean": 1.0000027915866105, "train/rep_loss_std": 8.320963516058496e-05, "train/reward_avg": 0.0006108553481549889, "train/reward_loss_mean": 0.011354909825724424, "train/reward_loss_std": 0.08033332026553984, "train/reward_max_data": 0.33763390168854873, "train/reward_max_pred": 0.13771169886146625, "train/reward_neg_acc": 0.9998942057496494, "train/reward_neg_loss": 0.008818962251210642, "train/reward_pos_acc": 0.34523809594767435, "train/reward_pos_loss": 3.9429088155834044, "train/reward_pred": 0.0005244417578106766, "train/reward_rate": 0.0006745328608247423, "train_stats/mean_log_entropy": 0.11839576771125099, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.008093219250440598, "report/cont_loss_std": 0.18901829421520233, "report/cont_neg_acc": 0.6000000238418579, "report/cont_neg_loss": 1.450082778930664, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0010177064687013626, "report/cont_pred": 0.9959849119186401, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.09787333011627197, "report/image_loss_std": 0.10896141827106476, "report/model_loss_mean": 0.7154883146286011, "report/model_loss_std": 0.22083733975887299, "report/post_ent_mag": 37.34996032714844, "report/post_ent_max": 37.34996032714844, "report/post_ent_mean": 36.25469970703125, "report/post_ent_min": 35.55223083496094, "report/post_ent_std": 0.33228111267089844, "report/prior_ent_mag": 37.932098388671875, "report/prior_ent_max": 37.932098388671875, "report/prior_ent_mean": 34.67144012451172, "report/prior_ent_min": 32.899131774902344, "report/prior_ent_std": 0.8165717124938965, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021355980425141752, "report/reward_loss_mean": 0.009521767497062683, "report/reward_loss_std": 0.01624894328415394, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.015190362930297852, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009521767497062683, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002853049663826823, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.021713700145483017, "eval/cont_loss_std": 0.4459155797958374, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 9.516484260559082, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0031329342164099216, "eval/cont_pred": 0.9978344440460205, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22062194347381592, "eval/image_loss_std": 0.16169284284114838, "eval/model_loss_mean": 0.8434116244316101, "eval/model_loss_std": 0.4704771339893341, "eval/post_ent_mag": 37.34994888305664, "eval/post_ent_max": 37.34994888305664, "eval/post_ent_mean": 36.22041320800781, "eval/post_ent_min": 35.604583740234375, "eval/post_ent_std": 0.3113345801830292, "eval/prior_ent_mag": 38.20341873168945, "eval/prior_ent_max": 38.20341873168945, "eval/prior_ent_mean": 34.6795539855957, "eval/prior_ent_min": 32.962493896484375, "eval/prior_ent_std": 0.8465988636016846, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0010759741999208927, "eval/reward_loss_std": 0.0015199019107967615, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.006669044494628906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0010759741999208927, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002011705655604601, "eval/reward_rate": 0.0, "replay/size": 465169.0, "replay/inserts": 31136.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.270603484264503e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.723505405335852e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6168.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0616352585966948e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.385807991027832e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1775147914886, "timer/env.step_count": 3892.0, "timer/env.step_total": 37.15586829185486, "timer/env.step_frac": 0.03714927374627183, "timer/env.step_avg": 0.009546728749191895, "timer/env.step_min": 0.007708311080932617, "timer/env.step_max": 0.04902529716491699, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 15.850411415100098, "timer/replay._sample_frac": 0.015847598232004347, "timer/replay._sample_avg": 0.0005090702535682199, "timer/replay._sample_min": 0.0003933906555175781, "timer/replay._sample_max": 0.02585124969482422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4663.0, "timer/agent.policy_total": 47.403581619262695, "timer/agent.policy_frac": 0.04739516827584864, "timer/agent.policy_avg": 0.010165897838143404, "timer/agent.policy_min": 0.00855398178100586, "timer/agent.policy_max": 0.08975100517272949, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.2210855484008789, "timer/dataset_train_frac": 0.00022104630941135442, "timer/dataset_train_avg": 0.00011361025097681342, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0004687309265136719, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 864.3388566970825, "timer/agent.train_frac": 0.8641854509969413, "timer/agent.train_avg": 0.44416179686386564, "timer/agent.train_min": 0.4317197799682617, "timer/agent.train_max": 1.7471954822540283, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48064732551574707, "timer/agent.report_frac": 0.0004805620186492092, "timer/agent.report_avg": 0.24032366275787354, "timer/agent.report_min": 0.2338266372680664, "timer/agent.report_max": 0.24682068824768066, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.4564558249376026e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 31.129921770376296}
{"step": 465848, "time": 15244.813624620438, "episode/length": 288.0, "episode/score": 0.018007963374316205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018007963374316205}
{"step": 466040, "time": 15250.837940692902, "episode/length": 60.0, "episode/score": 0.826487556924377, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.01398752752950827}
{"step": 466512, "time": 15265.880479574203, "episode/length": 288.0, "episode/score": 0.017987650707965486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017987650707965486}
{"step": 466552, "time": 15266.928406476974, "episode/length": 288.0, "episode/score": 0.017178179484034217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.017178179484034217}
{"step": 466568, "time": 15267.437922239304, "episode/length": 288.0, "episode/score": 0.022471729760752623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022471729760752623}
{"step": 466856, "time": 15276.659795761108, "episode/length": 288.0, "episode/score": 0.02382739907474729, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02382739907474729}
{"step": 467352, "time": 15292.808956861496, "episode/length": 288.0, "episode/score": 0.036634861983344535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036634861983344535}
{"step": 467760, "time": 15305.914145708084, "episode/length": 288.0, "episode/score": 0.0463385341428193, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0463385341428193}
{"step": 467960, "time": 15311.963193655014, "episode/length": 24.0, "episode/score": 0.9412740051582489, "episode/reward_rate": 0.04, "episode/intrinsic_return": 0.016273986077777636}
{"step": 468160, "time": 15318.520375967026, "episode/length": 288.0, "episode/score": 0.0372028921596268, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0372028921596268}
{"step": 468352, "time": 15324.517084360123, "episode/length": 288.0, "episode/score": 0.021311891789338233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021311891789338233}
{"step": 468824, "time": 15339.24279999733, "episode/length": 288.0, "episode/score": 0.03321898539661561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03321898539661561}
{"step": 468864, "time": 15340.715167999268, "episode/length": 288.0, "episode/score": 0.040635896527135174, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040635896527135174}
{"step": 468880, "time": 15341.221868038177, "episode/length": 288.0, "episode/score": 0.03622797341512296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03622797341512296}
{"step": 469168, "time": 15350.304908037186, "episode/length": 288.0, "episode/score": 0.056298432407174914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056298432407174914}
{"step": 469592, "time": 15363.547492027283, "episode/length": 279.0, "episode/score": 0.16126948209924308, "episode/reward_rate": 0.0035714285714285713, "episode/intrinsic_return": 0.033144485297754045}
{"step": 469696, "time": 15367.018120288849, "episode/length": 191.0, "episode/score": 0.4188925168867854, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.015767522113833365}
{"step": 470048, "time": 15378.0929646492, "episode/length": 109.0, "episode/score": 0.689789428866959, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.030414437085880763}
{"step": 470080, "time": 15384.999395370483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.007356882095, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.014785289764, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.022021770477, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.029737710953, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.03744316101, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.04366850853, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470080, "time": 15385.05151128769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 470272, "time": 15391.193755626678, "episode/length": 288.0, "episode/score": 0.040443287447573084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040443287447573084}
{"step": 470320, "time": 15392.70271229744, "episode/length": 90.0, "episode/score": 0.739669736285407, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.020919754417093372}
{"step": 470384, "time": 15394.728676080704, "episode/length": 187.0, "episode/score": 0.45891654046175745, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.04329152780741197}
{"step": 470664, "time": 15403.295666217804, "episode/length": 288.0, "episode/score": 0.021956949988521046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021956949988521046}
{"step": 470696, "time": 15404.324120998383, "episode/length": 80.0, "episode/score": 0.7641930915300748, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.014193117752625994}
{"step": 470832, "time": 15408.82391667366, "episode/length": 250.0, "episode/score": 0.2631364931881137, "episode/reward_rate": 0.00398406374501992, "episode/intrinsic_return": 0.04438649339184053}
{"step": 471176, "time": 15419.484822034836, "episode/length": 288.0, "episode/score": 0.052034129227763515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052034129227763515}
{"step": 471240, "time": 15421.49802350998, "episode/length": 71.0, "episode/score": 0.8071257321062149, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.029000759132031817}
{"step": 471688, "time": 15435.54001569748, "episode/length": 55.0, "episode/score": 0.8460396809572899, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.017914676868201695}
{"step": 472008, "time": 15445.580295562744, "episode/length": 288.0, "episode/score": 0.022886188656542572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022886188656542572}
{"step": 472584, "time": 15463.784753799438, "episode/length": 288.0, "episode/score": 0.04396575394210345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04396575394210345}
{"step": 472632, "time": 15465.307213783264, "episode/length": 288.0, "episode/score": 0.03429471893969094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03429471893969094}
{"step": 472696, "time": 15467.309980869293, "episode/length": 288.0, "episode/score": 0.010353236976328617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010353236976328617}
{"step": 473008, "time": 15477.402337789536, "episode/length": 288.0, "episode/score": 0.043750447456261554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043750447456261554}
{"step": 473064, "time": 15479.056004524231, "episode/length": 59.0, "episode/score": 0.8356681518253026, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.020043140719280927}
{"step": 473144, "time": 15481.60855793953, "episode/length": 288.0, "episode/score": 0.02821304953047843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02821304953047843}
{"step": 473144, "time": 15481.615929603577, "episode/length": 16.0, "episode/score": 0.9599432616423655, "episode/reward_rate": 0.058823529411764705, "episode/intrinsic_return": 0.00994327437820175}
{"step": 473328, "time": 15487.60936999321, "episode/length": 86.0, "episode/score": 0.7561311144525007, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.024881103032157625}
{"step": 473488, "time": 15492.602546453476, "episode/length": 288.0, "episode/score": 0.043422515286749785, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043422515286749785}
{"step": 473800, "time": 15502.088185787201, "episode/length": 81.0, "episode/score": 0.7698912946900691, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.023016298432821714}
{"step": 474000, "time": 15508.584444522858, "episode/length": 288.0, "episode/score": 0.04396536069802437, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04396536069802437}
{"step": 474320, "time": 15518.807819128036, "episode/length": 288.0, "episode/score": 0.03970239147420784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03970239147420784}
{"step": 474376, "time": 15520.390000581741, "episode/length": 71.0, "episode/score": 0.8048092532064857, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.026684241786142593}
{"step": 475008, "time": 15540.582505941391, "episode/length": 288.0, "episode/score": 0.033099604606832145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033099604606832145}
{"step": 475032, "time": 15541.127236366272, "episode/length": 81.0, "episode/score": 0.7648755318090252, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.018000514335085427}
{"step": 475376, "time": 15552.646778345108, "episode/length": 288.0, "episode/score": 0.03441650483637204, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03441650483637204}
{"step": 475456, "time": 15555.154134511948, "episode/length": 288.0, "episode/score": 0.025674437503539593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025674437503539593}
{"step": 475640, "time": 15560.707072734833, "episode/length": 288.0, "episode/score": 0.030745777972697397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030745777972697397}
{"step": 475800, "time": 15565.678529024124, "episode/length": 288.0, "episode/score": 0.03918158906736835, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03918158906736835}
{"step": 475824, "time": 15566.649430036545, "episode/length": 98.0, "episode/score": 0.7292332957192684, "episode/reward_rate": 0.010101010101010102, "episode/intrinsic_return": 0.03548324853613849}
{"step": 476312, "time": 15581.743029356003, "episode/length": 288.0, "episode/score": 0.014039460726735342, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014039460726735342}
{"step": 476488, "time": 15587.275927066803, "episode/length": 82.0, "episode/score": 0.7605030756953965, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.016753119677105133}
{"step": 476632, "time": 15591.807783842087, "episode/length": 288.0, "episode/score": 0.03913078950432691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03913078950432691}
{"step": 477320, "time": 15613.488084554672, "episode/length": 288.0, "episode/score": 0.007926833991234616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007926833991234616}
{"step": 477688, "time": 15625.002011299133, "episode/length": 288.0, "episode/score": 0.03818916215828949, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03818916215828949}
{"step": 477768, "time": 15627.525027275085, "episode/length": 55.0, "episode/score": 0.8444195762169215, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.01629457643520027}
{"step": 477768, "time": 15627.532759428024, "episode/length": 288.0, "episode/score": 0.04870173057827287, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04870173057827287}
{"step": 477952, "time": 15633.608127593994, "episode/length": 288.0, "episode/score": 0.01722914808169662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01722914808169662}
{"step": 478104, "time": 15638.149584293365, "episode/length": 41.0, "episode/score": 0.8825163814862549, "episode/reward_rate": 0.023809523809523808, "episode/intrinsic_return": 0.010641386247641549}
{"step": 478112, "time": 15638.627129793167, "episode/length": 288.0, "episode/score": 0.01797139560466121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01797139560466121}
{"step": 478624, "time": 15654.6429169178, "episode/length": 288.0, "episode/score": 0.04119179048825572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04119179048825572}
{"step": 478728, "time": 15657.685081720352, "episode/length": 77.0, "episode/score": 0.7800234806661024, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02064849632978394}
{"step": 478800, "time": 15660.227835655212, "episode/length": 288.0, "episode/score": 0.028202766918013822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028202766918013822}
{"step": 478944, "time": 15664.724114894867, "episode/length": 288.0, "episode/score": 0.02149019318022738, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02149019318022738}
{"step": 479240, "time": 15673.764702320099, "episode/length": 76.0, "episode/score": 0.7926140194496725, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.0301140515104521}
{"step": 479336, "time": 15676.764824151993, "episode/length": 75.0, "episode/score": 0.7888465910973537, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.023221591315632395}
{"step": 479496, "time": 15681.759996175766, "episode/length": 86.0, "episode/score": 0.7662339067034623, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.034983911464848916}
{"step": 480000, "time": 15697.904528617859, "episode/length": 288.0, "episode/score": 0.03172383865609163, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03172383865609163}
{"step": 480064, "time": 15701.1887216568, "eval_episode/length": 69.0, "eval_episode/score": 0.784375011920929, "eval_episode/reward_rate": 0.014285714285714285}
{"step": 480064, "time": 15701.399280071259, "eval_episode/length": 80.0, "eval_episode/score": 0.75, "eval_episode/reward_rate": 0.012345679012345678}
{"step": 480064, "time": 15702.294785737991, "eval_episode/length": 59.0, "eval_episode/score": 0.815625011920929, "eval_episode/reward_rate": 0.016666666666666666}
{"step": 480064, "time": 15705.126399755478, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15705.13437962532, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15705.142207860947, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15705.149028539658, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15705.155727386475, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480064, "time": 15705.163449525833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 480080, "time": 15705.665941953659, "episode/length": 288.0, "episode/score": 0.03990851026361497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03990851026361497}
{"step": 480264, "time": 15711.22898030281, "episode/length": 288.0, "episode/score": 0.012611439595957563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012611439595957563}
{"step": 480424, "time": 15716.265832185745, "episode/length": 288.0, "episode/score": 0.02612953618671554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02612953618671554}
{"step": 481088, "time": 15737.291170597076, "episode/length": 82.0, "episode/score": 0.7706252205612145, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.02687521576490326}
{"step": 481256, "time": 15742.343341112137, "episode/length": 288.0, "episode/score": 0.014873577498519808, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014873577498519808}
{"step": 481376, "time": 15746.312612771988, "episode/length": 35.0, "episode/score": 0.9063779928733311, "episode/reward_rate": 0.027777777777777776, "episode/intrinsic_return": 0.015752964235161926}
{"step": 481552, "time": 15751.931168794632, "episode/length": 288.0, "episode/score": 0.02268408986316217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02268408986316217}
{"step": 481648, "time": 15754.973405122757, "episode/length": 288.0, "episode/score": 0.06927496939624689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06927496939624689}
{"step": 481808, "time": 15759.970786333084, "episode/length": 288.0, "episode/score": 0.059967597745071544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059967597745071544}
{"step": 481936, "time": 15763.96239900589, "episode/length": 47.0, "episode/score": 0.8691093260217713, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.015984321225460008}
{"step": 482312, "time": 15775.556949615479, "episode/length": 288.0, "episode/score": 0.05250324665308881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05250324665308881}
{"step": 482392, "time": 15778.123470067978, "episode/length": 288.0, "episode/score": 0.028527035243939736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028527035243939736}
{"step": 482488, "time": 15781.25980091095, "episode/length": 84.0, "episode/score": 0.772820293222594, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.035320282116572344}
{"step": 482576, "time": 15784.25133395195, "episode/length": 288.0, "episode/score": 0.044064793645418376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044064793645418376}
{"step": 482872, "time": 15793.34304857254, "episode/length": 69.0, "episode/score": 0.7984222130210128, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.014047177758811813}
{"step": 482992, "time": 15797.346582651138, "episode/length": 62.0, "episode/score": 0.8363278565188921, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.03007788117565724}
{"step": 483448, "time": 15812.011196613312, "episode/length": 71.0, "episode/score": 0.7973996536638879, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.019274657406640472}
{"step": 483552, "time": 15815.520168066025, "episode/length": 69.0, "episode/score": 0.8069394150448943, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.02256439494578899}
{"step": 483568, "time": 15816.036822795868, "episode/length": 288.0, "episode/score": 0.04681826996818472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04681826996818472}
{"step": 483688, "time": 15819.653806447983, "episode/length": 288.0, "episode/score": 0.03340865611562549, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03340865611562549}
{"step": 483864, "time": 15825.17866563797, "episode/length": 21.0, "episode/score": 0.9411712837988944, "episode/reward_rate": 0.045454545454545456, "episode/intrinsic_return": 0.006796281400738735}
{"step": 483960, "time": 15828.204979896545, "episode/length": 288.0, "episode/score": 0.057757527606213444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057757527606213444}
{"step": 484144, "time": 15834.166885137558, "episode/length": 34.0, "episode/score": 0.9075547814045422, "episode/reward_rate": 0.02857142857142857, "episode/intrinsic_return": 0.013804761305436841}
{"step": 484248, "time": 15837.206349134445, "episode/length": 288.0, "episode/score": 0.04486511856111974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04486511856111974}
{"step": 484704, "time": 15851.795524835587, "episode/length": 288.0, "episode/score": 0.04402244792424881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04402244792424881}
{"step": 484888, "time": 15857.340542078018, "episode/length": 288.0, "episode/score": 0.03504983565261455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03504983565261455}
{"step": 485248, "time": 15868.937091827393, "episode/length": 124.0, "episode/score": 0.648119445594034, "episode/reward_rate": 0.008, "episode/intrinsic_return": 0.03561942651356276}
{"step": 485760, "time": 15884.945929765701, "episode/length": 288.0, "episode/score": 0.04997794853392179, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04997794853392179}
{"step": 485864, "time": 15887.989486932755, "episode/length": 288.0, "episode/score": 0.04475015869741128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04475015869741128}
{"step": 485880, "time": 15888.514663934708, "episode/length": 288.0, "episode/score": 0.03249761132161666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03249761132161666}
{"step": 486272, "time": 15901.133769512177, "episode/length": 288.0, "episode/score": 0.03513449036364591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03513449036364591}
{"step": 486456, "time": 15906.656376600266, "episode/length": 288.0, "episode/score": 0.05191904562650507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05191904562650507}
{"step": 486624, "time": 15912.137136936188, "episode/length": 107.0, "episode/score": 0.68607587993165, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.020450904588415142}
{"step": 486760, "time": 15916.179403066635, "episode/length": 60.0, "episode/score": 0.8276176796348409, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.015117650239972136}
{"step": 487016, "time": 15924.22896027565, "episode/length": 288.0, "episode/score": 0.03608859780968032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03608859780968032}
{"step": 487200, "time": 15930.343860387802, "episode/length": 288.0, "episode/score": 0.03231474617155072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03231474617155072}
{"step": 487352, "time": 15934.880661725998, "episode/length": 90.0, "episode/score": 0.7550092056389985, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.03625919131991395}
{"step": 487560, "time": 15941.407240867615, "episode/length": 288.0, "episode/score": 0.018286257237662085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018286257237662085}
{"step": 488176, "time": 15960.985272884369, "episode/length": 288.0, "episode/score": 0.0403529174192272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0403529174192272}
{"step": 488192, "time": 15961.491880655289, "episode/length": 288.0, "episode/score": 0.041352727090497865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041352727090497865}
{"step": 488768, "time": 15979.527659654617, "episode/length": 288.0, "episode/score": 0.02500270900554824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02500270900554824}
{"step": 489032, "time": 15987.587311983109, "episode/length": 104.0, "episode/score": 0.7115904577603942, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.03659042249819322}
{"step": 489072, "time": 15989.19364786148, "episode/length": 288.0, "episode/score": 0.01813333452344068, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01813333452344068}
{"step": 489288, "time": 15995.731858968735, "episode/length": 31.0, "episode/score": 0.92322512343992, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.02010010672267981}
{"step": 489328, "time": 15997.211573839188, "episode/length": 288.0, "episode/score": 0.07145179125666345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07145179125666345}
{"step": 489512, "time": 16002.777928352356, "episode/length": 288.0, "episode/score": 0.024609965452555116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024609965452555116}
{"step": 489664, "time": 16007.779978275299, "episode/length": 288.0, "episode/score": 0.02149123353763116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02149123353763116}
{"step": 489872, "time": 16014.334441423416, "episode/length": 288.0, "episode/score": 0.05482946168712033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05482946168712033}
{"step": 489912, "time": 16015.374361276627, "episode/length": 49.0, "episode/score": 0.8685826968488755, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.021707685742853755}
{"step": 490048, "time": 16020.833968639374, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 490048, "time": 16021.923806667328, "eval_episode/length": 108.0, "eval_episode/score": 0.6625000238418579, "eval_episode/reward_rate": 0.009174311926605505}
{"step": 490048, "time": 16021.968267440796, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 490048, "time": 16025.170221328735, "eval_episode/length": 139.0, "eval_episode/score": 0.565625011920929, "eval_episode/reward_rate": 0.007142857142857143}
{"step": 490048, "time": 16025.855526685715, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16025.863503217697, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16025.870065927505, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16025.876428604126, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490048, "time": 16025.883041858673, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 490488, "time": 16039.453172445297, "episode/length": 288.0, "episode/score": 0.01591765012159385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01591765012159385}
{"step": 490576, "time": 16042.445946216583, "episode/length": 187.0, "episode/score": 0.4715560614665151, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.055931056670203816}
{"step": 490664, "time": 16044.984952926636, "episode/length": 93.0, "episode/score": 0.7340452444734069, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.024670212453372642}
{"step": 491080, "time": 16058.132709980011, "episode/length": 288.0, "episode/score": 0.04800819510398924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04800819510398924}
{"step": 491328, "time": 16066.155511140823, "episode/length": 93.0, "episode/score": 0.7334712126243517, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.02409616544122173}
{"step": 491544, "time": 16073.19313454628, "episode/length": 109.0, "episode/score": 0.7072760139706133, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.047900993871508035}
{"step": 491600, "time": 16075.166004180908, "episode/length": 288.0, "episode/score": 0.012453234390875423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012453234390875423}
{"step": 491640, "time": 16076.217007637024, "episode/length": 288.0, "episode/score": 0.028356661032375996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028356661032375996}
{"step": 491656, "time": 16076.721279859543, "episode/length": 145.0, "episode/score": 0.5793446970939158, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.032469688915739425}
{"step": 491976, "time": 16086.843363761902, "episode/length": 288.0, "episode/score": 0.05607308334674599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05607308334674599}
{"step": 492176, "time": 16093.352383613586, "episode/length": 78.0, "episode/score": 0.7770481622297893, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.02079810899306267}
{"step": 492184, "time": 16093.392420768738, "episode/length": 288.0, "episode/score": 0.034428354816668616, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034428354816668616}
{"step": 492376, "time": 16099.399181365967, "episode/length": 96.0, "episode/score": 0.7312180988923842, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.031218103653770868}
{"step": 492488, "time": 16102.912961244583, "episode/length": 105.0, "episode/score": 0.7130189652320951, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.04114395807255278}
{"step": 493392, "time": 16131.596179485321, "episode/length": 288.0, "episode/score": 0.04411012860333585, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04411012860333585}
{"step": 493640, "time": 16139.213232517242, "episode/length": 288.0, "episode/score": 0.043515410208726735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043515410208726735}
{"step": 493968, "time": 16149.675013542175, "episode/length": 288.0, "episode/score": 0.03399216162358698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03399216162358698}
{"step": 494288, "time": 16159.698561906815, "episode/length": 288.0, "episode/score": 0.035114966681220494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035114966681220494}
{"step": 494488, "time": 16165.723913669586, "episode/length": 288.0, "episode/score": 0.025756236590353865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025756236590353865}
{"step": 494496, "time": 16166.201534032822, "episode/length": 288.0, "episode/score": 0.014601219220679695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014601219220679695}
{"step": 494688, "time": 16172.33285355568, "episode/length": 288.0, "episode/score": 0.021440074831787115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021440074831787115}
{"step": 494800, "time": 16175.830861330032, "episode/length": 288.0, "episode/score": 0.024012357268844653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024012357268844653}
{"step": 495088, "time": 16184.881265163422, "episode/length": 180.0, "episode/score": 0.4547502172658824, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.017250218080789637}
{"step": 495328, "time": 16192.422056436539, "episode/length": 241.0, "episode/score": 0.2807261286837388, "episode/reward_rate": 0.004132231404958678, "episode/intrinsic_return": 0.033851126867659787}
{"step": 495344, "time": 16192.929474115372, "episode/length": 105.0, "episode/score": 0.7197538624936328, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.0478788826334835}
{"step": 496192, "time": 16219.645381212234, "episode/length": 187.0, "episode/score": 0.4524622238202767, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.036837206189176186}
{"step": 496280, "time": 16222.210005760193, "episode/length": 288.0, "episode/score": 0.031947148246558754, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031947148246558754}
{"step": 496600, "time": 16232.443820238113, "episode/length": 288.0, "episode/score": 0.03732426140561529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03732426140561529}
{"step": 496640, "time": 16233.918252706528, "episode/length": 193.0, "episode/score": 0.44021084165405, "episode/reward_rate": 0.005154639175257732, "episode/intrinsic_return": 0.0433358329170801}
{"step": 496800, "time": 16238.926750183105, "episode/length": 288.0, "episode/score": 0.044875493002223266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044875493002223266}
{"step": 496809, "time": 16239.969507455826, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.631109149639423, "train/action_min": 0.0, "train/action_std": 1.4343240572856022, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.009463720234970633, "train/actor_opt_grad_steps": 29980.0, "train/actor_opt_loss": -6.4958802299120295, "train/adv_mag": 0.7197650671005249, "train/adv_max": 0.3170666278936924, "train/adv_mean": 0.001721581121289954, "train/adv_min": -0.6948832624997848, "train/adv_std": 0.03215627358414424, "train/cont_avg": 0.995888421474359, "train/cont_loss_mean": 0.011681360004541393, "train/cont_loss_std": 0.19490167116626905, "train/cont_neg_acc": 0.4911497835929577, "train/cont_neg_loss": 2.233445511111775, "train/cont_pos_acc": 0.9998289780739026, "train/cont_pos_loss": 0.002284302262481875, "train/cont_pred": 0.9959186382782765, "train/cont_rate": 0.995888421474359, "train/dyn_loss_mean": 1.0000044993865185, "train/dyn_loss_std": 0.00011266729651162257, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.4073938055489308, "train/extr_critic_critic_opt_grad_steps": 29980.0, "train/extr_critic_critic_opt_loss": 12324.942302684294, "train/extr_critic_mag": 0.8352380031194442, "train/extr_critic_max": 0.8352380031194442, "train/extr_critic_mean": 0.7850838740666707, "train/extr_critic_min": 0.737645942125565, "train/extr_critic_std": 0.012068142431477706, "train/extr_return_normed_mag": 0.7081893823085688, "train/extr_return_normed_max": 0.37310158350528816, "train/extr_return_normed_mean": 0.025534650556969258, "train/extr_return_normed_min": -0.6729024853461828, "train/extr_return_normed_std": 0.03487036971327586, "train/extr_return_rate": 0.9980709589444674, "train/extr_return_raw_mag": 1.1343723419385079, "train/extr_return_raw_max": 1.1343723419385079, "train/extr_return_raw_mean": 0.7868054509162903, "train/extr_return_raw_min": 0.08836827308703692, "train/extr_return_raw_std": 0.03487036975625998, "train/extr_reward_mag": 0.41694061817267003, "train/extr_reward_max": 0.41694061817267003, "train/extr_reward_mean": 0.001731015378400349, "train/extr_reward_min": 2.8066146068083936e-06, "train/extr_reward_std": 0.011020267177492571, "train/image_loss_mean": 0.09272935061882703, "train/image_loss_std": 0.09989885771885897, "train/model_loss_mean": 0.7160440689478165, "train/model_loss_std": 0.2879197678886927, "train/model_opt_grad_norm": 25.312568199940216, "train/model_opt_grad_steps": 29951.68717948718, "train/model_opt_loss": 3634.2203838641826, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 5076.923076923077, "train/policy_entropy_mag": 1.3454774899360462, "train/policy_entropy_max": 1.3454774899360462, "train/policy_entropy_mean": 0.12207603011375819, "train/policy_entropy_min": 0.06468652735153833, "train/policy_entropy_std": 0.15794042341220074, "train/policy_logprob_mag": 6.551080246460743, "train/policy_logprob_max": -0.008608139120042324, "train/policy_logprob_mean": -0.122700208119857, "train/policy_logprob_min": -6.551080246460743, "train/policy_logprob_std": 0.6615892327748812, "train/policy_randomness_mag": 0.6914386917383243, "train/policy_randomness_max": 0.6914386917383243, "train/policy_randomness_mean": 0.06273467315313144, "train/policy_randomness_min": 0.033242301299021795, "train/policy_randomness_std": 0.08116532659683472, "train/post_ent_mag": 35.484356259077025, "train/post_ent_max": 35.484356259077025, "train/post_ent_mean": 34.17397229121281, "train/post_ent_min": 33.35342832712027, "train/post_ent_std": 0.39810011448004307, "train/prior_ent_mag": 36.058503820957284, "train/prior_ent_max": 36.058503820957284, "train/prior_ent_mean": 33.09629799280411, "train/prior_ent_min": 31.383053285647662, "train/prior_ent_std": 0.731479212259635, "train/rep_loss_mean": 1.0000044993865185, "train/rep_loss_std": 0.00011266729651162257, "train/reward_avg": 0.0006736439547519415, "train/reward_loss_mean": 0.011630637248834738, "train/reward_loss_std": 0.08751452195529755, "train/reward_max_data": 0.35985047712874335, "train/reward_max_pred": 0.14459245999654133, "train/reward_neg_acc": 0.9998546447509374, "train/reward_neg_loss": 0.008616552415948648, "train/reward_pos_acc": 0.3151815188403177, "train/reward_pos_loss": 3.8432482938365182, "train/reward_pred": 0.0005792596192361834, "train/reward_rate": 0.0007862580128205128, "train_stats/mean_log_entropy": 0.09918676255078152, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.008265694603323936, "report/cont_loss_std": 0.10971207171678543, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.985297441482544, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.002456590998917818, "report/cont_pred": 0.9971338510513306, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.10077840089797974, "report/image_loss_std": 0.10833381861448288, "report/model_loss_mean": 0.7219698429107666, "report/model_loss_std": 0.24354009330272675, "report/post_ent_mag": 35.395259857177734, "report/post_ent_max": 35.395259857177734, "report/post_ent_mean": 33.97819519042969, "report/post_ent_min": 33.080162048339844, "report/post_ent_std": 0.4444582760334015, "report/prior_ent_mag": 34.823768615722656, "report/prior_ent_max": 34.823768615722656, "report/prior_ent_mean": 32.2371940612793, "report/prior_ent_min": 30.65962791442871, "report/prior_ent_std": 0.7298350930213928, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00065447180531919, "report/reward_loss_mean": 0.012925729155540466, "report/reward_loss_std": 0.12506143748760223, "report/reward_max_data": 0.46000000834465027, "report/reward_max_pred": 0.057648301124572754, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009043834172189236, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 3.9841041564941406, "report/reward_pred": 0.00034485291689634323, "report/reward_rate": 0.0009765625, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.01202323380857706, "eval/cont_loss_std": 0.3416808843612671, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 10.937518119812012, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013433784479275346, "eval/cont_pred": 0.9986884593963623, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.21618852019309998, "eval/image_loss_std": 0.14233684539794922, "eval/model_loss_mean": 0.8297171592712402, "eval/model_loss_std": 0.3655166029930115, "eval/post_ent_mag": 35.395233154296875, "eval/post_ent_max": 35.395233154296875, "eval/post_ent_mean": 33.88852310180664, "eval/post_ent_min": 33.07244873046875, "eval/post_ent_std": 0.42214953899383545, "eval/prior_ent_mag": 34.823768615722656, "eval/prior_ent_max": 34.823768615722656, "eval/prior_ent_mean": 32.047882080078125, "eval/prior_ent_min": 30.021766662597656, "eval/prior_ent_std": 0.7336685061454773, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001505411695688963, "eval/reward_loss_std": 0.0051486254669725895, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.05459415912628174, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001505411695688963, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002886293223127723, "eval/reward_rate": 0.0, "replay/size": 496305.0, "replay/inserts": 31136.0, "replay/samples": 31136.0, "replay/insert_wait_avg": 1.260985879711845e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.825883886919481e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1197698432543973e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4210071563721, "timer/env.step_count": 3892.0, "timer/env.step_total": 36.8729305267334, "timer/env.step_frac": 0.03685741329197211, "timer/env.step_avg": 0.009474031481688952, "timer/env.step_min": 0.007587909698486328, "timer/env.step_max": 0.052353858947753906, "timer/replay._sample_count": 31136.0, "timer/replay._sample_total": 15.902387142181396, "timer/replay._sample_frac": 0.015895694940855788, "timer/replay._sample_avg": 0.0005107395664883542, "timer/replay._sample_min": 0.0004181861877441406, "timer/replay._sample_max": 0.010188817977905273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4759.0, "timer/agent.policy_total": 48.28540396690369, "timer/agent.policy_frac": 0.04826508402112789, "timer/agent.policy_avg": 0.010146123968670663, "timer/agent.policy_min": 0.008748292922973633, "timer/agent.policy_max": 0.08707094192504883, "timer/dataset_train_count": 1946.0, "timer/dataset_train_total": 0.22176289558410645, "timer/dataset_train_frac": 0.00022166957110831992, "timer/dataset_train_avg": 0.00011395832249954082, "timer/dataset_train_min": 9.655952453613281e-05, "timer/dataset_train_max": 0.001079559326171875, "timer/agent.train_count": 1946.0, "timer/agent.train_total": 862.7829847335815, "timer/agent.train_frac": 0.8624198997839748, "timer/agent.train_avg": 0.44336227375826387, "timer/agent.train_min": 0.43105220794677734, "timer/agent.train_max": 0.6559062004089355, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47785210609436035, "timer/agent.report_frac": 0.0004776510116002283, "timer/agent.report_avg": 0.23892605304718018, "timer/agent.report_min": 0.23321008682250977, "timer/agent.report_max": 0.24464201927185059, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.2438507080078125e-05, "timer/dataset_eval_frac": 4.24206476838253e-08, "timer/dataset_eval_avg": 4.2438507080078125e-05, "timer/dataset_eval_min": 4.2438507080078125e-05, "timer/dataset_eval_max": 4.2438507080078125e-05, "fps": 31.122348689653318}
{"step": 497112, "time": 16249.209844350815, "episode/length": 288.0, "episode/score": 0.04775882301794354, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04775882301794354}
{"step": 497336, "time": 16256.260836362839, "episode/length": 142.0, "episode/score": 0.5805689292542979, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.024318953314434566}
{"step": 497640, "time": 16265.96927189827, "episode/length": 288.0, "episode/score": 0.029273839808638513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029273839808638513}
{"step": 497656, "time": 16266.478662014008, "episode/length": 288.0, "episode/score": 0.04413323217798393, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04413323217798393}
{"step": 497696, "time": 16267.954823493958, "episode/length": 72.0, "episode/score": 0.7875714775634037, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.01257151651014965}
{"step": 497752, "time": 16269.515278577805, "episode/length": 51.0, "episode/score": 0.8577988604041593, "episode/reward_rate": 0.019230769230769232, "episode/intrinsic_return": 0.017173890456774643}
{"step": 497856, "time": 16272.993967056274, "episode/length": 19.0, "episode/score": 0.9448430677473141, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.004218070931273132}
{"step": 497936, "time": 16275.511845827103, "episode/length": 36.0, "episode/score": 0.9013552711354578, "episode/reward_rate": 0.02702702702702703, "episode/intrinsic_return": 0.013855298161274732}
{"step": 497960, "time": 16276.050008535385, "episode/length": 25.0, "episode/score": 0.9292765866842387, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.007401600843252254}
{"step": 498576, "time": 16295.747129678726, "episode/length": 79.0, "episode/score": 0.7851993871590253, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.032074390342984316}
{"step": 498592, "time": 16296.255754709244, "episode/length": 288.0, "episode/score": 0.01862277084845232, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01862277084845232}
{"step": 498912, "time": 16306.274542570114, "episode/length": 288.0, "episode/score": 0.012450416371507345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012450416371507345}
{"step": 498952, "time": 16307.313496351242, "episode/length": 288.0, "episode/score": 0.03653988462818347, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03653988462818347}
{"step": 499112, "time": 16312.366966485977, "episode/length": 288.0, "episode/score": 0.03889526420948641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03889526420948641}
{"step": 499448, "time": 16322.985746860504, "episode/length": 108.0, "episode/score": 0.6912497087977272, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.02874969703395891}
{"step": 499968, "time": 16340.016413450241, "episode/length": 288.0, "episode/score": 0.011114207673642795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011114207673642795}
{"step": 500032, "time": 16342.867542266846, "eval_episode/length": 42.0, "eval_episode/score": 0.8687499761581421, "eval_episode/reward_rate": 0.023255813953488372}
{"step": 500032, "time": 16343.71079158783, "eval_episode/length": 86.0, "eval_episode/score": 0.731249988079071, "eval_episode/reward_rate": 0.011494252873563218}
{"step": 500032, "time": 16347.302881717682, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16347.310313940048, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16347.317325592041, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16347.323887586594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16347.331181287766, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500032, "time": 16347.339252710342, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 500168, "time": 16351.474218845367, "episode/length": 288.0, "episode/score": 0.04641698648103443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04641698648103443}
{"step": 500272, "time": 16354.992772340775, "episode/length": 288.0, "episode/score": 0.032948031252288956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032948031252288956}
{"step": 500576, "time": 16364.531058311462, "episode/length": 75.0, "episode/score": 0.7764310654492306, "episode/reward_rate": 0.013157894736842105, "episode/intrinsic_return": 0.010806037334930352}
{"step": 500848, "time": 16373.061967134476, "episode/length": 84.0, "episode/score": 0.7600358601132484, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.02253586235133298}
{"step": 500904, "time": 16374.605026483536, "episode/length": 288.0, "episode/score": 0.028849385807717454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028849385807717454}
