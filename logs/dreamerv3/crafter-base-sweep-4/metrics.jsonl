{"step": 1104, "time": 177.52232217788696, "episode/length": 137.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 1224, "time": 179.48329997062683, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 1264, "time": 180.95972156524658, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 1296, "time": 182.3903787136078, "episode/length": 161.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1376, "time": 184.00428676605225, "episode/length": 171.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 1424, "time": 185.60482931137085, "episode/length": 177.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 1464, "time": 187.1532473564148, "episode/length": 44.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 203.71753644943237, "eval_episode/length": 142.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 1560, "time": 205.360746383667, "eval_episode/length": 153.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.974025974025974}
{"step": 1560, "time": 206.86381649971008, "eval_episode/length": 160.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 1560, "time": 208.23034238815308, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9567901234567902}
{"step": 1560, "time": 209.78330779075623, "eval_episode/length": 166.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 1560, "time": 211.44205403327942, "eval_episode/length": 175.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1560, "time": 213.01475977897644, "eval_episode/length": 184.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 1560, "time": 214.55822610855103, "train_stats/sum_log_reward": 0.3857143244573048, "train_stats/max_log_achievement_collect_wood": 0.2857142857142857, "train_stats/max_log_achievement_wake_up": 1.6666666666666667, "train_stats/max_log_achievement_collect_sapling": 0.2, "train_stats/max_log_achievement_place_plant": 0.2, "eval_stats/sum_log_reward": 1.6714285771761621, "eval_stats/max_log_achievement_collect_sapling": 0.8571428571428571, "eval_stats/max_log_achievement_collect_wood": 0.5714285714285714, "eval_stats/max_log_achievement_place_plant": 0.5714285714285714, "eval_stats/max_log_achievement_wake_up": 1.5714285714285714}
{"step": 1560, "time": 254.58008909225464, "eval_episode/length": 54.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 1560, "time": 259.2144441604614, "eval_episode/length": 107.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 1560, "time": 261.04973816871643, "eval_episode/length": 111.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9910714285714286}
{"step": 1560, "time": 264.0733382701874, "eval_episode/length": 140.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9645390070921985}
{"step": 1560, "time": 266.035284280777, "eval_episode/length": 146.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 1560, "time": 268.4125165939331, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 1560, "time": 271.5481507778168, "eval_episode/length": 189.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 1560, "time": 273.9772412776947, "eval_episode/length": 197.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 1561, "time": 398.4018247127533, "eval_stats/sum_log_reward": 0.9749999474734068, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/max_log_achievement_collect_drink": 2.0, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.5361328125, "train/action_min": 0.0, "train/action_std": 4.595348358154297, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010714735981309786, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.7895641922950745, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9990234375, "train/cont_loss_mean": 0.9794619083404541, "train/cont_loss_std": 0.32805123925209045, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.5166895985603333, "train/cont_pos_acc": 0.19648094475269318, "train/cont_pos_loss": 0.9799143671989441, "train/cont_pred": 0.3947180509567261, "train/cont_rate": 0.9990234375, "train/dyn_loss_mean": 9.841178894042969, "train/dyn_loss_std": 0.4107290804386139, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 2.7925095558166504, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 11126.4609375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3914.267578125, "train/image_loss_std": 294.1440124511719, "train/model_loss_mean": 3926.69287109375, "train/model_loss_std": 294.14581298828125, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 39266928.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.787914752960205, "train/policy_entropy_max": 2.787914752960205, "train/policy_entropy_mean": 2.625786542892456, "train/policy_entropy_min": 1.9912108182907104, "train/policy_entropy_std": 0.07417318224906921, "train/policy_logprob_mag": 5.131371021270752, "train/policy_logprob_max": -0.6627716422080994, "train/policy_logprob_mean": -2.620286226272583, "train/policy_logprob_min": -5.131371021270752, "train/policy_logprob_std": 0.6229049563407898, "train/policy_randomness_mag": 0.9840115904808044, "train/policy_randomness_max": 0.9840115904808044, "train/policy_randomness_mean": 0.9267873764038086, "train/policy_randomness_min": 0.7028100490570068, "train/policy_randomness_std": 0.026179878041148186, "train/post_ent_mag": 106.5235595703125, "train/post_ent_max": 106.5235595703125, "train/post_ent_mean": 105.96473693847656, "train/post_ent_min": 105.48015594482422, "train/post_ent_std": 0.2352350503206253, "train/prior_ent_mag": 106.41188049316406, "train/prior_ent_max": 106.41188049316406, "train/prior_ent_mean": 105.59502410888672, "train/prior_ent_min": 104.5350341796875, "train/prior_ent_std": 0.312013179063797, "train/rep_loss_mean": 9.841178894042969, "train/rep_loss_std": 0.4107290804386139, "train/reward_avg": 0.004101562779396772, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.542561656417092e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 0.9999999403953552, "train/reward_neg_loss": 5.541262149810791, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541264057159424, "train/reward_pred": 0.0, "train/reward_rate": 0.0068359375, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.9837367534637451, "report/cont_loss_std": 0.32079899311065674, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.3651459217071533, "report/cont_pos_acc": 0.17986315488815308, "report/cont_pos_loss": 0.9843413829803467, "report/cont_pred": 0.3919529914855957, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 9.851176261901855, "report/dyn_loss_std": 0.4209296703338623, "report/image_loss_mean": 3910.919677734375, "report/image_loss_std": 286.1900634765625, "report/model_loss_mean": 3923.355712890625, "report/model_loss_std": 286.23486328125, "report/post_ent_mag": 106.5220947265625, "report/post_ent_max": 106.5220947265625, "report/post_ent_mean": 105.95590209960938, "report/post_ent_min": 105.4787368774414, "report/post_ent_std": 0.23250369727611542, "report/prior_ent_mag": 106.46253967285156, "report/prior_ent_max": 106.46253967285156, "report/prior_ent_mean": 105.65299224853516, "report/prior_ent_min": 104.70294189453125, "report/prior_ent_std": 0.2721531391143799, "report/rep_loss_mean": 9.851176261901855, "report/rep_loss_std": 0.4209296703338623, "report/reward_avg": 0.004101562779396772, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.542561656417092e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 5.541262149810791, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541264057159424, "report/reward_pred": 0.0, "report/reward_rate": 0.0068359375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.9485721588134766, "eval/cont_loss_std": 0.32341572642326355, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 0.5858590602874756, "eval/cont_pos_acc": 0.2235293984413147, "eval/cont_pos_loss": 0.9499944448471069, "eval/cont_pred": 0.40630024671554565, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 9.836437225341797, "eval/dyn_loss_std": 0.39535409212112427, "eval/image_loss_mean": 3936.6650390625, "eval/image_loss_std": 195.06204223632812, "eval/model_loss_mean": 3949.056640625, "eval/model_loss_std": 195.13771057128906, "eval/post_ent_mag": 106.61642456054688, "eval/post_ent_max": 106.61642456054688, "eval/post_ent_mean": 105.95828247070312, "eval/post_ent_min": 105.40409851074219, "eval/post_ent_std": 0.2368425726890564, "eval/prior_ent_mag": 106.45838165283203, "eval/prior_ent_max": 106.45838165283203, "eval/prior_ent_mean": 105.67418670654297, "eval/prior_ent_min": 104.7688980102539, "eval/prior_ent_std": 0.2758725881576538, "eval/rep_loss_mean": 9.836437225341797, "eval/rep_loss_std": 0.39535409212112427, "eval/reward_avg": 0.01132812537252903, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541263103485107, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.015625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 2.1683233688773137e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.940696716308594e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2640.0, "eval_replay/inserts": 2640.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.6725424564245976e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.110995701381139e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 236.5400881767273, "timer/env.step_count": 196.0, "timer/env.step_total": 26.64029026031494, "timer/env.step_frac": 0.11262484285712727, "timer/env.step_avg": 0.13591984826691297, "timer/env.step_min": 0.02417778968811035, "timer/env.step_max": 11.575550317764282, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.11862754821777344, "timer/replay._sample_frac": 0.0005015113891778999, "timer/replay._sample_avg": 0.0010591745376586914, "timer/replay._sample_min": 0.0003731250762939453, "timer/replay._sample_max": 0.013586044311523438, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.901650428771973, "timer/agent.save_frac": 0.04186034809192304, "timer/agent.save_avg": 9.901650428771973, "timer/agent.save_min": 9.901650428771973, "timer/agent.save_max": 9.901650428771973, "timer/agent.policy_count": 199.0, "timer/agent.policy_total": 26.695009231567383, "timer/agent.policy_frac": 0.11285617350249154, "timer/agent.policy_avg": 0.13414577503300193, "timer/agent.policy_min": 0.011545419692993164, "timer/agent.policy_max": 20.216639041900635, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.9577484130859375e-05, "timer/dataset_train_frac": 1.673182944841454e-07, "timer/dataset_train_avg": 3.9577484130859375e-05, "timer/dataset_train_min": 3.9577484130859375e-05, "timer/dataset_train_max": 3.9577484130859375e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 95.77309823036194, "timer/agent.train_frac": 0.4048916146459138, "timer/agent.train_avg": 95.77309823036194, "timer/agent.train_min": 95.77309823036194, "timer/agent.train_max": 95.77309823036194, "timer/agent.report_count": 2.0, "timer/agent.report_total": 26.054654598236084, "timer/agent.report_frac": 0.11014900179951632, "timer/agent.report_avg": 13.027327299118042, "timer/agent.report_min": 0.24492835998535156, "timer/agent.report_max": 25.809726238250732, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.030632019042969e-05, "timer/dataset_eval_frac": 2.126756634708113e-07, "timer/dataset_eval_avg": 5.030632019042969e-05, "timer/dataset_eval_min": 5.030632019042969e-05, "timer/dataset_eval_max": 5.030632019042969e-05}
{"step": 1712, "time": 403.5421245098114, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 2304, "time": 425.0968430042267, "episode/length": 115.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 2304, "time": 425.1039535999298, "episode/length": 109.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 2512, "time": 435.5008602142334, "episode/length": 155.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 2608, "time": 440.52144384384155, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 2704, "time": 445.4446439743042, "episode/length": 154.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 2880, "time": 453.07459807395935, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 2984, "time": 457.9742364883423, "episode/length": 372.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9758713136729222, "episode/intrinsic_return": 0.0}
{"step": 3128, "time": 464.5231261253357, "episode/length": 176.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 3720, "time": 486.1947684288025, "episode/length": 176.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 3752, "time": 488.9046173095703, "episode/length": 154.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 3808, "time": 492.62776613235474, "episode/length": 137.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 3872, "time": 496.4601595401764, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 4056, "time": 504.0946910381317, "episode/length": 218.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9634703196347032, "episode/intrinsic_return": 0.0}
{"step": 4096, "time": 507.2597930431366, "episode/length": 35.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 4168, "time": 511.1850426197052, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 4424, "time": 521.3980739116669, "episode/length": 83.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 4544, "time": 527.3989226818085, "episode/length": 176.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 4904, "time": 540.8946115970612, "episode/length": 147.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 5080, "time": 548.4360084533691, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 5160, "time": 552.7474045753479, "episode/length": 271.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9889705882352942, "episode/intrinsic_return": 0.0}
{"step": 5248, "time": 557.5285239219666, "episode/length": 148.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 5504, "time": 567.7754409313202, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 5584, "time": 572.077394247055, "episode/length": 185.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 6152, "time": 592.6228232383728, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 6192, "time": 595.7532474994659, "episode/length": 220.0, "episode/score": 2.1000000312924385, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 6296, "time": 600.5845859050751, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 6552, "time": 610.747211933136, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 6688, "time": 617.169914484024, "episode/length": 200.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 6840, "time": 623.7670571804047, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 6992, "time": 630.7297241687775, "episode/length": 175.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 7280, "time": 642.0001785755157, "episode/length": 140.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 7312, "time": 644.6134188175201, "episode/length": 257.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 7608, "time": 656.0706765651703, "episode/length": 163.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 7808, "time": 664.5882382392883, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 7824, "time": 666.7483022212982, "episode/length": 141.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 8064, "time": 676.3765170574188, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 8144, "time": 680.9153900146484, "episode/length": 107.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 8536, "time": 696.45858335495, "episode/length": 211.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 8536, "time": 696.4672958850861, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9896373056994818, "episode/intrinsic_return": 0.0}
{"step": 8624, "time": 702.9343919754028, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 9104, "time": 720.7316753864288, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 9216, "time": 725.989818572998, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 9272, "time": 729.3912920951843, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 9480, "time": 738.0444355010986, "episode/length": 166.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 9912, "time": 754.0220367908478, "episode/length": 171.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 761.6482577323914, "episode/length": 75.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 784.8871307373047, "eval_episode/length": 121.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9590163934426229}
{"step": 10088, "time": 787.9004004001617, "eval_episode/length": 155.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 10088, "time": 790.4520349502563, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 10088, "time": 792.1164691448212, "eval_episode/length": 178.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 10088, "time": 794.1763443946838, "eval_episode/length": 189.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 10088, "time": 796.5885863304138, "eval_episode/length": 206.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 10088, "time": 798.7833244800568, "eval_episode/length": 216.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 10088, "time": 802.6965346336365, "eval_episode/length": 108.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.963302752293578}
{"step": 10280, "time": 810.5604069232941, "episode/length": 276.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9927797833935018, "episode/intrinsic_return": 0.0}
{"step": 10280, "time": 810.5681047439575, "episode/length": 146.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 10312, "time": 815.1126163005829, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 10424, "time": 820.4522669315338, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 10472, "time": 823.6317830085754, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 10680, "time": 832.3276672363281, "episode/length": 95.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 11680, "time": 867.8202154636383, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 11680, "time": 867.8350355625153, "episode/length": 174.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 11752, "time": 873.3140189647675, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 11776, "time": 876.0084958076477, "episode/length": 210.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 11856, "time": 880.232447385788, "episode/length": 322.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 11944, "time": 884.5391321182251, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 11984, "time": 887.8330290317535, "episode/length": 162.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 12288, "time": 899.7642819881439, "episode/length": 226.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 12504, "time": 908.3876361846924, "episode/length": 90.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 12512, "time": 910.4530444145203, "episode/length": 103.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 12824, "time": 922.4077110290527, "episode/length": 104.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 12856, "time": 925.084846496582, "episode/length": 146.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 13400, "time": 945.0293099880219, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 13592, "time": 953.133073091507, "episode/length": 205.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 13696, "time": 958.428421497345, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 13696, "time": 958.4399812221527, "episode/length": 242.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 13952, "time": 970.5045416355133, "episode/length": 207.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 14240, "time": 981.8499600887299, "episode/length": 215.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 14312, "time": 985.7026777267456, "episode/length": 76.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 14400, "time": 990.5632014274597, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 14488, "time": 994.8413019180298, "episode/length": 207.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 14576, "time": 999.766708612442, "episode/length": 41.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 15056, "time": 1017.753261089325, "episode/length": 169.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 15080, "time": 1019.9484920501709, "episode/length": 209.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 15288, "time": 1028.562519311905, "episode/length": 88.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 15352, "time": 1032.2720110416412, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 15376, "time": 1034.7440257072449, "episode/length": 222.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 15568, "time": 1042.8411045074463, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 15672, "time": 1047.637374162674, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 15800, "time": 1053.3788363933563, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 16200, "time": 1068.5002942085266, "episode/length": 102.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 16632, "time": 1085.7724123001099, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 16736, "time": 1091.0316996574402, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 16944, "time": 1099.7735064029694, "episode/length": 235.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 16944, "time": 1099.782947063446, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 17320, "time": 1115.3872208595276, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 17328, "time": 1117.5171225070953, "episode/length": 219.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 17360, "time": 1120.236406326294, "episode/length": 250.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 17656, "time": 1131.814995765686, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 17944, "time": 1143.2039930820465, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 18416, "time": 1161.12953042984, "episode/length": 222.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9865470852017937, "episode/intrinsic_return": 0.0}
{"step": 18424, "time": 1162.7431807518005, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 18536, "time": 1168.1099569797516, "episode/length": 198.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 18576, "time": 1171.2803103923798, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 18576, "time": 1171.287941455841, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 18656, "time": 1177.5022099018097, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 19032, "time": 1191.452576637268, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 19512, "time": 1209.133267879486, "episode/length": 136.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 19672, "time": 1216.087567806244, "episode/length": 136.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.948905109489051, "episode/intrinsic_return": 0.0}
{"step": 19832, "time": 1223.1791603565216, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 19936, "time": 1228.4546806812286, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1250.2339487075806, "eval_episode/length": 55.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9107142857142857}
{"step": 20072, "time": 1254.4095628261566, "eval_episode/length": 117.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9576271186440678}
{"step": 20072, "time": 1257.7106440067291, "eval_episode/length": 156.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 20072, "time": 1260.136753320694, "eval_episode/length": 171.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 20072, "time": 1261.9254791736603, "eval_episode/length": 173.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 20072, "time": 1265.301968574524, "eval_episode/length": 155.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 20072, "time": 1265.3100862503052, "eval_episode/length": 211.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 20072, "time": 1268.7497630119324, "eval_episode/length": 213.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 20168, "time": 1271.972220659256, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 20232, "time": 1275.814237356186, "episode/length": 149.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 20288, "time": 1279.6526892185211, "episode/length": 203.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 20496, "time": 1288.2213771343231, "episode/length": 239.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 20656, "time": 1295.1124603748322, "episode/length": 338.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 20896, "time": 1304.7425949573517, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 21008, "time": 1310.1168744564056, "episode/length": 104.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 21192, "time": 1317.579514503479, "episode/length": 209.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 21216, "time": 1320.2241837978363, "episode/length": 159.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 21232, "time": 1322.3421440124512, "episode/length": 117.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 21800, "time": 1342.8634037971497, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 21880, "time": 1347.048594713211, "episode/length": 152.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 22000, "time": 1352.8480215072632, "episode/length": 187.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 22288, "time": 1364.1061856746674, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 22416, "time": 1370.1005687713623, "episode/length": 147.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 22432, "time": 1372.1893084049225, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 22433, "time": 1374.2491178512573, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.695072115384615, "train/action_min": 0.0, "train/action_std": 2.5375263264546026, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.01734273606349374, "train/actor_opt_grad_steps": 655.0, "train/actor_opt_loss": 175.94267719800655, "train/adv_mag": 1.710732253254033, "train/adv_max": 1.695597052301925, "train/adv_mean": 0.03103956443591988, "train/adv_min": -0.44508499271007995, "train/adv_std": 0.12632996521239667, "train/cont_avg": 0.9943659855769231, "train/cont_loss_mean": 0.030948004481167746, "train/cont_loss_std": 0.2566748328793507, "train/cont_neg_acc": 0.07103479974544966, "train/cont_neg_loss": 3.2366172503966553, "train/cont_pos_acc": 0.9936800625461798, "train/cont_pos_loss": 0.012534483842318877, "train/cont_pred": 0.9900016406407723, "train/cont_rate": 0.9943659855769231, "train/dyn_loss_mean": 5.5210771560668945, "train/dyn_loss_std": 7.551573756222542, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.695846024843362, "train/extr_critic_critic_opt_grad_steps": 655.0, "train/extr_critic_critic_opt_loss": 21163.254920372598, "train/extr_critic_mag": 0.1982606447660006, "train/extr_critic_max": 0.19826064293201154, "train/extr_critic_mean": 0.1156488129545827, "train/extr_critic_min": 0.02334303855895996, "train/extr_critic_std": 0.04875016786695443, "train/extr_return_normed_mag": 1.883677247506086, "train/extr_return_normed_max": 1.8788905368533866, "train/extr_return_normed_mean": 0.15892707039075527, "train/extr_return_normed_min": -0.3732806647752193, "train/extr_return_normed_std": 0.15114068814099396, "train/extr_return_rate": 0.033896235425401336, "train/extr_return_raw_mag": 1.870842624435855, "train/extr_return_raw_max": 1.8666518807841035, "train/extr_return_raw_mean": 0.14668840979381167, "train/extr_return_raw_min": -0.38551932272058004, "train/extr_return_raw_std": 0.15114068813382994, "train/extr_reward_mag": 0.5420538572164683, "train/extr_reward_max": 0.5415803799262413, "train/extr_reward_mean": 0.006901865902629932, "train/extr_reward_min": -0.098484245630411, "train/extr_reward_std": 0.030944836204918804, "train/image_loss_mean": 92.93329993027908, "train/image_loss_std": 49.78099222183228, "train/model_loss_mean": 96.61257454798772, "train/model_loss_std": 51.37761469620925, "train/model_opt_grad_norm": 260.15225870295086, "train/model_opt_grad_steps": 645.0, "train/model_opt_loss": 1298.4422237689678, "train/model_opt_model_opt_grad_overflow": 0.007692307692307693, "train/model_opt_model_opt_grad_scale": 11.944110576923077, "train/policy_entropy_mag": 1.475607748902761, "train/policy_entropy_max": 1.475607748902761, "train/policy_entropy_mean": 1.0178150183879413, "train/policy_entropy_min": 0.8102507325319144, "train/policy_entropy_std": 0.11513785978134435, "train/policy_logprob_mag": 6.698404306631822, "train/policy_logprob_max": -0.39071580581367016, "train/policy_logprob_mean": -1.0177575444945923, "train/policy_logprob_min": -6.698404306631822, "train/policy_logprob_std": 0.7863351652255425, "train/policy_randomness_mag": 0.5208247787104203, "train/policy_randomness_max": 0.5208247787104203, "train/policy_randomness_mean": 0.35924403888101764, "train/policy_randomness_min": 0.2859829517941062, "train/policy_randomness_std": 0.040638611700314166, "train/post_ent_mag": 52.39204615079439, "train/post_ent_max": 52.39204615079439, "train/post_ent_mean": 33.35394882789025, "train/post_ent_min": 16.58643283843994, "train/post_ent_std": 7.003989267578492, "train/prior_ent_mag": 57.78128943810096, "train/prior_ent_max": 57.78128943810096, "train/prior_ent_mean": 39.493237730172964, "train/prior_ent_min": 20.753859321887678, "train/prior_ent_std": 6.4215711130545685, "train/rep_loss_mean": 5.5210771560668945, "train/rep_loss_std": 7.551573756222542, "train/reward_avg": 0.007442908571997227, "train/reward_loss_mean": 0.33567978905943724, "train/reward_loss_std": 0.6802339637069841, "train/reward_max_data": 1.0084615404789263, "train/reward_max_pred": 0.6692353101877065, "train/reward_neg_acc": 0.9970481913823348, "train/reward_neg_loss": 0.29728675570625523, "train/reward_pos_acc": 0.4202540492209104, "train/reward_pos_loss": 3.2732839052493756, "train/reward_pred": 0.0050815998594491525, "train/reward_rate": 0.012575120192307693, "train_stats/sum_log_reward": 1.224999970321854, "train_stats/max_log_achievement_collect_drink": 0.225, "train_stats/max_log_achievement_collect_sapling": 7.791666666666667, "train_stats/max_log_achievement_collect_wood": 0.15833333333333333, "train_stats/max_log_achievement_place_plant": 1.125, "train_stats/max_log_achievement_wake_up": 0.48333333333333334, "train_stats/mean_log_entropy": 1.0529072485864162, "train_stats/max_log_achievement_place_table": 0.02586206896551724, "train_stats/max_log_achievement_defeat_zombie": 0.32926829268292684, "eval_stats/sum_log_reward": 1.4124999651685357, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 9.625, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.21428571428571427, "train_stats/max_log_achievement_eat_cow": 0.2054794520547945, "train_stats/max_log_achievement_defeat_skeleton": 0.014925373134328358, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.01493263989686966, "report/cont_loss_std": 0.15785443782806396, "report/cont_neg_acc": 0.5555555820465088, "report/cont_neg_loss": 1.053624153137207, "report/cont_pos_acc": 0.9970443844795227, "report/cont_pos_loss": 0.00572256650775671, "report/cont_pred": 0.9910292625427246, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 6.96879243850708, "report/dyn_loss_std": 5.994057655334473, "report/image_loss_mean": 23.938085556030273, "report/image_loss_std": 18.827198028564453, "report/model_loss_mean": 28.28338050842285, "report/model_loss_std": 20.467920303344727, "report/post_ent_mag": 44.28076171875, "report/post_ent_max": 44.28076171875, "report/post_ent_mean": 29.43863868713379, "report/post_ent_min": 12.324912071228027, "report/post_ent_std": 4.557995796203613, "report/prior_ent_mag": 48.577144622802734, "report/prior_ent_max": 48.577144622802734, "report/prior_ent_mean": 36.77304458618164, "report/prior_ent_min": 17.455894470214844, "report/prior_ent_std": 4.895533561706543, "report/rep_loss_mean": 6.96879243850708, "report/rep_loss_std": 5.994057655334473, "report/reward_avg": 0.01249999925494194, "report/reward_loss_mean": 0.14908629655838013, "report/reward_loss_std": 0.5372956395149231, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9734671115875244, "report/reward_neg_acc": 0.9960159659385681, "report/reward_neg_loss": 0.11997707933187485, "report/reward_pos_acc": 0.8500000238418579, "report/reward_pos_loss": 1.610369086265564, "report/reward_pred": 0.009155664592981339, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.004465716890990734, "eval/cont_loss_std": 0.07899118959903717, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 1.5958752632141113, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0013514128513634205, "eval/cont_pred": 0.9983245730400085, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 9.597710609436035, "eval/dyn_loss_std": 7.111412525177002, "eval/image_loss_mean": 56.490074157714844, "eval/image_loss_std": 49.980712890625, "eval/model_loss_mean": 62.40031433105469, "eval/model_loss_std": 51.763484954833984, "eval/post_ent_mag": 46.90106201171875, "eval/post_ent_max": 46.90106201171875, "eval/post_ent_mean": 30.426088333129883, "eval/post_ent_min": 12.266191482543945, "eval/post_ent_std": 6.5568156242370605, "eval/prior_ent_mag": 51.58594512939453, "eval/prior_ent_max": 51.58594512939453, "eval/prior_ent_mean": 37.493316650390625, "eval/prior_ent_min": 15.956803321838379, "eval/prior_ent_std": 6.7983598709106445, "eval/rep_loss_mean": 9.597710609436035, "eval/rep_loss_std": 7.111412525177002, "eval/reward_avg": 0.01201171800494194, "eval/reward_loss_mean": 0.14714425802230835, "eval/reward_loss_std": 0.7059662342071533, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9791727066040039, "eval/reward_neg_acc": 0.9980178475379944, "eval/reward_neg_loss": 0.10862637311220169, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.73811411857605, "eval/reward_pred": 0.0054155499674379826, "eval/reward_rate": 0.0146484375, "replay/size": 21929.0, "replay/inserts": 20872.0, "replay/samples": 20864.0, "replay/insert_wait_avg": 1.4539969383230974e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.830424025014865e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6472.0, "eval_replay/inserts": 3832.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3943007196414446e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 975.8361575603485, "timer/env.step_count": 2609.0, "timer/env.step_total": 264.8233358860016, "timer/env.step_frac": 0.2713809422148043, "timer/env.step_avg": 0.10150376998313591, "timer/env.step_min": 0.0241239070892334, "timer/env.step_max": 3.549243927001953, "timer/replay._sample_count": 20864.0, "timer/replay._sample_total": 11.040394306182861, "timer/replay._sample_frac": 0.011313778671395554, "timer/replay._sample_avg": 0.000529160003172108, "timer/replay._sample_min": 0.0003654956817626953, "timer/replay._sample_max": 0.02596569061279297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3088.0, "timer/agent.policy_total": 53.56088590621948, "timer/agent.policy_frac": 0.05488717085471095, "timer/agent.policy_avg": 0.017344846472221336, "timer/agent.policy_min": 0.00954127311706543, "timer/agent.policy_max": 0.12019968032836914, "timer/dataset_train_count": 1304.0, "timer/dataset_train_total": 0.15369057655334473, "timer/dataset_train_frac": 0.0001574962921414808, "timer/dataset_train_avg": 0.00011786087158998829, "timer/dataset_train_min": 9.036064147949219e-05, "timer/dataset_train_max": 0.0010776519775390625, "timer/agent.train_count": 1304.0, "timer/agent.train_total": 584.6194360256195, "timer/agent.train_frac": 0.5990958948346459, "timer/agent.train_avg": 0.44832778836320514, "timer/agent.train_min": 0.4357120990753174, "timer/agent.train_max": 1.2197136878967285, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47097182273864746, "timer/agent.report_frac": 0.0004826341175101633, "timer/agent.report_avg": 0.23548591136932373, "timer/agent.report_min": 0.2280445098876953, "timer/agent.report_max": 0.24292731285095215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.5426740136536305e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 21.388557594469475}
{"step": 22752, "time": 1385.240127325058, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 22896, "time": 1391.5730130672455, "episode/length": 126.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 22928, "time": 1394.2689173221588, "episode/length": 216.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 23384, "time": 1410.8331480026245, "episode/length": 60.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 23528, "time": 1417.2158076763153, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 23752, "time": 1426.1794941425323, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 23760, "time": 1428.4588108062744, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 24000, "time": 1437.9489767551422, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 24040, "time": 1440.5695927143097, "episode/length": 279.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 24112, "time": 1444.741444349289, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 24120, "time": 1446.3997197151184, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 24616, "time": 1465.7671732902527, "episode/length": 135.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 24664, "time": 1469.0089807510376, "episode/length": 67.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 24832, "time": 1476.3639779090881, "episode/length": 134.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 24840, "time": 1478.1206648349762, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 25240, "time": 1493.0690579414368, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 25360, "time": 1498.876921415329, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 25536, "time": 1506.2975490093231, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 25552, "time": 1508.411959886551, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 25872, "time": 1520.7157340049744, "episode/length": 156.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 25920, "time": 1524.0712730884552, "episode/length": 84.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9294117647058824, "episode/intrinsic_return": 0.0}
{"step": 25944, "time": 1526.362752199173, "episode/length": 48.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8979591836734694, "episode/intrinsic_return": 0.0}
{"step": 26048, "time": 1532.1518836021423, "episode/length": 151.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 26096, "time": 1535.2410111427307, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 26336, "time": 1544.755670785904, "episode/length": 186.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 26592, "time": 1555.0814106464386, "episode/length": 80.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 26704, "time": 1560.416350364685, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 27312, "time": 1582.4100394248962, "episode/length": 173.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 27360, "time": 1585.6753060817719, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 27392, "time": 1588.2953119277954, "episode/length": 99.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 27416, "time": 1590.593423128128, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 27536, "time": 1596.5494334697723, "episode/length": 179.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 27568, "time": 1599.2019765377045, "episode/length": 107.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 27608, "time": 1601.820306777954, "episode/length": 258.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9884169884169884, "episode/intrinsic_return": 0.0}
{"step": 27736, "time": 1607.7406508922577, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 28496, "time": 1634.9479188919067, "episode/length": 141.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 28720, "time": 1644.1040651798248, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 28744, "time": 1646.3234243392944, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 28752, "time": 1648.4246337413788, "episode/length": 179.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 28768, "time": 1651.0796887874603, "episode/length": 171.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 28896, "time": 1656.9242277145386, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 28984, "time": 1661.1501462459564, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 29064, "time": 1665.3307349681854, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 29512, "time": 1682.0576124191284, "episode/length": 55.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 29808, "time": 1693.7550168037415, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 30008, "time": 1701.946572303772, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1705.1371049880981, "episode/length": 163.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1723.9705934524536, "eval_episode/length": 110.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.963963963963964}
{"step": 30056, "time": 1726.7528829574585, "eval_episode/length": 133.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9626865671641791}
{"step": 30056, "time": 1729.2945129871368, "eval_episode/length": 150.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 30056, "time": 1731.6754438877106, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 30056, "time": 1734.7306096553802, "eval_episode/length": 171.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 30056, "time": 1736.5271291732788, "eval_episode/length": 178.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 30056, "time": 1738.210649728775, "eval_episode/length": 182.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.994535519125683}
{"step": 30056, "time": 1742.6336147785187, "eval_episode/length": 137.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 30112, "time": 1746.21062374115, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 30160, "time": 1749.424355506897, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 30208, "time": 1752.5817472934723, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 30256, "time": 1755.72390127182, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 30376, "time": 1761.2065880298615, "episode/length": 173.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 30840, "time": 1778.2115399837494, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 31408, "time": 1799.0613162517548, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 31448, "time": 1801.777807712555, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 31480, "time": 1804.4344699382782, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 31528, "time": 1807.5869085788727, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 31648, "time": 1813.4634425640106, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 31720, "time": 1817.4121260643005, "episode/length": 207.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 31760, "time": 1820.5400650501251, "episode/length": 199.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 32128, "time": 1834.4038798809052, "episode/length": 74.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 32168, "time": 1837.091565132141, "episode/length": 94.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 32656, "time": 1855.180253982544, "episode/length": 226.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 33040, "time": 1870.5819625854492, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 33208, "time": 1877.7507009506226, "episode/length": 215.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 33288, "time": 1882.0800516605377, "episode/length": 139.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 33664, "time": 1896.4268817901611, "episode/length": 237.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 33728, "time": 1900.0750830173492, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 33928, "time": 1908.2613825798035, "episode/length": 275.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 34128, "time": 1917.249752998352, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 34248, "time": 1922.5502672195435, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 34464, "time": 1931.5194058418274, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 34528, "time": 1935.1966893672943, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 34624, "time": 1940.11381149292, "episode/length": 46.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 34848, "time": 1949.179368019104, "episode/length": 399.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 34848, "time": 1949.188203573227, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 34992, "time": 1957.8052189350128, "episode/length": 157.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 35304, "time": 1969.5936522483826, "episode/length": 204.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 35424, "time": 1975.420470237732, "episode/length": 161.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 35672, "time": 1984.9543216228485, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 35912, "time": 1994.5790131092072, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 35952, "time": 1997.8859477043152, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 36080, "time": 2003.7318301200867, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 36440, "time": 2017.1994714736938, "episode/length": 65.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 36504, "time": 2020.8874695301056, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 36576, "time": 2025.2019600868225, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 36832, "time": 2035.416612148285, "episode/length": 190.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 37040, "time": 2043.9409866333008, "episode/length": 201.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 37168, "time": 2049.9387032985687, "episode/length": 90.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.945054945054945, "episode/intrinsic_return": 0.0}
{"step": 37296, "time": 2055.6603043079376, "episode/length": 202.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 37576, "time": 2066.5253925323486, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 37832, "time": 2076.620660305023, "episode/length": 218.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 37888, "time": 2080.364145755768, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 37944, "time": 2083.709973335266, "episode/length": 138.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 38144, "time": 2092.2545552253723, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9492753623188406, "episode/intrinsic_return": 0.0}
{"step": 38464, "time": 2104.503460407257, "episode/length": 71.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 38560, "time": 2109.2625806331635, "episode/length": 51.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 38664, "time": 2114.1261899471283, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 38912, "time": 2124.334057331085, "episode/length": 201.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 38928, "time": 2126.4273266792297, "episode/length": 136.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 39184, "time": 2136.643845319748, "episode/length": 154.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 39624, "time": 2152.644743680954, "episode/length": 119.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 39672, "time": 2155.848751306534, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 39760, "time": 2160.575792312622, "episode/length": 272.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 40008, "time": 2170.25860786438, "episode/length": 428.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2188.605381965637, "eval_episode/length": 55.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9285714285714286}
{"step": 40040, "time": 2194.115891456604, "eval_episode/length": 143.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 40040, "time": 2196.501918077469, "eval_episode/length": 161.0, "eval_episode/score": 3.099999964237213, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 40040, "time": 2196.5098876953125, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 40040, "time": 2200.409259557724, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9542857142857143}
{"step": 40040, "time": 2202.3488364219666, "eval_episode/length": 182.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.994535519125683}
{"step": 40040, "time": 2207.6460003852844, "eval_episode/length": 264.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 40040, "time": 2209.7746024131775, "eval_episode/length": 276.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9891696750902527}
{"step": 40152, "time": 2213.5372903347015, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 40288, "time": 2219.975682735443, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 40880, "time": 2241.514785051346, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 40968, "time": 2246.1352648735046, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 41168, "time": 2255.9317688941956, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 41208, "time": 2258.5797226428986, "episode/length": 191.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 41296, "time": 2263.3277196884155, "episode/length": 263.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 41352, "time": 2266.487909555435, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 41376, "time": 2269.279223680496, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 41408, "time": 2272.006878376007, "episode/length": 174.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 42328, "time": 2304.0708951950073, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 42400, "time": 2308.2980325222015, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 42464, "time": 2311.9836394786835, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 42512, "time": 2315.1664736270905, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 42624, "time": 2320.522079229355, "episode/length": 181.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 42640, "time": 2322.6113862991333, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 42656, "time": 2324.8558356761932, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 42680, "time": 2327.029400587082, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 43720, "time": 2363.467345237732, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 43824, "time": 2368.7205498218536, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 43832, "time": 2370.31170463562, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 43864, "time": 2372.9761703014374, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 43865, "time": 2375.6537642478943, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.536949043843284, "train/action_min": 0.0, "train/action_std": 3.102560436547692, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05152490778145061, "train/actor_opt_grad_steps": 1975.0, "train/actor_opt_loss": 57.03905075210244, "train/adv_mag": 2.594404564419789, "train/adv_max": 2.594404564419789, "train/adv_mean": 0.022802376574289344, "train/adv_min": -0.5883559555704914, "train/adv_std": 0.17999935355871471, "train/cont_avg": 0.9943519706156716, "train/cont_loss_mean": 0.0028211050003242983, "train/cont_loss_std": 0.0530293357896066, "train/cont_neg_acc": 0.8914055352780357, "train/cont_neg_loss": 0.3107545119031539, "train/cont_pos_acc": 0.9997065053946936, "train/cont_pos_loss": 0.001030411060403129, "train/cont_pred": 0.9943806208781342, "train/cont_rate": 0.9943519706156716, "train/dyn_loss_mean": 6.336519832041726, "train/dyn_loss_std": 5.660444942872916, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.371791153256573, "train/extr_critic_critic_opt_grad_steps": 1975.0, "train/extr_critic_critic_opt_loss": 15742.743601329292, "train/extr_critic_mag": 1.067751338232809, "train/extr_critic_max": 1.067751338232809, "train/extr_critic_mean": 0.3249382438944347, "train/extr_critic_min": -0.2077023146757439, "train/extr_critic_std": 0.39098997514194517, "train/extr_return_normed_mag": 3.32067620220469, "train/extr_return_normed_max": 3.32067620220469, "train/extr_return_normed_mean": 0.4084399270255174, "train/extr_return_normed_min": -0.3174590507883634, "train/extr_return_normed_std": 0.3684705412432329, "train/extr_return_rate": 0.2649686275216848, "train/extr_return_raw_mag": 4.134065080044874, "train/extr_return_raw_max": 4.134065080044874, "train/extr_return_raw_mean": 0.35616449541898804, "train/extr_return_raw_min": -0.6243040352614958, "train/extr_return_raw_std": 0.5011576563119888, "train/extr_reward_mag": 0.9845514430928586, "train/extr_reward_max": 0.9845514430928586, "train/extr_reward_mean": 0.011687054694108943, "train/extr_reward_min": -0.3534936504577523, "train/extr_reward_std": 0.08221371045141522, "train/image_loss_mean": 17.54022296506967, "train/image_loss_std": 18.407117736873342, "train/model_loss_mean": 21.422763361859676, "train/model_loss_std": 20.10788030766729, "train/model_opt_grad_norm": 137.98494663523203, "train/model_opt_grad_steps": 1965.0, "train/model_opt_loss": 622.2689961675387, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 28.713852611940297, "train/policy_entropy_mag": 2.067563599614955, "train/policy_entropy_max": 2.067563599614955, "train/policy_entropy_mean": 0.4662346391757922, "train/policy_entropy_min": 0.0795316418716267, "train/policy_entropy_std": 0.4119941746788238, "train/policy_logprob_mag": 7.4377321164999435, "train/policy_logprob_max": -0.009477547272595007, "train/policy_logprob_mean": -0.4668121297301641, "train/policy_logprob_min": -7.4377321164999435, "train/policy_logprob_std": 1.0549720903830742, "train/policy_randomness_mag": 0.7297592191998639, "train/policy_randomness_max": 0.7297592191998639, "train/policy_randomness_mean": 0.16456036775637028, "train/policy_randomness_min": 0.028071179374385236, "train/policy_randomness_std": 0.14541586296660686, "train/post_ent_mag": 41.392236823466284, "train/post_ent_max": 41.392236823466284, "train/post_ent_mean": 29.839227832964998, "train/post_ent_min": 13.226219952996097, "train/post_ent_std": 4.033174226533121, "train/prior_ent_mag": 50.65413608835704, "train/prior_ent_max": 50.65413608835704, "train/prior_ent_mean": 36.33510464340893, "train/prior_ent_min": 17.091702069809187, "train/prior_ent_std": 4.784168444462677, "train/rep_loss_mean": 6.336519832041726, "train/rep_loss_std": 5.660444942872916, "train/reward_avg": 0.00815939829066229, "train/reward_loss_mean": 0.07780734641449664, "train/reward_loss_std": 0.38464009617246797, "train/reward_max_data": 1.0074626883464073, "train/reward_max_pred": 0.9897652392956748, "train/reward_neg_acc": 0.9960526263535913, "train/reward_neg_loss": 0.05917001686601052, "train/reward_pos_acc": 0.8365132319393442, "train/reward_pos_loss": 1.4823264702042538, "train/reward_pred": 0.007184874547867855, "train/reward_rate": 0.013336637126865671, "train_stats/sum_log_reward": 1.9818897017343777, "train_stats/max_log_achievement_collect_drink": 11.204724409448819, "train_stats/max_log_achievement_collect_sapling": 2.2598425196850394, "train_stats/max_log_achievement_collect_wood": 0.1732283464566929, "train_stats/max_log_achievement_defeat_skeleton": 0.007874015748031496, "train_stats/max_log_achievement_defeat_zombie": 0.08661417322834646, "train_stats/max_log_achievement_eat_cow": 0.07086614173228346, "train_stats/max_log_achievement_place_plant": 2.125984251968504, "train_stats/max_log_achievement_place_table": 0.0, "train_stats/max_log_achievement_wake_up": 1.5354330708661417, "train_stats/mean_log_entropy": 0.34051345840213804, "eval_stats/sum_log_reward": 2.59999992698431, "eval_stats/max_log_achievement_collect_drink": 10.375, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_wood": 0.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 2.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.6479596524732187e-05, "report/cont_loss_std": 0.00026000954676419497, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0013815995771437883, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.433702532784082e-06, "report/cont_pred": 0.9941402673721313, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 5.99411678314209, "report/dyn_loss_std": 5.681138515472412, "report/image_loss_mean": 14.95730972290039, "report/image_loss_std": 15.38448715209961, "report/model_loss_mean": 18.61827278137207, "report/model_loss_std": 17.156421661376953, "report/post_ent_mag": 38.57666778564453, "report/post_ent_max": 38.57666778564453, "report/post_ent_mean": 30.030664443969727, "report/post_ent_min": 11.471206665039062, "report/post_ent_std": 3.854001045227051, "report/prior_ent_mag": 50.96000671386719, "report/prior_ent_max": 50.96000671386719, "report/prior_ent_mean": 36.48871612548828, "report/prior_ent_min": 14.933897972106934, "report/prior_ent_std": 5.106037139892578, "report/rep_loss_mean": 5.99411678314209, "report/rep_loss_std": 5.681138515472412, "report/reward_avg": 0.01103515550494194, "report/reward_loss_mean": 0.06447635591030121, "report/reward_loss_std": 0.4010692536830902, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9993609189987183, "report/reward_neg_acc": 0.9980159401893616, "report/reward_neg_loss": 0.03540150821208954, "report/reward_pos_acc": 0.75, "report/reward_pos_loss": 1.8961917161941528, "report/reward_pred": 0.008476920425891876, "report/reward_rate": 0.015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.000483088253531605, "eval/cont_loss_std": 0.009268254972994328, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01675637625157833, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00041927144047804177, "eval/cont_pred": 0.995777428150177, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 11.4082670211792, "eval/dyn_loss_std": 6.489123344421387, "eval/image_loss_mean": 48.90835189819336, "eval/image_loss_std": 57.65739440917969, "eval/model_loss_mean": 55.900550842285156, "eval/model_loss_std": 59.3068733215332, "eval/post_ent_mag": 41.15522766113281, "eval/post_ent_max": 41.15522766113281, "eval/post_ent_mean": 29.977855682373047, "eval/post_ent_min": 12.421897888183594, "eval/post_ent_std": 5.467820644378662, "eval/prior_ent_mag": 52.42621994018555, "eval/prior_ent_max": 52.42621994018555, "eval/prior_ent_mean": 38.743011474609375, "eval/prior_ent_min": 16.235363006591797, "eval/prior_ent_std": 6.774610996246338, "eval/rep_loss_mean": 11.4082670211792, "eval/rep_loss_std": 6.489123344421387, "eval/reward_avg": 0.01230468787252903, "eval/reward_loss_mean": 0.1467496007680893, "eval/reward_loss_std": 0.7389197945594788, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9967429637908936, "eval/reward_neg_acc": 0.9980159401893616, "eval/reward_neg_loss": 0.12158386409282684, "eval/reward_pos_acc": 0.8125, "eval/reward_pos_loss": 1.732191562652588, "eval/reward_pred": 0.009375747293233871, "eval/reward_rate": 0.015625, "replay/size": 43361.0, "replay/inserts": 21432.0, "replay/samples": 21440.0, "replay/insert_wait_avg": 1.4037016213229451e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.003704409101116e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10680.0, "eval_replay/inserts": 4208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3035966416275547e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3937880992889, "timer/env.step_count": 2679.0, "timer/env.step_total": 277.95534229278564, "timer/env.step_frac": 0.27756847066163964, "timer/env.step_avg": 0.10375339391294723, "timer/env.step_min": 0.02388906478881836, "timer/env.step_max": 3.3897573947906494, "timer/replay._sample_count": 21440.0, "timer/replay._sample_total": 11.072186946868896, "timer/replay._sample_frac": 0.011056776143863078, "timer/replay._sample_avg": 0.0005164266299845568, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.010225772857666016, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3205.0, "timer/agent.policy_total": 54.7682683467865, "timer/agent.policy_frac": 0.05469203923337718, "timer/agent.policy_avg": 0.01708838325952777, "timer/agent.policy_min": 0.009433507919311523, "timer/agent.policy_max": 0.12765789031982422, "timer/dataset_train_count": 1340.0, "timer/dataset_train_total": 0.15150737762451172, "timer/dataset_train_frac": 0.00015129650236005824, "timer/dataset_train_avg": 0.00011306520718247143, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.001081228256225586, "timer/agent.train_count": 1340.0, "timer/agent.train_total": 598.2526314258575, "timer/agent.train_frac": 0.5974199546028544, "timer/agent.train_avg": 0.446457187631237, "timer/agent.train_min": 0.43492770195007324, "timer/agent.train_max": 1.2729918956756592, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749877452850342, "timer/agent.report_frac": 0.00047432663446673865, "timer/agent.report_avg": 0.2374938726425171, "timer/agent.report_min": 0.23036670684814453, "timer/agent.report_max": 0.24462103843688965, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.118936250002774e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.40190740997183}
{"step": 43952, "time": 2378.6454558372498, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 43976, "time": 2380.9258217811584, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 44208, "time": 2390.7009992599487, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 44464, "time": 2401.02836227417, "episode/length": 266.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 44680, "time": 2409.6068363189697, "episode/length": 90.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9340659340659341, "episode/intrinsic_return": 0.0}
{"step": 44856, "time": 2417.1113600730896, "episode/length": 141.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 45192, "time": 2430.2605426311493, "episode/length": 63.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 45200, "time": 2432.246913433075, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 45264, "time": 2435.9378876686096, "episode/length": 178.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 45512, "time": 2445.7845306396484, "episode/length": 205.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 45704, "time": 2454.07678771019, "episode/length": 186.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 45784, "time": 2458.40442943573, "episode/length": 225.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 45848, "time": 2462.146833181381, "episode/length": 172.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 46456, "time": 2484.4508094787598, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 46520, "time": 2488.2494990825653, "episode/length": 156.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 46608, "time": 2493.074895143509, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 46720, "time": 2498.486338376999, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 46840, "time": 2504.0071358680725, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 46848, "time": 2506.016246318817, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 47536, "time": 2530.9685266017914, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 47600, "time": 2534.63596367836, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 47680, "time": 2539.041107416153, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 47832, "time": 2545.511740207672, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 48072, "time": 2555.1965210437775, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 48120, "time": 2558.35631108284, "episode/length": 188.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 48136, "time": 2560.453200340271, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 48400, "time": 2571.174881696701, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 48856, "time": 2587.9552977085114, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 48928, "time": 2592.306569337845, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 49320, "time": 2608.1903121471405, "episode/length": 214.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 49624, "time": 2620.1401109695435, "episode/length": 223.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 49664, "time": 2623.2946105003357, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 49800, "time": 2629.409159183502, "episode/length": 207.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2653.945774793625, "eval_episode/length": 50.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 50024, "time": 2655.8211929798126, "eval_episode/length": 55.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 50024, "time": 2658.885214805603, "eval_episode/length": 82.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9518072289156626}
{"step": 50024, "time": 2661.3820650577545, "eval_episode/length": 46.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 50024, "time": 2663.490510225296, "eval_episode/length": 114.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9652173913043478}
{"step": 50024, "time": 2667.193426847458, "eval_episode/length": 160.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 50024, "time": 2669.8898696899414, "eval_episode/length": 183.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 50024, "time": 2673.8853476047516, "eval_episode/length": 186.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 50024, "time": 2673.8934779167175, "eval_episode/length": 134.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9555555555555556}
{"step": 50232, "time": 2681.0445306301117, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 50296, "time": 2684.8121547698975, "episode/length": 271.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 50448, "time": 2691.9720084667206, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 50528, "time": 2696.2556834220886, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 50856, "time": 2708.812612771988, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 50944, "time": 2713.586123228073, "episode/length": 202.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 51248, "time": 2725.620926141739, "episode/length": 37.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 51272, "time": 2727.8663494586945, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 51400, "time": 2733.8520748615265, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 51504, "time": 2739.1678397655487, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 51680, "time": 2746.7608296871185, "episode/length": 143.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 52008, "time": 2759.468588113785, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 52168, "time": 2766.557590007782, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 52288, "time": 2772.3438851833344, "episode/length": 75.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9210526315789473, "episode/intrinsic_return": 0.0}
{"step": 52336, "time": 2775.5714609622955, "episode/length": 262.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 52664, "time": 2788.145993947983, "episode/length": 173.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 52768, "time": 2793.4602773189545, "episode/length": 189.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 53384, "time": 2815.64964222908, "episode/length": 89.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 53440, "time": 2819.3951086997986, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 53568, "time": 2825.2374234199524, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 53632, "time": 2828.969818353653, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 53680, "time": 2832.199861049652, "episode/length": 271.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 53800, "time": 2837.712647676468, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 54376, "time": 2858.8214650154114, "episode/length": 86.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 54568, "time": 2866.8191521167755, "episode/length": 278.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 54616, "time": 2870.2238454818726, "episode/length": 401.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 54808, "time": 2878.3464097976685, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 54880, "time": 2882.5857195854187, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 55024, "time": 2889.06201672554, "episode/length": 152.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 55272, "time": 2899.0122530460358, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 55416, "time": 2905.386048555374, "episode/length": 246.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 55528, "time": 2910.7211198806763, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 56144, "time": 2933.389352798462, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 56240, "time": 2938.206013917923, "episode/length": 208.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 56296, "time": 2941.4120774269104, "episode/length": 127.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 56448, "time": 2948.2960114479065, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 56616, "time": 2955.2666618824005, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 56648, "time": 2958.030531167984, "episode/length": 153.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 56656, "time": 2960.174446582794, "episode/length": 203.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 57264, "time": 2982.416746377945, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 57496, "time": 2993.0156836509705, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 57600, "time": 2998.3319544792175, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 58016, "time": 3014.0965218544006, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 58072, "time": 3017.5149619579315, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 58088, "time": 3019.693632364273, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 58192, "time": 3024.986685037613, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 58448, "time": 3035.1312329769135, "episode/length": 53.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 58696, "time": 3044.8769335746765, "episode/length": 299.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 58736, "time": 3048.2157049179077, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 58848, "time": 3053.496412038803, "episode/length": 155.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 59512, "time": 3077.2425384521484, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 59536, "time": 3080.053311109543, "episode/length": 254.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 59560, "time": 3082.234389781952, "episode/length": 138.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 59576, "time": 3084.3635013103485, "episode/length": 187.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 59976, "time": 3099.53098154068, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 59976, "time": 3099.5395028591156, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3119.206928253174, "eval_episode/length": 37.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 60008, "time": 3125.8862974643707, "eval_episode/length": 150.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 60008, "time": 3127.8629701137543, "eval_episode/length": 160.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 60008, "time": 3129.928931236267, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 60008, "time": 3131.8551704883575, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 60008, "time": 3133.620182275772, "eval_episode/length": 182.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 60008, "time": 3135.2560205459595, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 60008, "time": 3139.273220539093, "eval_episode/length": 232.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 60672, "time": 3161.8038985729218, "episode/length": 227.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 60680, "time": 3163.486700296402, "episode/length": 242.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 60696, "time": 3165.606461048126, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 60776, "time": 3170.063654899597, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 60880, "time": 3175.3860301971436, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 61024, "time": 3181.915260076523, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 61200, "time": 3189.487128019333, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 61664, "time": 3206.625577688217, "episode/length": 210.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 61840, "time": 3214.0228152275085, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 61896, "time": 3217.2725734710693, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 62032, "time": 3223.7252662181854, "episode/length": 156.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 62048, "time": 3225.9072732925415, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 62456, "time": 3241.1786954402924, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 62592, "time": 3247.614098548889, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 62592, "time": 3247.6223101615906, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 63128, "time": 3268.7563676834106, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 63216, "time": 3273.4962096214294, "episode/length": 145.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 63232, "time": 3275.609977245331, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 63280, "time": 3278.7730424404144, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 63800, "time": 3297.6884043216705, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 63832, "time": 3300.312374353409, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 63840, "time": 3302.399341106415, "episode/length": 88.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 63888, "time": 3305.6265301704407, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 64184, "time": 3316.8640592098236, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 64728, "time": 3336.903829574585, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 64832, "time": 3342.221705675125, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 64904, "time": 3345.9201242923737, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 65208, "time": 3357.855925798416, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9532163742690059, "episode/intrinsic_return": 0.0}
{"step": 65264, "time": 3361.564742088318, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 65272, "time": 3363.2425112724304, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 65496, "time": 3372.438302755356, "episode/length": 200.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 65521, "time": 3375.6740255355835, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.071708170572917, "train/action_min": 0.0, "train/action_std": 3.4559333147826017, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04774473403339033, "train/actor_opt_grad_steps": 3320.0, "train/actor_opt_loss": 30.53635061228717, "train/adv_mag": 1.3736705312022457, "train/adv_max": 1.3727994759877522, "train/adv_mean": 0.010533796548325982, "train/adv_min": -0.5531598965326945, "train/adv_std": 0.10692302474269161, "train/cont_avg": 0.9943504050925925, "train/cont_loss_mean": 0.000770892032614433, "train/cont_loss_std": 0.019224749311817706, "train/cont_neg_acc": 0.978136392875954, "train/cont_neg_loss": 0.06539905543277959, "train/cont_pos_acc": 0.9998543633355035, "train/cont_pos_loss": 0.0004182464385840595, "train/cont_pred": 0.9942782437359845, "train/cont_rate": 0.9943504050925925, "train/dyn_loss_mean": 7.347214780030427, "train/dyn_loss_std": 6.501900690573233, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0851656432505008, "train/extr_critic_critic_opt_grad_steps": 3320.0, "train/extr_critic_critic_opt_loss": 14694.891196469907, "train/extr_critic_mag": 1.8048552301194933, "train/extr_critic_max": 1.8048552301194933, "train/extr_critic_mean": 0.5106453670395745, "train/extr_critic_min": -0.17180149643509476, "train/extr_critic_std": 0.6366477699191482, "train/extr_return_normed_mag": 2.2131541146172418, "train/extr_return_normed_max": 2.2131541146172418, "train/extr_return_normed_mean": 0.36738476830500144, "train/extr_return_normed_min": -0.22488839245504802, "train/extr_return_normed_std": 0.37811877528826393, "train/extr_return_rate": 0.3386439234018326, "train/extr_return_raw_mag": 3.884371512024491, "train/extr_return_raw_max": 3.884371512024491, "train/extr_return_raw_mean": 0.5296557417622318, "train/extr_return_raw_min": -0.5442985788539604, "train/extr_return_raw_std": 0.6874741969285187, "train/extr_reward_mag": 1.0018515675156205, "train/extr_reward_max": 1.0018515675156205, "train/extr_reward_mean": 0.011832120197100771, "train/extr_reward_min": -0.37927343050638834, "train/extr_reward_std": 0.09222353536773611, "train/image_loss_mean": 17.71048088780156, "train/image_loss_std": 20.94233458483661, "train/model_loss_mean": 22.17641278019658, "train/model_loss_std": 23.26588906182183, "train/model_opt_grad_norm": 133.5986144736961, "train/model_opt_grad_steps": 3310.0, "train/model_opt_loss": 1504.0621975368924, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 67.41898148148148, "train/policy_entropy_mag": 2.40533316400316, "train/policy_entropy_max": 2.40533316400316, "train/policy_entropy_mean": 0.8746448534506338, "train/policy_entropy_min": 0.07962111626510267, "train/policy_entropy_std": 0.5526192976368798, "train/policy_logprob_mag": 7.43685641112151, "train/policy_logprob_max": -0.009489775766377096, "train/policy_logprob_mean": -0.8734066760098492, "train/policy_logprob_min": -7.43685641112151, "train/policy_logprob_std": 1.2246785852644178, "train/policy_randomness_mag": 0.848977052282404, "train/policy_randomness_max": 0.848977052282404, "train/policy_randomness_mean": 0.3087112507334462, "train/policy_randomness_min": 0.028102759947931325, "train/policy_randomness_std": 0.19505035987606756, "train/post_ent_mag": 43.42739376491971, "train/post_ent_max": 43.42739376491971, "train/post_ent_mean": 30.56905261852123, "train/post_ent_min": 13.239755143059625, "train/post_ent_std": 4.714227259600604, "train/prior_ent_mag": 55.3558481004503, "train/prior_ent_max": 55.3558481004503, "train/prior_ent_mean": 38.01942822491681, "train/prior_ent_min": 15.854028263798467, "train/prior_ent_std": 6.306731153417517, "train/rep_loss_mean": 7.347214780030427, "train/rep_loss_std": 6.501900690573233, "train/reward_avg": 0.010831163081995866, "train/reward_loss_mean": 0.05683185771383621, "train/reward_loss_std": 0.29705212359075195, "train/reward_max_data": 1.0170370410989833, "train/reward_max_pred": 0.9985958593863028, "train/reward_neg_acc": 0.9941243688265483, "train/reward_neg_loss": 0.03881804580213847, "train/reward_pos_acc": 0.909570993759014, "train/reward_pos_loss": 1.1672269445878487, "train/reward_pred": 0.010090423646141534, "train/reward_rate": 0.016022858796296297, "train_stats/sum_log_reward": 3.108333270748456, "train_stats/max_log_achievement_collect_drink": 6.841666666666667, "train_stats/max_log_achievement_collect_sapling": 3.8, "train_stats/max_log_achievement_collect_wood": 0.9, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.125, "train_stats/max_log_achievement_eat_cow": 0.11666666666666667, "train_stats/max_log_achievement_place_plant": 3.533333333333333, "train_stats/max_log_achievement_place_table": 0.03333333333333333, "train_stats/max_log_achievement_wake_up": 1.8416666666666666, "train_stats/mean_log_entropy": 0.8134831080834071, "eval_stats/sum_log_reward": 2.864705815034754, "eval_stats/max_log_achievement_collect_drink": 2.176470588235294, "eval_stats/max_log_achievement_collect_sapling": 3.764705882352941, "eval_stats/max_log_achievement_collect_wood": 0.5294117647058824, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_place_plant": 3.5294117647058822, "eval_stats/max_log_achievement_place_table": 0.17647058823529413, "eval_stats/max_log_achievement_wake_up": 1.1764705882352942, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.2, "train_stats/max_log_achievement_make_wood_sword": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 1.0445415682625026e-05, "report/cont_loss_std": 9.999655594583601e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0007645871955901384, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.507291578192962e-06, "report/cont_pred": 0.9921889901161194, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 9.09598159790039, "report/dyn_loss_std": 6.512106895446777, "report/image_loss_mean": 17.051342010498047, "report/image_loss_std": 17.11982536315918, "report/model_loss_mean": 22.571868896484375, "report/model_loss_std": 19.683319091796875, "report/post_ent_mag": 42.60850524902344, "report/post_ent_max": 42.60850524902344, "report/post_ent_mean": 30.55606460571289, "report/post_ent_min": 14.701949119567871, "report/post_ent_std": 4.813725471496582, "report/prior_ent_mag": 61.48661804199219, "report/prior_ent_max": 61.48661804199219, "report/prior_ent_mean": 40.870018005371094, "report/prior_ent_min": 16.567052841186523, "report/prior_ent_std": 7.364764213562012, "report/rep_loss_mean": 9.09598159790039, "report/rep_loss_std": 6.512106895446777, "report/reward_avg": 0.01894531399011612, "report/reward_loss_mean": 0.06292741745710373, "report/reward_loss_std": 0.27302494645118713, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9944746494293213, "report/reward_neg_acc": 0.9919840097427368, "report/reward_neg_loss": 0.044405531138181686, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7738828659057617, "report/reward_pred": 0.018737412989139557, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.3118594981497154e-05, "eval/cont_loss_std": 0.0004723137244582176, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.005133321974426508, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 3.078582039961475e-06, "eval/cont_pred": 0.9961106181144714, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 12.575371742248535, "eval/dyn_loss_std": 6.649532794952393, "eval/image_loss_mean": 28.35329818725586, "eval/image_loss_std": 24.109949111938477, "eval/model_loss_mean": 36.007537841796875, "eval/model_loss_std": 26.1307430267334, "eval/post_ent_mag": 43.02482223510742, "eval/post_ent_max": 43.02482223510742, "eval/post_ent_mean": 30.51144027709961, "eval/post_ent_min": 18.33480453491211, "eval/post_ent_std": 4.90128755569458, "eval/prior_ent_mag": 54.88969421386719, "eval/prior_ent_max": 54.88969421386719, "eval/prior_ent_mean": 41.25220489501953, "eval/prior_ent_min": 16.473373413085938, "eval/prior_ent_std": 7.483537673950195, "eval/rep_loss_mean": 12.575371742248535, "eval/rep_loss_std": 6.649532794952393, "eval/reward_avg": 0.011914062313735485, "eval/reward_loss_mean": 0.1089925616979599, "eval/reward_loss_std": 0.7272626161575317, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9989980459213257, "eval/reward_neg_acc": 0.9960356950759888, "eval/reward_neg_loss": 0.05847935006022453, "eval/reward_pos_acc": 0.6000000238418579, "eval/reward_pos_loss": 3.5068485736846924, "eval/reward_pred": 0.0037391898222267628, "eval/reward_rate": 0.0146484375, "replay/size": 65017.0, "replay/inserts": 21656.0, "replay/samples": 21648.0, "replay/insert_wait_avg": 1.4525522021380659e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.751926647674042e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 14448.0, "eval_replay/inserts": 3768.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3311703999837239e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0072827339172, "timer/env.step_count": 2707.0, "timer/env.step_total": 268.916246175766, "timer/env.step_frac": 0.26891428774456183, "timer/env.step_avg": 0.09934105880153897, "timer/env.step_min": 0.024287939071655273, "timer/env.step_max": 3.411932945251465, "timer/replay._sample_count": 21648.0, "timer/replay._sample_total": 11.59395694732666, "timer/replay._sample_frac": 0.011593872512238083, "timer/replay._sample_avg": 0.000535567116931202, "timer/replay._sample_min": 0.0003848075866699219, "timer/replay._sample_max": 0.011460304260253906, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3178.0, "timer/agent.policy_total": 54.726640462875366, "timer/agent.policy_frac": 0.05472624190621727, "timer/agent.policy_avg": 0.017220465847349077, "timer/agent.policy_min": 0.009663105010986328, "timer/agent.policy_max": 0.09465193748474121, "timer/dataset_train_count": 1353.0, "timer/dataset_train_total": 0.15900802612304688, "timer/dataset_train_frac": 0.00015900686811833536, "timer/dataset_train_avg": 0.0001175225618056518, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.0009486675262451172, "timer/agent.train_count": 1353.0, "timer/agent.train_total": 607.9678239822388, "timer/agent.train_frac": 0.6079633963465918, "timer/agent.train_avg": 0.4493479852049067, "timer/agent.train_min": 0.43829822540283203, "timer/agent.train_max": 1.5904479026794434, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772226810455322, "timer/agent.report_frac": 0.00047721920558503774, "timer/agent.report_avg": 0.2386113405227661, "timer/agent.report_min": 0.22894978523254395, "timer/agent.report_max": 0.24827289581298828, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2424690617418384e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 21.655590804053883}
{"step": 65736, "time": 3384.6238329410553, "episode/length": 193.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 66024, "time": 3395.8699333667755, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 66288, "time": 3406.5361063480377, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 66448, "time": 3413.587881565094, "episode/length": 154.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 66768, "time": 3425.9537551403046, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 66912, "time": 3432.389820098877, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 67032, "time": 3437.976894378662, "episode/length": 161.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 67032, "time": 3437.985421180725, "episode/length": 265.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 67064, "time": 3442.434088945389, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 67352, "time": 3453.6764285564423, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 67488, "time": 3460.172759771347, "episode/length": 52.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 67616, "time": 3466.1552481651306, "episode/length": 105.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 67752, "time": 3472.4858796596527, "episode/length": 49.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 67896, "time": 3479.488480567932, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 67960, "time": 3483.1918907165527, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 68320, "time": 3497.0300619602203, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 68408, "time": 3501.5324544906616, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 68416, "time": 3503.6124045848846, "episode/length": 172.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 69352, "time": 3536.8016204833984, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 69376, "time": 3539.4263932704926, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 69384, "time": 3541.0194849967957, "episode/length": 220.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 69664, "time": 3552.3198404312134, "episode/length": 238.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9916317991631799, "episode/intrinsic_return": 0.0}
{"step": 69856, "time": 3560.436133146286, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 69872, "time": 3562.6877777576447, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 70016, "time": 3569.3168909549713, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3593.555232524872, "eval_episode/length": 132.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 70096, "time": 3595.7103128433228, "eval_episode/length": 144.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 70096, "time": 3597.4175827503204, "eval_episode/length": 150.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 70096, "time": 3599.7459013462067, "eval_episode/length": 166.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 70096, "time": 3601.780121564865, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 70096, "time": 3605.5737686157227, "eval_episode/length": 193.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 70096, "time": 3607.195723772049, "eval_episode/length": 194.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 70096, "time": 3610.9426572322845, "eval_episode/length": 242.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 70592, "time": 3627.6061215400696, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 70592, "time": 3627.616856575012, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 70800, "time": 3637.985243320465, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 71008, "time": 3646.6874148845673, "episode/length": 439.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 71080, "time": 3650.6799609661102, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 71104, "time": 3653.219880580902, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 71368, "time": 3663.809591293335, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 71720, "time": 3677.3905234336853, "episode/length": 212.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 71936, "time": 3686.453691959381, "episode/length": 167.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 71968, "time": 3689.128399372101, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 72200, "time": 3698.3397827148438, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 72264, "time": 3702.0815527439117, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 72536, "time": 3713.1494879722595, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 72552, "time": 3715.298910140991, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 72832, "time": 3726.5337014198303, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 72976, "time": 3732.969501018524, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 73256, "time": 3743.752904891968, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 73752, "time": 3763.387672662735, "episode/length": 226.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 73800, "time": 3766.647433280945, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 73856, "time": 3770.507729291916, "episode/length": 206.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 73872, "time": 3773.2495040893555, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 74160, "time": 3785.117909193039, "episode/length": 200.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 74168, "time": 3786.7449016571045, "episode/length": 166.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 74424, "time": 3796.914033651352, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 74584, "time": 3804.1213138103485, "episode/length": 165.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 74768, "time": 3812.0541899204254, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 75016, "time": 3821.8164954185486, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 75168, "time": 3828.808963060379, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 75328, "time": 3835.960114955902, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 75352, "time": 3838.129019498825, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 75728, "time": 3852.594221830368, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 75736, "time": 3854.2533180713654, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 75944, "time": 3862.9597582817078, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 76216, "time": 3873.669553041458, "episode/length": 180.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 76312, "time": 3878.4738762378693, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 76528, "time": 3887.669618368149, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 76752, "time": 3896.768051147461, "episode/length": 216.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 76904, "time": 3903.2275552749634, "episode/length": 193.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 76968, "time": 3907.048747777939, "episode/length": 153.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 76976, "time": 3909.213297843933, "episode/length": 82.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 77184, "time": 3917.9765119552612, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 77344, "time": 3925.0156173706055, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 77456, "time": 3930.3015789985657, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 77648, "time": 3938.319182395935, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 78144, "time": 3956.6592643260956, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 78224, "time": 3960.972140312195, "episode/length": 109.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 78296, "time": 3964.729406118393, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 78568, "time": 3975.546199798584, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 78600, "time": 3978.2868275642395, "episode/length": 211.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 78648, "time": 3981.4164564609528, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 78760, "time": 3986.812079191208, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 78776, "time": 3988.8684434890747, "episode/length": 140.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 79472, "time": 4014.1951229572296, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 79632, "time": 4021.1593408584595, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 79664, "time": 4023.9024958610535, "episode/length": 189.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 79912, "time": 4033.6450934410095, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4059.543579339981, "eval_episode/length": 104.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 80080, "time": 4061.5177907943726, "eval_episode/length": 112.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 80080, "time": 4065.6361525058746, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 80080, "time": 4067.8754727840424, "eval_episode/length": 181.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 80080, "time": 4070.0342502593994, "eval_episode/length": 192.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 80080, "time": 4071.885443210602, "eval_episode/length": 197.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 80080, "time": 4074.3146879673004, "eval_episode/length": 203.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 80080, "time": 4077.024087905884, "eval_episode/length": 101.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 80448, "time": 4089.6114888191223, "episode/length": 210.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 80456, "time": 4091.2156977653503, "episode/length": 209.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 80496, "time": 4094.39492559433, "episode/length": 230.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 80824, "time": 4106.7889902591705, "episode/length": 46.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 80840, "time": 4108.903835058212, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 80888, "time": 4112.011311531067, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 81144, "time": 4122.262432098389, "episode/length": 188.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 81264, "time": 4128.226369380951, "episode/length": 52.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 81328, "time": 4131.960928916931, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 81736, "time": 4147.140572071075, "episode/length": 395.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 81800, "time": 4150.790270328522, "episode/length": 167.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 81936, "time": 4158.758604764938, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 82024, "time": 4163.468626737595, "episode/length": 35.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 82136, "time": 4168.758779525757, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 82576, "time": 4185.36669254303, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 82632, "time": 4188.717201471329, "episode/length": 225.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 82896, "time": 4199.357989311218, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 83024, "time": 4205.258210659027, "episode/length": 211.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 83216, "time": 4213.218768596649, "episode/length": 176.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 83264, "time": 4216.500915288925, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 83616, "time": 4230.045051813126, "episode/length": 129.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 83624, "time": 4231.8711524009705, "episode/length": 199.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 84248, "time": 4254.490394353867, "episode/length": 201.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 84440, "time": 4262.450777292252, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 84472, "time": 4265.050146818161, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 84672, "time": 4273.611293792725, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 84760, "time": 4278.002029657364, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 85152, "time": 4293.002993583679, "episode/length": 190.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 85296, "time": 4299.371391773224, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 85336, "time": 4302.158309936523, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 85560, "time": 4311.252235651016, "episode/length": 427.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 85808, "time": 4321.417594909668, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 85880, "time": 4325.193067073822, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 86160, "time": 4336.413270950317, "episode/length": 107.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 86344, "time": 4344.111969947815, "episode/length": 208.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 86384, "time": 4347.272972822189, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 86512, "time": 4353.107954502106, "episode/length": 218.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 86736, "time": 4362.292850971222, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 86888, "time": 4368.9007251262665, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 86936, "time": 4372.156140565872, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 86969, "time": 4375.767034292221, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.9213197622726215, "train/action_min": 0.0, "train/action_std": 4.0584137172841315, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045849954681609996, "train/actor_opt_grad_steps": 4665.0, "train/actor_opt_loss": 11.687415857813251, "train/adv_mag": 1.1546612199562698, "train/adv_max": 1.1514492960118536, "train/adv_mean": 0.006890661421439561, "train/adv_min": -0.5378143729558632, "train/adv_std": 0.09435109140824026, "train/cont_avg": 0.9940313083022388, "train/cont_loss_mean": 0.0007319282775207189, "train/cont_loss_std": 0.02097245688316855, "train/cont_neg_acc": 0.9718991651463864, "train/cont_neg_loss": 0.09634297172356332, "train/cont_pos_acc": 0.9999560082136695, "train/cont_pos_loss": 0.0001323356537900271, "train/cont_pred": 0.9941526139850048, "train/cont_rate": 0.9940313083022388, "train/dyn_loss_mean": 9.087836468397681, "train/dyn_loss_std": 7.206556829053964, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0930771062623208, "train/extr_critic_critic_opt_grad_steps": 4665.0, "train/extr_critic_critic_opt_loss": 14154.451725746268, "train/extr_critic_mag": 2.351343523210554, "train/extr_critic_max": 2.351343523210554, "train/extr_critic_mean": 0.5960054317517067, "train/extr_critic_min": -0.1855000862434729, "train/extr_critic_std": 0.6947225330036078, "train/extr_return_normed_mag": 2.1091466955284575, "train/extr_return_normed_max": 2.1091466955284575, "train/extr_return_normed_mean": 0.36147715940849107, "train/extr_return_normed_min": -0.21443001069684528, "train/extr_return_normed_std": 0.36724602086330527, "train/extr_return_rate": 0.35373670529963364, "train/extr_return_raw_mag": 4.105220417478192, "train/extr_return_raw_max": 4.105220417478192, "train/extr_return_raw_mean": 0.6097332764027724, "train/extr_return_raw_min": -0.5429642183789566, "train/extr_return_raw_std": 0.7354558252576572, "train/extr_reward_mag": 1.0060010223246332, "train/extr_reward_max": 1.0060010223246332, "train/extr_reward_mean": 0.012827171794653161, "train/extr_reward_min": -0.374338490749473, "train/extr_reward_std": 0.09976850213733182, "train/image_loss_mean": 16.381379839199692, "train/image_loss_std": 18.390209077009516, "train/model_loss_mean": 21.886650412829955, "train/model_loss_std": 21.246057987213135, "train/model_opt_grad_norm": 108.51079009895894, "train/model_opt_grad_steps": 4655.0, "train/model_opt_loss": 4227.324287072936, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 192.39738805970148, "train/policy_entropy_mag": 2.5292934303853047, "train/policy_entropy_max": 2.5292934303853047, "train/policy_entropy_mean": 0.927768353650819, "train/policy_entropy_min": 0.07939255354342176, "train/policy_entropy_std": 0.6551641537182367, "train/policy_logprob_mag": 7.4381782759481405, "train/policy_logprob_max": -0.009458672283078307, "train/policy_logprob_mean": -0.9284953101357417, "train/policy_logprob_min": -7.4381782759481405, "train/policy_logprob_std": 1.2602301400099227, "train/policy_randomness_mag": 0.8927295866297252, "train/policy_randomness_max": 0.8927295866297252, "train/policy_randomness_mean": 0.32746151489997977, "train/policy_randomness_min": 0.02802208738762941, "train/policy_randomness_std": 0.2312441974211095, "train/post_ent_mag": 44.22081417823905, "train/post_ent_max": 44.22081417823905, "train/post_ent_mean": 31.80807697239207, "train/post_ent_min": 15.351374113737647, "train/post_ent_std": 4.754306318154976, "train/prior_ent_mag": 56.46681150749548, "train/prior_ent_max": 56.46681150749548, "train/prior_ent_mean": 41.056374108613426, "train/prior_ent_min": 17.734044523381474, "train/prior_ent_std": 6.922096594056087, "train/rep_loss_mean": 9.087836468397681, "train/rep_loss_std": 7.206556829053964, "train/reward_avg": 0.01243295242189805, "train/reward_loss_mean": 0.051836813813937246, "train/reward_loss_std": 0.27225700109752254, "train/reward_max_data": 1.019402989700659, "train/reward_max_pred": 1.000599652083952, "train/reward_neg_acc": 0.9943590920362899, "train/reward_neg_loss": 0.033371854038325266, "train/reward_pos_acc": 0.9290344172449254, "train/reward_pos_loss": 1.072969428194103, "train/reward_pred": 0.011730153113603592, "train/reward_rate": 0.01781133395522388, "train_stats/sum_log_reward": 3.182644547509753, "train_stats/max_log_achievement_collect_drink": 6.785123966942149, "train_stats/max_log_achievement_collect_sapling": 3.628099173553719, "train_stats/max_log_achievement_collect_wood": 0.8677685950413223, "train_stats/max_log_achievement_defeat_skeleton": 0.008264462809917356, "train_stats/max_log_achievement_defeat_zombie": 0.1652892561983471, "train_stats/max_log_achievement_eat_cow": 0.03305785123966942, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 3.371900826446281, "train_stats/max_log_achievement_place_table": 0.10743801652892562, "train_stats/max_log_achievement_wake_up": 1.8264462809917354, "train_stats/mean_log_entropy": 0.8646038130295178, "eval_stats/sum_log_reward": 3.1624999344348907, "eval_stats/max_log_achievement_collect_drink": 1.25, "eval_stats/max_log_achievement_collect_sapling": 3.75, "eval_stats/max_log_achievement_collect_wood": 0.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 3.4375, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.4308623071410693e-06, "report/cont_loss_std": 3.907532664015889e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000386845029424876, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.3042780412652064e-06, "report/cont_pred": 0.9970691204071045, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 9.561569213867188, "report/dyn_loss_std": 7.109127521514893, "report/image_loss_mean": 14.470455169677734, "report/image_loss_std": 13.95061206817627, "report/model_loss_mean": 20.246732711791992, "report/model_loss_std": 16.950653076171875, "report/post_ent_mag": 44.67411804199219, "report/post_ent_max": 44.67411804199219, "report/post_ent_mean": 32.40437316894531, "report/post_ent_min": 13.85633659362793, "report/post_ent_std": 5.31749963760376, "report/prior_ent_mag": 57.84292984008789, "report/prior_ent_max": 57.84292984008789, "report/prior_ent_mean": 42.36723327636719, "report/prior_ent_min": 17.698762893676758, "report/prior_ent_std": 7.452568531036377, "report/rep_loss_mean": 9.561569213867188, "report/rep_loss_std": 7.109127521514893, "report/reward_avg": 0.00957031175494194, "report/reward_loss_mean": 0.03933271765708923, "report/reward_loss_std": 0.2133864313364029, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9992296695709229, "report/reward_neg_acc": 0.997026801109314, "report/reward_neg_loss": 0.024111295118927956, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.0632272958755493, "report/reward_pred": 0.008790959604084492, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.00025262299459427595, "eval/cont_loss_std": 0.007392320781946182, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0032558876555413008, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00023492203035857528, "eval/cont_pred": 0.9939512014389038, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 14.363901138305664, "eval/dyn_loss_std": 7.253434658050537, "eval/image_loss_mean": 30.216833114624023, "eval/image_loss_std": 26.504798889160156, "eval/model_loss_mean": 38.97101974487305, "eval/model_loss_std": 28.87390899658203, "eval/post_ent_mag": 42.34156036376953, "eval/post_ent_max": 42.34156036376953, "eval/post_ent_mean": 31.62835693359375, "eval/post_ent_min": 19.437389373779297, "eval/post_ent_std": 4.36140775680542, "eval/prior_ent_mag": 55.1783447265625, "eval/prior_ent_max": 55.1783447265625, "eval/prior_ent_mean": 43.8829345703125, "eval/prior_ent_min": 21.312511444091797, "eval/prior_ent_std": 7.16428279876709, "eval/rep_loss_mean": 14.363901138305664, "eval/rep_loss_std": 7.253434658050537, "eval/reward_avg": 0.01357421837747097, "eval/reward_loss_mean": 0.13559550046920776, "eval/reward_loss_std": 0.8245755434036255, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0025224685668945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.054577771574258804, "eval/reward_pos_acc": 0.45000001788139343, "eval/reward_pos_loss": 4.202685356140137, "eval/reward_pred": 0.0023523210547864437, "eval/reward_rate": 0.01953125, "replay/size": 86465.0, "replay/inserts": 21448.0, "replay/samples": 21456.0, "replay/insert_wait_avg": 1.4539331431177204e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.662563931310826e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18112.0, "eval_replay/inserts": 3664.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3215833355766196e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0812065601349, "timer/env.step_count": 2681.0, "timer/env.step_total": 270.18337750434875, "timer/env.step_frac": 0.27016143862323705, "timer/env.step_avg": 0.1007770897069559, "timer/env.step_min": 0.023994922637939453, "timer/env.step_max": 3.419015645980835, "timer/replay._sample_count": 21456.0, "timer/replay._sample_total": 11.743050575256348, "timer/replay._sample_frac": 0.011742097039946964, "timer/replay._sample_avg": 0.0005473084720011347, "timer/replay._sample_min": 0.00039887428283691406, "timer/replay._sample_max": 0.025551795959472656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3139.0, "timer/agent.policy_total": 55.7414448261261, "timer/agent.policy_frac": 0.055736918622692234, "timer/agent.policy_avg": 0.017757707813356515, "timer/agent.policy_min": 0.00966644287109375, "timer/agent.policy_max": 0.5291790962219238, "timer/dataset_train_count": 1341.0, "timer/dataset_train_total": 0.15227079391479492, "timer/dataset_train_frac": 0.00015225842953148113, "timer/dataset_train_avg": 0.00011355018189022739, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0008454322814941406, "timer/agent.train_count": 1341.0, "timer/agent.train_total": 605.0856919288635, "timer/agent.train_frac": 0.605036558991152, "timer/agent.train_avg": 0.4512197553533658, "timer/agent.train_min": 0.4383997917175293, "timer/agent.train_max": 1.6720125675201416, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4758906364440918, "timer/agent.report_frac": 0.00047585199414051433, "timer/agent.report_avg": 0.2379453182220459, "timer/agent.report_min": 0.23067688941955566, "timer/agent.report_max": 0.24521374702453613, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3137491513419884e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 21.446008293934174}
{"step": 87272, "time": 4385.8769562244415, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9617486338797814, "episode/intrinsic_return": 0.0}
{"step": 87312, "time": 4389.024477481842, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 87920, "time": 4411.239503860474, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 87992, "time": 4414.927773952484, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 88112, "time": 4420.832951545715, "episode/length": 220.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 88264, "time": 4427.289999961853, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 88344, "time": 4431.792756795883, "episode/length": 175.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 88392, "time": 4435.022542715073, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 88504, "time": 4440.378138303757, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 88528, "time": 4443.013689994812, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 89480, "time": 4476.513710737228, "episode/length": 194.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 89488, "time": 4478.577263832092, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 89648, "time": 4485.622035980225, "episode/length": 139.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 89656, "time": 4487.400721549988, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 89664, "time": 4489.490798950195, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 89808, "time": 4495.951545715332, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4525.324867010117, "eval_episode/length": 133.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9925373134328358}
{"step": 90064, "time": 4527.809787750244, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 90064, "time": 4529.407400608063, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 90064, "time": 4531.207234859467, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 90064, "time": 4533.140681505203, "eval_episode/length": 171.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 90064, "time": 4535.719726085663, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9637305699481865}
{"step": 90064, "time": 4542.190447807312, "eval_episode/length": 303.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9901315789473685}
{"step": 90064, "time": 4544.376546859741, "eval_episode/length": 159.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.99375}
{"step": 90408, "time": 4557.136146306992, "episode/length": 251.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 90600, "time": 4565.128434896469, "episode/length": 116.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 90888, "time": 4576.264337778091, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 90984, "time": 4581.147951602936, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 91072, "time": 4585.884734153748, "episode/length": 340.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9912023460410557, "episode/intrinsic_return": 0.0}
{"step": 91072, "time": 4585.893386363983, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 91144, "time": 4591.446254730225, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 91320, "time": 4599.032915353775, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 91760, "time": 4615.751184225082, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 91808, "time": 4618.955494403839, "episode/length": 60.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 92232, "time": 4634.625260591507, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 92424, "time": 4642.673425197601, "episode/length": 251.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 92472, "time": 4645.905903100967, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 92496, "time": 4648.572808980942, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 92592, "time": 4653.426037073135, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 92816, "time": 4662.50993514061, "episode/length": 48.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 92920, "time": 4667.466962099075, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 93088, "time": 4674.814550161362, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 93152, "time": 4678.682220220566, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 93824, "time": 4702.811324357986, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 93912, "time": 4707.171542882919, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 94112, "time": 4715.649136543274, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 94384, "time": 4726.378975868225, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 94408, "time": 4728.687623977661, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 94432, "time": 4731.281214237213, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 94432, "time": 4731.291414260864, "episode/length": 244.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 94512, "time": 4737.310512065887, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 95152, "time": 4760.41885972023, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 95176, "time": 4762.582962989807, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 95616, "time": 4779.193647623062, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 95664, "time": 4782.251509189606, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 95824, "time": 4789.308673858643, "episode/length": 213.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 95968, "time": 4795.867789268494, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 96064, "time": 4800.579461812973, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 96312, "time": 4810.300857543945, "episode/length": 234.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 96496, "time": 4818.276109218597, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 96672, "time": 4825.688372135162, "episode/length": 186.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 96888, "time": 4834.300003767014, "episode/length": 132.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 96904, "time": 4836.442040681839, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 96976, "time": 4840.655176401138, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 97376, "time": 4855.793935775757, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 97464, "time": 4860.079388618469, "episode/length": 174.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 97504, "time": 4863.168682575226, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 97984, "time": 4881.042972803116, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 98000, "time": 4883.08039188385, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 98320, "time": 4896.882989883423, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 98344, "time": 4899.065688610077, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 98640, "time": 4910.913156986237, "episode/length": 218.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 99008, "time": 4924.888547420502, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 99064, "time": 4928.073648929596, "episode/length": 199.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 99224, "time": 4935.023802280426, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 99552, "time": 4947.85480427742, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 99792, "time": 4957.504256725311, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 99800, "time": 4959.207373857498, "episode/length": 226.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4989.188565015793, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 100048, "time": 4991.216900110245, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 100048, "time": 4992.923050642014, "eval_episode/length": 168.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 100048, "time": 4994.715272903442, "eval_episode/length": 173.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 100048, "time": 4996.411006450653, "eval_episode/length": 176.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9661016949152542}
{"step": 100048, "time": 4998.575924158096, "eval_episode/length": 183.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 100048, "time": 5000.861172437668, "eval_episode/length": 197.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 100048, "time": 5003.325808048248, "eval_episode/length": 42.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 100136, "time": 5006.07057094574, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 100472, "time": 5018.991733074188, "episode/length": 182.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 100488, "time": 5021.126472949982, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 100552, "time": 5024.836186170578, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 100584, "time": 5027.555128335953, "episode/length": 279.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 100936, "time": 5040.944709539413, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 100936, "time": 5040.954479217529, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 101032, "time": 5047.304240465164, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 101320, "time": 5058.700654506683, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 101688, "time": 5072.553681850433, "episode/length": 149.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 101912, "time": 5081.601115942001, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 102096, "time": 5089.611850261688, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 102192, "time": 5094.487012624741, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 102464, "time": 5105.278836011887, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 102560, "time": 5110.001703977585, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 102928, "time": 5124.011425018311, "episode/length": 236.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 102992, "time": 5127.755900621414, "episode/length": 208.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 103032, "time": 5130.493915319443, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 103232, "time": 5139.001485347748, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 103264, "time": 5141.596311330795, "episode/length": 87.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 103288, "time": 5143.742795705795, "episode/length": 136.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 103440, "time": 5150.710264205933, "episode/length": 55.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 103744, "time": 5162.570858240128, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 103832, "time": 5166.999943256378, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 104320, "time": 5185.25289106369, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 104344, "time": 5187.512562513351, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 104512, "time": 5194.913596630096, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 104616, "time": 5199.799039840698, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 104776, "time": 5206.743717670441, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 105136, "time": 5220.951560974121, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 105368, "time": 5230.0752074718475, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 105432, "time": 5233.86079120636, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 105632, "time": 5242.538806676865, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 105760, "time": 5248.507751703262, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 105768, "time": 5250.181884288788, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 106256, "time": 5268.508951663971, "episode/length": 204.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 106288, "time": 5271.089251756668, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 106632, "time": 5285.208389997482, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 106920, "time": 5296.556860923767, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 106928, "time": 5299.236945152283, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 107000, "time": 5303.596002817154, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 107008, "time": 5306.262823820114, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 107568, "time": 5327.369418859482, "episode/length": 163.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9817073170731707, "episode/intrinsic_return": 0.0}
{"step": 107688, "time": 5332.8774173259735, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 107736, "time": 5336.027809858322, "episode/length": 246.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 108064, "time": 5348.801862955093, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 108152, "time": 5353.0984580516815, "episode/length": 142.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 108200, "time": 5356.264822006226, "episode/length": 158.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 108344, "time": 5362.77955698967, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 108400, "time": 5366.471436500549, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 108617, "time": 5376.087152481079, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.156732895795037, "train/action_min": 0.0, "train/action_std": 3.570997457293903, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04464362961623598, "train/actor_opt_grad_steps": 6015.0, "train/actor_opt_loss": 6.4145849178380825, "train/adv_mag": 1.0008738544933937, "train/adv_max": 0.998803003307651, "train/adv_mean": 0.00551595153137896, "train/adv_min": -0.5237389005282346, "train/adv_std": 0.0868165942511576, "train/cont_avg": 0.9942339728860294, "train/cont_loss_mean": 0.0005400223095217966, "train/cont_loss_std": 0.015083642557883917, "train/cont_neg_acc": 0.9889735071098104, "train/cont_neg_loss": 0.0461392105428168, "train/cont_pos_acc": 0.9999205658541006, "train/cont_pos_loss": 0.00025383572551767827, "train/cont_pred": 0.9942231051185552, "train/cont_rate": 0.9942339728860294, "train/dyn_loss_mean": 10.384405767216402, "train/dyn_loss_std": 7.750397696214564, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9748310608898892, "train/extr_critic_critic_opt_grad_steps": 6015.0, "train/extr_critic_critic_opt_loss": 14216.948026769302, "train/extr_critic_mag": 2.6145576974924873, "train/extr_critic_max": 2.6145576974924873, "train/extr_critic_mean": 0.6220046564498368, "train/extr_critic_min": -0.18525799582986271, "train/extr_critic_std": 0.7243833287673838, "train/extr_return_normed_mag": 2.011312747702879, "train/extr_return_normed_max": 2.011312747702879, "train/extr_return_normed_mean": 0.3505697763141464, "train/extr_return_normed_min": -0.21136191602358045, "train/extr_return_normed_std": 0.3573121400002171, "train/extr_return_rate": 0.35318725106908994, "train/extr_return_raw_mag": 4.142152318183114, "train/extr_return_raw_max": 4.142152318183114, "train/extr_return_raw_mean": 0.6336044395232902, "train/extr_return_raw_min": -0.5542541730272419, "train/extr_return_raw_std": 0.7552584236597314, "train/extr_reward_mag": 1.0079344572389828, "train/extr_reward_max": 1.0079344572389828, "train/extr_reward_mean": 0.01328945134232259, "train/extr_reward_min": -0.38676395311075096, "train/extr_reward_std": 0.10438951784197022, "train/image_loss_mean": 14.724454266183516, "train/image_loss_std": 17.88423720528098, "train/model_loss_mean": 21.005536128492917, "train/model_loss_std": 21.079241654452154, "train/model_opt_grad_norm": 85.01462538102093, "train/model_opt_grad_steps": 6005.0, "train/model_opt_loss": 9836.918819651884, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 468.75, "train/policy_entropy_mag": 2.520955725627787, "train/policy_entropy_max": 2.520955725627787, "train/policy_entropy_mean": 0.9163809458122534, "train/policy_entropy_min": 0.07938449654509039, "train/policy_entropy_std": 0.6675609120113009, "train/policy_logprob_mag": 7.438264604877023, "train/policy_logprob_max": -0.009457534815951744, "train/policy_logprob_mean": -0.9164282122955603, "train/policy_logprob_min": -7.438264604877023, "train/policy_logprob_std": 1.2753186392433502, "train/policy_randomness_mag": 0.8897867413128123, "train/policy_randomness_max": 0.8897867413128123, "train/policy_randomness_mean": 0.32344226089908795, "train/policy_randomness_min": 0.02801924363216933, "train/policy_randomness_std": 0.23561970780000968, "train/post_ent_mag": 45.38850285025204, "train/post_ent_max": 45.38850285025204, "train/post_ent_mean": 32.94225574942196, "train/post_ent_min": 16.793882369995117, "train/post_ent_std": 4.9032472582424385, "train/prior_ent_mag": 57.710987736197076, "train/prior_ent_max": 57.710987736197076, "train/prior_ent_mean": 43.47211630204145, "train/prior_ent_min": 19.57216367300819, "train/prior_ent_std": 7.149233849609599, "train/rep_loss_mean": 10.384405767216402, "train/rep_loss_std": 7.750397696214564, "train/reward_avg": 0.014287970892516622, "train/reward_loss_mean": 0.0498985252890955, "train/reward_loss_std": 0.25612425102907066, "train/reward_max_data": 1.013235297273187, "train/reward_max_pred": 1.0034465982633478, "train/reward_neg_acc": 0.9944565370678902, "train/reward_neg_loss": 0.03167086063802023, "train/reward_pos_acc": 0.9451917611500796, "train/reward_pos_loss": 0.969071671804961, "train/reward_pred": 0.01376420004389194, "train/reward_rate": 0.01945226332720588, "train_stats/sum_log_reward": 3.8999999344348906, "train_stats/max_log_achievement_collect_drink": 6.341666666666667, "train_stats/max_log_achievement_collect_sapling": 3.0416666666666665, "train_stats/max_log_achievement_collect_wood": 1.3083333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15833333333333333, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.016666666666666666, "train_stats/max_log_achievement_place_plant": 2.558333333333333, "train_stats/max_log_achievement_place_table": 0.38333333333333336, "train_stats/max_log_achievement_wake_up": 1.7333333333333334, "train_stats/mean_log_entropy": 0.8712395913898945, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017699115044247787, "eval_stats/sum_log_reward": 3.4124998971819878, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_wood": 1.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.0006506112986244261, "report/cont_loss_std": 0.018568163737654686, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.06734941154718399, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.919329123571515e-05, "report/cont_pred": 0.9916032552719116, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 12.627457618713379, "report/dyn_loss_std": 8.724749565124512, "report/image_loss_mean": 17.883787155151367, "report/image_loss_std": 28.15911865234375, "report/model_loss_mean": 25.532243728637695, "report/model_loss_std": 31.565126419067383, "report/post_ent_mag": 45.44593048095703, "report/post_ent_max": 45.44593048095703, "report/post_ent_mean": 33.1339111328125, "report/post_ent_min": 18.38306999206543, "report/post_ent_std": 4.5113630294799805, "report/prior_ent_mag": 58.776832580566406, "report/prior_ent_max": 58.776832580566406, "report/prior_ent_mean": 45.79027557373047, "report/prior_ent_min": 20.741313934326172, "report/prior_ent_std": 7.089310646057129, "report/rep_loss_mean": 12.627457618713379, "report/rep_loss_std": 8.724749565124512, "report/reward_avg": 0.0283203125, "report/reward_loss_mean": 0.07132954895496368, "report/reward_loss_std": 0.36260437965393066, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0002272129058838, "report/reward_neg_acc": 0.9949392676353455, "report/reward_neg_loss": 0.04490318149328232, "report/reward_pos_acc": 0.9722222089767456, "report/reward_pos_loss": 0.7965867519378662, "report/reward_pred": 0.0294610895216465, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 8.211826207116246e-05, "eval/cont_loss_std": 0.001869530649855733, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.028713786974549294, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.6087596779689193e-05, "eval/cont_pred": 0.998075544834137, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 15.237367630004883, "eval/dyn_loss_std": 8.004568099975586, "eval/image_loss_mean": 23.55960464477539, "eval/image_loss_std": 24.4202823638916, "eval/model_loss_mean": 32.782264709472656, "eval/model_loss_std": 27.240432739257812, "eval/post_ent_mag": 44.487632751464844, "eval/post_ent_max": 44.487632751464844, "eval/post_ent_mean": 32.77078628540039, "eval/post_ent_min": 21.044185638427734, "eval/post_ent_std": 4.006387710571289, "eval/prior_ent_mag": 57.064674377441406, "eval/prior_ent_max": 57.064674377441406, "eval/prior_ent_mean": 45.307395935058594, "eval/prior_ent_min": 24.541339874267578, "eval/prior_ent_std": 7.077202320098877, "eval/rep_loss_mean": 15.237367630004883, "eval/rep_loss_std": 8.004568099975586, "eval/reward_avg": 0.01298828050494194, "eval/reward_loss_mean": 0.08015883713960648, "eval/reward_loss_std": 0.537509024143219, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0036306381225586, "eval/reward_neg_acc": 0.9950446486473083, "eval/reward_neg_loss": 0.03838528320193291, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.890127182006836, "eval/reward_pred": 0.005971482954919338, "eval/reward_rate": 0.0146484375, "replay/size": 108113.0, "replay/inserts": 21648.0, "replay/samples": 21648.0, "replay/insert_wait_avg": 1.4600384614243828e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.699062217718041e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22384.0, "eval_replay/inserts": 4272.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.328714777914326e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3086452484131, "timer/env.step_count": 2706.0, "timer/env.step_total": 265.06607818603516, "timer/env.step_frac": 0.26498429204339186, "timer/env.step_avg": 0.09795494389727832, "timer/env.step_min": 0.023597240447998047, "timer/env.step_max": 3.3946595191955566, "timer/replay._sample_count": 21648.0, "timer/replay._sample_total": 11.959334135055542, "timer/replay._sample_frac": 0.011955644082317817, "timer/replay._sample_avg": 0.0005524452205772146, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.012027263641357422, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3240.0, "timer/agent.policy_total": 55.76487994194031, "timer/agent.policy_frac": 0.05574767368734662, "timer/agent.policy_avg": 0.017211382698129725, "timer/agent.policy_min": 0.00979924201965332, "timer/agent.policy_max": 0.10715293884277344, "timer/dataset_train_count": 1353.0, "timer/dataset_train_total": 0.15345263481140137, "timer/dataset_train_frac": 0.00015340528699848784, "timer/dataset_train_avg": 0.00011341658153096923, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0006284713745117188, "timer/agent.train_count": 1353.0, "timer/agent.train_total": 610.518319606781, "timer/agent.train_frac": 0.6103299441695489, "timer/agent.train_avg": 0.4512330521853518, "timer/agent.train_min": 0.43680405616760254, "timer/agent.train_max": 1.5214645862579346, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47026920318603516, "timer/agent.report_frac": 0.0004701241016159069, "timer/agent.report_avg": 0.23513460159301758, "timer/agent.report_min": 0.22319340705871582, "timer/agent.report_max": 0.24707579612731934, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.122319697091935e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.64104504438522}
{"step": 108888, "time": 5384.977762937546, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 109104, "time": 5394.1600251197815, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 109272, "time": 5401.109219551086, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 109304, "time": 5403.80406665802, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 109352, "time": 5406.97775554657, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 109608, "time": 5417.289050579071, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 109824, "time": 5426.448085784912, "episode/length": 208.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5453.765619516373, "eval_episode/length": 124.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.952}
{"step": 110032, "time": 5455.443340301514, "eval_episode/length": 127.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9609375}
{"step": 110032, "time": 5458.8540008068085, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 110032, "time": 5460.997986316681, "eval_episode/length": 180.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 110032, "time": 5462.620553255081, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 110032, "time": 5464.580220937729, "eval_episode/length": 190.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 110032, "time": 5466.700741529465, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 110032, "time": 5470.849457979202, "eval_episode/length": 226.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 110144, "time": 5474.590354442596, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 110304, "time": 5481.558509111404, "episode/length": 237.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 110424, "time": 5486.973190307617, "episode/length": 101.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 110504, "time": 5491.152854204178, "episode/length": 84.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 110576, "time": 5495.2734253406525, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 110624, "time": 5498.372915029526, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 110696, "time": 5502.119347572327, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 111448, "time": 5528.950576543808, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 111648, "time": 5537.673428058624, "episode/length": 127.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 111736, "time": 5542.464814662933, "episode/length": 307.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 111752, "time": 5544.575985431671, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 111768, "time": 5546.683260202408, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 111808, "time": 5549.896144151688, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 111888, "time": 5554.168586969376, "episode/length": 182.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 111920, "time": 5556.841639995575, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 112296, "time": 5571.148979663849, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 112560, "time": 5581.708722114563, "episode/length": 98.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 113128, "time": 5602.350918531418, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 113144, "time": 5604.547981500626, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 113160, "time": 5606.615702629089, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 113160, "time": 5606.625011205673, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 113312, "time": 5615.177031755447, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 113880, "time": 5635.675235033035, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 113936, "time": 5639.406281232834, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 113984, "time": 5643.066200494766, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 114384, "time": 5658.151490449905, "episode/length": 152.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 114424, "time": 5660.8341500759125, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 114536, "time": 5666.214420795441, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 114712, "time": 5674.988041162491, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 115040, "time": 5687.945927858353, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 115064, "time": 5690.1915192604065, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 115264, "time": 5698.741541385651, "episode/length": 264.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 115312, "time": 5701.809632778168, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 115800, "time": 5719.667336463928, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 115840, "time": 5722.751982927322, "episode/length": 99.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 115864, "time": 5724.862804174423, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 116176, "time": 5737.140516281128, "episode/length": 218.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 116176, "time": 5737.157337188721, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 116320, "time": 5745.262820959091, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 116680, "time": 5758.882479429245, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 116736, "time": 5762.576827049255, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 116840, "time": 5767.351282119751, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 117256, "time": 5783.0701014995575, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 117296, "time": 5786.257807016373, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 117392, "time": 5791.057822465897, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 117880, "time": 5809.006768703461, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 117984, "time": 5814.292752504349, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 118000, "time": 5816.381045818329, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 118048, "time": 5819.494953393936, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 118632, "time": 5840.631537437439, "episode/length": 223.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 118648, "time": 5842.689485788345, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 118960, "time": 5854.937269687653, "episode/length": 207.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 119104, "time": 5861.2692675590515, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 119208, "time": 5866.133985042572, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 119232, "time": 5868.889453411102, "episode/length": 74.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 119288, "time": 5871.986096382141, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 119376, "time": 5876.815832853317, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 119520, "time": 5883.456889867783, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5920.80385518074, "eval_episode/length": 135.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 120016, "time": 5922.949745178223, "eval_episode/length": 137.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 120016, "time": 5925.366510152817, "eval_episode/length": 145.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 120016, "time": 5928.76655626297, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 120016, "time": 5930.5025289058685, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 120016, "time": 5932.353802204132, "eval_episode/length": 178.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 120016, "time": 5934.0635232925415, "eval_episode/length": 180.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 120016, "time": 5936.691804409027, "eval_episode/length": 203.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 120144, "time": 5940.989305019379, "episode/length": 186.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 120368, "time": 5949.901045084, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 120736, "time": 5963.905512809753, "episode/length": 187.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 120776, "time": 5966.662406206131, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 120904, "time": 5972.478115081787, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 121024, "time": 5978.27933049202, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 121040, "time": 5980.347277402878, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 121184, "time": 5986.6810138225555, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 121472, "time": 5997.9564254283905, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 121944, "time": 6015.250604629517, "episode/length": 145.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 122096, "time": 6022.408812999725, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 122272, "time": 6029.835567474365, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 122336, "time": 6033.58202290535, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 122368, "time": 6036.431844711304, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 122616, "time": 6046.323748826981, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 122736, "time": 6052.248642444611, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 123136, "time": 6068.435247659683, "episode/length": 207.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 123280, "time": 6074.738941192627, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 123656, "time": 6088.7167847156525, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 123728, "time": 6092.897152662277, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 123768, "time": 6095.571333169937, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 123976, "time": 6104.055085897446, "episode/length": 86.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 124000, "time": 6106.727062225342, "episode/length": 237.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 124008, "time": 6108.545617580414, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 124216, "time": 6117.090104341507, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 124280, "time": 6120.745975255966, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 124880, "time": 6142.688189029694, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 124888, "time": 6144.316195726395, "episode/length": 139.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 124904, "time": 6146.421707868576, "episode/length": 111.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9464285714285714, "episode/intrinsic_return": 0.0}
{"step": 124944, "time": 6149.553275585175, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 125288, "time": 6162.431508541107, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 125320, "time": 6165.083076953888, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 125696, "time": 6179.61231136322, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 125712, "time": 6181.9608726501465, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 126016, "time": 6194.397927761078, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 126152, "time": 6200.358824968338, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 126320, "time": 6207.757138490677, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 126440, "time": 6213.1020703315735, "episode/length": 193.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 126520, "time": 6217.386669635773, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 126896, "time": 6231.784711837769, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 126960, "time": 6235.47002863884, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 127016, "time": 6238.736223697662, "episode/length": 107.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 127200, "time": 6246.6226217746735, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 127400, "time": 6254.681658267975, "episode/length": 54.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 127760, "time": 6268.507404327393, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 127920, "time": 6275.503373861313, "episode/length": 89.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 127968, "time": 6278.6668157577515, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 128168, "time": 6286.734511137009, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 128424, "time": 6297.024416685104, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 128568, "time": 6303.327698707581, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 128672, "time": 6308.607846021652, "episode/length": 293.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 128792, "time": 6313.984491109848, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 129216, "time": 6330.115805149078, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 129480, "time": 6340.278731584549, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 129544, "time": 6344.013787031174, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 129600, "time": 6347.797355413437, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 129880, "time": 6358.419716119766, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 129984, "time": 6363.690695762634, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6385.980343341827, "eval_episode/length": 157.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 130000, "time": 6387.9318997859955, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 130000, "time": 6389.998958110809, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 130000, "time": 6391.783499717712, "eval_episode/length": 180.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 130000, "time": 6393.644985437393, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 130000, "time": 6395.217912912369, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 130000, "time": 6397.774563550949, "eval_episode/length": 209.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 130000, "time": 6399.863658666611, "eval_episode/length": 220.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 130001, "time": 6401.091450691223, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.708944908658364, "train/action_min": 0.0, "train/action_std": 3.4944694203541693, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04623797430859921, "train/actor_opt_grad_steps": 7360.0, "train/actor_opt_loss": 7.597402539244272, "train/adv_mag": 0.895640986754482, "train/adv_max": 0.8923572221196684, "train/adv_mean": 0.00628084606487528, "train/adv_min": -0.48220487824059965, "train/adv_std": 0.08550179982207771, "train/cont_avg": 0.9941920230263158, "train/cont_loss_mean": 0.00040848362365906716, "train/cont_loss_std": 0.011273491046307057, "train/cont_neg_acc": 0.988495049171878, "train/cont_neg_loss": 0.030722457685487654, "train/cont_pos_acc": 0.9999408520253977, "train/cont_pos_loss": 0.00023286672392160553, "train/cont_pred": 0.9941685387962743, "train/cont_rate": 0.9941920230263158, "train/dyn_loss_mean": 11.446557346143221, "train/dyn_loss_std": 8.157841571291586, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0205583895059456, "train/extr_critic_critic_opt_grad_steps": 7360.0, "train/extr_critic_critic_opt_loss": 14978.925906073779, "train/extr_critic_mag": 2.9506903985389195, "train/extr_critic_max": 2.9506903985389195, "train/extr_critic_mean": 0.7089173016243411, "train/extr_critic_min": -0.22112529618399485, "train/extr_critic_std": 0.8178149076332724, "train/extr_return_normed_mag": 1.8696734089600413, "train/extr_return_normed_max": 1.8696734089600413, "train/extr_return_normed_mean": 0.3531675433978102, "train/extr_return_normed_min": -0.2022454410903436, "train/extr_return_normed_std": 0.3575792964687921, "train/extr_return_rate": 0.41458727072056073, "train/extr_return_raw_mag": 4.346957796498349, "train/extr_return_raw_max": 4.346957796498349, "train/extr_return_raw_mean": 0.7237786148723803, "train/extr_return_raw_min": -0.6032072738149112, "train/extr_return_raw_std": 0.8544881715810388, "train/extr_reward_mag": 1.005663764207883, "train/extr_reward_max": 1.005663764207883, "train/extr_reward_mean": 0.016039861593731587, "train/extr_reward_min": -0.4045163079311973, "train/extr_reward_std": 0.11449917540290303, "train/image_loss_mean": 13.153377769584942, "train/image_loss_std": 16.92667039713465, "train/model_loss_mean": 20.072232784185193, "train/model_loss_std": 20.328207668505218, "train/model_opt_grad_norm": 88.82641274588448, "train/model_opt_grad_steps": 7349.285714285715, "train/model_opt_loss": 13089.33048930921, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 653.1954887218045, "train/policy_entropy_mag": 2.5374573747018228, "train/policy_entropy_max": 2.5374573747018228, "train/policy_entropy_mean": 0.7920519727513307, "train/policy_entropy_min": 0.07937794341180558, "train/policy_entropy_std": 0.6743203504641253, "train/policy_logprob_mag": 7.4383510897930405, "train/policy_logprob_max": -0.009456481588514228, "train/policy_logprob_mean": -0.7915301457383579, "train/policy_logprob_min": -7.4383510897930405, "train/policy_logprob_std": 1.229692404431508, "train/policy_randomness_mag": 0.8956111006270674, "train/policy_randomness_max": 0.8956111006270674, "train/policy_randomness_mean": 0.2795595889700983, "train/policy_randomness_min": 0.028016930544062665, "train/policy_randomness_std": 0.23800549213599442, "train/post_ent_mag": 47.35315644113641, "train/post_ent_max": 47.35315644113641, "train/post_ent_mean": 34.160332299712906, "train/post_ent_min": 18.296044722535555, "train/post_ent_std": 5.049752357310819, "train/prior_ent_mag": 58.81954502880125, "train/prior_ent_max": 58.81954502880125, "train/prior_ent_mean": 45.81153774978523, "train/prior_ent_min": 21.481828345391982, "train/prior_ent_std": 6.854171910680327, "train/rep_loss_mean": 11.446557346143221, "train/rep_loss_std": 8.157841571291586, "train/reward_avg": 0.015522203947368422, "train/reward_loss_mean": 0.05051219151040217, "train/reward_loss_std": 0.26362338326031104, "train/reward_max_data": 1.0157894774487144, "train/reward_max_pred": 1.005385538689176, "train/reward_neg_acc": 0.9943990743249879, "train/reward_neg_loss": 0.031111214954153935, "train/reward_pos_acc": 0.9465840920469815, "train/reward_pos_loss": 0.966168901525942, "train/reward_pred": 0.014816028507132279, "train/reward_rate": 0.02070606203007519, "train_stats/sum_log_reward": 4.319512112414449, "train_stats/max_log_achievement_collect_drink": 4.495934959349594, "train_stats/max_log_achievement_collect_sapling": 2.203252032520325, "train_stats/max_log_achievement_collect_wood": 2.341463414634146, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.13821138211382114, "train_stats/max_log_achievement_eat_cow": 0.056910569105691054, "train_stats/max_log_achievement_make_wood_pickaxe": 0.04065040650406504, "train_stats/max_log_achievement_make_wood_sword": 0.04878048780487805, "train_stats/max_log_achievement_place_plant": 2.016260162601626, "train_stats/max_log_achievement_place_table": 0.6585365853658537, "train_stats/max_log_achievement_wake_up": 2.040650406504065, "train_stats/mean_log_entropy": 0.7482222073931035, "train_stats/max_log_achievement_collect_stone": 0.02564102564102564, "train_stats/max_log_achievement_place_stone": 0.008547008547008548, "eval_stats/sum_log_reward": 4.6833332777023315, "eval_stats/max_log_achievement_collect_drink": 4.416666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.5416666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 1.8333333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 2.25, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 2.2916666666666665, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.004078770522028208, "report/cont_loss_std": 0.12502117455005646, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 0.499959796667099, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0001741950400173664, "report/cont_pred": 0.9929882287979126, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.868690490722656, "report/dyn_loss_std": 8.013349533081055, "report/image_loss_mean": 10.900540351867676, "report/image_loss_std": 13.343449592590332, "report/model_loss_mean": 18.067298889160156, "report/model_loss_std": 16.41866683959961, "report/post_ent_mag": 47.70122146606445, "report/post_ent_max": 47.70122146606445, "report/post_ent_mean": 33.57823944091797, "report/post_ent_min": 18.166942596435547, "report/post_ent_std": 5.689309120178223, "report/prior_ent_mag": 58.50415802001953, "report/prior_ent_max": 58.50415802001953, "report/prior_ent_mean": 45.97898864746094, "report/prior_ent_min": 20.708614349365234, "report/prior_ent_std": 6.752076625823975, "report/rep_loss_mean": 11.868690490722656, "report/rep_loss_std": 8.013349533081055, "report/reward_avg": 0.01337890699505806, "report/reward_loss_mean": 0.04146648198366165, "report/reward_loss_std": 0.22827252745628357, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0014235973358154, "report/reward_neg_acc": 0.9970149993896484, "report/reward_neg_loss": 0.024482598528265953, "report/reward_pos_acc": 0.8947368264198303, "report/reward_pos_loss": 0.939824640750885, "report/reward_pred": 0.012865247204899788, "report/reward_rate": 0.0185546875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0052234213799238205, "eval/cont_loss_std": 0.1133866086602211, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.3981504738330841, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.003295417409390211, "eval/cont_pred": 0.9947367906570435, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.95315170288086, "eval/dyn_loss_std": 7.908705234527588, "eval/image_loss_mean": 25.576644897460938, "eval/image_loss_std": 28.529876708984375, "eval/model_loss_mean": 35.87419891357422, "eval/model_loss_std": 31.113035202026367, "eval/post_ent_mag": 43.70792770385742, "eval/post_ent_max": 43.70792770385742, "eval/post_ent_mean": 33.02312469482422, "eval/post_ent_min": 17.98775863647461, "eval/post_ent_std": 4.676061153411865, "eval/prior_ent_mag": 58.50415802001953, "eval/prior_ent_max": 58.50415802001953, "eval/prior_ent_mean": 46.97215270996094, "eval/prior_ent_min": 24.601713180541992, "eval/prior_ent_std": 6.511673450469971, "eval/rep_loss_mean": 16.95315170288086, "eval/rep_loss_std": 7.908705234527588, "eval/reward_avg": 0.0146484375, "eval/reward_loss_mean": 0.12044274806976318, "eval/reward_loss_std": 0.7334442138671875, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008928775787354, "eval/reward_neg_acc": 0.9970119595527649, "eval/reward_neg_loss": 0.06225021928548813, "eval/reward_pos_acc": 0.6500000357627869, "eval/reward_pos_loss": 3.041707754135132, "eval/reward_pred": 0.007377211935818195, "eval/reward_rate": 0.01953125, "replay/size": 129497.0, "replay/inserts": 21384.0, "replay/samples": 21376.0, "replay/insert_wait_avg": 1.444503960429262e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.761124339646208e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 27600.0, "eval_replay/inserts": 5216.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3293115639247777e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1024.3449466228485, "timer/env.step_count": 2673.0, "timer/env.step_total": 266.8473916053772, "timer/env.step_frac": 0.260505401510637, "timer/env.step_avg": 0.09983067400126344, "timer/env.step_min": 0.023643016815185547, "timer/env.step_max": 3.3066940307617188, "timer/replay._sample_count": 21376.0, "timer/replay._sample_total": 11.88634467124939, "timer/replay._sample_frac": 0.011603849572780486, "timer/replay._sample_avg": 0.0005560602858930291, "timer/replay._sample_min": 0.00038313865661621094, "timer/replay._sample_max": 0.026775836944580078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3325.0, "timer/agent.policy_total": 58.560192823410034, "timer/agent.policy_frac": 0.05716843043593516, "timer/agent.policy_avg": 0.017612088067190987, "timer/agent.policy_min": 0.009912729263305664, "timer/agent.policy_max": 0.1456449031829834, "timer/dataset_train_count": 1336.0, "timer/dataset_train_total": 0.15781664848327637, "timer/dataset_train_frac": 0.0001540659218396892, "timer/dataset_train_avg": 0.00011812623389466794, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.00033783912658691406, "timer/agent.train_count": 1336.0, "timer/agent.train_total": 600.7966933250427, "timer/agent.train_frac": 0.5865179452544796, "timer/agent.train_avg": 0.4496981237462895, "timer/agent.train_min": 0.4373900890350342, "timer/agent.train_max": 1.3456716537475586, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47576093673706055, "timer/agent.report_frac": 0.0004644538329647562, "timer/agent.report_avg": 0.23788046836853027, "timer/agent.report_min": 0.2303447723388672, "timer/agent.report_max": 0.24541616439819336, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.398182678949108e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 20.8755223912829}
{"step": 130568, "time": 6420.336024522781, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 130576, "time": 6422.395318031311, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 130600, "time": 6424.725642442703, "episode/length": 225.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 131048, "time": 6441.627155780792, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 131240, "time": 6451.087338924408, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 131416, "time": 6458.486875534058, "episode/length": 45.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 131792, "time": 6473.054614067078, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 132056, "time": 6483.346512079239, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 132296, "time": 6493.024503946304, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 132496, "time": 6501.618131399155, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 132824, "time": 6514.051971673965, "episode/length": 402.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950372208436724, "episode/intrinsic_return": 0.0}
{"step": 133240, "time": 6529.58624792099, "episode/length": 502.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9960238568588469, "episode/intrinsic_return": 0.0}
{"step": 133296, "time": 6533.278906106949, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 133320, "time": 6535.479753494263, "episode/length": 429.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 133368, "time": 6538.629713773727, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 133472, "time": 6543.940734624863, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 133648, "time": 6551.4651799201965, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 133872, "time": 6560.62345457077, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 134232, "time": 6574.077827453613, "episode/length": 72.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9452054794520548, "episode/intrinsic_return": 0.0}
{"step": 134424, "time": 6582.0491943359375, "episode/length": 199.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 134464, "time": 6585.125110626221, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 134712, "time": 6594.967177867889, "episode/length": 183.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 134816, "time": 6600.27055811882, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 134848, "time": 6602.918156147003, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 135024, "time": 6610.330065488815, "episode/length": 193.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 135096, "time": 6614.045211553574, "episode/length": 34.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 135392, "time": 6625.734520673752, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 135520, "time": 6631.517647027969, "episode/length": 136.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 135616, "time": 6636.317493438721, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 135896, "time": 6646.993232250214, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 136296, "time": 6662.082021713257, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 136312, "time": 6664.2831020355225, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 136328, "time": 6666.359878063202, "episode/length": 100.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9405940594059405, "episode/intrinsic_return": 0.0}
{"step": 136584, "time": 6676.482601881027, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 136608, "time": 6679.247507572174, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 136640, "time": 6681.838158607483, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 137064, "time": 6697.248337507248, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 137288, "time": 6706.33898639679, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 137664, "time": 6720.820920944214, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 137816, "time": 6727.134869337082, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 137840, "time": 6729.6132028102875, "episode/length": 149.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 137888, "time": 6732.785702228546, "episode/length": 159.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 138176, "time": 6743.927584171295, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 138488, "time": 6755.786240339279, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 138768, "time": 6766.9128930568695, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 139144, "time": 6780.921861410141, "episode/length": 46.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 139240, "time": 6785.751289367676, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 139248, "time": 6787.812583208084, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 139272, "time": 6790.358402967453, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 139480, "time": 6800.212333917618, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 139632, "time": 6807.044624567032, "episode/length": 412.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 139784, "time": 6813.493220806122, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6841.6500062942505, "eval_episode/length": 87.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9886363636363636}
{"step": 140088, "time": 6845.979736089706, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 140088, "time": 6848.467495203018, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 140088, "time": 6850.720668077469, "eval_episode/length": 189.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 140088, "time": 6852.715826034546, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 140088, "time": 6854.830517292023, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 140088, "time": 6856.963468790054, "eval_episode/length": 222.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 140088, "time": 6860.482607603073, "eval_episode/length": 40.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975609756097561}
{"step": 140112, "time": 6861.529990434647, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 140368, "time": 6871.556304216385, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 140400, "time": 6874.208258628845, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 140648, "time": 6883.837558269501, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 140776, "time": 6889.859367609024, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 140840, "time": 6893.588707923889, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 140984, "time": 6899.957919836044, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 141104, "time": 6905.708998203278, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 141680, "time": 6926.767847061157, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 141848, "time": 6933.798588037491, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 142040, "time": 6941.819307565689, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 142088, "time": 6944.937207221985, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 142288, "time": 6953.334623098373, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 142328, "time": 6955.956347227097, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 142432, "time": 6961.159525156021, "episode/length": 180.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 142648, "time": 6969.705499410629, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 142936, "time": 6981.110863447189, "episode/length": 135.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 143104, "time": 6988.711478471756, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 143264, "time": 6995.561018705368, "episode/length": 76.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 143648, "time": 7010.063082933426, "episode/length": 169.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 143832, "time": 7017.508591413498, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 143872, "time": 7020.642054319382, "episode/length": 75.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 143880, "time": 7022.244896888733, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 144152, "time": 7032.899761676788, "episode/length": 214.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 144456, "time": 7044.736135959625, "episode/length": 301.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 144496, "time": 7047.883293628693, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 144848, "time": 7061.451318740845, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 144944, "time": 7066.228852748871, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 145272, "time": 7078.66782283783, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 145328, "time": 7082.327566385269, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 145416, "time": 7086.562417507172, "episode/length": 197.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 145592, "time": 7094.031134843826, "episode/length": 179.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 145720, "time": 7099.955429553986, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 145912, "time": 7108.004066705704, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 146192, "time": 7119.093693733215, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 146312, "time": 7124.282898187637, "episode/length": 182.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 146320, "time": 7126.391253232956, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 146584, "time": 7136.613848209381, "episode/length": 83.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 146608, "time": 7139.190109491348, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 146736, "time": 7145.032490968704, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 146840, "time": 7150.1400554180145, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 147496, "time": 7175.170593500137, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 147616, "time": 7181.094291210175, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 147776, "time": 7188.1949031353, "episode/length": 197.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 148064, "time": 7199.516639709473, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 148128, "time": 7203.294391155243, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 148152, "time": 7205.362614393234, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 148208, "time": 7209.00003027916, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 148272, "time": 7212.897675991058, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 149000, "time": 7238.4559643268585, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 149176, "time": 7245.913615703583, "episode/length": 138.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 149296, "time": 7251.8796808719635, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 149520, "time": 7260.913949012756, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 149664, "time": 7267.27659368515, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 149792, "time": 7273.104155540466, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 149872, "time": 7277.680082798004, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 150008, "time": 7283.504131317139, "episode/length": 60.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7306.988399267197, "eval_episode/length": 155.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 150072, "time": 7309.257444620132, "eval_episode/length": 166.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 150072, "time": 7311.005281448364, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 150072, "time": 7312.6722939014435, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 150072, "time": 7314.245090723038, "eval_episode/length": 172.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.976878612716763}
{"step": 150072, "time": 7314.253248929977, "eval_episode/length": 172.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 150072, "time": 7317.777644872665, "eval_episode/length": 175.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 150072, "time": 7321.182473897934, "eval_episode/length": 215.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 150296, "time": 7328.6849529743195, "episode/length": 139.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 150328, "time": 7331.356921672821, "episode/length": 274.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 150520, "time": 7339.424494743347, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 150552, "time": 7342.022894382477, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 150832, "time": 7353.235484600067, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 150976, "time": 7359.843345880508, "episode/length": 147.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 151504, "time": 7379.041597366333, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 151552, "time": 7382.261461019516, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 151864, "time": 7393.989505529404, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 151888, "time": 7396.552485466003, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 151896, "time": 7398.374609708786, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 151896, "time": 7398.384185552597, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 151897, "time": 7402.817796468735, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.501529888515055, "train/action_min": 0.0, "train/action_std": 3.218886337141051, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.042391644573233425, "train/actor_opt_grad_steps": 8710.0, "train/actor_opt_loss": -1.0468309976595596, "train/adv_mag": 0.7790895300189944, "train/adv_max": 0.7688535739035502, "train/adv_mean": 0.004608179179561302, "train/adv_min": -0.48539937934736266, "train/adv_std": 0.07647386206871401, "train/cont_avg": 0.9946110857664233, "train/cont_loss_mean": 0.0004531170247147064, "train/cont_loss_std": 0.012299257319205358, "train/cont_neg_acc": 0.9940215518874843, "train/cont_neg_loss": 0.02449225337099952, "train/cont_pos_acc": 0.9999354442540747, "train/cont_pos_loss": 0.0003081282146860418, "train/cont_pred": 0.9945361161754079, "train/cont_rate": 0.9946110857664233, "train/dyn_loss_mean": 12.437349709281087, "train/dyn_loss_std": 8.562838112350798, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.974136519606096, "train/extr_critic_critic_opt_grad_steps": 8710.0, "train/extr_critic_critic_opt_loss": 14706.217445540602, "train/extr_critic_mag": 3.2708037891527164, "train/extr_critic_max": 3.2708037891527164, "train/extr_critic_mean": 0.7407029588727185, "train/extr_critic_min": -0.25311925115376493, "train/extr_critic_std": 0.9069127044538512, "train/extr_return_normed_mag": 1.790022237457498, "train/extr_return_normed_max": 1.790022237457498, "train/extr_return_normed_mean": 0.33249139513847603, "train/extr_return_normed_min": -0.17435838926556338, "train/extr_return_normed_std": 0.35085633005538996, "train/extr_return_rate": 0.404275988249013, "train/extr_return_raw_mag": 4.671452271677282, "train/extr_return_raw_max": 4.671452271677282, "train/extr_return_raw_mean": 0.752959625129282, "train/extr_return_raw_min": -0.6082884351702502, "train/extr_return_raw_std": 0.9431200414678477, "train/extr_reward_mag": 1.0072690700962597, "train/extr_reward_max": 1.0072690700962597, "train/extr_reward_mean": 0.016913491454192974, "train/extr_reward_min": -0.38130996610126355, "train/extr_reward_std": 0.12030249703539549, "train/image_loss_mean": 11.909038272217243, "train/image_loss_std": 15.202304331925664, "train/model_loss_mean": 19.421132073785266, "train/model_loss_std": 18.848835520500685, "train/model_opt_grad_norm": 82.60966018342624, "train/model_opt_grad_steps": 8698.2700729927, "train/model_opt_loss": 14954.474723426094, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 770.985401459854, "train/policy_entropy_mag": 2.5054136958435502, "train/policy_entropy_max": 2.5054136958435502, "train/policy_entropy_mean": 0.6813336441116612, "train/policy_entropy_min": 0.0793766987367268, "train/policy_entropy_std": 0.5967147250245087, "train/policy_logprob_mag": 7.438370304386111, "train/policy_logprob_max": -0.009456171314266041, "train/policy_logprob_mean": -0.6824799332305462, "train/policy_logprob_min": -7.438370304386111, "train/policy_logprob_std": 1.173738304715957, "train/policy_randomness_mag": 0.8843010881521406, "train/policy_randomness_max": 0.8843010881521406, "train/policy_randomness_mean": 0.24048087805727103, "train/policy_randomness_min": 0.02801649133763174, "train/policy_randomness_std": 0.21061411293318671, "train/post_ent_mag": 48.81467894394032, "train/post_ent_max": 48.81467894394032, "train/post_ent_mean": 34.62302607515433, "train/post_ent_min": 19.075857148553332, "train/post_ent_std": 5.1741138827191655, "train/prior_ent_mag": 59.96520709295343, "train/prior_ent_max": 59.96520709295343, "train/prior_ent_mean": 47.20576457559628, "train/prior_ent_min": 22.995238102265517, "train/prior_ent_std": 6.870442536625549, "train/rep_loss_mean": 12.437349709281087, "train/rep_loss_std": 8.562838112350798, "train/reward_avg": 0.017476191852975935, "train/reward_loss_mean": 0.049231030821909, "train/reward_loss_std": 0.24737172492229156, "train/reward_max_data": 1.0087591261759292, "train/reward_max_pred": 1.0038826239370082, "train/reward_neg_acc": 0.9940569861961978, "train/reward_neg_loss": 0.029071345789371615, "train/reward_pos_acc": 0.951830250503373, "train/reward_pos_loss": 0.9342843655252109, "train/reward_pred": 0.016738446595922222, "train/reward_rate": 0.022325501824817517, "train_stats/sum_log_reward": 4.455371830581633, "train_stats/max_log_achievement_collect_drink": 4.694214876033058, "train_stats/max_log_achievement_collect_sapling": 2.2479338842975207, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.0991735537190084, "train_stats/max_log_achievement_defeat_skeleton": 0.024793388429752067, "train_stats/max_log_achievement_defeat_zombie": 0.14049586776859505, "train_stats/max_log_achievement_eat_cow": 0.04132231404958678, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01652892561983471, "train_stats/max_log_achievement_make_wood_sword": 0.08264462809917356, "train_stats/max_log_achievement_place_plant": 2.090909090909091, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0413223140495869, "train_stats/max_log_achievement_wake_up": 2.1074380165289255, "train_stats/mean_log_entropy": 0.6444210730308344, "train_stats/max_log_achievement_eat_plant": 0.00909090909090909, "eval_stats/sum_log_reward": 4.537499934434891, "eval_stats/max_log_achievement_collect_drink": 1.75, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.1875, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.00018798094242811203, "report/cont_loss_std": 0.004325262736529112, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.047443002462387085, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.6671698378777364e-06, "report/cont_pred": 0.9962674379348755, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.439603805541992, "report/dyn_loss_std": 8.145800590515137, "report/image_loss_mean": 9.138261795043945, "report/image_loss_std": 10.68846607208252, "report/model_loss_mean": 16.03653907775879, "report/model_loss_std": 14.11507511138916, "report/post_ent_mag": 48.398094177246094, "report/post_ent_max": 48.398094177246094, "report/post_ent_mean": 35.49113082885742, "report/post_ent_min": 21.191848754882812, "report/post_ent_std": 5.187582015991211, "report/prior_ent_mag": 60.99419403076172, "report/prior_ent_max": 60.99419403076172, "report/prior_ent_mean": 47.622901916503906, "report/prior_ent_min": 24.676515579223633, "report/prior_ent_std": 5.943582057952881, "report/rep_loss_mean": 11.439603805541992, "report/rep_loss_std": 8.145800590515137, "report/reward_avg": 0.01142578199505806, "report/reward_loss_mean": 0.034327536821365356, "report/reward_loss_std": 0.2044481337070465, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0045006275177002, "report/reward_neg_acc": 0.99702388048172, "report/reward_neg_loss": 0.023623112589120865, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7087063193321228, "report/reward_pred": 0.012135257013142109, "report/reward_rate": 0.015625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.624651774065569e-05, "eval/cont_loss_std": 0.0011269962415099144, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01346149854362011, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.8285371526144445e-06, "eval/cont_pred": 0.9971023797988892, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.642877578735352, "eval/dyn_loss_std": 8.544316291809082, "eval/image_loss_mean": 13.36627197265625, "eval/image_loss_std": 19.76350975036621, "eval/model_loss_mean": 22.208560943603516, "eval/model_loss_std": 23.168174743652344, "eval/post_ent_mag": 46.58406448364258, "eval/post_ent_max": 46.58406448364258, "eval/post_ent_mean": 34.594627380371094, "eval/post_ent_min": 20.795255661010742, "eval/post_ent_std": 4.482088088989258, "eval/prior_ent_mag": 60.99419403076172, "eval/prior_ent_max": 60.99419403076172, "eval/prior_ent_mean": 46.89118576049805, "eval/prior_ent_min": 24.72899627685547, "eval/prior_ent_std": 5.1658034324646, "eval/rep_loss_mean": 14.642877578735352, "eval/rep_loss_std": 8.544316291809082, "eval/reward_avg": 0.011425781063735485, "eval/reward_loss_mean": 0.05651567876338959, "eval/reward_loss_std": 0.6023720502853394, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026495456695557, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.01604025438427925, "eval/reward_pos_acc": 0.6428571939468384, "eval/reward_pos_loss": 2.9765286445617676, "eval/reward_pred": 0.007269327994436026, "eval/reward_rate": 0.013671875, "replay/size": 151393.0, "replay/inserts": 21896.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.4325803241722768e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.77927654062944e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31440.0, "eval_replay/inserts": 3840.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2829899787902831e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1002.3568589687347, "timer/env.step_count": 2737.0, "timer/env.step_total": 267.2724139690399, "timer/env.step_frac": 0.2666439717328024, "timer/env.step_avg": 0.09765159443516255, "timer/env.step_min": 0.023876428604125977, "timer/env.step_max": 3.4374887943267822, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 11.884569883346558, "timer/replay._sample_frac": 0.011856625489223352, "timer/replay._sample_avg": 0.000542575323381417, "timer/replay._sample_min": 0.0003895759582519531, "timer/replay._sample_max": 0.02459716796875, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3217.0, "timer/agent.policy_total": 54.38182592391968, "timer/agent.policy_frac": 0.05425395699877776, "timer/agent.policy_avg": 0.016904515363357065, "timer/agent.policy_min": 0.009428739547729492, "timer/agent.policy_max": 0.10771489143371582, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.15113377571105957, "timer/dataset_train_frac": 0.0001507784122578381, "timer/dataset_train_avg": 0.00011039720650917427, "timer/dataset_train_min": 9.512901306152344e-05, "timer/dataset_train_max": 0.0003421306610107422, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 613.0716087818146, "timer/agent.train_frac": 0.6116300829353005, "timer/agent.train_avg": 0.44782440378510924, "timer/agent.train_min": 0.4351527690887451, "timer/agent.train_max": 1.3912928104400635, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4765641689300537, "timer/agent.report_frac": 0.0004754436153810153, "timer/agent.report_avg": 0.23828208446502686, "timer/agent.report_min": 0.2311854362487793, "timer/agent.report_max": 0.24537873268127441, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7591525840642653e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 21.844191224412164}
{"step": 152376, "time": 7418.676375389099, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 152688, "time": 7431.1410875320435, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 153104, "time": 7446.580281019211, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 153136, "time": 7449.282274723053, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 153216, "time": 7453.455868244171, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 153344, "time": 7459.446375131607, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 153552, "time": 7467.945578575134, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 154080, "time": 7487.387560129166, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 154128, "time": 7490.59325838089, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 154280, "time": 7497.189522981644, "episode/length": 297.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 154592, "time": 7509.5142776966095, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 154648, "time": 7512.649155139923, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 154744, "time": 7517.69176030159, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 154864, "time": 7523.488539934158, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 154992, "time": 7529.408666610718, "episode/length": 49.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 155352, "time": 7542.758628606796, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.0}
{"step": 155520, "time": 7550.351209402084, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 155576, "time": 7553.625791549683, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 155928, "time": 7568.3608503341675, "episode/length": 132.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 155936, "time": 7570.449424505234, "episode/length": 160.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 156072, "time": 7576.345344543457, "episode/length": 248.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 156296, "time": 7585.5708384513855, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 156400, "time": 7590.886740922928, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 156952, "time": 7610.909719467163, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 157000, "time": 7614.038256645203, "episode/length": 205.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 157328, "time": 7626.639533519745, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 157400, "time": 7630.38750910759, "episode/length": 234.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 157408, "time": 7632.420288801193, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 157424, "time": 7634.605807065964, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 157528, "time": 7639.600199222565, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 157552, "time": 7642.202040672302, "episode/length": 74.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 157872, "time": 7654.491698265076, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 158576, "time": 7679.699913024902, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 158656, "time": 7683.974978923798, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 158696, "time": 7686.732473373413, "episode/length": 211.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 158736, "time": 7689.804508686066, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 158792, "time": 7692.995083093643, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 158880, "time": 7697.825206041336, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 158920, "time": 7700.473195314407, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 159544, "time": 7722.944329738617, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 159864, "time": 7735.325883150101, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 160016, "time": 7742.174250125885, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7744.788886785507, "episode/length": 164.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7766.277062416077, "eval_episode/length": 153.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 160056, "time": 7768.093754529953, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 160056, "time": 7769.904772758484, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 160056, "time": 7771.739140033722, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 160056, "time": 7773.755685806274, "eval_episode/length": 178.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 160056, "time": 7775.435514450073, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 160056, "time": 7777.354944467545, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 160056, "time": 7779.113897562027, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 160128, "time": 7783.37371468544, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 160272, "time": 7789.954812049866, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 160384, "time": 7795.3500187397, "episode/length": 45.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 160576, "time": 7803.4319269657135, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 160888, "time": 7815.301578760147, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 160944, "time": 7819.088862895966, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 161184, "time": 7828.740025997162, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 161352, "time": 7835.647928953171, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 161456, "time": 7840.867220163345, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 161680, "time": 7850.058326482773, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 161752, "time": 7853.892263889313, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 161792, "time": 7857.085898637772, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 161824, "time": 7859.716854095459, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 162144, "time": 7872.006832122803, "episode/length": 48.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 162152, "time": 7873.765053510666, "episode/length": 44.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 162368, "time": 7882.877598524094, "episode/length": 67.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 162688, "time": 7895.161486387253, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 162792, "time": 7900.004146099091, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 162856, "time": 7903.762259244919, "episode/length": 238.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 162984, "time": 7909.830942630768, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 163288, "time": 7921.467329502106, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 163488, "time": 7930.0477504730225, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 163688, "time": 7938.270972967148, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 164048, "time": 7953.448906421661, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 164064, "time": 7955.472301721573, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 164272, "time": 7963.9958646297455, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 164416, "time": 7970.578625202179, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 164472, "time": 7973.8396146297455, "episode/length": 262.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 164840, "time": 7987.592216014862, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 165032, "time": 7995.591087818146, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 165144, "time": 8000.912903308868, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 165376, "time": 8010.3523209095, "episode/length": 137.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 165456, "time": 8014.580963611603, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 165808, "time": 8028.080546617508, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 165912, "time": 8032.823968410492, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 165952, "time": 8036.063197135925, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 166248, "time": 8047.15354681015, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 166280, "time": 8049.784677028656, "episode/length": 112.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 166488, "time": 8058.529331445694, "episode/length": 181.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 166520, "time": 8061.110193014145, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 166840, "time": 8073.3399024009705, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 167392, "time": 8093.787309169769, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 167480, "time": 8098.118577480316, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 167760, "time": 8109.288237094879, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 167856, "time": 8114.122172832489, "episode/length": 170.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 167864, "time": 8115.69048500061, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 168024, "time": 8122.81613278389, "episode/length": 276.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 168336, "time": 8135.025830745697, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 168680, "time": 8148.016957044601, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 168688, "time": 8150.090501308441, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 169096, "time": 8165.107091665268, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 169136, "time": 8168.373872995377, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 169168, "time": 8170.987637042999, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 169288, "time": 8176.429339647293, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 169384, "time": 8181.477632761002, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 169768, "time": 8195.957730054855, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 169840, "time": 8200.213314771652, "episode/length": 144.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8230.568108320236, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 170040, "time": 8232.280997276306, "eval_episode/length": 156.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 170040, "time": 8234.39235496521, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 170040, "time": 8236.727016448975, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 170040, "time": 8238.74285364151, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 170040, "time": 8240.613560676575, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 170040, "time": 8243.70053768158, "eval_episode/length": 224.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 170040, "time": 8246.721248149872, "eval_episode/length": 255.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.97265625}
{"step": 170088, "time": 8248.335674285889, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 170536, "time": 8265.091760158539, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 170560, "time": 8267.753093719482, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 170808, "time": 8277.389535188675, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 171048, "time": 8287.049391031265, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 171296, "time": 8297.105295419693, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 171352, "time": 8300.553191423416, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 171584, "time": 8310.121387720108, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 171768, "time": 8317.670376300812, "episode/length": 297.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 172072, "time": 8331.006064891815, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 172152, "time": 8335.250754117966, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 172344, "time": 8343.23355126381, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 172464, "time": 8348.961613893509, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 172512, "time": 8352.178849458694, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 172680, "time": 8359.65917634964, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 172912, "time": 8369.360612154007, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 173368, "time": 8386.135189056396, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 173560, "time": 8394.318432569504, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 173600, "time": 8397.498184919357, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 173689, "time": 8402.86961221695, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.485632054946002, "train/action_min": 0.0, "train/action_std": 3.401684417444117, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04228666406946585, "train/actor_opt_grad_steps": 10075.0, "train/actor_opt_loss": -2.0712619991425205, "train/adv_mag": 0.7741432847345576, "train/adv_max": 0.7659545904573273, "train/adv_mean": 0.004325762557929171, "train/adv_min": -0.4738640986821231, "train/adv_std": 0.0768232615390683, "train/cont_avg": 0.9944852941176471, "train/cont_loss_mean": 0.00025967788723590957, "train/cont_loss_std": 0.00716342268648037, "train/cont_neg_acc": 0.9896002367690757, "train/cont_neg_loss": 0.02052992792123826, "train/cont_pos_acc": 0.9999638138448491, "train/cont_pos_loss": 0.00013928195420463124, "train/cont_pred": 0.9944742273758439, "train/cont_rate": 0.9944852941176471, "train/dyn_loss_mean": 12.896991035517525, "train/dyn_loss_std": 8.850779831409454, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9294502564212855, "train/extr_critic_critic_opt_grad_steps": 10075.0, "train/extr_critic_critic_opt_loss": 14936.751055549174, "train/extr_critic_mag": 3.4965731080840614, "train/extr_critic_max": 3.4965731080840614, "train/extr_critic_mean": 0.704443742028054, "train/extr_critic_min": -0.2831405900857028, "train/extr_critic_std": 0.9274397089200861, "train/extr_return_normed_mag": 1.7926305067889832, "train/extr_return_normed_max": 1.7926305067889832, "train/extr_return_normed_mean": 0.3086616652195944, "train/extr_return_normed_min": -0.18270113992997827, "train/extr_return_normed_std": 0.34609928288880515, "train/extr_return_rate": 0.36831678822636604, "train/extr_return_raw_mag": 4.845068090102252, "train/extr_return_raw_max": 4.845068090102252, "train/extr_return_raw_mean": 0.7165308564024813, "train/extr_return_raw_min": -0.6507307060939425, "train/extr_return_raw_std": 0.9628900907495442, "train/extr_reward_mag": 1.0076589128550362, "train/extr_reward_max": 1.0076589128550362, "train/extr_reward_mean": 0.0171994093723376, "train/extr_reward_min": -0.4179374303887872, "train/extr_reward_std": 0.12124182503013049, "train/image_loss_mean": 10.997285909512463, "train/image_loss_std": 14.778722713975345, "train/model_loss_mean": 18.786429482347824, "train/model_loss_std": 18.515687164138345, "train/model_opt_grad_norm": 80.12780683180866, "train/model_opt_grad_steps": 10061.933823529413, "train/model_opt_loss": 13484.790563246783, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 721.5073529411765, "train/policy_entropy_mag": 2.525618777555578, "train/policy_entropy_max": 2.525618777555578, "train/policy_entropy_mean": 0.6516242494039676, "train/policy_entropy_min": 0.07937644454924499, "train/policy_entropy_std": 0.6180323949631523, "train/policy_logprob_mag": 7.438378021997564, "train/policy_logprob_max": -0.009456122896688826, "train/policy_logprob_mean": -0.6508286154883749, "train/policy_logprob_min": -7.438378021997564, "train/policy_logprob_std": 1.1627835534951265, "train/policy_randomness_mag": 0.8914325938505285, "train/policy_randomness_max": 0.8914325938505285, "train/policy_randomness_mean": 0.2299947615932016, "train/policy_randomness_min": 0.02801640157806961, "train/policy_randomness_std": 0.2181383143453037, "train/post_ent_mag": 50.38597160227158, "train/post_ent_max": 50.38597160227158, "train/post_ent_mean": 35.34258247824276, "train/post_ent_min": 19.540279072873734, "train/post_ent_std": 5.433924738098593, "train/prior_ent_mag": 60.81408312741448, "train/prior_ent_max": 60.81408312741448, "train/prior_ent_mean": 48.359851724961224, "train/prior_ent_min": 25.531089235754575, "train/prior_ent_std": 6.577234306756188, "train/rep_loss_mean": 12.896991035517525, "train/rep_loss_std": 8.850779831409454, "train/reward_avg": 0.018571920870967647, "train/reward_loss_mean": 0.05068944041233729, "train/reward_loss_std": 0.2590568635941428, "train/reward_max_data": 1.0117647086872774, "train/reward_max_pred": 1.0052634880823248, "train/reward_neg_acc": 0.9943379663369235, "train/reward_neg_loss": 0.02911259570871206, "train/reward_pos_acc": 0.9502088708036086, "train/reward_pos_loss": 0.9466681388371131, "train/reward_pred": 0.017692773500183487, "train/reward_rate": 0.0235595703125, "train_stats/sum_log_reward": 4.705041935463913, "train_stats/max_log_achievement_collect_drink": 3.3361344537815127, "train_stats/max_log_achievement_collect_sapling": 2.4453781512605044, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.3445378151260505, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.226890756302521, "train_stats/max_log_achievement_eat_cow": 0.09243697478991597, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.06722689075630252, "train_stats/max_log_achievement_make_wood_sword": 0.17647058823529413, "train_stats/max_log_achievement_place_plant": 2.0252100840336134, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.2016806722689075, "train_stats/max_log_achievement_wake_up": 1.8823529411764706, "train_stats/mean_log_entropy": 0.6114944780574125, "eval_stats/sum_log_reward": 5.037499964237213, "eval_stats/max_log_achievement_collect_drink": 4.8125, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.190610985053354e-06, "report/cont_loss_std": 3.1006813514977694e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0002480827388353646, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4681071434097248e-06, "report/cont_pred": 0.9970695972442627, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.847464561462402, "report/dyn_loss_std": 8.42004680633545, "report/image_loss_mean": 11.633480072021484, "report/image_loss_std": 14.421252250671387, "report/model_loss_mean": 20.575531005859375, "report/model_loss_std": 17.840330123901367, "report/post_ent_mag": 52.17322540283203, "report/post_ent_max": 52.17322540283203, "report/post_ent_mean": 34.78007507324219, "report/post_ent_min": 21.01050567626953, "report/post_ent_std": 5.209047317504883, "report/prior_ent_mag": 60.966552734375, "report/prior_ent_max": 60.966552734375, "report/prior_ent_mean": 49.7441291809082, "report/prior_ent_min": 24.767860412597656, "report/prior_ent_std": 6.255147933959961, "report/rep_loss_mean": 14.847464561462402, "report/rep_loss_std": 8.42004680633545, "report/reward_avg": 0.02646484225988388, "report/reward_loss_mean": 0.03357091173529625, "report/reward_loss_std": 0.1558716893196106, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029616355895996, "report/reward_neg_acc": 0.9969818592071533, "report/reward_neg_loss": 0.011665902100503445, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7593569755554199, "report/reward_pred": 0.026027267798781395, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.39172890764894e-06, "eval/cont_loss_std": 0.00012748621520586312, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010816770372912288, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.6708055738945404e-07, "eval/cont_pred": 0.9960978627204895, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 12.251755714416504, "eval/dyn_loss_std": 8.803969383239746, "eval/image_loss_mean": 12.895721435546875, "eval/image_loss_std": 19.848369598388672, "eval/model_loss_mean": 20.28469467163086, "eval/model_loss_std": 23.091075897216797, "eval/post_ent_mag": 51.44056701660156, "eval/post_ent_max": 51.44056701660156, "eval/post_ent_mean": 36.782447814941406, "eval/post_ent_min": 21.977903366088867, "eval/post_ent_std": 5.460240364074707, "eval/prior_ent_mag": 60.966552734375, "eval/prior_ent_max": 60.966552734375, "eval/prior_ent_mean": 46.21018600463867, "eval/prior_ent_min": 22.63092041015625, "eval/prior_ent_std": 7.021044731140137, "eval/rep_loss_mean": 12.251755714416504, "eval/rep_loss_std": 8.803969383239746, "eval/reward_avg": 0.01533203199505806, "eval/reward_loss_mean": 0.03791444003582001, "eval/reward_loss_std": 0.2963356077671051, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0019781589508057, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.013437638990581036, "eval/reward_pos_acc": 0.8947368264198303, "eval/reward_pos_loss": 1.3326085805892944, "eval/reward_pred": 0.011346676386892796, "eval/reward_rate": 0.0185546875, "replay/size": 173185.0, "replay/inserts": 21792.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.4534430706903622e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.735450178866169e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35024.0, "eval_replay/inserts": 3584.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3425014913082123e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0366053581238, "timer/env.step_count": 2724.0, "timer/env.step_total": 263.65742683410645, "timer/env.step_frac": 0.2636477759128506, "timer/env.step_avg": 0.0967905384853548, "timer/env.step_min": 0.02344536781311035, "timer/env.step_max": 2.0296378135681152, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.89220380783081, "timer/replay._sample_frac": 0.011891768505385945, "timer/replay._sample_avg": 0.0005457141982301216, "timer/replay._sample_min": 0.00039696693420410156, "timer/replay._sample_max": 0.02434992790222168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3172.0, "timer/agent.policy_total": 55.717551469802856, "timer/agent.policy_frac": 0.05571551198353365, "timer/agent.policy_avg": 0.017565432367529273, "timer/agent.policy_min": 0.00966024398803711, "timer/agent.policy_max": 0.12349414825439453, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.15858197212219238, "timer/dataset_train_frac": 0.00015857616738479538, "timer/dataset_train_avg": 0.00011643316602216768, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0007588863372802734, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 611.1023142337799, "timer/agent.train_frac": 0.611079945433535, "timer/agent.train_avg": 0.4486801132406607, "timer/agent.train_min": 0.434234619140625, "timer/agent.train_max": 1.4805312156677246, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48035097122192383, "timer/agent.report_frac": 0.00048033338844622093, "timer/agent.report_avg": 0.24017548561096191, "timer/agent.report_min": 0.23175692558288574, "timer/agent.report_max": 0.24859404563903809, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337737928329685e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 21.79089357146038}
{"step": 173976, "time": 8412.41194820404, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 173976, "time": 8412.42290186882, "episode/length": 182.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 174032, "time": 8417.993296861649, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 174520, "time": 8435.705157756805, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 174576, "time": 8439.398195505142, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 174768, "time": 8447.513155937195, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 174920, "time": 8453.98658490181, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 175056, "time": 8460.401382923126, "episode/length": 186.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 175216, "time": 8467.279650688171, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 175976, "time": 8494.3164665699, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 176048, "time": 8498.484006404877, "episode/length": 258.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 176376, "time": 8510.944913625717, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 176392, "time": 8512.96883225441, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 176480, "time": 8517.774440050125, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 176568, "time": 8522.444264411926, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 176968, "time": 8537.466084241867, "episode/length": 238.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 177184, "time": 8546.44275689125, "episode/length": 245.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 177448, "time": 8556.761813640594, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 177480, "time": 8559.441307067871, "episode/length": 124.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.992, "episode/intrinsic_return": 0.0}
{"step": 177528, "time": 8562.637672901154, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 177656, "time": 8568.78209733963, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 177848, "time": 8576.74240732193, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 178008, "time": 8583.69872879982, "episode/length": 43.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 178208, "time": 8592.073031187057, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 178352, "time": 8598.495217323303, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 178448, "time": 8603.279911756516, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 178648, "time": 8611.30775141716, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 178680, "time": 8613.966465950012, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 178760, "time": 8618.24389076233, "episode/length": 153.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 178816, "time": 8621.933433532715, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 179712, "time": 8653.71788573265, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 179720, "time": 8655.356753349304, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 179760, "time": 8658.52782034874, "episode/length": 163.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 179824, "time": 8662.288552045822, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 179840, "time": 8664.474745512009, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8692.630745649338, "eval_episode/length": 170.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 180024, "time": 8694.538469076157, "eval_episode/length": 178.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.994413407821229}
{"step": 180024, "time": 8696.457039117813, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 180024, "time": 8698.324414491653, "eval_episode/length": 192.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9844559585492227}
{"step": 180024, "time": 8700.095272541046, "eval_episode/length": 197.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 180024, "time": 8702.18631863594, "eval_episode/length": 36.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.972972972972973}
{"step": 180024, "time": 8705.04944396019, "eval_episode/length": 235.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 180024, "time": 8707.691598653793, "eval_episode/length": 258.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9806949806949807}
{"step": 180232, "time": 8715.025211572647, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 180704, "time": 8734.011076927185, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 180936, "time": 8743.130522489548, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 181072, "time": 8749.626364707947, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 181176, "time": 8754.49497961998, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 181288, "time": 8759.70151925087, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 181744, "time": 8776.74070429802, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 181912, "time": 8784.405366420746, "episode/length": 274.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9781818181818182, "episode/intrinsic_return": 0.0}
{"step": 181952, "time": 8787.538279294968, "episode/length": 96.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 182016, "time": 8791.260370731354, "episode/length": 273.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 182320, "time": 8803.035072803497, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 182384, "time": 8806.780900001526, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 182464, "time": 8811.135987758636, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 183056, "time": 8832.46722126007, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 183080, "time": 8834.820944309235, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 183368, "time": 8846.10599899292, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 183376, "time": 8848.158950567245, "episode/length": 36.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 183536, "time": 8855.061068534851, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 183776, "time": 8864.744950532913, "episode/length": 181.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 183920, "time": 8871.235210895538, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 184040, "time": 8876.726337432861, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 184064, "time": 8879.259420633316, "episode/length": 255.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 184632, "time": 8899.715893507004, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 184656, "time": 8902.244108438492, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 184752, "time": 8907.07650566101, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 184928, "time": 8914.527469873428, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 185272, "time": 8927.491144895554, "episode/length": 64.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 185464, "time": 8935.586691379547, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 185464, "time": 8935.601264715195, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 185512, "time": 8940.441429138184, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 185872, "time": 8954.400600194931, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 185952, "time": 8958.853395462036, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 186016, "time": 8962.612242221832, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 186168, "time": 8969.138085842133, "episode/length": 36.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 186544, "time": 8983.408653020859, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 186592, "time": 8986.577150583267, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 186904, "time": 8999.161061763763, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 187240, "time": 9012.084842681885, "episode/length": 221.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 187328, "time": 9016.908712387085, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 187400, "time": 9020.986018419266, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 187608, "time": 9029.618188858032, "episode/length": 267.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 187984, "time": 9044.085102796555, "episode/length": 308.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 188160, "time": 9051.691938638687, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 188192, "time": 9054.33485364914, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 188192, "time": 9054.344348192215, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 188480, "time": 9068.825124263763, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 188592, "time": 9074.221029996872, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 188872, "time": 9085.073996305466, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 189232, "time": 9099.77266550064, "episode/length": 155.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 189344, "time": 9105.124967575073, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 189360, "time": 9107.184837818146, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 189416, "time": 9110.662901639938, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 189688, "time": 9121.295192241669, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 189928, "time": 9131.344828367233, "episode/length": 131.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 189960, "time": 9133.996446609497, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9157.598550319672, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 190008, "time": 9159.25597167015, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 190008, "time": 9161.06437754631, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 190008, "time": 9163.671983718872, "eval_episode/length": 188.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 190008, "time": 9165.390383720398, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 190008, "time": 9168.004638671875, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 190008, "time": 9170.089732170105, "eval_episode/length": 219.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 190008, "time": 9173.07948255539, "eval_episode/length": 250.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9800796812749004}
{"step": 190264, "time": 9181.738583087921, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 190624, "time": 9195.736510515213, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 190664, "time": 9198.597155332565, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 190904, "time": 9208.28464269638, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 191016, "time": 9213.653173923492, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 191176, "time": 9220.649359941483, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 191200, "time": 9223.255331277847, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 191456, "time": 9233.608006000519, "episode/length": 190.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 191760, "time": 9245.441704511642, "episode/length": 69.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 191816, "time": 9249.137973546982, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 191920, "time": 9254.422837972641, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 192200, "time": 9265.395673274994, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 192232, "time": 9268.114778518677, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 192336, "time": 9273.455207586288, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 192504, "time": 9280.477680206299, "episode/length": 185.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 192576, "time": 9284.692199230194, "episode/length": 174.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 192784, "time": 9293.44899058342, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 193200, "time": 9308.934712648392, "episode/length": 217.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 193448, "time": 9318.766951560974, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 193456, "time": 9320.822566270828, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 193552, "time": 9325.657328605652, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 193568, "time": 9327.817791700363, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 193952, "time": 9342.305573225021, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 193960, "time": 9343.890139341354, "episode/length": 172.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 194128, "time": 9351.394013643265, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 194632, "time": 9369.66847705841, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 194880, "time": 9380.085675477982, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 194976, "time": 9385.027851581573, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 195184, "time": 9393.704310894012, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 195336, "time": 9400.126338720322, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 195353, "time": 9403.144519329071, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.420472088982077, "train/action_min": 0.0, "train/action_std": 3.61933734311777, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.045610934085048294, "train/actor_opt_grad_steps": 11435.0, "train/actor_opt_loss": 11.829680023605333, "train/adv_mag": 0.7598337787477409, "train/adv_max": 0.7446092419764575, "train/adv_mean": 0.007252717598917383, "train/adv_min": -0.46791982519276004, "train/adv_std": 0.07998985208242256, "train/cont_avg": 0.9943201401654411, "train/cont_loss_mean": 0.0004296671586529629, "train/cont_loss_std": 0.01240233986904032, "train/cont_neg_acc": 0.9884512148359242, "train/cont_neg_loss": 0.043890649563861885, "train/cont_pos_acc": 0.9999277350657126, "train/cont_pos_loss": 0.00022411104394566152, "train/cont_pred": 0.9943023345926228, "train/cont_rate": 0.9943201401654411, "train/dyn_loss_mean": 13.306351879063774, "train/dyn_loss_std": 8.921258526689867, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0056779099737896, "train/extr_critic_critic_opt_grad_steps": 11435.0, "train/extr_critic_critic_opt_loss": 15983.697954963236, "train/extr_critic_mag": 3.802996512721567, "train/extr_critic_max": 3.802996512721567, "train/extr_critic_mean": 0.8581590836538988, "train/extr_critic_min": -0.2645425875397289, "train/extr_critic_std": 0.9851923589320744, "train/extr_return_normed_mag": 1.7588597387075424, "train/extr_return_normed_max": 1.7588597387075424, "train/extr_return_normed_mean": 0.3303409424774787, "train/extr_return_normed_min": -0.17078074004829807, "train/extr_return_normed_std": 0.34079429441515136, "train/extr_return_rate": 0.46296724260729905, "train/extr_return_raw_mag": 5.185308310915442, "train/extr_return_raw_max": 5.185308310915442, "train/extr_return_raw_mean": 0.8800030374789939, "train/extr_return_raw_min": -0.6313104548436754, "train/extr_return_raw_std": 1.0267689100959723, "train/extr_reward_mag": 1.0076712930903715, "train/extr_reward_max": 1.0076712930903715, "train/extr_reward_mean": 0.021148014258976805, "train/extr_reward_min": -0.4181484790409313, "train/extr_reward_std": 0.13404005152337692, "train/image_loss_mean": 10.198291007210226, "train/image_loss_std": 13.51695445355247, "train/model_loss_mean": 18.233943862073563, "train/model_loss_std": 17.342020848218134, "train/model_opt_grad_norm": 73.5957857019761, "train/model_opt_grad_steps": 11420.97794117647, "train/model_opt_loss": 15407.074448529413, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 845.5882352941177, "train/policy_entropy_mag": 2.5126464577282177, "train/policy_entropy_max": 2.5126464577282177, "train/policy_entropy_mean": 0.6260318999343059, "train/policy_entropy_min": 0.07937548945055288, "train/policy_entropy_std": 0.6050282392431708, "train/policy_logprob_mag": 7.438379561199861, "train/policy_logprob_max": -0.009455899297095397, "train/policy_logprob_mean": -0.6250777840614319, "train/policy_logprob_min": -7.438379561199861, "train/policy_logprob_std": 1.1373147079173256, "train/policy_randomness_mag": 0.8868539355256978, "train/policy_randomness_max": 0.8868539355256978, "train/policy_randomness_mean": 0.220961787902257, "train/policy_randomness_min": 0.0280160645077772, "train/policy_randomness_std": 0.2135484175866141, "train/post_ent_mag": 51.52356532040764, "train/post_ent_max": 51.52356532040764, "train/post_ent_mean": 35.92723714604097, "train/post_ent_min": 19.735955981647265, "train/post_ent_std": 5.630796362372005, "train/prior_ent_mag": 61.641985304215375, "train/prior_ent_max": 61.641985304215375, "train/prior_ent_mean": 49.34676652796128, "train/prior_ent_min": 27.864892160191257, "train/prior_ent_std": 6.197030372479382, "train/rep_loss_mean": 13.306351879063774, "train/rep_loss_std": 8.921258526689867, "train/reward_avg": 0.0193761487984482, "train/reward_loss_mean": 0.05141210251980845, "train/reward_loss_std": 0.2532418364768519, "train/reward_max_data": 1.0088235315154581, "train/reward_max_pred": 1.0044009948478025, "train/reward_neg_acc": 0.9941841552362722, "train/reward_neg_loss": 0.030468894387869275, "train/reward_pos_acc": 0.9604892274912666, "train/reward_pos_loss": 0.8927701010423548, "train/reward_pred": 0.018925545939162153, "train/reward_rate": 0.02450741038602941, "train_stats/sum_log_reward": 4.966666583220164, "train_stats/max_log_achievement_collect_drink": 3.591666666666667, "train_stats/max_log_achievement_collect_sapling": 1.875, "train_stats/max_log_achievement_collect_stone": 0.1, "train_stats/max_log_achievement_collect_wood": 5.283333333333333, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.21666666666666667, "train_stats/max_log_achievement_eat_cow": 0.025, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4583333333333333, "train_stats/max_log_achievement_make_wood_sword": 0.19166666666666668, "train_stats/max_log_achievement_place_plant": 1.525, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.325, "train_stats/max_log_achievement_wake_up": 1.6, "train_stats/mean_log_entropy": 0.6273952811956406, "eval_stats/sum_log_reward": 5.287499934434891, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 4.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 0.9375, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.02702702702702703, "eval_stats/max_log_achievement_collect_coal": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 6.081401807023212e-05, "report/cont_loss_std": 0.0016925150994211435, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019148671999573708, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.71857308386825e-05, "report/cont_pred": 0.9979950189590454, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.905692100524902, "report/dyn_loss_std": 8.892334938049316, "report/image_loss_mean": 6.045253753662109, "report/image_loss_std": 8.222847938537598, "report/model_loss_mean": 13.817815780639648, "report/model_loss_std": 12.354852676391602, "report/post_ent_mag": 47.575599670410156, "report/post_ent_max": 47.575599670410156, "report/post_ent_mean": 34.43098831176758, "report/post_ent_min": 17.89719581604004, "report/post_ent_std": 4.791707515716553, "report/prior_ent_mag": 61.62158966064453, "report/prior_ent_max": 61.62158966064453, "report/prior_ent_mean": 47.96249008178711, "report/prior_ent_min": 28.11988067626953, "report/prior_ent_std": 6.631189823150635, "report/rep_loss_mean": 12.905692100524902, "report/rep_loss_std": 8.892334938049316, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.029086779803037643, "report/reward_loss_std": 0.19143490493297577, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0028085708618164, "report/reward_neg_acc": 0.999000072479248, "report/reward_neg_loss": 0.008436121046543121, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.8895310163497925, "report/reward_pred": 0.021449614316225052, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.2125298781029414e-05, "eval/cont_loss_std": 0.0001692003570497036, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001530698500573635, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.170108463265933e-06, "eval/cont_pred": 0.9960936307907104, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 14.790704727172852, "eval/dyn_loss_std": 9.816554069519043, "eval/image_loss_mean": 11.910713195800781, "eval/image_loss_std": 17.217090606689453, "eval/model_loss_mean": 20.875410079956055, "eval/model_loss_std": 21.649829864501953, "eval/post_ent_mag": 47.13648223876953, "eval/post_ent_max": 47.13648223876953, "eval/post_ent_mean": 35.814414978027344, "eval/post_ent_min": 20.538745880126953, "eval/post_ent_std": 4.656494617462158, "eval/prior_ent_mag": 62.27427291870117, "eval/prior_ent_max": 62.27427291870117, "eval/prior_ent_mean": 47.929443359375, "eval/prior_ent_min": 25.996997833251953, "eval/prior_ent_std": 6.52489709854126, "eval/rep_loss_mean": 14.790704727172852, "eval/rep_loss_std": 9.816554069519043, "eval/reward_avg": 0.01943359524011612, "eval/reward_loss_mean": 0.09026069939136505, "eval/reward_loss_std": 0.7076058387756348, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0032410621643066, "eval/reward_neg_acc": 0.9960000514984131, "eval/reward_neg_loss": 0.03416288644075394, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.4276702404022217, "eval/reward_pred": 0.016420241445302963, "eval/reward_rate": 0.0234375, "replay/size": 194849.0, "replay/inserts": 21664.0, "replay/samples": 21664.0, "replay/insert_wait_avg": 1.458145755080388e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.669526397389534e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 39104.0, "eval_replay/inserts": 4080.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.34122137929879e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.26194190979, "timer/env.step_count": 2708.0, "timer/env.step_total": 268.51961302757263, "timer/env.step_frac": 0.26844929490658304, "timer/env.step_avg": 0.09915790732185105, "timer/env.step_min": 0.024214744567871094, "timer/env.step_max": 3.379035711288452, "timer/replay._sample_count": 21664.0, "timer/replay._sample_total": 11.787642240524292, "timer/replay._sample_frac": 0.011784555371584233, "timer/replay._sample_avg": 0.0005441119941157816, "timer/replay._sample_min": 0.0004146099090576172, "timer/replay._sample_max": 0.012023210525512695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3218.0, "timer/agent.policy_total": 55.66558504104614, "timer/agent.policy_frac": 0.0556510077098049, "timer/agent.policy_avg": 0.01729819298975952, "timer/agent.policy_min": 0.009616613388061523, "timer/agent.policy_max": 0.09710049629211426, "timer/dataset_train_count": 1354.0, "timer/dataset_train_total": 0.15768671035766602, "timer/dataset_train_frac": 0.0001576454164162203, "timer/dataset_train_avg": 0.00011645990425233827, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.00027871131896972656, "timer/agent.train_count": 1354.0, "timer/agent.train_total": 607.9264118671417, "timer/agent.train_frac": 0.60776721216288, "timer/agent.train_avg": 0.4489855331367369, "timer/agent.train_min": 0.43632006645202637, "timer/agent.train_max": 1.5409021377563477, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47428250312805176, "timer/agent.report_frac": 0.0004741583011970934, "timer/agent.report_avg": 0.23714125156402588, "timer/agent.report_min": 0.22982287406921387, "timer/agent.report_max": 0.2444596290588379, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.265479167841802e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 21.65806856691418}
{"step": 195472, "time": 9407.276221036911, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 195488, "time": 9409.511343240738, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 195640, "time": 9416.04800415039, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
