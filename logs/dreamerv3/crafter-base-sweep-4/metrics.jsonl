{"step": 1176, "time": 124.6422688961029, "episode/length": 146.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 1256, "time": 126.32807612419128, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 1288, "time": 127.87155151367188, "episode/length": 160.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1320, "time": 129.46407675743103, "episode/length": 164.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 1392, "time": 131.3416223526001, "episode/length": 173.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 1456, "time": 132.93764400482178, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 1552, "time": 134.63885807991028, "episode/length": 193.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 136.0595257282257, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 149.44912195205688, "eval_episode/length": 78.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9240506329113924}
{"step": 1560, "time": 152.41779589653015, "eval_episode/length": 141.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9929577464788732}
{"step": 1560, "time": 153.94101977348328, "eval_episode/length": 149.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 1560, "time": 155.48765230178833, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 1560, "time": 157.56316256523132, "eval_episode/length": 182.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.994535519125683}
{"step": 1560, "time": 159.02426433563232, "eval_episode/length": 185.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 1560, "time": 160.85277819633484, "train_stats/sum_log_reward": 1.8499999418854713, "train_stats/max_log_achievement_wake_up": 1.875, "train_stats/max_log_achievement_collect_sapling": 0.7142857142857143, "train_stats/max_log_achievement_place_plant": 0.7142857142857143, "train_stats/max_log_achievement_collect_drink": 0.3333333333333333, "train_stats/max_log_achievement_collect_wood": 1.0, "train_stats/max_log_achievement_eat_cow": 0.3333333333333333, "eval_stats/sum_log_reward": 1.4333332777023315, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 0.6666666666666666, "eval_stats/max_log_achievement_collect_wood": 0.16666666666666666, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 1.8333333333333333}
{"step": 1560, "time": 194.83442997932434, "eval_episode/length": 51.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9038461538461539}
{"step": 1560, "time": 200.79905009269714, "eval_episode/length": 145.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 1560, "time": 203.15143060684204, "eval_episode/length": 149.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 1560, "time": 205.30552625656128, "eval_episode/length": 150.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9536423841059603}
{"step": 1560, "time": 207.51986861228943, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 1560, "time": 210.5845558643341, "eval_episode/length": 168.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 1560, "time": 212.62358713150024, "eval_episode/length": 173.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 1560, "time": 216.1003270149231, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 1561, "time": 346.2049460411072, "eval_stats/sum_log_reward": 1.4750000014901161, "eval_stats/max_log_achievement_collect_drink": 0.875, "eval_stats/max_log_achievement_collect_sapling": 0.75, "eval_stats/max_log_achievement_collect_wood": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 0.75, "eval_stats/max_log_achievement_wake_up": 1.5, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 7.5703125, "train/action_min": 0.0, "train/action_std": 4.562880992889404, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00010229247709503397, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.6949850916862488, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.9970703125, "train/cont_loss_mean": 1.0277705192565918, "train/cont_loss_std": 0.3290090262889862, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.4973142147064209, "train/cont_pos_acc": 0.15670910477638245, "train/cont_pos_loss": 1.0293291807174683, "train/cont_pred": 0.37601807713508606, "train/cont_rate": 0.9970703125, "train/dyn_loss_mean": 9.85970687866211, "train/dyn_loss_std": 0.40032193064689636, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 2.4110543727874756, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 9822.921875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3943.7724609375, "train/image_loss_std": 190.80288696289062, "train/model_loss_mean": 3956.257568359375, "train/model_loss_std": 190.87161254882812, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 39562576.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.802191972732544, "train/policy_entropy_max": 2.802191972732544, "train/policy_entropy_mean": 2.619833469390869, "train/policy_entropy_min": 2.0160279273986816, "train/policy_entropy_std": 0.07905405759811401, "train/policy_logprob_mag": 5.157093524932861, "train/policy_logprob_max": -0.7038899660110474, "train/policy_logprob_mean": -2.6204710006713867, "train/policy_logprob_min": -5.157093524932861, "train/policy_logprob_std": 0.6352691650390625, "train/policy_randomness_mag": 0.9890508055686951, "train/policy_randomness_max": 0.9890508055686951, "train/policy_randomness_mean": 0.9246862530708313, "train/policy_randomness_min": 0.7115693688392639, "train/policy_randomness_std": 0.02790261246263981, "train/post_ent_mag": 106.57012939453125, "train/post_ent_max": 106.57012939453125, "train/post_ent_mean": 105.97172546386719, "train/post_ent_min": 105.26265716552734, "train/post_ent_std": 0.2390742003917694, "train/prior_ent_mag": 106.39482116699219, "train/prior_ent_max": 106.39482116699219, "train/prior_ent_mean": 105.64381408691406, "train/prior_ent_min": 104.60343933105469, "train/prior_ent_std": 0.2696845829486847, "train/rep_loss_mean": 9.85970687866211, "train/rep_loss_std": 0.40032193064689636, "train/reward_avg": 0.00498046912252903, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.548376738166553e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0087890625, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.9897432327270508, "report/cont_loss_std": 0.3378311097621918, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.4862140119075775, "report/cont_pos_acc": 0.19686581194400787, "report/cont_pos_loss": 0.991222620010376, "report/cont_pred": 0.39155277609825134, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 9.891440391540527, "report/dyn_loss_std": 0.364462673664093, "report/image_loss_mean": 3940.6396484375, "report/image_loss_std": 188.32241821289062, "report/model_loss_mean": 3953.10546875, "report/model_loss_std": 188.3760986328125, "report/post_ent_mag": 106.59162902832031, "report/post_ent_max": 106.59162902832031, "report/post_ent_mean": 105.97044372558594, "report/post_ent_min": 105.40254974365234, "report/post_ent_std": 0.24329495429992676, "report/prior_ent_mag": 106.44483947753906, "report/prior_ent_max": 106.44483947753906, "report/prior_ent_mean": 105.60322570800781, "report/prior_ent_min": 104.76520538330078, "report/prior_ent_std": 0.2791057229042053, "report/rep_loss_mean": 9.891440391540527, "report/rep_loss_std": 0.364462673664093, "report/reward_avg": 0.00498046912252903, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.548376738166553e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.9640230536460876, "eval/cont_loss_std": 0.33415651321411133, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.4251992106437683, "eval/cont_pos_acc": 0.22233104705810547, "eval/cont_pos_loss": 0.9656062126159668, "eval/cont_pred": 0.4009917676448822, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 9.80278491973877, "eval/dyn_loss_std": 0.43353787064552307, "eval/image_loss_mean": 3950.12255859375, "eval/image_loss_std": 219.34056091308594, "eval/model_loss_mean": 3962.509765625, "eval/model_loss_std": 219.44642639160156, "eval/post_ent_mag": 106.58331298828125, "eval/post_ent_max": 106.58331298828125, "eval/post_ent_mean": 105.97765350341797, "eval/post_ent_min": 105.40774536132812, "eval/post_ent_std": 0.25929898023605347, "eval/prior_ent_mag": 106.44793701171875, "eval/prior_ent_max": 106.44793701171875, "eval/prior_ent_mean": 105.62686920166016, "eval/prior_ent_min": 104.5623779296875, "eval/prior_ent_std": 0.3014630675315857, "eval/rep_loss_mean": 9.80278491973877, "eval/rep_loss_std": 0.43353787064552307, "eval/reward_avg": 0.010058593936264515, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541264057159424, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0146484375, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.7444931795378281e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 2.0052705492292134e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2776.0, "eval_replay/inserts": 2776.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5760017746807175e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.64318002973284e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 236.7443871498108, "timer/env.step_count": 196.0, "timer/env.step_total": 27.898498058319092, "timer/env.step_frac": 0.11784227873020299, "timer/env.step_avg": 0.14233927580775046, "timer/env.step_min": 0.022601842880249023, "timer/env.step_max": 11.44351577758789, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.1402137279510498, "timer/replay._sample_frac": 0.0005922578762651854, "timer/replay._sample_avg": 0.0012519082852772304, "timer/replay._sample_min": 0.00037598609924316406, "timer/replay._sample_max": 0.0150604248046875, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.215070247650146, "timer/agent.save_frac": 0.03892413399359239, "timer/agent.save_avg": 9.215070247650146, "timer/agent.save_min": 9.215070247650146, "timer/agent.save_max": 9.215070247650146, "timer/agent.policy_count": 216.0, "timer/agent.policy_total": 21.214860916137695, "timer/agent.policy_frac": 0.08961082951763087, "timer/agent.policy_avg": 0.09821694868582266, "timer/agent.policy_min": 0.010627031326293945, "timer/agent.policy_max": 14.673464059829712, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.8623809814453125e-05, "timer/dataset_train_frac": 1.6314561996357763e-07, "timer/dataset_train_avg": 3.8623809814453125e-05, "timer/dataset_train_min": 3.8623809814453125e-05, "timer/dataset_train_max": 3.8623809814453125e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 98.46708178520203, "timer/agent.train_frac": 0.4159215049220681, "timer/agent.train_avg": 98.46708178520203, "timer/agent.train_min": 98.46708178520203, "timer/agent.train_max": 98.46708178520203, "timer/agent.report_count": 2.0, "timer/agent.report_total": 27.305374145507812, "timer/agent.report_frac": 0.11533694409502132, "timer/agent.report_avg": 13.652687072753906, "timer/agent.report_min": 0.24822115898132324, "timer/agent.report_max": 27.05715298652649, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.981590270996094e-05, "timer/dataset_eval_frac": 1.681809786044288e-07, "timer/dataset_eval_avg": 3.981590270996094e-05, "timer/dataset_eval_min": 3.981590270996094e-05, "timer/dataset_eval_max": 3.981590270996094e-05}
{"step": 2336, "time": 372.81367325782776, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 2432, "time": 377.6525514125824, "episode/length": 146.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 2488, "time": 380.97616624832153, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 2656, "time": 388.51901483535767, "episode/length": 136.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 2680, "time": 390.6546034812927, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 2736, "time": 394.3687982559204, "episode/length": 180.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 2792, "time": 397.6380741596222, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 3184, "time": 413.0885155200958, "episode/length": 203.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 3952, "time": 441.1953458786011, "episode/length": 161.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 3968, "time": 443.48352432250977, "episode/length": 146.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 4088, "time": 448.92976570129395, "episode/length": 199.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 4128, "time": 452.082617521286, "episode/length": 223.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 4144, "time": 454.25967478752136, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 4352, "time": 463.266969203949, "episode/length": 49.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 4368, "time": 465.5346095561981, "episode/length": 241.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 4808, "time": 481.9492115974426, "episode/length": 265.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 5264, "time": 499.60757517814636, "episode/length": 161.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 5760, "time": 518.1768770217896, "episode/length": 208.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 5840, "time": 522.7692406177521, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 5840, "time": 522.7792096138, "episode/length": 213.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 5848, "time": 526.21018409729, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 6080, "time": 536.0027222633362, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 6112, "time": 538.6972622871399, "episode/length": 245.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 6496, "time": 553.5698437690735, "episode/length": 413.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 6696, "time": 561.7378075122833, "episode/length": 24.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.84, "episode/intrinsic_return": 0.0}
{"step": 6896, "time": 570.410427570343, "episode/length": 101.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9509803921568627, "episode/intrinsic_return": 0.0}
{"step": 7160, "time": 581.1189558506012, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 7216, "time": 584.9481182098389, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 7304, "time": 589.4010632038116, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 7328, "time": 592.0629684925079, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 7600, "time": 602.8999373912811, "episode/length": 291.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 7808, "time": 611.7231228351593, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 8496, "time": 638.36159324646, "episode/length": 224.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 8512, "time": 640.6974227428436, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 8608, "time": 645.663064956665, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 8704, "time": 651.0933735370636, "episode/length": 174.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 8768, "time": 654.8936672210693, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 8832, "time": 658.6662156581879, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 8928, "time": 663.6457166671753, "episode/length": 139.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 9192, "time": 674.1416771411896, "episode/length": 286.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9930313588850174, "episode/intrinsic_return": 0.0}
{"step": 9720, "time": 693.6849000453949, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 9800, "time": 697.9807035923004, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 9944, "time": 704.7410264015198, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 9984, "time": 707.9879634380341, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 730.9068140983582, "eval_episode/length": 97.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9591836734693877}
{"step": 10088, "time": 732.7414724826813, "eval_episode/length": 100.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9603960396039604}
{"step": 10088, "time": 736.1205177307129, "eval_episode/length": 137.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9637681159420289}
{"step": 10088, "time": 739.5490031242371, "eval_episode/length": 178.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 10088, "time": 741.712827205658, "eval_episode/length": 189.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 10088, "time": 744.0825297832489, "eval_episode/length": 205.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 10088, "time": 747.0488579273224, "eval_episode/length": 234.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9872340425531915}
{"step": 10088, "time": 750.8174619674683, "eval_episode/length": 44.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 10144, "time": 752.9210300445557, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 10336, "time": 761.1542468070984, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 10456, "time": 766.5891230106354, "episode/length": 63.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.921875, "episode/intrinsic_return": 0.0}
{"step": 10520, "time": 770.2531394958496, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 10808, "time": 781.5648853778839, "episode/length": 201.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 11088, "time": 793.1864628791809, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 11184, "time": 798.1622130870819, "episode/length": 182.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 11456, "time": 808.950305223465, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 11472, "time": 811.2457768917084, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 11688, "time": 820.1505534648895, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 11768, "time": 824.5502045154572, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 11848, "time": 829.035059928894, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 12376, "time": 848.7805199623108, "episode/length": 148.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 12528, "time": 855.9390449523926, "episode/length": 214.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 12968, "time": 872.4945681095123, "episode/length": 186.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 13072, "time": 877.9962434768677, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 13152, "time": 882.5714247226715, "episode/length": 182.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 13264, "time": 888.3092081546783, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 13288, "time": 890.9827013015747, "episode/length": 274.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 13656, "time": 905.4587097167969, "episode/length": 274.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 13904, "time": 915.9948074817657, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 13920, "time": 918.3197960853577, "episode/length": 192.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 14296, "time": 932.5167579650879, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 14328, "time": 935.2880079746246, "episode/length": 146.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 14424, "time": 940.3177325725555, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 14544, "time": 946.2403202056885, "episode/length": 159.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 14856, "time": 958.2956213951111, "episode/length": 195.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 15128, "time": 969.2268657684326, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 15152, "time": 972.1734547615051, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 15400, "time": 981.9601767063141, "episode/length": 121.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 15400, "time": 981.9721319675446, "episode/length": 217.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 15512, "time": 989.300439119339, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 15768, "time": 1000.1008365154266, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 15944, "time": 1008.2521913051605, "episode/length": 201.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 16192, "time": 1018.5504760742188, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 16336, "time": 1025.1159944534302, "episode/length": 150.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 16744, "time": 1041.9386909008026, "episode/length": 198.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 16792, "time": 1045.2731387615204, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 16824, "time": 1047.9722249507904, "episode/length": 177.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 16928, "time": 1053.393390417099, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 17336, "time": 1069.081980228424, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 17552, "time": 1078.3075468540192, "episode/length": 254.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 17568, "time": 1080.6414453983307, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 17616, "time": 1084.0498547554016, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 17648, "time": 1086.6992483139038, "episode/length": 102.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 18088, "time": 1103.3811869621277, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 18344, "time": 1113.792376279831, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 18688, "time": 1127.5962414741516, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 18840, "time": 1134.2299284934998, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 18896, "time": 1138.16783452034, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 18944, "time": 1141.4833192825317, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 18968, "time": 1143.664921283722, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 19032, "time": 1147.450365304947, "episode/length": 117.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 19344, "time": 1160.1558599472046, "episode/length": 221.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1207.0331149101257, "eval_episode/length": 143.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 20072, "time": 1209.3894619941711, "eval_episode/length": 158.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 20072, "time": 1211.2196412086487, "eval_episode/length": 159.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 20072, "time": 1213.0153245925903, "eval_episode/length": 162.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 20072, "time": 1214.8418309688568, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 20072, "time": 1217.6418702602386, "eval_episode/length": 176.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 20072, "time": 1220.538829088211, "eval_episode/length": 192.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 20072, "time": 1223.1856665611267, "eval_episode/length": 201.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 20072, "time": 1223.193217754364, "eval_episode/length": 38.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 20200, "time": 1227.615494966507, "episode/length": 231.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 20224, "time": 1230.335218667984, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 20272, "time": 1233.6947996616364, "episode/length": 115.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.0}
{"step": 20392, "time": 1239.2286450862885, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 20432, "time": 1242.5893805027008, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 20480, "time": 1245.851799249649, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 21128, "time": 1269.3104031085968, "episode/length": 304.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9934426229508196, "episode/intrinsic_return": 0.0}
{"step": 21344, "time": 1278.7481274604797, "episode/length": 107.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 21496, "time": 1285.265344619751, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 21536, "time": 1288.4020161628723, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 21544, "time": 1289.991702079773, "episode/length": 337.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9970414201183432, "episode/intrinsic_return": 0.0}
{"step": 21672, "time": 1295.936157464981, "episode/length": 40.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 21832, "time": 1303.1617579460144, "episode/length": 87.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 21840, "time": 1305.3653936386108, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 22000, "time": 1312.4898166656494, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 22137, "time": 1319.530995130539, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.438902854919434, "train/action_min": 0.0, "train/action_std": 2.1409023399464786, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.020980647572287126, "train/actor_opt_grad_steps": 645.0, "train/actor_opt_loss": 234.09096310433233, "train/adv_mag": 2.3854742768035067, "train/adv_max": 2.3852888979181444, "train/adv_mean": 0.04584436750516829, "train/adv_min": -0.32476455479991273, "train/adv_std": 0.18791145772866003, "train/cont_avg": 0.99468994140625, "train/cont_loss_mean": 0.0292817118597668, "train/cont_loss_std": 0.2439708675865404, "train/cont_neg_acc": 0.05988626493009057, "train/cont_neg_loss": 3.1997432868311724, "train/cont_pos_acc": 0.9936271073529497, "train/cont_pos_loss": 0.012586627261498506, "train/cont_pred": 0.9899969100952148, "train/cont_rate": 0.99468994140625, "train/dyn_loss_mean": 5.424757541157305, "train/dyn_loss_std": 7.3351234486326575, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.446997108869255, "train/extr_critic_critic_opt_grad_steps": 645.0, "train/extr_critic_critic_opt_loss": 23127.830047607422, "train/extr_critic_mag": 0.32184021081775427, "train/extr_critic_max": 0.3218402089551091, "train/extr_critic_mean": 0.12970770991864808, "train/extr_critic_min": -0.0018401965498924255, "train/extr_critic_std": 0.0953182232851793, "train/extr_return_normed_mag": 2.6415302944060386, "train/extr_return_normed_max": 2.6415302944060386, "train/extr_return_normed_mean": 0.19534500354257034, "train/extr_return_normed_min": -0.19986239997865596, "train/extr_return_normed_std": 0.23282308808029484, "train/extr_return_rate": 0.09125061528311562, "train/extr_return_raw_mag": 2.8919251164934394, "train/extr_return_raw_max": 2.8919251164934394, "train/extr_return_raw_mean": 0.17983693558471714, "train/extr_return_raw_min": -0.27356833183694107, "train/extr_return_raw_std": 0.269808258656667, "train/extr_reward_mag": 0.6319904737174511, "train/extr_reward_max": 0.6319904737174511, "train/extr_reward_mean": 0.010421524086495992, "train/extr_reward_min": -0.08466726262122393, "train/extr_reward_std": 0.04805664341081095, "train/image_loss_mean": 98.90930244326591, "train/image_loss_std": 51.2297086417675, "train/model_loss_mean": 102.5086964815855, "train/model_loss_std": 52.66189340502024, "train/model_opt_grad_norm": 399.2231515645981, "train/model_opt_grad_steps": 636.0, "train/model_opt_loss": 2116.7964339256287, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 23.8037109375, "train/policy_entropy_mag": 1.1764489252818748, "train/policy_entropy_max": 1.1764489252818748, "train/policy_entropy_mean": 0.7165446177823469, "train/policy_entropy_min": 0.5940196572919376, "train/policy_entropy_std": 0.09160955445622676, "train/policy_logprob_mag": 6.95643450692296, "train/policy_logprob_max": -0.2687652737440658, "train/policy_logprob_mean": -0.7171770479762927, "train/policy_logprob_min": -6.95643450692296, "train/policy_logprob_std": 0.8350967196747661, "train/policy_randomness_mag": 0.4152348432689905, "train/policy_randomness_max": 0.4152348432689905, "train/policy_randomness_mean": 0.25290880106331315, "train/policy_randomness_min": 0.20966287012561224, "train/policy_randomness_std": 0.032334152334897226, "train/post_ent_mag": 52.0579888522625, "train/post_ent_max": 52.0579888522625, "train/post_ent_mean": 33.45889502763748, "train/post_ent_min": 16.482261560857296, "train/post_ent_std": 6.387334152124822, "train/prior_ent_mag": 57.41074529290199, "train/prior_ent_max": 57.41074529290199, "train/prior_ent_mean": 39.55681002140045, "train/prior_ent_min": 22.522056236863136, "train/prior_ent_std": 6.083632329013199, "train/rep_loss_mean": 5.424757541157305, "train/rep_loss_std": 7.3351234486326575, "train/reward_avg": 0.00963058462139088, "train/reward_loss_mean": 0.31525843270355836, "train/reward_loss_std": 0.6395450530244364, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.7289245780557394, "train/reward_neg_acc": 0.9966205595992506, "train/reward_neg_loss": 0.27461966293049045, "train/reward_pos_acc": 0.4907443832489662, "train/reward_pos_loss": 2.9793952954933047, "train/reward_pred": 0.0064668736022213125, "train/reward_rate": 0.0143890380859375, "train_stats/sum_log_reward": 1.303539781707578, "train_stats/max_log_achievement_collect_drink": 0.6991150442477876, "train_stats/max_log_achievement_collect_sapling": 8.946902654867257, "train_stats/max_log_achievement_collect_wood": 0.1504424778761062, "train_stats/max_log_achievement_eat_cow": 0.1415929203539823, "train_stats/max_log_achievement_place_plant": 1.008849557522124, "train_stats/max_log_achievement_wake_up": 0.7168141592920354, "train_stats/mean_log_entropy": 0.728608071869981, "train_stats/max_log_achievement_place_table": 0.018018018018018018, "train_stats/max_log_achievement_defeat_zombie": 0.21428571428571427, "eval_stats/sum_log_reward": 1.3352940590942608, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 7.705882352941177, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.11764705882352941, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_place_plant": 1.411764705882353, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.9411764705882353, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.019533079117536545, "report/cont_loss_std": 0.22455929219722748, "report/cont_neg_acc": 0.1428571492433548, "report/cont_neg_loss": 2.292682647705078, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.003887016559019685, "report/cont_pred": 0.9948914647102356, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 5.968419075012207, "report/dyn_loss_std": 5.158713340759277, "report/image_loss_mean": 16.50617790222168, "report/image_loss_std": 16.559972763061523, "report/model_loss_mean": 20.182540893554688, "report/model_loss_std": 17.889265060424805, "report/post_ent_mag": 43.15977096557617, "report/post_ent_max": 43.15977096557617, "report/post_ent_mean": 30.39372444152832, "report/post_ent_min": 12.047202110290527, "report/post_ent_std": 3.610635995864868, "report/prior_ent_mag": 48.49667739868164, "report/prior_ent_max": 48.49667739868164, "report/prior_ent_mean": 36.288124084472656, "report/prior_ent_min": 18.52558708190918, "report/prior_ent_std": 3.779672145843506, "report/rep_loss_mean": 5.968419075012207, "report/rep_loss_std": 5.158713340759277, "report/reward_avg": 0.0074218749068677425, "report/reward_loss_mean": 0.0757775753736496, "report/reward_loss_std": 0.39621952176094055, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9848674535751343, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.056895725429058075, "report/reward_pos_acc": 0.7272727489471436, "report/reward_pos_loss": 1.8146247863769531, "report/reward_pred": 0.005434851627796888, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.023885423317551613, "eval/cont_loss_std": 0.3012875020503998, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.111027717590332, "eval/cont_pos_acc": 0.9960822463035583, "eval/cont_pos_loss": 0.008937893435359001, "eval/cont_pred": 0.9932306408882141, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 9.350951194763184, "eval/dyn_loss_std": 7.251603126525879, "eval/image_loss_mean": 65.80294799804688, "eval/image_loss_std": 66.33184051513672, "eval/model_loss_mean": 71.5926284790039, "eval/model_loss_std": 68.12269592285156, "eval/post_ent_mag": 46.78877258300781, "eval/post_ent_max": 46.78877258300781, "eval/post_ent_mean": 30.73769760131836, "eval/post_ent_min": 12.14409065246582, "eval/post_ent_std": 6.371804714202881, "eval/prior_ent_mag": 49.175254821777344, "eval/prior_ent_max": 49.175254821777344, "eval/prior_ent_mean": 36.4180793762207, "eval/prior_ent_min": 18.002891540527344, "eval/prior_ent_std": 6.656142234802246, "eval/rep_loss_mean": 9.350951194763184, "eval/rep_loss_std": 7.251603126525879, "eval/reward_avg": 0.009472656063735485, "eval/reward_loss_mean": 0.15522243082523346, "eval/reward_loss_std": 0.7910736799240112, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9699865579605103, "eval/reward_neg_acc": 0.9990108609199524, "eval/reward_neg_loss": 0.12389001995325089, "eval/reward_pos_acc": 0.692307710647583, "eval/reward_pos_loss": 2.5919189453125, "eval/reward_pred": 0.002839288441464305, "eval/reward_rate": 0.0126953125, "replay/size": 21633.0, "replay/inserts": 20576.0, "replay/samples": 20576.0, "replay/insert_wait_avg": 1.5190146388384639e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.078584599828646e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6632.0, "eval_replay/inserts": 3856.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.5069958579985433e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 973.3145272731781, "timer/env.step_count": 2572.0, "timer/env.step_total": 260.56491684913635, "timer/env.step_frac": 0.2677088541759782, "timer/env.step_avg": 0.1013082880439877, "timer/env.step_min": 0.02470254898071289, "timer/env.step_max": 3.5093061923980713, "timer/replay._sample_count": 20576.0, "timer/replay._sample_total": 11.778759956359863, "timer/replay._sample_frac": 0.012101699529091632, "timer/replay._sample_avg": 0.0005724513975680338, "timer/replay._sample_min": 0.00036454200744628906, "timer/replay._sample_max": 0.02860403060913086, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3054.0, "timer/agent.policy_total": 56.55613040924072, "timer/agent.policy_frac": 0.05810673613152312, "timer/agent.policy_avg": 0.018518706748277904, "timer/agent.policy_min": 0.010243654251098633, "timer/agent.policy_max": 0.11390924453735352, "timer/dataset_train_count": 1286.0, "timer/dataset_train_total": 0.16414499282836914, "timer/dataset_train_frac": 0.0001686453743665319, "timer/dataset_train_avg": 0.0001276399633191051, "timer/dataset_train_min": 9.751319885253906e-05, "timer/dataset_train_max": 0.001077890396118164, "timer/agent.train_count": 1286.0, "timer/agent.train_total": 584.6066770553589, "timer/agent.train_frac": 0.6006349033885103, "timer/agent.train_avg": 0.4545930614738405, "timer/agent.train_min": 0.43874216079711914, "timer/agent.train_max": 1.4337685108184814, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48034048080444336, "timer/agent.report_frac": 0.0004935100292298701, "timer/agent.report_avg": 0.24017024040222168, "timer/agent.report_min": 0.23229646682739258, "timer/agent.report_max": 0.24804401397705078, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.457069396972656e-05, "timer/dataset_eval_frac": 3.55185225341075e-08, "timer/dataset_eval_avg": 3.457069396972656e-05, "timer/dataset_eval_min": 3.457069396972656e-05, "timer/dataset_eval_max": 3.457069396972656e-05, "fps": 21.139875638403364}
{"step": 22144, "time": 1319.5615212917328, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 22776, "time": 1343.2231078147888, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 22904, "time": 1349.1335649490356, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 22968, "time": 1353.032752275467, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 23040, "time": 1357.3649535179138, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 23112, "time": 1361.3803236484528, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 23280, "time": 1369.0289964675903, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 23504, "time": 1378.4588255882263, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 23632, "time": 1384.561594247818, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 23712, "time": 1388.9089107513428, "episode/length": 116.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 24208, "time": 1407.5529956817627, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 24424, "time": 1416.3054485321045, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 24520, "time": 1421.43199801445, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 24560, "time": 1424.6331369876862, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 24560, "time": 1424.6431221961975, "episode/length": 189.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 24776, "time": 1436.4162306785583, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 24824, "time": 1439.6828377246857, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 25472, "time": 1463.9421441555023, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 25528, "time": 1467.3427591323853, "episode/length": 125.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 25720, "time": 1475.6184766292572, "episode/length": 260.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 25880, "time": 1482.8745255470276, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 25984, "time": 1488.2386269569397, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 26040, "time": 1491.6472346782684, "episode/length": 201.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 26384, "time": 1505.3788862228394, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 26488, "time": 1510.43417429924, "episode/length": 75.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9342105263157895, "episode/intrinsic_return": 0.0}
{"step": 26832, "time": 1524.0352957248688, "episode/length": 138.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 26872, "time": 1526.7370030879974, "episode/length": 255.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 27000, "time": 1532.7246689796448, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 27120, "time": 1538.6419923305511, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 27568, "time": 1555.6491708755493, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 27640, "time": 1559.5580670833588, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 27720, "time": 1563.9245615005493, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 27744, "time": 1566.4877996444702, "episode/length": 212.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 27952, "time": 1575.433708190918, "episode/length": 139.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 28048, "time": 1580.3378257751465, "episode/length": 37.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 28056, "time": 1582.046528339386, "episode/length": 60.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 28384, "time": 1595.1704981327057, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 28432, "time": 1598.535115480423, "episode/length": 98.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 28776, "time": 1611.894424200058, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 28816, "time": 1615.1462705135345, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 29200, "time": 1630.0418689250946, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 29448, "time": 1639.8800446987152, "episode/length": 132.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 29480, "time": 1642.597005367279, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 29504, "time": 1645.295729637146, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 29792, "time": 1656.89519906044, "episode/length": 169.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 29808, "time": 1659.309231519699, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1685.0154650211334, "eval_episode/length": 36.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 30056, "time": 1690.2319190502167, "eval_episode/length": 111.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 30056, "time": 1693.347520828247, "eval_episode/length": 134.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 30056, "time": 1697.6638026237488, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 30056, "time": 1700.1581563949585, "eval_episode/length": 190.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 30056, "time": 1701.9569115638733, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 30056, "time": 1703.9249680042267, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 30056, "time": 1706.859958410263, "eval_episode/length": 230.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 30232, "time": 1712.9024889469147, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 30296, "time": 1716.7655498981476, "episode/length": 279.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 30752, "time": 1734.2521646022797, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 30768, "time": 1736.384702205658, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 30792, "time": 1738.5506246089935, "episode/length": 246.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 31288, "time": 1757.2418084144592, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 31304, "time": 1759.8948955535889, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 31336, "time": 1763.2332723140717, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 31632, "time": 1775.2850182056427, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 31640, "time": 1777.138292312622, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 31744, "time": 1782.7295348644257, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 32088, "time": 1795.8309268951416, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 32304, "time": 1805.1503653526306, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 32640, "time": 1818.343896150589, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 32688, "time": 1821.6721727848053, "episode/length": 241.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 32704, "time": 1823.738038778305, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 32816, "time": 1830.5159327983856, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 32904, "time": 1834.894894361496, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 32920, "time": 1837.0931470394135, "episode/length": 159.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 33400, "time": 1855.2137570381165, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 34016, "time": 1878.1847896575928, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 34184, "time": 1885.337946176529, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 34208, "time": 1887.986142873764, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 34336, "time": 1894.0276319980621, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 34640, "time": 1906.3441112041473, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 34712, "time": 1910.3210453987122, "episode/length": 300.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9900332225913622, "episode/intrinsic_return": 0.0}
{"step": 34856, "time": 1916.9399602413177, "episode/length": 270.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.988929889298893, "episode/intrinsic_return": 0.0}
{"step": 34952, "time": 1921.9502880573273, "episode/length": 29.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 34984, "time": 1924.6666297912598, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 35512, "time": 1944.7005426883698, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 35784, "time": 1956.240834236145, "episode/length": 220.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 35808, "time": 1958.9957134723663, "episode/length": 183.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 36088, "time": 1970.0765092372894, "episode/length": 180.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 36216, "time": 1976.0660419464111, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 36360, "time": 1982.6166541576385, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 36544, "time": 1990.8638017177582, "episode/length": 294.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9932203389830508, "episode/intrinsic_return": 0.0}
{"step": 36648, "time": 1995.9086692333221, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 36656, "time": 1997.9802215099335, "episode/length": 105.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 36664, "time": 1999.5504467487335, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9454545454545454, "episode/intrinsic_return": 0.0}
{"step": 36744, "time": 2004.4065732955933, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 37328, "time": 2026.2390975952148, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 37536, "time": 2034.978464126587, "episode/length": 164.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 37680, "time": 2041.4831013679504, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 37888, "time": 2050.861669063568, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 37888, "time": 2050.8725712299347, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 38000, "time": 2059.215861082077, "episode/length": 156.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 38112, "time": 2065.2904329299927, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 38160, "time": 2069.1945519447327, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 38752, "time": 2091.7092065811157, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 39104, "time": 2105.1619713306427, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 39184, "time": 2109.5560126304626, "episode/length": 187.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 39240, "time": 2113.031724691391, "episode/length": 168.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 39280, "time": 2116.306562423706, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 39320, "time": 2119.137972831726, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 39320, "time": 2119.146992921829, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 39328, "time": 2122.9662466049194, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2166.267010450363, "eval_episode/length": 90.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9560439560439561}
{"step": 40040, "time": 2171.052359342575, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 40040, "time": 2173.1169233322144, "eval_episode/length": 169.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 40040, "time": 2174.767741203308, "eval_episode/length": 170.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 40040, "time": 2176.4645042419434, "eval_episode/length": 173.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 40040, "time": 2178.144130706787, "eval_episode/length": 176.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 40040, "time": 2180.4192712306976, "eval_episode/length": 191.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 40040, "time": 2182.89936542511, "eval_episode/length": 212.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9812206572769953}
{"step": 40192, "time": 2188.239002943039, "episode/length": 125.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 40352, "time": 2195.219736814499, "episode/length": 199.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 40592, "time": 2205.188352584839, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 40616, "time": 2207.4564146995544, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 40664, "time": 2210.684076309204, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 40712, "time": 2213.9331369400024, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 40840, "time": 2219.800325155258, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 41112, "time": 2231.853313446045, "episode/length": 222.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 41416, "time": 2243.6785242557526, "episode/length": 132.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 41768, "time": 2257.2979385852814, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 42040, "time": 2268.332910299301, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 42072, "time": 2271.0289421081543, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 42136, "time": 2274.8065729141235, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 42200, "time": 2278.705896615982, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 42248, "time": 2281.985737323761, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 42440, "time": 2290.3014097213745, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 42744, "time": 2302.241810798645, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 43177, "time": 2319.682490825653, "train_stats/sum_log_reward": 2.352100758993325, "train_stats/max_log_achievement_collect_drink": 8.798319327731093, "train_stats/max_log_achievement_collect_sapling": 2.2941176470588234, "train_stats/max_log_achievement_collect_wood": 0.23529411764705882, "train_stats/max_log_achievement_defeat_zombie": 0.1092436974789916, "train_stats/max_log_achievement_eat_cow": 0.03361344537815126, "train_stats/max_log_achievement_place_plant": 2.0504201680672267, "train_stats/max_log_achievement_place_table": 0.008403361344537815, "train_stats/max_log_achievement_wake_up": 1.73109243697479, "train_stats/mean_log_entropy": 0.46431794994268094, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.088500051787405, "train/action_min": 0.0, "train/action_std": 3.0474457785938727, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039302217378986606, "train/actor_opt_grad_steps": 1945.0, "train/actor_opt_loss": 30.712644864701637, "train/adv_mag": 1.7839975117733984, "train/adv_max": 1.7822062653122526, "train/adv_mean": 0.01691939494974742, "train/adv_min": -0.5536725981668993, "train/adv_std": 0.13764533081628155, "train/cont_avg": 0.9942737926136364, "train/cont_loss_mean": 0.00305475212199767, "train/cont_loss_std": 0.05292429059139095, "train/cont_neg_acc": 0.8471350470049814, "train/cont_neg_loss": 0.41134163782722183, "train/cont_pos_acc": 0.9998511884248618, "train/cont_pos_loss": 0.0007688319209011518, "train/cont_pred": 0.9945878422621525, "train/cont_rate": 0.9942737926136364, "train/dyn_loss_mean": 6.573014588067026, "train/dyn_loss_std": 5.9039632696093935, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.376428213534933, "train/extr_critic_critic_opt_grad_steps": 1945.0, "train/extr_critic_critic_opt_loss": 16517.774044152462, "train/extr_critic_mag": 1.545015890489925, "train/extr_critic_max": 1.545015890489925, "train/extr_critic_mean": 0.4025533166572903, "train/extr_critic_min": -0.2785400721159848, "train/extr_critic_std": 0.6099336169885866, "train/extr_return_normed_mag": 2.610969358321392, "train/extr_return_normed_max": 2.610969358321392, "train/extr_return_normed_mean": 0.379310787965854, "train/extr_return_normed_min": -0.20483389469992483, "train/extr_return_normed_std": 0.3789646584879268, "train/extr_return_rate": 0.33633356834902906, "train/extr_return_raw_mag": 4.603696255972891, "train/extr_return_raw_max": 4.603696255972891, "train/extr_return_raw_mean": 0.43380401926961815, "train/extr_return_raw_min": -0.6540390047611613, "train/extr_return_raw_std": 0.7084622017361901, "train/extr_reward_mag": 0.995491090145978, "train/extr_reward_max": 0.995491090145978, "train/extr_reward_mean": 0.01236625503268883, "train/extr_reward_min": -0.26031033378658874, "train/extr_reward_std": 0.0845056094342109, "train/image_loss_mean": 19.457140344561953, "train/image_loss_std": 20.123396053458706, "train/model_loss_mean": 23.481669303142663, "train/model_loss_std": 21.83133008263328, "train/model_opt_grad_norm": 169.69428810928807, "train/model_opt_grad_steps": 1936.0, "train/model_opt_loss": 1357.7544102524266, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.52225378787879, "train/policy_entropy_mag": 2.1410119569662847, "train/policy_entropy_max": 2.1410119569662847, "train/policy_entropy_mean": 0.54077087207274, "train/policy_entropy_min": 0.08003039217808029, "train/policy_entropy_std": 0.4260037974877791, "train/policy_logprob_mag": 7.436806707671194, "train/policy_logprob_max": -0.009547395547005262, "train/policy_logprob_mean": -0.5402087034149603, "train/policy_logprob_min": -7.436806707671194, "train/policy_logprob_std": 1.0995270677588203, "train/policy_randomness_mag": 0.7556832644975546, "train/policy_randomness_max": 0.7556832644975546, "train/policy_randomness_mean": 0.19086838603922815, "train/policy_randomness_min": 0.028247216377745975, "train/policy_randomness_std": 0.15036064544410416, "train/post_ent_mag": 43.76716868082682, "train/post_ent_max": 43.76716868082682, "train/post_ent_mean": 30.164068149797846, "train/post_ent_min": 12.026208234555794, "train/post_ent_std": 4.906555378075802, "train/prior_ent_mag": 52.66459410118334, "train/prior_ent_max": 52.66459410118334, "train/prior_ent_mean": 36.86394026785186, "train/prior_ent_min": 15.226284489487156, "train/prior_ent_std": 5.835482248754213, "train/rep_loss_mean": 6.573014588067026, "train/rep_loss_std": 5.9039632696093935, "train/reward_avg": 0.009886215620843524, "train/reward_loss_mean": 0.07766555970760458, "train/reward_loss_std": 0.38272565450857987, "train/reward_max_data": 1.000757575938196, "train/reward_max_pred": 0.9952757602388208, "train/reward_neg_acc": 0.9961066480838892, "train/reward_neg_loss": 0.05802288948501827, "train/reward_pos_acc": 0.8609684037439751, "train/reward_pos_loss": 1.3973960149468798, "train/reward_pred": 0.008884716301867174, "train/reward_rate": 0.014885179924242424, "eval_stats/sum_log_reward": 2.4749999418854713, "eval_stats/max_log_achievement_collect_drink": 14.375, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.07692307692307693, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0005640409654006362, "report/cont_loss_std": 0.016621079295873642, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00023515193606726825, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0005663046031259, "report/cont_pred": 0.9927199482917786, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 6.663905620574951, "report/dyn_loss_std": 6.393710136413574, "report/image_loss_mean": 14.897714614868164, "report/image_loss_std": 12.671762466430664, "report/model_loss_mean": 18.934513092041016, "report/model_loss_std": 15.033432006835938, "report/post_ent_mag": 41.68042755126953, "report/post_ent_max": 41.68042755126953, "report/post_ent_mean": 29.149457931518555, "report/post_ent_min": 11.894306182861328, "report/post_ent_std": 5.08135986328125, "report/prior_ent_mag": 56.37220001220703, "report/prior_ent_max": 56.37220001220703, "report/prior_ent_mean": 36.289222717285156, "report/prior_ent_min": 14.158052444458008, "report/prior_ent_std": 6.889626502990723, "report/rep_loss_mean": 6.663905620574951, "report/rep_loss_std": 6.393710136413574, "report/reward_avg": 0.011914062313735485, "report/reward_loss_mean": 0.03789091482758522, "report/reward_loss_std": 0.19002868235111237, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9988936185836792, "report/reward_neg_acc": 0.9930486679077148, "report/reward_neg_loss": 0.023857921361923218, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8691393733024597, "report/reward_pred": 0.01197718270123005, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0058379038237035275, "eval/cont_loss_std": 0.0902777835726738, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.05207085236907005, "eval/cont_pos_acc": 0.996078372001648, "eval/cont_pos_loss": 0.005656598135828972, "eval/cont_pred": 0.9931923747062683, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 11.730196952819824, "eval/dyn_loss_std": 8.382431030273438, "eval/image_loss_mean": 57.392581939697266, "eval/image_loss_std": 56.72550582885742, "eval/model_loss_mean": 64.61393737792969, "eval/model_loss_std": 59.47389602661133, "eval/post_ent_mag": 45.17595672607422, "eval/post_ent_max": 45.17595672607422, "eval/post_ent_mean": 30.02999496459961, "eval/post_ent_min": 12.047954559326172, "eval/post_ent_std": 6.199508190155029, "eval/prior_ent_mag": 54.661277770996094, "eval/prior_ent_max": 54.661277770996094, "eval/prior_ent_mean": 38.60950469970703, "eval/prior_ent_min": 15.48392391204834, "eval/prior_ent_std": 7.484481334686279, "eval/rep_loss_mean": 11.730196952819824, "eval/rep_loss_std": 8.382431030273438, "eval/reward_avg": 0.01582031324505806, "eval/reward_loss_mean": 0.1773945689201355, "eval/reward_loss_std": 1.0119867324829102, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9991745948791504, "eval/reward_neg_acc": 0.9970149993896484, "eval/reward_neg_loss": 0.0937880203127861, "eval/reward_pos_acc": 0.42105263471603394, "eval/reward_pos_loss": 4.599740505218506, "eval/reward_pred": 0.003801260609179735, "eval/reward_rate": 0.0185546875, "replay/size": 42673.0, "replay/inserts": 21040.0, "replay/samples": 21040.0, "replay/insert_wait_avg": 1.48781578803697e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.999848093823335e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10184.0, "eval_replay/inserts": 3552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2800902933687777e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0855491161346, "timer/env.step_count": 2630.0, "timer/env.step_total": 276.2633271217346, "timer/env.step_frac": 0.2762396950599809, "timer/env.step_avg": 0.10504309016035537, "timer/env.step_min": 0.024843931198120117, "timer/env.step_max": 4.4305641651153564, "timer/replay._sample_count": 21040.0, "timer/replay._sample_total": 12.104145526885986, "timer/replay._sample_frac": 0.012103110116513039, "timer/replay._sample_avg": 0.0005752920877797523, "timer/replay._sample_min": 0.00040340423583984375, "timer/replay._sample_max": 0.028009653091430664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3074.0, "timer/agent.policy_total": 56.24847865104675, "timer/agent.policy_frac": 0.056243667055042024, "timer/agent.policy_avg": 0.018298138793443965, "timer/agent.policy_min": 0.009924173355102539, "timer/agent.policy_max": 0.1382613182067871, "timer/dataset_train_count": 1315.0, "timer/dataset_train_total": 0.17024540901184082, "timer/dataset_train_frac": 0.00017023084591343408, "timer/dataset_train_avg": 0.0001294641893626166, "timer/dataset_train_min": 0.00011157989501953125, "timer/dataset_train_max": 0.0010924339294433594, "timer/agent.train_count": 1315.0, "timer/agent.train_total": 597.5810022354126, "timer/agent.train_frac": 0.5975298840819654, "timer/agent.train_avg": 0.45443422223225294, "timer/agent.train_min": 0.43901777267456055, "timer/agent.train_max": 1.3832998275756836, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.49580883979797363, "timer/agent.report_frac": 0.0004957664274182988, "timer/agent.report_avg": 0.24790441989898682, "timer/agent.report_min": 0.22917866706848145, "timer/agent.report_max": 0.2666301727294922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.7190116758226137e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 21.037351843165865}
{"step": 43512, "time": 2331.0535361766815, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 43600, "time": 2335.8776047229767, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 43664, "time": 2339.661685705185, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 43696, "time": 2342.480591058731, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 43712, "time": 2344.590751171112, "episode/length": 242.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 43752, "time": 2347.2456862926483, "episode/length": 209.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 43984, "time": 2357.1332726478577, "episode/length": 242.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 44072, "time": 2361.5573308467865, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 44512, "time": 2378.1893787384033, "episode/length": 113.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 44840, "time": 2390.973178625107, "episode/length": 40.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 45056, "time": 2400.0987977981567, "episode/length": 122.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 45072, "time": 2402.2287497520447, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 45144, "time": 2406.023201227188, "episode/length": 203.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 45152, "time": 2408.045921087265, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 45240, "time": 2412.668301820755, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 45424, "time": 2420.704996585846, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 45512, "time": 2425.0911750793457, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 45960, "time": 2442.1984963417053, "episode/length": 112.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9646017699115044, "episode/intrinsic_return": 0.0}
{"step": 46320, "time": 2456.354341506958, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 46496, "time": 2464.102936267853, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 46584, "time": 2468.575681447983, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 46992, "time": 2484.491030693054, "episode/length": 230.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 47144, "time": 2491.0798614025116, "episode/length": 214.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 47248, "time": 2496.5621576309204, "episode/length": 216.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 47312, "time": 2500.518536090851, "episode/length": 39.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 47512, "time": 2508.7576882839203, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 47800, "time": 2520.187186717987, "episode/length": 162.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 47864, "time": 2523.9402990341187, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 48104, "time": 2533.7916553020477, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 48296, "time": 2541.9339339733124, "episode/length": 392.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 48440, "time": 2548.433413505554, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 48536, "time": 2553.4148399829865, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 48712, "time": 2561.1646983623505, "episode/length": 149.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 48768, "time": 2564.927144050598, "episode/length": 58.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 49032, "time": 2575.282893896103, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 49328, "time": 2588.5595796108246, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 49616, "time": 2600.282970428467, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 49784, "time": 2607.454978942871, "episode/length": 316.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 49824, "time": 2610.602308988571, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2618.8241777420044, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2634.6545877456665, "eval_episode/length": 46.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 50024, "time": 2638.248257637024, "eval_episode/length": 90.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.989010989010989}
{"step": 50024, "time": 2642.3147978782654, "eval_episode/length": 144.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 50024, "time": 2646.350284576416, "eval_episode/length": 196.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 50024, "time": 2648.0858051776886, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 50024, "time": 2650.527514696121, "eval_episode/length": 212.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 50024, "time": 2652.328539609909, "eval_episode/length": 216.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 50024, "time": 2654.9463217258453, "eval_episode/length": 240.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.995850622406639}
{"step": 50032, "time": 2657.085451602936, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 50104, "time": 2660.821521759033, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 50352, "time": 2671.1407990455627, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 50456, "time": 2676.065806388855, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 51192, "time": 2702.8129875659943, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 51488, "time": 2714.7404911518097, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 51528, "time": 2717.400498151779, "episode/length": 41.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 51568, "time": 2720.5371475219727, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 51728, "time": 2727.548014163971, "episode/length": 237.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 51784, "time": 2730.7619104385376, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 51800, "time": 2732.9011664390564, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 51832, "time": 2735.653675556183, "episode/length": 276.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 52104, "time": 2746.6189029216766, "episode/length": 249.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 52864, "time": 2774.9234290122986, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 53056, "time": 2783.22346162796, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 53064, "time": 2784.8832561969757, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 53176, "time": 2790.38641500473, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 53232, "time": 2794.2006466388702, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 53272, "time": 2796.9163587093353, "episode/length": 222.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 53520, "time": 2807.370458841324, "episode/length": 42.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 53728, "time": 2816.0657091140747, "episode/length": 236.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 54096, "time": 2830.3883657455444, "episode/length": 315.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 54248, "time": 2837.245585203171, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 54448, "time": 2845.975963830948, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 54480, "time": 2848.6186470985413, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 54552, "time": 2852.506794691086, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 54616, "time": 2856.292542695999, "episode/length": 218.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9908675799086758, "episode/intrinsic_return": 0.0}
{"step": 55032, "time": 2872.3431901931763, "episode/length": 116.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9572649572649573, "episode/intrinsic_return": 0.0}
{"step": 55112, "time": 2876.7273416519165, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 55224, "time": 2882.2980768680573, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 55392, "time": 2890.047568798065, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 55928, "time": 2909.619875192642, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 55944, "time": 2911.7256643772125, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 56072, "time": 2917.6924526691437, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 56576, "time": 2936.883619070053, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 56624, "time": 2940.1785917282104, "episode/length": 84.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 57104, "time": 2958.2823984622955, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9914893617021276, "episode/intrinsic_return": 0.0}
{"step": 57112, "time": 2959.9949555397034, "episode/length": 319.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 57184, "time": 2964.2195916175842, "episode/length": 156.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 57200, "time": 2966.4953553676605, "episode/length": 260.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 57360, "time": 2975.077568054199, "episode/length": 245.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 57712, "time": 2988.7857434749603, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 57832, "time": 2994.2946026325226, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 58656, "time": 3024.4455258846283, "episode/length": 161.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 58672, "time": 3026.5549745559692, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 58728, "time": 3029.8497273921967, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 58872, "time": 3036.429441690445, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 58912, "time": 3039.937146425247, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 59160, "time": 3049.742195367813, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 59216, "time": 3053.494970560074, "episode/length": 323.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 59328, "time": 3058.9692330360413, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 59960, "time": 3081.7706916332245, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3100.852323293686, "eval_episode/length": 48.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 60008, "time": 3102.8220508098602, "eval_episode/length": 56.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 60008, "time": 3110.1920948028564, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 60008, "time": 3112.11354470253, "eval_episode/length": 186.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 60008, "time": 3113.977372407913, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 60008, "time": 3116.5912716388702, "eval_episode/length": 215.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 60008, "time": 3118.4726178646088, "eval_episode/length": 221.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 60008, "time": 3120.06418299675, "eval_episode/length": 222.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9596412556053812}
{"step": 60224, "time": 3127.569642305374, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 60304, "time": 3132.0434789657593, "episode/length": 173.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 60320, "time": 3134.1676206588745, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 60344, "time": 3136.436126947403, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 60720, "time": 3151.1775155067444, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 60792, "time": 3154.9796249866486, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 60792, "time": 3154.989925146103, "episode/length": 58.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 60856, "time": 3160.7735691070557, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 61096, "time": 3170.4982013702393, "episode/length": 29.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 61152, "time": 3174.3272738456726, "episode/length": 148.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 61232, "time": 3178.712639093399, "episode/length": 54.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 61392, "time": 3185.6461913585663, "episode/length": 130.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 61688, "time": 3197.3677463531494, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 61792, "time": 3202.836611032486, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 62200, "time": 3218.1641716957092, "episode/length": 130.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 62208, "time": 3220.437653064728, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 62480, "time": 3231.366920232773, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 62624, "time": 3237.9244334697723, "episode/length": 173.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 62664, "time": 3240.6208040714264, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 62920, "time": 3251.1106038093567, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 63104, "time": 3259.212098836899, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 63216, "time": 3264.6198966503143, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 63456, "time": 3274.4334921836853, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 63600, "time": 3281.0778861045837, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 63712, "time": 3286.4369065761566, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 63912, "time": 3294.5627715587616, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 64072, "time": 3301.5640914440155, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 64521, "time": 3319.779412984848, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.214214583088581, "train/action_min": 0.0, "train/action_std": 3.30408349431547, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05228242584805291, "train/actor_opt_grad_steps": 3270.0, "train/actor_opt_loss": 29.208161785526382, "train/adv_mag": 1.5549896256367963, "train/adv_max": 1.553533705105459, "train/adv_mean": 0.008924321443640323, "train/adv_min": -0.6025272520413076, "train/adv_std": 0.11387676070619346, "train/cont_avg": 0.9942213933270677, "train/cont_loss_mean": 0.0008251095641933142, "train/cont_loss_std": 0.022014507873921372, "train/cont_neg_acc": 0.9756176211780175, "train/cont_neg_loss": 0.07321271363572923, "train/cont_pos_acc": 0.9998891142974222, "train/cont_pos_loss": 0.0003903508170560941, "train/cont_pred": 0.9942193645283692, "train/cont_rate": 0.9942213933270677, "train/dyn_loss_mean": 7.664147972164297, "train/dyn_loss_std": 6.77936641793502, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.251458810236221, "train/extr_critic_critic_opt_grad_steps": 3270.0, "train/extr_critic_critic_opt_loss": 14770.458139978853, "train/extr_critic_mag": 2.025229149294975, "train/extr_critic_max": 2.025229149294975, "train/extr_critic_mean": 0.4636694595105666, "train/extr_critic_min": -0.18324264189354458, "train/extr_critic_std": 0.5992684561507147, "train/extr_return_normed_mag": 2.4400555065699985, "train/extr_return_normed_max": 2.4400555065699985, "train/extr_return_normed_mean": 0.34508186220226433, "train/extr_return_normed_min": -0.23100751554383372, "train/extr_return_normed_std": 0.3644492795368783, "train/extr_return_rate": 0.3192111305276254, "train/extr_return_raw_mag": 4.191118367632529, "train/extr_return_raw_max": 4.191118367632529, "train/extr_return_raw_mean": 0.479500011057782, "train/extr_return_raw_min": -0.5414901579681196, "train/extr_return_raw_std": 0.6466140363897596, "train/extr_reward_mag": 0.9999909768427225, "train/extr_reward_max": 0.9999909768427225, "train/extr_reward_mean": 0.010498582810877745, "train/extr_reward_min": -0.34125205717588725, "train/extr_reward_std": 0.08272868652540938, "train/image_loss_mean": 20.85060815882862, "train/image_loss_std": 24.357495071296405, "train/model_loss_mean": 25.50816968329867, "train/model_loss_std": 26.779352582486947, "train/model_opt_grad_norm": 138.5148168004545, "train/model_opt_grad_steps": 3261.0, "train/model_opt_loss": 3405.960549261337, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 132.16635338345864, "train/policy_entropy_mag": 2.361886133824972, "train/policy_entropy_max": 2.361886133824972, "train/policy_entropy_mean": 0.7623170869691032, "train/policy_entropy_min": 0.0795983150041193, "train/policy_entropy_std": 0.49122163832635807, "train/policy_logprob_mag": 7.436820410248032, "train/policy_logprob_max": -0.009486700219095201, "train/policy_logprob_mean": -0.7624355373077822, "train/policy_logprob_min": -7.436820410248032, "train/policy_logprob_std": 1.1932161150122047, "train/policy_randomness_mag": 0.8336421582931862, "train/policy_randomness_max": 0.8336421582931862, "train/policy_randomness_mean": 0.26906447751181467, "train/policy_randomness_min": 0.02809471219666022, "train/policy_randomness_std": 0.173379682732704, "train/post_ent_mag": 46.06524173478435, "train/post_ent_max": 46.06524173478435, "train/post_ent_mean": 31.755007378140785, "train/post_ent_min": 13.19411139380663, "train/post_ent_std": 5.32645791276057, "train/prior_ent_mag": 58.694331348390506, "train/prior_ent_max": 58.694331348390506, "train/prior_ent_mean": 39.62112051024473, "train/prior_ent_min": 15.372279934417037, "train/prior_ent_std": 7.113137112524276, "train/rep_loss_mean": 7.664147972164297, "train/rep_loss_std": 6.77936641793502, "train/reward_avg": 0.011251762169728377, "train/reward_loss_mean": 0.0582477759037699, "train/reward_loss_std": 0.3078758778204595, "train/reward_max_data": 1.0045112792710613, "train/reward_max_pred": 0.9990058958082271, "train/reward_neg_acc": 0.9946135529001853, "train/reward_neg_loss": 0.04000073648232939, "train/reward_pos_acc": 0.912740637485246, "train/reward_pos_loss": 1.1514845638346851, "train/reward_pred": 0.010283807851024028, "train/reward_rate": 0.01652079417293233, "train_stats/sum_log_reward": 3.108403315376334, "train_stats/max_log_achievement_collect_drink": 19.092436974789916, "train_stats/max_log_achievement_collect_sapling": 1.7226890756302522, "train_stats/max_log_achievement_collect_wood": 1.453781512605042, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.14285714285714285, "train_stats/max_log_achievement_eat_cow": 0.04201680672268908, "train_stats/max_log_achievement_place_plant": 1.4621848739495797, "train_stats/max_log_achievement_place_table": 0.21008403361344538, "train_stats/max_log_achievement_wake_up": 1.6554621848739495, "train_stats/mean_log_entropy": 0.8057602656488659, "eval_stats/sum_log_reward": 3.5999999782070518, "eval_stats/max_log_achievement_collect_drink": 13.9375, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_wood": 2.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_table": 0.375, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.07142857142857142, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 7.528746937168762e-05, "report/cont_loss_std": 0.0021807579323649406, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00026813274598680437, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.396010187221691e-05, "report/cont_pred": 0.993094801902771, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 9.488731384277344, "report/dyn_loss_std": 7.8227715492248535, "report/image_loss_mean": 26.83106231689453, "report/image_loss_std": 30.514253616333008, "report/model_loss_mean": 32.59324645996094, "report/model_loss_std": 33.64913558959961, "report/post_ent_mag": 48.06033706665039, "report/post_ent_max": 48.06033706665039, "report/post_ent_mean": 33.44208908081055, "report/post_ent_min": 13.500286102294922, "report/post_ent_std": 6.147158622741699, "report/prior_ent_mag": 59.99864196777344, "report/prior_ent_max": 59.99864196777344, "report/prior_ent_mean": 43.6824951171875, "report/prior_ent_min": 15.97640323638916, "report/prior_ent_std": 8.422539710998535, "report/rep_loss_mean": 9.488731384277344, "report/rep_loss_std": 7.8227715492248535, "report/reward_avg": 0.01455078087747097, "report/reward_loss_mean": 0.0688728615641594, "report/reward_loss_std": 0.3711228668689728, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0033369064331055, "report/reward_neg_acc": 0.9990040063858032, "report/reward_neg_loss": 0.04358604550361633, "report/reward_pos_acc": 0.8500000238418579, "report/reward_pos_loss": 1.3382710218429565, "report/reward_pred": 0.010484030470252037, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0060116443783044815, "eval/cont_loss_std": 0.18264126777648926, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.057174503803253174, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0058110058307647705, "eval/cont_pred": 0.9952408671379089, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.317594528198242, "eval/dyn_loss_std": 8.110864639282227, "eval/image_loss_mean": 37.489009857177734, "eval/image_loss_std": 37.212005615234375, "eval/model_loss_mean": 45.63518524169922, "eval/model_loss_std": 40.24817657470703, "eval/post_ent_mag": 46.61027145385742, "eval/post_ent_max": 46.61027145385742, "eval/post_ent_mean": 31.634315490722656, "eval/post_ent_min": 14.088027954101562, "eval/post_ent_std": 5.724524974822998, "eval/prior_ent_mag": 60.432106018066406, "eval/prior_ent_max": 60.432106018066406, "eval/prior_ent_mean": 42.34248733520508, "eval/prior_ent_min": 15.528916358947754, "eval/prior_ent_std": 7.8829874992370605, "eval/rep_loss_mean": 13.317594528198242, "eval/rep_loss_std": 8.110864639282227, "eval/reward_avg": 0.00888671912252903, "eval/reward_loss_mean": 0.14961004257202148, "eval/reward_loss_std": 0.8921812772750854, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004112720489502, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.09519194066524506, "eval/reward_pos_acc": 0.38461539149284363, "eval/reward_pos_loss": 4.381664276123047, "eval/reward_pred": 0.0003773779608309269, "eval/reward_rate": 0.0126953125, "replay/size": 64017.0, "replay/inserts": 21344.0, "replay/samples": 21344.0, "replay/insert_wait_avg": 1.4269258128828195e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.670375801097865e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13896.0, "eval_replay/inserts": 3712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2398793779570482e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1067409515381, "timer/env.step_count": 2668.0, "timer/env.step_total": 271.1165008544922, "timer/env.step_frac": 0.27108756470988493, "timer/env.step_avg": 0.10161787888099408, "timer/env.step_min": 0.024667024612426758, "timer/env.step_max": 3.498535633087158, "timer/replay._sample_count": 21344.0, "timer/replay._sample_total": 12.032803058624268, "timer/replay._sample_frac": 0.012031518802858802, "timer/replay._sample_avg": 0.0005637557654902674, "timer/replay._sample_min": 0.0003771781921386719, "timer/replay._sample_max": 0.024858474731445312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3132.0, "timer/agent.policy_total": 55.72112059593201, "timer/agent.policy_frac": 0.05571517350529694, "timer/agent.policy_avg": 0.017790906959109835, "timer/agent.policy_min": 0.009986162185668945, "timer/agent.policy_max": 0.10855555534362793, "timer/dataset_train_count": 1334.0, "timer/dataset_train_total": 0.17093396186828613, "timer/dataset_train_frac": 0.0001709157181618967, "timer/dataset_train_avg": 0.0001281364031996148, "timer/dataset_train_min": 0.00011134147644042969, "timer/dataset_train_max": 0.0009057521820068359, "timer/agent.train_count": 1334.0, "timer/agent.train_total": 604.435028553009, "timer/agent.train_frac": 0.6043705174688928, "timer/agent.train_avg": 0.45309972155397976, "timer/agent.train_min": 0.4375572204589844, "timer/agent.train_max": 1.5007824897766113, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48501038551330566, "timer/agent.report_frac": 0.00048495862056868955, "timer/agent.report_avg": 0.24250519275665283, "timer/agent.report_min": 0.23424386978149414, "timer/agent.report_max": 0.2507665157318115, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.337503859084194e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 21.34145202854651}
{"step": 64592, "time": 3322.3328568935394, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 64800, "time": 3331.1517827510834, "episode/length": 135.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 64808, "time": 3332.8517050743103, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 64816, "time": 3334.9883694648743, "episode/length": 273.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 65192, "time": 3349.2799088954926, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 65224, "time": 3351.9446427822113, "episode/length": 220.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 65480, "time": 3362.135340690613, "episode/length": 175.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 65528, "time": 3365.38440489769, "episode/length": 201.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 65816, "time": 3378.3114833831787, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 66072, "time": 3388.6545417308807, "episode/length": 156.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 66160, "time": 3393.4959392547607, "episode/length": 168.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 66472, "time": 3406.385318517685, "episode/length": 208.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 66728, "time": 3416.8250715732574, "episode/length": 266.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 67136, "time": 3432.7469975948334, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 67272, "time": 3438.8016905784607, "episode/length": 255.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 67304, "time": 3441.440506219864, "episode/length": 263.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 67408, "time": 3446.8104615211487, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 67432, "time": 3448.9888496398926, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 67496, "time": 3452.751499891281, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 67912, "time": 3468.676954984665, "episode/length": 51.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 67936, "time": 3471.2132833004, "episode/length": 182.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 68376, "time": 3487.496617078781, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 68608, "time": 3497.47292637825, "episode/length": 86.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 68752, "time": 3503.949241399765, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 68888, "time": 3509.9547283649445, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 68888, "time": 3509.968836545944, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 68912, "time": 3514.321758031845, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 69376, "time": 3531.7659599781036, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 69712, "time": 3545.114736557007, "episode/length": 221.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 70000, "time": 3556.6374864578247, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 70040, "time": 3559.3273820877075, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3563.1592564582825, "episode/length": 150.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3583.979581594467, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 70096, "time": 3585.889967441559, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 70096, "time": 3588.1994037628174, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9945652173913043}
{"step": 70096, "time": 3589.98912191391, "eval_episode/length": 185.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 70096, "time": 3591.6707277297974, "eval_episode/length": 187.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 70096, "time": 3593.5984337329865, "eval_episode/length": 195.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 70096, "time": 3595.353568792343, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 70096, "time": 3604.8757519721985, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9570552147239264}
{"step": 70136, "time": 3607.731687307358, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 70312, "time": 3615.585424423218, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 70448, "time": 3622.127077102661, "episode/length": 191.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 70768, "time": 3634.5775542259216, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 71168, "time": 3650.075343132019, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 71280, "time": 3655.549373149872, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 71424, "time": 3662.1347608566284, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 71512, "time": 3666.6250751018524, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 71616, "time": 3672.0235064029694, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 71864, "time": 3683.6054985523224, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 71904, "time": 3687.312639951706, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 71960, "time": 3690.855907678604, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 72416, "time": 3708.2765963077545, "episode/length": 123.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 72464, "time": 3711.645019054413, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9888475836431226, "episode/intrinsic_return": 0.0}
{"step": 72960, "time": 3730.418468952179, "episode/length": 209.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 72984, "time": 3732.6689579486847, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 73016, "time": 3735.30420422554, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 73136, "time": 3741.240074634552, "episode/length": 89.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 73200, "time": 3745.2270019054413, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 73400, "time": 3753.5098130702972, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 73536, "time": 3760.1941771507263, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 73976, "time": 3778.079126596451, "episode/length": 54.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 74024, "time": 3781.317803621292, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 74240, "time": 3790.6236350536346, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.0}
{"step": 74448, "time": 3799.2799973487854, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 74560, "time": 3804.732569217682, "episode/length": 196.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 74632, "time": 3808.4817349910736, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 74744, "time": 3814.013237476349, "episode/length": 200.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 74768, "time": 3816.595582962036, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 75296, "time": 3836.3272354602814, "episode/length": 164.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 75368, "time": 3840.2970151901245, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 75392, "time": 3842.8996562957764, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 75640, "time": 3852.8143339157104, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 75840, "time": 3861.410577774048, "episode/length": 133.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 76072, "time": 3870.754553794861, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 76088, "time": 3873.3591260910034, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 76424, "time": 3887.103048324585, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 76648, "time": 3896.4616351127625, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 76864, "time": 3905.839917898178, "episode/length": 152.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 77336, "time": 3923.34729719162, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 77360, "time": 3926.008256673813, "episode/length": 61.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 77408, "time": 3929.167585134506, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 77416, "time": 3930.9425354003906, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 77464, "time": 3934.1441535949707, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 77720, "time": 3944.5008549690247, "episode/length": 37.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 77728, "time": 3946.6413204669952, "episode/length": 303.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 77904, "time": 3954.2407784461975, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 77992, "time": 3958.5857348442078, "episode/length": 195.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 78472, "time": 3976.406619310379, "episode/length": 141.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 78544, "time": 3980.9850487709045, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 78600, "time": 3984.3172574043274, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 78840, "time": 3994.0988023281097, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 79000, "time": 4001.37007522583, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 79056, "time": 4005.1257030963898, "episode/length": 198.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 79280, "time": 4014.2703742980957, "episode/length": 171.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 79744, "time": 4031.838791370392, "episode/length": 218.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4060.7946944236755, "eval_episode/length": 50.0, "eval_episode/score": 1.0999999791383743, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 80080, "time": 4066.9412593841553, "eval_episode/length": 152.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 80080, "time": 4068.974374771118, "eval_episode/length": 161.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 80080, "time": 4071.405713558197, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 80080, "time": 4073.7984294891357, "eval_episode/length": 195.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 80080, "time": 4076.1143980026245, "eval_episode/length": 49.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9}
{"step": 80080, "time": 4078.41459608078, "eval_episode/length": 225.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 80080, "time": 4082.200124025345, "eval_episode/length": 267.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9813432835820896}
{"step": 80272, "time": 4088.8603279590607, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 80344, "time": 4092.9701046943665, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 80392, "time": 4096.137145519257, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 80416, "time": 4098.872606039047, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 80624, "time": 4107.600357294083, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 80792, "time": 4114.636090517044, "episode/length": 188.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 81256, "time": 4131.914973497391, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 81552, "time": 4144.276748180389, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 81784, "time": 4153.792603492737, "episode/length": 179.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 81856, "time": 4158.06090259552, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 81984, "time": 4165.465896368027, "episode/length": 429.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 82024, "time": 4168.189630031586, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 82152, "time": 4174.129911899567, "episode/length": 190.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 82224, "time": 4178.519797801971, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 82360, "time": 4184.636812925339, "episode/length": 41.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 82664, "time": 4196.500188827515, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 82688, "time": 4199.189204454422, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 82872, "time": 4206.876128435135, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 83192, "time": 4219.445175409317, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 83304, "time": 4224.776615142822, "episode/length": 189.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 83520, "time": 4234.000854969025, "episode/length": 161.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 83656, "time": 4240.077951431274, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 83664, "time": 4242.192791700363, "episode/length": 225.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 84040, "time": 4256.340349674225, "episode/length": 168.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 84200, "time": 4263.4913012981415, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 84696, "time": 4282.0481169223785, "episode/length": 253.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 84752, "time": 4285.824038743973, "episode/length": 180.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 84816, "time": 4289.717579841614, "episode/length": 143.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 84968, "time": 4296.18305683136, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 84992, "time": 4298.774940729141, "episode/length": 224.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 85232, "time": 4308.700593709946, "episode/length": 148.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 85272, "time": 4311.402588129044, "episode/length": 34.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 85344, "time": 4315.689173221588, "episode/length": 80.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 85401, "time": 4319.934318065643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.148681174707777, "train/action_min": 0.0, "train/action_std": 3.3713141397665476, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05689574647268266, "train/actor_opt_grad_steps": 4590.0, "train/actor_opt_loss": 21.929953640369515, "train/adv_mag": 1.3536484114086356, "train/adv_max": 1.3536484114086356, "train/adv_mean": 0.00860066266569579, "train/adv_min": -0.5580802946600295, "train/adv_std": 0.10541808517038367, "train/cont_avg": 0.9947220896946565, "train/cont_loss_mean": 0.0006969037573825047, "train/cont_loss_std": 0.019298106432995524, "train/cont_neg_acc": 0.971428575861545, "train/cont_neg_loss": 0.09989829070951438, "train/cont_pos_acc": 0.999932495692304, "train/cont_pos_loss": 0.0002503193620799471, "train/cont_pred": 0.9947214890982359, "train/cont_rate": 0.9947220896946565, "train/dyn_loss_mean": 9.796405868675873, "train/dyn_loss_std": 7.768745116605103, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1968476476560113, "train/extr_critic_critic_opt_grad_steps": 4590.0, "train/extr_critic_critic_opt_loss": 14435.048515028626, "train/extr_critic_mag": 2.30312184887078, "train/extr_critic_max": 2.30312184887078, "train/extr_critic_mean": 0.5733822381678428, "train/extr_critic_min": -0.17296624183654785, "train/extr_critic_std": 0.6214306654820916, "train/extr_return_normed_mag": 2.3765272466280987, "train/extr_return_normed_max": 2.3765272466280987, "train/extr_return_normed_mean": 0.37148073622743594, "train/extr_return_normed_min": -0.2543889198253173, "train/extr_return_normed_std": 0.3677915812448691, "train/extr_return_rate": 0.37653220461980075, "train/extr_return_raw_mag": 4.218057692505931, "train/extr_return_raw_max": 4.218057692505931, "train/extr_return_raw_mean": 0.5890196734712324, "train/extr_return_raw_min": -0.5466333035066837, "train/extr_return_raw_std": 0.6672592320060002, "train/extr_reward_mag": 1.0013717058050724, "train/extr_reward_max": 1.0013717058050724, "train/extr_reward_mean": 0.01147002772293018, "train/extr_reward_min": -0.3490469319219808, "train/extr_reward_std": 0.0884394075522441, "train/image_loss_mean": 20.74318633188728, "train/image_loss_std": 22.507662452814234, "train/model_loss_mean": 26.676777308223812, "train/model_loss_std": 25.827669616873937, "train/model_opt_grad_norm": 115.51580892082389, "train/model_opt_grad_steps": 4581.0, "train/model_opt_loss": 9483.467162154104, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 357.82442748091603, "train/policy_entropy_mag": 2.2454116581050494, "train/policy_entropy_max": 2.2454116581050494, "train/policy_entropy_mean": 0.7364116406622734, "train/policy_entropy_min": 0.07946058027161897, "train/policy_entropy_std": 0.4638596252175688, "train/policy_logprob_mag": 7.437517202537478, "train/policy_logprob_max": -0.009467949294520698, "train/policy_logprob_mean": -0.7368039739040928, "train/policy_logprob_min": -7.437517202537478, "train/policy_logprob_std": 1.1523837870313922, "train/policy_randomness_mag": 0.792531781069195, "train/policy_randomness_max": 0.792531781069195, "train/policy_randomness_mean": 0.259920991559065, "train/policy_randomness_min": 0.028046097762825836, "train/policy_randomness_std": 0.16372209173122435, "train/post_ent_mag": 47.92248654547539, "train/post_ent_max": 47.92248654547539, "train/post_ent_mean": 33.86888164782342, "train/post_ent_min": 15.626071944491553, "train/post_ent_std": 5.2838264057654465, "train/prior_ent_mag": 61.556118040594434, "train/prior_ent_max": 61.556118040594434, "train/prior_ent_mean": 43.89621353149414, "train/prior_ent_min": 18.169935816116915, "train/prior_ent_std": 8.053041148731726, "train/rep_loss_mean": 9.796405868675873, "train/rep_loss_std": 7.768745116605103, "train/reward_avg": 0.013659947386494916, "train/reward_loss_mean": 0.055050513188120064, "train/reward_loss_std": 0.29155622638818873, "train/reward_max_data": 1.006106871684999, "train/reward_max_pred": 0.9997908641363829, "train/reward_neg_acc": 0.9941712899972465, "train/reward_neg_loss": 0.03438358347976708, "train/reward_pos_acc": 0.915837871664353, "train/reward_pos_loss": 1.160290146602019, "train/reward_pred": 0.012480743701271144, "train/reward_rate": 0.018495050095419848, "train_stats/sum_log_reward": 3.3314049208213476, "train_stats/max_log_achievement_collect_drink": 7.31404958677686, "train_stats/max_log_achievement_collect_sapling": 1.975206611570248, "train_stats/max_log_achievement_collect_wood": 1.6611570247933884, "train_stats/max_log_achievement_defeat_skeleton": 0.008264462809917356, "train_stats/max_log_achievement_defeat_zombie": 0.14049586776859505, "train_stats/max_log_achievement_eat_cow": 0.049586776859504134, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 1.8429752066115703, "train_stats/max_log_achievement_place_table": 0.45454545454545453, "train_stats/max_log_achievement_wake_up": 1.9834710743801653, "train_stats/mean_log_entropy": 0.7429519288303438, "train_stats/max_log_achievement_make_wood_sword": 0.010638297872340425, "eval_stats/sum_log_reward": 3.2249999046325684, "eval_stats/max_log_achievement_collect_drink": 7.0625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_wood": 1.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.1875, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00447961688041687, "report/cont_loss_std": 0.09969431906938553, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.014385253190994263, "report/cont_pos_acc": 0.9980353713035583, "report/cont_pos_loss": 0.004421234130859375, "report/cont_pred": 0.9924635887145996, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.22217082977295, "report/dyn_loss_std": 8.112420082092285, "report/image_loss_mean": 21.998878479003906, "report/image_loss_std": 20.64490509033203, "report/model_loss_mean": 29.392492294311523, "report/model_loss_std": 24.30411720275879, "report/post_ent_mag": 52.85587692260742, "report/post_ent_max": 52.85587692260742, "report/post_ent_mean": 35.279937744140625, "report/post_ent_min": 15.334976196289062, "report/post_ent_std": 5.601494312286377, "report/prior_ent_mag": 62.593780517578125, "report/prior_ent_max": 62.593780517578125, "report/prior_ent_mean": 48.2474365234375, "report/prior_ent_min": 16.435848236083984, "report/prior_ent_std": 9.064221382141113, "report/rep_loss_mean": 12.22217082977295, "report/rep_loss_std": 8.112420082092285, "report/reward_avg": 0.01552734337747097, "report/reward_loss_mean": 0.0558321475982666, "report/reward_loss_std": 0.270508348941803, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9984561204910278, "report/reward_neg_acc": 0.9970059990882874, "report/reward_neg_loss": 0.03287447988986969, "report/reward_pos_acc": 0.9090909361839294, "report/reward_pos_loss": 1.1014496088027954, "report/reward_pred": 0.012536234222352505, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00018859350529965013, "eval/cont_loss_std": 0.0027711165603250265, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.017059871926903725, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0001390206889482215, "eval/cont_pred": 0.9969843626022339, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.580158233642578, "eval/dyn_loss_std": 8.499309539794922, "eval/image_loss_mean": 30.279081344604492, "eval/image_loss_std": 26.979326248168945, "eval/model_loss_mean": 39.129371643066406, "eval/model_loss_std": 30.3915958404541, "eval/post_ent_mag": 47.84267807006836, "eval/post_ent_max": 47.84267807006836, "eval/post_ent_mean": 33.790367126464844, "eval/post_ent_min": 18.6321964263916, "eval/post_ent_std": 5.74675989151001, "eval/prior_ent_mag": 60.89704132080078, "eval/prior_ent_max": 60.89704132080078, "eval/prior_ent_mean": 46.24267578125, "eval/prior_ent_min": 20.332557678222656, "eval/prior_ent_std": 7.962868690490723, "eval/rep_loss_mean": 14.580158233642578, "eval/rep_loss_std": 8.499309539794922, "eval/reward_avg": 0.00996093638241291, "eval/reward_loss_mean": 0.10200535506010056, "eval/reward_loss_std": 0.7054197192192078, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0014641284942627, "eval/reward_neg_acc": 0.9980217218399048, "eval/reward_neg_loss": 0.04356038197875023, "eval/reward_pos_acc": 0.38461539149284363, "eval/reward_pos_loss": 4.647226333618164, "eval/reward_pred": 0.001118403859436512, "eval/reward_rate": 0.0126953125, "replay/size": 84897.0, "replay/inserts": 20880.0, "replay/samples": 20880.0, "replay/insert_wait_avg": 1.4132352624359715e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.37136959207469e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18704.0, "eval_replay/inserts": 4808.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.269747532544636e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.144454240799, "timer/env.step_count": 2610.0, "timer/env.step_total": 275.3359155654907, "timer/env.step_frac": 0.2752961478694554, "timer/env.step_avg": 0.10549268795612671, "timer/env.step_min": 0.025020360946655273, "timer/env.step_max": 3.333562135696411, "timer/replay._sample_count": 20880.0, "timer/replay._sample_total": 11.756427764892578, "timer/replay._sample_frac": 0.011754729744331564, "timer/replay._sample_avg": 0.0005630473067477288, "timer/replay._sample_min": 0.0004012584686279297, "timer/replay._sample_max": 0.02761244773864746, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3211.0, "timer/agent.policy_total": 59.070303440093994, "timer/agent.policy_frac": 0.05906177171670042, "timer/agent.policy_avg": 0.01839623277486577, "timer/agent.policy_min": 0.009968042373657227, "timer/agent.policy_max": 0.13527297973632812, "timer/dataset_train_count": 1305.0, "timer/dataset_train_total": 0.16798949241638184, "timer/dataset_train_frac": 0.00016796522912672772, "timer/dataset_train_avg": 0.00012872758039569489, "timer/dataset_train_min": 0.00011110305786132812, "timer/dataset_train_max": 0.00045180320739746094, "timer/agent.train_count": 1305.0, "timer/agent.train_total": 591.3058404922485, "timer/agent.train_frac": 0.5912204361929935, "timer/agent.train_avg": 0.45310792374884945, "timer/agent.train_min": 0.43910694122314453, "timer/agent.train_max": 1.5132510662078857, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4801943302154541, "timer/agent.report_frac": 0.000480124974126828, "timer/agent.report_avg": 0.24009716510772705, "timer/agent.report_min": 0.23243141174316406, "timer/agent.report_max": 0.24776291847229004, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.5299530029296875e-05, "timer/dataset_eval_frac": 4.529298726520796e-08, "timer/dataset_eval_avg": 4.5299530029296875e-05, "timer/dataset_eval_min": 4.5299530029296875e-05, "timer/dataset_eval_max": 4.5299530029296875e-05, "fps": 20.87672219896156}
{"step": 85472, "time": 4322.439778089523, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 85520, "time": 4325.717545509338, "episode/length": 232.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 86312, "time": 4354.046136856079, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 86440, "time": 4360.141731500626, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 86480, "time": 4363.321709394455, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 86488, "time": 4364.904340982437, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 86712, "time": 4374.147914409637, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 86848, "time": 4380.5757167339325, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 86904, "time": 4383.866476535797, "episode/length": 51.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 87112, "time": 4392.740554094315, "episode/length": 49.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 87160, "time": 4395.956285476685, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 87216, "time": 4399.614547014236, "episode/length": 211.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 87256, "time": 4402.295596599579, "episode/length": 247.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 87536, "time": 4413.625704526901, "episode/length": 152.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 87720, "time": 4421.374400615692, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 88152, "time": 4437.777685642242, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 88408, "time": 4448.581737518311, "episode/length": 108.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 88776, "time": 4462.855028867722, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 88784, "time": 4465.075149536133, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 88904, "time": 4470.4715032577515, "episode/length": 210.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 88944, "time": 4473.661824703217, "episode/length": 222.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 88944, "time": 4473.6749131679535, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 89344, "time": 4490.597003936768, "episode/length": 202.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 89664, "time": 4503.015450000763, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4537.16933465004, "eval_episode/length": 91.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9565217391304348}
{"step": 90064, "time": 4540.778948068619, "eval_episode/length": 131.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 90064, "time": 4543.414008617401, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 90064, "time": 4545.1927790641785, "eval_episode/length": 157.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 90064, "time": 4547.187553882599, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 90064, "time": 4549.814279556274, "eval_episode/length": 184.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 90064, "time": 4552.392148733139, "eval_episode/length": 204.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 90064, "time": 4556.350505828857, "eval_episode/length": 50.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 90080, "time": 4556.901129722595, "episode/length": 240.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 90168, "time": 4562.693907737732, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 90224, "time": 4566.485109806061, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 90224, "time": 4566.494782924652, "episode/length": 164.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 90264, "time": 4571.243231058121, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 90432, "time": 4578.792345046997, "episode/length": 43.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 91016, "time": 4600.116014242172, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 91456, "time": 4616.914621353149, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 91480, "time": 4619.114216566086, "episode/length": 156.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 91496, "time": 4621.292060136795, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 91568, "time": 4625.559718370438, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 91568, "time": 4625.569317817688, "episode/length": 162.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 91896, "time": 4640.084194898605, "episode/length": 40.0, "episode/score": 2.099999964237213, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 92008, "time": 4645.518855810165, "episode/length": 65.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 92040, "time": 4648.250769376755, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 92104, "time": 4652.046270132065, "episode/length": 394.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9772151898734177, "episode/intrinsic_return": 0.0}
{"step": 92344, "time": 4661.999735832214, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 92664, "time": 4674.486684322357, "episode/length": 39.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 92744, "time": 4678.833361148834, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 93000, "time": 4689.154734611511, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 93000, "time": 4689.16454410553, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 93144, "time": 4697.53941488266, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 93360, "time": 4706.69176864624, "episode/length": 156.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 93512, "time": 4713.195044517517, "episode/length": 183.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 93960, "time": 4730.087714672089, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 93984, "time": 4732.688405990601, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 94096, "time": 4738.091967344284, "episode/length": 260.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 94416, "time": 4750.7423095703125, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 94592, "time": 4758.316355228424, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 94744, "time": 4764.971746921539, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 95032, "time": 4776.2676701545715, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 95192, "time": 4783.373851060867, "episode/length": 273.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 95264, "time": 4787.720490694046, "episode/length": 162.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 95488, "time": 4797.106137752533, "episode/length": 187.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 95560, "time": 4801.348673582077, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 95592, "time": 4804.5264258384705, "episode/length": 186.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 95928, "time": 4818.135145187378, "episode/length": 91.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9456521739130435, "episode/intrinsic_return": 0.0}
{"step": 96056, "time": 4824.171163082123, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 96080, "time": 4826.894821405411, "episode/length": 130.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 96120, "time": 4829.715274333954, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 96568, "time": 4846.657342672348, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 97112, "time": 4866.654757738113, "episode/length": 189.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 97176, "time": 4870.6762137413025, "episode/length": 155.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 97200, "time": 4873.286452531815, "episode/length": 213.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 97432, "time": 4882.695856809616, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 97480, "time": 4885.889311313629, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 97536, "time": 4889.635427474976, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 97728, "time": 4897.674011707306, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 97800, "time": 4901.671241044998, "episode/length": 279.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 98536, "time": 4929.6107931137085, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 98912, "time": 4944.5746059417725, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 98920, "time": 4946.226882457733, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 98992, "time": 4950.5079135894775, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 99048, "time": 4953.858615636826, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 99128, "time": 4958.2802991867065, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 99248, "time": 4964.403712749481, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 99576, "time": 4976.841535329819, "episode/length": 307.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 99896, "time": 4989.341492176056, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 5026.138204574585, "eval_episode/length": 152.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 100048, "time": 5028.581780195236, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 100048, "time": 5030.292656183243, "eval_episode/length": 171.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 100048, "time": 5032.473160266876, "eval_episode/length": 185.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 100048, "time": 5034.484228372574, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 100048, "time": 5036.206883430481, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 100048, "time": 5040.566240787506, "eval_episode/length": 255.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.98046875}
{"step": 100048, "time": 5044.851673841476, "eval_episode/length": 156.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 100456, "time": 5058.506649494171, "episode/length": 182.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 100512, "time": 5062.172699689865, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 100544, "time": 5064.887179851532, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 100736, "time": 5072.962693691254, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 100752, "time": 5075.046642065048, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8918918918918919, "episode/intrinsic_return": 0.0}
{"step": 101136, "time": 5089.797546863556, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 101136, "time": 5089.807880401611, "episode/length": 194.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 101216, "time": 5095.864995718002, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 101440, "time": 5105.181746006012, "episode/length": 315.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 102112, "time": 5129.701948642731, "episode/length": 199.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 102320, "time": 5138.420404672623, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 102512, "time": 5146.997128725052, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 102528, "time": 5149.249567270279, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 102560, "time": 5152.062000989914, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 102792, "time": 5161.341455936432, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 102904, "time": 5166.78075003624, "episode/length": 72.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9178082191780822, "episode/intrinsic_return": 0.0}
{"step": 103040, "time": 5173.333992958069, "episode/length": 287.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 103656, "time": 5195.4582624435425, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 103832, "time": 5203.276748418808, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 103880, "time": 5206.540230035782, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 104072, "time": 5214.68369603157, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 104144, "time": 5218.971220970154, "episode/length": 375.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9893617021276596, "episode/intrinsic_return": 0.0}
{"step": 104144, "time": 5218.980797529221, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 104168, "time": 5222.820792198181, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 105080, "time": 5256.380608320236, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 105128, "time": 5259.674719333649, "episode/length": 260.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 105512, "time": 5274.463710308075, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 105552, "time": 5277.6493101119995, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 105560, "time": 5279.428687572479, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 105592, "time": 5282.106985569, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 105608, "time": 5284.2564470767975, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 105840, "time": 5294.084413051605, "episode/length": 40.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 105976, "time": 5300.002588272095, "episode/length": 51.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 106120, "time": 5306.517067432404, "episode/length": 243.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 106384, "time": 5317.389765024185, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 106393, "time": 5320.167236089706, "train_stats/sum_log_reward": 4.023076857129733, "train_stats/max_log_achievement_collect_drink": 7.136752136752137, "train_stats/max_log_achievement_collect_sapling": 1.794871794871795, "train_stats/max_log_achievement_collect_wood": 2.3675213675213675, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.1282051282051282, "train_stats/max_log_achievement_eat_cow": 0.07692307692307693, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017094017094017096, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 1.6324786324786325, "train_stats/max_log_achievement_place_table": 0.8205128205128205, "train_stats/max_log_achievement_wake_up": 2.076923076923077, "train_stats/mean_log_entropy": 0.6494860137120272, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.928846985329199, "train/action_min": 0.0, "train/action_std": 3.4028438720994325, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.053899627150470066, "train/actor_opt_grad_steps": 5900.0, "train/actor_opt_loss": 3.6153644325623984, "train/adv_mag": 1.1594235624065836, "train/adv_max": 1.1569178909745834, "train/adv_mean": 0.005432716943034796, "train/adv_min": -0.5320687432780521, "train/adv_std": 0.09690056695737911, "train/cont_avg": 0.9945655415076335, "train/cont_loss_mean": 0.0006391467819700478, "train/cont_loss_std": 0.0170068692489896, "train/cont_neg_acc": 0.9858028100087093, "train/cont_neg_loss": 0.05909884123843767, "train/cont_pos_acc": 0.9998949729759274, "train/cont_pos_loss": 0.0003296354336143864, "train/cont_pred": 0.9945567823548354, "train/cont_rate": 0.9945655415076335, "train/dyn_loss_mean": 11.874169356950366, "train/dyn_loss_std": 8.47506959929721, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1290532132141462, "train/extr_critic_critic_opt_grad_steps": 5900.0, "train/extr_critic_critic_opt_loss": 15042.382954138835, "train/extr_critic_mag": 2.856872891651765, "train/extr_critic_max": 2.856872891651765, "train/extr_critic_mean": 0.6475539034559527, "train/extr_critic_min": -0.21066413944914142, "train/extr_critic_std": 0.7401658166910856, "train/extr_return_normed_mag": 2.1511479889163536, "train/extr_return_normed_max": 2.1511479889163536, "train/extr_return_normed_mean": 0.3523012780733691, "train/extr_return_normed_min": -0.20965670595187266, "train/extr_return_normed_std": 0.35837168218070314, "train/extr_return_rate": 0.4154123161130279, "train/extr_return_raw_mag": 4.5974737906274, "train/extr_return_raw_max": 4.5974737906274, "train/extr_return_raw_mean": 0.6592820122951769, "train/extr_return_raw_min": -0.5710476996334455, "train/extr_return_raw_std": 0.7848638664675123, "train/extr_reward_mag": 1.0044247594498497, "train/extr_reward_max": 1.0044247594498497, "train/extr_reward_mean": 0.013818261864104571, "train/extr_reward_min": -0.3499036899959768, "train/extr_reward_std": 0.10029583048956994, "train/image_loss_mean": 18.724661215571047, "train/image_loss_std": 20.135162833992762, "train/model_loss_mean": 25.90390802339743, "train/model_loss_std": 23.91485256457147, "train/model_opt_grad_norm": 104.02966812366748, "train/model_opt_grad_steps": 5890.274809160305, "train/model_opt_loss": 13767.004021797471, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 531.9656488549618, "train/policy_entropy_mag": 2.3204193333633074, "train/policy_entropy_max": 2.3204193333633074, "train/policy_entropy_mean": 0.6427380194645802, "train/policy_entropy_min": 0.07939638692231579, "train/policy_entropy_std": 0.46249814479405643, "train/policy_logprob_mag": 7.438241456301157, "train/policy_logprob_max": -0.00945921644625318, "train/policy_logprob_mean": -0.6430097044879244, "train/policy_logprob_min": -7.438241456301157, "train/policy_logprob_std": 1.1110525204025152, "train/policy_randomness_mag": 0.8190061977801432, "train/policy_randomness_max": 0.8190061977801432, "train/policy_randomness_mean": 0.2268583166007777, "train/policy_randomness_min": 0.02802344043348127, "train/policy_randomness_std": 0.16324154816511025, "train/post_ent_mag": 49.85668319236231, "train/post_ent_max": 49.85668319236231, "train/post_ent_mean": 35.519283352917384, "train/post_ent_min": 17.805734073842753, "train/post_ent_std": 5.114949892495424, "train/prior_ent_mag": 62.96788662626543, "train/prior_ent_max": 62.96788662626543, "train/prior_ent_mean": 47.59500005591007, "train/prior_ent_min": 20.898225485823538, "train/prior_ent_std": 8.069199259954555, "train/rep_loss_mean": 11.874169356950366, "train/rep_loss_std": 8.47506959929721, "train/reward_avg": 0.016117753990648586, "train/reward_loss_mean": 0.0541061048914913, "train/reward_loss_std": 0.27324515865504284, "train/reward_max_data": 1.0137404612912477, "train/reward_max_pred": 1.002413709655063, "train/reward_neg_acc": 0.9935232291694815, "train/reward_neg_loss": 0.03283927593209589, "train/reward_pos_acc": 0.934317140178826, "train/reward_pos_loss": 1.0397002933589556, "train/reward_pred": 0.015191349455063011, "train/reward_rate": 0.02105945849236641, "eval_stats/sum_log_reward": 3.5999999111518264, "eval_stats/max_log_achievement_collect_drink": 7.1875, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_wood": 2.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.6875, "eval_stats/max_log_achievement_wake_up": 1.8125, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.05263157894736842, "train_stats/max_log_achievement_collect_stone": 0.3157894736842105, "train_stats/max_log_achievement_place_stone": 0.05263157894736842, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.2149768028612016e-06, "report/cont_loss_std": 5.5762753618182614e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00037264853017404675, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.973441664584243e-07, "report/cont_pred": 0.9951186776161194, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 10.570297241210938, "report/dyn_loss_std": 8.399947166442871, "report/image_loss_mean": 12.925569534301758, "report/image_loss_std": 14.313326835632324, "report/model_loss_mean": 19.29767608642578, "report/model_loss_std": 18.226926803588867, "report/post_ent_mag": 52.57189178466797, "report/post_ent_max": 52.57189178466797, "report/post_ent_mean": 35.86903381347656, "report/post_ent_min": 17.427839279174805, "report/post_ent_std": 5.624203205108643, "report/prior_ent_mag": 61.87372589111328, "report/prior_ent_max": 61.87372589111328, "report/prior_ent_mean": 47.52920913696289, "report/prior_ent_min": 21.23434066772461, "report/prior_ent_std": 8.29258918762207, "report/rep_loss_mean": 10.570297241210938, "report/rep_loss_std": 8.399947166442871, "report/reward_avg": 0.00869140587747097, "report/reward_loss_mean": 0.029926467686891556, "report/reward_loss_std": 0.14250895380973816, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9985508918762207, "report/reward_neg_acc": 0.997029721736908, "report/reward_neg_loss": 0.02009741961956024, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7390219569206238, "report/reward_pred": 0.008197411894798279, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.5064676517795306e-05, "eval/cont_loss_std": 0.0003074302221648395, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006927779875695705, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.307378266181331e-06, "eval/cont_pred": 0.9990220069885254, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 15.753497123718262, "eval/dyn_loss_std": 9.25306224822998, "eval/image_loss_mean": 33.06640625, "eval/image_loss_std": 33.204471588134766, "eval/model_loss_mean": 42.61973571777344, "eval/model_loss_std": 36.9932861328125, "eval/post_ent_mag": 51.395843505859375, "eval/post_ent_max": 51.395843505859375, "eval/post_ent_mean": 33.9061393737793, "eval/post_ent_min": 18.128515243530273, "eval/post_ent_std": 4.998725414276123, "eval/prior_ent_mag": 62.447364807128906, "eval/prior_ent_max": 62.447364807128906, "eval/prior_ent_mean": 47.13277816772461, "eval/prior_ent_min": 23.209590911865234, "eval/prior_ent_std": 8.504963874816895, "eval/rep_loss_mean": 15.753497123718262, "eval/rep_loss_std": 9.25306224822998, "eval/reward_avg": 0.012500000186264515, "eval/reward_loss_mean": 0.1012139618396759, "eval/reward_loss_std": 0.7442106604576111, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999163150787354, "eval/reward_neg_acc": 0.998019814491272, "eval/reward_neg_loss": 0.03512578457593918, "eval/reward_pos_acc": 0.2857142984867096, "eval/reward_pos_loss": 4.869004726409912, "eval/reward_pred": 0.0023447915446013212, "eval/reward_rate": 0.013671875, "replay/size": 105889.0, "replay/inserts": 20992.0, "replay/samples": 20992.0, "replay/insert_wait_avg": 1.4131797886476285e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.648657007915218e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 23232.0, "eval_replay/inserts": 4528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.244115323986687e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1980292797089, "timer/env.step_count": 2624.0, "timer/env.step_total": 270.54887557029724, "timer/env.step_frac": 0.2704953095789767, "timer/env.step_avg": 0.10310551660453401, "timer/env.step_min": 0.024743080139160156, "timer/env.step_max": 3.654003620147705, "timer/replay._sample_count": 20992.0, "timer/replay._sample_total": 11.34827208518982, "timer/replay._sample_frac": 0.011346025239983987, "timer/replay._sample_avg": 0.0005405998516191797, "timer/replay._sample_min": 0.0003714561462402344, "timer/replay._sample_max": 0.03374505043029785, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3190.0, "timer/agent.policy_total": 56.992175817489624, "timer/agent.policy_frac": 0.05698089193250306, "timer/agent.policy_avg": 0.017865885836203643, "timer/agent.policy_min": 0.009787321090698242, "timer/agent.policy_max": 0.09932875633239746, "timer/dataset_train_count": 1312.0, "timer/dataset_train_total": 0.1620616912841797, "timer/dataset_train_frac": 0.00016202960467827374, "timer/dataset_train_avg": 0.00012352263055196623, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0006198883056640625, "timer/agent.train_count": 1312.0, "timer/agent.train_total": 590.5669116973877, "timer/agent.train_frac": 0.5904499853120923, "timer/agent.train_avg": 0.4501272192815455, "timer/agent.train_min": 0.4364049434661865, "timer/agent.train_max": 1.4756731986999512, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4881875514984131, "timer/agent.report_frac": 0.0004880908952100022, "timer/agent.report_avg": 0.24409377574920654, "timer/agent.report_min": 0.23362016677856445, "timer/agent.report_max": 0.25456738471984863, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765107945243411e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 20.98750330548394}
{"step": 106440, "time": 5321.650267124176, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 106864, "time": 5339.390946865082, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 107216, "time": 5353.009037256241, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 107240, "time": 5355.179711103439, "episode/length": 203.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 107384, "time": 5361.641311883926, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 107560, "time": 5369.172370195389, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 107600, "time": 5372.4381012916565, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 107608, "time": 5374.150999546051, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 107808, "time": 5383.029471874237, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 108016, "time": 5391.613564729691, "episode/length": 51.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 108456, "time": 5408.017749071121, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 108488, "time": 5410.9247789382935, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 108792, "time": 5422.7528784275055, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 108952, "time": 5429.978164196014, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 108968, "time": 5432.705818414688, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 109120, "time": 5440.250683069229, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 109224, "time": 5445.253898382187, "episode/length": 176.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 109296, "time": 5449.6984848976135, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 109688, "time": 5464.30628156662, "episode/length": 48.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5499.231485843658, "eval_episode/length": 142.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.958041958041958}
{"step": 110032, "time": 5501.44056558609, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 110032, "time": 5503.378622531891, "eval_episode/length": 159.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 110032, "time": 5505.910050868988, "eval_episode/length": 178.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 110032, "time": 5507.8331823349, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 110032, "time": 5510.0591468811035, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 110032, "time": 5512.392174243927, "eval_episode/length": 215.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 110032, "time": 5514.401063919067, "eval_episode/length": 223.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 110144, "time": 5518.20370388031, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 110320, "time": 5525.75159406662, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 110320, "time": 5525.762102842331, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 110416, "time": 5532.491734743118, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 110656, "time": 5542.291748523712, "episode/length": 270.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 110656, "time": 5542.302770853043, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 110936, "time": 5555.013416290283, "episode/length": 213.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 111048, "time": 5560.635976314545, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 111400, "time": 5574.1046488285065, "episode/length": 43.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 111680, "time": 5585.491621494293, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 111712, "time": 5588.13570523262, "episode/length": 161.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 111856, "time": 5594.776076793671, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 111968, "time": 5600.267870426178, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 112088, "time": 5605.598995447159, "episode/length": 178.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 112096, "time": 5607.686222314835, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 112376, "time": 5618.468708276749, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 5636.4041612148285, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 112944, "time": 5641.192012786865, "episode/length": 192.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 113128, "time": 5648.810960769653, "episode/length": 129.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 113152, "time": 5651.621752023697, "episode/length": 147.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 113360, "time": 5660.295431137085, "episode/length": 187.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 113600, "time": 5669.920763492584, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 113832, "time": 5679.053606510162, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 113952, "time": 5685.181520938873, "episode/length": 196.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 114008, "time": 5688.4872789382935, "episode/length": 50.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 114272, "time": 5699.215108394623, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 114464, "time": 5707.36280632019, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 114704, "time": 5718.620604276657, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 114744, "time": 5721.406932115555, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 115272, "time": 5740.990516424179, "episode/length": 267.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 115376, "time": 5746.348662614822, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 115472, "time": 5751.232749700546, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 115752, "time": 5762.123692512512, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 115856, "time": 5767.456332445145, "episode/length": 237.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 115928, "time": 5771.381479978561, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 116016, "time": 5776.34868812561, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 116352, "time": 5789.388465642929, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 116568, "time": 5798.15367436409, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 116696, "time": 5804.326652288437, "episode/length": 104.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9619047619047619, "episode/intrinsic_return": 0.0}
{"step": 116968, "time": 5815.071200370789, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 117096, "time": 5820.967835187912, "episode/length": 214.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 117576, "time": 5838.971395492554, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 117824, "time": 5849.134887933731, "episode/length": 236.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 118128, "time": 5861.305337429047, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 118200, "time": 5865.125591993332, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 118320, "time": 5871.061427593231, "episode/length": 287.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 118448, "time": 5877.018774271011, "episode/length": 39.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 118544, "time": 5885.4530391693115, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 118560, "time": 5887.649054527283, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9849246231155779, "episode/intrinsic_return": 0.0}
{"step": 118640, "time": 5892.027482509613, "episode/length": 285.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 118784, "time": 5898.547410488129, "episode/length": 29.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 119232, "time": 5915.212552547455, "episode/length": 206.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 119288, "time": 5918.457098484039, "episode/length": 135.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9558823529411765, "episode/intrinsic_return": 0.0}
{"step": 119840, "time": 5939.192728281021, "episode/length": 251.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5967.765461921692, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 120016, "time": 5969.92676782608, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 120016, "time": 5972.463826656342, "eval_episode/length": 173.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 120016, "time": 5974.651864290237, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 120016, "time": 5977.076921463013, "eval_episode/length": 180.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 120016, "time": 5979.242616176605, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 120016, "time": 5981.645327091217, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 120016, "time": 5983.94634437561, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 120312, "time": 5993.820543527603, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 120376, "time": 5997.525902032852, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 120440, "time": 6001.88516330719, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 120608, "time": 6009.567294836044, "episode/length": 255.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 120680, "time": 6013.364524841309, "episode/length": 294.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 120768, "time": 6018.164166688919, "episode/length": 289.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 120944, "time": 6025.637748718262, "episode/length": 137.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 121072, "time": 6031.476645708084, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 121464, "time": 6046.023202180862, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 121632, "time": 6053.497488021851, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 121712, "time": 6057.84627699852, "episode/length": 166.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 122208, "time": 6076.28325176239, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 122224, "time": 6078.462849617004, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 122496, "time": 6089.164161205292, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 122680, "time": 6096.764523506165, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 122840, "time": 6103.862866401672, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 122944, "time": 6110.7626922130585, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 123112, "time": 6117.902580022812, "episode/length": 53.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 123256, "time": 6124.402266263962, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 123416, "time": 6131.487973690033, "episode/length": 212.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 123544, "time": 6137.414895057678, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 123568, "time": 6140.16224527359, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 123864, "time": 6151.526775121689, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 124184, "time": 6164.070875167847, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 124408, "time": 6173.191007852554, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 124472, "time": 6176.950166940689, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 124496, "time": 6179.546556711197, "episode/length": 249.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 124744, "time": 6189.290068864822, "episode/length": 33.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 124760, "time": 6191.58127784729, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 124760, "time": 6191.589074134827, "episode/length": 43.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 124904, "time": 6199.866862297058, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 125104, "time": 6208.45047211647, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 125176, "time": 6212.340948581696, "episode/length": 51.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 126016, "time": 6242.643230438232, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 126184, "time": 6249.964226961136, "episode/length": 289.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 126360, "time": 6257.715041875839, "episode/length": 271.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 126368, "time": 6259.861282587051, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 126384, "time": 6261.987279653549, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 126416, "time": 6264.628151416779, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 126440, "time": 6266.804790973663, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 126832, "time": 6287.241418123245, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 127320, "time": 6305.095524311066, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 127689, "time": 6320.2275586128235, "train_stats/sum_log_reward": 4.047826031109561, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.3478260869565215, "train_stats/max_log_achievement_collect_sapling": 2.4434782608695653, "train_stats/max_log_achievement_collect_stone": 0.017391304347826087, "train_stats/max_log_achievement_collect_wood": 2.4260869565217393, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.25217391304347825, "train_stats/max_log_achievement_eat_cow": 0.034782608695652174, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008695652173913044, "train_stats/max_log_achievement_make_wood_sword": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 2.139130434782609, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 0.8782608695652174, "train_stats/max_log_achievement_wake_up": 1.6869565217391305, "train_stats/mean_log_entropy": 0.6235623639562856, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.895342145647321, "train/action_min": 0.0, "train/action_std": 3.479055250497689, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05348495809935538, "train/actor_opt_grad_steps": 7220.0, "train/actor_opt_loss": 0.7274838365558395, "train/adv_mag": 1.0770118890848375, "train/adv_max": 1.0752401347447158, "train/adv_mean": 0.005745444077817403, "train/adv_min": -0.5262919583714994, "train/adv_std": 0.09500879503058311, "train/cont_avg": 0.994140625, "train/cont_loss_mean": 0.0005297243504340932, "train/cont_loss_std": 0.014032540485770465, "train/cont_neg_acc": 0.9827423028479841, "train/cont_neg_loss": 0.0596079615060214, "train/cont_pos_acc": 0.999955659970305, "train/cont_pos_loss": 0.0001341934995848414, "train/cont_pred": 0.9941814936193308, "train/cont_rate": 0.994140625, "train/dyn_loss_mean": 13.387659051364526, "train/dyn_loss_std": 8.877206988800737, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.11835552561552, "train/extr_critic_critic_opt_grad_steps": 7220.0, "train/extr_critic_critic_opt_loss": 15298.442713228384, "train/extr_critic_mag": 3.280863378280984, "train/extr_critic_max": 3.280863378280984, "train/extr_critic_mean": 0.6371938916749524, "train/extr_critic_min": -0.2592574895772719, "train/extr_critic_std": 0.7935939579081714, "train/extr_return_normed_mag": 2.2101362128006783, "train/extr_return_normed_max": 2.2101362128006783, "train/extr_return_normed_mean": 0.3440052509531939, "train/extr_return_normed_min": -0.19860018386428518, "train/extr_return_normed_std": 0.3606184682899848, "train/extr_return_rate": 0.3933070175405732, "train/extr_return_raw_mag": 4.9984887399171525, "train/extr_return_raw_max": 4.9984887399171525, "train/extr_return_raw_mean": 0.650599130338296, "train/extr_return_raw_min": -0.6128215664311459, "train/extr_return_raw_std": 0.8401234889388981, "train/extr_reward_mag": 1.0045796381799799, "train/extr_reward_max": 1.0045796381799799, "train/extr_reward_mean": 0.01487977135597371, "train/extr_reward_min": -0.3163178056702578, "train/extr_reward_std": 0.10876483117279254, "train/image_loss_mean": 15.743500903136749, "train/image_loss_std": 17.4744531946971, "train/model_loss_mean": 23.831884441519144, "train/model_loss_std": 21.376069585183508, "train/model_opt_grad_norm": 95.90982247833023, "train/model_opt_grad_steps": 7209.0, "train/model_opt_loss": 11564.132845541588, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 491.07142857142856, "train/policy_entropy_mag": 2.3982686548304737, "train/policy_entropy_max": 2.3982686548304737, "train/policy_entropy_mean": 0.6454063360404251, "train/policy_entropy_min": 0.07938705227876965, "train/policy_entropy_std": 0.5032824307007897, "train/policy_logprob_mag": 7.438337218492551, "train/policy_logprob_max": -0.009457874594998538, "train/policy_logprob_mean": -0.6456827395840695, "train/policy_logprob_min": -7.438337218492551, "train/policy_logprob_std": 1.1217085069283508, "train/policy_randomness_mag": 0.8464835886668441, "train/policy_randomness_max": 0.8464835886668441, "train/policy_randomness_mean": 0.22780011314198487, "train/policy_randomness_min": 0.028020145567624194, "train/policy_randomness_std": 0.17763661161849373, "train/post_ent_mag": 51.85159336176134, "train/post_ent_max": 51.85159336176134, "train/post_ent_mean": 36.85031529476768, "train/post_ent_min": 19.5024211854863, "train/post_ent_std": 5.233043455539789, "train/prior_ent_mag": 63.791504307797084, "train/prior_ent_max": 63.791504307797084, "train/prior_ent_mean": 50.46026447841099, "train/prior_ent_min": 23.533058023094235, "train/prior_ent_std": 7.611999676639872, "train/rep_loss_mean": 13.387659051364526, "train/rep_loss_std": 8.877206988800737, "train/reward_avg": 0.016821105365774462, "train/reward_loss_mean": 0.055258408188819885, "train/reward_loss_std": 0.27249135648397577, "train/reward_max_data": 1.0097744384206326, "train/reward_max_pred": 1.0025645046305836, "train/reward_neg_acc": 0.9930228362406107, "train/reward_neg_loss": 0.033973229880955885, "train/reward_pos_acc": 0.9388058898144198, "train/reward_pos_loss": 0.9957175729866314, "train/reward_pred": 0.01589219721342276, "train/reward_rate": 0.022159891917293232, "eval_stats/sum_log_reward": 4.787499904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 7.6875, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.75, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.330381671024952e-06, "report/cont_loss_std": 9.664925892138854e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005437396466732025, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.176338160912564e-07, "report/cont_pred": 0.9931672215461731, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.886810302734375, "report/dyn_loss_std": 8.970993995666504, "report/image_loss_mean": 10.63938045501709, "report/image_loss_std": 12.687202453613281, "report/model_loss_mean": 18.41676139831543, "report/model_loss_std": 16.743654251098633, "report/post_ent_mag": 53.91665267944336, "report/post_ent_max": 53.91665267944336, "report/post_ent_mean": 36.13750457763672, "report/post_ent_min": 18.533145904541016, "report/post_ent_std": 4.9935808181762695, "report/prior_ent_mag": 64.34268951416016, "report/prior_ent_max": 64.34268951416016, "report/prior_ent_mean": 49.37903594970703, "report/prior_ent_min": 23.817420959472656, "report/prior_ent_std": 7.797072410583496, "report/rep_loss_mean": 12.886810302734375, "report/rep_loss_std": 8.970993995666504, "report/reward_avg": 0.00966796837747097, "report/reward_loss_mean": 0.0452912263572216, "report/reward_loss_std": 0.24589607119560242, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0062909126281738, "report/reward_neg_acc": 0.9950397610664368, "report/reward_neg_loss": 0.03012874908745289, "report/reward_pos_acc": 0.9375, "report/reward_pos_loss": 1.000527262687683, "report/reward_pred": 0.009938823990523815, "report/reward_rate": 0.015625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 8.435054041910917e-06, "eval/cont_loss_std": 0.00020545457664411515, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001676857704296708, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.8922204390037223e-06, "eval/cont_pred": 0.9960984587669373, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.74371337890625, "eval/dyn_loss_std": 9.295051574707031, "eval/image_loss_mean": 16.560840606689453, "eval/image_loss_std": 20.757905960083008, "eval/model_loss_mean": 26.700634002685547, "eval/model_loss_std": 24.440359115600586, "eval/post_ent_mag": 48.03608703613281, "eval/post_ent_max": 48.03608703613281, "eval/post_ent_mean": 34.93177032470703, "eval/post_ent_min": 19.096599578857422, "eval/post_ent_std": 5.095789909362793, "eval/prior_ent_mag": 63.534385681152344, "eval/prior_ent_max": 63.534385681152344, "eval/prior_ent_mean": 47.94306945800781, "eval/prior_ent_min": 24.4372501373291, "eval/prior_ent_std": 8.814678192138672, "eval/rep_loss_mean": 16.74371337890625, "eval/rep_loss_std": 9.295051574707031, "eval/reward_avg": 0.01093750074505806, "eval/reward_loss_mean": 0.09355700016021729, "eval/reward_loss_std": 0.6062766313552856, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0017669200897217, "eval/reward_neg_acc": 0.9990079998970032, "eval/reward_neg_loss": 0.053671859204769135, "eval/reward_pos_acc": 0.6875, "eval/reward_pos_loss": 2.606321334838867, "eval/reward_pred": 0.005158938933163881, "eval/reward_rate": 0.015625, "replay/size": 127185.0, "replay/inserts": 21296.0, "replay/samples": 21296.0, "replay/insert_wait_avg": 1.3646821524306941e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.650531565310093e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26560.0, "eval_replay/inserts": 3328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2539183864226709e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0579688549042, "timer/env.step_count": 2662.0, "timer/env.step_total": 262.55500626564026, "timer/env.step_frac": 0.26253978713481324, "timer/env.step_avg": 0.098630731129091, "timer/env.step_min": 0.024347305297851562, "timer/env.step_max": 3.5015034675598145, "timer/replay._sample_count": 21296.0, "timer/replay._sample_total": 11.727719068527222, "timer/replay._sample_frac": 0.011727039265489585, "timer/replay._sample_avg": 0.0005507005573125104, "timer/replay._sample_min": 0.0003695487976074219, "timer/replay._sample_max": 0.011896610260009766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3078.0, "timer/agent.policy_total": 55.05168390274048, "timer/agent.policy_frac": 0.055048492804648394, "timer/agent.policy_avg": 0.01788553733032504, "timer/agent.policy_min": 0.009759902954101562, "timer/agent.policy_max": 0.15053725242614746, "timer/dataset_train_count": 1331.0, "timer/dataset_train_total": 0.1629793643951416, "timer/dataset_train_frac": 0.00016296991721565678, "timer/dataset_train_avg": 0.0001224488087116015, "timer/dataset_train_min": 0.0001068115234375, "timer/dataset_train_max": 0.0006363391876220703, "timer/agent.train_count": 1331.0, "timer/agent.train_total": 602.3748302459717, "timer/agent.train_frac": 0.6023399132909352, "timer/agent.train_avg": 0.4525731256543739, "timer/agent.train_min": 0.43885350227355957, "timer/agent.train_max": 1.5858261585235596, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4872910976409912, "timer/agent.report_frac": 0.00048726285157144826, "timer/agent.report_avg": 0.2436455488204956, "timer/agent.report_min": 0.23689031600952148, "timer/agent.report_max": 0.2504007816314697, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.027740439943593e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.29433944621832}
{"step": 127744, "time": 6322.21798157692, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 127752, "time": 6324.024791479111, "episode/length": 172.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 127808, "time": 6327.75449180603, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 127848, "time": 6330.404885292053, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 128000, "time": 6337.479124069214, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 128616, "time": 6359.907740354538, "episode/length": 271.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 128624, "time": 6362.02997136116, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 128800, "time": 6369.649201631546, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 128816, "time": 6371.944029808044, "episode/length": 125.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 129096, "time": 6382.795272350311, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 129112, "time": 6384.839480400085, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 129304, "time": 6392.87798666954, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 129496, "time": 6401.141659021378, "episode/length": 186.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 129848, "time": 6414.538465261459, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 129936, "time": 6419.332867145538, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 129952, "time": 6421.391893148422, "episode/length": 80.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6447.084416627884, "eval_episode/length": 156.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9554140127388535}
{"step": 130000, "time": 6448.920604228973, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 130000, "time": 6450.594606637955, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 130000, "time": 6452.702061653137, "eval_episode/length": 172.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 130000, "time": 6454.802343130112, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 130000, "time": 6456.525527238846, "eval_episode/length": 184.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 130000, "time": 6458.3526957035065, "eval_episode/length": 187.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 130000, "time": 6460.709140062332, "eval_episode/length": 44.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 130040, "time": 6461.860666513443, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 130176, "time": 6468.387238025665, "episode/length": 40.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 130336, "time": 6475.436698675156, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 130416, "time": 6483.797403097153, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 130592, "time": 6491.4223301410675, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 130824, "time": 6500.615124702454, "episode/length": 108.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 130880, "time": 6504.51350235939, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 131248, "time": 6520.086273431778, "episode/length": 52.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 131424, "time": 6527.5959668159485, "episode/length": 172.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 131608, "time": 6535.235145330429, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 131824, "time": 6544.448648691177, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 131904, "time": 6548.862704992294, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 132320, "time": 6564.723787307739, "episode/length": 179.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 132568, "time": 6574.417938232422, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 132800, "time": 6584.187114477158, "episode/length": 327.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 132840, "time": 6586.860827445984, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 132912, "time": 6591.042318105698, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 132992, "time": 6595.313951253891, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 133344, "time": 6609.154910802841, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 133720, "time": 6624.064020872116, "episode/length": 226.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 133992, "time": 6634.796683073044, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 134024, "time": 6637.51261472702, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 134392, "time": 6651.626998901367, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 134400, "time": 6653.716990709305, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 134496, "time": 6658.526903867722, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 134576, "time": 6662.803283691406, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 134624, "time": 6666.015758752823, "episode/length": 159.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 135272, "time": 6689.550375699997, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 135344, "time": 6693.843663930893, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 135504, "time": 6701.084978818893, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 135584, "time": 6705.427478313446, "episode/length": 148.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 135752, "time": 6712.506395339966, "episode/length": 156.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 135880, "time": 6718.47346496582, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 135968, "time": 6723.308089733124, "episode/length": 173.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 136120, "time": 6730.027450323105, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 136976, "time": 6761.147569894791, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 136992, "time": 6763.276342868805, "episode/length": 205.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 137096, "time": 6768.275458097458, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 137304, "time": 6776.9959926605225, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 137328, "time": 6779.5414299964905, "episode/length": 217.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 137496, "time": 6786.506263971329, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 137800, "time": 6798.433338165283, "episode/length": 315.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.0}
{"step": 137840, "time": 6801.515894174576, "episode/length": 42.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 138312, "time": 6818.845599651337, "episode/length": 166.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 138328, "time": 6821.160115003586, "episode/length": 352.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943342776203966, "episode/intrinsic_return": 0.0}
{"step": 138376, "time": 6824.517392873764, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 138664, "time": 6835.840710878372, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 138808, "time": 6842.4031620025635, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 138880, "time": 6847.203468084335, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 139072, "time": 6855.376727581024, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 139592, "time": 6875.945334672928, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 139656, "time": 6879.7873775959015, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 139696, "time": 6882.8147530555725, "episode/length": 324.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 139728, "time": 6885.520836353302, "episode/length": 132.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 139944, "time": 6894.1894998550415, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 140048, "time": 6899.6814386844635, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6919.031146287918, "eval_episode/length": 75.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9342105263157895}
{"step": 140088, "time": 6924.382163286209, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 140088, "time": 6926.371565103531, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 140088, "time": 6928.515388250351, "eval_episode/length": 168.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 140088, "time": 6930.626960277557, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 140088, "time": 6933.965482234955, "eval_episode/length": 192.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 140088, "time": 6936.076977491379, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 140088, "time": 6939.352464199066, "eval_episode/length": 230.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 140496, "time": 6953.447069644928, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 140752, "time": 6963.568704128265, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 141104, "time": 6977.0913252830505, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 141192, "time": 6981.57962679863, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 141344, "time": 6988.53520321846, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 141512, "time": 6995.640842437744, "episode/length": 231.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 141696, "time": 7003.778946876526, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 141920, "time": 7013.037461280823, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 141928, "time": 7014.671928882599, "episode/length": 72.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9452054794520548, "episode/intrinsic_return": 0.0}
{"step": 142000, "time": 7018.96041059494, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 142144, "time": 7025.455869436264, "episode/length": 301.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9867549668874173, "episode/intrinsic_return": 0.0}
{"step": 142288, "time": 7032.042221546173, "episode/length": 45.0, "episode/score": -0.9000000283122063, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 142456, "time": 7039.116208791733, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 142992, "time": 7059.089956998825, "episode/length": 235.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 143296, "time": 7071.268794298172, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 143328, "time": 7073.932348012924, "episode/length": 203.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 143720, "time": 7088.648877382278, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627906976744186, "episode/intrinsic_return": 0.0}
{"step": 143736, "time": 7090.829477071762, "episode/length": 198.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 143784, "time": 7094.043215036392, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 143856, "time": 7098.332745790482, "episode/length": 240.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 143936, "time": 7102.54136633873, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 144576, "time": 7125.76443696022, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 144656, "time": 7130.030560493469, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 144960, "time": 7141.932634353638, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 144984, "time": 7144.099617958069, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 145120, "time": 7150.672827005386, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 145136, "time": 7152.742702722549, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 145776, "time": 7176.1458377838135, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 145800, "time": 7178.489303588867, "episode/length": 82.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.927710843373494, "episode/intrinsic_return": 0.0}
{"step": 145928, "time": 7184.736776828766, "episode/length": 168.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 145960, "time": 7187.43132686615, "episode/length": 124.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 146072, "time": 7192.761602878571, "episode/length": 135.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 146112, "time": 7195.90855717659, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 146112, "time": 7195.91916179657, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 146136, "time": 7199.792051315308, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 146544, "time": 7215.64900970459, "episode/length": 50.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 146600, "time": 7218.962454080582, "episode/length": 184.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 147136, "time": 7238.8360247612, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 147208, "time": 7242.907987356186, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.948905109489051, "episode/intrinsic_return": 0.0}
{"step": 147368, "time": 7249.958436012268, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 147392, "time": 7252.500424623489, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 147408, "time": 7254.551662445068, "episode/length": 33.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 147408, "time": 7254.561982154846, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 147416, "time": 7258.085663557053, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 147432, "time": 7260.20588183403, "episode/length": 27.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8214285714285714, "episode/intrinsic_return": 0.0}
{"step": 148064, "time": 7300.465517759323, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 148248, "time": 7308.015311002731, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 148256, "time": 7310.147459030151, "episode/length": 102.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 148489, "time": 7320.3394939899445, "train_stats/sum_log_reward": 4.4666666203488905, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.041666666666667, "train_stats/max_log_achievement_collect_sapling": 2.433333333333333, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.9583333333333335, "train_stats/max_log_achievement_defeat_skeleton": 0.016666666666666666, "train_stats/max_log_achievement_defeat_zombie": 0.2833333333333333, "train_stats/max_log_achievement_eat_cow": 0.10833333333333334, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05, "train_stats/max_log_achievement_make_wood_sword": 0.016666666666666666, "train_stats/max_log_achievement_place_plant": 2.2666666666666666, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.0833333333333333, "train_stats/max_log_achievement_wake_up": 1.5416666666666667, "train_stats/mean_log_entropy": 0.5636179355283578, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.982345346304086, "train/action_min": 0.0, "train/action_std": 3.455865639906663, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05292555603843469, "train/actor_opt_grad_steps": 8535.0, "train/actor_opt_loss": 3.184315932255525, "train/adv_mag": 1.016888971053637, "train/adv_max": 1.0145251723436208, "train/adv_mean": 0.005769387092564452, "train/adv_min": -0.5284590175518623, "train/adv_std": 0.09258608646117723, "train/cont_avg": 0.9941331129807692, "train/cont_loss_mean": 0.0004966352515728326, "train/cont_loss_std": 0.013203492196603642, "train/cont_neg_acc": 0.9831746046359723, "train/cont_neg_loss": 0.05346683729855368, "train/cont_pos_acc": 0.9999621744339283, "train/cont_pos_loss": 0.0002036348445772299, "train/cont_pred": 0.9941228348475236, "train/cont_rate": 0.9941331129807692, "train/dyn_loss_mean": 14.417341877863958, "train/dyn_loss_std": 9.16172912304218, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.072770458459854, "train/extr_critic_critic_opt_grad_steps": 8535.0, "train/extr_critic_critic_opt_loss": 15345.612958233172, "train/extr_critic_mag": 3.6899290029819194, "train/extr_critic_max": 3.6899290029819194, "train/extr_critic_mean": 0.6752998748650918, "train/extr_critic_min": -0.2628893833893996, "train/extr_critic_std": 0.8510726690292358, "train/extr_return_normed_mag": 2.1546140184769262, "train/extr_return_normed_max": 2.1546140184769262, "train/extr_return_normed_mean": 0.3452960734183972, "train/extr_return_normed_min": -0.17366924348932047, "train/extr_return_normed_std": 0.3650328085972713, "train/extr_return_rate": 0.41021035806490824, "train/extr_return_raw_mag": 5.129880144045903, "train/extr_return_raw_max": 5.129880144045903, "train/extr_return_raw_mean": 0.6894434087551558, "train/extr_return_raw_min": -0.5839879455474707, "train/extr_return_raw_std": 0.8960966247778672, "train/extr_reward_mag": 1.0073794236549964, "train/extr_reward_max": 1.0073794236549964, "train/extr_reward_mean": 0.016573873405846266, "train/extr_reward_min": -0.29649390624119687, "train/extr_reward_std": 0.11737692665595274, "train/image_loss_mean": 13.758394175309402, "train/image_loss_std": 15.740894214923566, "train/model_loss_mean": 22.46453869159405, "train/model_loss_std": 19.731085637899547, "train/model_opt_grad_norm": 88.12136373593826, "train/model_opt_grad_steps": 8523.238461538462, "train/model_opt_loss": 14933.240166766827, "train/model_opt_model_opt_grad_overflow": 0.007692307692307693, "train/model_opt_model_opt_grad_scale": 658.6538461538462, "train/policy_entropy_mag": 2.4112938990959756, "train/policy_entropy_max": 2.4112938990959756, "train/policy_entropy_mean": 0.6004966722084926, "train/policy_entropy_min": 0.07937980420314349, "train/policy_entropy_std": 0.49741987310923064, "train/policy_logprob_mag": 7.438361116556021, "train/policy_logprob_max": -0.0094567612458307, "train/policy_logprob_mean": -0.6007244644256738, "train/policy_logprob_min": -7.438361116556021, "train/policy_logprob_std": 1.1098868012428285, "train/policy_randomness_mag": 0.8510809311499963, "train/policy_randomness_max": 0.8510809311499963, "train/policy_randomness_mean": 0.21194897362819085, "train/policy_randomness_min": 0.028017587415300884, "train/policy_randomness_std": 0.17556738704442978, "train/post_ent_mag": 53.30303702721229, "train/post_ent_max": 53.30303702721229, "train/post_ent_mean": 37.57793822655311, "train/post_ent_min": 20.39356969686655, "train/post_ent_std": 5.518554548116831, "train/prior_ent_mag": 64.66318887563853, "train/prior_ent_max": 64.66318887563853, "train/prior_ent_mean": 52.189869807316704, "train/prior_ent_min": 25.083530323322, "train/prior_ent_std": 7.371444518749531, "train/rep_loss_mean": 14.417341877863958, "train/rep_loss_std": 9.16172912304218, "train/reward_avg": 0.01780799260506263, "train/reward_loss_mean": 0.05524278730154038, "train/reward_loss_std": 0.273569592833519, "train/reward_max_data": 1.0076923095262968, "train/reward_max_pred": 1.0038273572921752, "train/reward_neg_acc": 0.9930556324812082, "train/reward_neg_loss": 0.03329918958389988, "train/reward_pos_acc": 0.9393473029136657, "train/reward_pos_loss": 1.005437015570127, "train/reward_pred": 0.016871477520236603, "train/reward_rate": 0.022919170673076923, "eval_stats/sum_log_reward": 3.9749999684281647, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.6875, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.6875, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00041290096123702824, "report/cont_loss_std": 0.012201005592942238, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.08154644817113876, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4797198673477396e-05, "report/cont_pred": 0.9954351186752319, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 16.865447998046875, "report/dyn_loss_std": 9.628307342529297, "report/image_loss_mean": 17.41860580444336, "report/image_loss_std": 26.911317825317383, "report/model_loss_mean": 27.623435974121094, "report/model_loss_std": 30.811569213867188, "report/post_ent_mag": 54.92784118652344, "report/post_ent_max": 54.92784118652344, "report/post_ent_mean": 38.66504669189453, "report/post_ent_min": 21.03396987915039, "report/post_ent_std": 5.5259246826171875, "report/prior_ent_mag": 65.02972412109375, "report/prior_ent_max": 65.02972412109375, "report/prior_ent_mean": 55.42543411254883, "report/prior_ent_min": 28.749467849731445, "report/prior_ent_std": 6.20282506942749, "report/rep_loss_mean": 16.865447998046875, "report/rep_loss_std": 9.628307342529297, "report/reward_avg": 0.01425781287252903, "report/reward_loss_mean": 0.08514843881130219, "report/reward_loss_std": 0.4599928855895996, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001882553100586, "report/reward_neg_acc": 0.9930139780044556, "report/reward_neg_loss": 0.05605875700712204, "report/reward_pos_acc": 0.8636363744735718, "report/reward_pos_loss": 1.4100509881973267, "report/reward_pred": 0.010881254449486732, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.00038825429510325193, "eval/cont_loss_std": 0.009015374816954136, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.035383839160203934, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.0002510166959837079, "eval/cont_pred": 0.9960026144981384, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.240242958068848, "eval/dyn_loss_std": 8.652042388916016, "eval/image_loss_mean": 10.804084777832031, "eval/image_loss_std": 8.800811767578125, "eval/model_loss_mean": 20.004112243652344, "eval/model_loss_std": 12.326411247253418, "eval/post_ent_mag": 54.07195281982422, "eval/post_ent_max": 54.07195281982422, "eval/post_ent_mean": 38.46363830566406, "eval/post_ent_min": 20.633037567138672, "eval/post_ent_std": 5.323474884033203, "eval/prior_ent_mag": 65.02972412109375, "eval/prior_ent_max": 65.02972412109375, "eval/prior_ent_mean": 50.77961730957031, "eval/prior_ent_min": 22.858436584472656, "eval/prior_ent_std": 6.519493103027344, "eval/rep_loss_mean": 15.240242958068848, "eval/rep_loss_std": 8.652042388916016, "eval/reward_avg": 0.0029296872671693563, "eval/reward_loss_mean": 0.055495262145996094, "eval/reward_loss_std": 0.3611070215702057, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000633716583252, "eval/reward_neg_acc": 0.9980295896530151, "eval/reward_neg_loss": 0.04289519414305687, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 1.4765030145645142, "eval/reward_pred": 0.0032748158555477858, "eval/reward_rate": 0.0087890625, "replay/size": 147985.0, "replay/inserts": 20800.0, "replay/samples": 20800.0, "replay/insert_wait_avg": 1.3929490859691913e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.812105692349947e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 30024.0, "eval_replay/inserts": 3464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2583738111183219e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0948348045349, "timer/env.step_count": 2600.0, "timer/env.step_total": 266.3118269443512, "timer/env.step_frac": 0.26628657370918324, "timer/env.step_avg": 0.10242762574782738, "timer/env.step_min": 0.02401876449584961, "timer/env.step_max": 3.505025625228882, "timer/replay._sample_count": 20800.0, "timer/replay._sample_total": 11.658872365951538, "timer/replay._sample_frac": 0.011657766803915375, "timer/replay._sample_avg": 0.0005605227099015163, "timer/replay._sample_min": 0.00039386749267578125, "timer/replay._sample_max": 0.012092351913452148, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3033.0, "timer/agent.policy_total": 52.988553047180176, "timer/agent.policy_frac": 0.052983528364624145, "timer/agent.policy_avg": 0.017470673606060066, "timer/agent.policy_min": 0.00986933708190918, "timer/agent.policy_max": 0.11451435089111328, "timer/dataset_train_count": 1300.0, "timer/dataset_train_total": 0.15933966636657715, "timer/dataset_train_frac": 0.00015932455685337035, "timer/dataset_train_avg": 0.00012256897412813626, "timer/dataset_train_min": 0.00010561943054199219, "timer/dataset_train_max": 0.0006456375122070312, "timer/agent.train_count": 1300.0, "timer/agent.train_total": 590.5746765136719, "timer/agent.train_frac": 0.5905186747905738, "timer/agent.train_avg": 0.45428821270282455, "timer/agent.train_min": 0.4382319450378418, "timer/agent.train_max": 1.5371170043945312, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47716546058654785, "timer/agent.report_frac": 0.0004771202129844098, "timer/agent.report_avg": 0.23858273029327393, "timer/agent.report_min": 0.22751355171203613, "timer/agent.report_max": 0.24965190887451172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.409062383387568e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 20.79774649890414}
{"step": 148672, "time": 7326.6569900512695, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 148888, "time": 7335.483763933182, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 148888, "time": 7335.49530673027, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 149072, "time": 7345.343537807465, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 149208, "time": 7351.281377315521, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 149760, "time": 7372.004247665405, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 149936, "time": 7379.544575452805, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7400.720237016678, "eval_episode/length": 46.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 150072, "time": 7407.380549192429, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 150072, "time": 7410.121000289917, "eval_episode/length": 185.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 150072, "time": 7412.054144859314, "eval_episode/length": 192.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 150072, "time": 7414.529618501663, "eval_episode/length": 212.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 150072, "time": 7416.237699747086, "eval_episode/length": 214.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9953488372093023}
{"step": 150072, "time": 7419.373022556305, "eval_episode/length": 33.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 150072, "time": 7421.57066988945, "eval_episode/length": 256.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9727626459143969}
{"step": 150096, "time": 7422.620158910751, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 150240, "time": 7429.1337015628815, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 150248, "time": 7430.776977300644, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 150368, "time": 7446.059453010559, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 150416, "time": 7451.240516901016, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 150592, "time": 7458.906176567078, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 150768, "time": 7467.93940114975, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 151200, "time": 7484.283368110657, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 151480, "time": 7495.139686584473, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 151600, "time": 7501.064087867737, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 151728, "time": 7507.024344921112, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 151736, "time": 7508.753597736359, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 152024, "time": 7520.2378532886505, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 152096, "time": 7524.495677947998, "episode/length": 187.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 152152, "time": 7527.833443403244, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 153040, "time": 7559.8868663311005, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 153056, "time": 7561.99830198288, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 153208, "time": 7568.550909996033, "episode/length": 250.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 153256, "time": 7571.982987165451, "episode/length": 190.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 153472, "time": 7581.150026082993, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 153512, "time": 7583.874687671661, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 153528, "time": 7585.964625120163, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 153576, "time": 7589.162530183792, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 154192, "time": 7612.124650716782, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 154384, "time": 7620.216237545013, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 154576, "time": 7628.234459638596, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 154728, "time": 7634.931509017944, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 154752, "time": 7637.661751270294, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 154856, "time": 7642.537386894226, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 154880, "time": 7645.211480379105, "episode/length": 175.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 154960, "time": 7649.53206205368, "episode/length": 218.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 155152, "time": 7657.6976001262665, "episode/length": 119.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 155200, "time": 7660.967032670975, "episode/length": 39.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 155320, "time": 7666.519049167633, "episode/length": 73.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 156080, "time": 7695.609313964844, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 156144, "time": 7699.3771369457245, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 156416, "time": 7710.330726861954, "episode/length": 194.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 156520, "time": 7715.988932132721, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 156568, "time": 7719.221935272217, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 156824, "time": 7729.681829690933, "episode/length": 232.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 156864, "time": 7732.871413946152, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 157144, "time": 7743.764068603516, "episode/length": 132.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 157224, "time": 7748.050034999847, "episode/length": 44.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 157344, "time": 7754.181143522263, "episode/length": 149.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 157728, "time": 7768.818163633347, "episode/length": 300.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 157752, "time": 7770.986803770065, "episode/length": 50.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 158184, "time": 7787.351004600525, "episode/length": 56.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 158256, "time": 7791.732267379761, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 158424, "time": 7798.7068128585815, "episode/length": 231.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 158472, "time": 7801.882864952087, "episode/length": 256.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 158544, "time": 7806.153545618057, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 158576, "time": 7808.847988843918, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 158816, "time": 7818.712784767151, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 158960, "time": 7825.139608383179, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 159584, "time": 7847.909131765366, "episode/length": 174.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 159760, "time": 7855.588045358658, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 159872, "time": 7861.009995222092, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7885.08963060379, "eval_episode/length": 35.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 160056, "time": 7887.3222115039825, "eval_episode/length": 48.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 160056, "time": 7893.319363355637, "eval_episode/length": 149.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 160056, "time": 7895.173343420029, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 160056, "time": 7897.466282367706, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 160056, "time": 7900.155659675598, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 160056, "time": 7901.864751338959, "eval_episode/length": 194.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 160056, "time": 7904.031059503555, "eval_episode/length": 207.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 160088, "time": 7905.1142246723175, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 160536, "time": 7921.990486860275, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 160584, "time": 7925.2002375125885, "episode/length": 61.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 160720, "time": 7931.805699825287, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 160728, "time": 7933.333783388138, "episode/length": 272.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 160936, "time": 7942.063912153244, "episode/length": 307.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 161264, "time": 7954.950040102005, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 161528, "time": 7965.287806034088, "episode/length": 242.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 161672, "time": 7971.693283319473, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 162064, "time": 7986.691687107086, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 162168, "time": 7991.646158456802, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 162208, "time": 7994.950964212418, "episode/length": 202.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 162448, "time": 8004.591726779938, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 162952, "time": 8023.100638389587, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 163000, "time": 8026.363297700882, "episode/length": 283.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 163024, "time": 8028.955586194992, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 163184, "time": 8036.025454282761, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 163232, "time": 8039.193603992462, "episode/length": 145.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 163480, "time": 8049.0171065330505, "episode/length": 128.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 163760, "time": 8060.507607698441, "episode/length": 198.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 163768, "time": 8062.244633674622, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 164208, "time": 8080.646377801895, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 164360, "time": 8087.263925790787, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 164440, "time": 8091.756075620651, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 164680, "time": 8101.414334774017, "episode/length": 186.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 165080, "time": 8116.880311489105, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 165088, "time": 8118.949138641357, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 165528, "time": 8135.247289896011, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 165592, "time": 8139.047597885132, "episode/length": 228.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 165696, "time": 8144.5303683280945, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 165704, "time": 8146.1479551792145, "episode/length": 167.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 166256, "time": 8166.63577580452, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 166320, "time": 8170.350163698196, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 166400, "time": 8174.579941987991, "episode/length": 244.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 166840, "time": 8190.768411159515, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 167112, "time": 8201.843302965164, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 167368, "time": 8212.199293851852, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 167592, "time": 8221.443582773209, "episode/length": 235.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 167648, "time": 8225.232615709305, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 167712, "time": 8228.963021993637, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 167816, "time": 8234.00557923317, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 167888, "time": 8238.252448320389, "episode/length": 203.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 168392, "time": 8256.783603191376, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 168896, "time": 8276.159618139267, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 169016, "time": 8281.508344173431, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 169024, "time": 8283.552249193192, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 169072, "time": 8286.929759263992, "episode/length": 184.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 169128, "time": 8290.326144695282, "episode/length": 219.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 169160, "time": 8293.001310110092, "episode/length": 95.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 169440, "time": 8304.209070920944, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 169568, "time": 8310.226578235626, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 169801, "time": 8320.589624643326, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.8756571604793235, "train/action_min": 0.0, "train/action_std": 3.4230139345154726, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050599821612126845, "train/actor_opt_grad_steps": 9850.0, "train/actor_opt_loss": 0.7306200414896011, "train/adv_mag": 0.8885169239868795, "train/adv_max": 0.8863271497246018, "train/adv_mean": 0.004711887785034426, "train/adv_min": -0.5029543118369311, "train/adv_std": 0.08535814590584066, "train/cont_avg": 0.9947647438909775, "train/cont_loss_mean": 0.000514720984504196, "train/cont_loss_std": 0.013924355741172055, "train/cont_neg_acc": 0.9807912671476379, "train/cont_neg_loss": 0.054951525325088735, "train/cont_pos_acc": 0.9999113723747712, "train/cont_pos_loss": 0.00024413608589022022, "train/cont_pred": 0.9947572628358253, "train/cont_rate": 0.9947647438909775, "train/dyn_loss_mean": 15.064194464145746, "train/dyn_loss_std": 9.466347321531826, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0972979870953954, "train/extr_critic_critic_opt_grad_steps": 9850.0, "train/extr_critic_critic_opt_loss": 15409.364507460057, "train/extr_critic_mag": 3.757884312393074, "train/extr_critic_max": 3.757884312393074, "train/extr_critic_mean": 0.6506491919657341, "train/extr_critic_min": -0.26634730163373443, "train/extr_critic_std": 0.852772957848427, "train/extr_return_normed_mag": 1.9361164704301304, "train/extr_return_normed_max": 1.9361164704301304, "train/extr_return_normed_mean": 0.30813272689518173, "train/extr_return_normed_min": -0.16397560247801302, "train/extr_return_normed_std": 0.3375530006518041, "train/extr_return_rate": 0.3770363600854587, "train/extr_return_raw_mag": 4.961787533939333, "train/extr_return_raw_max": 4.961787533939333, "train/extr_return_raw_mean": 0.6630980764564715, "train/extr_return_raw_min": -0.5829743960298094, "train/extr_return_raw_std": 0.8913952627576384, "train/extr_reward_mag": 1.0087180254154635, "train/extr_reward_max": 1.0087180254154635, "train/extr_reward_mean": 0.016708194729837037, "train/extr_reward_min": -0.31670805206872465, "train/extr_reward_std": 0.11738828838543784, "train/image_loss_mean": 13.192854142726812, "train/image_loss_std": 16.422947797560155, "train/model_loss_mean": 22.286927000920574, "train/model_loss_std": 20.476798860650312, "train/model_opt_grad_norm": 84.55767942729749, "train/model_opt_grad_steps": 9836.924812030074, "train/model_opt_loss": 15071.831862370771, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 676.6917293233083, "train/policy_entropy_mag": 2.3985673771764997, "train/policy_entropy_max": 2.3985673771764997, "train/policy_entropy_mean": 0.595456884319621, "train/policy_entropy_min": 0.07937705046252201, "train/policy_entropy_std": 0.529257678671887, "train/policy_logprob_mag": 7.438373382826497, "train/policy_logprob_max": -0.009456214291932887, "train/policy_logprob_mean": -0.5945426756726172, "train/policy_logprob_min": -7.438373382826497, "train/policy_logprob_std": 1.1119569988179028, "train/policy_randomness_mag": 0.846589027490831, "train/policy_randomness_max": 0.846589027490831, "train/policy_randomness_mean": 0.21017015193189895, "train/policy_randomness_min": 0.028016615406911177, "train/policy_randomness_std": 0.18680473669130998, "train/post_ent_mag": 54.76108338779077, "train/post_ent_max": 54.76108338779077, "train/post_ent_mean": 38.34207867500477, "train/post_ent_min": 20.779772995109845, "train/post_ent_std": 5.798500595236183, "train/prior_ent_mag": 65.57979732886292, "train/prior_ent_max": 65.57979732886292, "train/prior_ent_mean": 53.541370592619245, "train/prior_ent_min": 27.864808175796853, "train/prior_ent_std": 6.913393734092999, "train/rep_loss_mean": 15.064194464145746, "train/rep_loss_std": 9.466347321531826, "train/reward_avg": 0.01836157765561589, "train/reward_loss_mean": 0.055041684692067314, "train/reward_loss_std": 0.27052144426152225, "train/reward_max_data": 1.011278198177653, "train/reward_max_pred": 1.0049710838418258, "train/reward_neg_acc": 0.9929320113103193, "train/reward_neg_loss": 0.03262016296918903, "train/reward_pos_acc": 0.9423148708235949, "train/reward_pos_loss": 0.998474339345344, "train/reward_pred": 0.01740687555822551, "train/reward_rate": 0.02331267622180451, "train_stats/sum_log_reward": 4.526086919204048, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.791304347826087, "train_stats/max_log_achievement_collect_sapling": 2.7304347826086954, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.8956521739130436, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.391304347826087, "train_stats/max_log_achievement_eat_cow": 0.05217391304347826, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017391304347826087, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.4260869565217393, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.1130434782608696, "train_stats/max_log_achievement_wake_up": 1.5826086956521739, "train_stats/mean_log_entropy": 0.5713276703720508, "eval_stats/sum_log_reward": 4.28749992698431, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.25, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.8448117771185935e-05, "report/cont_loss_std": 0.0002463406417518854, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002734276233240962, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0468212167324964e-05, "report/cont_pred": 0.9970678687095642, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 16.032766342163086, "report/dyn_loss_std": 9.654328346252441, "report/image_loss_mean": 12.576740264892578, "report/image_loss_std": 18.09427261352539, "report/model_loss_mean": 22.223407745361328, "report/model_loss_std": 22.0206356048584, "report/post_ent_mag": 57.704933166503906, "report/post_ent_max": 57.704933166503906, "report/post_ent_mean": 38.623077392578125, "report/post_ent_min": 22.907760620117188, "report/post_ent_std": 6.25914192199707, "report/prior_ent_mag": 66.5572509765625, "report/prior_ent_max": 66.5572509765625, "report/prior_ent_mean": 54.483150482177734, "report/prior_ent_min": 26.044002532958984, "report/prior_ent_std": 7.398783206939697, "report/rep_loss_mean": 16.032766342163086, "report/rep_loss_std": 9.654328346252441, "report/reward_avg": 0.006640625186264515, "report/reward_loss_mean": 0.026989592239260674, "report/reward_loss_std": 0.18414287269115448, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000812292098999, "report/reward_neg_acc": 0.9970414042472839, "report/reward_neg_loss": 0.017348889261484146, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 1.0045570135116577, "report/reward_pred": 0.00634922506287694, "report/reward_rate": 0.009765625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.782721695548389e-06, "eval/cont_loss_std": 6.22662846581079e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00037287361919879913, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.709976332786027e-06, "eval/cont_pred": 0.9970647096633911, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.232205390930176, "eval/dyn_loss_std": 8.883735656738281, "eval/image_loss_mean": 10.42574691772461, "eval/image_loss_std": 13.991230010986328, "eval/model_loss_mean": 19.00305938720703, "eval/model_loss_std": 17.473222732543945, "eval/post_ent_mag": 53.249725341796875, "eval/post_ent_max": 53.249725341796875, "eval/post_ent_mean": 39.13691329956055, "eval/post_ent_min": 22.225345611572266, "eval/post_ent_std": 5.92073392868042, "eval/prior_ent_mag": 65.98650360107422, "eval/prior_ent_max": 65.98650360107422, "eval/prior_ent_mean": 50.09563446044922, "eval/prior_ent_min": 26.583772659301758, "eval/prior_ent_std": 7.891542911529541, "eval/rep_loss_mean": 14.232205390930176, "eval/rep_loss_std": 8.883735656738281, "eval/reward_avg": 0.01240234263241291, "eval/reward_loss_mean": 0.03798018395900726, "eval/reward_loss_std": 0.3032192587852478, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0007355213165283, "eval/reward_neg_acc": 0.9940535426139832, "eval/reward_neg_loss": 0.02835123986005783, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 0.6856875419616699, "eval/reward_pred": 0.01577412337064743, "eval/reward_rate": 0.0146484375, "replay/size": 169297.0, "replay/inserts": 21312.0, "replay/samples": 21312.0, "replay/insert_wait_avg": 1.3810758655135696e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.346451308276203e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 33744.0, "eval_replay/inserts": 3720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2254843147852087e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2387187480927, "timer/env.step_count": 2664.0, "timer/env.step_total": 260.0573399066925, "timer/env.step_frac": 0.25999527416033497, "timer/env.step_avg": 0.09761912158659629, "timer/env.step_min": 0.02410268783569336, "timer/env.step_max": 3.4027750492095947, "timer/replay._sample_count": 21312.0, "timer/replay._sample_total": 12.067701816558838, "timer/replay._sample_frac": 0.012064821717422495, "timer/replay._sample_avg": 0.0005662397624136091, "timer/replay._sample_min": 0.00037670135498046875, "timer/replay._sample_max": 0.02587437629699707, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3129.0, "timer/agent.policy_total": 56.13647413253784, "timer/agent.policy_frac": 0.056123076501976184, "timer/agent.policy_avg": 0.01794070761666278, "timer/agent.policy_min": 0.009778022766113281, "timer/agent.policy_max": 0.13635492324829102, "timer/dataset_train_count": 1332.0, "timer/dataset_train_total": 0.1635303497314453, "timer/dataset_train_frac": 0.00016349132128790344, "timer/dataset_train_avg": 0.0001227705328314154, "timer/dataset_train_min": 0.00010704994201660156, "timer/dataset_train_max": 0.0006527900695800781, "timer/agent.train_count": 1332.0, "timer/agent.train_total": 602.7656977176666, "timer/agent.train_frac": 0.6026218405863085, "timer/agent.train_avg": 0.4525268000883383, "timer/agent.train_min": 0.437366247177124, "timer/agent.train_max": 1.5819361209869385, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4860110282897949, "timer/agent.report_frac": 0.0004858950360350882, "timer/agent.report_avg": 0.24300551414489746, "timer/agent.report_min": 0.23518943786621094, "timer/agent.report_max": 0.250821590423584, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6226043701171875e-05, "timer/dataset_eval_frac": 2.621978454702955e-08, "timer/dataset_eval_avg": 2.6226043701171875e-05, "timer/dataset_eval_min": 2.6226043701171875e-05, "timer/dataset_eval_max": 2.6226043701171875e-05, "fps": 21.306640274869345}
{"step": 170040, "time": 8343.382301807404, "eval_episode/length": 36.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8648648648648649}
{"step": 170040, "time": 8349.205958127975, "eval_episode/length": 132.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9924812030075187}
{"step": 170040, "time": 8351.192576885223, "eval_episode/length": 138.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9712230215827338}
{"step": 170040, "time": 8354.285210132599, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9590643274853801}
{"step": 170040, "time": 8358.728659391403, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 170040, "time": 8361.414199352264, "eval_episode/length": 253.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.984251968503937}
{"step": 170040, "time": 8363.414207220078, "eval_episode/length": 261.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732824427480916}
{"step": 170040, "time": 8365.400228023529, "eval_episode/length": 268.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9814126394052045}
{"step": 170384, "time": 8377.33164358139, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 170416, "time": 8380.18003821373, "episode/length": 189.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 170464, "time": 8383.429320335388, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 170472, "time": 8385.157463550568, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 171056, "time": 8406.761818170547, "episode/length": 79.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 171168, "time": 8412.350102901459, "episode/length": 261.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.0}
{"step": 171184, "time": 8414.57418012619, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 171200, "time": 8416.708485603333, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 171640, "time": 8433.031825304031, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 171744, "time": 8438.340374708176, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 171832, "time": 8442.86892747879, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 172184, "time": 8458.173931837082, "episode/length": 43.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 172520, "time": 8471.633175611496, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 172720, "time": 8480.207885503769, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 172880, "time": 8487.340032339096, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 172896, "time": 8489.5137758255, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 173040, "time": 8495.989042758942, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 173088, "time": 8499.241022348404, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 173456, "time": 8513.606258153915, "episode/length": 51.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 173520, "time": 8517.406730651855, "episode/length": 291.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 173784, "time": 8527.787247657776, "episode/length": 157.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 173864, "time": 8532.250991344452, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 174024, "time": 8539.32577085495, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 174072, "time": 8542.55117726326, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 174144, "time": 8546.915380477905, "episode/length": 34.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 174256, "time": 8552.34743142128, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 174432, "time": 8560.000997781754, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 175064, "time": 8582.729409456253, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 175088, "time": 8585.238787651062, "episode/length": 126.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 175168, "time": 8589.599758148193, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 175288, "time": 8595.052062511444, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 175720, "time": 8611.350572109222, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 175976, "time": 8621.79595541954, "episode/length": 192.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 176144, "time": 8629.40019440651, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 176336, "time": 8637.504767656326, "episode/length": 23.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 176472, "time": 8643.473394155502, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 176536, "time": 8647.174265623093, "episode/length": 298.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9866220735785953, "episode/intrinsic_return": 0.0}
{"step": 176552, "time": 8649.361603736877, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 176632, "time": 8653.864810228348, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9562841530054644, "episode/intrinsic_return": 0.0}
{"step": 176904, "time": 8664.655411481857, "episode/length": 201.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 177200, "time": 8676.46079325676, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 177320, "time": 8681.988018512726, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 177800, "time": 8699.799364566803, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 177928, "time": 8705.749213218689, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 178088, "time": 8712.852249622345, "episode/length": 201.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 178400, "time": 8725.189779043198, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 178432, "time": 8727.91674375534, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 178472, "time": 8730.459939479828, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 178872, "time": 8745.644844055176, "episode/length": 291.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 178920, "time": 8748.870188951492, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 178968, "time": 8752.193247318268, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 179136, "time": 8759.737197637558, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 179408, "time": 8770.650553941727, "episode/length": 164.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 179736, "time": 8783.18458366394, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 179768, "time": 8785.861076116562, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 179936, "time": 8793.303158044815, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8819.5175075531, "eval_episode/length": 151.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 180024, "time": 8822.33462023735, "eval_episode/length": 176.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 180024, "time": 8824.06472826004, "eval_episode/length": 178.0, "eval_episode/score": 4.1000000312924385, "eval_episode/reward_rate": 0.994413407821229}
{"step": 180024, "time": 8826.246505260468, "eval_episode/length": 191.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 180024, "time": 8828.68742799759, "eval_episode/length": 209.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 180024, "time": 8830.869057416916, "eval_episode/length": 217.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 180024, "time": 8833.21271944046, "eval_episode/length": 236.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 180024, "time": 8836.47410440445, "eval_episode/length": 36.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.972972972972973}
{"step": 180224, "time": 8843.645422935486, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 180304, "time": 8849.574493646622, "episode/length": 45.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 180440, "time": 8855.441866636276, "episode/length": 189.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 180448, "time": 8857.588699102402, "episode/length": 163.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 180496, "time": 8860.927097558975, "episode/length": 6.0, "episode/score": -0.8999999761581421, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 180536, "time": 8863.647403478622, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 180824, "time": 8875.053752660751, "episode/length": 176.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 181000, "time": 8882.767394542694, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 181776, "time": 8911.02096414566, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 181928, "time": 8917.627828359604, "episode/length": 273.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 181936, "time": 8919.72763800621, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 182104, "time": 8926.810903072357, "episode/length": 195.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 182176, "time": 8931.02704668045, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 182184, "time": 8932.62136387825, "episode/length": 50.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 182304, "time": 8938.475811243057, "episode/length": 162.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 182376, "time": 8942.30131983757, "episode/length": 240.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 182648, "time": 8953.091203927994, "episode/length": 42.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 182680, "time": 8955.707123041153, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 183080, "time": 8970.825832128525, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 183520, "time": 8987.648736715317, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 183576, "time": 8991.034988641739, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 183632, "time": 8994.741683483124, "episode/length": 212.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9906103286384976, "episode/intrinsic_return": 0.0}
{"step": 183896, "time": 9005.30804491043, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 184016, "time": 9011.35016489029, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 184376, "time": 9024.940403223038, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 184608, "time": 9034.628098249435, "episode/length": 312.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 184808, "time": 9042.888266324997, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 184840, "time": 9045.582222700119, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 185088, "time": 9055.813261032104, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 185304, "time": 9064.579194307327, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 185456, "time": 9071.615501880646, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730639730639731, "episode/intrinsic_return": 0.0}
{"step": 185704, "time": 9081.349915504456, "episode/length": 165.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 185752, "time": 9084.549864053726, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 186000, "time": 9094.693034648895, "episode/length": 148.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 186032, "time": 9097.44800567627, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 186632, "time": 9119.16439318657, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 186752, "time": 9125.182314157486, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 186872, "time": 9130.7761054039, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 186960, "time": 9135.51165151596, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 186968, "time": 9137.091581106186, "episode/length": 234.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 187280, "time": 9149.393487930298, "episode/length": 39.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 187520, "time": 9159.011617422104, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 187608, "time": 9163.638034582138, "episode/length": 231.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 188008, "time": 9178.810227870941, "episode/length": 287.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826388888888888, "episode/intrinsic_return": 0.0}
{"step": 188128, "time": 9184.709594488144, "episode/length": 265.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 188280, "time": 9191.407106399536, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 188640, "time": 9206.892050266266, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 189024, "time": 9221.567199230194, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 189040, "time": 9223.7240588665, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 189072, "time": 9226.406607151031, "episode/length": 262.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 189480, "time": 9241.50300359726, "episode/length": 274.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 189512, "time": 9244.281516313553, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 189768, "time": 9254.572569131851, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 189824, "time": 9258.350026845932, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9285.664407730103, "eval_episode/length": 148.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731543624161074}
{"step": 190008, "time": 9287.755598068237, "eval_episode/length": 159.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 190008, "time": 9289.671375274658, "eval_episode/length": 167.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 190008, "time": 9291.61561870575, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 190008, "time": 9293.307235956192, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9550561797752809}
{"step": 190008, "time": 9295.187875509262, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9672131147540983}
{"step": 190008, "time": 9298.753608703613, "eval_episode/length": 224.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 190008, "time": 9303.8853161335, "eval_episode/length": 296.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.98989898989899}
{"step": 190312, "time": 9315.384725570679, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 190336, "time": 9318.06280875206, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 190345, "time": 9320.752484083176, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6322447311046515, "train/action_min": 0.0, "train/action_std": 3.3578310105227684, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05008455010694127, "train/actor_opt_grad_steps": 11160.0, "train/actor_opt_loss": 6.462283564572648, "train/adv_mag": 0.8287216027577718, "train/adv_max": 0.8139291752216428, "train/adv_mean": 0.00674248752486249, "train/adv_min": -0.514623012653617, "train/adv_std": 0.08335857179968856, "train/cont_avg": 0.9947311046511628, "train/cont_loss_mean": 0.0002543802208289789, "train/cont_loss_std": 0.0069208855821968895, "train/cont_neg_acc": 0.9904761924300083, "train/cont_neg_loss": 0.02037813540520322, "train/cont_pos_acc": 0.9999467291573222, "train/cont_pos_loss": 0.00015101909958865675, "train/cont_pred": 0.9946939492410467, "train/cont_rate": 0.9947311046511628, "train/dyn_loss_mean": 15.532720151797745, "train/dyn_loss_std": 9.555897956670718, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0098222979279452, "train/extr_critic_critic_opt_grad_steps": 11160.0, "train/extr_critic_critic_opt_loss": 15451.347557836725, "train/extr_critic_mag": 3.86610812179802, "train/extr_critic_max": 3.86610812179802, "train/extr_critic_mean": 0.7231091018332991, "train/extr_critic_min": -0.26066381617109907, "train/extr_critic_std": 0.9076494181803031, "train/extr_return_normed_mag": 1.834577477255533, "train/extr_return_normed_max": 1.834577477255533, "train/extr_return_normed_mean": 0.30984922527342806, "train/extr_return_normed_min": -0.16990032110565392, "train/extr_return_normed_std": 0.3367634146481521, "train/extr_return_rate": 0.41519705131072404, "train/extr_return_raw_mag": 5.047069098598273, "train/extr_return_raw_max": 5.047069098598273, "train/extr_return_raw_mean": 0.7421114710412284, "train/extr_return_raw_min": -0.6133551528287489, "train/extr_return_raw_std": 0.9514626236849053, "train/extr_reward_mag": 1.0113830705021702, "train/extr_reward_max": 1.0113830705021702, "train/extr_reward_mean": 0.01805123442047557, "train/extr_reward_min": -0.35826558475346526, "train/extr_reward_std": 0.12124713383210722, "train/image_loss_mean": 12.540448314459749, "train/image_loss_std": 15.783090110897094, "train/model_loss_mean": 21.914872627849725, "train/model_loss_std": 19.85916586439739, "train/model_opt_grad_norm": 81.20482150528782, "train/model_opt_grad_steps": 11145.98449612403, "train/model_opt_loss": 18496.356891957363, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 852.7131782945736, "train/policy_entropy_mag": 2.435060743213624, "train/policy_entropy_max": 2.435060743213624, "train/policy_entropy_mean": 0.5804107651229977, "train/policy_entropy_min": 0.07937601220238116, "train/policy_entropy_std": 0.5382385743680851, "train/policy_logprob_mag": 7.438376223394113, "train/policy_logprob_max": -0.009455969780972299, "train/policy_logprob_mean": -0.5798713366190592, "train/policy_logprob_min": -7.438376223394113, "train/policy_logprob_std": 1.1049737269564193, "train/policy_randomness_mag": 0.8594695828681769, "train/policy_randomness_max": 0.8594695828681769, "train/policy_randomness_mean": 0.20485952912374986, "train/policy_randomness_min": 0.028016248977808064, "train/policy_randomness_std": 0.1899745978357256, "train/post_ent_mag": 55.914982019468795, "train/post_ent_max": 55.914982019468795, "train/post_ent_mean": 38.713729799255844, "train/post_ent_min": 21.315830363783725, "train/post_ent_std": 6.102161551630775, "train/prior_ent_mag": 66.28830523823582, "train/prior_ent_max": 66.28830523823582, "train/prior_ent_mean": 54.4368449070657, "train/prior_ent_min": 29.907722621001014, "train/prior_ent_std": 6.569181797116301, "train/rep_loss_mean": 15.532720151797745, "train/rep_loss_std": 9.555897956670718, "train/reward_avg": 0.019132297522164592, "train/reward_loss_mean": 0.054537991162880446, "train/reward_loss_std": 0.26867365952610045, "train/reward_max_data": 1.0093023277992426, "train/reward_max_pred": 1.006352884824886, "train/reward_neg_acc": 0.9932819484740265, "train/reward_neg_loss": 0.03189444586692392, "train/reward_pos_acc": 0.9445323468178741, "train/reward_pos_loss": 0.9791249041409456, "train/reward_pred": 0.017968566669512166, "train/reward_rate": 0.02404312015503876, "eval_stats/sum_log_reward": 4.724999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.208333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.2083333333333335, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.2916666666666665, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.25, "eval_stats/max_log_achievement_wake_up": 1.8333333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 4.43035709844636, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.571428571428571, "train_stats/max_log_achievement_collect_sapling": 2.017857142857143, "train_stats/max_log_achievement_collect_stone": 0.017857142857142856, "train_stats/max_log_achievement_collect_wood": 3.8035714285714284, "train_stats/max_log_achievement_defeat_skeleton": 0.008928571428571428, "train_stats/max_log_achievement_defeat_zombie": 0.30357142857142855, "train_stats/max_log_achievement_eat_cow": 0.10714285714285714, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03571428571428571, "train_stats/max_log_achievement_make_wood_sword": 0.008928571428571428, "train_stats/max_log_achievement_place_plant": 1.7678571428571428, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 1.5535714285714286, "train_stats/max_log_achievement_wake_up": 1.5982142857142858, "train_stats/mean_log_entropy": 0.5550374451226422, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.586471939343028e-05, "report/cont_loss_std": 0.0006813262589275837, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.007307789754122496, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.830452447393327e-07, "report/cont_pred": 0.995152473449707, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.367473602294922, "report/dyn_loss_std": 9.255640983581543, "report/image_loss_mean": 11.090970993041992, "report/image_loss_std": 13.086152076721191, "report/model_loss_mean": 20.3804931640625, "report/model_loss_std": 16.993104934692383, "report/post_ent_mag": 55.157127380371094, "report/post_ent_max": 55.157127380371094, "report/post_ent_mean": 38.716033935546875, "report/post_ent_min": 19.735532760620117, "report/post_ent_std": 6.602475166320801, "report/prior_ent_mag": 67.01521301269531, "report/prior_ent_max": 67.01521301269531, "report/prior_ent_mean": 54.901611328125, "report/prior_ent_min": 27.39413833618164, "report/prior_ent_std": 7.403421401977539, "report/rep_loss_mean": 15.367473602294922, "report/rep_loss_std": 9.255640983581543, "report/reward_avg": 0.02802734076976776, "report/reward_loss_mean": 0.06900350004434586, "report/reward_loss_std": 0.28840821981430054, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0085761547088623, "report/reward_neg_acc": 0.9929364323616028, "report/reward_neg_loss": 0.04014265537261963, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.9357033371925354, "report/reward_pred": 0.024246972054243088, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00013389578089118004, "eval/cont_loss_std": 0.0038116793148219585, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.04115641117095947, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.335948400082998e-05, "eval/cont_pred": 0.9971708059310913, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 14.363578796386719, "eval/dyn_loss_std": 9.377020835876465, "eval/image_loss_mean": 13.367984771728516, "eval/image_loss_std": 14.648214340209961, "eval/model_loss_mean": 22.09264373779297, "eval/model_loss_std": 18.60374641418457, "eval/post_ent_mag": 54.434112548828125, "eval/post_ent_max": 54.434112548828125, "eval/post_ent_mean": 39.26113510131836, "eval/post_ent_min": 19.708560943603516, "eval/post_ent_std": 5.764501094818115, "eval/prior_ent_mag": 66.75565338134766, "eval/prior_ent_max": 66.75565338134766, "eval/prior_ent_mean": 51.96846008300781, "eval/prior_ent_min": 24.84463119506836, "eval/prior_ent_std": 7.9277520179748535, "eval/rep_loss_mean": 14.363578796386719, "eval/rep_loss_std": 9.377020835876465, "eval/reward_avg": 0.01806640625, "eval/reward_loss_mean": 0.10637782514095306, "eval/reward_loss_std": 0.7743664383888245, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0034019947052002, "eval/reward_neg_acc": 0.9990040063858032, "eval/reward_neg_loss": 0.02966640703380108, "eval/reward_pos_acc": 0.5, "eval/reward_pos_loss": 3.9572911262512207, "eval/reward_pred": 0.007255673874169588, "eval/reward_rate": 0.01953125, "replay/size": 189841.0, "replay/inserts": 20544.0, "replay/samples": 20544.0, "replay/insert_wait_avg": 1.3545782209556794e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.913862804757472e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 40464.0, "eval_replay/inserts": 6720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1866646153586251e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.146621465683, "timer/env.step_count": 2568.0, "timer/env.step_total": 255.23358702659607, "timer/env.step_frac": 0.25519616979014476, "timer/env.step_avg": 0.0993900261006994, "timer/env.step_min": 0.023804664611816406, "timer/env.step_max": 3.187793016433716, "timer/replay._sample_count": 20544.0, "timer/replay._sample_total": 11.491101503372192, "timer/replay._sample_frac": 0.011489416908225266, "timer/replay._sample_avg": 0.0005593409999694409, "timer/replay._sample_min": 0.00043129920959472656, "timer/replay._sample_max": 0.012087583541870117, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3408.0, "timer/agent.policy_total": 59.13579201698303, "timer/agent.policy_frac": 0.059127122711589444, "timer/agent.policy_avg": 0.017352051648175774, "timer/agent.policy_min": 0.009666204452514648, "timer/agent.policy_max": 0.13138604164123535, "timer/dataset_train_count": 1284.0, "timer/dataset_train_total": 0.15808343887329102, "timer/dataset_train_frac": 0.0001580602638457397, "timer/dataset_train_avg": 0.00012311794304773445, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.0012965202331542969, "timer/agent.train_count": 1284.0, "timer/agent.train_total": 581.5114912986755, "timer/agent.train_frac": 0.5814262417309264, "timer/agent.train_avg": 0.4528905695472551, "timer/agent.train_min": 0.4357893466949463, "timer/agent.train_max": 1.6413278579711914, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4738919734954834, "timer/agent.report_frac": 0.00047382250094592113, "timer/agent.report_avg": 0.2369459867477417, "timer/agent.report_min": 0.2263338565826416, "timer/agent.report_max": 0.2475581169128418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.504753112792969e-05, "timer/dataset_eval_frac": 3.50423931608834e-08, "timer/dataset_eval_avg": 3.504753112792969e-05, "timer/dataset_eval_min": 3.504753112792969e-05, "timer/dataset_eval_max": 3.504753112792969e-05, "fps": 20.54067232414701}
{"step": 190448, "time": 9324.261945962906, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 190496, "time": 9327.436292648315, "episode/length": 126.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.952755905511811, "episode/intrinsic_return": 0.0}
{"step": 190784, "time": 9338.720653533936, "episode/length": 158.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 191048, "time": 9349.890691280365, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 191224, "time": 9357.401141881943, "episode/length": 21.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 191488, "time": 9368.153733491898, "episode/length": 355.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9971910112359551, "episode/intrinsic_return": 0.0}
{"step": 191624, "time": 9374.19341301918, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 191720, "time": 9379.05627322197, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 191800, "time": 9383.266824483871, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 192040, "time": 9392.849572181702, "episode/length": 212.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 192216, "time": 9403.113945484161, "episode/length": 214.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 192704, "time": 9421.228716373444, "episode/length": 184.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 193016, "time": 9433.44711112976, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 193280, "time": 9444.1976416111, "episode/length": 223.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 193384, "time": 9449.040041923523, "episode/length": 324.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9876923076923076, "episode/intrinsic_return": 0.0}
{"step": 193520, "time": 9455.515411376953, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 193584, "time": 9459.856881141663, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 193808, "time": 9469.702939033508, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 194272, "time": 9486.898797512054, "episode/length": 278.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 194552, "time": 9497.785804271698, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 194816, "time": 9508.558157205582, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 194984, "time": 9515.573803186417, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 195008, "time": 9518.171107769012, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 195240, "time": 9527.667652845383, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 195360, "time": 9534.061980962753, "episode/length": 259.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 195480, "time": 9539.626627206802, "episode/length": 346.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 195608, "time": 9545.517472743988, "episode/length": 166.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 195832, "time": 9554.844642877579, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 196408, "time": 9575.719047784805, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 196512, "time": 9581.245611667633, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 196728, "time": 9591.399047374725, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 196832, "time": 9596.748412132263, "episode/length": 230.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 197096, "time": 9607.16383266449, "episode/length": 72.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 197104, "time": 9609.32608962059, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 197104, "time": 9609.335947990417, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 197232, "time": 9617.133968353271, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 197256, "time": 9619.565610170364, "episode/length": 280.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 197872, "time": 9642.838493347168, "episode/length": 79.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.925, "episode/intrinsic_return": 0.0}
{"step": 198120, "time": 9652.601855039597, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 198216, "time": 9657.423493862152, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.956989247311828, "episode/intrinsic_return": 0.0}
{"step": 198464, "time": 9667.468043088913, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 198496, "time": 9670.23936367035, "episode/length": 34.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 198552, "time": 9673.622007131577, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 198592, "time": 9676.807868719101, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 198760, "time": 9683.917454242706, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 198808, "time": 9687.092994689941, "episode/length": 299.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 199360, "time": 9707.562628030777, "episode/length": 185.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 199800, "time": 9723.662925958633, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 199928, "time": 9729.465742588043, "episode/length": 225.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 200032, "time": 9734.878847837448, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 200072, "time": 9737.627058506012, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 200088, "time": 9739.729669332504, "episode/length": 165.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9762.244139909744, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 200096, "time": 9764.662664413452, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 200096, "time": 9766.23214173317, "eval_episode/length": 179.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 200096, "time": 9766.240545988083, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 200096, "time": 9769.886782169342, "eval_episode/length": 185.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 200096, "time": 9773.732322216034, "eval_episode/length": 235.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 200096, "time": 9775.654505491257, "eval_episode/length": 242.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 200096, "time": 9779.23344540596, "eval_episode/length": 287.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 200304, "time": 9786.229846715927, "episode/length": 213.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 200560, "time": 9796.580240488052, "episode/length": 218.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 200824, "time": 9806.956091165543, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 200984, "time": 9814.0452978611, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9527027027027027, "episode/intrinsic_return": 0.0}
{"step": 201200, "time": 9823.198428153992, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 201336, "time": 9829.137974977493, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 201376, "time": 9832.26541352272, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 201568, "time": 9840.291833162308, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 201760, "time": 9848.452463388443, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 202112, "time": 9862.362718105316, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 202328, "time": 9871.052437782288, "episode/length": 167.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 202488, "time": 9878.003635883331, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 202536, "time": 9881.47757768631, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 202752, "time": 9890.63564991951, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 202752, "time": 9890.645407676697, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 202952, "time": 9900.363325834274, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 203328, "time": 9914.90702366829, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 203616, "time": 9926.26495051384, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 203952, "time": 9939.197323799133, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 204160, "time": 9947.947665691376, "episode/length": 175.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 204168, "time": 9949.526673793793, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 204280, "time": 9954.9497590065, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 204640, "time": 9968.893045425415, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 204784, "time": 9975.603833198547, "episode/length": 253.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 204792, "time": 9977.278057575226, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 205032, "time": 9988.416592359543, "episode/length": 48.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 205136, "time": 9993.845627069473, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 205536, "time": 10009.060538291931, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 205672, "time": 10015.114741563797, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 205736, "time": 10018.773779153824, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 206296, "time": 10039.148772478104, "episode/length": 334.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.0}
{"step": 206352, "time": 10043.091227769852, "episode/length": 84.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 206376, "time": 10045.296617269516, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 206496, "time": 10051.266907215118, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 206792, "time": 10062.68720459938, "episode/length": 219.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 206792, "time": 10062.69753074646, "episode/length": 249.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 206904, "time": 10069.610432863235, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 207480, "time": 10090.678017139435, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 207624, "time": 10097.084207296371, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 207744, "time": 10102.940941810608, "episode/length": 180.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 207792, "time": 10106.227941989899, "episode/length": 176.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 208048, "time": 10116.218598604202, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 208152, "time": 10121.122922897339, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 208504, "time": 10134.624832630157, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 208592, "time": 10139.470009326935, "episode/length": 224.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 209040, "time": 10156.155710458755, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 209160, "time": 10161.555367469788, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 209416, "time": 10171.6704185009, "episode/length": 241.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 209536, "time": 10177.581419229507, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 209568, "time": 10180.4151263237, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 209848, "time": 10191.195747613907, "episode/length": 224.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10200.858349561691, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10216.183362007141, "eval_episode/length": 39.0, "eval_episode/score": 3.1000000163912773, "eval_episode/reward_rate": 0.925}
{"step": 210080, "time": 10222.867112874985, "eval_episode/length": 152.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 210080, "time": 10222.876839637756, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 210080, "time": 10227.328203439713, "eval_episode/length": 173.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 210080, "time": 10230.087349176407, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9646464646464646}
{"step": 210080, "time": 10230.096135854721, "eval_episode/length": 197.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 210080, "time": 10233.69848394394, "eval_episode/length": 203.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 210080, "time": 10236.10709476471, "eval_episode/length": 220.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.995475113122172}
{"step": 210208, "time": 10242.141399145126, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 210592, "time": 10256.56189584732, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 210696, "time": 10261.430192232132, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 210768, "time": 10265.616189479828, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 210864, "time": 10270.661069393158, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 211216, "time": 10284.055088281631, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 211264, "time": 10287.2052526474, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 211320, "time": 10290.426814317703, "episode/length": 90.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 211400, "time": 10294.846541166306, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 211856, "time": 10312.150074481964, "episode/length": 205.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 212041, "time": 10320.79720878601, "train_stats/sum_log_reward": 5.003508728520389, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.745614035087719, "train_stats/max_log_achievement_collect_sapling": 2.508771929824561, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 5.254385964912281, "train_stats/max_log_achievement_defeat_skeleton": 0.008771929824561403, "train_stats/max_log_achievement_defeat_zombie": 0.3508771929824561, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05263157894736842, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.210526315789474, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.236842105263158, "train_stats/max_log_achievement_wake_up": 1.7456140350877194, "train_stats/mean_log_entropy": 0.5440158228340902, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.700568757233796, "train/action_min": 0.0, "train/action_std": 3.270662454322532, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049335429983006586, "train/actor_opt_grad_steps": 12480.0, "train/actor_opt_loss": -2.2691848504827012, "train/adv_mag": 0.7616463798063773, "train/adv_max": 0.7457902758209793, "train/adv_mean": 0.004537751817810608, "train/adv_min": -0.5148343944991076, "train/adv_std": 0.08132523974334752, "train/cont_avg": 0.9946469907407407, "train/cont_loss_mean": 0.00023818464194981195, "train/cont_loss_std": 0.006943769349975439, "train/cont_neg_acc": 0.9869838621881273, "train/cont_neg_loss": 0.026977264354051535, "train/cont_pos_acc": 0.9999926880553917, "train/cont_pos_loss": 5.660699642054586e-05, "train/cont_pred": 0.9946917962144922, "train/cont_rate": 0.9946469907407407, "train/dyn_loss_mean": 15.271270857916939, "train/dyn_loss_std": 9.678249429773402, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0327688208332768, "train/extr_critic_critic_opt_grad_steps": 12480.0, "train/extr_critic_critic_opt_loss": 15704.583492476851, "train/extr_critic_mag": 4.270062538429543, "train/extr_critic_max": 4.270062538429543, "train/extr_critic_mean": 0.8411266183411633, "train/extr_critic_min": -0.2522733494087502, "train/extr_critic_std": 0.9767490448775115, "train/extr_return_normed_mag": 1.8353954359337135, "train/extr_return_normed_max": 1.8353954359337135, "train/extr_return_normed_mean": 0.3186601404790525, "train/extr_return_normed_min": -0.1711371903894124, "train/extr_return_normed_std": 0.33959951290377866, "train/extr_return_rate": 0.4645794994301266, "train/extr_return_raw_mag": 5.392593931268762, "train/extr_return_raw_max": 5.392593931268762, "train/extr_return_raw_mean": 0.8547066803331729, "train/extr_return_raw_min": -0.6105696692510888, "train/extr_return_raw_std": 1.0161222912647105, "train/extr_reward_mag": 1.013291734236258, "train/extr_reward_max": 1.013291734236258, "train/extr_reward_mean": 0.01993606810423511, "train/extr_reward_min": -0.3843215200636122, "train/extr_reward_std": 0.1276346744210632, "train/image_loss_mean": 11.133889509130407, "train/image_loss_std": 14.596077650564688, "train/model_loss_mean": 20.350472697505243, "train/model_loss_std": 18.706432420236094, "train/model_opt_grad_norm": 82.63881222760236, "train/model_opt_grad_steps": 12464.162962962962, "train/model_opt_loss": 8083.728830295139, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 393.51851851851853, "train/policy_entropy_mag": 2.4680907832251653, "train/policy_entropy_max": 2.4680907832251653, "train/policy_entropy_mean": 0.580697614175302, "train/policy_entropy_min": 0.07937576710074036, "train/policy_entropy_std": 0.5696836363386225, "train/policy_logprob_mag": 7.438379556161386, "train/policy_logprob_max": -0.009455919334733928, "train/policy_logprob_mean": -0.580108294442848, "train/policy_logprob_min": -7.438379556161386, "train/policy_logprob_std": 1.1044670718687553, "train/policy_randomness_mag": 0.8711277370099668, "train/policy_randomness_max": 0.8711277370099668, "train/policy_randomness_mean": 0.20496077405081856, "train/policy_randomness_min": 0.028016162525724482, "train/policy_randomness_std": 0.20107332567373912, "train/post_ent_mag": 56.79319031326859, "train/post_ent_max": 56.79319031326859, "train/post_ent_mean": 39.18420777497468, "train/post_ent_min": 20.968394187644677, "train/post_ent_std": 6.4408721923828125, "train/prior_ent_mag": 66.89069682933666, "train/prior_ent_max": 66.89069682933666, "train/prior_ent_mean": 54.647987337465636, "train/prior_ent_min": 31.765662807888454, "train/prior_ent_std": 6.30102194680108, "train/rep_loss_mean": 15.271270857916939, "train/rep_loss_std": 9.678249429773402, "train/reward_avg": 0.02012514448897154, "train/reward_loss_mean": 0.05358250661304703, "train/reward_loss_std": 0.2644144940155524, "train/reward_max_data": 1.0185185229336773, "train/reward_max_pred": 1.0086688977700693, "train/reward_neg_acc": 0.9932392848862542, "train/reward_neg_loss": 0.030475755608468144, "train/reward_pos_acc": 0.9451586091959918, "train/reward_pos_loss": 0.9627825299898783, "train/reward_pred": 0.018947881260127933, "train/reward_rate": 0.024927662037037036, "eval_stats/sum_log_reward": 5.0374999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.8125, "eval_stats/max_log_achievement_collect_sapling": 2.4375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.298224444530206e-06, "report/cont_loss_std": 4.9546939408173785e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000598752056248486, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.456664098346664e-07, "report/cont_pred": 0.9970716238021851, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.216898918151855, "report/dyn_loss_std": 9.416593551635742, "report/image_loss_mean": 9.203078269958496, "report/image_loss_std": 12.434704780578613, "report/model_loss_mean": 17.183988571166992, "report/model_loss_std": 16.50762939453125, "report/post_ent_mag": 62.7381591796875, "report/post_ent_max": 62.7381591796875, "report/post_ent_mean": 40.332984924316406, "report/post_ent_min": 21.65350341796875, "report/post_ent_std": 6.545081615447998, "report/prior_ent_mag": 68.17343139648438, "report/prior_ent_max": 68.17343139648438, "report/prior_ent_mean": 53.811317443847656, "report/prior_ent_min": 36.459712982177734, "report/prior_ent_std": 6.204235553741455, "report/rep_loss_mean": 13.216898918151855, "report/rep_loss_std": 9.416593551635742, "report/reward_avg": 0.01972656324505806, "report/reward_loss_mean": 0.050769224762916565, "report/reward_loss_std": 0.2503318190574646, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0064940452575684, "report/reward_neg_acc": 0.9980000257492065, "report/reward_neg_loss": 0.02716834284365177, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 1.0341393947601318, "report/reward_pred": 0.015401531010866165, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 8.282707312901039e-06, "eval/cont_loss_std": 0.00019074436568189412, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.948094232939184e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.10288929642411e-06, "eval/cont_pred": 0.9970625638961792, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.720550537109375, "eval/dyn_loss_std": 10.282397270202637, "eval/image_loss_mean": 16.068241119384766, "eval/image_loss_std": 19.08314323425293, "eval/model_loss_mean": 26.756969451904297, "eval/model_loss_std": 22.95817756652832, "eval/post_ent_mag": 55.672142028808594, "eval/post_ent_max": 55.672142028808594, "eval/post_ent_mean": 40.059730529785156, "eval/post_ent_min": 20.726030349731445, "eval/post_ent_std": 6.6066508293151855, "eval/prior_ent_mag": 68.17343139648438, "eval/prior_ent_max": 68.17343139648438, "eval/prior_ent_mean": 54.302574157714844, "eval/prior_ent_min": 32.635555267333984, "eval/prior_ent_std": 6.189299583435059, "eval/rep_loss_mean": 17.720550537109375, "eval/rep_loss_std": 10.282397270202637, "eval/reward_avg": 0.01015624962747097, "eval/reward_loss_mean": 0.0563877671957016, "eval/reward_loss_std": 0.41202712059020996, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0069496631622314, "eval/reward_neg_acc": 0.9900990128517151, "eval/reward_neg_loss": 0.04380639269948006, "eval/reward_pos_acc": 0.9285714626312256, "eval/reward_pos_loss": 0.9640446305274963, "eval/reward_pred": 0.014431031420826912, "eval/reward_rate": 0.013671875, "replay/size": 211537.0, "replay/inserts": 21696.0, "replay/samples": 21696.0, "replay/insert_wait_avg": 1.368544182594547e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.861900997724505e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44536.0, "eval_replay/inserts": 4072.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2076673901151346e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0336313247681, "timer/env.step_count": 2712.0, "timer/env.step_total": 262.6896321773529, "timer/env.step_frac": 0.2626807978741293, "timer/env.step_avg": 0.09686195876746051, "timer/env.step_min": 0.02433633804321289, "timer/env.step_max": 3.5226409435272217, "timer/replay._sample_count": 21696.0, "timer/replay._sample_total": 11.578166484832764, "timer/replay._sample_frac": 0.011577777108850724, "timer/replay._sample_avg": 0.0005336544286888258, "timer/replay._sample_min": 0.00037026405334472656, "timer/replay._sample_max": 0.028232574462890625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3221.0, "timer/agent.policy_total": 55.0524423122406, "timer/agent.policy_frac": 0.055050590887939774, "timer/agent.policy_avg": 0.017091723785234585, "timer/agent.policy_min": 0.009701013565063477, "timer/agent.policy_max": 0.11274337768554688, "timer/dataset_train_count": 1356.0, "timer/dataset_train_total": 0.16153597831726074, "timer/dataset_train_frac": 0.00016153054583101394, "timer/dataset_train_avg": 0.00011912682766759642, "timer/dataset_train_min": 0.00010418891906738281, "timer/dataset_train_max": 0.000759124755859375, "timer/agent.train_count": 1356.0, "timer/agent.train_total": 610.3650455474854, "timer/agent.train_frac": 0.6103445188527514, "timer/agent.train_avg": 0.4501217150055202, "timer/agent.train_min": 0.4367692470550537, "timer/agent.train_max": 1.6095201969146729, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4841644763946533, "timer/agent.report_frac": 0.0004841481938495101, "timer/agent.report_avg": 0.24208223819732666, "timer/agent.report_min": 0.23329710960388184, "timer/agent.report_max": 0.2508673667907715, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0278141251896624e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 21.69496381210909}
{"step": 212192, "time": 10325.987978935242, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 212224, "time": 10328.614981174469, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 212320, "time": 10333.56290769577, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 212488, "time": 10340.554040431976, "episode/length": 36.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 212536, "time": 10343.669675827026, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 212592, "time": 10347.525465011597, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 212848, "time": 10357.759036540985, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 212944, "time": 10362.7005777359, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 213632, "time": 10388.912977695465, "episode/length": 163.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 213632, "time": 10388.923246622086, "episode/length": 221.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 213704, "time": 10394.429285287857, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 213896, "time": 10402.4772772789, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 213952, "time": 10406.160455465317, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 213952, "time": 10406.171201467514, "episode/length": 182.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 214264, "time": 10420.01859331131, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 214288, "time": 10422.717821598053, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 215056, "time": 10450.131176948547, "episode/length": 177.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 215064, "time": 10451.766322612762, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 215296, "time": 10461.477614402771, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 215496, "time": 10469.562682151794, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 215592, "time": 10474.454744815826, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 215640, "time": 10477.70675110817, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 215704, "time": 10481.588418722153, "episode/length": 176.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 216128, "time": 10497.671176671982, "episode/length": 271.0, "episode/score": 4.1000000461936, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 216376, "time": 10507.526132583618, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 216560, "time": 10515.644174814224, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 216608, "time": 10518.841422080994, "episode/length": 192.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 216856, "time": 10528.370242595673, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 216952, "time": 10533.28974890709, "episode/length": 102.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.941747572815534, "episode/intrinsic_return": 0.0}
{"step": 217056, "time": 10538.623775482178, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 217168, "time": 10544.214599132538, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 217192, "time": 10546.499382257462, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 217504, "time": 10558.67550110817, "episode/length": 38.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 217848, "time": 10571.619958400726, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 218064, "time": 10580.739577770233, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 218384, "time": 10593.174966335297, "episode/length": 250.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 218392, "time": 10594.816148281097, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 218432, "time": 10598.031778097153, "episode/length": 171.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 218448, "time": 10600.342498779297, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 218560, "time": 10605.807882070541, "episode/length": 173.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 218968, "time": 10621.414501190186, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 219224, "time": 10631.704588413239, "episode/length": 104.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 219304, "time": 10635.886754274368, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 219320, "time": 10637.995384931564, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 219816, "time": 10656.107763528824, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 219944, "time": 10662.141327857971, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10683.439969778061, "eval_episode/length": 44.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 220064, "time": 10689.186015844345, "eval_episode/length": 123.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9596774193548387}
{"step": 220064, "time": 10693.022741794586, "eval_episode/length": 171.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9593023255813954}
{"step": 220064, "time": 10694.686702251434, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 220064, "time": 10697.804562568665, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 220064, "time": 10700.783053159714, "eval_episode/length": 207.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 220064, "time": 10703.133011817932, "eval_episode/length": 167.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 220064, "time": 10705.382999897003, "eval_episode/length": 42.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8837209302325582}
{"step": 220120, "time": 10707.075722694397, "episode/length": 208.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 220264, "time": 10713.434332609177, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 220360, "time": 10718.355352640152, "episode/length": 173.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 220608, "time": 10728.679687261581, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 220664, "time": 10731.919662475586, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 220992, "time": 10744.606787443161, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 221328, "time": 10758.9213783741, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 221392, "time": 10762.557623147964, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 221576, "time": 10770.253437042236, "episode/length": 163.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 221656, "time": 10774.54074382782, "episode/length": 229.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 221688, "time": 10777.323997735977, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 222008, "time": 10789.664290189743, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 222056, "time": 10792.91593503952, "episode/length": 173.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 222344, "time": 10804.187488079071, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 222584, "time": 10813.982550144196, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 222800, "time": 10822.963164567947, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 222880, "time": 10827.23284292221, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 222968, "time": 10831.501519203186, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 223016, "time": 10834.739609479904, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 223176, "time": 10841.727036237717, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 223272, "time": 10846.620440244675, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 223560, "time": 10857.7876329422, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 223704, "time": 10864.204001426697, "episode/length": 169.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 223952, "time": 10874.476199150085, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 224400, "time": 10891.297220945358, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 224536, "time": 10897.214419841766, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 224680, "time": 10903.770689964294, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 224904, "time": 10912.94225358963, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 225088, "time": 10920.95451426506, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 225128, "time": 10923.690106868744, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 225576, "time": 10940.510573387146, "episode/length": 202.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 225864, "time": 10962.764870166779, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 226056, "time": 10971.897438526154, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 226144, "time": 10976.908170700073, "episode/length": 390.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9974424552429667, "episode/intrinsic_return": 0.0}
{"step": 226320, "time": 10984.358951568604, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 226336, "time": 10986.989259243011, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 226576, "time": 10997.342475652695, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 226944, "time": 11011.188007116318, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 226944, "time": 11011.197330236435, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 227264, "time": 11025.304931640625, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 227448, "time": 11032.824145793915, "episode/length": 138.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9496402877697842, "episode/intrinsic_return": 0.0}
{"step": 227600, "time": 11039.676307439804, "episode/length": 192.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 227696, "time": 11044.470306634903, "episode/length": 171.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 227936, "time": 11054.067923545837, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 228352, "time": 11069.663943052292, "episode/length": 175.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 228696, "time": 11082.703842639923, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 228704, "time": 11084.898916006088, "episode/length": 137.0, "episode/score": 6.100000061094761, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 228712, "time": 11086.636467933655, "episode/length": 157.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 228840, "time": 11092.525471687317, "episode/length": 336.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 228864, "time": 11095.191048383713, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 228896, "time": 11097.869552373886, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 229288, "time": 11112.525097608566, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 229312, "time": 11115.167194843292, "episode/length": 171.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 229680, "time": 11130.622538805008, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 230040, "time": 11144.34896850586, "episode/length": 165.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 11165.7151761055, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 230048, "time": 11167.461855173111, "eval_episode/length": 143.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 230048, "time": 11169.94950723648, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 230048, "time": 11172.241166114807, "eval_episode/length": 29.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8333333333333334}
{"step": 230048, "time": 11173.890526771545, "eval_episode/length": 174.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 230048, "time": 11175.515488862991, "eval_episode/length": 175.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 230048, "time": 11178.371002197266, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 230048, "time": 11180.024200439453, "eval_episode/length": 207.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 230472, "time": 11193.97103857994, "episode/length": 200.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 230504, "time": 11196.548481702805, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 230712, "time": 11205.206446409225, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 230752, "time": 11208.358046293259, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 230776, "time": 11210.512181282043, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 230968, "time": 11218.552168607712, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 231176, "time": 11227.089515686035, "episode/length": 186.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 231664, "time": 11245.236541032791, "episode/length": 144.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 231744, "time": 11249.419461488724, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 231936, "time": 11257.364290475845, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 232072, "time": 11263.500356197357, "episode/length": 169.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 232336, "time": 11274.27290558815, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 232504, "time": 11281.231982946396, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 232632, "time": 11287.288598299026, "episode/length": 231.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9698275862068966, "episode/intrinsic_return": 0.0}
{"step": 232984, "time": 11300.735670566559, "episode/length": 130.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 233264, "time": 11311.899636030197, "episode/length": 199.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 233288, "time": 11314.089303016663, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 233417, "time": 11321.05713057518, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.613752678259095, "train/action_min": 0.0, "train/action_std": 3.280201831860329, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.051500725796195995, "train/actor_opt_grad_steps": 13825.0, "train/actor_opt_loss": 1.6423485023039046, "train/adv_mag": 0.7703699038099887, "train/adv_max": 0.758037960351403, "train/adv_mean": 0.005233278344172477, "train/adv_min": -0.5162352610435059, "train/adv_std": 0.08245555442104589, "train/cont_avg": 0.9943956972947762, "train/cont_loss_mean": 0.00029068049815414237, "train/cont_loss_std": 0.008453847337426879, "train/cont_neg_acc": 0.9887230525265879, "train/cont_neg_loss": 0.030561486763572045, "train/cont_pos_acc": 0.9999559801905903, "train/cont_pos_loss": 0.00012179209862484495, "train/cont_pred": 0.9943991481368222, "train/cont_rate": 0.9943956972947762, "train/dyn_loss_mean": 15.748410630581985, "train/dyn_loss_std": 9.645737363331353, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9645707802986031, "train/extr_critic_critic_opt_grad_steps": 13825.0, "train/extr_critic_critic_opt_loss": 15520.382506413247, "train/extr_critic_mag": 4.488388086432841, "train/extr_critic_max": 4.488388086432841, "train/extr_critic_mean": 0.9053351603337189, "train/extr_critic_min": -0.2298975471240371, "train/extr_critic_std": 0.9872155153929297, "train/extr_return_normed_mag": 1.8730268780864887, "train/extr_return_normed_max": 1.8730268780864887, "train/extr_return_normed_mean": 0.326949233884242, "train/extr_return_normed_min": -0.16630119674686175, "train/extr_return_normed_std": 0.3401802304520536, "train/extr_return_rate": 0.49646788323993113, "train/extr_return_raw_mag": 5.597927783852193, "train/extr_return_raw_max": 5.597927783852193, "train/extr_return_raw_mean": 0.9211343122062399, "train/extr_return_raw_min": -0.5714676529169083, "train/extr_return_raw_std": 1.029586953903312, "train/extr_reward_mag": 1.0118959421542153, "train/extr_reward_max": 1.0118959421542153, "train/extr_reward_mean": 0.021120115871360496, "train/extr_reward_min": -0.3837840130080038, "train/extr_reward_std": 0.13237757691696508, "train/image_loss_mean": 10.90939404715353, "train/image_loss_std": 14.422827599653557, "train/model_loss_mean": 20.413978804403275, "train/model_loss_std": 18.456678938509814, "train/model_opt_grad_norm": 71.54154828769057, "train/model_opt_grad_steps": 13808.858208955224, "train/model_opt_loss": 15440.82227291278, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 755.5970149253732, "train/policy_entropy_mag": 2.4532350693176044, "train/policy_entropy_max": 2.4532350693176044, "train/policy_entropy_mean": 0.6029593099409075, "train/policy_entropy_min": 0.07937550550298904, "train/policy_entropy_std": 0.5916325961475941, "train/policy_logprob_mag": 7.438381401460562, "train/policy_logprob_max": -0.009455897615972295, "train/policy_logprob_mean": -0.6028786403919334, "train/policy_logprob_min": -7.438381401460562, "train/policy_logprob_std": 1.1102696959652119, "train/policy_randomness_mag": 0.8658843236183053, "train/policy_randomness_max": 0.8658843236183053, "train/policy_randomness_mean": 0.2128181755542755, "train/policy_randomness_min": 0.028016070168076168, "train/policy_randomness_std": 0.20882034501922664, "train/post_ent_mag": 57.67727866101621, "train/post_ent_max": 57.67727866101621, "train/post_ent_mean": 39.57791820924673, "train/post_ent_min": 21.598404841636544, "train/post_ent_std": 6.657312866467149, "train/prior_ent_mag": 67.49417865810109, "train/prior_ent_max": 67.49417865810109, "train/prior_ent_mean": 55.43538198898088, "train/prior_ent_min": 34.39062334886238, "train/prior_ent_std": 5.85063218714586, "train/rep_loss_mean": 15.748410630581985, "train/rep_loss_std": 9.645737363331353, "train/reward_avg": 0.020553725431047713, "train/reward_loss_mean": 0.05524793712060843, "train/reward_loss_std": 0.26228927743079056, "train/reward_max_data": 1.0156716455274553, "train/reward_max_pred": 1.0073565395910349, "train/reward_neg_acc": 0.9926089328616413, "train/reward_neg_loss": 0.03221771102954647, "train/reward_pos_acc": 0.9490924784496649, "train/reward_pos_loss": 0.9435887078740703, "train/reward_pred": 0.019918796474308664, "train/reward_rate": 0.025536380597014924, "train_stats/sum_log_reward": 4.955932160555306, "train_stats/max_log_achievement_collect_coal": 0.00847457627118644, "train_stats/max_log_achievement_collect_drink": 4.52542372881356, "train_stats/max_log_achievement_collect_sapling": 2.2542372881355934, "train_stats/max_log_achievement_collect_stone": 0.01694915254237288, "train_stats/max_log_achievement_collect_wood": 6.330508474576271, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.3305084745762712, "train_stats/max_log_achievement_eat_cow": 0.03389830508474576, "train_stats/max_log_achievement_make_wood_pickaxe": 0.059322033898305086, "train_stats/max_log_achievement_make_wood_sword": 0.01694915254237288, "train_stats/max_log_achievement_place_plant": 2.059322033898305, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.7203389830508473, "train_stats/max_log_achievement_wake_up": 1.5593220338983051, "train_stats/mean_log_entropy": 0.5291516129243172, "eval_stats/sum_log_reward": 4.412499941885471, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.1875, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 2.3221384253702126e-05, "report/cont_loss_std": 0.0005785661051049829, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0029527682345360518, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5408217279855307e-07, "report/cont_pred": 0.992210328578949, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 16.218692779541016, "report/dyn_loss_std": 9.172754287719727, "report/image_loss_mean": 10.545690536499023, "report/image_loss_std": 13.273019790649414, "report/model_loss_mean": 20.33352279663086, "report/model_loss_std": 17.125059127807617, "report/post_ent_mag": 56.01339340209961, "report/post_ent_max": 56.01339340209961, "report/post_ent_mean": 39.12567901611328, "report/post_ent_min": 19.821014404296875, "report/post_ent_std": 6.503953456878662, "report/prior_ent_mag": 67.83578491210938, "report/prior_ent_max": 67.83578491210938, "report/prior_ent_mean": 55.883419036865234, "report/prior_ent_min": 35.15007400512695, "report/prior_ent_std": 4.822507381439209, "report/rep_loss_mean": 16.218692779541016, "report/rep_loss_std": 9.172754287719727, "report/reward_avg": 0.02568359300494194, "report/reward_loss_mean": 0.05659446865320206, "report/reward_loss_std": 0.2451808899641037, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022709369659424, "report/reward_neg_acc": 0.9929364323616028, "report/reward_neg_loss": 0.030539557337760925, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.8390312194824219, "report/reward_pred": 0.025122523307800293, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.3218688006163575e-06, "eval/cont_loss_std": 7.13936606189236e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007746307528577745, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.42139389381191e-07, "eval/cont_pred": 0.9951205253601074, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.868858337402344, "eval/dyn_loss_std": 11.142037391662598, "eval/image_loss_mean": 16.93041229248047, "eval/image_loss_std": 20.195960998535156, "eval/model_loss_mean": 28.335920333862305, "eval/model_loss_std": 24.969539642333984, "eval/post_ent_mag": 56.61567306518555, "eval/post_ent_max": 56.61567306518555, "eval/post_ent_mean": 39.835906982421875, "eval/post_ent_min": 21.999053955078125, "eval/post_ent_std": 6.4635820388793945, "eval/prior_ent_mag": 67.83578491210938, "eval/prior_ent_max": 67.83578491210938, "eval/prior_ent_mean": 56.36086654663086, "eval/prior_ent_min": 37.09967803955078, "eval/prior_ent_std": 5.056817054748535, "eval/rep_loss_mean": 18.868858337402344, "eval/rep_loss_std": 11.142037391662598, "eval/reward_avg": 0.02509765699505806, "eval/reward_loss_mean": 0.08418508619070053, "eval/reward_loss_std": 0.5162128806114197, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0072999000549316, "eval/reward_neg_acc": 0.9889224767684937, "eval/reward_neg_loss": 0.03735290840268135, "eval/reward_pos_acc": 0.8709677457809448, "eval/reward_pos_loss": 1.5843251943588257, "eval/reward_pred": 0.02016306295990944, "eval/reward_rate": 0.0302734375, "replay/size": 232913.0, "replay/inserts": 21376.0, "replay/samples": 21376.0, "replay/insert_wait_avg": 1.3482985560765524e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.820878914016449e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 47936.0, "eval_replay/inserts": 3400.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2455267064711626e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2422308921814, "timer/env.step_count": 2672.0, "timer/env.step_total": 265.07926964759827, "timer/env.step_frac": 0.26501507480958564, "timer/env.step_avg": 0.09920631349086761, "timer/env.step_min": 0.023721933364868164, "timer/env.step_max": 3.4196486473083496, "timer/replay._sample_count": 21376.0, "timer/replay._sample_total": 11.370612859725952, "timer/replay._sample_frac": 0.011367859213046583, "timer/replay._sample_avg": 0.000531933610578497, "timer/replay._sample_min": 0.0003707408905029297, "timer/replay._sample_max": 0.011579036712646484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3097.0, "timer/agent.policy_total": 52.79668354988098, "timer/agent.policy_frac": 0.052783897659258165, "timer/agent.policy_avg": 0.017047686002544714, "timer/agent.policy_min": 0.009584426879882812, "timer/agent.policy_max": 0.10327863693237305, "timer/dataset_train_count": 1336.0, "timer/dataset_train_total": 0.1577925682067871, "timer/dataset_train_frac": 0.0001577543552285746, "timer/dataset_train_avg": 0.00011810820973561909, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.0004773139953613281, "timer/agent.train_count": 1336.0, "timer/agent.train_total": 601.3719511032104, "timer/agent.train_frac": 0.6012263155163999, "timer/agent.train_avg": 0.4501287059155767, "timer/agent.train_min": 0.43686580657958984, "timer/agent.train_max": 1.5471065044403076, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4837501049041748, "timer/agent.report_frac": 0.000483632954062224, "timer/agent.report_avg": 0.2418750524520874, "timer/agent.report_min": 0.23570489883422852, "timer/agent.report_max": 0.2480452060699463, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074854845577584e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 21.370525206114806}
{"step": 233568, "time": 11326.176049470901, "episode/length": 324.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9907692307692307, "episode/intrinsic_return": 0.0}
{"step": 233856, "time": 11337.44373512268, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 234088, "time": 11346.684584856033, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 234104, "time": 11349.451036691666, "episode/length": 253.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 234184, "time": 11353.904901504517, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 234192, "time": 11355.897647857666, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 234632, "time": 11372.038798809052, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 234680, "time": 11375.23537349701, "episode/length": 60.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 235176, "time": 11393.692432880402, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 235176, "time": 11393.704752445221, "episode/length": 235.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 235288, "time": 11400.876493692398, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 235584, "time": 11412.643061161041, "episode/length": 50.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 235704, "time": 11417.98896765709, "episode/length": 266.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 235720, "time": 11420.109778881073, "episode/length": 135.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 235760, "time": 11423.194202184677, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 236072, "time": 11435.070182800293, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 236168, "time": 11440.011623382568, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 236328, "time": 11447.155722141266, "episode/length": 205.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 236392, "time": 11450.854227304459, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 236760, "time": 11464.817646980286, "episode/length": 183.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 236888, "time": 11470.743931770325, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 237040, "time": 11478.262984752655, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 237184, "time": 11484.61211514473, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 237416, "time": 11493.674062728882, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 237512, "time": 11498.517158031464, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 237984, "time": 11517.814570188522, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 238232, "time": 11527.41215467453, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 238416, "time": 11535.57347202301, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 238464, "time": 11538.781039237976, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 238944, "time": 11556.440678834915, "episode/length": 346.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9971181556195965, "episode/intrinsic_return": 0.0}
{"step": 239248, "time": 11568.316314220428, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 239416, "time": 11575.436841249466, "episode/length": 178.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 239616, "time": 11584.061916828156, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 239688, "time": 11587.778389930725, "episode/length": 33.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 239720, "time": 11590.537099599838, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 239752, "time": 11593.184204101562, "episode/length": 160.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 239984, "time": 11602.754565477371, "episode/length": 32.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.8484848484848485, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11627.296139478683, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 240032, "time": 11629.303812265396, "eval_episode/length": 165.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 240032, "time": 11630.997834205627, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 240032, "time": 11632.955887317657, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 240032, "time": 11635.151015520096, "eval_episode/length": 188.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 240032, "time": 11636.898070573807, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 240032, "time": 11640.355852365494, "eval_episode/length": 236.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 240032, "time": 11645.074390649796, "eval_episode/length": 304.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9868852459016394}
{"step": 240048, "time": 11645.61273932457, "episode/length": 53.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 240056, "time": 11647.290852546692, "episode/length": 317.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 240632, "time": 11668.351852416992, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 240840, "time": 11676.905814409256, "episode/length": 236.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 240872, "time": 11679.744224071503, "episode/length": 460.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9891540130151844, "episode/intrinsic_return": 0.0}
{"step": 241192, "time": 11692.047794818878, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 241384, "time": 11700.142701625824, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 241520, "time": 11706.483018159866, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 241696, "time": 11713.98610830307, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 241952, "time": 11724.105904579163, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 242048, "time": 11728.943898916245, "episode/length": 43.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 242520, "time": 11746.293885946274, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 242544, "time": 11749.013002157211, "episode/length": 208.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 242808, "time": 11759.13390493393, "episode/length": 381.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 242872, "time": 11762.81849193573, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 243232, "time": 11776.968707561493, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 243288, "time": 11780.269377231598, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 243648, "time": 11794.28410243988, "episode/length": 306.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9837133550488599, "episode/intrinsic_return": 0.0}
{"step": 243816, "time": 11801.37153506279, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 243840, "time": 11804.040198802948, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 244128, "time": 11815.318265914917, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 244272, "time": 11821.721529722214, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 244464, "time": 11829.935797452927, "episode/length": 153.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 244536, "time": 11833.782426834106, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 244816, "time": 11844.990234851837, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 245480, "time": 11868.90048289299, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 245568, "time": 11873.764818906784, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 245632, "time": 11877.554499149323, "episode/length": 226.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 245696, "time": 11881.24089717865, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 245808, "time": 11888.248993873596, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 245872, "time": 11892.161468982697, "episode/length": 166.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 246496, "time": 11914.579208135605, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 246808, "time": 11926.55957365036, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 247032, "time": 11935.772600889206, "episode/length": 166.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 247088, "time": 11939.58962392807, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 247232, "time": 11945.96149468422, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 247264, "time": 11948.65356206894, "episode/length": 427.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 247432, "time": 11956.286423921585, "episode/length": 202.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 247856, "time": 11972.224454641342, "episode/length": 285.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9965034965034965, "episode/intrinsic_return": 0.0}
{"step": 248168, "time": 11984.192607879639, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 248328, "time": 11991.12585067749, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 248448, "time": 11996.992567062378, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 248464, "time": 11999.100075244904, "episode/length": 245.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 248560, "time": 12003.96092414856, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 248984, "time": 12019.627700328827, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 249040, "time": 12023.29888176918, "episode/length": 147.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 249208, "time": 12030.252456188202, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 249440, "time": 12039.95621228218, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 249736, "time": 12051.186307907104, "episode/length": 175.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 12082.592466592789, "eval_episode/length": 157.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 250016, "time": 12084.269231796265, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 250016, "time": 12085.951503276825, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9567901234567902}
{"step": 250016, "time": 12089.108598947525, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 250016, "time": 12092.188096284866, "eval_episode/length": 231.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 250016, "time": 12094.73791885376, "eval_episode/length": 252.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9762845849802372}
{"step": 250016, "time": 12096.854120016098, "eval_episode/length": 263.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 250016, "time": 12100.74288225174, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 250024, "time": 12100.798095703125, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 250152, "time": 12106.760334253311, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620853080568721, "episode/intrinsic_return": 0.0}
{"step": 250280, "time": 12112.656208276749, "episode/length": 228.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 250336, "time": 12116.294166564941, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 250584, "time": 12125.92156457901, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 250632, "time": 12129.01198387146, "episode/length": 177.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 251328, "time": 12154.216320753098, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 251424, "time": 12159.373748064041, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 251456, "time": 12162.246328115463, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 251576, "time": 12167.631806135178, "episode/length": 30.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 251720, "time": 12174.156321048737, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 251784, "time": 12177.92909359932, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 251992, "time": 12186.456418037415, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 252000, "time": 12188.556856870651, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 252176, "time": 12196.25081205368, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 252640, "time": 12213.312007188797, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 253112, "time": 12230.788770914078, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 253176, "time": 12234.533647298813, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 253192, "time": 12236.715410470963, "episode/length": 216.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 253384, "time": 12244.827682256699, "episode/length": 25.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8461538461538461, "episode/intrinsic_return": 0.0}
{"step": 253408, "time": 12247.523464918137, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 253544, "time": 12253.776691198349, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 253872, "time": 12266.695993423462, "episode/length": 234.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 254104, "time": 12277.374476194382, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 254344, "time": 12287.200679302216, "episode/length": 345.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 254456, "time": 12292.641701221466, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 254560, "time": 12297.926852703094, "episode/length": 180.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 254624, "time": 12301.76120376587, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 255129, "time": 12322.147950649261, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.687672706886574, "train/action_min": 0.0, "train/action_std": 3.258486994990596, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050069201985994974, "train/actor_opt_grad_steps": 15170.0, "train/actor_opt_loss": -5.294089071838944, "train/adv_mag": 0.7207307162108245, "train/adv_max": 0.7022307367236525, "train/adv_mean": 0.0038139546317526966, "train/adv_min": -0.5148157603210873, "train/adv_std": 0.07867288523250156, "train/cont_avg": 0.9943070023148148, "train/cont_loss_mean": 0.0004540845807477362, "train/cont_loss_std": 0.012983587376671763, "train/cont_neg_acc": 0.9867813061784815, "train/cont_neg_loss": 0.03664449876865816, "train/cont_pos_acc": 0.9999053924172013, "train/cont_pos_loss": 0.00025740953271148707, "train/cont_pred": 0.9942849530114068, "train/cont_rate": 0.9943070023148148, "train/dyn_loss_mean": 15.75338069068061, "train/dyn_loss_std": 9.593112797207302, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.960121257216842, "train/extr_critic_critic_opt_grad_steps": 15170.0, "train/extr_critic_critic_opt_loss": 15513.931626157408, "train/extr_critic_mag": 4.683926967338279, "train/extr_critic_max": 4.683926967338279, "train/extr_critic_mean": 0.9532055146164364, "train/extr_critic_min": -0.2140337899879173, "train/extr_critic_std": 1.0212109212522154, "train/extr_return_normed_mag": 1.8218597685849225, "train/extr_return_normed_max": 1.8218597685849225, "train/extr_return_normed_mean": 0.31646913565971235, "train/extr_return_normed_min": -0.1705179609634258, "train/extr_return_normed_std": 0.33458935817082724, "train/extr_return_rate": 0.4964487149759575, "train/extr_return_raw_mag": 5.731989147044994, "train/extr_return_raw_max": 5.731989147044994, "train/extr_return_raw_mean": 0.9652655374120783, "train/extr_return_raw_min": -0.5769443324318638, "train/extr_return_raw_std": 1.059447580355185, "train/extr_reward_mag": 1.0106510188844469, "train/extr_reward_max": 1.0106510188844469, "train/extr_reward_mean": 0.0219438256488906, "train/extr_reward_min": -0.39272163179185654, "train/extr_reward_std": 0.13531849174587815, "train/image_loss_mean": 10.293650206813107, "train/image_loss_std": 13.94480963812934, "train/model_loss_mean": 19.801669134917084, "train/model_loss_std": 17.92744290387189, "train/model_opt_grad_norm": 71.81219869543006, "train/model_opt_grad_steps": 15152.637037037037, "train/model_opt_loss": 12841.467708333334, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 648.1481481481482, "train/policy_entropy_mag": 2.432694097801491, "train/policy_entropy_max": 2.432694097801491, "train/policy_entropy_mean": 0.5509729793778172, "train/policy_entropy_min": 0.07937535836740776, "train/policy_entropy_std": 0.5462659409752598, "train/policy_logprob_mag": 7.4383820463109895, "train/policy_logprob_max": -0.009455860826980184, "train/policy_logprob_mean": -0.5508984431072518, "train/policy_logprob_min": -7.4383820463109895, "train/policy_logprob_std": 1.0865376671155293, "train/policy_randomness_mag": 0.8586342630562959, "train/policy_randomness_max": 0.8586342630562959, "train/policy_randomness_mean": 0.19446928136878544, "train/policy_randomness_min": 0.028016018219016215, "train/policy_randomness_std": 0.19280790631417874, "train/post_ent_mag": 57.67419885706018, "train/post_ent_max": 57.67419885706018, "train/post_ent_mean": 39.83243781195746, "train/post_ent_min": 21.322319793701173, "train/post_ent_std": 6.780878483807599, "train/prior_ent_mag": 67.87806147822627, "train/prior_ent_max": 67.87806147822627, "train/prior_ent_mean": 55.79024392587167, "train/prior_ent_min": 35.47947622228552, "train/prior_ent_std": 5.544102887754087, "train/rep_loss_mean": 15.75338069068061, "train/rep_loss_std": 9.593112797207302, "train/reward_avg": 0.020405092518086785, "train/reward_loss_mean": 0.05553646374631811, "train/reward_loss_std": 0.26637318631013235, "train/reward_max_data": 1.022222227520413, "train/reward_max_pred": 1.0117335478464762, "train/reward_neg_acc": 0.993005249676881, "train/reward_neg_loss": 0.03281316266015724, "train/reward_pos_acc": 0.9549625061176441, "train/reward_pos_loss": 0.9300754193906431, "train/reward_pred": 0.019646556147684655, "train/reward_rate": 0.02549189814814815, "train_stats/sum_log_reward": 5.0649122011504675, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.7368421052631575, "train_stats/max_log_achievement_collect_sapling": 2.7017543859649122, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.552631578947368, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.34210526315789475, "train_stats/max_log_achievement_eat_cow": 0.07894736842105263, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08771929824561403, "train_stats/max_log_achievement_make_wood_sword": 0.03508771929824561, "train_stats/max_log_achievement_place_plant": 2.508771929824561, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.7280701754385963, "train_stats/max_log_achievement_wake_up": 1.7894736842105263, "train_stats/mean_log_entropy": 0.5095429234860236, "eval_stats/sum_log_reward": 5.287499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 12.8125, "eval_stats/max_log_achievement_collect_sapling": 3.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 4.696796167991124e-06, "report/cont_loss_std": 6.914252298884094e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004996669013053179, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.755736431936384e-06, "report/cont_pred": 0.9960929155349731, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.388338088989258, "report/dyn_loss_std": 9.144989013671875, "report/image_loss_mean": 7.735407829284668, "report/image_loss_std": 11.837749481201172, "report/model_loss_mean": 16.409282684326172, "report/model_loss_std": 15.605887413024902, "report/post_ent_mag": 59.88763427734375, "report/post_ent_max": 59.88763427734375, "report/post_ent_mean": 41.67265319824219, "report/post_ent_min": 23.904329299926758, "report/post_ent_std": 7.840810775756836, "report/prior_ent_mag": 68.32298278808594, "report/prior_ent_max": 68.32298278808594, "report/prior_ent_mean": 56.35120391845703, "report/prior_ent_min": 36.0609130859375, "report/prior_ent_std": 5.020505428314209, "report/rep_loss_mean": 14.388338088989258, "report/rep_loss_std": 9.144989013671875, "report/reward_avg": 0.01835937425494194, "report/reward_loss_mean": 0.04086613655090332, "report/reward_loss_std": 0.18601107597351074, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0074946880340576, "report/reward_neg_acc": 0.9950099587440491, "report/reward_neg_loss": 0.02358928881585598, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8277480006217957, "report/reward_pred": 0.01754002645611763, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 1.3009380381845403e-06, "eval/cont_loss_std": 6.88536374582327e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.863268547225744e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.214887768393965e-07, "eval/cont_pred": 0.9951165914535522, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.5394287109375, "eval/dyn_loss_std": 9.413371086120605, "eval/image_loss_mean": 10.296675682067871, "eval/image_loss_std": 12.148295402526855, "eval/model_loss_mean": 20.87916374206543, "eval/model_loss_std": 15.914691925048828, "eval/post_ent_mag": 58.69460678100586, "eval/post_ent_max": 58.69460678100586, "eval/post_ent_mean": 40.88485336303711, "eval/post_ent_min": 22.099822998046875, "eval/post_ent_std": 6.274660110473633, "eval/prior_ent_mag": 68.32298278808594, "eval/prior_ent_max": 68.32298278808594, "eval/prior_ent_mean": 56.18409729003906, "eval/prior_ent_min": 36.95014190673828, "eval/prior_ent_std": 5.102090835571289, "eval/rep_loss_mean": 17.5394287109375, "eval/rep_loss_std": 9.413371086120605, "eval/reward_avg": 0.010839843191206455, "eval/reward_loss_mean": 0.05883160978555679, "eval/reward_loss_std": 0.5150595307350159, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002882957458496, "eval/reward_neg_acc": 0.9950446486473083, "eval/reward_neg_loss": 0.02907932549715042, "eval/reward_pos_acc": 0.8666667342185974, "eval/reward_pos_loss": 2.060168743133545, "eval/reward_pred": 0.008394423872232437, "eval/reward_rate": 0.0146484375, "replay/size": 254625.0, "replay/inserts": 21712.0, "replay/samples": 21712.0, "replay/insert_wait_avg": 1.4236044514767808e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.800982994636193e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 52864.0, "eval_replay/inserts": 4928.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1921896562947856e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1692683696747, "timer/env.step_count": 2714.0, "timer/env.step_total": 261.1361036300659, "timer/env.step_frac": 0.26109190902828944, "timer/env.step_avg": 0.09621816640754087, "timer/env.step_min": 0.024263620376586914, "timer/env.step_max": 3.4604125022888184, "timer/replay._sample_count": 21712.0, "timer/replay._sample_total": 11.466593980789185, "timer/replay._sample_frac": 0.011464653377603072, "timer/replay._sample_avg": 0.0005281224198963331, "timer/replay._sample_min": 0.0004067420959472656, "timer/replay._sample_max": 0.010336160659790039, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3330.0, "timer/agent.policy_total": 57.78882431983948, "timer/agent.policy_frac": 0.05777904415523396, "timer/agent.policy_avg": 0.01735400129724909, "timer/agent.policy_min": 0.009569168090820312, "timer/agent.policy_max": 0.12978625297546387, "timer/dataset_train_count": 1357.0, "timer/dataset_train_total": 0.16088199615478516, "timer/dataset_train_frac": 0.00016085476853036163, "timer/dataset_train_avg": 0.00011855710844125657, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.00058746337890625, "timer/agent.train_count": 1357.0, "timer/agent.train_total": 610.2353117465973, "timer/agent.train_frac": 0.6101320356916294, "timer/agent.train_avg": 0.4496944080667629, "timer/agent.train_min": 0.4342620372772217, "timer/agent.train_max": 1.5565276145935059, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47440552711486816, "timer/agent.report_frac": 0.0004743252388549916, "timer/agent.report_avg": 0.23720276355743408, "timer/agent.report_min": 0.22586655616760254, "timer/agent.report_max": 0.24853897094726562, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.812863104646596e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 21.708040241517054}
{"step": 255144, "time": 12322.23383307457, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 255248, "time": 12328.0400223732, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 255824, "time": 12349.22113609314, "episode/length": 304.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 255920, "time": 12354.06152844429, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 255928, "time": 12355.867869377136, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 256096, "time": 12363.32069015503, "episode/length": 191.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9895833333333334, "episode/intrinsic_return": 0.0}
{"step": 256136, "time": 12365.995455026627, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 256248, "time": 12371.451461315155, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 256392, "time": 12377.957998991013, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 256712, "time": 12390.257398366928, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 257112, "time": 12405.3824634552, "episode/length": 345.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9913294797687862, "episode/intrinsic_return": 0.0}
{"step": 257184, "time": 12410.252259254456, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 257416, "time": 12419.44202375412, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 257464, "time": 12422.61541056633, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 257608, "time": 12429.331902742386, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 257656, "time": 12432.668718099594, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 257760, "time": 12437.99171924591, "episode/length": 42.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 257920, "time": 12444.9679479599, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 258496, "time": 12465.746448993683, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 258872, "time": 12479.74559044838, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 258896, "time": 12482.296516895294, "episode/length": 330.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 258912, "time": 12484.37169098854, "episode/length": 180.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 259248, "time": 12497.368424415588, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 259264, "time": 12499.496673583984, "episode/length": 95.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 259688, "time": 12515.131776332855, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 259888, "time": 12523.697390794754, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12549.36508846283, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 260000, "time": 12551.284229278564, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 260000, "time": 12551.293871164322, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 260000, "time": 12555.233007192612, "eval_episode/length": 180.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 260000, "time": 12557.463465452194, "eval_episode/length": 195.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 260000, "time": 12559.950757026672, "eval_episode/length": 215.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9953703703703703}
{"step": 260000, "time": 12565.565780878067, "eval_episode/length": 301.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9834437086092715}
{"step": 260000, "time": 12568.478735923767, "eval_episode/length": 317.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9842767295597484}
{"step": 260120, "time": 12572.444431066513, "episode/length": 294.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 260432, "time": 12585.403589010239, "episode/length": 191.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 260496, "time": 12589.050686597824, "episode/length": 46.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 260600, "time": 12593.918496608734, "episode/length": 166.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 260600, "time": 12593.928245306015, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 260608, "time": 12597.68538594246, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 260632, "time": 12600.0666410923, "episode/length": 214.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 261232, "time": 12622.275074958801, "episode/length": 78.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9240506329113924, "episode/intrinsic_return": 0.0}
{"step": 261256, "time": 12624.472135066986, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 261360, "time": 12629.64911866188, "episode/length": 183.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 261856, "time": 12648.096184015274, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 262104, "time": 12657.876156330109, "episode/length": 200.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 262312, "time": 12667.948620319366, "episode/length": 213.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 262320, "time": 12670.243673086166, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 262352, "time": 12672.860285758972, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 262632, "time": 12683.60848402977, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 262736, "time": 12689.055454492569, "episode/length": 47.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 262744, "time": 12690.595091819763, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 262912, "time": 12698.103341341019, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 263144, "time": 12707.47503900528, "episode/length": 313.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 263416, "time": 12718.347929239273, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 263720, "time": 12730.301452636719, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 263968, "time": 12740.501325130463, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 264000, "time": 12743.175497293472, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 264064, "time": 12746.914687156677, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 264400, "time": 12759.970297336578, "episode/length": 286.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 264512, "time": 12765.328246831894, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 264592, "time": 12769.610675811768, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 265008, "time": 12785.315758943558, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 265152, "time": 12791.908405542374, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 265496, "time": 12805.027481079102, "episode/length": 178.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 265592, "time": 12810.025492668152, "episode/length": 198.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 265768, "time": 12817.520051240921, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 265928, "time": 12824.64117193222, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 266040, "time": 12830.048624753952, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 266192, "time": 12836.96153497696, "episode/length": 277.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 266328, "time": 12842.952563285828, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 266920, "time": 12864.651105880737, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 267096, "time": 12872.191544055939, "episode/length": 242.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 267152, "time": 12875.822849273682, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 267552, "time": 12891.03873181343, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 267624, "time": 12894.772480249405, "episode/length": 265.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 267728, "time": 12900.19836473465, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 268040, "time": 12912.180421590805, "episode/length": 213.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 268504, "time": 12929.297521591187, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 268664, "time": 12936.292328357697, "episode/length": 195.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 268976, "time": 12948.697796583176, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 269056, "time": 12952.900008916855, "episode/length": 266.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 269392, "time": 12965.814334869385, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 269480, "time": 12970.280980110168, "episode/length": 463.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9978448275862069, "episode/intrinsic_return": 0.0}
{"step": 269584, "time": 12975.692702531815, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 269968, "time": 12990.224287509918, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 13010.61081314087, "eval_episode/length": 33.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8529411764705882}
{"step": 270088, "time": 13015.911296844482, "eval_episode/length": 114.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9391304347826087}
{"step": 270088, "time": 13020.303566932678, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 270088, "time": 13022.444210290909, "eval_episode/length": 179.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 270088, "time": 13025.858521223068, "eval_episode/length": 182.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 270088, "time": 13029.812067508698, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 270088, "time": 13032.908924341202, "eval_episode/length": 101.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9509803921568627}
{"step": 270088, "time": 13035.469487190247, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 270088, "time": 13035.47884964943, "eval_episode/length": 236.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 270176, "time": 13038.678927898407, "episode/length": 149.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 270512, "time": 13053.239414930344, "episode/length": 369.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 270560, "time": 13056.462985515594, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 270648, "time": 13060.842693567276, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 270736, "time": 13065.659262895584, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 271104, "time": 13079.686131238937, "episode/length": 189.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 271432, "time": 13092.193707942963, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 271448, "time": 13094.295016527176, "episode/length": 298.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9899665551839465, "episode/intrinsic_return": 0.0}
{"step": 271488, "time": 13097.490354299545, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 271664, "time": 13104.943040370941, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 272040, "time": 13119.059439182281, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 272248, "time": 13127.976648807526, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 272328, "time": 13132.305215120316, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 272384, "time": 13136.032618045807, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 272696, "time": 13148.097972393036, "episode/length": 45.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 272856, "time": 13155.632501125336, "episode/length": 170.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 273008, "time": 13162.59324145317, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 273264, "time": 13172.703435659409, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 273280, "time": 13174.889510393143, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 273440, "time": 13181.905541181564, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 273488, "time": 13185.20758152008, "episode/length": 78.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 273608, "time": 13190.524680614471, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 274208, "time": 13213.203619003296, "episode/length": 244.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 274288, "time": 13217.634366750717, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 274504, "time": 13226.3015396595, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 274824, "time": 13238.741063833237, "episode/length": 226.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 274832, "time": 13240.86040520668, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 274832, "time": 13240.86987733841, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 274864, "time": 13245.315706253052, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 275032, "time": 13252.310305833817, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9550561797752809, "episode/intrinsic_return": 0.0}
{"step": 275344, "time": 13264.676363229752, "episode/length": 38.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 275568, "time": 13273.845720529556, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 275728, "time": 13280.840214967728, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 275872, "time": 13287.322118520737, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 276232, "time": 13301.050416231155, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 276328, "time": 13305.826944112778, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 276440, "time": 13311.23745393753, "episode/length": 200.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 276600, "time": 13318.182474136353, "episode/length": 216.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 276617, "time": 13321.405434846878, "train_stats/sum_log_reward": 4.875862000060493, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.870689655172414, "train_stats/max_log_achievement_collect_sapling": 2.560344827586207, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 6.258620689655173, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.29310344827586204, "train_stats/max_log_achievement_eat_cow": 0.07758620689655173, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05172413793103448, "train_stats/max_log_achievement_make_wood_sword": 0.008620689655172414, "train_stats/max_log_achievement_place_plant": 2.439655172413793, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.663793103448276, "train_stats/max_log_achievement_wake_up": 1.6810344827586208, "train_stats/mean_log_entropy": 0.5380733801886953, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.494722493489584, "train/action_min": 0.0, "train/action_std": 3.129832227141769, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04798429969836165, "train/actor_opt_grad_steps": 16520.0, "train/actor_opt_loss": -8.079882591631677, "train/adv_mag": 0.716544716446488, "train/adv_max": 0.6984641821296127, "train/adv_mean": 0.002982346010284581, "train/adv_min": -0.4976348846047013, "train/adv_std": 0.07565836945065746, "train/cont_avg": 0.9941623263888889, "train/cont_loss_mean": 0.00038052839389235015, "train/cont_loss_std": 0.010622630973473744, "train/cont_neg_acc": 0.9863283647431268, "train/cont_neg_loss": 0.04740635806356295, "train/cont_pos_acc": 0.9999416836985835, "train/cont_pos_loss": 0.00014607383787255946, "train/cont_pred": 0.9941747192983275, "train/cont_rate": 0.9941623263888889, "train/dyn_loss_mean": 15.713954063698097, "train/dyn_loss_std": 9.526971322518808, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8888681636916267, "train/extr_critic_critic_opt_grad_steps": 16520.0, "train/extr_critic_critic_opt_loss": 15385.7013671875, "train/extr_critic_mag": 4.70647297611943, "train/extr_critic_max": 4.70647297611943, "train/extr_critic_mean": 0.9197306376916391, "train/extr_critic_min": -0.25138499030360467, "train/extr_critic_std": 1.0482225612357812, "train/extr_return_normed_mag": 1.8042970101038616, "train/extr_return_normed_max": 1.8042970101038616, "train/extr_return_normed_mean": 0.3038238944830718, "train/extr_return_normed_min": -0.16039165065244393, "train/extr_return_normed_std": 0.3363191031747394, "train/extr_return_rate": 0.4518002745178011, "train/extr_return_raw_mag": 5.761735071959319, "train/extr_return_raw_max": 5.761735071959319, "train/extr_return_raw_mean": 0.9293762851644445, "train/extr_return_raw_min": -0.5661096168888939, "train/extr_return_raw_std": 1.0834909253650242, "train/extr_reward_mag": 1.0148206057371916, "train/extr_reward_max": 1.0148206057371916, "train/extr_reward_mean": 0.021815737812883325, "train/extr_reward_min": -0.34979234094972966, "train/extr_reward_std": 0.13706057496644833, "train/image_loss_mean": 9.539906593605323, "train/image_loss_std": 12.798961226145426, "train/model_loss_mean": 19.022868735701948, "train/model_loss_std": 16.756895383199055, "train/model_opt_grad_norm": 71.25667846114547, "train/model_opt_grad_steps": 16501.48148148148, "train/model_opt_loss": 13159.942860243056, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 689.8148148148148, "train/policy_entropy_mag": 2.426536957422892, "train/policy_entropy_max": 2.426536957422892, "train/policy_entropy_mean": 0.5558417532179091, "train/policy_entropy_min": 0.07937532343246319, "train/policy_entropy_std": 0.5504643453492059, "train/policy_logprob_mag": 7.4383825690658005, "train/policy_logprob_max": -0.009455853817915475, "train/policy_logprob_mean": -0.5554486519760555, "train/policy_logprob_min": -7.4383825690658005, "train/policy_logprob_std": 1.084159009103422, "train/policy_randomness_mag": 0.856461058722602, "train/policy_randomness_max": 0.856461058722602, "train/policy_randomness_mean": 0.19618774674556874, "train/policy_randomness_min": 0.028016005939355604, "train/policy_randomness_std": 0.19428975957411307, "train/post_ent_mag": 58.508595925790296, "train/post_ent_max": 58.508595925790296, "train/post_ent_mean": 40.41227103339301, "train/post_ent_min": 21.424513513070565, "train/post_ent_std": 7.154637251959906, "train/prior_ent_mag": 68.21734031394676, "train/prior_ent_max": 68.21734031394676, "train/prior_ent_mean": 56.246155180754485, "train/prior_ent_min": 37.191428855613424, "train/prior_ent_std": 5.325132232242161, "train/rep_loss_mean": 15.713954063698097, "train/rep_loss_std": 9.526971322518808, "train/reward_avg": 0.020490451122599618, "train/reward_loss_mean": 0.05420933520352399, "train/reward_loss_std": 0.26095648893603574, "train/reward_max_data": 1.0170370410989833, "train/reward_max_pred": 1.0066023014209888, "train/reward_neg_acc": 0.9925763289133708, "train/reward_neg_loss": 0.03156702359103494, "train/reward_pos_acc": 0.9567065821753608, "train/reward_pos_loss": 0.921317129223435, "train/reward_pred": 0.019799130182299347, "train/reward_rate": 0.025622106481481482, "eval_stats/sum_log_reward": 5.041176452356226, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.470588235294118, "eval_stats/max_log_achievement_collect_sapling": 3.0588235294117645, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6470588235294118, "eval_stats/max_log_achievement_eat_cow": 0.058823529411764705, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.058823529411764705, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.0588235294117645, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5294117647058822, "eval_stats/max_log_achievement_wake_up": 1.7058823529411764, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.0002167330967495218, "report/cont_loss_std": 0.006757022812962532, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.054870907217264175, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.4030075564951403e-06, "report/cont_pred": 0.9962843656539917, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 16.884986877441406, "report/dyn_loss_std": 9.321592330932617, "report/image_loss_mean": 10.483959197998047, "report/image_loss_std": 14.49213981628418, "report/model_loss_mean": 20.68317413330078, "report/model_loss_std": 18.426860809326172, "report/post_ent_mag": 57.753807067871094, "report/post_ent_max": 57.753807067871094, "report/post_ent_mean": 39.62892150878906, "report/post_ent_min": 21.595502853393555, "report/post_ent_std": 7.287543296813965, "report/prior_ent_mag": 67.99845886230469, "report/prior_ent_max": 67.99845886230469, "report/prior_ent_mean": 56.83238220214844, "report/prior_ent_min": 41.77220916748047, "report/prior_ent_std": 4.938196659088135, "report/rep_loss_mean": 16.884986877441406, "report/rep_loss_std": 9.321592330932617, "report/reward_avg": 0.02421874925494194, "report/reward_loss_mean": 0.06800304353237152, "report/reward_loss_std": 0.4992166757583618, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0096650123596191, "report/reward_neg_acc": 0.9919679760932922, "report/reward_neg_loss": 0.04150504618883133, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 1.0105748176574707, "report/reward_pred": 0.020789962261915207, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.742836042874842e-06, "eval/cont_loss_std": 6.451740046031773e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007451653364114463, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.0484494339380035e-07, "eval/cont_pred": 0.9951207041740417, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.142133712768555, "eval/dyn_loss_std": 10.796249389648438, "eval/image_loss_mean": 19.45589828491211, "eval/image_loss_std": 25.917015075683594, "eval/model_loss_mean": 31.66234588623047, "eval/model_loss_std": 30.161788940429688, "eval/post_ent_mag": 59.17439270019531, "eval/post_ent_max": 59.17439270019531, "eval/post_ent_mean": 40.30693054199219, "eval/post_ent_min": 21.504688262939453, "eval/post_ent_std": 6.658980846405029, "eval/prior_ent_mag": 67.99845886230469, "eval/prior_ent_max": 67.99845886230469, "eval/prior_ent_mean": 57.47218322753906, "eval/prior_ent_min": 34.99803161621094, "eval/prior_ent_std": 4.846011161804199, "eval/rep_loss_mean": 20.142133712768555, "eval/rep_loss_std": 10.796249389648438, "eval/reward_avg": 0.01503906212747097, "eval/reward_loss_mean": 0.12116488814353943, "eval/reward_loss_std": 0.8684937357902527, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0007965564727783, "eval/reward_neg_acc": 0.9930209517478943, "eval/reward_neg_loss": 0.03990074247121811, "eval/reward_pos_acc": 0.5714285969734192, "eval/reward_pos_loss": 4.002495765686035, "eval/reward_pred": 0.007135358173400164, "eval/reward_rate": 0.0205078125, "replay/size": 276113.0, "replay/inserts": 21488.0, "replay/samples": 21488.0, "replay/insert_wait_avg": 1.3213657391932324e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.390776234425809e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 57304.0, "eval_replay/inserts": 4440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1796886856491502e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1578779220581, "timer/env.step_count": 2686.0, "timer/env.step_total": 263.8282506465912, "timer/env.step_frac": 0.2637866045655956, "timer/env.step_avg": 0.09822347380736828, "timer/env.step_min": 0.024407386779785156, "timer/env.step_max": 3.3980393409729004, "timer/replay._sample_count": 21488.0, "timer/replay._sample_total": 10.914271831512451, "timer/replay._sample_frac": 0.010912548980954982, "timer/replay._sample_avg": 0.0005079240427919049, "timer/replay._sample_min": 0.00039076805114746094, "timer/replay._sample_max": 0.011647224426269531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3241.0, "timer/agent.policy_total": 55.761813163757324, "timer/agent.policy_frac": 0.05575301099423307, "timer/agent.policy_avg": 0.01720512593759868, "timer/agent.policy_min": 0.009612321853637695, "timer/agent.policy_max": 0.10262727737426758, "timer/dataset_train_count": 1343.0, "timer/dataset_train_total": 0.15804505348205566, "timer/dataset_train_frac": 0.00015802010559614075, "timer/dataset_train_avg": 0.00011768060572007123, "timer/dataset_train_min": 0.00010204315185546875, "timer/dataset_train_max": 0.0005970001220703125, "timer/agent.train_count": 1343.0, "timer/agent.train_total": 603.8815472126007, "timer/agent.train_frac": 0.6037862226983938, "timer/agent.train_avg": 0.44965118928711895, "timer/agent.train_min": 0.43573689460754395, "timer/agent.train_max": 1.5866968631744385, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48325538635253906, "timer/agent.report_frac": 0.00048317910303976924, "timer/agent.report_avg": 0.24162769317626953, "timer/agent.report_min": 0.23598384857177734, "timer/agent.report_max": 0.24727153778076172, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.43865966796875e-05, "timer/dataset_eval_frac": 7.437485453220058e-08, "timer/dataset_eval_avg": 7.43865966796875e-05, "timer/dataset_eval_min": 7.43865966796875e-05, "timer/dataset_eval_max": 7.43865966796875e-05, "fps": 21.484326943227895}
{"step": 276720, "time": 13324.94683098793, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 277128, "time": 13340.307066202164, "episode/length": 85.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 277136, "time": 13342.338001728058, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 277272, "time": 13348.372113227844, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 277304, "time": 13351.09492444992, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 277896, "time": 13372.908816099167, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 277992, "time": 13377.696769714355, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 278112, "time": 13383.573743343353, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 278232, "time": 13389.083597898483, "episode/length": 203.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 278320, "time": 13393.995794534683, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 278544, "time": 13404.43067407608, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 278744, "time": 13412.579166173935, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 279104, "time": 13426.667372465134, "episode/length": 228.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 279448, "time": 13439.514060974121, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 279456, "time": 13441.496239900589, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 279488, "time": 13444.143538236618, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 280048, "time": 13464.705769062042, "episode/length": 241.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13484.652474403381, "eval_episode/length": 43.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9090909090909091}
{"step": 280072, "time": 13487.606454372406, "eval_episode/length": 61.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 280072, "time": 13493.422101736069, "eval_episode/length": 136.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 280072, "time": 13497.773741483688, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 280072, "time": 13500.140503168106, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 280072, "time": 13502.435014486313, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 280072, "time": 13504.078367710114, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 280072, "time": 13507.010329961777, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 280152, "time": 13509.770861387253, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 280256, "time": 13515.156431913376, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 280384, "time": 13521.516008377075, "episode/length": 257.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 280592, "time": 13530.071365118027, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 280704, "time": 13535.383564710617, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 281040, "time": 13548.348811864853, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 281320, "time": 13559.19489455223, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 281816, "time": 13578.007339477539, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 281824, "time": 13580.099376916885, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764309764309764, "episode/intrinsic_return": 0.0}
{"step": 281840, "time": 13582.261528491974, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 281856, "time": 13584.490366697311, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 282152, "time": 13596.265234231949, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 282288, "time": 13602.714094877243, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 282688, "time": 13617.86404132843, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 282704, "time": 13619.972756147385, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 283064, "time": 13633.50257730484, "episode/length": 44.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 283240, "time": 13641.163846492767, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 283424, "time": 13649.239526033401, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 283664, "time": 13659.036039352417, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 283792, "time": 13665.192876577377, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 283952, "time": 13672.164550065994, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 284024, "time": 13675.874149084091, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 284336, "time": 13688.087339401245, "episode/length": 309.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9774193548387097, "episode/intrinsic_return": 0.0}
{"step": 284608, "time": 13698.98094010353, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 284768, "time": 13706.089575767517, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 284992, "time": 13715.35344004631, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 285176, "time": 13722.952589988708, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 285456, "time": 13734.405457258224, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 285640, "time": 13742.058805942535, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 285680, "time": 13745.118756055832, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 286144, "time": 13762.260597467422, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 286184, "time": 13764.995638847351, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 286232, "time": 13768.332312822342, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 286504, "time": 13778.851275920868, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 286800, "time": 13792.296611309052, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 286824, "time": 13794.483264684677, "episode/length": 228.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 287000, "time": 13802.096453666687, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 287000, "time": 13802.1060693264, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 287008, "time": 13805.95956158638, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 287432, "time": 13821.679476976395, "episode/length": 52.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 287512, "time": 13825.839539766312, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 287632, "time": 13831.521502017975, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 287904, "time": 13842.265463590622, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 288320, "time": 13857.877816200256, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 288656, "time": 13871.232543230057, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 288824, "time": 13878.270026922226, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 288976, "time": 13885.13919043541, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 289008, "time": 13887.87995505333, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 289016, "time": 13889.488123893738, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 289376, "time": 13903.436234235764, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 289688, "time": 13915.273265123367, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 290016, "time": 13928.167498111725, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13951.194518327713, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9520958083832335}
{"step": 290056, "time": 13952.86355137825, "eval_episode/length": 169.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9823529411764705}
{"step": 290056, "time": 13956.145856380463, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 290056, "time": 13957.773572444916, "eval_episode/length": 204.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 290056, "time": 13959.43088889122, "eval_episode/length": 205.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 290056, "time": 13961.213371515274, "eval_episode/length": 206.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 290056, "time": 13963.996359109879, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 290056, "time": 13966.097395658493, "eval_episode/length": 244.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9755102040816327}
{"step": 290296, "time": 13974.150836706161, "episode/length": 436.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931350114416476, "episode/intrinsic_return": 0.0}
{"step": 290392, "time": 13978.994807958603, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 290400, "time": 13981.104616880417, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 290480, "time": 13985.49958372116, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 290512, "time": 13988.269397735596, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 291240, "time": 14014.243077039719, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 291416, "time": 14021.736235141754, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 291928, "time": 14040.575380563736, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 291960, "time": 14043.240857601166, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 291968, "time": 14045.187833547592, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 291968, "time": 14045.19963312149, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 292168, "time": 14055.011048078537, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 292432, "time": 14065.709442138672, "episode/length": 239.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9708333333333333, "episode/intrinsic_return": 0.0}
{"step": 292728, "time": 14076.99447774887, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 292744, "time": 14079.247531175613, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 293216, "time": 14096.931281805038, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 293312, "time": 14101.714641332626, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 293816, "time": 14120.272776842117, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 294008, "time": 14128.932857513428, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 294184, "time": 14136.410896062851, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 294208, "time": 14138.970591068268, "episode/length": 279.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9892857142857143, "episode/intrinsic_return": 0.0}
{"step": 294400, "time": 14147.135445356369, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 294480, "time": 14151.38663816452, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 295096, "time": 14175.184468507767, "episode/length": 295.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 295184, "time": 14180.05669593811, "episode/length": 233.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 295296, "time": 14185.438353538513, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 295384, "time": 14189.791613340378, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 295504, "time": 14195.683604717255, "episode/length": 164.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 295600, "time": 14200.518336057663, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 296024, "time": 14216.314669847488, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 296040, "time": 14218.423744916916, "episode/length": 54.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 296328, "time": 14229.796344518661, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 296456, "time": 14235.732456445694, "episode/length": 169.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 296808, "time": 14249.06920170784, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 296912, "time": 14254.517451286316, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 297072, "time": 14261.548836708069, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 297240, "time": 14268.54688501358, "episode/length": 242.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9711934156378601, "episode/intrinsic_return": 0.0}
{"step": 297320, "time": 14272.769888401031, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 297544, "time": 14281.906994104385, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 297704, "time": 14288.908789873123, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 298128, "time": 14305.038421154022, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 298192, "time": 14308.910415410995, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 298472, "time": 14319.803480863571, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 298473, "time": 14322.49262046814, "train_stats/sum_log_reward": 5.332142768161638, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.607142857142857, "train_stats/max_log_achievement_collect_sapling": 2.607142857142857, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.080357142857143, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.42857142857142855, "train_stats/max_log_achievement_eat_cow": 0.10714285714285714, "train_stats/max_log_achievement_make_wood_pickaxe": 0.044642857142857144, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.080357142857143, "train_stats/max_log_achievement_wake_up": 1.625, "train_stats/mean_log_entropy": 0.4741866210741656, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.483809976016774, "train/action_min": 0.0, "train/action_std": 3.216999176670523, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04855192148619715, "train/actor_opt_grad_steps": 17875.0, "train/actor_opt_loss": -1.7470349021913374, "train/adv_mag": 0.7424546666443348, "train/adv_max": 0.7193159662625369, "train/adv_mean": 0.004449223993212988, "train/adv_min": -0.5289767305640614, "train/adv_std": 0.07626894425929469, "train/cont_avg": 0.9944278492647058, "train/cont_loss_mean": 0.0002816920414151687, "train/cont_loss_std": 0.008302719785950116, "train/cont_neg_acc": 0.9904761927969316, "train/cont_neg_loss": 0.033078827919884105, "train/cont_pos_acc": 0.9999638164744657, "train/cont_pos_loss": 9.250562960600875e-05, "train/cont_pred": 0.9944266812766299, "train/cont_rate": 0.9944278492647058, "train/dyn_loss_mean": 15.646567828514996, "train/dyn_loss_std": 9.516521117266487, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8783893024220186, "train/extr_critic_critic_opt_grad_steps": 17875.0, "train/extr_critic_critic_opt_loss": 15485.86296530331, "train/extr_critic_mag": 4.839249537271612, "train/extr_critic_max": 4.839249537271612, "train/extr_critic_mean": 0.9369308948516846, "train/extr_critic_min": -0.2279877864262637, "train/extr_critic_std": 1.0300175179453457, "train/extr_return_normed_mag": 1.838876666391597, "train/extr_return_normed_max": 1.838876666391597, "train/extr_return_normed_mean": 0.3067968303666395, "train/extr_return_normed_min": -0.16034448598785436, "train/extr_return_normed_std": 0.33289794076014967, "train/extr_return_rate": 0.47677794252248373, "train/extr_return_raw_mag": 5.853854410788593, "train/extr_return_raw_max": 5.853854410788593, "train/extr_return_raw_mean": 0.9511500796412721, "train/extr_return_raw_min": -0.5435671761412831, "train/extr_return_raw_std": 1.0654914707821959, "train/extr_reward_mag": 1.0184637816513287, "train/extr_reward_max": 1.0184637816513287, "train/extr_reward_mean": 0.02405167666866499, "train/extr_reward_min": -0.35369133598664226, "train/extr_reward_std": 0.1427146092276363, "train/image_loss_mean": 9.156237146433662, "train/image_loss_std": 12.82136046185213, "train/model_loss_mean": 18.5998876655803, "train/model_loss_std": 16.754981370533216, "train/model_opt_grad_norm": 67.32167105113759, "train/model_opt_grad_steps": 17855.816176470587, "train/model_opt_loss": 18473.037655101103, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 997.2426470588235, "train/policy_entropy_mag": 2.3906856249360477, "train/policy_entropy_max": 2.3906856249360477, "train/policy_entropy_mean": 0.515464624061304, "train/policy_entropy_min": 0.07937529918682926, "train/policy_entropy_std": 0.5140350325142636, "train/policy_logprob_mag": 7.438382902566125, "train/policy_logprob_max": -0.009455815847853528, "train/policy_logprob_mean": -0.5143875175100916, "train/policy_logprob_min": -7.438382902566125, "train/policy_logprob_std": 1.0586916615857798, "train/policy_randomness_mag": 0.8438071130829699, "train/policy_randomness_max": 0.8438071130829699, "train/policy_randomness_mean": 0.18193639113622553, "train/policy_randomness_min": 0.02801599741146407, "train/policy_randomness_std": 0.18143180894720204, "train/post_ent_mag": 58.81923611023847, "train/post_ent_max": 58.81923611023847, "train/post_ent_mean": 40.548554196077234, "train/post_ent_min": 21.70770886365105, "train/post_ent_std": 7.133662577937631, "train/prior_ent_mag": 68.49882984161377, "train/prior_ent_max": 68.49882984161377, "train/prior_ent_mean": 56.30886734233183, "train/prior_ent_min": 37.539076426449945, "train/prior_ent_std": 5.280918824322083, "train/rep_loss_mean": 15.646567828514996, "train/rep_loss_std": 9.516521117266487, "train/reward_avg": 0.0219130570823087, "train/reward_loss_mean": 0.05542831462534035, "train/reward_loss_std": 0.26207189623485594, "train/reward_max_data": 1.0117647086872774, "train/reward_max_pred": 1.007897346335299, "train/reward_neg_acc": 0.9927153556662447, "train/reward_neg_loss": 0.03147851301165407, "train/reward_pos_acc": 0.9523937636438538, "train/reward_pos_loss": 0.9234573486096719, "train/reward_pred": 0.02098265917875859, "train/reward_rate": 0.026984719669117647, "eval_stats/sum_log_reward": 4.662499904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.8125, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 6.0465539718279615e-05, "report/cont_loss_std": 0.0015147470403462648, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005073706619441509, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.573515252559446e-05, "report/cont_pred": 0.9970405697822571, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 13.451393127441406, "report/dyn_loss_std": 9.739690780639648, "report/image_loss_mean": 7.905316352844238, "report/image_loss_std": 11.279513359069824, "report/model_loss_mean": 16.027610778808594, "report/model_loss_std": 15.46001148223877, "report/post_ent_mag": 58.097869873046875, "report/post_ent_max": 58.097869873046875, "report/post_ent_mean": 41.51036071777344, "report/post_ent_min": 18.05051612854004, "report/post_ent_std": 6.844685077667236, "report/prior_ent_mag": 68.68428802490234, "report/prior_ent_max": 68.68428802490234, "report/prior_ent_mean": 54.943763732910156, "report/prior_ent_min": 33.48966598510742, "report/prior_ent_std": 5.832225322723389, "report/rep_loss_mean": 13.451393127441406, "report/rep_loss_std": 9.739690780639648, "report/reward_avg": 0.02226562425494194, "report/reward_loss_mean": 0.05139729380607605, "report/reward_loss_std": 0.26600486040115356, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.015040397644043, "report/reward_neg_acc": 0.9949849843978882, "report/reward_neg_loss": 0.030155451968312263, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8357720375061035, "report/reward_pred": 0.020287007093429565, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.4023858006548835e-06, "eval/cont_loss_std": 8.375420293305069e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0016229329630732536, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.3305017293751007e-07, "eval/cont_pred": 0.9980499148368835, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.59801483154297, "eval/dyn_loss_std": 10.456655502319336, "eval/image_loss_mean": 20.333309173583984, "eval/image_loss_std": 28.208250045776367, "eval/model_loss_mean": 32.182945251464844, "eval/model_loss_std": 32.39657211303711, "eval/post_ent_mag": 58.56963348388672, "eval/post_ent_max": 58.56963348388672, "eval/post_ent_mean": 40.763671875, "eval/post_ent_min": 25.4494686126709, "eval/post_ent_std": 6.720261096954346, "eval/prior_ent_mag": 68.68428802490234, "eval/prior_ent_max": 68.68428802490234, "eval/prior_ent_mean": 57.267242431640625, "eval/prior_ent_min": 39.161376953125, "eval/prior_ent_std": 5.460469722747803, "eval/rep_loss_mean": 19.59801483154297, "eval/rep_loss_std": 10.456655502319336, "eval/reward_avg": 0.03027343936264515, "eval/reward_loss_mean": 0.0908239483833313, "eval/reward_loss_std": 0.5594608783721924, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016701221466064, "eval/reward_neg_acc": 0.992943525314331, "eval/reward_neg_loss": 0.04620737209916115, "eval/reward_pos_acc": 0.8125, "eval/reward_pos_loss": 1.4739376306533813, "eval/reward_pred": 0.024109624326229095, "eval/reward_rate": 0.03125, "replay/size": 297969.0, "replay/inserts": 21856.0, "replay/samples": 21856.0, "replay/insert_wait_avg": 1.3356720196904062e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.432035960006155e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 61064.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2577848231538813e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.0769743919373, "timer/env.step_count": 2732.0, "timer/env.step_total": 258.8434555530548, "timer/env.step_frac": 0.258564987682669, "timer/env.step_avg": 0.09474504229614011, "timer/env.step_min": 0.02395915985107422, "timer/env.step_max": 3.3833327293395996, "timer/replay._sample_count": 21856.0, "timer/replay._sample_total": 11.133879899978638, "timer/replay._sample_frac": 0.011121901896446526, "timer/replay._sample_avg": 0.0005094198343694472, "timer/replay._sample_min": 0.00037980079650878906, "timer/replay._sample_max": 0.013428688049316406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3202.0, "timer/agent.policy_total": 55.38929009437561, "timer/agent.policy_frac": 0.05532970142282969, "timer/agent.policy_avg": 0.017298341690935543, "timer/agent.policy_min": 0.009704113006591797, "timer/agent.policy_max": 0.13105225563049316, "timer/dataset_train_count": 1366.0, "timer/dataset_train_total": 0.15933632850646973, "timer/dataset_train_frac": 0.00015916491197218074, "timer/dataset_train_avg": 0.00011664445717896759, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0010733604431152344, "timer/agent.train_count": 1366.0, "timer/agent.train_total": 614.3748733997345, "timer/agent.train_frac": 0.6137139192247539, "timer/agent.train_avg": 0.4497619863834074, "timer/agent.train_min": 0.43598246574401855, "timer/agent.train_max": 1.6423518657684326, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48363780975341797, "timer/agent.report_frac": 0.00048311750457269653, "timer/agent.report_avg": 0.24181890487670898, "timer/agent.report_min": 0.23489117622375488, "timer/agent.report_max": 0.24874663352966309, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.881761224086887e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 21.832227806514602}
{"step": 298512, "time": 14323.925487041473, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 299272, "time": 14350.892966508865, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 299544, "time": 14361.794577121735, "episode/length": 308.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 299552, "time": 14363.908228635788, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 299656, "time": 14368.853166818619, "episode/length": 182.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 299680, "time": 14371.408759593964, "episode/length": 266.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 299872, "time": 14379.488291501999, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 299944, "time": 14383.469218969345, "episode/length": 32.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14403.710349082947, "eval_episode/length": 44.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 300040, "time": 14410.634809017181, "eval_episode/length": 155.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 300040, "time": 14412.70443868637, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 300040, "time": 14414.751668214798, "eval_episode/length": 179.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 300040, "time": 14416.52335691452, "eval_episode/length": 184.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 300040, "time": 14418.848153829575, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 300040, "time": 14421.117294311523, "eval_episode/length": 215.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 300040, "time": 14423.115280866623, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 300472, "time": 14437.542697668076, "episode/length": 403.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 300632, "time": 14444.67662024498, "episode/length": 264.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 300672, "time": 14447.814032316208, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 300824, "time": 14454.270479679108, "episode/length": 159.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 300928, "time": 14459.603039979935, "episode/length": 56.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 300992, "time": 14463.429722309113, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 301224, "time": 14473.272235631943, "episode/length": 208.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 301464, "time": 14482.86528635025, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 301560, "time": 14487.574303865433, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 301752, "time": 14495.65265583992, "episode/length": 94.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 302056, "time": 14507.537972688675, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 302136, "time": 14511.827068090439, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 302368, "time": 14521.448955059052, "episode/length": 216.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 302712, "time": 14534.597706317902, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 302912, "time": 14543.058717012405, "episode/length": 180.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 303032, "time": 14548.589655399323, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 303160, "time": 14555.984451770782, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 303200, "time": 14559.303918361664, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 303592, "time": 14574.06058716774, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 303616, "time": 14576.763437747955, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 303752, "time": 14582.81132531166, "episode/length": 201.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 304208, "time": 14600.13243818283, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 304384, "time": 14607.613122463226, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 304592, "time": 14616.326431035995, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 304616, "time": 14618.558120250702, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 305032, "time": 14634.457870721817, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9650655021834061, "episode/intrinsic_return": 0.0}
{"step": 305048, "time": 14636.57184100151, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 305096, "time": 14639.836349010468, "episode/length": 187.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 305768, "time": 14664.243883371353, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 305880, "time": 14669.611402273178, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 305968, "time": 14674.378014087677, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 306104, "time": 14680.353444337845, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 306360, "time": 14690.642980575562, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 306496, "time": 14696.983860969543, "episode/length": 359.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 306624, "time": 14702.810557126999, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 307128, "time": 14721.447422266006, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 307304, "time": 14729.389590263367, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 307592, "time": 14740.774512767792, "episode/length": 213.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 307776, "time": 14748.773293495178, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9513888888888888, "episode/intrinsic_return": 0.0}
{"step": 307840, "time": 14752.551409244537, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 308112, "time": 14763.305678844452, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 308128, "time": 14765.360305309296, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 308200, "time": 14769.215597391129, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 308224, "time": 14771.949905395508, "episode/length": 47.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 308896, "time": 14796.171168804169, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 309088, "time": 14804.35497713089, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 309472, "time": 14818.898972988129, "episode/length": 292.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 309648, "time": 14826.425926208496, "episode/length": 256.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 309664, "time": 14828.704776287079, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 309688, "time": 14831.163194656372, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 309752, "time": 14834.913598060608, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14863.35589647293, "eval_episode/length": 58.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 310024, "time": 14868.871122121811, "eval_episode/length": 145.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 310024, "time": 14871.689629793167, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 310024, "time": 14873.315346240997, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 310024, "time": 14875.577671289444, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 310024, "time": 14877.768982887268, "eval_episode/length": 179.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 310024, "time": 14879.931292057037, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9613259668508287}
{"step": 310024, "time": 14882.140812397003, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 310200, "time": 14888.15107178688, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 310784, "time": 14909.752579689026, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 310928, "time": 14916.268326759338, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9548387096774194, "episode/intrinsic_return": 0.0}
{"step": 310952, "time": 14918.34534573555, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 311080, "time": 14924.59470129013, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 311224, "time": 14931.0712621212, "episode/length": 218.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 311352, "time": 14938.596201896667, "episode/length": 393.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 311848, "time": 14957.064635515213, "episode/length": 205.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 311952, "time": 14962.40292263031, "episode/length": 285.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 312296, "time": 14975.482728481293, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 312400, "time": 14980.892548799515, "episode/length": 164.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 312456, "time": 14984.265444278717, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 312496, "time": 14987.419553995132, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 312528, "time": 14990.083220720291, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 312928, "time": 15005.194735050201, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 313144, "time": 15014.000133991241, "episode/length": 161.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 313504, "time": 15027.890122652054, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 313760, "time": 15038.240405082703, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 313760, "time": 15038.249707221985, "episode/length": 153.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 313808, "time": 15043.453569173813, "episode/length": 168.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 314272, "time": 15060.841413736343, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 314320, "time": 15064.05359339714, "episode/length": 227.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 314704, "time": 15078.850566387177, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 315040, "time": 15091.721521377563, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 315120, "time": 15096.045885324478, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 315312, "time": 15104.364485263824, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 315560, "time": 15113.997364282608, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 315696, "time": 15120.327715873718, "episode/length": 47.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 315760, "time": 15124.088142633438, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 315808, "time": 15127.309537649155, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 315944, "time": 15133.390229701996, "episode/length": 47.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 316520, "time": 15154.442309617996, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 316520, "time": 15154.474601984024, "episode/length": 226.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 316544, "time": 15158.81780076027, "episode/length": 424.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 316840, "time": 15170.352056264877, "episode/length": 214.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 316920, "time": 15174.689621448517, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 317232, "time": 15187.0854742527, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 317312, "time": 15191.422822237015, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 317360, "time": 15194.7412378788, "episode/length": 199.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 317904, "time": 15215.13840675354, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 317968, "time": 15218.91995382309, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 318152, "time": 15226.713214159012, "episode/length": 200.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 318384, "time": 15236.277423381805, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 318504, "time": 15241.740001678467, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 318664, "time": 15248.940757989883, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 319016, "time": 15262.744336128235, "episode/length": 212.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 319432, "time": 15278.464562654495, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 319576, "time": 15286.492020606995, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 319952, "time": 15300.980886220932, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 319952, "time": 15300.990229845047, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15321.49756360054, "eval_episode/length": 48.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 320008, "time": 15329.747799634933, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 320008, "time": 15332.185796260834, "eval_episode/length": 179.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 320008, "time": 15333.8053252697, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 320008, "time": 15335.553292751312, "eval_episode/length": 184.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 320008, "time": 15337.772476196289, "eval_episode/length": 197.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 320008, "time": 15339.492640256882, "eval_episode/length": 201.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9653465346534653}
{"step": 320008, "time": 15342.870401859283, "eval_episode/length": 236.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 320009, "time": 15343.899206399918, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.422935203269676, "train/action_min": 0.0, "train/action_std": 3.1920151834134702, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04860124085788373, "train/actor_opt_grad_steps": 19230.0, "train/actor_opt_loss": -7.570475910535014, "train/adv_mag": 0.7356870905116752, "train/adv_max": 0.7110992087258233, "train/adv_mean": 0.0033361175567632826, "train/adv_min": -0.5228001561429766, "train/adv_std": 0.07561951790142943, "train/cont_avg": 0.9943793402777777, "train/cont_loss_mean": 0.00024474542181249286, "train/cont_loss_std": 0.007157069359359243, "train/cont_neg_acc": 0.9928216084615508, "train/cont_neg_loss": 0.02263246522986957, "train/cont_pos_acc": 0.9999635992226777, "train/cont_pos_loss": 0.00011201644363228314, "train/cont_pred": 0.9943789217207167, "train/cont_rate": 0.9943793402777777, "train/dyn_loss_mean": 15.636453741568106, "train/dyn_loss_std": 9.441150410970051, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8494330437095077, "train/extr_critic_critic_opt_grad_steps": 19230.0, "train/extr_critic_critic_opt_loss": 15472.132277199074, "train/extr_critic_mag": 4.868297428554959, "train/extr_critic_max": 4.868297428554959, "train/extr_critic_mean": 0.9348588669741595, "train/extr_critic_min": -0.20981058456279614, "train/extr_critic_std": 1.034740697896039, "train/extr_return_normed_mag": 1.8544865413948342, "train/extr_return_normed_max": 1.8544865413948342, "train/extr_return_normed_mean": 0.29994611022648987, "train/extr_return_normed_min": -0.1630172815311838, "train/extr_return_normed_std": 0.33522662454181246, "train/extr_return_rate": 0.4574932725341232, "train/extr_return_raw_mag": 5.9039940798724135, "train/extr_return_raw_max": 5.9039940798724135, "train/extr_return_raw_mean": 0.9454663104481167, "train/extr_return_raw_min": -0.5321640439883426, "train/extr_return_raw_std": 1.0696017976160404, "train/extr_reward_mag": 1.018558519857901, "train/extr_reward_max": 1.018558519857901, "train/extr_reward_mean": 0.02414787170925626, "train/extr_reward_min": -0.3580647027051007, "train/extr_reward_std": 0.14347564627726872, "train/image_loss_mean": 8.825254231912119, "train/image_loss_std": 12.911223616423431, "train/model_loss_mean": 18.262586332250525, "train/model_loss_std": 16.77357044926396, "train/model_opt_grad_norm": 69.10317531161839, "train/model_opt_grad_steps": 19210.0, "train/model_opt_loss": 16418.45023148148, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 902.7777777777778, "train/policy_entropy_mag": 2.339405658509996, "train/policy_entropy_max": 2.339405658509996, "train/policy_entropy_mean": 0.496739297442966, "train/policy_entropy_min": 0.079375277183674, "train/policy_entropy_std": 0.4811226643897869, "train/policy_logprob_mag": 7.438383063563594, "train/policy_logprob_max": -0.009455801249930153, "train/policy_logprob_mean": -0.49724124471346537, "train/policy_logprob_min": -7.438383063563594, "train/policy_logprob_std": 1.0504818148083157, "train/policy_randomness_mag": 0.8257075375980801, "train/policy_randomness_max": 0.8257075375980801, "train/policy_randomness_mean": 0.17532717353767818, "train/policy_randomness_min": 0.028015989658457262, "train/policy_randomness_std": 0.16981518737695836, "train/post_ent_mag": 59.098318622730396, "train/post_ent_max": 59.098318622730396, "train/post_ent_mean": 40.74578015362775, "train/post_ent_min": 21.680177024558738, "train/post_ent_std": 7.231418319984718, "train/prior_ent_mag": 68.79616659658926, "train/prior_ent_max": 68.79616659658926, "train/prior_ent_mean": 56.49768673932111, "train/prior_ent_min": 38.59599937156395, "train/prior_ent_std": 5.1370052443610295, "train/rep_loss_mean": 15.636453741568106, "train/rep_loss_std": 9.441150410970051, "train/reward_avg": 0.022868923504871352, "train/reward_loss_mean": 0.05521521424805677, "train/reward_loss_std": 0.26077243442888615, "train/reward_max_data": 1.022222227520413, "train/reward_max_pred": 1.0123655902014839, "train/reward_neg_acc": 0.9928493420283, "train/reward_neg_loss": 0.03039013882064157, "train/reward_pos_acc": 0.9521123232664885, "train/reward_pos_loss": 0.9237263427840339, "train/reward_pred": 0.021827218177969808, "train/reward_rate": 0.027900752314814814, "train_stats/sum_log_reward": 5.191743045498471, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.605504587155964, "train_stats/max_log_achievement_collect_sapling": 2.8256880733944953, "train_stats/max_log_achievement_collect_stone": 0.07339449541284404, "train_stats/max_log_achievement_collect_wood": 6.36697247706422, "train_stats/max_log_achievement_defeat_skeleton": 0.01834862385321101, "train_stats/max_log_achievement_defeat_zombie": 0.3761467889908257, "train_stats/max_log_achievement_eat_cow": 0.07339449541284404, "train_stats/max_log_achievement_make_wood_pickaxe": 0.045871559633027525, "train_stats/max_log_achievement_make_wood_sword": 0.01834862385321101, "train_stats/max_log_achievement_place_plant": 2.669724770642202, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.6055045871559632, "train_stats/max_log_achievement_wake_up": 1.5229357798165137, "train_stats/mean_log_entropy": 0.4671432572767275, "eval_stats/sum_log_reward": 5.183333307504654, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.333333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.5416666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.458333333333333, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4583333333333335, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.254236359382048e-05, "report/cont_loss_std": 0.0012649546843022108, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00571324210613966, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.364865576964803e-05, "report/cont_pred": 0.9931790828704834, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 17.06580352783203, "report/dyn_loss_std": 9.243300437927246, "report/image_loss_mean": 10.425230979919434, "report/image_loss_std": 14.33945369720459, "report/model_loss_mean": 20.723663330078125, "report/model_loss_std": 18.379806518554688, "report/post_ent_mag": 58.135555267333984, "report/post_ent_max": 58.135555267333984, "report/post_ent_mean": 39.38990020751953, "report/post_ent_min": 22.50372314453125, "report/post_ent_std": 7.0230302810668945, "report/prior_ent_mag": 68.36837005615234, "report/prior_ent_max": 68.36837005615234, "report/prior_ent_mean": 56.43117141723633, "report/prior_ent_min": 36.907745361328125, "report/prior_ent_std": 5.502392768859863, "report/rep_loss_mean": 17.06580352783203, "report/rep_loss_std": 9.243300437927246, "report/reward_avg": 0.02207031100988388, "report/reward_loss_mean": 0.05888637155294418, "report/reward_loss_std": 0.20192354917526245, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0099563598632812, "report/reward_neg_acc": 0.9849246144294739, "report/reward_neg_loss": 0.04000367224216461, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.706758439540863, "report/reward_pred": 0.022993886843323708, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 6.326212769636186e-06, "eval/cont_loss_std": 2.995036993524991e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00039801080129109323, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.175327714823652e-06, "eval/cont_pred": 0.9970663785934448, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.174407958984375, "eval/dyn_loss_std": 10.887085914611816, "eval/image_loss_mean": 18.335527420043945, "eval/image_loss_std": 27.319963455200195, "eval/model_loss_mean": 29.951602935791016, "eval/model_loss_std": 31.538103103637695, "eval/post_ent_mag": 57.2768440246582, "eval/post_ent_max": 57.2768440246582, "eval/post_ent_mean": 40.37471389770508, "eval/post_ent_min": 21.747909545898438, "eval/post_ent_std": 6.676168441772461, "eval/prior_ent_mag": 68.36837005615234, "eval/prior_ent_max": 68.36837005615234, "eval/prior_ent_mean": 56.42837905883789, "eval/prior_ent_min": 39.40568542480469, "eval/prior_ent_std": 4.985683441162109, "eval/rep_loss_mean": 19.174407958984375, "eval/rep_loss_std": 10.887085914611816, "eval/reward_avg": 0.02451171912252903, "eval/reward_loss_mean": 0.11142360419034958, "eval/reward_loss_std": 0.6173727512359619, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9975845813751221, "eval/reward_neg_acc": 0.9829317927360535, "eval/reward_neg_loss": 0.05331725254654884, "eval/reward_pos_acc": 0.7500000596046448, "eval/reward_pos_loss": 2.178349494934082, "eval/reward_pred": 0.022373881191015244, "eval/reward_rate": 0.02734375, "replay/size": 319505.0, "replay/inserts": 21536.0, "replay/samples": 21536.0, "replay/insert_wait_avg": 1.351599530337647e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.559073449598201e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 66232.0, "eval_replay/inserts": 5168.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2429321513456456e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1021.389476776123, "timer/env.step_count": 2692.0, "timer/env.step_total": 255.36169123649597, "timer/env.step_frac": 0.2500140221167252, "timer/env.step_avg": 0.0948594692557563, "timer/env.step_min": 0.024170875549316406, "timer/env.step_max": 3.624210834503174, "timer/replay._sample_count": 21536.0, "timer/replay._sample_total": 11.116384029388428, "timer/replay._sample_frac": 0.010883589739416331, "timer/replay._sample_avg": 0.0005161768215726424, "timer/replay._sample_min": 0.0004036426544189453, "timer/replay._sample_max": 0.011458396911621094, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3338.0, "timer/agent.policy_total": 58.951948165893555, "timer/agent.policy_frac": 0.05771740311244185, "timer/agent.policy_avg": 0.017660859246822515, "timer/agent.policy_min": 0.009647607803344727, "timer/agent.policy_max": 0.13051199913024902, "timer/dataset_train_count": 1346.0, "timer/dataset_train_total": 0.1578378677368164, "timer/dataset_train_frac": 0.00015453249845006253, "timer/dataset_train_avg": 0.00011726438910610432, "timer/dataset_train_min": 0.00010132789611816406, "timer/dataset_train_max": 0.0003895759582519531, "timer/agent.train_count": 1346.0, "timer/agent.train_total": 605.7916233539581, "timer/agent.train_frac": 0.5931054089827291, "timer/agent.train_avg": 0.4500680708424652, "timer/agent.train_min": 0.4362199306488037, "timer/agent.train_max": 1.6143572330474854, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.479203462600708, "timer/agent.report_frac": 0.0004691682002767921, "timer/agent.report_avg": 0.239601731300354, "timer/agent.report_min": 0.2252349853515625, "timer/agent.report_max": 0.2539684772491455, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.871136417231759e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 21.084718223611503}
{"step": 320024, "time": 15343.992322683334, "episode/length": 55.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 320256, "time": 15354.542252063751, "episode/length": 218.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 320320, "time": 15358.236360549927, "episode/length": 434.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9977011494252873, "episode/intrinsic_return": 0.0}
{"step": 320464, "time": 15364.764506101608, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 320576, "time": 15370.405398368835, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 320800, "time": 15380.208439588547, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 320872, "time": 15383.950562953949, "episode/length": 339.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 321256, "time": 15398.431861162186, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 321448, "time": 15406.671594142914, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 321952, "time": 15425.631137371063, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 321960, "time": 15427.39057636261, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 321976, "time": 15429.676867961884, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 322160, "time": 15437.760990142822, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 322376, "time": 15446.348393917084, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 322456, "time": 15450.69049024582, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 322488, "time": 15453.373326778412, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 322664, "time": 15460.958312988281, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 322992, "time": 15473.958930969238, "episode/length": 128.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 323328, "time": 15486.872981786728, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 323704, "time": 15501.077814817429, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 323728, "time": 15503.715460538864, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 323896, "time": 15510.811992883682, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 323960, "time": 15514.580823659897, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 324352, "time": 15530.359740972519, "episode/length": 232.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 324720, "time": 15544.364989042282, "episode/length": 173.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 324856, "time": 15550.658288002014, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 324952, "time": 15555.934003829956, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 325048, "time": 15560.672207593918, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 325168, "time": 15566.467355966568, "episode/length": 348.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.997134670487106, "episode/intrinsic_return": 0.0}
{"step": 325448, "time": 15578.021568536758, "episode/length": 49.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 325488, "time": 15581.42738366127, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 325616, "time": 15587.307255744934, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 325656, "time": 15590.021997451782, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 326064, "time": 15605.661757230759, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 326200, "time": 15611.771359682083, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 326560, "time": 15625.637295246124, "episode/length": 138.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 326584, "time": 15627.77773475647, "episode/length": 203.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 326696, "time": 15633.143508911133, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 326768, "time": 15637.40596652031, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 327128, "time": 15651.105516433716, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 327400, "time": 15662.038665771484, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 327640, "time": 15671.760058164597, "episode/length": 196.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 327640, "time": 15671.769217967987, "episode/length": 134.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 327976, "time": 15687.93740272522, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 328056, "time": 15692.198722839355, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 328072, "time": 15694.251755475998, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 328488, "time": 15710.00814461708, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 328512, "time": 15712.624772787094, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 328560, "time": 15715.877760410309, "episode/length": 362.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9972451790633609, "episode/intrinsic_return": 0.0}
{"step": 328616, "time": 15719.175432920456, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 329216, "time": 15742.532309055328, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 329312, "time": 15747.403861284256, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 329392, "time": 15751.624386548996, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 329728, "time": 15764.564585208893, "episode/length": 41.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 329760, "time": 15767.275188446045, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 329896, "time": 15773.207466840744, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 330024, "time": 15779.465123176575, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15803.926462888718, "eval_episode/length": 150.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9668874172185431}
{"step": 330096, "time": 15805.846769809723, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 330096, "time": 15807.882219552994, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 330096, "time": 15809.928847789764, "eval_episode/length": 176.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 330096, "time": 15811.73639011383, "eval_episode/length": 180.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 330096, "time": 15813.714509010315, "eval_episode/length": 38.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 330096, "time": 15815.71975183487, "eval_episode/length": 199.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.98}
{"step": 330096, "time": 15818.410609960556, "eval_episode/length": 225.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 330120, "time": 15819.006823539734, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 330120, "time": 15819.014699220657, "episode/length": 48.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 330392, "time": 15831.585862874985, "episode/length": 45.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 330528, "time": 15837.993354558945, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 330840, "time": 15850.0273001194, "episode/length": 55.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 331120, "time": 15861.229477405548, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 331144, "time": 15863.354891777039, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 331160, "time": 15865.70812034607, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 331168, "time": 15867.806187868118, "episode/length": 334.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 331616, "time": 15884.580576181412, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 331912, "time": 15896.077726364136, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 331952, "time": 15899.31696486473, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 332216, "time": 15909.632739543915, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 332552, "time": 15922.987780094147, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 332592, "time": 15926.379528045654, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 332944, "time": 15940.04648900032, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 332968, "time": 15942.195369243622, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 332992, "time": 15944.803694486618, "episode/length": 230.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 333312, "time": 15957.364433526993, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 333336, "time": 15959.460095405579, "episode/length": 177.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 333720, "time": 15974.150926113129, "episode/length": 47.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 333784, "time": 15977.812265396118, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 334072, "time": 15989.624058008194, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 334272, "time": 15998.22072482109, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 334456, "time": 16005.958000659943, "episode/length": 142.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 334616, "time": 16012.933783769608, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 334752, "time": 16019.52031135559, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 335184, "time": 16035.905957698822, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 335360, "time": 16043.408029079437, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 335640, "time": 16054.151055335999, "episode/length": 239.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 335680, "time": 16057.269048452377, "episode/length": 115.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 335696, "time": 16059.430245399475, "episode/length": 392.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 335760, "time": 16063.296469211578, "episode/length": 7.0, "episode/score": -0.8999999761581421, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 336224, "time": 16082.032577991486, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 336272, "time": 16085.260938882828, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 336328, "time": 16088.548304080963, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 336664, "time": 16101.743528366089, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 336856, "time": 16109.810358047485, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 337240, "time": 16124.55886054039, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 337616, "time": 16139.109612703323, "episode/length": 417.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 337744, "time": 16145.017423152924, "episode/length": 134.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 337848, "time": 16150.048305273056, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 337976, "time": 16155.94902586937, "episode/length": 291.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 338776, "time": 16184.804146766663, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 339024, "time": 16195.001183986664, "episode/length": 343.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 339400, "time": 16209.151360034943, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 339504, "time": 16214.57225227356, "episode/length": 219.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 339520, "time": 16216.787769079208, "episode/length": 237.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 339576, "time": 16220.036088466644, "episode/length": 405.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 339592, "time": 16222.059768915176, "episode/length": 201.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 339896, "time": 16233.91350030899, "episode/length": 37.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 16256.835618257523, "eval_episode/length": 40.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 340080, "time": 16262.606567382812, "eval_episode/length": 134.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9555555555555556}
{"step": 340080, "time": 16264.922579050064, "eval_episode/length": 149.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 340080, "time": 16267.772830247879, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 340080, "time": 16270.226140499115, "eval_episode/length": 189.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 340080, "time": 16272.125776290894, "eval_episode/length": 195.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 340080, "time": 16273.745154380798, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 340080, "time": 16276.333407878876, "eval_episode/length": 220.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9773755656108597}
{"step": 340136, "time": 16278.039765119553, "episode/length": 409.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 340184, "time": 16281.290380954742, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 340928, "time": 16308.441859006882, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 340944, "time": 16310.654113531113, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 340984, "time": 16313.379645109177, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 341360, "time": 16327.908230304718, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 341392, "time": 16330.629984140396, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 341528, "time": 16336.488385677338, "episode/length": 312.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 341624, "time": 16341.554377794266, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 341625, "time": 16344.18890953064, "train_stats/sum_log_reward": 4.860683685566625, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.3247863247863245, "train_stats/max_log_achievement_collect_sapling": 2.675213675213675, "train_stats/max_log_achievement_collect_stone": 0.017094017094017096, "train_stats/max_log_achievement_collect_wood": 7.145299145299146, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.23076923076923078, "train_stats/max_log_achievement_eat_cow": 0.03418803418803419, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1623931623931624, "train_stats/max_log_achievement_make_wood_sword": 0.017094017094017096, "train_stats/max_log_achievement_place_plant": 2.5811965811965814, "train_stats/max_log_achievement_place_stone": 0.008547008547008548, "train_stats/max_log_achievement_place_table": 2.8547008547008548, "train_stats/max_log_achievement_wake_up": 1.547008547008547, "train_stats/mean_log_entropy": 0.4886630387642445, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.465284559461805, "train/action_min": 0.0, "train/action_std": 3.360821114646064, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04780519190761778, "train/actor_opt_grad_steps": 20580.0, "train/actor_opt_loss": -7.796860331738436, "train/adv_mag": 0.7102847677690012, "train/adv_max": 0.6893764054333722, "train/adv_mean": 0.003140722710803082, "train/adv_min": -0.520130420393414, "train/adv_std": 0.07455071014938532, "train/cont_avg": 0.9946180555555556, "train/cont_loss_mean": 0.000163645697443405, "train/cont_loss_std": 0.0041602278441974635, "train/cont_neg_acc": 0.9947325106020327, "train/cont_neg_loss": 0.013726512375800397, "train/cont_pos_acc": 0.9999781630657337, "train/cont_pos_loss": 7.437888583549718e-05, "train/cont_pred": 0.9946248637305366, "train/cont_rate": 0.9946180555555556, "train/dyn_loss_mean": 15.426756993046514, "train/dyn_loss_std": 9.486734976591887, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8194142663920367, "train/extr_critic_critic_opt_grad_steps": 20580.0, "train/extr_critic_critic_opt_loss": 15434.1955078125, "train/extr_critic_mag": 4.791994437464961, "train/extr_critic_max": 4.791994437464961, "train/extr_critic_mean": 0.9087861467290808, "train/extr_critic_min": -0.25490486798463047, "train/extr_critic_std": 1.02609545301508, "train/extr_return_normed_mag": 1.827196756998698, "train/extr_return_normed_max": 1.827196756998698, "train/extr_return_normed_mean": 0.3078497510265421, "train/extr_return_normed_min": -0.17164845461094821, "train/extr_return_normed_std": 0.33354798202161434, "train/extr_return_rate": 0.4667038262994201, "train/extr_return_raw_mag": 5.7519336771082, "train/extr_return_raw_max": 5.7519336771082, "train/extr_return_raw_mean": 0.9187897275995325, "train/extr_return_raw_min": -0.606634725023199, "train/extr_return_raw_std": 1.0609074888405976, "train/extr_reward_mag": 1.0142747154942264, "train/extr_reward_max": 1.0142747154942264, "train/extr_reward_mean": 0.024204047196717173, "train/extr_reward_min": -0.37610652888262713, "train/extr_reward_std": 0.1454417559283751, "train/image_loss_mean": 8.478481479927346, "train/image_loss_std": 12.221732785966662, "train/model_loss_mean": 17.787285211351183, "train/model_loss_std": 16.109496724164046, "train/model_opt_grad_norm": 70.69037071626578, "train/model_opt_grad_steps": 20559.066666666666, "train/model_opt_loss": 14022.754242621528, "train/model_opt_model_opt_grad_overflow": 0.007407407407407408, "train/model_opt_model_opt_grad_scale": 782.4074074074074, "train/policy_entropy_mag": 2.3456421463577835, "train/policy_entropy_max": 2.3456421463577835, "train/policy_entropy_mean": 0.5287360805052298, "train/policy_entropy_min": 0.0793752493681731, "train/policy_entropy_std": 0.532463088521251, "train/policy_logprob_mag": 7.438383067095721, "train/policy_logprob_max": -0.009455753062610274, "train/policy_logprob_mean": -0.5287484155760871, "train/policy_logprob_min": -7.438383067095721, "train/policy_logprob_std": 1.0684741117336132, "train/policy_randomness_mag": 0.8279087411032783, "train/policy_randomness_max": 0.8279087411032783, "train/policy_randomness_mean": 0.18662063313855065, "train/policy_randomness_min": 0.028015979765741914, "train/policy_randomness_std": 0.18793610290244775, "train/post_ent_mag": 59.30057454992224, "train/post_ent_max": 59.30057454992224, "train/post_ent_mean": 41.0382942199707, "train/post_ent_min": 21.81183292247631, "train/post_ent_std": 7.281313041404442, "train/prior_ent_mag": 68.89588786937573, "train/prior_ent_max": 68.89588786937573, "train/prior_ent_mean": 56.49420355337637, "train/prior_ent_min": 39.43221075269911, "train/prior_ent_std": 5.0225701332092285, "train/rep_loss_mean": 15.426756993046514, "train/rep_loss_std": 9.486734976591887, "train/reward_avg": 0.022658419898814626, "train/reward_loss_mean": 0.05258612232627692, "train/reward_loss_std": 0.24812433587180244, "train/reward_max_data": 1.0140740774295949, "train/reward_max_pred": 1.0099172671635945, "train/reward_neg_acc": 0.9930195764259055, "train/reward_neg_loss": 0.029375368591260026, "train/reward_pos_acc": 0.9637538697984483, "train/reward_pos_loss": 0.8780962630554482, "train/reward_pred": 0.021997621224296313, "train/reward_rate": 0.027372685185185184, "eval_stats/sum_log_reward": 4.474999907426536, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.4375, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.002455418696627021, "report/cont_loss_std": 0.06002720445394516, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 0.29635530710220337, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.0007231993949972093, "report/cont_pred": 0.994442880153656, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.303942680358887, "report/dyn_loss_std": 9.815980911254883, "report/image_loss_mean": 7.007339954376221, "report/image_loss_std": 10.042374610900879, "report/model_loss_mean": 15.02411937713623, "report/model_loss_std": 14.379279136657715, "report/post_ent_mag": 59.25493621826172, "report/post_ent_max": 59.25493621826172, "report/post_ent_mean": 43.01787567138672, "report/post_ent_min": 22.373313903808594, "report/post_ent_std": 7.6684889793396, "report/prior_ent_mag": 69.13362121582031, "report/prior_ent_max": 69.13362121582031, "report/prior_ent_mean": 56.472312927246094, "report/prior_ent_min": 43.30681228637695, "report/prior_ent_std": 4.864024639129639, "report/rep_loss_mean": 13.303942680358887, "report/rep_loss_std": 9.815980911254883, "report/reward_avg": 0.02070312388241291, "report/reward_loss_mean": 0.03195837140083313, "report/reward_loss_std": 0.13733431696891785, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021157264709473, "report/reward_neg_acc": 0.9989989995956421, "report/reward_neg_loss": 0.01526659820228815, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.698961615562439, "report/reward_pred": 0.020453382283449173, "report/reward_rate": 0.0244140625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0007811706163920462, "eval/cont_loss_std": 0.022376911714673042, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.004874184262007475, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.000765119562856853, "eval/cont_pred": 0.9955512285232544, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 19.28449249267578, "eval/dyn_loss_std": 10.72561264038086, "eval/image_loss_mean": 17.899520874023438, "eval/image_loss_std": 23.505531311035156, "eval/model_loss_mean": 29.57672691345215, "eval/model_loss_std": 27.559476852416992, "eval/post_ent_mag": 60.2528190612793, "eval/post_ent_max": 60.2528190612793, "eval/post_ent_mean": 41.08720016479492, "eval/post_ent_min": 22.177133560180664, "eval/post_ent_std": 6.9025983810424805, "eval/prior_ent_mag": 69.13362121582031, "eval/prior_ent_max": 69.13362121582031, "eval/prior_ent_mean": 57.75828552246094, "eval/prior_ent_min": 39.02540588378906, "eval/prior_ent_std": 5.0557050704956055, "eval/rep_loss_mean": 19.28449249267578, "eval/rep_loss_std": 10.72561264038086, "eval/reward_avg": 0.02656250074505806, "eval/reward_loss_mean": 0.10572975873947144, "eval/reward_loss_std": 0.7614877820014954, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0035676956176758, "eval/reward_neg_acc": 0.9929506778717041, "eval/reward_neg_loss": 0.021029658615589142, "eval/reward_pos_acc": 0.7096773982048035, "eval/reward_pos_loss": 2.8188652992248535, "eval/reward_pred": 0.018076758831739426, "eval/reward_rate": 0.0302734375, "replay/size": 341121.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.321901752717578e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.683859323237579e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 69808.0, "eval_replay/inserts": 3576.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.196359894686364e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2720463275909, "timer/env.step_count": 2702.0, "timer/env.step_total": 266.6171019077301, "timer/env.step_frac": 0.26654458943103615, "timer/env.step_avg": 0.0986739829414249, "timer/env.step_min": 0.024196386337280273, "timer/env.step_max": 3.4389610290527344, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.208508253097534, "timer/replay._sample_frac": 0.011205459848896674, "timer/replay._sample_avg": 0.0005185283240700192, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.023384571075439453, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3149.0, "timer/agent.policy_total": 53.874809980392456, "timer/agent.policy_frac": 0.053860157522335035, "timer/agent.policy_avg": 0.017108545563795634, "timer/agent.policy_min": 0.009523153305053711, "timer/agent.policy_max": 0.10926461219787598, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.1625080108642578, "timer/dataset_train_frac": 0.00016246381318051563, "timer/dataset_train_avg": 0.00012028720271225597, "timer/dataset_train_min": 0.00010061264038085938, "timer/dataset_train_max": 0.0010836124420166016, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 612.6254961490631, "timer/agent.train_frac": 0.6124588789602415, "timer/agent.train_avg": 0.4534607669497136, "timer/agent.train_min": 0.43651461601257324, "timer/agent.train_max": 1.6999294757843018, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4883081912994385, "timer/agent.report_frac": 0.00048817538497873474, "timer/agent.report_avg": 0.24415409564971924, "timer/agent.report_min": 0.23665237426757812, "timer/agent.report_max": 0.25165581703186035, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050927818791153e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.609792235925482}
{"step": 341816, "time": 16350.487061023712, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 342160, "time": 16363.991398334503, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 342368, "time": 16372.606030702591, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 342576, "time": 16381.146003961563, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 342880, "time": 16393.252497434616, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 342912, "time": 16395.87981724739, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 343184, "time": 16406.738505601883, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 343264, "time": 16411.084031820297, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 343424, "time": 16418.080357551575, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 343904, "time": 16435.9902946949, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 343984, "time": 16440.356343746185, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 344112, "time": 16447.765348911285, "episode/length": 286.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 344480, "time": 16461.741818904877, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 344720, "time": 16471.524138450623, "episode/length": 293.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 344744, "time": 16473.747302770615, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 345088, "time": 16487.220165491104, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 345344, "time": 16497.36228108406, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 345384, "time": 16500.145622253418, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 345472, "time": 16504.819341421127, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 345704, "time": 16513.99409222603, "episode/length": 224.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 346008, "time": 16525.619899749756, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 346192, "time": 16533.62802529335, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 346488, "time": 16545.14871430397, "episode/length": 250.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 346560, "time": 16549.355684280396, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 346736, "time": 16557.059137821198, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 346736, "time": 16557.06877541542, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 347256, "time": 16577.67035984993, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 347504, "time": 16587.9282040596, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 347560, "time": 16591.090780496597, "episode/length": 102.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 347608, "time": 16594.30286383629, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 347952, "time": 16607.803996801376, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 348128, "time": 16615.27887749672, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 348200, "time": 16619.123436689377, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 348256, "time": 16622.817608833313, "episode/length": 347.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 348744, "time": 16640.58342075348, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 348912, "time": 16648.047820329666, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 348952, "time": 16650.73610854149, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 349224, "time": 16661.5858001709, "episode/length": 38.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 349224, "time": 16661.600034952164, "episode/length": 214.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 349304, "time": 16667.626051664352, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 349680, "time": 16682.05295729637, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 349760, "time": 16686.237871408463, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 349800, "time": 16688.961431980133, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 349840, "time": 16692.27935886383, "episode/length": 136.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16716.10015487671, "eval_episode/length": 38.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 350064, "time": 16718.225049734116, "eval_episode/length": 49.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9}
{"step": 350064, "time": 16723.87185549736, "eval_episode/length": 139.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 350064, "time": 16726.060920000076, "eval_episode/length": 152.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 350064, "time": 16728.65578866005, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 350064, "time": 16730.468967199326, "eval_episode/length": 178.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 350064, "time": 16733.0647649765, "eval_episode/length": 198.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 350064, "time": 16736.291135787964, "eval_episode/length": 181.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 350384, "time": 16747.051687002182, "episode/length": 178.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 350720, "time": 16759.985411167145, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 350816, "time": 16764.784739017487, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 351016, "time": 16772.824474573135, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 351208, "time": 16780.9180662632, "episode/length": 247.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 351312, "time": 16786.18794465065, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 351336, "time": 16788.308579206467, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 351584, "time": 16798.444689273834, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 351984, "time": 16813.739469766617, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 352056, "time": 16817.53888654709, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 352152, "time": 16822.337958812714, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 352512, "time": 16837.671888828278, "episode/length": 44.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 352568, "time": 16841.085612535477, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 352792, "time": 16850.282779932022, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 352864, "time": 16854.498161554337, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 353352, "time": 16872.434454202652, "episode/length": 267.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 353400, "time": 16875.632281780243, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 353464, "time": 16879.53313922882, "episode/length": 118.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9495798319327731, "episode/intrinsic_return": 0.0}
{"step": 353512, "time": 16882.706018924713, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 353776, "time": 16893.491678714752, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 353800, "time": 16895.60520720482, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 354032, "time": 16905.325875997543, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 354824, "time": 16933.25921702385, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 354928, "time": 16938.677904605865, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 355208, "time": 16949.536061763763, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 355264, "time": 16953.270490407944, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 355312, "time": 16956.531570911407, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 355376, "time": 16960.34622001648, "episode/length": 196.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 355528, "time": 16966.779745340347, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 356576, "time": 17003.73577094078, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 356576, "time": 17003.74543786049, "episode/length": 205.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 356960, "time": 17020.239852905273, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 356968, "time": 17021.866434812546, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 357056, "time": 17028.279502153397, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 357112, "time": 17031.804513454437, "episode/length": 463.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9892241379310345, "episode/intrinsic_return": 0.0}
{"step": 357344, "time": 17041.459543466568, "episode/length": 47.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 357552, "time": 17050.13142490387, "episode/length": 292.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 357776, "time": 17059.200965166092, "episode/length": 368.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 358024, "time": 17068.786145687103, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 358096, "time": 17073.05953478813, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 358480, "time": 17087.7483150959, "episode/length": 47.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 358560, "time": 17092.134303331375, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 358736, "time": 17099.71275496483, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 358824, "time": 17103.927534103394, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 358992, "time": 17111.608460187912, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 359272, "time": 17122.269536733627, "episode/length": 240.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 359288, "time": 17124.552183151245, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 359392, "time": 17129.857031583786, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 359800, "time": 17145.080903053284, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 17176.176926851273, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 360048, "time": 17178.516830682755, "eval_episode/length": 166.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 360048, "time": 17181.70934200287, "eval_episode/length": 186.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 360048, "time": 17183.801619529724, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 360048, "time": 17186.78873872757, "eval_episode/length": 200.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9651741293532339}
{"step": 360048, "time": 17189.680549621582, "eval_episode/length": 209.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 360048, "time": 17192.218707323074, "eval_episode/length": 228.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 360048, "time": 17194.195610284805, "eval_episode/length": 237.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9789915966386554}
{"step": 360112, "time": 17196.388818979263, "episode/length": 203.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 360440, "time": 17208.911370515823, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 360496, "time": 17214.01401424408, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 360536, "time": 17216.806875944138, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 360544, "time": 17218.858299970627, "episode/length": 158.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 360640, "time": 17223.72547030449, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 360984, "time": 17236.76771759987, "episode/length": 280.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 361720, "time": 17263.30491375923, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 361736, "time": 17265.37110710144, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 362040, "time": 17277.303225517273, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 362104, "time": 17280.99600291252, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 362408, "time": 17293.04525232315, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 362456, "time": 17296.359582662582, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 362592, "time": 17302.851071596146, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 362640, "time": 17306.07070207596, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 363160, "time": 17325.13304758072, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 363240, "time": 17329.43686056137, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 363568, "time": 17342.19615459442, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 363569, "time": 17344.321417808533, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.65914939267792, "train/action_min": 0.0, "train/action_std": 3.4073235414324015, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04719469062712071, "train/actor_opt_grad_steps": 21940.0, "train/actor_opt_loss": -5.31204827045546, "train/adv_mag": 0.7503419172589796, "train/adv_max": 0.7310154153047687, "train/adv_mean": 0.003624407628334015, "train/adv_min": -0.5142349798748963, "train/adv_std": 0.07395593079663541, "train/cont_avg": 0.9948391879562044, "train/cont_loss_mean": 0.00026308004737135533, "train/cont_loss_std": 0.007812469565768826, "train/cont_neg_acc": 0.9936948860133136, "train/cont_neg_loss": 0.015917934488094976, "train/cont_pos_acc": 0.9999497850445935, "train/cont_pos_loss": 0.0001682740626870825, "train/cont_pred": 0.9948214301227654, "train/cont_rate": 0.9948391879562044, "train/dyn_loss_mean": 15.248648629571399, "train/dyn_loss_std": 9.396589773414778, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8256321849614164, "train/extr_critic_critic_opt_grad_steps": 21940.0, "train/extr_critic_critic_opt_loss": 15476.39627765739, "train/extr_critic_mag": 4.876082871082056, "train/extr_critic_max": 4.876082871082056, "train/extr_critic_mean": 0.8567880677045697, "train/extr_critic_min": -0.2584541609687527, "train/extr_critic_std": 1.0381609703937587, "train/extr_return_normed_mag": 1.8359167349599574, "train/extr_return_normed_max": 1.8359167349599574, "train/extr_return_normed_mean": 0.2920736014081614, "train/extr_return_normed_min": -0.15959275067940246, "train/extr_return_normed_std": 0.33187743015315413, "train/extr_return_rate": 0.42351260563752946, "train/extr_return_raw_mag": 5.8572545121185975, "train/extr_return_raw_max": 5.8572545121185975, "train/extr_return_raw_mean": 0.8684938228043326, "train/extr_return_raw_min": -0.5908188961283134, "train/extr_return_raw_std": 1.0726364394174004, "train/extr_reward_mag": 1.0176082858203972, "train/extr_reward_max": 1.0176082858203972, "train/extr_reward_mean": 0.023462486324192833, "train/extr_reward_min": -0.3635367355207457, "train/extr_reward_std": 0.14315479063857212, "train/image_loss_mean": 8.13333622382505, "train/image_loss_std": 12.056253454110918, "train/model_loss_mean": 17.3367942336702, "train/model_loss_std": 15.94259696459248, "train/model_opt_grad_norm": 70.30078736186897, "train/model_opt_grad_steps": 21918.554744525547, "train/model_opt_loss": 21825.271384580294, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.1240875912408, "train/policy_entropy_mag": 2.3340663370424815, "train/policy_entropy_max": 2.3340663370424815, "train/policy_entropy_mean": 0.527658246947031, "train/policy_entropy_min": 0.07937522194463842, "train/policy_entropy_std": 0.5209241574698121, "train/policy_logprob_mag": 7.43838314418375, "train/policy_logprob_max": -0.00945572922155805, "train/policy_logprob_mean": -0.5284070611870202, "train/policy_logprob_min": -7.43838314418375, "train/policy_logprob_std": 1.075306412947439, "train/policy_randomness_mag": 0.8238229916913666, "train/policy_randomness_max": 0.8238229916913666, "train/policy_randomness_mean": 0.18624020492943533, "train/policy_randomness_min": 0.028015969932949455, "train/policy_randomness_std": 0.18386336791254307, "train/post_ent_mag": 59.613182179249115, "train/post_ent_max": 59.613182179249115, "train/post_ent_mean": 41.51148766844812, "train/post_ent_min": 21.849311981758063, "train/post_ent_std": 7.377071652099164, "train/prior_ent_mag": 69.13334355041059, "train/prior_ent_max": 69.13334355041059, "train/prior_ent_mean": 56.81222589868699, "train/prior_ent_min": 39.72498485815786, "train/prior_ent_std": 4.8919542897356685, "train/rep_loss_mean": 15.248648629571399, "train/rep_loss_std": 9.396589773414778, "train/reward_avg": 0.0222306967114717, "train/reward_loss_mean": 0.054005881798637176, "train/reward_loss_std": 0.2528131429622643, "train/reward_max_data": 1.0175182523518582, "train/reward_max_pred": 1.012425801179705, "train/reward_neg_acc": 0.9925972236333972, "train/reward_neg_loss": 0.030599545945760108, "train/reward_pos_acc": 0.9554616969867344, "train/reward_pos_loss": 0.9016778621360333, "train/reward_pred": 0.02149375717760655, "train/reward_rate": 0.027030109489051095, "train_stats/sum_log_reward": 5.388288241248947, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 7.603603603603603, "train_stats/max_log_achievement_collect_sapling": 2.6666666666666665, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 7.198198198198198, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.36936936936936937, "train_stats/max_log_achievement_eat_cow": 0.0990990990990991, "train_stats/max_log_achievement_make_wood_pickaxe": 0.3153153153153153, "train_stats/max_log_achievement_make_wood_sword": 0.009009009009009009, "train_stats/max_log_achievement_place_plant": 2.5945945945945947, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.675675675675676, "train_stats/max_log_achievement_wake_up": 1.4234234234234233, "train_stats/mean_log_entropy": 0.49234405267346015, "eval_stats/sum_log_reward": 5.2874999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 8.0625, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.375, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.9375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.447527706157416e-05, "report/cont_loss_std": 0.0009371418273076415, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006836007232777774, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.0649393011117354e-05, "report/cont_pred": 0.9941146373748779, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.473810195922852, "report/dyn_loss_std": 9.877331733703613, "report/image_loss_mean": 8.425768852233887, "report/image_loss_std": 12.38885498046875, "report/model_loss_mean": 17.16815948486328, "report/model_loss_std": 16.43488311767578, "report/post_ent_mag": 61.25453186035156, "report/post_ent_max": 61.25453186035156, "report/post_ent_mean": 41.972469329833984, "report/post_ent_min": 21.125732421875, "report/post_ent_std": 7.518917560577393, "report/prior_ent_mag": 68.90374755859375, "report/prior_ent_max": 68.90374755859375, "report/prior_ent_mean": 56.53241729736328, "report/prior_ent_min": 41.79629898071289, "report/prior_ent_std": 5.4250922203063965, "report/rep_loss_mean": 14.473810195922852, "report/rep_loss_std": 9.877331733703613, "report/reward_avg": 0.02001953125, "report/reward_loss_mean": 0.05807012319564819, "report/reward_loss_std": 0.26949769258499146, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016734600067139, "report/reward_neg_acc": 0.9969940185546875, "report/reward_neg_loss": 0.034019216895103455, "report/reward_pos_acc": 0.9615384936332703, "report/reward_pos_loss": 0.9812549352645874, "report/reward_pred": 0.017015717923641205, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.003023124998435378, "eval/cont_loss_std": 0.09661799669265747, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.6191064715385437, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.450658402291083e-07, "eval/cont_pred": 0.996051549911499, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.66130256652832, "eval/dyn_loss_std": 11.533857345581055, "eval/image_loss_mean": 15.579717636108398, "eval/image_loss_std": 26.44620132446289, "eval/model_loss_mean": 27.460323333740234, "eval/model_loss_std": 30.829736709594727, "eval/post_ent_mag": 60.76514434814453, "eval/post_ent_max": 60.76514434814453, "eval/post_ent_mean": 41.254356384277344, "eval/post_ent_min": 21.150569915771484, "eval/post_ent_std": 7.744614601135254, "eval/prior_ent_mag": 68.90374755859375, "eval/prior_ent_max": 68.90374755859375, "eval/prior_ent_mean": 57.748836517333984, "eval/prior_ent_min": 40.345245361328125, "eval/prior_ent_std": 4.478316307067871, "eval/rep_loss_mean": 19.66130256652832, "eval/rep_loss_std": 11.533857345581055, "eval/reward_avg": 0.01894531212747097, "eval/reward_loss_mean": 0.08080045878887177, "eval/reward_loss_std": 0.5476706624031067, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9984201192855835, "eval/reward_neg_acc": 0.9900000691413879, "eval/reward_neg_loss": 0.051754046231508255, "eval/reward_pos_acc": 0.875, "eval/reward_pos_loss": 1.2910679578781128, "eval/reward_pred": 0.01935809850692749, "eval/reward_rate": 0.0234375, "replay/size": 363065.0, "replay/inserts": 21944.0, "replay/samples": 21936.0, "replay/insert_wait_avg": 1.3484056961610288e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.647523733927854e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 73568.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1963413116779733e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1187038421631, "timer/env.step_count": 2743.0, "timer/env.step_total": 254.19283533096313, "timer/env.step_frac": 0.254162665246064, "timer/env.step_avg": 0.0926696446704204, "timer/env.step_min": 0.02429986000061035, "timer/env.step_max": 3.3546626567840576, "timer/replay._sample_count": 21936.0, "timer/replay._sample_total": 11.457948446273804, "timer/replay._sample_frac": 0.011456588505200154, "timer/replay._sample_avg": 0.0005223353595128466, "timer/replay._sample_min": 0.0003838539123535156, "timer/replay._sample_max": 0.011800527572631836, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3213.0, "timer/agent.policy_total": 56.03497791290283, "timer/agent.policy_frac": 0.056028327135201915, "timer/agent.policy_avg": 0.01744008027167844, "timer/agent.policy_min": 0.009496927261352539, "timer/agent.policy_max": 0.13957786560058594, "timer/dataset_train_count": 1371.0, "timer/dataset_train_total": 0.16420578956604004, "timer/dataset_train_frac": 0.00016418630002139697, "timer/dataset_train_avg": 0.00011977081660542673, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.001093149185180664, "timer/agent.train_count": 1371.0, "timer/agent.train_total": 618.0236029624939, "timer/agent.train_frac": 0.6179502498935658, "timer/agent.train_avg": 0.4507830802060495, "timer/agent.train_min": 0.4363250732421875, "timer/agent.train_max": 1.6055641174316406, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4749133586883545, "timer/agent.report_frac": 0.00047485699133900455, "timer/agent.report_avg": 0.23745667934417725, "timer/agent.report_min": 0.22490453720092773, "timer/agent.report_max": 0.25000882148742676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.099073656370155e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 21.941015605185548}
{"step": 363880, "time": 17356.266292333603, "episode/length": 229.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 364064, "time": 17364.554715633392, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 364128, "time": 17368.442951202393, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 364224, "time": 17373.37744808197, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 364440, "time": 17382.122955560684, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 364672, "time": 17391.550642728806, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 364944, "time": 17402.20336651802, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 365128, "time": 17409.78675031662, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 365152, "time": 17412.350421190262, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 365448, "time": 17423.770387649536, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 365632, "time": 17431.767451047897, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 365696, "time": 17435.503590345383, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 365928, "time": 17444.86032986641, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 366384, "time": 17462.09465622902, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 366496, "time": 17467.426135778427, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 366552, "time": 17470.81679916382, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 366696, "time": 17477.231128692627, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 366928, "time": 17486.868131875992, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 367064, "time": 17493.996220588684, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 367544, "time": 17511.79584670067, "episode/length": 59.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 368040, "time": 17530.26279234886, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 368048, "time": 17532.33149409294, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 368264, "time": 17540.897255897522, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 368328, "time": 17544.580856084824, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 368400, "time": 17548.793704032898, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 368544, "time": 17555.167062044144, "episode/length": 512.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 368640, "time": 17560.41786813736, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 368832, "time": 17570.122876644135, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 369384, "time": 17590.013766765594, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 369400, "time": 17592.133075237274, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 369680, "time": 17603.108582496643, "episode/length": 141.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 369848, "time": 17610.171750068665, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 369984, "time": 17616.558957338333, "episode/length": 435.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9977064220183486, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17634.725754976273, "eval_episode/length": 40.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 370032, "time": 17640.694208860397, "eval_episode/length": 142.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.993006993006993}
{"step": 370032, "time": 17642.393420934677, "eval_episode/length": 146.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 370032, "time": 17644.269366264343, "eval_episode/length": 154.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9612903225806452}
{"step": 370032, "time": 17646.461573839188, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 370032, "time": 17650.00052857399, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 370032, "time": 17652.72274661064, "eval_episode/length": 229.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 370032, "time": 17656.643305540085, "eval_episode/length": 282.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9681978798586572}
{"step": 370152, "time": 17660.40246486664, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 370376, "time": 17669.495594978333, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 370816, "time": 17686.066573619843, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 370968, "time": 17692.618104696274, "episode/length": 329.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787878787878788, "episode/intrinsic_return": 0.0}
{"step": 371168, "time": 17701.092197179794, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 371424, "time": 17711.46107339859, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 371568, "time": 17717.789091825485, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 371592, "time": 17719.86578130722, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 371824, "time": 17729.387935638428, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 372136, "time": 17741.293353796005, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 372344, "time": 17749.88561987877, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 372552, "time": 17758.458787679672, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 372736, "time": 17766.46617078781, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 372744, "time": 17768.14889025688, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 372992, "time": 17778.4808716774, "episode/length": 30.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 373040, "time": 17782.1415579319, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 373168, "time": 17788.585107326508, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 373416, "time": 17798.318762540817, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 373720, "time": 17810.336612701416, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 373800, "time": 17814.482793569565, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 373936, "time": 17820.847409963608, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 374024, "time": 17825.1944334507, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 374264, "time": 17834.909524202347, "episode/length": 190.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 374328, "time": 17838.699509382248, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 374496, "time": 17846.185282230377, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 374944, "time": 17862.922884702682, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 375112, "time": 17869.81711268425, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 375352, "time": 17879.40220594406, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 375520, "time": 17886.935580015182, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 375616, "time": 17892.351259231567, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 375696, "time": 17896.540848255157, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 376328, "time": 17919.02906012535, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 376344, "time": 17921.373757362366, "episode/length": 300.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9867109634551495, "episode/intrinsic_return": 0.0}
{"step": 376448, "time": 17926.655784845352, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 376768, "time": 17938.992476463318, "episode/length": 176.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 377152, "time": 17955.049964666367, "episode/length": 254.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 377200, "time": 17958.13815665245, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 377200, "time": 17958.147852897644, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 377344, "time": 17966.367373228073, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 377568, "time": 17975.481300592422, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 377800, "time": 17984.699259757996, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 377904, "time": 17990.049690961838, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 378104, "time": 17998.091385126114, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 378552, "time": 18014.67310333252, "episode/length": 55.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 378584, "time": 18017.206403017044, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 378592, "time": 18019.276955366135, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 378664, "time": 18022.97270464897, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 378664, "time": 18022.985638856888, "episode/length": 236.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 378952, "time": 18035.959117412567, "episode/length": 49.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 379120, "time": 18043.52568912506, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 379200, "time": 18047.950298786163, "episode/length": 30.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 379424, "time": 18057.034876346588, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 379464, "time": 18059.775270462036, "episode/length": 194.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 379840, "time": 18074.278846740723, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 379936, "time": 18079.080631017685, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 18083.306624412537, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 18097.991369009018, "eval_episode/length": 35.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 380016, "time": 18104.967054843903, "eval_episode/length": 152.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 380016, "time": 18106.685836315155, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 380016, "time": 18108.55404663086, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 380016, "time": 18110.277122735977, "eval_episode/length": 165.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 380016, "time": 18111.933145284653, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 380016, "time": 18115.440628767014, "eval_episode/length": 208.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 380016, "time": 18118.021951675415, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 380176, "time": 18124.81310248375, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 380424, "time": 18134.479907274246, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 380800, "time": 18148.749546527863, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 381040, "time": 18158.372584104538, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 381136, "time": 18163.261167764664, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 381464, "time": 18175.51677131653, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 381784, "time": 18187.671561717987, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 381864, "time": 18192.13992547989, "episode/length": 299.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.99, "episode/intrinsic_return": 0.0}
{"step": 381944, "time": 18196.416694164276, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 382120, "time": 18203.866646528244, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 382232, "time": 18209.206026792526, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 383072, "time": 18239.299193382263, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 383120, "time": 18242.470237255096, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 383288, "time": 18249.386213064194, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 383344, "time": 18253.44825744629, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 383448, "time": 18258.36141729355, "episode/length": 428.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 383552, "time": 18263.709848880768, "episode/length": 178.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9888268156424581, "episode/intrinsic_return": 0.0}
{"step": 383640, "time": 18267.925005435944, "episode/length": 231.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9870689655172413, "episode/intrinsic_return": 0.0}
{"step": 383904, "time": 18278.601150751114, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 384128, "time": 18287.961578130722, "episode/length": 60.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 384648, "time": 18306.84217596054, "episode/length": 149.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 384688, "time": 18310.20368218422, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 384840, "time": 18316.668523311615, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 384912, "time": 18321.019115924835, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 384960, "time": 18324.171906471252, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 385248, "time": 18336.84012579918, "episode/length": 271.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 385401, "time": 18344.515669822693, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.807169447850137, "train/action_min": 0.0, "train/action_std": 3.506683970889906, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04743570523051015, "train/actor_opt_grad_steps": 23310.0, "train/actor_opt_loss": -7.190450519744823, "train/adv_mag": 0.7529679678217338, "train/adv_max": 0.7390830579900394, "train/adv_mean": 0.003198439599066122, "train/adv_min": -0.5034679061304914, "train/adv_std": 0.07400516564719868, "train/cont_avg": 0.9946182139598541, "train/cont_loss_mean": 0.00018389339441546244, "train/cont_loss_std": 0.005566981065942359, "train/cont_neg_acc": 0.9942214114822611, "train/cont_neg_loss": 0.022062484247519762, "train/cont_pos_acc": 0.9999641436729988, "train/cont_pos_loss": 9.99741632896979e-05, "train/cont_pred": 0.9945915506704011, "train/cont_rate": 0.9946182139598541, "train/dyn_loss_mean": 15.263046069736898, "train/dyn_loss_std": 9.378144312949075, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.800610282995405, "train/extr_critic_critic_opt_grad_steps": 23310.0, "train/extr_critic_critic_opt_loss": 15442.335039347628, "train/extr_critic_mag": 4.856946774642833, "train/extr_critic_max": 4.856946774642833, "train/extr_critic_mean": 0.8776703594374831, "train/extr_critic_min": -0.2564174502435392, "train/extr_critic_std": 1.034569669378935, "train/extr_return_normed_mag": 1.8397686551087093, "train/extr_return_normed_max": 1.8397686551087093, "train/extr_return_normed_mean": 0.30238424730997016, "train/extr_return_normed_min": -0.13956626325193114, "train/extr_return_normed_std": 0.3326714477182305, "train/extr_return_rate": 0.4494654083774038, "train/extr_return_raw_mag": 5.821770452234867, "train/extr_return_raw_max": 5.821770452234867, "train/extr_return_raw_mean": 0.8879396700075943, "train/extr_return_raw_min": -0.5305638258909657, "train/extr_return_raw_std": 1.0679584946075495, "train/extr_reward_mag": 1.0184229899496928, "train/extr_reward_max": 1.0184229899496928, "train/extr_reward_mean": 0.024123102814013506, "train/extr_reward_min": -0.3250845914339497, "train/extr_reward_std": 0.14532211297837488, "train/image_loss_mean": 7.992663978660194, "train/image_loss_std": 12.162397638724668, "train/model_loss_mean": 17.20378541598355, "train/model_loss_std": 15.959063884985708, "train/model_opt_grad_norm": 66.73800458627589, "train/model_opt_grad_steps": 23286.85401459854, "train/model_opt_loss": 16934.82536638914, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 980.8394160583941, "train/policy_entropy_mag": 2.3616430272151083, "train/policy_entropy_max": 2.3616430272151083, "train/policy_entropy_mean": 0.519738311315105, "train/policy_entropy_min": 0.07937521226432202, "train/policy_entropy_std": 0.5191900695327425, "train/policy_logprob_mag": 7.438383269484025, "train/policy_logprob_max": -0.009455719724786978, "train/policy_logprob_mean": -0.5190633541911188, "train/policy_logprob_min": -7.438383269484025, "train/policy_logprob_std": 1.0737991128524724, "train/policy_randomness_mag": 0.8335563514354455, "train/policy_randomness_max": 0.8335563514354455, "train/policy_randomness_mean": 0.1834448159393603, "train/policy_randomness_min": 0.02801596637081056, "train/policy_randomness_std": 0.18325131174421658, "train/post_ent_mag": 59.69649330194849, "train/post_ent_max": 59.69649330194849, "train/post_ent_mean": 41.64087356790139, "train/post_ent_min": 21.599723829840222, "train/post_ent_std": 7.386725512734295, "train/prior_ent_mag": 69.35910652327712, "train/prior_ent_max": 69.35910652327712, "train/prior_ent_mean": 56.92305429834519, "train/prior_ent_min": 40.405618291701714, "train/prior_ent_std": 4.747480789240259, "train/rep_loss_mean": 15.263046069736898, "train/rep_loss_std": 9.378144312949075, "train/reward_avg": 0.022688326622991667, "train/reward_loss_mean": 0.05311001166973236, "train/reward_loss_std": 0.25137034776437023, "train/reward_max_data": 1.016788325170531, "train/reward_max_pred": 1.0090150406760892, "train/reward_neg_acc": 0.9933075439320863, "train/reward_neg_loss": 0.02917501189657589, "train/reward_pos_acc": 0.9537471397949832, "train/reward_pos_loss": 0.9046040238255132, "train/reward_pred": 0.021804655881693762, "train/reward_rate": 0.02743641651459854, "train_stats/sum_log_reward": 5.369565150400867, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.3652173913043475, "train_stats/max_log_achievement_collect_sapling": 2.773913043478261, "train_stats/max_log_achievement_collect_stone": 0.043478260869565216, "train_stats/max_log_achievement_collect_wood": 7.278260869565218, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3391304347826087, "train_stats/max_log_achievement_eat_cow": 0.12173913043478261, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4608695652173913, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.7130434782608694, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.391304347826087, "train_stats/max_log_achievement_wake_up": 1.5478260869565217, "train_stats/mean_log_entropy": 0.492952264521433, "eval_stats/sum_log_reward": 5.037499904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.8125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 0.00010548302816459909, "report/cont_loss_std": 0.00327933207154274, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014087728050071746, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00010541376832406968, "report/cont_pred": 0.9979472160339355, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 15.681783676147461, "report/dyn_loss_std": 9.548990249633789, "report/image_loss_mean": 8.9221773147583, "report/image_loss_std": 12.017023086547852, "report/model_loss_mean": 18.376794815063477, "report/model_loss_std": 16.119827270507812, "report/post_ent_mag": 57.20627975463867, "report/post_ent_max": 57.20627975463867, "report/post_ent_mean": 40.77018737792969, "report/post_ent_min": 21.522546768188477, "report/post_ent_std": 6.989324569702148, "report/prior_ent_mag": 68.87747192382812, "report/prior_ent_max": 68.87747192382812, "report/prior_ent_mean": 57.03091812133789, "report/prior_ent_min": 45.63490295410156, "report/prior_ent_std": 4.302867889404297, "report/rep_loss_mean": 15.681783676147461, "report/rep_loss_std": 9.548990249633789, "report/reward_avg": 0.01699218712747097, "report/reward_loss_mean": 0.04544170945882797, "report/reward_loss_std": 0.23967595398426056, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0014023780822754, "report/reward_neg_acc": 0.9880478382110596, "report/reward_neg_loss": 0.02599957399070263, "report/reward_pos_acc": 0.9000000357627869, "report/reward_pos_loss": 1.0214370489120483, "report/reward_pred": 0.017729608342051506, "report/reward_rate": 0.01953125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00011962426651734859, "eval/cont_loss_std": 0.0035353254061192274, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0017720742616802454, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011151607759529725, "eval/cont_pred": 0.9950209856033325, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.93817901611328, "eval/dyn_loss_std": 10.828413963317871, "eval/image_loss_mean": 14.48684310913086, "eval/image_loss_std": 21.287097930908203, "eval/model_loss_mean": 25.953994750976562, "eval/model_loss_std": 26.060129165649414, "eval/post_ent_mag": 54.83708190917969, "eval/post_ent_max": 54.83708190917969, "eval/post_ent_mean": 40.344024658203125, "eval/post_ent_min": 21.687395095825195, "eval/post_ent_std": 6.417898654937744, "eval/prior_ent_mag": 69.52719116210938, "eval/prior_ent_max": 69.52719116210938, "eval/prior_ent_mean": 57.2053337097168, "eval/prior_ent_min": 37.88005447387695, "eval/prior_ent_std": 4.643779277801514, "eval/rep_loss_mean": 18.93817901611328, "eval/rep_loss_std": 10.828413963317871, "eval/reward_avg": 0.02880859561264515, "eval/reward_loss_mean": 0.10412479937076569, "eval/reward_loss_std": 0.6050209999084473, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004246234893799, "eval/reward_neg_acc": 0.9949494004249573, "eval/reward_neg_loss": 0.0411977581679821, "eval/reward_pos_acc": 0.7352941036224365, "eval/reward_pos_loss": 1.9364120960235596, "eval/reward_pred": 0.018905656412243843, "eval/reward_rate": 0.033203125, "replay/size": 384897.0, "replay/inserts": 21832.0, "replay/samples": 21840.0, "replay/insert_wait_avg": 1.314742174634308e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.748822152832926e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77672.0, "eval_replay/inserts": 4104.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2332235860545732e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1817977428436, "timer/env.step_count": 2729.0, "timer/env.step_total": 262.52578258514404, "timer/env.step_frac": 0.2624780646654419, "timer/env.step_avg": 0.09619852788022867, "timer/env.step_min": 0.024396896362304688, "timer/env.step_max": 3.424032211303711, "timer/replay._sample_count": 21840.0, "timer/replay._sample_total": 11.489202976226807, "timer/replay._sample_frac": 0.011487114644712611, "timer/replay._sample_avg": 0.0005260624073363923, "timer/replay._sample_min": 0.000377655029296875, "timer/replay._sample_max": 0.011743545532226562, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3242.0, "timer/agent.policy_total": 55.616758823394775, "timer/agent.policy_frac": 0.055606649659999494, "timer/agent.policy_avg": 0.017155076749967545, "timer/agent.policy_min": 0.009659767150878906, "timer/agent.policy_max": 0.12346911430358887, "timer/dataset_train_count": 1365.0, "timer/dataset_train_total": 0.16233515739440918, "timer/dataset_train_frac": 0.00016230565059348052, "timer/dataset_train_avg": 0.0001189268552339994, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0005335807800292969, "timer/agent.train_count": 1365.0, "timer/agent.train_total": 611.4111785888672, "timer/agent.train_frac": 0.6113000456203732, "timer/agent.train_avg": 0.4479202773544815, "timer/agent.train_min": 0.43538856506347656, "timer/agent.train_max": 1.5101256370544434, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760096073150635, "timer/agent.report_frac": 0.00047592308557233926, "timer/agent.report_avg": 0.23800480365753174, "timer/agent.report_min": 0.22525525093078613, "timer/agent.report_max": 0.25075435638427734, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.5789947509765625e-05, "timer/dataset_eval_frac": 5.577980686678099e-08, "timer/dataset_eval_avg": 5.5789947509765625e-05, "timer/dataset_eval_min": 5.5789947509765625e-05, "timer/dataset_eval_max": 5.5789947509765625e-05, "fps": 21.82774441875373}
{"step": 385576, "time": 18350.3430724144, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 385664, "time": 18355.117218494415, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 385864, "time": 18363.392300605774, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 385984, "time": 18369.27007317543, "episode/length": 50.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 386240, "time": 18380.156608581543, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 386264, "time": 18382.400275707245, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 386704, "time": 18398.971814393997, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 387064, "time": 18413.064581632614, "episode/length": 262.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 387336, "time": 18423.90722680092, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 387448, "time": 18429.219875574112, "episode/length": 222.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968609865470852, "episode/intrinsic_return": 0.0}
{"step": 387472, "time": 18432.033001184464, "episode/length": 347.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 387600, "time": 18437.975350379944, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 387816, "time": 18446.612638950348, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 387896, "time": 18450.988899230957, "episode/length": 253.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 388328, "time": 18467.274317979813, "episode/length": 53.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 388384, "time": 18470.855875492096, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 388552, "time": 18477.903359651566, "episode/length": 151.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 388800, "time": 18488.344341039658, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 389088, "time": 18499.776540517807, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 389200, "time": 18505.081211805344, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 389424, "time": 18514.1541492939, "episode/length": 200.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9651741293532339, "episode/intrinsic_return": 0.0}
{"step": 389600, "time": 18521.83269262314, "episode/length": 249.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 389608, "time": 18523.628418684006, "episode/length": 152.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18559.0407602787, "eval_episode/length": 161.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 390000, "time": 18561.00399160385, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 390000, "time": 18562.784558057785, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 390000, "time": 18564.9192070961, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 390000, "time": 18567.630311489105, "eval_episode/length": 205.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 390000, "time": 18569.93074631691, "eval_episode/length": 221.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 390000, "time": 18572.5080575943, "eval_episode/length": 242.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9794238683127572}
{"step": 390000, "time": 18574.248107671738, "eval_episode/length": 246.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 390168, "time": 18579.760806560516, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 390280, "time": 18585.149901866913, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 390368, "time": 18589.848856925964, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 390720, "time": 18603.10929751396, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 390720, "time": 18603.119510889053, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 390912, "time": 18612.794858932495, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 391112, "time": 18620.96122288704, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 391208, "time": 18625.785656929016, "episode/length": 331.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 391936, "time": 18651.91325855255, "episode/length": 151.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 392064, "time": 18657.732615470886, "episode/length": 236.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 392136, "time": 18661.567792892456, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 392136, "time": 18661.577940940857, "episode/length": 220.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 392520, "time": 18677.992884159088, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 392544, "time": 18680.742919445038, "episode/length": 50.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 392848, "time": 18692.558614730835, "episode/length": 320.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 392864, "time": 18694.65963602066, "episode/length": 206.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9903381642512077, "episode/intrinsic_return": 0.0}
{"step": 393416, "time": 18716.31103992462, "episode/length": 111.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 393488, "time": 18720.632942676544, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 393680, "time": 18728.550395965576, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 393760, "time": 18733.01363635063, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 394224, "time": 18749.984689235687, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 394248, "time": 18752.15602684021, "episode/length": 440.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9977324263038548, "episode/intrinsic_return": 0.0}
{"step": 394368, "time": 18757.8587141037, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 394376, "time": 18759.442358255386, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 394920, "time": 18779.33140850067, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 395160, "time": 18788.937619924545, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 395192, "time": 18791.827970027924, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 395216, "time": 18794.40453028679, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 395864, "time": 18817.502121448517, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 396112, "time": 18827.710419654846, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 396392, "time": 18838.50987315178, "episode/length": 183.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 396624, "time": 18848.125194072723, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 396712, "time": 18852.562041044235, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 396888, "time": 18860.28561449051, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 397344, "time": 18877.81326007843, "episode/length": 386.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948320413436692, "episode/intrinsic_return": 0.0}
{"step": 397608, "time": 18888.151473760605, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 397672, "time": 18891.860381364822, "episode/length": 225.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 397712, "time": 18894.939663410187, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 398024, "time": 18906.7835419178, "episode/length": 474.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9852631578947368, "episode/intrinsic_return": 0.0}
{"step": 398112, "time": 18911.65319943428, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 398184, "time": 18915.391134500504, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 398224, "time": 18918.53858757019, "episode/length": 68.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9420289855072463, "episode/intrinsic_return": 0.0}
{"step": 398568, "time": 18931.463197231293, "episode/length": 209.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 399064, "time": 18949.814690113068, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 399528, "time": 18967.15605545044, "episode/length": 226.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 399728, "time": 18976.502829551697, "episode/length": 144.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 399752, "time": 18978.72489619255, "episode/length": 85.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 399768, "time": 18980.88377737999, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 399808, "time": 18984.038796901703, "episode/length": 202.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 399904, "time": 18988.990942955017, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18996.490099191666, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 19018.167611837387, "eval_episode/length": 174.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 400088, "time": 19020.54754090309, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 400088, "time": 19022.659269332886, "eval_episode/length": 185.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 400088, "time": 19024.917248249054, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 400088, "time": 19027.67555785179, "eval_episode/length": 204.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 400088, "time": 19031.684318065643, "eval_episode/length": 225.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.995575221238938}
{"step": 400088, "time": 19035.575858831406, "eval_episode/length": 241.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9793388429752066}
{"step": 400088, "time": 19037.96773815155, "eval_episode/length": 248.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9799196787148594}
{"step": 400128, "time": 19041.737363100052, "episode/length": 27.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 400272, "time": 19048.522142887115, "episode/length": 365.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 401104, "time": 19077.94744992256, "episode/length": 196.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 401120, "time": 19080.14151263237, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 401136, "time": 19082.214992523193, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 401344, "time": 19090.8538479805, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 401752, "time": 19107.653252601624, "episode/length": 184.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 401792, "time": 19110.83632159233, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 401864, "time": 19114.66001868248, "episode/length": 261.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 401984, "time": 19120.593919992447, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 402184, "time": 19128.62203478813, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 402240, "time": 19132.345305919647, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 402536, "time": 19143.640585899353, "episode/length": 178.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 402848, "time": 19155.952925920486, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 403080, "time": 19165.072811365128, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 403496, "time": 19180.634454250336, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 403560, "time": 19184.46259880066, "episode/length": 302.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 403632, "time": 19188.67077565193, "episode/length": 229.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 403800, "time": 19195.81527543068, "episode/length": 194.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 403872, "time": 19200.106308460236, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 404208, "time": 19212.97830057144, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 404280, "time": 19216.756459712982, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 404640, "time": 19230.499321222305, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 404696, "time": 19233.639835834503, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 405096, "time": 19248.855570077896, "episode/length": 182.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 405232, "time": 19255.271789312363, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 405296, "time": 19258.902196884155, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 405624, "time": 19271.39200234413, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 405800, "time": 19278.93115234375, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 405816, "time": 19281.12280011177, "episode/length": 139.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 406408, "time": 19302.55668568611, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 406528, "time": 19308.653071403503, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 406576, "time": 19311.942569971085, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 406656, "time": 19316.152500629425, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 407433, "time": 19344.656284809113, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.561109111256843, "train/action_min": 0.0, "train/action_std": 3.2846344004582315, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04822952898531935, "train/actor_opt_grad_steps": 24680.0, "train/actor_opt_loss": -6.147792758053019, "train/adv_mag": 0.7374795757941086, "train/adv_max": 0.7152519062922819, "train/adv_mean": 0.003723003491989794, "train/adv_min": -0.5105806186686467, "train/adv_std": 0.0738862161762523, "train/cont_avg": 0.9948962135036497, "train/cont_loss_mean": 0.0002250352522690365, "train/cont_loss_std": 0.006671817699457544, "train/cont_neg_acc": 0.9931091431283603, "train/cont_neg_loss": 0.015120380092793956, "train/cont_pos_acc": 0.9999641171337044, "train/cont_pos_loss": 0.0001340597028372635, "train/cont_pred": 0.9948963018229408, "train/cont_rate": 0.9948962135036497, "train/dyn_loss_mean": 14.921318499711308, "train/dyn_loss_std": 9.34362611283351, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8000798040497912, "train/extr_critic_critic_opt_grad_steps": 24680.0, "train/extr_critic_critic_opt_loss": 15454.205363252737, "train/extr_critic_mag": 4.887725642127712, "train/extr_critic_max": 4.887725642127712, "train/extr_critic_mean": 0.8698253477141805, "train/extr_critic_min": -0.26952144786389204, "train/extr_critic_std": 1.0531735585553803, "train/extr_return_normed_mag": 1.8557962144378328, "train/extr_return_normed_max": 1.8557962144378328, "train/extr_return_normed_mean": 0.3009922204226473, "train/extr_return_normed_min": -0.16055526209138607, "train/extr_return_normed_std": 0.3366316662435114, "train/extr_return_rate": 0.4495723314963988, "train/extr_return_raw_mag": 5.911386033914385, "train/extr_return_raw_max": 5.911386033914385, "train/extr_return_raw_mean": 0.8818752108699214, "train/extr_return_raw_min": -0.6115294532836789, "train/extr_return_raw_std": 1.0891215396623541, "train/extr_reward_mag": 1.0205182976966356, "train/extr_reward_max": 1.0205182976966356, "train/extr_reward_mean": 0.02466463601474997, "train/extr_reward_min": -0.4147639144076048, "train/extr_reward_std": 0.14734363088207522, "train/image_loss_mean": 7.85121737779492, "train/image_loss_std": 12.261267588956512, "train/model_loss_mean": 16.85670778873193, "train/model_loss_std": 16.045191702181405, "train/model_opt_grad_norm": 64.21700785281884, "train/model_opt_grad_steps": 24655.68613138686, "train/model_opt_loss": 14552.83741303604, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 866.7883211678832, "train/policy_entropy_mag": 2.419394524428096, "train/policy_entropy_max": 2.419394524428096, "train/policy_entropy_mean": 0.5290652844157532, "train/policy_entropy_min": 0.07937518447420022, "train/policy_entropy_std": 0.5479544633931487, "train/policy_logprob_mag": 7.438383346056416, "train/policy_logprob_max": -0.009455711954701556, "train/policy_logprob_mean": -0.5290625232414607, "train/policy_logprob_min": -7.438383346056416, "train/policy_logprob_std": 1.0845478216226954, "train/policy_randomness_mag": 0.8539400944744584, "train/policy_randomness_max": 0.8539400944744584, "train/policy_randomness_mean": 0.1867368293069575, "train/policy_randomness_min": 0.028015956622514413, "train/policy_randomness_std": 0.1934038800914792, "train/post_ent_mag": 59.586325067673286, "train/post_ent_max": 59.586325067673286, "train/post_ent_mean": 41.965717733341414, "train/post_ent_min": 21.640601025880688, "train/post_ent_std": 7.422471032525501, "train/prior_ent_mag": 69.39596067553889, "train/prior_ent_max": 69.39596067553889, "train/prior_ent_mean": 56.93338859168282, "train/prior_ent_min": 40.59667810036318, "train/prior_ent_std": 4.767581943177829, "train/rep_loss_mean": 14.921318499711308, "train/rep_loss_std": 9.34362611283351, "train/reward_avg": 0.023183736141200048, "train/reward_loss_mean": 0.05247439161269334, "train/reward_loss_std": 0.25230084957867643, "train/reward_max_data": 1.020437961077168, "train/reward_max_pred": 1.009840596331297, "train/reward_neg_acc": 0.9928721937819989, "train/reward_neg_loss": 0.02853292320603437, "train/reward_pos_acc": 0.9624098199997505, "train/reward_pos_loss": 0.8939857078294684, "train/reward_pred": 0.02235360419799159, "train/reward_rate": 0.02773580063868613, "train_stats/sum_log_reward": 5.488888846503364, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.675925925925926, "train_stats/max_log_achievement_collect_sapling": 2.611111111111111, "train_stats/max_log_achievement_collect_stone": 0.08333333333333333, "train_stats/max_log_achievement_collect_wood": 7.7592592592592595, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5185185185185185, "train_stats/max_log_achievement_eat_cow": 0.06481481481481481, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4537037037037037, "train_stats/max_log_achievement_make_wood_sword": 0.009259259259259259, "train_stats/max_log_achievement_place_plant": 2.4814814814814814, "train_stats/max_log_achievement_place_stone": 0.027777777777777776, "train_stats/max_log_achievement_place_table": 2.7685185185185186, "train_stats/max_log_achievement_wake_up": 1.6296296296296295, "train_stats/mean_log_entropy": 0.5246405140669258, "eval_stats/sum_log_reward": 5.974999964237213, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 7.0625, "eval_stats/max_log_achievement_collect_sapling": 2.75, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 9.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.3125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.0608803222567076e-06, "report/cont_loss_std": 1.482217840020894e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.9699491531355307e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.877877573671867e-07, "report/cont_pred": 0.9960927963256836, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.538519859313965, "report/dyn_loss_std": 9.574275016784668, "report/image_loss_mean": 7.370799541473389, "report/image_loss_std": 9.461845397949219, "report/model_loss_mean": 16.748559951782227, "report/model_loss_std": 13.607081413269043, "report/post_ent_mag": 61.69535446166992, "report/post_ent_max": 61.69535446166992, "report/post_ent_mean": 41.4941520690918, "report/post_ent_min": 24.10135269165039, "report/post_ent_std": 7.735952377319336, "report/prior_ent_mag": 70.10554504394531, "report/prior_ent_max": 70.10554504394531, "report/prior_ent_mean": 57.39379119873047, "report/prior_ent_min": 40.247135162353516, "report/prior_ent_std": 4.447996139526367, "report/rep_loss_mean": 15.538519859313965, "report/rep_loss_std": 9.574275016784668, "report/reward_avg": 0.02363281324505806, "report/reward_loss_mean": 0.0546468049287796, "report/reward_loss_std": 0.28593987226486206, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001716136932373, "report/reward_neg_acc": 0.9909639358520508, "report/reward_neg_loss": 0.022664707154035568, "report/reward_pos_acc": 0.8928571939468384, "report/reward_pos_loss": 1.192295789718628, "report/reward_pred": 0.019350145012140274, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 3.9323513192357495e-06, "eval/cont_loss_std": 7.165108399931341e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00037181374500505626, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.7640911664784653e-06, "eval/cont_pred": 0.9941410422325134, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 17.105144500732422, "eval/dyn_loss_std": 10.793660163879395, "eval/image_loss_mean": 12.716741561889648, "eval/image_loss_std": 17.241945266723633, "eval/model_loss_mean": 23.085113525390625, "eval/model_loss_std": 21.81344985961914, "eval/post_ent_mag": 61.02827453613281, "eval/post_ent_max": 61.02827453613281, "eval/post_ent_mean": 41.94042205810547, "eval/post_ent_min": 23.070348739624023, "eval/post_ent_std": 7.699745178222656, "eval/prior_ent_mag": 70.10554504394531, "eval/prior_ent_max": 70.10554504394531, "eval/prior_ent_mean": 57.533843994140625, "eval/prior_ent_min": 39.24802017211914, "eval/prior_ent_std": 4.71222448348999, "eval/rep_loss_mean": 17.105144500732422, "eval/rep_loss_std": 10.793660163879395, "eval/reward_avg": 0.02675781212747097, "eval/reward_loss_mean": 0.10528235882520676, "eval/reward_loss_std": 0.5622218251228333, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.053147315979004, "eval/reward_neg_acc": 0.9889000654220581, "eval/reward_neg_loss": 0.04455484822392464, "eval/reward_pos_acc": 0.7575757503509521, "eval/reward_pos_loss": 1.9289478063583374, "eval/reward_pred": 0.021417299285531044, "eval/reward_rate": 0.0322265625, "replay/size": 406929.0, "replay/inserts": 22032.0, "replay/samples": 22032.0, "replay/insert_wait_avg": 1.3233140143433947e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.442789140090444e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81640.0, "eval_replay/inserts": 3968.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2453885809067757e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1256561279297, "timer/env.step_count": 2754.0, "timer/env.step_total": 254.49636316299438, "timer/env.step_frac": 0.25446438815328304, "timer/env.step_avg": 0.09240971792410835, "timer/env.step_min": 0.02429986000061035, "timer/env.step_max": 3.2919182777404785, "timer/replay._sample_count": 22032.0, "timer/replay._sample_total": 11.687137842178345, "timer/replay._sample_frac": 0.011685669466200956, "timer/replay._sample_avg": 0.0005304619572521035, "timer/replay._sample_min": 0.0003478527069091797, "timer/replay._sample_max": 0.03510308265686035, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3250.0, "timer/agent.policy_total": 56.59006452560425, "timer/agent.policy_frac": 0.056582954530631106, "timer/agent.policy_avg": 0.01741232754633977, "timer/agent.policy_min": 0.009772300720214844, "timer/agent.policy_max": 0.14023280143737793, "timer/dataset_train_count": 1377.0, "timer/dataset_train_total": 0.16610002517700195, "timer/dataset_train_frac": 0.0001660791563132898, "timer/dataset_train_avg": 0.00012062456439869423, "timer/dataset_train_min": 0.00010132789611816406, "timer/dataset_train_max": 0.0010938644409179688, "timer/agent.train_count": 1377.0, "timer/agent.train_total": 615.4660937786102, "timer/agent.train_frac": 0.6153887664090518, "timer/agent.train_avg": 0.4469615786337039, "timer/agent.train_min": 0.43155646324157715, "timer/agent.train_max": 1.6053330898284912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4855637550354004, "timer/agent.report_frac": 0.0004855027486399071, "timer/agent.report_avg": 0.2427818775177002, "timer/agent.report_min": 0.23491764068603516, "timer/agent.report_max": 0.25064611434936523, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.289763012719578e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 22.028912394280827}
{"step": 407696, "time": 19353.736929655075, "episode/length": 426.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 407856, "time": 19360.831434488297, "episode/length": 159.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 407880, "time": 19363.032354593277, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 407992, "time": 19368.432448863983, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 408008, "time": 19370.543473243713, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 408056, "time": 19373.70974445343, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 408104, "time": 19376.83233523369, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 408200, "time": 19381.572281122208, "episode/length": 299.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 409136, "time": 19415.004677772522, "episode/length": 142.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 409304, "time": 19422.272305965424, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 409304, "time": 19422.28498506546, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 409592, "time": 19435.19293665886, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 409608, "time": 19437.63523888588, "episode/length": 193.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 409824, "time": 19448.084201574326, "episode/length": 226.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 409856, "time": 19450.964707136154, "episode/length": 246.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19480.451853513718, "eval_episode/length": 168.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 410072, "time": 19482.87323474884, "eval_episode/length": 187.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 410072, "time": 19484.719321012497, "eval_episode/length": 192.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 410072, "time": 19487.030836820602, "eval_episode/length": 205.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 410072, "time": 19490.095695495605, "eval_episode/length": 234.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9829787234042553}
{"step": 410072, "time": 19491.840793132782, "eval_episode/length": 237.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 410072, "time": 19495.686779499054, "eval_episode/length": 287.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9965277777777778}
{"step": 410072, "time": 19500.314671993256, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 410104, "time": 19501.388001918793, "episode/length": 280.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 410384, "time": 19512.63926076889, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 410744, "time": 19527.481064081192, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 410824, "time": 19531.965220928192, "episode/length": 189.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 411288, "time": 19549.774406433105, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 411528, "time": 19559.463040351868, "episode/length": 277.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 411936, "time": 19575.087596178055, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 412032, "time": 19579.764074087143, "episode/length": 275.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 412120, "time": 19584.03225660324, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 412160, "time": 19587.132292985916, "episode/length": 256.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 412400, "time": 19596.73761701584, "episode/length": 350.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 412672, "time": 19607.53990459442, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 412896, "time": 19616.62282896042, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 413168, "time": 19627.301174402237, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 413240, "time": 19631.31252670288, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 413504, "time": 19642.18044567108, "episode/length": 167.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 413640, "time": 19648.188213825226, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 413920, "time": 19659.393132209778, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 414112, "time": 19667.6044857502, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 414224, "time": 19672.931023836136, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 414376, "time": 19679.44871878624, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 414904, "time": 19698.851770401, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 415216, "time": 19711.106243133545, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 415288, "time": 19714.85356926918, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 415536, "time": 19725.75282883644, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 415576, "time": 19728.52263569832, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 415744, "time": 19735.921231031418, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 415760, "time": 19738.033276557922, "episode/length": 281.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 415792, "time": 19740.771852493286, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 416168, "time": 19754.73841881752, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 416560, "time": 19769.82121515274, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 416880, "time": 19782.33615398407, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 416912, "time": 19785.02104997635, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 417024, "time": 19790.350810289383, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 417056, "time": 19793.212803840637, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 417104, "time": 19796.981049776077, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 417848, "time": 19825.418564796448, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727626459143969, "episode/intrinsic_return": 0.0}
{"step": 417928, "time": 19829.834245204926, "episode/length": 219.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 417960, "time": 19832.473320961, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 418224, "time": 19843.307501792908, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 418296, "time": 19847.222640514374, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 418368, "time": 19851.50243163109, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 418600, "time": 19860.632469177246, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 418768, "time": 19868.103462457657, "episode/length": 49.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 419104, "time": 19881.15283513069, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 419160, "time": 19884.49123930931, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 419392, "time": 19894.077152252197, "episode/length": 291.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 419632, "time": 19903.823168039322, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 419744, "time": 19909.08697795868, "episode/length": 226.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 419936, "time": 19917.08154654503, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 420032, "time": 19921.940923929214, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19945.14529299736, "eval_episode/length": 145.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 420056, "time": 19946.798616170883, "eval_episode/length": 148.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 420056, "time": 19950.797461032867, "eval_episode/length": 200.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9751243781094527}
{"step": 420056, "time": 19952.404331207275, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 420056, "time": 19954.125233650208, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 420056, "time": 19958.19216942787, "eval_episode/length": 259.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 420056, "time": 19961.760106563568, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.954248366013072}
{"step": 420056, "time": 19963.46105337143, "eval_episode/length": 304.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9868852459016394}
{"step": 420272, "time": 19970.924571990967, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 420512, "time": 19980.529953479767, "episode/length": 175.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 420736, "time": 19989.678742408752, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 420744, "time": 19991.433770895004, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 421000, "time": 20001.577648878098, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 421376, "time": 20016.000686645508, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 421384, "time": 20017.56146621704, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 421552, "time": 20025.068831205368, "episode/length": 189.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 421880, "time": 20037.36729168892, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 421960, "time": 20041.674467802048, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 422080, "time": 20047.545624494553, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 422296, "time": 20056.225617408752, "episode/length": 222.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 422408, "time": 20061.680423021317, "episode/length": 175.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 422768, "time": 20075.599217653275, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 422984, "time": 20084.31502532959, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 423200, "time": 20093.40391612053, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 423272, "time": 20097.13950753212, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 423624, "time": 20110.647144317627, "episode/length": 207.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 423936, "time": 20123.00055217743, "episode/length": 190.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9895287958115183, "episode/intrinsic_return": 0.0}
{"step": 424024, "time": 20127.336762666702, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 424136, "time": 20132.62695479393, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 424256, "time": 20138.627898216248, "episode/length": 271.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 424648, "time": 20153.390048503876, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 424736, "time": 20158.201759576797, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 424768, "time": 20160.864929676056, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 425008, "time": 20170.741465568542, "episode/length": 133.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 425312, "time": 20182.542706012726, "episode/length": 146.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 425520, "time": 20191.212443113327, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 425616, "time": 20196.022372961044, "episode/length": 198.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 425824, "time": 20204.599407672882, "episode/length": 274.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 425960, "time": 20210.45814037323, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.0}
{"step": 426224, "time": 20222.584808588028, "episode/length": 49.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 426240, "time": 20224.731577157974, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 426384, "time": 20231.34735608101, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 426696, "time": 20243.163118839264, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 426856, "time": 20250.282737493515, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 427032, "time": 20257.74383020401, "episode/length": 176.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 427256, "time": 20266.92081952095, "episode/length": 310.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 427560, "time": 20278.709536075592, "episode/length": 164.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 427992, "time": 20294.740956783295, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 428248, "time": 20304.89811348915, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 428312, "time": 20308.65013360977, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 428328, "time": 20310.855436325073, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 428896, "time": 20331.873177051544, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 429209, "time": 20344.74024128914, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.546545589671416, "train/action_min": 0.0, "train/action_std": 3.3785448915818157, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04678048656376846, "train/actor_opt_grad_steps": 26045.0, "train/actor_opt_loss": -7.418781017501126, "train/adv_mag": 0.7126486599445343, "train/adv_max": 0.6908738707356593, "train/adv_mean": 0.0032390644847135478, "train/adv_min": -0.5202573298969689, "train/adv_std": 0.07235007459188209, "train/cont_avg": 0.9946432674632353, "train/cont_loss_mean": 0.0002706229720977697, "train/cont_loss_std": 0.008150287388526908, "train/cont_neg_acc": 0.9878180456512115, "train/cont_neg_loss": 0.03289044632589701, "train/cont_pos_acc": 0.999971103580559, "train/cont_pos_loss": 7.222256184537829e-05, "train/cont_pred": 0.9946732450934017, "train/cont_rate": 0.9946432674632353, "train/dyn_loss_mean": 14.668059839921838, "train/dyn_loss_std": 9.314441014738644, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7879366690621656, "train/extr_critic_critic_opt_grad_steps": 26045.0, "train/extr_critic_critic_opt_loss": 15388.318962545956, "train/extr_critic_mag": 5.021516368669622, "train/extr_critic_max": 5.021516368669622, "train/extr_critic_mean": 0.874191261608811, "train/extr_critic_min": -0.2598496815737556, "train/extr_critic_std": 1.0862223251777536, "train/extr_return_normed_mag": 1.843733185354401, "train/extr_return_normed_max": 1.843733185354401, "train/extr_return_normed_mean": 0.2964577084297643, "train/extr_return_normed_min": -0.16180144590051734, "train/extr_return_normed_std": 0.3397342665668796, "train/extr_return_rate": 0.4321988206356764, "train/extr_return_raw_mag": 5.981093413689557, "train/extr_return_raw_max": 5.981093413689557, "train/extr_return_raw_mean": 0.8849031462827149, "train/extr_return_raw_min": -0.6244864249054123, "train/extr_return_raw_std": 1.1190108630587072, "train/extr_reward_mag": 1.0173973441123962, "train/extr_reward_max": 1.0173973441123962, "train/extr_reward_mean": 0.024629148997037727, "train/extr_reward_min": -0.39395668576745424, "train/extr_reward_std": 0.1474580480991041, "train/image_loss_mean": 7.498910767190597, "train/image_loss_std": 11.664265408235437, "train/model_loss_mean": 16.354116972754984, "train/model_loss_std": 15.43473505973816, "train/model_opt_grad_norm": 63.530143303029675, "train/model_opt_grad_steps": 26019.46323529412, "train/model_opt_loss": 10654.613992130055, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 652.5735294117648, "train/policy_entropy_mag": 2.4310652420801273, "train/policy_entropy_max": 2.4310652420801273, "train/policy_entropy_mean": 0.5533165344420601, "train/policy_entropy_min": 0.07937512946698595, "train/policy_entropy_std": 0.5794469764565721, "train/policy_logprob_mag": 7.438383449526394, "train/policy_logprob_max": -0.00945566887008574, "train/policy_logprob_mean": -0.5536082487772492, "train/policy_logprob_min": -7.438383449526394, "train/policy_logprob_std": 1.1015018417554743, "train/policy_randomness_mag": 0.8580593444845256, "train/policy_randomness_max": 0.8580593444845256, "train/policy_randomness_mean": 0.19529645495554981, "train/policy_randomness_min": 0.028015937354853925, "train/policy_randomness_std": 0.2045193563270218, "train/post_ent_mag": 59.97756004333496, "train/post_ent_max": 59.97756004333496, "train/post_ent_mean": 42.31438527387731, "train/post_ent_min": 21.673542387345258, "train/post_ent_std": 7.437801862464232, "train/prior_ent_mag": 69.58300444659065, "train/prior_ent_max": 69.58300444659065, "train/prior_ent_mean": 57.03645450928632, "train/prior_ent_min": 40.65051255506628, "train/prior_ent_std": 4.717631101608276, "train/rep_loss_mean": 14.668059839921838, "train/rep_loss_std": 9.314441014738644, "train/reward_avg": 0.023089240603011978, "train/reward_loss_mean": 0.05409991359064246, "train/reward_loss_std": 0.25749417898409505, "train/reward_max_data": 1.0154411801520515, "train/reward_max_pred": 1.0082613834563423, "train/reward_neg_acc": 0.9932107868440011, "train/reward_neg_loss": 0.02998956954380607, "train/reward_pos_acc": 0.9578094837420127, "train/reward_pos_loss": 0.9008619456606752, "train/reward_pred": 0.02212211492416613, "train/reward_rate": 0.027846392463235295, "train_stats/sum_log_reward": 5.581818133050745, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 5.7, "train_stats/max_log_achievement_collect_sapling": 2.5727272727272728, "train_stats/max_log_achievement_collect_stone": 0.11818181818181818, "train_stats/max_log_achievement_collect_wood": 8.9, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4818181818181818, "train_stats/max_log_achievement_eat_cow": 0.1, "train_stats/max_log_achievement_make_wood_pickaxe": 0.509090909090909, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 2.5, "train_stats/max_log_achievement_place_stone": 0.03636363636363636, "train_stats/max_log_achievement_place_table": 3.272727272727273, "train_stats/max_log_achievement_wake_up": 1.809090909090909, "train_stats/mean_log_entropy": 0.5435657693581147, "eval_stats/sum_log_reward": 5.7249999940395355, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.4375, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 8.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.3125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.6875, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.034482758620689655, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 3.845889750664355e-06, "report/cont_loss_std": 4.8082572902785614e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006445173057727516, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.9634073851193534e-06, "report/cont_pred": 0.9970701932907104, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.36660385131836, "report/dyn_loss_std": 9.781805992126465, "report/image_loss_mean": 7.511967658996582, "report/image_loss_std": 10.343061447143555, "report/model_loss_mean": 16.185691833496094, "report/model_loss_std": 14.277850151062012, "report/post_ent_mag": 60.19597625732422, "report/post_ent_max": 60.19597625732422, "report/post_ent_mean": 43.05964279174805, "report/post_ent_min": 19.54947853088379, "report/post_ent_std": 8.123705863952637, "report/prior_ent_mag": 69.33259582519531, "report/prior_ent_max": 69.33259582519531, "report/prior_ent_mean": 57.297393798828125, "report/prior_ent_min": 38.64655303955078, "report/prior_ent_std": 5.299290180206299, "report/rep_loss_mean": 14.36660385131836, "report/rep_loss_std": 9.781805992126465, "report/reward_avg": 0.02529296837747097, "report/reward_loss_mean": 0.05375777930021286, "report/reward_loss_std": 0.3316984474658966, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011935234069824, "report/reward_neg_acc": 0.9969818592071533, "report/reward_neg_loss": 0.031942546367645264, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7765693664550781, "report/reward_pred": 0.023014608770608902, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.4345744148158701e-06, "eval/cont_loss_std": 1.7126039892900735e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.2797465135226957e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.3718039326704456e-06, "eval/cont_pred": 0.9970690011978149, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.04844856262207, "eval/dyn_loss_std": 10.437175750732422, "eval/image_loss_mean": 18.813629150390625, "eval/image_loss_std": 27.807653427124023, "eval/model_loss_mean": 30.94285011291504, "eval/model_loss_std": 31.375036239624023, "eval/post_ent_mag": 58.861114501953125, "eval/post_ent_max": 58.861114501953125, "eval/post_ent_mean": 40.53783416748047, "eval/post_ent_min": 22.75122833251953, "eval/post_ent_std": 6.855706214904785, "eval/prior_ent_mag": 68.85554504394531, "eval/prior_ent_max": 68.85554504394531, "eval/prior_ent_mean": 58.10799026489258, "eval/prior_ent_min": 46.08277130126953, "eval/prior_ent_std": 3.8213095664978027, "eval/rep_loss_mean": 20.04844856262207, "eval/rep_loss_std": 10.437175750732422, "eval/reward_avg": 0.03007812425494194, "eval/reward_loss_mean": 0.10014894604682922, "eval/reward_loss_std": 0.6375433802604675, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9981751441955566, "eval/reward_neg_acc": 0.9899091720581055, "eval/reward_neg_loss": 0.03501579537987709, "eval/reward_pos_acc": 0.7878787517547607, "eval/reward_pos_loss": 2.056117057800293, "eval/reward_pred": 0.025049477815628052, "eval/reward_rate": 0.0322265625, "replay/size": 428705.0, "replay/inserts": 21776.0, "replay/samples": 21776.0, "replay/insert_wait_avg": 1.3296850282947953e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.155185057607142e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 86920.0, "eval_replay/inserts": 5280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2006723519527551e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0668556690216, "timer/env.step_count": 2722.0, "timer/env.step_total": 254.78614020347595, "timer/env.step_frac": 0.2547691074443517, "timer/env.step_avg": 0.09360254967063775, "timer/env.step_min": 0.024168968200683594, "timer/env.step_max": 3.232778787612915, "timer/replay._sample_count": 21776.0, "timer/replay._sample_total": 11.501493692398071, "timer/replay._sample_frac": 0.011500724803747083, "timer/replay._sample_avg": 0.0005281729285634677, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.02647566795349121, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3382.0, "timer/agent.policy_total": 57.79151225090027, "timer/agent.policy_frac": 0.05778764881897729, "timer/agent.policy_avg": 0.017087969323152062, "timer/agent.policy_min": 0.009244203567504883, "timer/agent.policy_max": 0.11605000495910645, "timer/dataset_train_count": 1361.0, "timer/dataset_train_total": 0.16171622276306152, "timer/dataset_train_frac": 0.00016170541183956858, "timer/dataset_train_avg": 0.00011882161848865652, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.0010845661163330078, "timer/agent.train_count": 1361.0, "timer/agent.train_total": 613.0850095748901, "timer/agent.train_frac": 0.6130440241065188, "timer/agent.train_avg": 0.45046657573467314, "timer/agent.train_min": 0.4313673973083496, "timer/agent.train_max": 1.7389779090881348, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4833223819732666, "timer/agent.report_frac": 0.00048329007129221886, "timer/agent.report_avg": 0.2416611909866333, "timer/agent.report_min": 0.2326972484588623, "timer/agent.report_max": 0.2506251335144043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4809112548828125e-05, "timer/dataset_eval_frac": 3.480678551789583e-08, "timer/dataset_eval_avg": 3.4809112548828125e-05, "timer/dataset_eval_min": 3.4809112548828125e-05, "timer/dataset_eval_max": 3.4809112548828125e-05, "fps": 21.774251966816482}
{"step": 429256, "time": 20346.23154759407, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 429296, "time": 20349.443291902542, "episode/length": 282.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 429312, "time": 20351.77496266365, "episode/length": 132.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 429472, "time": 20358.832686185837, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 429576, "time": 20363.745771169662, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 429768, "time": 20371.72856760025, "episode/length": 275.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20382.54795241356, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20402.16135072708, "eval_episode/length": 153.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 430040, "time": 20405.113748550415, "eval_episode/length": 174.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9942857142857143}
{"step": 430040, "time": 20410.339723348618, "eval_episode/length": 208.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9808612440191388}
{"step": 430040, "time": 20412.021319627762, "eval_episode/length": 210.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.981042654028436}
{"step": 430040, "time": 20414.58799123764, "eval_episode/length": 230.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 430040, "time": 20416.306506872177, "eval_episode/length": 59.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 430040, "time": 20419.17116189003, "eval_episode/length": 262.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9771863117870723}
{"step": 430040, "time": 20422.024947166443, "eval_episode/length": 290.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9965635738831615}
{"step": 430376, "time": 20434.834229946136, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 430464, "time": 20439.670379400253, "episode/length": 150.0, "episode/score": 5.100000038743019, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 430680, "time": 20448.420276641846, "episode/length": 170.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 430816, "time": 20454.75888156891, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 430896, "time": 20458.94359254837, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 431304, "time": 20474.174267292023, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 431512, "time": 20482.669312238693, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 431608, "time": 20487.41969704628, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 431808, "time": 20495.85500073433, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 432488, "time": 20520.106130599976, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841897233201581, "episode/intrinsic_return": 0.0}
{"step": 432584, "time": 20524.905243635178, "episode/length": 220.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 432680, "time": 20529.638018131256, "episode/length": 222.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 432808, "time": 20537.213575839996, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 432928, "time": 20543.926864624023, "episode/length": 164.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 432976, "time": 20547.134434461594, "episode/length": 366.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 433304, "time": 20559.662353992462, "episode/length": 223.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 433368, "time": 20563.47626376152, "episode/length": 54.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 433456, "time": 20568.262444257736, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 433920, "time": 20586.22208762169, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 433928, "time": 20587.831767320633, "episode/length": 167.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 434080, "time": 20594.77410387993, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 434496, "time": 20611.792240858078, "episode/length": 226.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 434736, "time": 20621.585693359375, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 434904, "time": 20628.612680912018, "episode/length": 240.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 435064, "time": 20635.463278770447, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 435128, "time": 20639.119389295578, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 435664, "time": 20659.039225816727, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 435808, "time": 20665.441618204117, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 435992, "time": 20672.94964838028, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 436008, "time": 20675.053151607513, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 436024, "time": 20677.122178792953, "episode/length": 111.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 436152, "time": 20683.188692331314, "episode/length": 155.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 436256, "time": 20688.612533330917, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 436648, "time": 20703.1132440567, "episode/length": 197.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 437048, "time": 20718.181555509567, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 437056, "time": 20720.274739265442, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 437352, "time": 20731.658276557922, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 437504, "time": 20738.5456199646, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 437544, "time": 20741.356972932816, "episode/length": 189.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9842105263157894, "episode/intrinsic_return": 0.0}
{"step": 437632, "time": 20746.023802757263, "episode/length": 204.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 437888, "time": 20756.263313293457, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 438008, "time": 20761.5895755291, "episode/length": 57.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 438328, "time": 20773.89231657982, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 438336, "time": 20775.953487873077, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 438384, "time": 20779.163293361664, "episode/length": 216.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9907834101382489, "episode/intrinsic_return": 0.0}
{"step": 439008, "time": 20801.817888975143, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 439008, "time": 20801.82801413536, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 439336, "time": 20815.855966567993, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 439336, "time": 20815.88743329048, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9624413145539906, "episode/intrinsic_return": 0.0}
{"step": 439424, "time": 20822.56130671501, "episode/length": 176.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 439480, "time": 20825.82289338112, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 439648, "time": 20833.30895447731, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 439744, "time": 20838.11979532242, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20863.705617189407, "eval_episode/length": 40.0, "eval_episode/score": 2.0999999716877937, "eval_episode/reward_rate": 0.975609756097561}
{"step": 440024, "time": 20872.156399726868, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9493670886075949}
{"step": 440024, "time": 20874.0315618515, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 440024, "time": 20877.193338394165, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 440024, "time": 20877.20372223854, "eval_episode/length": 198.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 440024, "time": 20881.118720054626, "eval_episode/length": 173.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 440024, "time": 20882.81107211113, "eval_episode/length": 216.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9723502304147466}
{"step": 440024, "time": 20884.693261384964, "eval_episode/length": 222.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 440096, "time": 20887.32747912407, "episode/length": 220.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 440576, "time": 20905.09138774872, "episode/length": 195.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 440576, "time": 20905.101805448532, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 440696, "time": 20912.13262653351, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 440760, "time": 20915.8894674778, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 440912, "time": 20922.98575901985, "episode/length": 41.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 441104, "time": 20931.164033651352, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 441192, "time": 20935.49379515648, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9637305699481865, "episode/intrinsic_return": 0.0}
{"step": 441304, "time": 20940.765805482864, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 441648, "time": 20954.265880823135, "episode/length": 133.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 441656, "time": 20955.806002378464, "episode/length": 111.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 441840, "time": 20963.66559290886, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 442168, "time": 20976.069576501846, "episode/length": 40.0, "episode/score": 2.1000000312924385, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 442448, "time": 20988.94968366623, "episode/length": 218.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 442624, "time": 20996.393233060837, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 442768, "time": 21002.730048656464, "episode/length": 139.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 442936, "time": 21009.999617099762, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 442952, "time": 21012.160675048828, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 443120, "time": 21019.591314077377, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 443728, "time": 21041.700763225555, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 443832, "time": 21046.611683130264, "episode/length": 364.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9945205479452055, "episode/intrinsic_return": 0.0}
{"step": 443976, "time": 21052.953906297684, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 444040, "time": 21056.70727968216, "episode/length": 233.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 444168, "time": 21062.490001916885, "episode/length": 174.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 444224, "time": 21066.224703788757, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 444512, "time": 21077.608984708786, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 445088, "time": 21098.810968637466, "episode/length": 169.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 445136, "time": 21102.05934691429, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 445136, "time": 21102.06793308258, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 445408, "time": 21114.44762992859, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 445584, "time": 21122.120914936066, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 445616, "time": 21124.759654521942, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 445992, "time": 21138.83074426651, "episode/length": 184.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 446216, "time": 21148.06640648842, "episode/length": 386.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948320413436692, "episode/intrinsic_return": 0.0}
{"step": 446480, "time": 21158.829528570175, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 446712, "time": 21168.24058032036, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 446840, "time": 21174.115122556686, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 447104, "time": 21184.814873695374, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 447168, "time": 21188.618285655975, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 447256, "time": 21193.113189935684, "episode/length": 264.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 447776, "time": 21212.259282827377, "episode/length": 161.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 448056, "time": 21223.139694452286, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 448160, "time": 21228.570525169373, "episode/length": 131.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 448192, "time": 21231.350205898285, "episode/length": 168.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 448624, "time": 21247.52251958847, "episode/length": 53.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 448776, "time": 21254.113753318787, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 449248, "time": 21271.63718676567, "episode/length": 183.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 449616, "time": 21285.598214626312, "episode/length": 194.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 449736, "time": 21291.02586865425, "episode/length": 439.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 449736, "time": 21291.039565086365, "episode/length": 518.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9845857418111753, "episode/intrinsic_return": 0.0}
{"step": 449816, "time": 21296.98205280304, "episode/length": 330.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9969788519637462, "episode/intrinsic_return": 0.0}
{"step": 449848, "time": 21299.804290533066, "episode/length": 210.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 21324.48943734169, "eval_episode/length": 100.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9603960396039604}
{"step": 450008, "time": 21328.343457698822, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 450008, "time": 21330.85735321045, "eval_episode/length": 171.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 450008, "time": 21333.174889802933, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 450008, "time": 21335.028912305832, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 450008, "time": 21339.325919389725, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 450008, "time": 21341.27689099312, "eval_episode/length": 258.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9884169884169884}
{"step": 450008, "time": 21342.981040477753, "eval_episode/length": 261.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9809160305343512}
{"step": 450041, "time": 21345.118674993515, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.746040635436546, "train/action_min": 0.0, "train/action_std": 3.442728268281194, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04887330884696873, "train/actor_opt_grad_steps": 27380.0, "train/actor_opt_loss": -5.396734734584812, "train/adv_mag": 0.738242391866582, "train/adv_max": 0.7246786387822101, "train/adv_mean": 0.003513759167006578, "train/adv_min": -0.5086702681679762, "train/adv_std": 0.0737969041268789, "train/cont_avg": 0.9947742724236641, "train/cont_loss_mean": 0.00014716242269870438, "train/cont_loss_std": 0.004136827220428888, "train/cont_neg_acc": 0.9982824430210899, "train/cont_neg_loss": 0.004936376860113001, "train/cont_pos_acc": 0.9999550044081593, "train/cont_pos_loss": 0.00011263280405876838, "train/cont_pred": 0.9947354088302787, "train/cont_rate": 0.9947742724236641, "train/dyn_loss_mean": 14.650224809428208, "train/dyn_loss_std": 9.340270879614444, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7991556045208269, "train/extr_critic_critic_opt_grad_steps": 27380.0, "train/extr_critic_critic_opt_loss": 15389.299387225668, "train/extr_critic_mag": 4.919891160863046, "train/extr_critic_max": 4.919891160863046, "train/extr_critic_mean": 0.8461164047244851, "train/extr_critic_min": -0.269364565383387, "train/extr_critic_std": 1.049735690346201, "train/extr_return_normed_mag": 1.8300026473198228, "train/extr_return_normed_max": 1.8300026473198228, "train/extr_return_normed_mean": 0.2950020753245317, "train/extr_return_normed_min": -0.16535335312817842, "train/extr_return_normed_std": 0.3369908748009733, "train/extr_return_rate": 0.42408657745095607, "train/extr_return_raw_mag": 5.794646172123101, "train/extr_return_raw_max": 5.794646172123101, "train/extr_return_raw_mean": 0.857408233498799, "train/extr_return_raw_min": -0.6234187879635178, "train/extr_return_raw_std": 1.0839533696647818, "train/extr_reward_mag": 1.0166984077628332, "train/extr_reward_max": 1.0166984077628332, "train/extr_reward_mean": 0.023932970043641467, "train/extr_reward_min": -0.387967468218039, "train/extr_reward_std": 0.14572005588134737, "train/image_loss_mean": 7.303523165579061, "train/image_loss_std": 11.394271905185612, "train/model_loss_mean": 16.14826744749346, "train/model_loss_std": 15.182927255412094, "train/model_opt_grad_norm": 67.9382420022979, "train/model_opt_grad_steps": 27353.992366412214, "train/model_opt_loss": 18622.203266638837, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1149.8091603053435, "train/policy_entropy_mag": 2.445879017123739, "train/policy_entropy_max": 2.445879017123739, "train/policy_entropy_mean": 0.5741403735320987, "train/policy_entropy_min": 0.0793751012960463, "train/policy_entropy_std": 0.6042886390030839, "train/policy_logprob_mag": 7.438383521014497, "train/policy_logprob_max": -0.009455666592956045, "train/policy_logprob_mean": -0.5737273031063662, "train/policy_logprob_min": -7.438383521014497, "train/policy_logprob_std": 1.1171921291424118, "train/policy_randomness_mag": 0.8632879584800196, "train/policy_randomness_max": 0.8632879584800196, "train/policy_randomness_mean": 0.20264635547881818, "train/policy_randomness_min": 0.02801592760356783, "train/policy_randomness_std": 0.21328737160176722, "train/post_ent_mag": 59.96652760396477, "train/post_ent_max": 59.96652760396477, "train/post_ent_mean": 42.397692440120316, "train/post_ent_min": 21.80928904409627, "train/post_ent_std": 7.470002953332799, "train/prior_ent_mag": 69.62724962307297, "train/prior_ent_max": 69.62724962307297, "train/prior_ent_mean": 57.10724040024153, "train/prior_ent_min": 41.07716573467692, "train/prior_ent_std": 4.597568539262728, "train/rep_loss_mean": 14.650224809428208, "train/rep_loss_std": 9.340270879614444, "train/reward_avg": 0.023819179082189806, "train/reward_loss_mean": 0.05446228402034017, "train/reward_loss_std": 0.2552751360731271, "train/reward_max_data": 1.0167938971337471, "train/reward_max_pred": 1.0086747708211419, "train/reward_neg_acc": 0.9926436015667807, "train/reward_neg_loss": 0.030042216018240416, "train/reward_pos_acc": 0.9618593904808277, "train/reward_pos_loss": 0.8865332193957031, "train/reward_pred": 0.022952651448604713, "train/reward_rate": 0.028514134064885496, "train_stats/sum_log_reward": 5.626785687037876, "train_stats/max_log_achievement_collect_coal": 0.008928571428571428, "train_stats/max_log_achievement_collect_drink": 6.357142857142857, "train_stats/max_log_achievement_collect_sapling": 2.7410714285714284, "train_stats/max_log_achievement_collect_stone": 0.0625, "train_stats/max_log_achievement_collect_wood": 8.116071428571429, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.38392857142857145, "train_stats/max_log_achievement_eat_cow": 0.05357142857142857, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.5892857142857143, "train_stats/max_log_achievement_make_wood_sword": 0.0625, "train_stats/max_log_achievement_place_plant": 2.642857142857143, "train_stats/max_log_achievement_place_stone": 0.017857142857142856, "train_stats/max_log_achievement_place_table": 2.9285714285714284, "train_stats/max_log_achievement_wake_up": 1.8214285714285714, "train_stats/mean_log_entropy": 0.5596623000289712, "eval_stats/sum_log_reward": 5.51666659116745, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.666666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.6666666666666665, "eval_stats/max_log_achievement_collect_stone": 0.20833333333333334, "eval_stats/max_log_achievement_collect_wood": 8.041666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_stone_sword": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.6666666666666666, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.041666666666666664, "eval_stats/max_log_achievement_place_table": 2.4583333333333335, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 2.264401473439648e-06, "report/cont_loss_std": 2.924793261627201e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005099126137793064, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.2709608654404292e-06, "report/cont_pred": 0.9980465769767761, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.51194953918457, "report/dyn_loss_std": 9.258130073547363, "report/image_loss_mean": 7.423642158508301, "report/image_loss_std": 15.258001327514648, "report/model_loss_mean": 14.967005729675293, "report/model_loss_std": 18.600513458251953, "report/post_ent_mag": 59.59419250488281, "report/post_ent_max": 59.59419250488281, "report/post_ent_mean": 43.34722137451172, "report/post_ent_min": 23.58765411376953, "report/post_ent_std": 7.320862770080566, "report/prior_ent_mag": 69.34073638916016, "report/prior_ent_max": 69.34073638916016, "report/prior_ent_mean": 56.49243927001953, "report/prior_ent_min": 35.18708419799805, "report/prior_ent_std": 5.142848968505859, "report/rep_loss_mean": 12.51194953918457, "report/rep_loss_std": 9.258130073547363, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.03619161620736122, "report/reward_loss_std": 0.18737977743148804, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0056915283203125, "report/reward_neg_acc": 0.9980000257492065, "report/reward_neg_loss": 0.02040894888341427, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6938028335571289, "report/reward_pred": 0.021481651812791824, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0004289978533051908, "eval/cont_loss_std": 0.01263215858489275, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0820365846157074, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.8568074412760325e-05, "eval/cont_pred": 0.9954198598861694, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.416088104248047, "eval/dyn_loss_std": 10.04386043548584, "eval/image_loss_mean": 11.808798789978027, "eval/image_loss_std": 14.962646484375, "eval/model_loss_mean": 23.550689697265625, "eval/model_loss_std": 18.74477767944336, "eval/post_ent_mag": 58.831729888916016, "eval/post_ent_max": 58.831729888916016, "eval/post_ent_mean": 40.40846252441406, "eval/post_ent_min": 22.91154670715332, "eval/post_ent_std": 7.008732795715332, "eval/prior_ent_mag": 69.34073638916016, "eval/prior_ent_max": 69.34073638916016, "eval/prior_ent_mean": 57.5716552734375, "eval/prior_ent_min": 40.03449249267578, "eval/prior_ent_std": 4.779660224914551, "eval/rep_loss_mean": 19.416088104248047, "eval/rep_loss_std": 10.04386043548584, "eval/reward_avg": 0.02109375037252903, "eval/reward_loss_mean": 0.09181047976016998, "eval/reward_loss_std": 0.5587891340255737, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0013184547424316, "eval/reward_neg_acc": 0.9889779686927795, "eval/reward_neg_loss": 0.047277871519327164, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.8011775016784668, "eval/reward_pred": 0.02104749158024788, "eval/reward_rate": 0.025390625, "replay/size": 449537.0, "replay/inserts": 20832.0, "replay/samples": 20832.0, "replay/insert_wait_avg": 1.337041594831991e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.355016314305835e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 93128.0, "eval_replay/inserts": 6208.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1761932028937586e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3653519153595, "timer/env.step_count": 2604.0, "timer/env.step_total": 252.3596053123474, "timer/env.step_frac": 0.252267438920355, "timer/env.step_avg": 0.09691229082655431, "timer/env.step_min": 0.024106979370117188, "timer/env.step_max": 3.5436360836029053, "timer/replay._sample_count": 20832.0, "timer/replay._sample_total": 10.941914319992065, "timer/replay._sample_frac": 0.010937918130652986, "timer/replay._sample_avg": 0.0005252455030718158, "timer/replay._sample_min": 0.0004093647003173828, "timer/replay._sample_max": 0.02215409278869629, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3380.0, "timer/agent.policy_total": 58.90369439125061, "timer/agent.policy_frac": 0.05888218167339569, "timer/agent.policy_avg": 0.017427128518121483, "timer/agent.policy_min": 0.009622573852539062, "timer/agent.policy_max": 0.13433432579040527, "timer/dataset_train_count": 1302.0, "timer/dataset_train_total": 0.15439629554748535, "timer/dataset_train_frac": 0.00015433990716678557, "timer/dataset_train_avg": 0.00011858394435290734, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0005550384521484375, "timer/agent.train_count": 1302.0, "timer/agent.train_total": 584.4292483329773, "timer/agent.train_frac": 0.5842158039700136, "timer/agent.train_avg": 0.4488703904247137, "timer/agent.train_min": 0.43552207946777344, "timer/agent.train_max": 1.5898692607879639, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48427438735961914, "timer/agent.report_frac": 0.0004840975214029538, "timer/agent.report_avg": 0.24213719367980957, "timer/agent.report_min": 0.23459362983703613, "timer/agent.report_max": 0.249680757522583, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.2651416079510214e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 20.824107435970888}
{"step": 450160, "time": 21349.212406873703, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 450184, "time": 21351.30018877983, "episode/length": 55.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9107142857142857, "episode/intrinsic_return": 0.0}
{"step": 450656, "time": 21370.572511196136, "episode/length": 175.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 450664, "time": 21372.694137573242, "episode/length": 235.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 450968, "time": 21384.95460009575, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 451016, "time": 21388.117728471756, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 451080, "time": 21391.81341934204, "episode/length": 167.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 451304, "time": 21401.09003019333, "episode/length": 185.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 451528, "time": 21410.114915132523, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 451632, "time": 21415.39580631256, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 452224, "time": 21436.949355840683, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 452464, "time": 21446.60145020485, "episode/length": 225.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 452584, "time": 21452.00514292717, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 452984, "time": 21467.349519491196, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 453008, "time": 21469.999343395233, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 453344, "time": 21482.83581662178, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 453416, "time": 21486.659714460373, "episode/length": 53.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 453432, "time": 21488.753720521927, "episode/length": 52.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 453712, "time": 21500.204355716705, "episode/length": 300.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 454016, "time": 21511.938976049423, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 454208, "time": 21520.237218379974, "episode/length": 247.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 454504, "time": 21531.52354836464, "episode/length": 254.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 454608, "time": 21536.848076581955, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 454816, "time": 21545.559993505478, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 454840, "time": 21547.702664852142, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 454944, "time": 21553.071242570877, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 455376, "time": 21569.164757966995, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 455400, "time": 21571.517296552658, "episode/length": 69.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 455688, "time": 21582.831034183502, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 455776, "time": 21587.514053106308, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 455864, "time": 21591.85611796379, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 455912, "time": 21595.13035964966, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 456336, "time": 21611.33692932129, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 456344, "time": 21612.959115982056, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 456656, "time": 21625.243284463882, "episode/length": 159.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 456680, "time": 21627.48455786705, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 457096, "time": 21643.231407642365, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 457176, "time": 21647.532255649567, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 457216, "time": 21650.724103212357, "episode/length": 69.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 457352, "time": 21656.7137196064, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 457664, "time": 21669.031981945038, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 457680, "time": 21671.332902908325, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 457728, "time": 21674.629541873932, "episode/length": 46.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 457768, "time": 21677.421439886093, "episode/length": 178.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 458232, "time": 21694.599266767502, "episode/length": 57.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 458280, "time": 21697.809458732605, "episode/length": 199.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 458312, "time": 21700.540010929108, "episode/length": 151.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 458704, "time": 21715.41988134384, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 459120, "time": 21732.591543912888, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 459192, "time": 21736.417890787125, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 459232, "time": 21739.53677725792, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 459296, "time": 21743.30088353157, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 459792, "time": 21761.69619703293, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 459864, "time": 21765.456235170364, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 460024, "time": 21772.416523218155, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21791.84765267372, "eval_episode/length": 38.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.8974358974358975}
{"step": 460096, "time": 21797.584617853165, "eval_episode/length": 131.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9621212121212122}
{"step": 460096, "time": 21800.215698719025, "eval_episode/length": 157.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 460096, "time": 21801.91668319702, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 460096, "time": 21803.86668896675, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 460096, "time": 21806.596868276596, "eval_episode/length": 193.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 460096, "time": 21808.73096203804, "eval_episode/length": 203.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 460096, "time": 21811.67549276352, "eval_episode/length": 236.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 460616, "time": 21828.980373620987, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 460656, "time": 21832.18975830078, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 460832, "time": 21839.700459480286, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 460896, "time": 21843.340909957886, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 461360, "time": 21860.562518835068, "episode/length": 186.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 461680, "time": 21872.979666233063, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 461696, "time": 21875.12380337715, "episode/length": 237.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 461752, "time": 21878.341304302216, "episode/length": 429.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 462160, "time": 21894.022172927856, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 462176, "time": 21896.10690832138, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 462264, "time": 21900.4362680912, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 463024, "time": 21928.09243607521, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 463136, "time": 21933.40582203865, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 463192, "time": 21936.5961458683, "episode/length": 228.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 463272, "time": 21940.962044000626, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 463592, "time": 21953.22945666313, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 463944, "time": 21966.671903133392, "episode/length": 410.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 463952, "time": 21968.837562561035, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 464528, "time": 21989.990686178207, "episode/length": 166.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 464544, "time": 21992.10615682602, "episode/length": 158.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 464648, "time": 21996.907098293304, "episode/length": 368.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.997289972899729, "episode/intrinsic_return": 0.0}
{"step": 464688, "time": 22000.257480859756, "episode/length": 193.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 464800, "time": 22005.642075777054, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 465224, "time": 22021.360657453537, "episode/length": 71.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.0}
{"step": 465320, "time": 22026.179540395737, "episode/length": 171.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 465456, "time": 22032.680797100067, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 465776, "time": 22044.955396175385, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 465880, "time": 22049.93647146225, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 465904, "time": 22052.631781101227, "episode/length": 288.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9896193771626297, "episode/intrinsic_return": 0.0}
{"step": 466472, "time": 22073.429677963257, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 466520, "time": 22076.608998537064, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 466528, "time": 22078.720237731934, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 467016, "time": 22097.93848514557, "episode/length": 276.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 467088, "time": 22102.111653089523, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9536423841059603, "episode/intrinsic_return": 0.0}
{"step": 467232, "time": 22108.496459960938, "episode/length": 221.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 467544, "time": 22120.34589076042, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 467784, "time": 22129.970400571823, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 467816, "time": 22132.650385141373, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 467888, "time": 22136.81055879593, "episode/length": 42.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8837209302325582, "episode/intrinsic_return": 0.0}
{"step": 467960, "time": 22140.656138420105, "episode/length": 185.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 468408, "time": 22157.335303544998, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 468424, "time": 22159.53894329071, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 468704, "time": 22170.73103618622, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 468712, "time": 22172.370122671127, "episode/length": 272.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 469136, "time": 22188.551063776016, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 469328, "time": 22196.574254989624, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 469392, "time": 22200.339785337448, "episode/length": 178.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 469840, "time": 22216.970351696014, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 22241.368359327316, "eval_episode/length": 35.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 470080, "time": 22247.583540916443, "eval_episode/length": 142.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 470080, "time": 22247.59261393547, "eval_episode/length": 142.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 470080, "time": 22252.08626294136, "eval_episode/length": 167.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 470080, "time": 22253.898118257523, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 470080, "time": 22256.501976966858, "eval_episode/length": 194.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 470080, "time": 22258.3836145401, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 470080, "time": 22260.07847738266, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 470288, "time": 22267.011192798615, "episode/length": 232.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 470320, "time": 22269.64650964737, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 470520, "time": 22278.245057582855, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 470608, "time": 22283.613936185837, "episode/length": 95.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 470816, "time": 22292.541216135025, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 471296, "time": 22310.347194194794, "episode/length": 425.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 471440, "time": 22316.856075286865, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 471472, "time": 22319.482036590576, "episode/length": 344.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 471632, "time": 22326.3003885746, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 471720, "time": 22330.676770448685, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 471832, "time": 22336.11946463585, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 472024, "time": 22344.211807012558, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 472025, "time": 22346.866787195206, "train_stats/sum_log_reward": 5.5956521272659305, "train_stats/max_log_achievement_collect_coal": 0.02608695652173913, "train_stats/max_log_achievement_collect_drink": 6.3652173913043475, "train_stats/max_log_achievement_collect_sapling": 3.026086956521739, "train_stats/max_log_achievement_collect_stone": 0.2, "train_stats/max_log_achievement_collect_wood": 7.434782608695652, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "train_stats/max_log_achievement_defeat_zombie": 0.3217391304347826, "train_stats/max_log_achievement_eat_cow": 0.02608695652173913, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7565217391304347, "train_stats/max_log_achievement_make_wood_sword": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 2.965217391304348, "train_stats/max_log_achievement_place_stone": 0.043478260869565216, "train_stats/max_log_achievement_place_table": 2.4521739130434783, "train_stats/max_log_achievement_wake_up": 1.3217391304347825, "train_stats/mean_log_entropy": 0.5526771953572398, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.916147051066377, "train/action_min": 0.0, "train/action_std": 3.6266237836684625, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04900883472640149, "train/actor_opt_grad_steps": 28720.0, "train/actor_opt_loss": -3.350831451397525, "train/adv_mag": 0.7100945780747128, "train/adv_max": 0.6995262503623962, "train/adv_mean": 0.004136315556356716, "train/adv_min": -0.49097049627860967, "train/adv_std": 0.07296029426646929, "train/cont_avg": 0.9946681113138686, "train/cont_loss_mean": 0.00032992406030507815, "train/cont_loss_std": 0.010015874441524915, "train/cont_neg_acc": 0.9934132790913547, "train/cont_neg_loss": 0.02440096497570014, "train/cont_pos_acc": 0.9999426703383453, "train/cont_pos_loss": 0.00018345986059392272, "train/cont_pred": 0.9946555708446642, "train/cont_rate": 0.9946681113138686, "train/dyn_loss_mean": 14.48542378418637, "train/dyn_loss_std": 9.374745640441448, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7886804524999466, "train/extr_critic_critic_opt_grad_steps": 28720.0, "train/extr_critic_critic_opt_loss": 15463.779389541514, "train/extr_critic_mag": 5.094137967938054, "train/extr_critic_max": 5.094137967938054, "train/extr_critic_mean": 0.8729413475868476, "train/extr_critic_min": -0.27005351285864837, "train/extr_critic_std": 1.0990530657072137, "train/extr_return_normed_mag": 1.8169231849865322, "train/extr_return_normed_max": 1.8169231849865322, "train/extr_return_normed_mean": 0.2949162872820875, "train/extr_return_normed_min": -0.14554759691448976, "train/extr_return_normed_std": 0.3369031268967329, "train/extr_return_rate": 0.42960958661389176, "train/extr_return_raw_mag": 6.011865605403037, "train/extr_return_raw_max": 6.011865605403037, "train/extr_return_raw_mean": 0.8868830317128313, "train/extr_return_raw_min": -0.5962823931753201, "train/extr_return_raw_std": 1.1345945179027364, "train/extr_reward_mag": 1.018356377190917, "train/extr_reward_max": 1.018356377190917, "train/extr_reward_mean": 0.025106369966409938, "train/extr_reward_min": -0.3996943200591707, "train/extr_reward_std": 0.1490063884288725, "train/image_loss_mean": 7.254975541664736, "train/image_loss_std": 11.482627966108113, "train/model_loss_mean": 16.000475911328394, "train/model_loss_std": 15.325592507411093, "train/model_opt_grad_norm": 60.42473323849866, "train/model_opt_grad_steps": 28692.007299270073, "train/model_opt_loss": 12689.008486114279, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 793.7956204379562, "train/policy_entropy_mag": 2.4870947764737763, "train/policy_entropy_max": 2.4870947764737763, "train/policy_entropy_mean": 0.5886761644025789, "train/policy_entropy_min": 0.07937509294626487, "train/policy_entropy_std": 0.6025025357295127, "train/policy_logprob_mag": 7.4383835131234495, "train/policy_logprob_max": -0.009455662744160551, "train/policy_logprob_mean": -0.5893297121472603, "train/policy_logprob_min": -7.4383835131234495, "train/policy_logprob_std": 1.1309870672922064, "train/policy_randomness_mag": 0.8778353137691526, "train/policy_randomness_max": 0.8778353137691526, "train/policy_randomness_mean": 0.20777685450811456, "train/policy_randomness_min": 0.028015924508880526, "train/policy_randomness_std": 0.21265695423540407, "train/post_ent_mag": 59.84652253311046, "train/post_ent_max": 59.84652253311046, "train/post_ent_mean": 42.62919477476691, "train/post_ent_min": 21.378267664108833, "train/post_ent_std": 7.474425315856934, "train/prior_ent_mag": 69.6749332177378, "train/prior_ent_max": 69.6749332177378, "train/prior_ent_mean": 57.169782596783044, "train/prior_ent_min": 41.23972844033346, "train/prior_ent_std": 4.630014995588874, "train/rep_loss_mean": 14.48542378418637, "train/rep_loss_std": 9.374745640441448, "train/reward_avg": 0.024281477943117167, "train/reward_loss_mean": 0.05391622499229699, "train/reward_loss_std": 0.24879609439929906, "train/reward_max_data": 1.0182481795331857, "train/reward_max_pred": 1.011142325227278, "train/reward_neg_acc": 0.9926831091407442, "train/reward_neg_loss": 0.02958687579082529, "train/reward_pos_acc": 0.9650409735032242, "train/reward_pos_loss": 0.8696289702053488, "train/reward_pred": 0.023640711016844222, "train/reward_rate": 0.02899036268248175, "train_stats/max_log_achievement_place_furnace": 0.01098901098901099, "eval_stats/sum_log_reward": 5.1624999195337296, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 7.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 8.801326475804672e-05, "report/cont_loss_std": 0.0023044703993946314, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.022295620292425156, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.246152785635786e-07, "report/cont_pred": 0.9961773157119751, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.636144638061523, "report/dyn_loss_std": 9.428560256958008, "report/image_loss_mean": 7.7152099609375, "report/image_loss_std": 12.337536811828613, "report/model_loss_mean": 15.933259010314941, "report/model_loss_std": 16.199556350708008, "report/post_ent_mag": 59.21146011352539, "report/post_ent_max": 59.21146011352539, "report/post_ent_mean": 43.391231536865234, "report/post_ent_min": 20.677902221679688, "report/post_ent_std": 7.362130641937256, "report/prior_ent_mag": 69.76295471191406, "report/prior_ent_max": 69.76295471191406, "report/prior_ent_mean": 57.151023864746094, "report/prior_ent_min": 40.21055603027344, "report/prior_ent_std": 5.1737961769104, "report/rep_loss_mean": 13.636144638061523, "report/rep_loss_std": 9.428560256958008, "report/reward_avg": 0.00820312462747097, "report/reward_loss_mean": 0.03627443686127663, "report/reward_loss_std": 0.15056854486465454, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0009820461273193, "report/reward_neg_acc": 0.9930693507194519, "report/reward_neg_loss": 0.02693863958120346, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7097856402397156, "report/reward_pred": 0.00868501141667366, "report/reward_rate": 0.013671875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.24233076046221e-06, "eval/cont_loss_std": 6.310985190793872e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0008029878954403102, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.895379796224006e-06, "eval/cont_pred": 0.9970707893371582, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.793209075927734, "eval/dyn_loss_std": 10.62013053894043, "eval/image_loss_mean": 12.259981155395508, "eval/image_loss_std": 15.56301498413086, "eval/model_loss_mean": 24.24575424194336, "eval/model_loss_std": 19.841136932373047, "eval/post_ent_mag": 63.89959716796875, "eval/post_ent_max": 63.89959716796875, "eval/post_ent_mean": 40.28339385986328, "eval/post_ent_min": 21.695167541503906, "eval/post_ent_std": 7.260030746459961, "eval/prior_ent_mag": 70.3078384399414, "eval/prior_ent_max": 70.3078384399414, "eval/prior_ent_mean": 57.264854431152344, "eval/prior_ent_min": 40.055084228515625, "eval/prior_ent_std": 4.645371913909912, "eval/rep_loss_mean": 19.793209075927734, "eval/rep_loss_std": 10.62013053894043, "eval/reward_avg": 0.03378906100988388, "eval/reward_loss_mean": 0.10984455794095993, "eval/reward_loss_std": 0.5937876105308533, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002089262008667, "eval/reward_neg_acc": 0.9868153929710388, "eval/reward_neg_loss": 0.04715351760387421, "eval/reward_pos_acc": 0.7631579041481018, "eval/reward_pos_loss": 1.7365120649337769, "eval/reward_pred": 0.026681728661060333, "eval/reward_rate": 0.037109375, "replay/size": 471521.0, "replay/inserts": 21984.0, "replay/samples": 21984.0, "replay/insert_wait_avg": 1.3391415451638389e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.294628123876136e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 96640.0, "eval_replay/inserts": 3512.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2204695942733174e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1622905731201172e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.7362909317017, "timer/env.step_count": 2748.0, "timer/env.step_total": 262.62826013565063, "timer/env.step_frac": 0.262173051443892, "timer/env.step_avg": 0.09557069146129936, "timer/env.step_min": 0.024562835693359375, "timer/env.step_max": 2.149535894393921, "timer/replay._sample_count": 21984.0, "timer/replay._sample_total": 11.471259832382202, "timer/replay._sample_frac": 0.011451376910497009, "timer/replay._sample_avg": 0.0005218003926665849, "timer/replay._sample_min": 0.00041985511779785156, "timer/replay._sample_max": 0.011467933654785156, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3187.0, "timer/agent.policy_total": 54.14432382583618, "timer/agent.policy_frac": 0.054050476473680775, "timer/agent.policy_avg": 0.016989119493516218, "timer/agent.policy_min": 0.009619712829589844, "timer/agent.policy_max": 0.0986936092376709, "timer/dataset_train_count": 1374.0, "timer/dataset_train_total": 0.16148138046264648, "timer/dataset_train_frac": 0.0001612014877812351, "timer/dataset_train_avg": 0.00011752647777485188, "timer/dataset_train_min": 0.00010251998901367188, "timer/dataset_train_max": 0.0007622241973876953, "timer/agent.train_count": 1374.0, "timer/agent.train_total": 618.5229022502899, "timer/agent.train_frac": 0.617450827976902, "timer/agent.train_avg": 0.4501622287120014, "timer/agent.train_min": 0.43602514266967773, "timer/agent.train_max": 1.5305705070495605, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4838426113128662, "timer/agent.report_frac": 0.00048300397588955333, "timer/agent.report_avg": 0.2419213056564331, "timer/agent.report_min": 0.2355048656463623, "timer/agent.report_max": 0.2483377456665039, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.5762786865234375e-05, "timer/dataset_eval_frac": 3.570079989013065e-08, "timer/dataset_eval_avg": 3.5762786865234375e-05, "timer/dataset_eval_min": 3.5762786865234375e-05, "timer/dataset_eval_max": 3.5762786865234375e-05, "fps": 21.94558350343073}
{"step": 472176, "time": 22357.753908872604, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 472944, "time": 22385.166993141174, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 473320, "time": 22399.247676610947, "episode/length": 252.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 473392, "time": 22403.520357847214, "episode/length": 170.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 473504, "time": 22408.92974090576, "episode/length": 253.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 473720, "time": 22417.603382587433, "episode/length": 49.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 473848, "time": 22423.47834253311, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 473856, "time": 22425.565687656403, "episode/length": 252.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 473912, "time": 22428.760382175446, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9838187702265372, "episode/intrinsic_return": 0.0}
{"step": 474112, "time": 22437.325484752655, "episode/length": 32.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 474224, "time": 22442.75690793991, "episode/length": 159.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 474280, "time": 22445.99453139305, "episode/length": 262.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 474424, "time": 22452.470739126205, "episode/length": 38.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 475016, "time": 22473.91650891304, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 475032, "time": 22476.01650595665, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 475104, "time": 22480.289385795593, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 475456, "time": 22495.157168865204, "episode/length": 199.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 475472, "time": 22497.26660823822, "episode/length": 148.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 475584, "time": 22502.520724773407, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 475984, "time": 22517.53059029579, "episode/length": 49.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 476184, "time": 22525.579461574554, "episode/length": 283.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 476592, "time": 22541.074604272842, "episode/length": 194.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 476600, "time": 22542.75317144394, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 476792, "time": 22550.87536406517, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 477136, "time": 22564.046905994415, "episode/length": 338.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9911504424778761, "episode/intrinsic_return": 0.0}
{"step": 477456, "time": 22576.607628583908, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 477528, "time": 22580.36154961586, "episode/length": 256.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 477840, "time": 22592.64056992531, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 477880, "time": 22595.324424505234, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 478272, "time": 22610.3108856678, "episode/length": 208.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 478304, "time": 22613.009283304214, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 478416, "time": 22618.32879757881, "episode/length": 110.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 478504, "time": 22622.596404075623, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 478520, "time": 22624.730439424515, "episode/length": 382.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9973890339425587, "episode/intrinsic_return": 0.0}
{"step": 478680, "time": 22631.724165201187, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 479216, "time": 22651.490621566772, "episode/length": 171.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 479216, "time": 22651.499737739563, "episode/length": 113.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 479584, "time": 22667.800358057022, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 479656, "time": 22671.530291080475, "episode/length": 172.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 479824, "time": 22679.0118162632, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 479904, "time": 22683.322704553604, "episode/length": 185.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 480032, "time": 22689.207304239273, "episode/length": 188.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22706.78015446663, "eval_episode/length": 30.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.967741935483871}
{"step": 480064, "time": 22715.4923517704, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9875}
{"step": 480064, "time": 22717.210881710052, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 480064, "time": 22719.219138383865, "eval_episode/length": 170.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 480064, "time": 22721.613595485687, "eval_episode/length": 184.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 480064, "time": 22723.367012262344, "eval_episode/length": 187.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 480064, "time": 22726.895291805267, "eval_episode/length": 232.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 480064, "time": 22728.75777196884, "eval_episode/length": 239.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9958333333333333}
{"step": 480344, "time": 22737.83884382248, "episode/length": 54.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 480504, "time": 22744.72799730301, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 480560, "time": 22748.28892993927, "episode/length": 65.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 480680, "time": 22753.741764068604, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 481048, "time": 22767.658367156982, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 481320, "time": 22778.296575546265, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 481672, "time": 22791.888610124588, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 481864, "time": 22799.96432352066, "episode/length": 397.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773869346733668, "episode/intrinsic_return": 0.0}
{"step": 481984, "time": 22805.873286485672, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 482072, "time": 22810.270951509476, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 482096, "time": 22812.836288690567, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 482336, "time": 22822.43768596649, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 482664, "time": 22834.863266468048, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 482712, "time": 22838.01802587509, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 483224, "time": 22857.0301759243, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 483424, "time": 22866.891948461533, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 483528, "time": 22871.851412296295, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 483672, "time": 22878.33956336975, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 483888, "time": 22888.134778022766, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 484184, "time": 22899.359070539474, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 484496, "time": 22911.697710752487, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 484648, "time": 22918.11975502968, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 484968, "time": 22930.54601097107, "episode/length": 192.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 484976, "time": 22932.579161643982, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 485008, "time": 22935.20993065834, "episode/length": 44.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 485144, "time": 22941.14458012581, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 485304, "time": 22948.133581638336, "episode/length": 453.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9801762114537445, "episode/intrinsic_return": 0.0}
{"step": 485424, "time": 22953.98918914795, "episode/length": 191.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 485448, "time": 22956.629558324814, "episode/length": 347.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 485488, "time": 22960.33134484291, "episode/length": 64.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 486352, "time": 22991.355309724808, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 486480, "time": 22997.302496910095, "episode/length": 183.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 486536, "time": 23000.66904759407, "episode/length": 254.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 486576, "time": 23003.85588145256, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 486704, "time": 23009.767022371292, "episode/length": 174.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 486888, "time": 23017.376158952713, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 487128, "time": 23027.022654294968, "episode/length": 209.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 487264, "time": 23033.497423171997, "episode/length": 221.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 487536, "time": 23044.16578936577, "episode/length": 50.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 487664, "time": 23050.193253040314, "episode/length": 49.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 487744, "time": 23054.374489545822, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 487912, "time": 23061.476390361786, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 488032, "time": 23067.421194314957, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 488128, "time": 23072.196121692657, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 488200, "time": 23075.91871356964, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 488568, "time": 23089.869167089462, "episode/length": 54.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 488688, "time": 23095.596185684204, "episode/length": 143.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 488944, "time": 23105.799973487854, "episode/length": 256.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 488984, "time": 23108.41024327278, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 489184, "time": 23117.047596931458, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 489192, "time": 23118.703373908997, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 489336, "time": 23125.130572795868, "episode/length": 141.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 489336, "time": 23125.139557361603, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 489936, "time": 23148.73347234726, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 23174.521238327026, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 490048, "time": 23176.198623418808, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 490048, "time": 23178.09782767296, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 490048, "time": 23181.247444868088, "eval_episode/length": 201.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 490048, "time": 23183.019433021545, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 490048, "time": 23185.130230903625, "eval_episode/length": 215.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 490048, "time": 23187.351852178574, "eval_episode/length": 230.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 490048, "time": 23190.614670038223, "eval_episode/length": 51.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 490384, "time": 23201.92278766632, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 490416, "time": 23204.71689772606, "episode/length": 183.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 490584, "time": 23212.25225877762, "episode/length": 173.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 490944, "time": 23226.15070438385, "episode/length": 200.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 491248, "time": 23238.06705236435, "episode/length": 334.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 491288, "time": 23240.79136991501, "episode/length": 168.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 491328, "time": 23244.06533932686, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 491936, "time": 23267.53044772148, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 492264, "time": 23279.720479488373, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 492344, "time": 23284.027100801468, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 492568, "time": 23293.401572942734, "episode/length": 422.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 492792, "time": 23302.542785167694, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 492800, "time": 23304.71091914177, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 493008, "time": 23313.209523677826, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 493368, "time": 23326.711998462677, "episode/length": 254.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 493560, "time": 23334.691241025925, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 493616, "time": 23338.26867055893, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 493792, "time": 23345.84613609314, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 493793, "time": 23348.177985191345, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.049950992359834, "train/action_min": 0.0, "train/action_std": 3.749391387490665, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04767253145794658, "train/actor_opt_grad_steps": 30085.0, "train/actor_opt_loss": -5.718540643300751, "train/adv_mag": 0.7194631388958763, "train/adv_max": 0.7000618546324617, "train/adv_mean": 0.0034764246772604514, "train/adv_min": -0.511554096113233, "train/adv_std": 0.07229820814202814, "train/cont_avg": 0.9944924747242647, "train/cont_loss_mean": 0.0002368661570311387, "train/cont_loss_std": 0.007262256795032125, "train/cont_neg_acc": 0.9948879572398522, "train/cont_neg_loss": 0.02416732522766217, "train/cont_pos_acc": 0.9999565880964784, "train/cont_pos_loss": 8.218742623021606e-05, "train/cont_pred": 0.9944940077907899, "train/cont_rate": 0.9944924747242647, "train/dyn_loss_mean": 14.360585843815523, "train/dyn_loss_std": 9.309299679363475, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7810290151220911, "train/extr_critic_critic_opt_grad_steps": 30085.0, "train/extr_critic_critic_opt_loss": 15420.606007295497, "train/extr_critic_mag": 5.1869570262291855, "train/extr_critic_max": 5.1869570262291855, "train/extr_critic_mean": 0.8765920181484783, "train/extr_critic_min": -0.2895368697012172, "train/extr_critic_std": 1.1197554087814163, "train/extr_return_normed_mag": 1.829051598906517, "train/extr_return_normed_max": 1.829051598906517, "train/extr_return_normed_mean": 0.29530884062542634, "train/extr_return_normed_min": -0.1559643116505707, "train/extr_return_normed_std": 0.34179627807701335, "train/extr_return_rate": 0.4329546971575302, "train/extr_return_raw_mag": 6.062497636851142, "train/extr_return_raw_max": 6.062497636851142, "train/extr_return_raw_mean": 0.8883257587166393, "train/extr_return_raw_min": -0.6338340245625552, "train/extr_return_raw_std": 1.1532235434826683, "train/extr_reward_mag": 1.0219150974470026, "train/extr_reward_max": 1.0219150974470026, "train/extr_reward_mean": 0.02607744052896605, "train/extr_reward_min": -0.3953455362249823, "train/extr_reward_std": 0.15282364879899166, "train/image_loss_mean": 6.880900091984692, "train/image_loss_std": 11.292216861949248, "train/model_loss_mean": 15.55193335869733, "train/model_loss_std": 15.077132961329292, "train/model_opt_grad_norm": 61.484109345604395, "train/model_opt_grad_steps": 30056.139705882353, "train/model_opt_loss": 12264.045489142924, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 790.4411764705883, "train/policy_entropy_mag": 2.488893810440512, "train/policy_entropy_max": 2.488893810440512, "train/policy_entropy_mean": 0.6032238611403633, "train/policy_entropy_min": 0.07937508564004127, "train/policy_entropy_std": 0.6146532726638457, "train/policy_logprob_mag": 7.438383502118728, "train/policy_logprob_max": -0.009455660173176405, "train/policy_logprob_mean": -0.6040346168858164, "train/policy_logprob_min": -7.438383502118728, "train/policy_logprob_std": 1.142621612724136, "train/policy_randomness_mag": 0.878470291986185, "train/policy_randomness_max": 0.878470291986185, "train/policy_randomness_mean": 0.212911550722578, "train/policy_randomness_min": 0.028015921946943682, "train/policy_randomness_std": 0.21694563405916972, "train/post_ent_mag": 60.029087347142834, "train/post_ent_max": 60.029087347142834, "train/post_ent_mean": 42.7579143187579, "train/post_ent_min": 21.404836570515354, "train/post_ent_std": 7.472787674735574, "train/prior_ent_mag": 69.78005235335407, "train/prior_ent_max": 69.78005235335407, "train/prior_ent_mean": 57.191371356739715, "train/prior_ent_min": 41.57070011251113, "train/prior_ent_std": 4.568178336409962, "train/rep_loss_mean": 14.360585843815523, "train/rep_loss_std": 9.309299679363475, "train/reward_avg": 0.02472354646991281, "train/reward_loss_mean": 0.05444501507479478, "train/reward_loss_std": 0.24752444554777706, "train/reward_max_data": 1.0147058858590967, "train/reward_max_pred": 1.0114253101979984, "train/reward_neg_acc": 0.9929224861895337, "train/reward_neg_loss": 0.0301559755085584, "train/reward_pos_acc": 0.9664295534877216, "train/reward_pos_loss": 0.8519836957840359, "train/reward_pred": 0.024116983349599382, "train/reward_rate": 0.02962000229779412, "train_stats/sum_log_reward": 5.76666665181779, "train_stats/max_log_achievement_collect_coal": 0.008771929824561403, "train_stats/max_log_achievement_collect_drink": 7.421052631578948, "train_stats/max_log_achievement_collect_sapling": 2.3947368421052633, "train_stats/max_log_achievement_collect_stone": 0.37719298245614036, "train_stats/max_log_achievement_collect_wood": 7.385964912280702, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5175438596491229, "train_stats/max_log_achievement_eat_cow": 0.06140350877192982, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.7368421052631579, "train_stats/max_log_achievement_make_wood_sword": 0.017543859649122806, "train_stats/max_log_achievement_place_furnace": 0.008771929824561403, "train_stats/max_log_achievement_place_plant": 2.3596491228070176, "train_stats/max_log_achievement_place_stone": 0.07017543859649122, "train_stats/max_log_achievement_place_table": 2.6315789473684212, "train_stats/max_log_achievement_wake_up": 1.3157894736842106, "train_stats/mean_log_entropy": 0.5462750568985939, "eval_stats/sum_log_reward": 5.600000004284084, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.8125, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 6.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.4375, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.000156532070832327, "report/cont_loss_std": 0.00480633182451129, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.02603425458073616, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.011115379398689e-06, "report/cont_pred": 0.9942783117294312, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.9982328414917, "report/dyn_loss_std": 9.241588592529297, "report/image_loss_mean": 6.476860046386719, "report/image_loss_std": 10.736767768859863, "report/model_loss_mean": 14.92546558380127, "report/model_loss_std": 14.557827949523926, "report/post_ent_mag": 59.42418670654297, "report/post_ent_max": 59.42418670654297, "report/post_ent_mean": 42.95954132080078, "report/post_ent_min": 22.09557342529297, "report/post_ent_std": 7.742672443389893, "report/prior_ent_mag": 69.32196044921875, "report/prior_ent_max": 69.32196044921875, "report/prior_ent_mean": 57.33022689819336, "report/prior_ent_min": 41.89607620239258, "report/prior_ent_std": 4.837363243103027, "report/rep_loss_mean": 13.9982328414917, "report/rep_loss_std": 9.241588592529297, "report/reward_avg": 0.0302734375, "report/reward_loss_mean": 0.04950893297791481, "report/reward_loss_std": 0.26306548714637756, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0050537586212158, "report/reward_neg_acc": 0.9919109344482422, "report/reward_neg_loss": 0.0152363870292902, "report/reward_pos_acc": 0.9142857193946838, "report/reward_pos_loss": 1.0179531574249268, "report/reward_pred": 0.0269012413918972, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0008068124880082905, "eval/cont_loss_std": 0.025588901713490486, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003229579422622919, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.000802071241196245, "eval/cont_pred": 0.9975066184997559, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.96420669555664, "eval/dyn_loss_std": 11.73444652557373, "eval/image_loss_mean": 15.237292289733887, "eval/image_loss_std": 27.04935646057129, "eval/model_loss_mean": 26.118972778320312, "eval/model_loss_std": 31.4395809173584, "eval/post_ent_mag": 63.51585006713867, "eval/post_ent_max": 63.51585006713867, "eval/post_ent_mean": 41.908348083496094, "eval/post_ent_min": 21.505111694335938, "eval/post_ent_std": 8.02027702331543, "eval/prior_ent_mag": 69.32196044921875, "eval/prior_ent_max": 69.32196044921875, "eval/prior_ent_mean": 57.704288482666016, "eval/prior_ent_min": 43.093563079833984, "eval/prior_ent_std": 3.9996705055236816, "eval/rep_loss_mean": 17.96420669555664, "eval/rep_loss_std": 11.73444652557373, "eval/reward_avg": 0.03310547024011612, "eval/reward_loss_mean": 0.10235004127025604, "eval/reward_loss_std": 0.6878228187561035, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001147747039795, "eval/reward_neg_acc": 0.9898682236671448, "eval/reward_neg_loss": 0.026063017547130585, "eval/reward_pos_acc": 0.8108108043670654, "eval/reward_pos_loss": 2.137357711791992, "eval/reward_pred": 0.02403358183801174, "eval/reward_rate": 0.0361328125, "replay/size": 493289.0, "replay/inserts": 21768.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.3530101026081504e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.060411221840803e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4064.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2227752077297902e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.2642598152161, "timer/env.step_count": 2721.0, "timer/env.step_total": 260.4418408870697, "timer/env.step_frac": 0.26011299048578285, "timer/env.step_avg": 0.0957154872793347, "timer/env.step_min": 0.023735523223876953, "timer/env.step_max": 3.988319158554077, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.213006734848022, "timer/replay._sample_frac": 0.011198848480737133, "timer/replay._sample_avg": 0.0005153036183294128, "timer/replay._sample_min": 0.00040984153747558594, "timer/replay._sample_max": 0.025810718536376953, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3229.0, "timer/agent.policy_total": 55.740840673446655, "timer/agent.policy_frac": 0.05567045874955495, "timer/agent.policy_avg": 0.01726257066381129, "timer/agent.policy_min": 0.00949406623840332, "timer/agent.policy_max": 0.12012982368469238, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.15843820571899414, "timer/dataset_train_frac": 0.00015823815158271404, "timer/dataset_train_avg": 0.00011649868067573098, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0009326934814453125, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 610.4228448867798, "timer/agent.train_frac": 0.6096520862528676, "timer/agent.train_avg": 0.4488403271226322, "timer/agent.train_min": 0.43535947799682617, "timer/agent.train_max": 1.566418170928955, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4885373115539551, "timer/agent.report_frac": 0.0004879204533317857, "timer/agent.report_avg": 0.24426865577697754, "timer/agent.report_min": 0.23431015014648438, "timer/agent.report_max": 0.2542271614074707, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.143151484026234e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 21.740050411821336}
{"step": 494112, "time": 23359.46145915985, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 494152, "time": 23362.253545045853, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 494736, "time": 23383.799358844757, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 495008, "time": 23394.45748758316, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 495152, "time": 23400.90695285797, "episode/length": 322.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 495696, "time": 23420.80550813675, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 495704, "time": 23422.49409866333, "episode/length": 336.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 496000, "time": 23434.150555610657, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 496496, "time": 23452.647592782974, "episode/length": 292.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931740614334471, "episode/intrinsic_return": 0.0}
{"step": 496544, "time": 23455.929932832718, "episode/length": 303.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 496712, "time": 23462.93035006523, "episode/length": 212.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 496744, "time": 23465.615632534027, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 497184, "time": 23482.28640985489, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 497440, "time": 23492.875902175903, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 497576, "time": 23498.662371635437, "episode/length": 196.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 497712, "time": 23505.130047559738, "episode/length": 371.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 497952, "time": 23514.79507613182, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 498296, "time": 23527.796400785446, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 498376, "time": 23532.7982943058, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 498448, "time": 23536.896635055542, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 498648, "time": 23544.993525981903, "episode/length": 268.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 498880, "time": 23554.676802635193, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 499080, "time": 23562.939929246902, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 499248, "time": 23570.480192422867, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 499528, "time": 23581.237503290176, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 499776, "time": 23593.17406129837, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 499976, "time": 23601.382747411728, "episode/length": 136.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9562043795620438, "episode/intrinsic_return": 0.0}
{"step": 500000, "time": 23604.116688489914, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23622.637838840485, "eval_episode/length": 55.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 500032, "time": 23628.110383749008, "eval_episode/length": 143.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 500032, "time": 23631.30617761612, "eval_episode/length": 177.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 500032, "time": 23633.711651563644, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 500032, "time": 23636.172422647476, "eval_episode/length": 215.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 500032, "time": 23638.8088285923, "eval_episode/length": 238.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9790794979079498}
{"step": 500032, "time": 23642.775809526443, "eval_episode/length": 292.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9829351535836177}
{"step": 500032, "time": 23644.59282231331, "eval_episode/length": 239.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 500224, "time": 23651.140157461166, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 500384, "time": 23658.078610897064, "episode/length": 250.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 500832, "time": 23674.655764579773, "episode/length": 197.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 501024, "time": 23682.755706071854, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 501208, "time": 23690.46031332016, "episode/length": 178.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 501344, "time": 23697.409255504608, "episode/length": 39.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 501400, "time": 23700.71200609207, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 501408, "time": 23702.798892974854, "episode/length": 290.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 501568, "time": 23709.96994805336, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 501856, "time": 23721.18221259117, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 502448, "time": 23742.925248146057, "episode/length": 137.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 502512, "time": 23746.85115289688, "episode/length": 285.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 502592, "time": 23751.16403746605, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 502864, "time": 23762.33672809601, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 503064, "time": 23770.564884662628, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 503256, "time": 23778.528619766235, "episode/length": 174.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9828571428571429, "episode/intrinsic_return": 0.0}
{"step": 503480, "time": 23787.641991376877, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 503960, "time": 23805.417978286743, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 504048, "time": 23811.66725587845, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 504168, "time": 23817.612253904343, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 504576, "time": 23833.121363162994, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 504592, "time": 23835.185356140137, "episode/length": 166.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 504840, "time": 23844.92441034317, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 504944, "time": 23850.159737825394, "episode/length": 45.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 504976, "time": 23852.9332382679, "episode/length": 470.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787685774946921, "episode/intrinsic_return": 0.0}
{"step": 505032, "time": 23856.145599126816, "episode/length": 245.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 505304, "time": 23866.966229200363, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 505904, "time": 23888.945488214493, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 505912, "time": 23890.732639074326, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 506384, "time": 23908.286762714386, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 506400, "time": 23910.486693143845, "episode/length": 225.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 506488, "time": 23914.77640771866, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 506528, "time": 23917.942188978195, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 506792, "time": 23928.21033501625, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 507336, "time": 23948.066119670868, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 507472, "time": 23954.585893154144, "episode/length": 195.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 507928, "time": 23972.697515249252, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 508040, "time": 23978.108855724335, "episode/length": 399.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 508192, "time": 23985.147062301636, "episode/length": 223.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 508272, "time": 23989.432283878326, "episode/length": 235.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 508296, "time": 23991.816737413406, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 508672, "time": 24006.094581604004, "episode/length": 267.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 508984, "time": 24018.09449863434, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 509288, "time": 24029.948969602585, "episode/length": 126.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 509400, "time": 24035.393167495728, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 509552, "time": 24042.483664751053, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 509752, "time": 24050.54785513878, "episode/length": 213.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 24082.391861200333, "eval_episode/length": 177.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 510016, "time": 24084.8508477211, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675675675675676}
{"step": 510016, "time": 24086.864839553833, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 510016, "time": 24089.335995197296, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 510016, "time": 24091.43662405014, "eval_episode/length": 198.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.964824120603015}
{"step": 510016, "time": 24093.37739610672, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9660194174757282}
{"step": 510016, "time": 24097.32020163536, "eval_episode/length": 260.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9846743295019157}
{"step": 510016, "time": 24101.38246178627, "eval_episode/length": 50.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 510272, "time": 24109.997502565384, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 510488, "time": 24118.617634534836, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 510608, "time": 24124.433074235916, "episode/length": 391.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9923469387755102, "episode/intrinsic_return": 0.0}
{"step": 510616, "time": 24126.183695316315, "episode/length": 302.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 510776, "time": 24133.296875715256, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 510992, "time": 24142.351107358932, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 511072, "time": 24146.614066123962, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 511960, "time": 24177.89134645462, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 512072, "time": 24183.169327020645, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 512096, "time": 24185.993510484695, "episode/length": 200.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 512152, "time": 24189.247879981995, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 512584, "time": 24205.45756983757, "episode/length": 411.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 512696, "time": 24210.803020238876, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 512784, "time": 24215.60738682747, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 513320, "time": 24235.05260181427, "episode/length": 317.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 513616, "time": 24246.804092407227, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 513680, "time": 24250.631547927856, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 513944, "time": 24260.833840847015, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 514088, "time": 24267.358605623245, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 514224, "time": 24273.710344076157, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 514312, "time": 24277.876544475555, "episode/length": 276.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 514936, "time": 24300.449820041656, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 515248, "time": 24312.75987315178, "episode/length": 162.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 515336, "time": 24317.12948012352, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 515432, "time": 24321.93723154068, "episode/length": 167.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 515512, "time": 24326.310741186142, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 515728, "time": 24335.286866426468, "episode/length": 255.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 516041, "time": 24348.18727350235, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.796054757756295, "train/action_min": 0.0, "train/action_std": 3.4930797703832175, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04811054527116337, "train/actor_opt_grad_steps": 31460.0, "train/actor_opt_loss": -2.5312404685097634, "train/adv_mag": 0.729102111977639, "train/adv_max": 0.7071252135064104, "train/adv_mean": 0.004073296726189563, "train/adv_min": -0.5063240727503523, "train/adv_std": 0.07254505647922592, "train/cont_avg": 0.9947869829136691, "train/cont_loss_mean": 0.00019170314054396166, "train/cont_loss_std": 0.005725305897860001, "train/cont_neg_acc": 0.9880749952021263, "train/cont_neg_loss": 0.029219479851706625, "train/cont_pos_acc": 0.999978800471738, "train/cont_pos_loss": 6.306018656457402e-05, "train/cont_pred": 0.9948111931197077, "train/cont_rate": 0.9947869829136691, "train/dyn_loss_mean": 14.111344227687917, "train/dyn_loss_std": 9.289132996428785, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7910857607992433, "train/extr_critic_critic_opt_grad_steps": 31460.0, "train/extr_critic_critic_opt_loss": 15563.603501573742, "train/extr_critic_mag": 5.1816852967516125, "train/extr_critic_max": 5.1816852967516125, "train/extr_critic_mean": 0.8579926741637772, "train/extr_critic_min": -0.3006532243687472, "train/extr_critic_std": 1.095026638010423, "train/extr_return_normed_mag": 1.8458832596703398, "train/extr_return_normed_max": 1.8458832596703398, "train/extr_return_normed_mean": 0.29096575274313097, "train/extr_return_normed_min": -0.15684522098774534, "train/extr_return_normed_std": 0.3329603562680937, "train/extr_return_rate": 0.43229449995987707, "train/extr_return_raw_mag": 6.147743420635196, "train/extr_return_raw_max": 6.147743420635196, "train/extr_return_raw_mean": 0.8718096549562413, "train/extr_return_raw_min": -0.6478686527811366, "train/extr_return_raw_std": 1.1298550959113691, "train/extr_reward_mag": 1.0225205009789775, "train/extr_reward_max": 1.0225205009789775, "train/extr_reward_mean": 0.02554095149201026, "train/extr_reward_min": -0.4074966916077429, "train/extr_reward_std": 0.1509639826073921, "train/image_loss_mean": 6.880153518786534, "train/image_loss_std": 11.19213665818139, "train/model_loss_mean": 15.400223512443707, "train/model_loss_std": 14.96624362039909, "train/model_opt_grad_norm": 62.69943478810701, "train/model_opt_grad_steps": 31430.273381294963, "train/model_opt_loss": 12324.319694244605, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 800.3597122302158, "train/policy_entropy_mag": 2.485408589136686, "train/policy_entropy_max": 2.485408589136686, "train/policy_entropy_mean": 0.5875882750792469, "train/policy_entropy_min": 0.07937507047284421, "train/policy_entropy_std": 0.6127891420460433, "train/policy_logprob_mag": 7.438383606698015, "train/policy_logprob_max": -0.009455660967786106, "train/policy_logprob_mean": -0.5871811416938151, "train/policy_logprob_min": -7.438383606698015, "train/policy_logprob_std": 1.1286523402166024, "train/policy_randomness_mag": 0.8772401642456329, "train/policy_randomness_max": 0.8772401642456329, "train/policy_randomness_mean": 0.20739287620396923, "train/policy_randomness_min": 0.028015916631054537, "train/policy_randomness_std": 0.2162876758429644, "train/post_ent_mag": 59.935407048506704, "train/post_ent_max": 59.935407048506704, "train/post_ent_mean": 42.99537472073123, "train/post_ent_min": 21.497364455847432, "train/post_ent_std": 7.5174551353180155, "train/prior_ent_mag": 69.76726120324443, "train/prior_ent_max": 69.76726120324443, "train/prior_ent_mean": 57.15102726778538, "train/prior_ent_min": 41.445323587321546, "train/prior_ent_std": 4.544147925411197, "train/rep_loss_mean": 14.111344227687917, "train/rep_loss_std": 9.289132996428785, "train/reward_avg": 0.023793699219822884, "train/reward_loss_mean": 0.05307184249537883, "train/reward_loss_std": 0.24315231770491427, "train/reward_max_data": 1.0201438896947628, "train/reward_max_pred": 1.0111089524605292, "train/reward_neg_acc": 0.9925824155052789, "train/reward_neg_loss": 0.02948481480343093, "train/reward_pos_acc": 0.9665086337988326, "train/reward_pos_loss": 0.8605349840020105, "train/reward_pred": 0.023179537576469157, "train/reward_rate": 0.02853810701438849, "train_stats/sum_log_reward": 6.305882372108161, "train_stats/max_log_achievement_collect_coal": 0.00980392156862745, "train_stats/max_log_achievement_collect_drink": 9.303921568627452, "train_stats/max_log_achievement_collect_sapling": 2.8137254901960786, "train_stats/max_log_achievement_collect_stone": 0.9705882352941176, "train_stats/max_log_achievement_collect_wood": 7.980392156862745, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5196078431372549, "train_stats/max_log_achievement_eat_cow": 0.09803921568627451, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0686274509803921, "train_stats/max_log_achievement_make_wood_sword": 0.0392156862745098, "train_stats/max_log_achievement_place_furnace": 0.00980392156862745, "train_stats/max_log_achievement_place_plant": 2.5980392156862746, "train_stats/max_log_achievement_place_stone": 0.20588235294117646, "train_stats/max_log_achievement_place_table": 2.7450980392156863, "train_stats/max_log_achievement_wake_up": 1.4509803921568627, "train_stats/mean_log_entropy": 0.5712604399989633, "eval_stats/sum_log_reward": 5.850000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 0.875, "eval_stats/max_log_achievement_collect_wood": 8.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0001242527214344591, "report/cont_loss_std": 0.0025570434518158436, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0055374158546328545, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.699396857991815e-05, "report/cont_pred": 0.9931185245513916, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.910832405090332, "report/dyn_loss_std": 9.921276092529297, "report/image_loss_mean": 7.666585922241211, "report/image_loss_std": 12.802377700805664, "report/model_loss_mean": 16.675596237182617, "report/model_loss_std": 17.007408142089844, "report/post_ent_mag": 59.68952178955078, "report/post_ent_max": 59.68952178955078, "report/post_ent_mean": 42.834354400634766, "report/post_ent_min": 21.238983154296875, "report/post_ent_std": 7.686766624450684, "report/prior_ent_mag": 69.81975555419922, "report/prior_ent_max": 69.81975555419922, "report/prior_ent_mean": 57.74064636230469, "report/prior_ent_min": 41.505104064941406, "report/prior_ent_std": 4.552280426025391, "report/rep_loss_mean": 14.910832405090332, "report/rep_loss_std": 9.921276092529297, "report/reward_avg": 0.03261718899011612, "report/reward_loss_mean": 0.06238660588860512, "report/reward_loss_std": 0.27583175897598267, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0021553039550781, "report/reward_neg_acc": 0.9939086437225342, "report/reward_neg_loss": 0.027849959209561348, "report/reward_pos_acc": 0.9487179517745972, "report/reward_pos_loss": 0.9346583485603333, "report/reward_pred": 0.03043011575937271, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.142169432772789e-05, "eval/cont_loss_std": 0.00037545087980106473, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006243094801902771, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.1405811569129582e-06, "eval/cont_pred": 0.9970855116844177, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.919822692871094, "eval/dyn_loss_std": 11.029308319091797, "eval/image_loss_mean": 14.040613174438477, "eval/image_loss_std": 24.12628746032715, "eval/model_loss_mean": 24.8978271484375, "eval/model_loss_std": 28.3510799407959, "eval/post_ent_mag": 57.69730758666992, "eval/post_ent_max": 57.69730758666992, "eval/post_ent_mean": 42.01972961425781, "eval/post_ent_min": 22.690446853637695, "eval/post_ent_std": 7.519982814788818, "eval/prior_ent_mag": 69.81975555419922, "eval/prior_ent_max": 69.81975555419922, "eval/prior_ent_mean": 57.40089416503906, "eval/prior_ent_min": 42.63596725463867, "eval/prior_ent_std": 4.2180705070495605, "eval/rep_loss_mean": 17.919822692871094, "eval/rep_loss_std": 11.029308319091797, "eval/reward_avg": 0.03935547173023224, "eval/reward_loss_mean": 0.10530130565166473, "eval/reward_loss_std": 0.6510258316993713, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022938251495361, "eval/reward_neg_acc": 0.9959225058555603, "eval/reward_neg_loss": 0.025095580145716667, "eval/reward_pos_acc": 0.7674418687820435, "eval/reward_pos_loss": 1.9351109266281128, "eval/reward_pred": 0.028705956414341927, "eval/reward_rate": 0.0419921875, "replay/size": 515537.0, "replay/inserts": 22248.0, "replay/samples": 22256.0, "replay/insert_wait_avg": 1.3229294845158571e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.005688271704207e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1465071063292653e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0190665721893, "timer/env.step_count": 2781.0, "timer/env.step_total": 243.10957384109497, "timer/env.step_frac": 0.24310493866323238, "timer/env.step_avg": 0.087418041654475, "timer/env.step_min": 0.02376723289489746, "timer/env.step_max": 2.26194167137146, "timer/replay._sample_count": 22256.0, "timer/replay._sample_total": 11.1914803981781, "timer/replay._sample_frac": 0.011191267019077591, "timer/replay._sample_avg": 0.0005028522824486925, "timer/replay._sample_min": 0.0004191398620605469, "timer/replay._sample_max": 0.010728836059570312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3389.0, "timer/agent.policy_total": 57.54969835281372, "timer/agent.policy_frac": 0.057548601098256484, "timer/agent.policy_avg": 0.016981321437832316, "timer/agent.policy_min": 0.009631633758544922, "timer/agent.policy_max": 0.14912128448486328, "timer/dataset_train_count": 1391.0, "timer/dataset_train_total": 0.15813827514648438, "timer/dataset_train_frac": 0.00015813526004913297, "timer/dataset_train_avg": 0.00011368675423902542, "timer/dataset_train_min": 9.965896606445312e-05, "timer/dataset_train_max": 0.00028967857360839844, "timer/agent.train_count": 1391.0, "timer/agent.train_total": 626.3776173591614, "timer/agent.train_frac": 0.6263656747128076, "timer/agent.train_avg": 0.4503074172244151, "timer/agent.train_min": 0.4373815059661865, "timer/agent.train_max": 1.8962852954864502, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48393893241882324, "timer/agent.report_frac": 0.00048392970553815803, "timer/agent.report_avg": 0.24196946620941162, "timer/agent.report_min": 0.23543095588684082, "timer/agent.report_max": 0.24850797653198242, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.099382433721398e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 22.247277784980962}
{"step": 516160, "time": 24353.797415733337, "episode/length": 432.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9976905311778291, "episode/intrinsic_return": 0.0}
{"step": 516872, "time": 24379.495264053345, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 516968, "time": 24384.248599529266, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 517072, "time": 24389.66380429268, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 517192, "time": 24395.31786775589, "episode/length": 219.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 517208, "time": 24397.433926343918, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 517232, "time": 24400.318126916885, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 517392, "time": 24407.221891880035, "episode/length": 395.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974747474747475, "episode/intrinsic_return": 0.0}
{"step": 517656, "time": 24417.43949985504, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 518088, "time": 24433.53169155121, "episode/length": 393.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 518592, "time": 24452.347034454346, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 518680, "time": 24456.71084046364, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 518712, "time": 24459.390203475952, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 519056, "time": 24472.913023471832, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 519168, "time": 24478.207941293716, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 519248, "time": 24482.51548743248, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24530.84010195732, "eval_episode/length": 145.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.952054794520548}
{"step": 520000, "time": 24533.33575773239, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 520000, "time": 24535.441690683365, "eval_episode/length": 169.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 520000, "time": 24537.232269763947, "eval_episode/length": 173.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9597701149425287}
{"step": 520000, "time": 24541.01298069954, "eval_episode/length": 222.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 520000, "time": 24547.56279182434, "eval_episode/length": 329.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.990909090909091}
{"step": 520000, "time": 24550.471540927887, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 520000, "time": 24552.432957410812, "eval_episode/length": 354.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9915492957746479}
{"step": 520016, "time": 24552.98426604271, "episode/length": 162.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 520224, "time": 24561.42257452011, "episode/length": 406.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 520240, "time": 24564.429493665695, "episode/length": 194.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 520480, "time": 24574.18768119812, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 520504, "time": 24576.284683704376, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 520720, "time": 24585.366594076157, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 520752, "time": 24588.254576921463, "episode/length": 269.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 521264, "time": 24606.995574474335, "episode/length": 396.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773299748110831, "episode/intrinsic_return": 0.0}
{"step": 521640, "time": 24621.016288995743, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 521680, "time": 24624.08166575432, "episode/length": 181.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 521848, "time": 24631.006634950638, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 521912, "time": 24634.74902486801, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 522208, "time": 24646.68249487877, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 522416, "time": 24655.27760076523, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 522624, "time": 24663.784710884094, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 522680, "time": 24667.09564423561, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 523104, "time": 24683.135367155075, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 523128, "time": 24685.24139380455, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 523312, "time": 24693.195038557053, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 523488, "time": 24700.81596183777, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 523624, "time": 24706.81969857216, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 524088, "time": 24723.937379837036, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 524232, "time": 24730.563071727753, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 524304, "time": 24736.469441652298, "episode/length": 235.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 524328, "time": 24738.568538427353, "episode/length": 152.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 524568, "time": 24748.194683790207, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 524688, "time": 24753.98547577858, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.958974358974359, "episode/intrinsic_return": 0.0}
{"step": 525152, "time": 24771.250492334366, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 525264, "time": 24776.603234291077, "episode/length": 71.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9305555555555556, "episode/intrinsic_return": 0.0}
{"step": 525304, "time": 24779.87848854065, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 525544, "time": 24789.65770792961, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 525840, "time": 24801.54021048546, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 525848, "time": 24803.166281700134, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 525864, "time": 24805.349883556366, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 525976, "time": 24810.75564455986, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 526424, "time": 24827.58554816246, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 526432, "time": 24829.68602180481, "episode/length": 70.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 526512, "time": 24834.010909080505, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 526896, "time": 24848.47095298767, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 526920, "time": 24850.809566020966, "episode/length": 171.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 527128, "time": 24859.39916229248, "episode/length": 87.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 527272, "time": 24865.877962350845, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 527432, "time": 24872.767882347107, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 527616, "time": 24880.820822000504, "episode/length": 220.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 527936, "time": 24893.224936008453, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 528016, "time": 24897.49301815033, "episode/length": 49.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 528176, "time": 24904.438464403152, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 528608, "time": 24920.73820567131, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 528640, "time": 24923.467395305634, "episode/length": 214.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 528888, "time": 24933.27637219429, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 529024, "time": 24939.680310726166, "episode/length": 265.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 529144, "time": 24945.13910841942, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 529616, "time": 24962.918518066406, "episode/length": 209.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 529672, "time": 24966.128087997437, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 529992, "time": 24978.586540460587, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24998.237050056458, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 530088, "time": 25006.27636861801, "eval_episode/length": 177.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 530088, "time": 25007.99329519272, "eval_episode/length": 182.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 530088, "time": 25010.085399866104, "eval_episode/length": 194.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 530088, "time": 25011.922585964203, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 530088, "time": 25014.682290554047, "eval_episode/length": 226.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973568281938326}
{"step": 530088, "time": 25017.097323656082, "eval_episode/length": 244.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9836734693877551}
{"step": 530088, "time": 25021.259027957916, "eval_episode/length": 301.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9867549668874173}
{"step": 530128, "time": 25022.834710121155, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 530432, "time": 25034.783847808838, "episode/length": 54.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 530464, "time": 25037.299561023712, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 530744, "time": 25048.1135969162, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 531152, "time": 25063.7164978981, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 531248, "time": 25068.645748138428, "episode/length": 262.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 531384, "time": 25075.10057401657, "episode/length": 294.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 531496, "time": 25080.28094291687, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 531704, "time": 25088.95738363266, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 531824, "time": 25094.91004037857, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 532208, "time": 25109.284116268158, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 532368, "time": 25116.351449728012, "episode/length": 108.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 532472, "time": 25121.356742858887, "episode/length": 254.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 532920, "time": 25139.370054244995, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 532992, "time": 25143.57873249054, "episode/length": 217.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9862385321100917, "episode/intrinsic_return": 0.0}
{"step": 533048, "time": 25146.88358259201, "episode/length": 207.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 533216, "time": 25154.348989009857, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 533392, "time": 25161.845766544342, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 533704, "time": 25173.704282283783, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 533768, "time": 25177.436385154724, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 533768, "time": 25177.445828914642, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 534280, "time": 25198.05969619751, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 534280, "time": 25198.071045398712, "episode/length": 321.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 534824, "time": 25219.85099172592, "episode/length": 131.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 534832, "time": 25221.992777347565, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 535088, "time": 25232.351299762726, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 535224, "time": 25238.3344540596, "episode/length": 287.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 535296, "time": 25242.80391383171, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 535760, "time": 25259.893226146698, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 535848, "time": 25264.23099374771, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 536048, "time": 25272.912273406982, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 536288, "time": 25282.456845521927, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 536624, "time": 25295.31002521515, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9518072289156626, "episode/intrinsic_return": 0.0}
{"step": 536792, "time": 25302.493298768997, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 536912, "time": 25308.367308855057, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 537000, "time": 25312.725661039352, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 537144, "time": 25319.24696779251, "episode/length": 136.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 537728, "time": 25340.74521803856, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 537800, "time": 25344.518886327744, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 537833, "time": 25348.419921398163, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.6990212833180145, "train/action_min": 0.0, "train/action_std": 3.441462592167013, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04715328669065938, "train/actor_opt_grad_steps": 32835.0, "train/actor_opt_loss": -1.1783950164475863, "train/adv_mag": 0.7114552796325263, "train/adv_max": 0.702814360094421, "train/adv_mean": 0.004237264229096675, "train/adv_min": -0.46597444441388636, "train/adv_std": 0.07097129677148427, "train/cont_avg": 0.9945355583639706, "train/cont_loss_mean": 0.00034292248206720355, "train/cont_loss_std": 0.010391039348398343, "train/cont_neg_acc": 0.9935682234940706, "train/cont_neg_loss": 0.02396334479244952, "train/cont_pos_acc": 0.9999421913834179, "train/cont_pos_loss": 0.0001915250833240629, "train/cont_pred": 0.9945137947797775, "train/cont_rate": 0.9945355583639706, "train/dyn_loss_mean": 14.056383792091818, "train/dyn_loss_std": 9.315368561183705, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.7934006684843231, "train/extr_critic_critic_opt_grad_steps": 32835.0, "train/extr_critic_critic_opt_loss": 15554.542839499081, "train/extr_critic_mag": 5.35512714175617, "train/extr_critic_max": 5.35512714175617, "train/extr_critic_mean": 0.9290775071610423, "train/extr_critic_min": -0.29759882302845225, "train/extr_critic_std": 1.127310714300941, "train/extr_return_normed_mag": 1.821844583925079, "train/extr_return_normed_max": 1.821844583925079, "train/extr_return_normed_mean": 0.2990884730482803, "train/extr_return_normed_min": -0.15498340091503718, "train/extr_return_normed_std": 0.3350093428264646, "train/extr_return_rate": 0.4563548598876771, "train/extr_return_raw_mag": 6.2165509637664345, "train/extr_return_raw_max": 6.2165509637664345, "train/extr_return_raw_mean": 0.9437111361938364, "train/extr_return_raw_min": -0.6300280565286384, "train/extr_return_raw_std": 1.160839716301245, "train/extr_reward_mag": 1.0176843159339006, "train/extr_reward_max": 1.0176843159339006, "train/extr_reward_mean": 0.026099632596870995, "train/extr_reward_min": -0.3867749966242734, "train/extr_reward_std": 0.1526577634846463, "train/image_loss_mean": 6.813083129770615, "train/image_loss_std": 11.303880077951094, "train/model_loss_mean": 15.302014203632579, "train/model_loss_std": 15.074353316250969, "train/model_opt_grad_norm": 62.518301374772015, "train/model_opt_grad_steps": 32804.73529411765, "train/model_opt_loss": 19278.01502900965, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.1911764705883, "train/policy_entropy_mag": 2.4859753759468304, "train/policy_entropy_max": 2.4859753759468304, "train/policy_entropy_mean": 0.5643146467559478, "train/policy_entropy_min": 0.07937504931846086, "train/policy_entropy_std": 0.594709096586003, "train/policy_logprob_mag": 7.438383645871106, "train/policy_logprob_max": -0.009455658433794537, "train/policy_logprob_mean": -0.5643930744160625, "train/policy_logprob_min": -7.438383645871106, "train/policy_logprob_std": 1.1141867471091889, "train/policy_randomness_mag": 0.8774402124040267, "train/policy_randomness_max": 0.8774402124040267, "train/policy_randomness_mean": 0.1991783050710664, "train/policy_randomness_min": 0.02801590905908276, "train/policy_randomness_std": 0.20990621276638088, "train/post_ent_mag": 60.193733159233545, "train/post_ent_max": 60.193733159233545, "train/post_ent_mean": 43.22245454788208, "train/post_ent_min": 21.316069392596972, "train/post_ent_std": 7.541937088265138, "train/prior_ent_mag": 70.04639479693245, "train/prior_ent_max": 70.04639479693245, "train/prior_ent_mean": 57.345848083496094, "train/prior_ent_min": 42.21366273655611, "train/prior_ent_std": 4.453654529417262, "train/rep_loss_mean": 14.056383792091818, "train/rep_loss_std": 9.315368561183705, "train/reward_avg": 0.024558392551946726, "train/reward_loss_mean": 0.054757926010471934, "train/reward_loss_std": 0.250856482588193, "train/reward_max_data": 1.0198529459097807, "train/reward_max_pred": 1.011486795018701, "train/reward_neg_acc": 0.9927702984389137, "train/reward_neg_loss": 0.03033457279397065, "train/reward_pos_acc": 0.9656760626856018, "train/reward_pos_loss": 0.8623548987157205, "train/reward_pred": 0.024034132475636023, "train/reward_rate": 0.029411764705882353, "train_stats/sum_log_reward": 6.345454554124312, "train_stats/max_log_achievement_collect_coal": 0.02727272727272727, "train_stats/max_log_achievement_collect_drink": 8.572727272727272, "train_stats/max_log_achievement_collect_sapling": 2.6818181818181817, "train_stats/max_log_achievement_collect_stone": 0.6818181818181818, "train_stats/max_log_achievement_collect_wood": 7.8090909090909095, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5636363636363636, "train_stats/max_log_achievement_eat_cow": 0.045454545454545456, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1181818181818182, "train_stats/max_log_achievement_make_wood_sword": 0.045454545454545456, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.6454545454545455, "train_stats/max_log_achievement_place_stone": 0.09090909090909091, "train_stats/max_log_achievement_place_table": 2.4272727272727272, "train_stats/max_log_achievement_wake_up": 1.4363636363636363, "train_stats/mean_log_entropy": 0.5344519970091907, "eval_stats/sum_log_reward": 6.912500023841858, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.875, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_stone": 3.0625, "eval_stats/max_log_achievement_collect_wood": 6.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.75, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.875, "eval_stats/max_log_achievement_place_stone": 0.25, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.779498224001145e-06, "report/cont_loss_std": 0.00014359485066961497, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000888923357706517, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.4461121509157238e-06, "report/cont_pred": 0.995120108127594, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 12.9759521484375, "report/dyn_loss_std": 9.300557136535645, "report/image_loss_mean": 5.498210430145264, "report/image_loss_std": 11.371599197387695, "report/model_loss_mean": 13.334540367126465, "report/model_loss_std": 15.282350540161133, "report/post_ent_mag": 60.713951110839844, "report/post_ent_max": 60.713951110839844, "report/post_ent_mean": 43.959800720214844, "report/post_ent_min": 21.441688537597656, "report/post_ent_std": 7.30416202545166, "report/prior_ent_mag": 69.28758239746094, "report/prior_ent_max": 69.28758239746094, "report/prior_ent_mean": 56.821556091308594, "report/prior_ent_min": 40.45636749267578, "report/prior_ent_std": 4.8397650718688965, "report/rep_loss_mean": 12.9759521484375, "report/rep_loss_std": 9.300557136535645, "report/reward_avg": 0.02656250074505806, "report/reward_loss_mean": 0.05075257644057274, "report/reward_loss_std": 0.20267193019390106, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9984811544418335, "report/reward_neg_acc": 0.9939515590667725, "report/reward_neg_loss": 0.02527412585914135, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.8405844569206238, "report/reward_pred": 0.025761108845472336, "report/reward_rate": 0.03125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.5544100051556597e-07, "eval/cont_loss_std": 2.4907658371375874e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.5565688954666257e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.252839609833245e-07, "eval/cont_pred": 0.998046875, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.19173812866211, "eval/dyn_loss_std": 10.736976623535156, "eval/image_loss_mean": 10.19913101196289, "eval/image_loss_std": 14.802034378051758, "eval/model_loss_mean": 21.207820892333984, "eval/model_loss_std": 19.34501838684082, "eval/post_ent_mag": 58.891319274902344, "eval/post_ent_max": 58.891319274902344, "eval/post_ent_mean": 41.92639923095703, "eval/post_ent_min": 21.727020263671875, "eval/post_ent_std": 7.686140537261963, "eval/prior_ent_mag": 69.28758239746094, "eval/prior_ent_max": 69.28758239746094, "eval/prior_ent_mean": 57.94171142578125, "eval/prior_ent_min": 41.041748046875, "eval/prior_ent_std": 4.181718349456787, "eval/rep_loss_mean": 18.19173812866211, "eval/rep_loss_std": 10.736976623535156, "eval/reward_avg": 0.02167968824505806, "eval/reward_loss_mean": 0.09364597499370575, "eval/reward_loss_std": 0.6390071511268616, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9993971586227417, "eval/reward_neg_acc": 0.9920000433921814, "eval/reward_neg_loss": 0.06050059199333191, "eval/reward_pos_acc": 0.7916666865348816, "eval/reward_pos_loss": 1.474703311920166, "eval/reward_pred": 0.02085094340145588, "eval/reward_rate": 0.0234375, "replay/size": 537329.0, "replay/inserts": 21792.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.3468592877605062e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.053106891951372e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.152175020772391e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2195715904236, "timer/env.step_count": 2724.0, "timer/env.step_total": 252.88966012001038, "timer/env.step_frac": 0.25283414492469586, "timer/env.step_avg": 0.09283761384728721, "timer/env.step_min": 0.023801088333129883, "timer/env.step_max": 3.499717950820923, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.133274555206299, "timer/replay._sample_frac": 0.011130830541041668, "timer/replay._sample_avg": 0.0005108881495597604, "timer/replay._sample_min": 0.0003838539123535156, "timer/replay._sample_max": 0.011254549026489258, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3381.0, "timer/agent.policy_total": 59.4346239566803, "timer/agent.policy_frac": 0.05942157666658614, "timer/agent.policy_avg": 0.017579007381449362, "timer/agent.policy_min": 0.009584665298461914, "timer/agent.policy_max": 0.1267108917236328, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.15653014183044434, "timer/dataset_train_frac": 0.00015649577980317837, "timer/dataset_train_avg": 0.00011492668269489305, "timer/dataset_train_min": 9.989738464355469e-05, "timer/dataset_train_max": 0.0005204677581787109, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 613.2880499362946, "timer/agent.train_frac": 0.6131534188649407, "timer/agent.train_avg": 0.4502849118474997, "timer/agent.train_min": 0.43448472023010254, "timer/agent.train_max": 1.6051688194274902, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.482252836227417, "timer/agent.report_frac": 0.0004821469704502973, "timer/agent.report_avg": 0.2411264181137085, "timer/agent.report_min": 0.23414850234985352, "timer/agent.report_max": 0.24810433387756348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.581710815429688e-05, "timer/dataset_eval_frac": 7.580046452574612e-08, "timer/dataset_eval_avg": 7.581710815429688e-05, "timer/dataset_eval_min": 7.581710815429688e-05, "timer/dataset_eval_max": 7.581710815429688e-05, "fps": 21.786927037076246}
{"step": 538128, "time": 25358.61719608307, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 538280, "time": 25365.33759212494, "episode/length": 398.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 538288, "time": 25367.452221393585, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 538296, "time": 25368.951775312424, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 538632, "time": 25381.846223592758, "episode/length": 214.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 538856, "time": 25391.090638637543, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 539240, "time": 25405.505353450775, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 539376, "time": 25411.95570731163, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 539384, "time": 25413.51819586754, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 539768, "time": 25428.017122268677, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 539984, "time": 25437.155435323715, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 25462.08242869377, "eval_episode/length": 163.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9817073170731707}
{"step": 540072, "time": 25464.642791986465, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 540072, "time": 25466.227103233337, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.978494623655914}
{"step": 540072, "time": 25467.892442703247, "eval_episode/length": 187.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 540072, "time": 25470.972645044327, "eval_episode/length": 221.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 540072, "time": 25472.708357810974, "eval_episode/length": 224.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9733333333333334}
{"step": 540072, "time": 25475.94060230255, "eval_episode/length": 262.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 540072, "time": 25478.17558336258, "eval_episode/length": 277.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9856115107913669}
{"step": 540288, "time": 25485.764357328415, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 540552, "time": 25495.94150710106, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 540880, "time": 25510.252301692963, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 540904, "time": 25512.464846134186, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 541216, "time": 25524.799215078354, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 541232, "time": 25528.574736356735, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 541688, "time": 25545.88626217842, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 541840, "time": 25552.851432323456, "episode/length": 372.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9865951742627346, "episode/intrinsic_return": 0.0}
{"step": 542008, "time": 25559.883631706238, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 542104, "time": 25564.70235657692, "episode/length": 477.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9916317991631799, "episode/intrinsic_return": 0.0}
{"step": 542728, "time": 25587.316334962845, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 542816, "time": 25592.086126327515, "episode/length": 140.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 543032, "time": 25600.837598323822, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 543248, "time": 25610.027339935303, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 543376, "time": 25616.04572916031, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 543504, "time": 25621.911472320557, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 543656, "time": 25628.3347799778, "episode/length": 205.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 544432, "time": 25656.2877471447, "episode/length": 201.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 544448, "time": 25658.59894180298, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 544480, "time": 25661.38082051277, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 544528, "time": 25664.921802520752, "episode/length": 224.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 544592, "time": 25669.363528728485, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 544712, "time": 25674.911668777466, "episode/length": 325.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 545280, "time": 25696.09971833229, "episode/length": 202.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 545696, "time": 25711.66358113289, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 545760, "time": 25715.42109966278, "episode/length": 163.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 545784, "time": 25717.6711666584, "episode/length": 168.0, "episode/score": 8.100000038743019, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 545824, "time": 25720.873127937317, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 545944, "time": 25726.259027957916, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 546176, "time": 25735.799663305283, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 546624, "time": 25752.459869384766, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 546896, "time": 25763.153035640717, "episode/length": 439.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 547192, "time": 25774.511285066605, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 547368, "time": 25782.231166362762, "episode/length": 177.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 547608, "time": 25792.045481204987, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 547720, "time": 25797.46409368515, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 548232, "time": 25816.833062171936, "episode/length": 308.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 548296, "time": 25820.607971668243, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 548392, "time": 25825.361572504044, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 548648, "time": 25835.619215011597, "episode/length": 368.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.986449864498645, "episode/intrinsic_return": 0.0}
{"step": 548664, "time": 25837.736886262894, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 548760, "time": 25842.714534282684, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 548792, "time": 25845.344724178314, "episode/length": 61.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9354838709677419, "episode/intrinsic_return": 0.0}
{"step": 549112, "time": 25859.143328905106, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 549552, "time": 25875.881192922592, "episode/length": 242.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 549992, "time": 25892.041796207428, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 25910.79626584053, "eval_episode/length": 40.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.975609756097561}
{"step": 550056, "time": 25915.620147943497, "eval_episode/length": 112.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9557522123893806}
{"step": 550056, "time": 25921.168775320053, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 550056, "time": 25924.039234399796, "eval_episode/length": 187.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 550056, "time": 25927.764971733093, "eval_episode/length": 232.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9785407725321889}
{"step": 550056, "time": 25927.77401614189, "eval_episode/length": 232.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 550056, "time": 25931.851550102234, "eval_episode/length": 202.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 550056, "time": 25935.29163980484, "eval_episode/length": 284.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 550176, "time": 25939.55448126793, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 550560, "time": 25953.9653737545, "episode/length": 238.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 550584, "time": 25956.24798154831, "episode/length": 273.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 550592, "time": 25958.394958257675, "episode/length": 184.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 551344, "time": 25985.37792468071, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 551424, "time": 25989.959572315216, "episode/length": 398.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949874686716792, "episode/intrinsic_return": 0.0}
{"step": 551728, "time": 26001.84156370163, "episode/length": 142.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 551760, "time": 26004.542853355408, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 551904, "time": 26010.933936834335, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 552112, "time": 26019.784136533737, "episode/length": 319.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 552232, "time": 26025.283353805542, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 552760, "time": 26044.620089530945, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 553008, "time": 26054.83251810074, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 553064, "time": 26058.13212966919, "episode/length": 383.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 553064, "time": 26058.141404151917, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 553136, "time": 26064.10260438919, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 553392, "time": 26074.39711380005, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 553552, "time": 26081.442894935608, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 553816, "time": 26091.70333957672, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 554264, "time": 26108.513025522232, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 554656, "time": 26123.65789747238, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 554880, "time": 26132.83441233635, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 554984, "time": 26137.697804927826, "episode/length": 246.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 555184, "time": 26146.41738128662, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 555328, "time": 26152.985654592514, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 555544, "time": 26161.62569832802, "episode/length": 309.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 555824, "time": 26172.947178840637, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 556224, "time": 26188.012182474136, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 556352, "time": 26193.992929458618, "episode/length": 260.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 556552, "time": 26202.16700577736, "episode/length": 195.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 556840, "time": 26213.473868608475, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 557160, "time": 26228.034065246582, "episode/length": 201.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 557472, "time": 26240.60842037201, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 557536, "time": 26244.365732192993, "episode/length": 293.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 557912, "time": 26258.46915102005, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 558160, "time": 26268.684938192368, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 558672, "time": 26287.4322180748, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 558680, "time": 26289.006412029266, "episode/length": 418.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 559192, "time": 26308.003862142563, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 559480, "time": 26319.3469953537, "episode/length": 390.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948849104859335, "episode/intrinsic_return": 0.0}
{"step": 559800, "time": 26331.81178188324, "episode/length": 235.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 559904, "time": 26337.083909749985, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 559968, "time": 26340.83668613434, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 560016, "time": 26344.098160028458, "episode/length": 309.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 26361.631179094315, "eval_episode/length": 48.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 560040, "time": 26363.96847319603, "eval_episode/length": 65.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 560040, "time": 26369.78215956688, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 560040, "time": 26371.416768074036, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 560040, "time": 26374.57164812088, "eval_episode/length": 197.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 560040, "time": 26376.510024547577, "eval_episode/length": 203.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 560040, "time": 26379.843117952347, "eval_episode/length": 189.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9842105263157894}
{"step": 560040, "time": 26382.63720560074, "eval_episode/length": 260.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9885057471264368}
{"step": 560041, "time": 26383.682990550995, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.64291447701214, "train/action_min": 0.0, "train/action_std": 3.376799290128749, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.048571843412711466, "train/actor_opt_grad_steps": 34210.0, "train/actor_opt_loss": -3.0132063041447843, "train/adv_mag": 0.7061063527203292, "train/adv_max": 0.6957291776327779, "train/adv_mean": 0.0046334557311455285, "train/adv_min": -0.47428819194114463, "train/adv_std": 0.07204599080861901, "train/cont_avg": 0.9946815984712231, "train/cont_loss_mean": 0.00019067282711675363, "train/cont_loss_std": 0.005721178678790755, "train/cont_neg_acc": 0.9948641091799565, "train/cont_neg_loss": 0.023503505338801182, "train/cont_pos_acc": 0.9999858548315309, "train/cont_pos_loss": 4.285022249239576e-05, "train/cont_pred": 0.994691979542053, "train/cont_rate": 0.9946815984712231, "train/dyn_loss_mean": 14.271726423030277, "train/dyn_loss_std": 9.274033567030653, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8004401013147917, "train/extr_critic_critic_opt_grad_steps": 34210.0, "train/extr_critic_critic_opt_loss": 15627.413563680306, "train/extr_critic_mag": 5.442387680355593, "train/extr_critic_max": 5.442387680355593, "train/extr_critic_mean": 1.0333279366973493, "train/extr_critic_min": -0.29451250000823315, "train/extr_critic_std": 1.1336320853061814, "train/extr_return_normed_mag": 1.8460092544555664, "train/extr_return_normed_max": 1.8460092544555664, "train/extr_return_normed_mean": 0.3247976085479311, "train/extr_return_normed_min": -0.14492590521736967, "train/extr_return_normed_std": 0.3318850933004626, "train/extr_return_rate": 0.5490108222412549, "train/extr_return_raw_mag": 6.413764881573135, "train/extr_return_raw_max": 6.413764881573135, "train/extr_return_raw_mean": 1.0496849486296125, "train/extr_return_raw_min": -0.6077282152158751, "train/extr_return_raw_std": 1.170995674973769, "train/extr_reward_mag": 1.0244960081663064, "train/extr_reward_max": 1.0244960081663064, "train/extr_reward_mean": 0.026089463657666026, "train/extr_reward_min": -0.36332869701248277, "train/extr_reward_std": 0.15317535555834394, "train/image_loss_mean": 6.783182322550163, "train/image_loss_std": 11.323068817742437, "train/model_loss_mean": 15.400289645297923, "train/model_loss_std": 15.077168382329049, "train/model_opt_grad_norm": 61.370627547339566, "train/model_opt_grad_steps": 34178.482014388486, "train/model_opt_loss": 19683.873222515736, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1276.978417266187, "train/policy_entropy_mag": 2.4615754120641475, "train/policy_entropy_max": 2.4615754120641475, "train/policy_entropy_mean": 0.5092157146913542, "train/policy_entropy_min": 0.07937503332714382, "train/policy_entropy_std": 0.5629076063632965, "train/policy_logprob_mag": 7.438383689029611, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5082692377430071, "train/policy_logprob_min": -7.438383689029611, "train/policy_logprob_std": 1.073153176753641, "train/policy_randomness_mag": 0.8688280964069229, "train/policy_randomness_max": 0.8688280964069229, "train/policy_randomness_mean": 0.17973080084478255, "train/policy_randomness_min": 0.028015903418334268, "train/policy_randomness_std": 0.1986816856715319, "train/post_ent_mag": 60.17024639870623, "train/post_ent_max": 60.17024639870623, "train/post_ent_mean": 43.051209346853575, "train/post_ent_min": 21.058451467280765, "train/post_ent_std": 7.552651666051192, "train/prior_ent_mag": 70.11910544196479, "train/prior_ent_max": 70.11910544196479, "train/prior_ent_mean": 57.38758636035507, "train/prior_ent_min": 42.41744023604359, "train/prior_ent_std": 4.418080664367127, "train/rep_loss_mean": 14.271726423030277, "train/rep_loss_std": 9.274033567030653, "train/reward_avg": 0.02472318989633442, "train/reward_loss_mean": 0.05388094466045606, "train/reward_loss_std": 0.2491647280591855, "train/reward_max_data": 1.0172661911669394, "train/reward_max_pred": 1.0135188900309502, "train/reward_neg_acc": 0.9933213900319107, "train/reward_neg_loss": 0.02913470615183921, "train/reward_pos_acc": 0.9665030180979118, "train/reward_pos_loss": 0.865997714962033, "train/reward_pred": 0.02394173504690901, "train/reward_rate": 0.029556823291366906, "train_stats/sum_log_reward": 6.84257427536615, "train_stats/max_log_achievement_collect_coal": 0.12871287128712872, "train_stats/max_log_achievement_collect_drink": 9.247524752475247, "train_stats/max_log_achievement_collect_sapling": 2.6930693069306932, "train_stats/max_log_achievement_collect_stone": 1.613861386138614, "train_stats/max_log_achievement_collect_wood": 10.475247524752476, "train_stats/max_log_achievement_defeat_skeleton": 0.009900990099009901, "train_stats/max_log_achievement_defeat_zombie": 0.594059405940594, "train_stats/max_log_achievement_eat_cow": 0.06930693069306931, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.108910891089109, "train_stats/max_log_achievement_make_wood_sword": 0.06930693069306931, "train_stats/max_log_achievement_place_furnace": 0.0297029702970297, "train_stats/max_log_achievement_place_plant": 2.4158415841584158, "train_stats/max_log_achievement_place_stone": 0.12871287128712872, "train_stats/max_log_achievement_place_table": 2.782178217821782, "train_stats/max_log_achievement_wake_up": 1.297029702970297, "train_stats/mean_log_entropy": 0.49674110778487557, "eval_stats/sum_log_reward": 6.183333367109299, "eval_stats/max_log_achievement_collect_coal": 0.08333333333333333, "eval_stats/max_log_achievement_collect_drink": 8.083333333333334, "eval_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "eval_stats/max_log_achievement_collect_stone": 1.0833333333333333, "eval_stats/max_log_achievement_collect_wood": 8.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.041666666666666664, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.7916666666666667, "eval_stats/max_log_achievement_place_stone": 0.08333333333333333, "eval_stats/max_log_achievement_place_table": 2.3333333333333335, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.256422521895729e-05, "report/cont_loss_std": 0.00045510820928029716, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002752417465671897, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.7746765428892104e-06, "report/cont_pred": 0.9931790232658386, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.477681159973145, "report/dyn_loss_std": 9.446236610412598, "report/image_loss_mean": 6.18958044052124, "report/image_loss_std": 10.667006492614746, "report/model_loss_mean": 14.938499450683594, "report/model_loss_std": 14.579190254211426, "report/post_ent_mag": 58.743194580078125, "report/post_ent_max": 58.743194580078125, "report/post_ent_mean": 42.460960388183594, "report/post_ent_min": 22.919090270996094, "report/post_ent_std": 7.055209159851074, "report/prior_ent_mag": 70.03950500488281, "report/prior_ent_max": 70.03950500488281, "report/prior_ent_mean": 57.08765411376953, "report/prior_ent_min": 43.89686965942383, "report/prior_ent_std": 4.514069557189941, "report/rep_loss_mean": 14.477681159973145, "report/rep_loss_std": 9.446236610412598, "report/reward_avg": 0.02822265774011612, "report/reward_loss_mean": 0.062287554144859314, "report/reward_loss_std": 0.21217067539691925, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0206034183502197, "report/reward_neg_acc": 0.986842155456543, "report/reward_neg_loss": 0.03613445162773132, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7800449132919312, "report/reward_pred": 0.029634583741426468, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 4.307587914809119e-06, "eval/cont_loss_std": 4.7239300329238176e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005841196980327368, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.0338152353360783e-06, "eval/cont_pred": 0.9960939884185791, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.582603454589844, "eval/dyn_loss_std": 10.656610488891602, "eval/image_loss_mean": 11.778644561767578, "eval/image_loss_std": 23.0087890625, "eval/model_loss_mean": 22.422338485717773, "eval/model_loss_std": 26.620651245117188, "eval/post_ent_mag": 58.267765045166016, "eval/post_ent_max": 58.267765045166016, "eval/post_ent_mean": 42.33233642578125, "eval/post_ent_min": 19.752090454101562, "eval/post_ent_std": 7.225118160247803, "eval/prior_ent_mag": 70.03950500488281, "eval/prior_ent_max": 70.03950500488281, "eval/prior_ent_mean": 57.917724609375, "eval/prior_ent_min": 41.42845916748047, "eval/prior_ent_std": 3.833235263824463, "eval/rep_loss_mean": 17.582603454589844, "eval/rep_loss_std": 10.656610488891602, "eval/reward_avg": 0.03505859151482582, "eval/reward_loss_mean": 0.0941283106803894, "eval/reward_loss_std": 0.518032431602478, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.005094051361084, "eval/reward_neg_acc": 0.9867886900901794, "eval/reward_neg_loss": 0.05713759735226631, "eval/reward_pos_acc": 0.949999988079071, "eval/reward_pos_loss": 1.0041002035140991, "eval/reward_pred": 0.03975243493914604, "eval/reward_rate": 0.0390625, "replay/size": 559537.0, "replay/inserts": 22208.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3473956316967176e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.167480005654546e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6592.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1647861559414169e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1035.2457916736603, "timer/env.step_count": 2776.0, "timer/env.step_total": 242.96295619010925, "timer/env.step_frac": 0.23469108316520285, "timer/env.step_avg": 0.08752267874283474, "timer/env.step_min": 0.024161815643310547, "timer/env.step_max": 3.3481409549713135, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.333658218383789, "timer/replay._sample_frac": 0.010947794532988055, "timer/replay._sample_avg": 0.0005103412382197311, "timer/replay._sample_min": 0.00035190582275390625, "timer/replay._sample_max": 0.01020503044128418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3600.0, "timer/agent.policy_total": 63.11832642555237, "timer/agent.policy_frac": 0.06096941125789102, "timer/agent.policy_avg": 0.017532868451542324, "timer/agent.policy_min": 0.009546279907226562, "timer/agent.policy_max": 0.14006972312927246, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.1658310890197754, "timer/dataset_train_frac": 0.0001601852336455092, "timer/dataset_train_avg": 0.00011947484799695633, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0006513595581054688, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 625.1978678703308, "timer/agent.train_frac": 0.6039124939204886, "timer/agent.train_avg": 0.4504307405405842, "timer/agent.train_min": 0.4356062412261963, "timer/agent.train_max": 1.6731672286987305, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48665571212768555, "timer/agent.report_frac": 0.0004700871194471792, "timer/agent.report_avg": 0.24332785606384277, "timer/agent.report_min": 0.23495721817016602, "timer/agent.report_max": 0.25169849395751953, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 2.9017979313135516e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.45163820613692}
{"step": 560160, "time": 26388.118344545364, "episode/length": 335.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 560192, "time": 26390.783358573914, "episode/length": 35.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 560368, "time": 26398.17288184166, "episode/length": 43.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 560616, "time": 26408.051558971405, "episode/length": 241.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 560648, "time": 26410.83542895317, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 561120, "time": 26428.671107769012, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 561312, "time": 26436.714642763138, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 561368, "time": 26440.015555620193, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 561512, "time": 26446.41411089897, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 561648, "time": 26452.768186330795, "episode/length": 34.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 561840, "time": 26460.763974428177, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 562056, "time": 26469.58687710762, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 562216, "time": 26476.90828061104, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 562568, "time": 26490.295245170593, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 562688, "time": 26496.64933013916, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 563088, "time": 26511.897156715393, "episode/length": 179.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 563248, "time": 26518.874495267868, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 563376, "time": 26524.93391227722, "episode/length": 281.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 563408, "time": 26527.525800943375, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 563664, "time": 26537.880469083786, "episode/length": 268.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 563688, "time": 26539.98762512207, "episode/length": 183.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 563992, "time": 26551.92032122612, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 564696, "time": 26577.32729792595, "episode/length": 200.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 564776, "time": 26581.593517780304, "episode/length": 260.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 565080, "time": 26593.53654408455, "episode/length": 212.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 565184, "time": 26598.68297314644, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 565240, "time": 26602.01370716095, "episode/length": 228.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 565664, "time": 26619.822437763214, "episode/length": 301.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 565672, "time": 26621.429539442062, "episode/length": 209.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 566144, "time": 26639.137541294098, "episode/length": 309.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 566528, "time": 26653.789138317108, "episode/length": 218.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 566632, "time": 26658.719794511795, "episode/length": 241.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 566760, "time": 26664.65593957901, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 566888, "time": 26670.48293876648, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 566976, "time": 26675.200255393982, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 567656, "time": 26699.700520277023, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 567840, "time": 26707.59736609459, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 567872, "time": 26710.45803284645, "episode/length": 154.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 567896, "time": 26712.61377096176, "episode/length": 278.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 567968, "time": 26716.961532354355, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 568240, "time": 26727.628848314285, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 568448, "time": 26736.14977121353, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 569016, "time": 26756.84315109253, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 569224, "time": 26765.45590853691, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 569336, "time": 26770.882109880447, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 569672, "time": 26783.829236984253, "episode/length": 336.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940652818991098, "episode/intrinsic_return": 0.0}
{"step": 569872, "time": 26792.400720596313, "episode/length": 237.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26818.7849650383, "eval_episode/length": 145.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 570024, "time": 26820.8364007473, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 570024, "time": 26822.92138504982, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 570024, "time": 26825.17869257927, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 570024, "time": 26827.029685020447, "eval_episode/length": 185.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 570024, "time": 26828.931146621704, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 570024, "time": 26830.971798419952, "eval_episode/length": 202.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 570024, "time": 26832.894715309143, "eval_episode/length": 211.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9716981132075472}
{"step": 570264, "time": 26840.982751607895, "episode/length": 252.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 570376, "time": 26846.389404773712, "episode/length": 312.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.987220447284345, "episode/intrinsic_return": 0.0}
{"step": 570552, "time": 26853.90801334381, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 570712, "time": 26860.914001226425, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 570944, "time": 26870.486844062805, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 571016, "time": 26874.191193580627, "episode/length": 249.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 571120, "time": 26879.445020198822, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 571168, "time": 26882.74419593811, "episode/length": 76.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 571392, "time": 26892.040495157242, "episode/length": 367.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 572008, "time": 26914.00949406624, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 572440, "time": 26930.29382109642, "episode/length": 215.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 572560, "time": 26936.21889424324, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 572616, "time": 26939.426189422607, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 572944, "time": 26952.414172649384, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 573192, "time": 26962.210755109787, "episode/length": 271.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 573544, "time": 26977.242828130722, "episode/length": 296.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 573592, "time": 26980.55674099922, "episode/length": 415.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9975961538461539, "episode/intrinsic_return": 0.0}
{"step": 573688, "time": 26985.343639612198, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 574016, "time": 26998.112181186676, "episode/length": 196.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 574048, "time": 27000.906591892242, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 574104, "time": 27004.1807448864, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 574888, "time": 27032.36262369156, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 575400, "time": 27051.685253620148, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 575512, "time": 27057.215599298477, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 575568, "time": 27060.98297381401, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 575592, "time": 27063.227049827576, "episode/length": 249.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 575608, "time": 27065.356554746628, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 575808, "time": 27073.95134282112, "episode/length": 326.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938837920489296, "episode/intrinsic_return": 0.0}
{"step": 575920, "time": 27079.851936101913, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 575992, "time": 27084.12920308113, "episode/length": 137.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 576904, "time": 27116.47279214859, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 577072, "time": 27124.000172138214, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 577144, "time": 27127.848413944244, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 577272, "time": 27134.449527978897, "episode/length": 212.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 577464, "time": 27142.484553813934, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 577608, "time": 27149.068885087967, "episode/length": 224.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 577672, "time": 27152.874498605728, "episode/length": 209.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 577792, "time": 27158.603967905045, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 578256, "time": 27175.96105313301, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 578456, "time": 27183.951198101044, "episode/length": 163.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 578544, "time": 27188.686885356903, "episode/length": 35.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 578576, "time": 27191.427157640457, "episode/length": 162.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 578736, "time": 27198.280475378036, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 578880, "time": 27204.596588373184, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 578936, "time": 27207.858029603958, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 579184, "time": 27218.005286216736, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 579232, "time": 27221.259523630142, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 579984, "time": 27248.144233465195, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 27265.996803998947, "eval_episode/length": 50.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 580008, "time": 27267.779278039932, "eval_episode/length": 55.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9107142857142857}
{"step": 580008, "time": 27269.770040035248, "eval_episode/length": 63.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.984375}
{"step": 580008, "time": 27276.285639047623, "eval_episode/length": 173.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 580008, "time": 27278.167388916016, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 580008, "time": 27282.467720985413, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 580008, "time": 27284.432962179184, "eval_episode/length": 240.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.979253112033195}
{"step": 580008, "time": 27286.612161636353, "eval_episode/length": 187.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 580104, "time": 27289.864321947098, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 580112, "time": 27291.91939997673, "episode/length": 153.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 580232, "time": 27297.22162628174, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 580264, "time": 27299.93744134903, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 580464, "time": 27308.4676053524, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 580520, "time": 27311.94069957733, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 580856, "time": 27324.96649312973, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 580976, "time": 27330.8248796463, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 581384, "time": 27345.929588079453, "episode/length": 143.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 581688, "time": 27359.40524840355, "episode/length": 177.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 581704, "time": 27361.606206178665, "episode/length": 199.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 581744, "time": 27364.842936754227, "episode/length": 159.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 581824, "time": 27369.105188846588, "episode/length": 409.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 582184, "time": 27382.849400281906, "episode/length": 207.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 582185, "time": 27385.57764697075, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.815470084869604, "train/action_min": 0.0, "train/action_std": 3.60141813326225, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047285440049583106, "train/actor_opt_grad_steps": 35600.0, "train/actor_opt_loss": -0.09717922617527221, "train/adv_mag": 0.7082393656102873, "train/adv_max": 0.6890194774102821, "train/adv_mean": 0.004646797651900716, "train/adv_min": -0.4550803224388644, "train/adv_std": 0.06960187640657528, "train/cont_avg": 0.9948431879496403, "train/cont_loss_mean": 0.00023382906237130432, "train/cont_loss_std": 0.006751226560117103, "train/cont_neg_acc": 0.9936306653679281, "train/cont_neg_loss": 0.025601383791878186, "train/cont_pos_acc": 0.999985846255323, "train/cont_pos_loss": 5.062735460252933e-05, "train/cont_pred": 0.994859751608732, "train/cont_rate": 0.9948431879496403, "train/dyn_loss_mean": 13.865926118205778, "train/dyn_loss_std": 9.327888776930116, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8712101145613965, "train/extr_critic_critic_opt_grad_steps": 35600.0, "train/extr_critic_critic_opt_loss": 15858.69111819919, "train/extr_critic_mag": 5.633584948752424, "train/extr_critic_max": 5.633584948752424, "train/extr_critic_mean": 1.1722648431071274, "train/extr_critic_min": -0.29765617761680546, "train/extr_critic_std": 1.2046457027359831, "train/extr_return_normed_mag": 1.771046425798814, "train/extr_return_normed_max": 1.771046425798814, "train/extr_return_normed_mean": 0.33516902803517074, "train/extr_return_normed_min": -0.1408655258069793, "train/extr_return_normed_std": 0.32462874505159667, "train/extr_return_rate": 0.6092139139449854, "train/extr_return_raw_mag": 6.681403510004497, "train/extr_return_raw_max": 6.681403510004497, "train/extr_return_raw_mean": 1.1901025261810358, "train/extr_return_raw_min": -0.6320574251439074, "train/extr_return_raw_std": 1.2423481701089323, "train/extr_reward_mag": 1.021665658882196, "train/extr_reward_max": 1.021665658882196, "train/extr_reward_mean": 0.026782127586360886, "train/extr_reward_min": -0.40803541296677626, "train/extr_reward_std": 0.15362793753901832, "train/image_loss_mean": 6.7356410884171085, "train/image_loss_std": 11.421361072457952, "train/model_loss_mean": 15.109821381328775, "train/model_loss_std": 15.193243273728186, "train/model_opt_grad_norm": 58.579084615913224, "train/model_opt_grad_steps": 35567.22302158274, "train/model_opt_loss": 20009.127423842176, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1321.9424460431655, "train/policy_entropy_mag": 2.428138036522076, "train/policy_entropy_max": 2.428138036522076, "train/policy_entropy_mean": 0.5024046591288752, "train/policy_entropy_min": 0.07937503482798021, "train/policy_entropy_std": 0.5416598047712724, "train/policy_logprob_mag": 7.438383678738162, "train/policy_logprob_max": -0.009455658415024229, "train/policy_logprob_mean": -0.5027354488269888, "train/policy_logprob_min": -7.438383678738162, "train/policy_logprob_std": 1.0732559784710836, "train/policy_randomness_mag": 0.8570261696259752, "train/policy_randomness_max": 0.8570261696259752, "train/policy_randomness_mean": 0.1773267969381895, "train/policy_randomness_min": 0.02801590392754661, "train/policy_randomness_std": 0.19118214082374846, "train/post_ent_mag": 60.22947780691462, "train/post_ent_max": 60.22947780691462, "train/post_ent_mean": 43.394538440292685, "train/post_ent_min": 21.089581647365215, "train/post_ent_std": 7.561527094395041, "train/prior_ent_mag": 70.16813736510791, "train/prior_ent_max": 70.16813736510791, "train/prior_ent_mean": 57.364812535347696, "train/prior_ent_min": 41.91749745650257, "train/prior_ent_std": 4.4259993927084285, "train/rep_loss_mean": 13.865926118205778, "train/rep_loss_std": 9.327888776930116, "train/reward_avg": 0.02571029089418032, "train/reward_loss_mean": 0.054390986778324456, "train/reward_loss_std": 0.25137753741775487, "train/reward_max_data": 1.019424465062807, "train/reward_max_pred": 1.0167254912767478, "train/reward_neg_acc": 0.9931140361929969, "train/reward_neg_loss": 0.029291953630209398, "train/reward_pos_acc": 0.9646128977803018, "train/reward_pos_loss": 0.8675918047376674, "train/reward_pred": 0.02500893822837648, "train/reward_rate": 0.0302734375, "train_stats/sum_log_reward": 6.971559723582836, "train_stats/max_log_achievement_collect_coal": 0.08256880733944955, "train_stats/max_log_achievement_collect_drink": 6.513761467889908, "train_stats/max_log_achievement_collect_sapling": 2.2752293577981653, "train_stats/max_log_achievement_collect_stone": 1.2935779816513762, "train_stats/max_log_achievement_collect_wood": 11.587155963302752, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.7064220183486238, "train_stats/max_log_achievement_eat_cow": 0.08256880733944955, "train_stats/max_log_achievement_make_stone_sword": 0.009174311926605505, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7798165137614679, "train_stats/max_log_achievement_make_wood_sword": 1.3211009174311927, "train_stats/max_log_achievement_place_furnace": 0.009174311926605505, "train_stats/max_log_achievement_place_plant": 2.229357798165138, "train_stats/max_log_achievement_place_stone": 0.10091743119266056, "train_stats/max_log_achievement_place_table": 3.0091743119266057, "train_stats/max_log_achievement_wake_up": 1.110091743119266, "train_stats/mean_log_entropy": 0.44744604477368366, "eval_stats/sum_log_reward": 6.224999949336052, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.75, "eval_stats/max_log_achievement_collect_wood": 10.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.75, "eval_stats/max_log_achievement_wake_up": 0.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.105853584704164e-06, "report/cont_loss_std": 7.770670890749898e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.7081615523202345e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0832710586328176e-06, "report/cont_pred": 0.9951161742210388, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.84161376953125, "report/dyn_loss_std": 10.107385635375977, "report/image_loss_mean": 7.036812782287598, "report/image_loss_std": 12.2466402053833, "report/model_loss_mean": 16.61258316040039, "report/model_loss_std": 16.4872989654541, "report/post_ent_mag": 60.917999267578125, "report/post_ent_max": 60.917999267578125, "report/post_ent_mean": 42.61960220336914, "report/post_ent_min": 22.196819305419922, "report/post_ent_std": 8.148397445678711, "report/prior_ent_mag": 70.74212646484375, "report/prior_ent_max": 70.74212646484375, "report/prior_ent_mean": 58.22247314453125, "report/prior_ent_min": 41.913230895996094, "report/prior_ent_std": 4.634860992431641, "report/rep_loss_mean": 15.84161376953125, "report/rep_loss_std": 10.107385635375977, "report/reward_avg": 0.02460937388241291, "report/reward_loss_mean": 0.07080277800559998, "report/reward_loss_std": 0.38943061232566833, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0006024837493896, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 0.04634670540690422, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.88111412525177, "report/reward_pred": 0.021174326539039612, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 6.82973791299446e-07, "eval/cont_loss_std": 2.5242886749765603e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.1806381735368632e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.39352549569594e-07, "eval/cont_pred": 0.996093213558197, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.762317657470703, "eval/dyn_loss_std": 10.45207405090332, "eval/image_loss_mean": 10.97073745727539, "eval/image_loss_std": 15.855772018432617, "eval/model_loss_mean": 21.09609603881836, "eval/model_loss_std": 20.004932403564453, "eval/post_ent_mag": 59.80596160888672, "eval/post_ent_max": 59.80596160888672, "eval/post_ent_mean": 43.22470474243164, "eval/post_ent_min": 22.933502197265625, "eval/post_ent_std": 7.732941150665283, "eval/prior_ent_mag": 70.74212646484375, "eval/prior_ent_max": 70.74212646484375, "eval/prior_ent_mean": 57.997318267822266, "eval/prior_ent_min": 43.29533767700195, "eval/prior_ent_std": 4.048379898071289, "eval/rep_loss_mean": 16.762317657470703, "eval/rep_loss_std": 10.45207405090332, "eval/reward_avg": 0.02490234375, "eval/reward_loss_mean": 0.0679675042629242, "eval/reward_loss_std": 0.4435119926929474, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023694038391113, "eval/reward_neg_acc": 0.9939637184143066, "eval/reward_neg_loss": 0.027241257950663567, "eval/reward_pos_acc": 0.9000000357627869, "eval/reward_pos_loss": 1.4173635244369507, "eval/reward_pred": 0.021818403154611588, "eval/reward_rate": 0.029296875, "replay/size": 581681.0, "replay/inserts": 22144.0, "replay/samples": 22144.0, "replay/insert_wait_avg": 1.3737277143952474e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.589162819647375e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3712.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.182458524046273e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.8881359100342, "timer/env.step_count": 2768.0, "timer/env.step_total": 253.79312777519226, "timer/env.step_frac": 0.2533148349387999, "timer/env.step_avg": 0.0916882687049105, "timer/env.step_min": 0.024667024612426758, "timer/env.step_max": 2.2876360416412354, "timer/replay._sample_count": 22144.0, "timer/replay._sample_total": 11.453484773635864, "timer/replay._sample_frac": 0.011431899793116568, "timer/replay._sample_avg": 0.0005172274554568219, "timer/replay._sample_min": 0.00042510032653808594, "timer/replay._sample_max": 0.011209726333618164, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3232.0, "timer/agent.policy_total": 55.672642946243286, "timer/agent.policy_frac": 0.055567723532003656, "timer/agent.policy_avg": 0.01722544645613963, "timer/agent.policy_min": 0.009842872619628906, "timer/agent.policy_max": 0.11186695098876953, "timer/dataset_train_count": 1384.0, "timer/dataset_train_total": 0.1626732349395752, "timer/dataset_train_frac": 0.00016236666460953345, "timer/dataset_train_avg": 0.00011753846455171619, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0003008842468261719, "timer/agent.train_count": 1384.0, "timer/agent.train_total": 624.1163115501404, "timer/agent.train_frac": 0.6229401159474192, "timer/agent.train_avg": 0.45095109216050605, "timer/agent.train_min": 0.4371917247772217, "timer/agent.train_max": 1.62113618850708, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48311352729797363, "timer/agent.report_frac": 0.00048220306237996556, "timer/agent.report_avg": 0.24155676364898682, "timer/agent.report_min": 0.2344498634338379, "timer/agent.report_max": 0.24866366386413574, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.147125244140625e-05, "timer/dataset_eval_frac": 3.1411942424909854e-08, "timer/dataset_eval_avg": 3.147125244140625e-05, "timer/dataset_eval_min": 3.147125244140625e-05, "timer/dataset_eval_max": 3.147125244140625e-05, "fps": 22.101957624951257}
{"step": 582248, "time": 27387.566930532455, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 582824, "time": 27408.629852294922, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 582848, "time": 27411.36327981949, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 583112, "time": 27421.61959862709, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 583352, "time": 27431.36091017723, "episode/length": 207.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 583592, "time": 27441.114298582077, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 583680, "time": 27445.971445083618, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 584064, "time": 27460.803208827972, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 584120, "time": 27463.99689388275, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 584160, "time": 27467.198387622833, "episode/length": 301.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834437086092715, "episode/intrinsic_return": 0.0}
{"step": 584328, "time": 27474.211392879486, "episode/length": 187.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 584560, "time": 27483.876110315323, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 585040, "time": 27501.627474069595, "episode/length": 59.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 585320, "time": 27512.490928173065, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 585336, "time": 27514.636131048203, "episode/length": 247.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 585408, "time": 27518.862021684647, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 585904, "time": 27537.268864393234, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 585984, "time": 27541.50909137726, "episode/length": 232.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 586104, "time": 27546.803419351578, "episode/length": 254.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 586456, "time": 27560.246462106705, "episode/length": 176.0, "episode/score": 6.100000038743019, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 586656, "time": 27568.78063607216, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 586904, "time": 27578.440826654434, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 587000, "time": 27583.444104909897, "episode/length": 354.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 587344, "time": 27596.77578306198, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 587424, "time": 27601.098267793655, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 587448, "time": 27603.26095199585, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 587632, "time": 27611.373923540115, "episode/length": 205.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 587984, "time": 27624.776342868805, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 588360, "time": 27638.6363093853, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 588440, "time": 27643.334389209747, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 588648, "time": 27651.913187026978, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 588744, "time": 27656.69326877594, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 588872, "time": 27662.68213200569, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 589032, "time": 27669.703376293182, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 589552, "time": 27689.14091539383, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 589808, "time": 27699.36942768097, "episode/length": 227.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 589808, "time": 27699.379923582077, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 589824, "time": 27703.60024523735, "episode/length": 420.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995249406175772, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27736.10989832878, "eval_episode/length": 153.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 590096, "time": 27741.423728466034, "eval_episode/length": 195.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9693877551020408}
{"step": 590096, "time": 27743.54585671425, "eval_episode/length": 207.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 590096, "time": 27746.046412944794, "eval_episode/length": 227.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 590096, "time": 27747.74534201622, "eval_episode/length": 229.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9826086956521739}
{"step": 590096, "time": 27749.586852312088, "eval_episode/length": 233.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 590096, "time": 27753.23354959488, "eval_episode/length": 280.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9750889679715302}
{"step": 590096, "time": 27755.919305324554, "eval_episode/length": 304.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 590624, "time": 27773.800597429276, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 590904, "time": 27784.732842683792, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 590992, "time": 27789.52952504158, "episode/length": 280.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 591168, "time": 27797.163813829422, "episode/length": 169.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 591224, "time": 27800.41881918907, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 591240, "time": 27802.50711417198, "episode/length": 295.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 592216, "time": 27836.988919734955, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 592248, "time": 27839.63631772995, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 592416, "time": 27847.079560995102, "episode/length": 357.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 592624, "time": 27855.86669111252, "episode/length": 351.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 592696, "time": 27859.587714910507, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 592704, "time": 27861.63355255127, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 592744, "time": 27864.29852414131, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 593856, "time": 27903.826637268066, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 593888, "time": 27906.436074972153, "episode/length": 332.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 593936, "time": 27909.962569713593, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 593992, "time": 27913.166394472122, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 594016, "time": 27915.826674938202, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 594032, "time": 27917.999619483948, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 594120, "time": 27922.24191069603, "episode/length": 233.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 595216, "time": 27961.146365642548, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 595216, "time": 27961.159093618393, "episode/length": 308.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 595224, "time": 27964.61521077156, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 595248, "time": 27967.166412353516, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 595472, "time": 27976.48049044609, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 595496, "time": 27978.68484210968, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 595504, "time": 27980.96018886566, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 595592, "time": 27985.28819489479, "episode/length": 45.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 596648, "time": 28022.33407354355, "episode/length": 178.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 596712, "time": 28025.97209095955, "episode/length": 139.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 596928, "time": 28035.089805603027, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 597032, "time": 28040.008559703827, "episode/length": 39.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 597104, "time": 28044.285271644592, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 597104, "time": 28044.295835018158, "episode/length": 235.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 597128, "time": 28048.307705163956, "episode/length": 206.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 597344, "time": 28057.33888554573, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 597416, "time": 28061.375716924667, "episode/length": 411.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 598080, "time": 28087.080978393555, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 598136, "time": 28090.49042391777, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 598320, "time": 28098.529193401337, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 598632, "time": 28110.491251945496, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 598776, "time": 28117.001267910004, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 598776, "time": 28117.011777162552, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 598984, "time": 28127.364444732666, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 599000, "time": 28129.665766239166, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 599888, "time": 28161.329631328583, "episode/length": 195.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 599984, "time": 28166.19729948044, "episode/length": 230.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 28191.95372056961, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 600080, "time": 28194.31513261795, "eval_episode/length": 175.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 600080, "time": 28196.976314544678, "eval_episode/length": 197.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 600080, "time": 28198.718577623367, "eval_episode/length": 200.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9651741293532339}
{"step": 600080, "time": 28200.477304458618, "eval_episode/length": 203.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 600080, "time": 28202.875514268875, "eval_episode/length": 221.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.972972972972973}
{"step": 600080, "time": 28204.58016347885, "eval_episode/length": 223.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 600080, "time": 28207.408170223236, "eval_episode/length": 249.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.996}
{"step": 600120, "time": 28208.55812072754, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 600296, "time": 28216.384054660797, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 600448, "time": 28223.30277943611, "episode/length": 208.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 600464, "time": 28225.38851428032, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 600488, "time": 28227.52683711052, "episode/length": 300.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 600952, "time": 28244.8073720932, "episode/length": 271.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 601328, "time": 28259.261511325836, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 601456, "time": 28265.099838256836, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 601600, "time": 28271.697361946106, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 601720, "time": 28277.146936655045, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 601760, "time": 28280.334986448288, "episode/length": 221.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 601768, "time": 28281.95105099678, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 601848, "time": 28286.38604402542, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 602304, "time": 28303.625263929367, "episode/length": 56.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 602408, "time": 28308.496073961258, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 602744, "time": 28321.36939573288, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 602992, "time": 28331.606570720673, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 603176, "time": 28339.24404525757, "episode/length": 181.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 603264, "time": 28344.030034303665, "episode/length": 186.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 603328, "time": 28347.868892669678, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 603400, "time": 28351.69667649269, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 604064, "time": 28376.17969226837, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 604272, "time": 28384.826361894608, "episode/length": 190.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 604273, "time": 28386.985147476196, "train_stats/sum_log_reward": 6.516666648219581, "train_stats/max_log_achievement_collect_coal": 0.018518518518518517, "train_stats/max_log_achievement_collect_drink": 5.537037037037037, "train_stats/max_log_achievement_collect_sapling": 2.3703703703703702, "train_stats/max_log_achievement_collect_stone": 0.12962962962962962, "train_stats/max_log_achievement_collect_wood": 12.953703703703704, "train_stats/max_log_achievement_defeat_skeleton": 0.018518518518518517, "train_stats/max_log_achievement_defeat_zombie": 0.6481481481481481, "train_stats/max_log_achievement_eat_cow": 0.1111111111111111, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.1574074074074074, "train_stats/max_log_achievement_make_wood_sword": 3.8796296296296298, "train_stats/max_log_achievement_place_furnace": 0.009259259259259259, "train_stats/max_log_achievement_place_plant": 2.2685185185185186, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 3.4074074074074074, "train_stats/max_log_achievement_wake_up": 1.1944444444444444, "train_stats/mean_log_entropy": 0.4174577294400445, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.886333963145381, "train/action_min": 0.0, "train/action_std": 3.7505482124245684, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04556089507388896, "train/actor_opt_grad_steps": 36985.0, "train/actor_opt_loss": 7.779991425465846, "train/adv_mag": 0.6212918561869774, "train/adv_max": 0.5954204871170763, "train/adv_mean": 0.0076256008395685585, "train/adv_min": -0.4372924311437469, "train/adv_std": 0.06713268460462922, "train/cont_avg": 0.9947775135869565, "train/cont_loss_mean": 0.00019260436686041444, "train/cont_loss_std": 0.005722498590642587, "train/cont_neg_acc": 0.9941338862197987, "train/cont_neg_loss": 0.015054831142023155, "train/cont_pos_acc": 0.9999715504438981, "train/cont_pos_loss": 0.0001137978491938111, "train/cont_pred": 0.9947800105032714, "train/cont_rate": 0.9947775135869565, "train/dyn_loss_mean": 13.786362724027772, "train/dyn_loss_std": 9.321664312611455, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.939720367607863, "train/extr_critic_critic_opt_grad_steps": 36985.0, "train/extr_critic_critic_opt_loss": 16491.590629245922, "train/extr_critic_mag": 5.940266246381014, "train/extr_critic_max": 5.940266246381014, "train/extr_critic_mean": 1.4940344712872435, "train/extr_critic_min": -0.2836900966754858, "train/extr_critic_std": 1.3486403291640074, "train/extr_return_normed_mag": 1.6924743367278057, "train/extr_return_normed_max": 1.6924743367278057, "train/extr_return_normed_mean": 0.37481546304796054, "train/extr_return_normed_min": -0.12472761044467705, "train/extr_return_normed_std": 0.3272441977608031, "train/extr_return_rate": 0.6833739408116409, "train/extr_return_raw_mag": 7.117752486380978, "train/extr_return_raw_max": 7.117752486380978, "train/extr_return_raw_mean": 1.5264139862164208, "train/extr_return_raw_min": -0.5997626580621885, "train/extr_return_raw_std": 1.3915927090506623, "train/extr_reward_mag": 1.0173345925151438, "train/extr_reward_max": 1.0173345925151438, "train/extr_reward_mean": 0.02807170930116073, "train/extr_reward_min": -0.40106754285701807, "train/extr_reward_std": 0.15700967231954355, "train/image_loss_mean": 6.67451590731524, "train/image_loss_std": 11.44954456453738, "train/model_loss_mean": 15.001553314319555, "train/model_loss_std": 15.229412327642025, "train/model_opt_grad_norm": 58.49666653508725, "train/model_opt_grad_steps": 36950.739130434784, "train/model_opt_loss": 19460.615538666214, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1295.2898550724638, "train/policy_entropy_mag": 2.4182528378306953, "train/policy_entropy_max": 2.4182528378306953, "train/policy_entropy_mean": 0.4432764873988386, "train/policy_entropy_min": 0.07937502807033235, "train/policy_entropy_std": 0.48250400480152905, "train/policy_logprob_mag": 7.438383745110554, "train/policy_logprob_max": -0.009455658421190321, "train/policy_logprob_mean": -0.44359932321569195, "train/policy_logprob_min": -7.438383745110554, "train/policy_logprob_std": 1.0301998827768408, "train/policy_randomness_mag": 0.853537128455397, "train/policy_randomness_max": 0.853537128455397, "train/policy_randomness_mean": 0.1564571482763774, "train/policy_randomness_min": 0.02801590151005033, "train/policy_randomness_std": 0.17030273901595586, "train/post_ent_mag": 60.7071434242138, "train/post_ent_max": 60.7071434242138, "train/post_ent_mean": 43.591304474982664, "train/post_ent_min": 20.982639077780902, "train/post_ent_std": 7.633881472159123, "train/prior_ent_mag": 70.2189345428909, "train/prior_ent_max": 70.2189345428909, "train/prior_ent_mean": 57.4461763077888, "train/prior_ent_min": 41.521748169608735, "train/prior_ent_std": 4.485750528349393, "train/rep_loss_mean": 13.786362724027772, "train/rep_loss_std": 9.321664312611455, "train/reward_avg": 0.025528617439440626, "train/reward_loss_mean": 0.05502727935495584, "train/reward_loss_std": 0.2505293013393015, "train/reward_max_data": 1.013043481370677, "train/reward_max_pred": 1.005829796410989, "train/reward_neg_acc": 0.9924096603324448, "train/reward_neg_loss": 0.029529418809798317, "train/reward_pos_acc": 0.9596266789712767, "train/reward_pos_loss": 0.8769482542639193, "train/reward_pred": 0.0245099067080604, "train/reward_rate": 0.030131906702898552, "eval_stats/sum_log_reward": 7.287500083446503, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 6.625, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 0.8125, "eval_stats/max_log_achievement_collect_wood": 14.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.25, "eval_stats/max_log_achievement_make_wood_sword": 4.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9375, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 3.6875, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 5.3680737437389325e-06, "report/cont_loss_std": 0.00011977272515650839, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0008362858789041638, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.7071947051335883e-07, "report/cont_pred": 0.9941451549530029, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.720046043395996, "report/dyn_loss_std": 9.207752227783203, "report/image_loss_mean": 6.421725273132324, "report/image_loss_std": 7.853617191314697, "report/model_loss_mean": 14.70876693725586, "report/model_loss_std": 11.794865608215332, "report/post_ent_mag": 63.047882080078125, "report/post_ent_max": 63.047882080078125, "report/post_ent_mean": 43.47259521484375, "report/post_ent_min": 23.593557357788086, "report/post_ent_std": 7.687806606292725, "report/prior_ent_mag": 70.28380584716797, "report/prior_ent_max": 70.28380584716797, "report/prior_ent_mean": 57.14565658569336, "report/prior_ent_min": 38.578575134277344, "report/prior_ent_std": 5.4059038162231445, "report/rep_loss_mean": 13.720046043395996, "report/rep_loss_std": 9.207752227783203, "report/reward_avg": 0.02275390550494194, "report/reward_loss_mean": 0.05500860884785652, "report/reward_loss_std": 0.2596222162246704, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011563301086426, "report/reward_neg_acc": 0.9869346618652344, "report/reward_neg_loss": 0.0352545827627182, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7327759861946106, "report/reward_pred": 0.02290484681725502, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.834307765122503e-05, "eval/cont_loss_std": 0.0014020762173458934, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.009608226828277111, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4349233197208378e-06, "eval/cont_pred": 0.995161771774292, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.784107208251953, "eval/dyn_loss_std": 11.578112602233887, "eval/image_loss_mean": 14.447391510009766, "eval/image_loss_std": 28.52606201171875, "eval/model_loss_mean": 25.27449607849121, "eval/model_loss_std": 32.59699630737305, "eval/post_ent_mag": 58.979393005371094, "eval/post_ent_max": 58.979393005371094, "eval/post_ent_mean": 42.20512390136719, "eval/post_ent_min": 21.13446044921875, "eval/post_ent_std": 7.856850624084473, "eval/prior_ent_mag": 70.28380584716797, "eval/prior_ent_max": 70.28380584716797, "eval/prior_ent_mean": 57.61196517944336, "eval/prior_ent_min": 42.47417449951172, "eval/prior_ent_std": 4.604120254516602, "eval/rep_loss_mean": 17.784107208251953, "eval/rep_loss_std": 11.578112602233887, "eval/reward_avg": 0.0390625, "eval/reward_loss_mean": 0.15659154951572418, "eval/reward_loss_std": 0.9736973643302917, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018069744110107, "eval/reward_neg_acc": 0.9897855520248413, "eval/reward_neg_loss": 0.05057374760508537, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.4630677700042725, "eval/reward_pred": 0.03351216018199921, "eval/reward_rate": 0.0439453125, "replay/size": 603769.0, "replay/inserts": 22088.0, "replay/samples": 22080.0, "replay/insert_wait_avg": 1.3577812869062635e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.184951201729153e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1712581187755137e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.3909168243408, "timer/env.step_count": 2761.0, "timer/env.step_total": 252.7162742614746, "timer/env.step_frac": 0.2523652551821627, "timer/env.step_avg": 0.09153070418742289, "timer/env.step_min": 0.0239717960357666, "timer/env.step_max": 3.461785316467285, "timer/replay._sample_count": 22080.0, "timer/replay._sample_total": 11.36863088607788, "timer/replay._sample_frac": 0.011352840029876276, "timer/replay._sample_avg": 0.0005148836452028026, "timer/replay._sample_min": 0.000396728515625, "timer/replay._sample_max": 0.009991168975830078, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3316.0, "timer/agent.policy_total": 58.185450315475464, "timer/agent.policy_frac": 0.05810463160580283, "timer/agent.policy_avg": 0.017546878864739282, "timer/agent.policy_min": 0.00963282585144043, "timer/agent.policy_max": 0.12701845169067383, "timer/dataset_train_count": 1380.0, "timer/dataset_train_total": 0.1634361743927002, "timer/dataset_train_frac": 0.00016320916402057738, "timer/dataset_train_avg": 0.00011843201042949289, "timer/dataset_train_min": 0.00010323524475097656, "timer/dataset_train_max": 0.00046753883361816406, "timer/agent.train_count": 1380.0, "timer/agent.train_total": 619.6732823848724, "timer/agent.train_frac": 0.6188125655762988, "timer/agent.train_avg": 0.4490386104238206, "timer/agent.train_min": 0.43802785873413086, "timer/agent.train_max": 1.6106207370758057, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48352956771850586, "timer/agent.report_frac": 0.00048285795246865045, "timer/agent.report_avg": 0.24176478385925293, "timer/agent.report_min": 0.23318076133728027, "timer/agent.report_max": 0.2503488063812256, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 5.7697296142578125e-05, "timer/dataset_eval_frac": 5.761715547166193e-08, "timer/dataset_eval_avg": 5.7697296142578125e-05, "timer/dataset_eval_min": 5.7697296142578125e-05, "timer/dataset_eval_max": 5.7697296142578125e-05, "fps": 22.05699007236481}
{"step": 604544, "time": 28396.587780475616, "episode/length": 142.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 604568, "time": 28398.774752616882, "episode/length": 269.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 604688, "time": 28404.6090528965, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 604744, "time": 28407.811170339584, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 605432, "time": 28432.649307727814, "episode/length": 304.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 605832, "time": 28447.740795850754, "episode/length": 160.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 605888, "time": 28451.578729391098, "episode/length": 338.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9793510324483776, "episode/intrinsic_return": 0.0}
{"step": 606080, "time": 28459.597863197327, "episode/length": 251.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 606656, "time": 28482.35820889473, "episode/length": 71.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 606656, "time": 28482.369288921356, "episode/length": 297.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 606872, "time": 28492.88520169258, "episode/length": 265.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 606920, "time": 28496.185282230377, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 606936, "time": 28498.458939552307, "episode/length": 280.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 607312, "time": 28512.957865715027, "episode/length": 342.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9883381924198251, "episode/intrinsic_return": 0.0}
{"step": 607416, "time": 28517.70110630989, "episode/length": 190.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 607592, "time": 28525.243061304092, "episode/length": 219.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 608208, "time": 28547.817296266556, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 608312, "time": 28552.782479524612, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 608336, "time": 28555.410124778748, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 608552, "time": 28564.048166275024, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 608648, "time": 28568.747640132904, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 608800, "time": 28575.81736421585, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 608864, "time": 28579.547478437424, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 609056, "time": 28587.545402765274, "episode/length": 182.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 609528, "time": 28604.87194943428, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 609760, "time": 28614.605817317963, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 609840, "time": 28618.92627263069, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 610048, "time": 28627.586474895477, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28645.57665514946, "eval_episode/length": 63.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.921875}
{"step": 610064, "time": 28652.565123796463, "eval_episode/length": 180.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 610064, "time": 28654.514348506927, "eval_episode/length": 188.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 610064, "time": 28656.916422843933, "eval_episode/length": 206.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 610064, "time": 28659.403190135956, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 610064, "time": 28661.39103937149, "eval_episode/length": 50.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 610064, "time": 28663.409853696823, "eval_episode/length": 240.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.983402489626556}
{"step": 610064, "time": 28667.82175064087, "eval_episode/length": 301.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 610392, "time": 28678.669059038162, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 610464, "time": 28682.855063438416, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 610512, "time": 28687.648166656494, "episode/length": 244.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 610600, "time": 28692.121389389038, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9631336405529954, "episode/intrinsic_return": 0.0}
{"step": 611224, "time": 28714.751963377, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 611648, "time": 28731.015031576157, "episode/length": 235.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 611712, "time": 28734.900923490524, "episode/length": 164.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 611960, "time": 28744.60058426857, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 612008, "time": 28747.89530158043, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 612104, "time": 28752.74799132347, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 612216, "time": 28758.057608127594, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 612624, "time": 28773.55960869789, "episode/length": 174.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 613424, "time": 28802.35178375244, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 613624, "time": 28810.542998552322, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 613712, "time": 28815.35605740547, "episode/length": 399.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 613752, "time": 28818.059223890305, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 613840, "time": 28822.846384763718, "episode/length": 265.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 614216, "time": 28836.9034075737, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 614232, "time": 28838.961887598038, "episode/length": 265.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 614800, "time": 28861.58815050125, "episode/length": 135.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 614832, "time": 28864.35472035408, "episode/length": 397.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773869346733668, "episode/intrinsic_return": 0.0}
{"step": 614976, "time": 28870.926820516586, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 615104, "time": 28876.8583176136, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 615416, "time": 28888.688591241837, "episode/length": 147.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 615432, "time": 28890.87747311592, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 615760, "time": 28905.017107963562, "episode/length": 192.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 615824, "time": 28908.80475950241, "episode/length": 123.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 616496, "time": 28933.08684539795, "episode/length": 189.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 616520, "time": 28935.4089281559, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 616560, "time": 28938.664186239243, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 616856, "time": 28950.03771328926, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 616984, "time": 28955.859174728394, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 617048, "time": 28959.666251897812, "episode/length": 400.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9800498753117207, "episode/intrinsic_return": 0.0}
{"step": 617160, "time": 28965.045790672302, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 617296, "time": 28971.43970632553, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 617632, "time": 28984.373413801193, "episode/length": 133.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 618336, "time": 29009.775179624557, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 618512, "time": 29017.339918375015, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 618600, "time": 29021.736676216125, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 618632, "time": 29024.368196249008, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 618848, "time": 29033.28449988365, "episode/length": 210.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 619368, "time": 29052.257834911346, "episode/length": 358.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 619400, "time": 29054.946827173233, "episode/length": 220.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 619840, "time": 29071.51304769516, "episode/length": 54.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 29100.188773155212, "eval_episode/length": 152.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 620048, "time": 29101.943485975266, "eval_episode/length": 156.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 620048, "time": 29104.21516561508, "eval_episode/length": 171.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 620048, "time": 29106.31944322586, "eval_episode/length": 185.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 620048, "time": 29108.392990350723, "eval_episode/length": 193.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 620048, "time": 29110.36618256569, "eval_episode/length": 197.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9949494949494949}
{"step": 620048, "time": 29112.999250888824, "eval_episode/length": 208.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9712918660287081}
{"step": 620048, "time": 29118.635333299637, "eval_episode/length": 66.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9850746268656716}
{"step": 620176, "time": 29123.048382520676, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 620192, "time": 29125.152841329575, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 620384, "time": 29133.092594861984, "episode/length": 482.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958592132505176, "episode/intrinsic_return": 0.0}
{"step": 620448, "time": 29136.864278316498, "episode/length": 263.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 620728, "time": 29147.72409772873, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 620792, "time": 29151.553537130356, "episode/length": 118.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9915966386554622, "episode/intrinsic_return": 0.0}
{"step": 620832, "time": 29154.64396429062, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 621344, "time": 29173.630660772324, "episode/length": 145.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 621528, "time": 29181.07106900215, "episode/length": 166.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 621992, "time": 29198.2597720623, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 622480, "time": 29216.80738902092, "episode/length": 480.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958419958419958, "episode/intrinsic_return": 0.0}
{"step": 622672, "time": 29226.44468474388, "episode/length": 229.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 622808, "time": 29232.494609832764, "episode/length": 251.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 622824, "time": 29234.546997070312, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 622832, "time": 29236.60383963585, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 622944, "time": 29241.961380004883, "episode/length": 319.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 623680, "time": 29268.607523202896, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 623864, "time": 29276.22620153427, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 624080, "time": 29285.40965771675, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 624248, "time": 29292.66468191147, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 624296, "time": 29296.031814098358, "episode/length": 183.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 624440, "time": 29302.525452136993, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 624520, "time": 29306.789095401764, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 624528, "time": 29308.780066728592, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 625232, "time": 29334.289528608322, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 625312, "time": 29338.62597680092, "episode/length": 414.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 625808, "time": 29357.26075577736, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 625984, "time": 29364.844505548477, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 626112, "time": 29370.783421278, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 626112, "time": 29370.794733285904, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 626248, "time": 29378.591940641403, "episode/length": 270.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 626392, "time": 29385.26304268837, "episode/length": 267.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9738805970149254, "episode/intrinsic_return": 0.0}
{"step": 626393, "time": 29387.921543359756, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.9289886916893115, "train/action_min": 0.0, "train/action_std": 3.8060840972955674, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04210555931364281, "train/actor_opt_grad_steps": 38365.0, "train/actor_opt_loss": 1.9107635498478792, "train/adv_mag": 0.5758219298677169, "train/adv_max": 0.5340991871080537, "train/adv_mean": 0.004421378081673723, "train/adv_min": -0.43703763716030813, "train/adv_std": 0.060996783492357834, "train/cont_avg": 0.9945722939311594, "train/cont_loss_mean": 0.00014681377689683677, "train/cont_loss_std": 0.0044446708778913034, "train/cont_neg_acc": 0.9910340473271798, "train/cont_neg_loss": 0.018907843497188787, "train/cont_pos_acc": 0.9999857665835947, "train/cont_pos_loss": 4.854841159585493e-05, "train/cont_pred": 0.9945902258589647, "train/cont_rate": 0.9945722939311594, "train/dyn_loss_mean": 13.849659574204598, "train/dyn_loss_std": 9.300046630527662, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9539051751295725, "train/extr_critic_critic_opt_grad_steps": 38365.0, "train/extr_critic_critic_opt_loss": 16220.299656080164, "train/extr_critic_mag": 6.604074198266734, "train/extr_critic_max": 6.604074198266734, "train/extr_critic_mean": 1.846539824769117, "train/extr_critic_min": -0.28230142766150873, "train/extr_critic_std": 1.5427230527435525, "train/extr_return_normed_mag": 1.6455942927927212, "train/extr_return_normed_max": 1.6455942927927212, "train/extr_return_normed_mean": 0.3970186479281688, "train/extr_return_normed_min": -0.12019434233830459, "train/extr_return_normed_std": 0.32944393579078757, "train/extr_return_rate": 0.7400834482649098, "train/extr_return_raw_mag": 7.844138826149098, "train/extr_return_raw_max": 7.844138826149098, "train/extr_return_raw_mean": 1.8677368595980215, "train/extr_return_raw_min": -0.6086515300515769, "train/extr_return_raw_std": 1.5770635656688525, "train/extr_reward_mag": 1.0218922331713247, "train/extr_reward_max": 1.0218922331713247, "train/extr_reward_mean": 0.02872083521704527, "train/extr_reward_min": -0.388719852419867, "train/extr_reward_std": 0.16025821092552034, "train/image_loss_mean": 6.706322175869043, "train/image_loss_std": 11.156818859819053, "train/model_loss_mean": 15.07157966364985, "train/model_loss_std": 14.923359635947406, "train/model_opt_grad_norm": 56.60233858357305, "train/model_opt_grad_steps": 38329.49275362319, "train/model_opt_loss": 19373.992371490036, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1286.231884057971, "train/policy_entropy_mag": 2.401748906011167, "train/policy_entropy_max": 2.401748906011167, "train/policy_entropy_mean": 0.49706803629363794, "train/policy_entropy_min": 0.07937502364317577, "train/policy_entropy_std": 0.5452962619239006, "train/policy_logprob_mag": 7.438383769297945, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4977753907442093, "train/policy_logprob_min": -7.438383769297945, "train/policy_logprob_std": 1.0533998992995939, "train/policy_randomness_mag": 0.8477119673853335, "train/policy_randomness_max": 0.8477119673853335, "train/policy_randomness_mean": 0.17544320447073466, "train/policy_randomness_min": 0.028015899930851185, "train/policy_randomness_std": 0.19246565302213034, "train/post_ent_mag": 60.52824200063512, "train/post_ent_max": 60.52824200063512, "train/post_ent_mean": 43.524606649426445, "train/post_ent_min": 21.209934746009715, "train/post_ent_std": 7.615041318147079, "train/prior_ent_mag": 70.28593256853628, "train/prior_ent_max": 70.28593256853628, "train/prior_ent_mean": 57.4525143996529, "train/prior_ent_min": 41.64201501486958, "train/prior_ent_std": 4.48399463598279, "train/rep_loss_mean": 13.849659574204598, "train/rep_loss_std": 9.300046630527662, "train/reward_avg": 0.026075633789372187, "train/reward_loss_mean": 0.05531505041796228, "train/reward_loss_std": 0.24941989865855893, "train/reward_max_data": 1.0195652220560156, "train/reward_max_pred": 1.0121001912199932, "train/reward_neg_acc": 0.9926864366600479, "train/reward_neg_loss": 0.02989536052758711, "train/reward_pos_acc": 0.9669878556244615, "train/reward_pos_loss": 0.8589411701845087, "train/reward_pred": 0.025327085321634146, "train/reward_rate": 0.030959861865942028, "train_stats/sum_log_reward": 7.5134616654652815, "train_stats/max_log_achievement_collect_coal": 0.15384615384615385, "train_stats/max_log_achievement_collect_drink": 6.894230769230769, "train_stats/max_log_achievement_collect_sapling": 1.9519230769230769, "train_stats/max_log_achievement_collect_stone": 2.1634615384615383, "train_stats/max_log_achievement_collect_wood": 13.057692307692308, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5192307692307693, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5961538461538463, "train_stats/max_log_achievement_make_wood_sword": 1.3461538461538463, "train_stats/max_log_achievement_place_furnace": 0.028846153846153848, "train_stats/max_log_achievement_place_plant": 1.9134615384615385, "train_stats/max_log_achievement_place_stone": 0.125, "train_stats/max_log_achievement_place_table": 3.548076923076923, "train_stats/max_log_achievement_wake_up": 1.0673076923076923, "train_stats/mean_log_entropy": 0.4472481075387735, "eval_stats/sum_log_reward": 7.1000001430511475, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.25, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 0.5625, "eval_stats/max_log_achievement_collect_wood": 12.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00035690245567820966, "report/cont_loss_std": 0.00962966401129961, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001354628475382924, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0003579889889806509, "report/cont_pred": 0.9948039054870605, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.282626152038574, "report/dyn_loss_std": 9.109294891357422, "report/image_loss_mean": 7.760621070861816, "report/image_loss_std": 10.441299438476562, "report/model_loss_mean": 16.989669799804688, "report/model_loss_std": 14.303289413452148, "report/post_ent_mag": 61.51567840576172, "report/post_ent_max": 61.51567840576172, "report/post_ent_mean": 43.496978759765625, "report/post_ent_min": 20.759796142578125, "report/post_ent_std": 7.776924133300781, "report/prior_ent_mag": 70.30445098876953, "report/prior_ent_max": 70.30445098876953, "report/prior_ent_mean": 58.40537643432617, "report/prior_ent_min": 44.97309875488281, "report/prior_ent_std": 4.139489650726318, "report/rep_loss_mean": 15.282626152038574, "report/rep_loss_std": 9.109294891357422, "report/reward_avg": 0.02294921875, "report/reward_loss_mean": 0.059115514159202576, "report/reward_loss_std": 0.3046129047870636, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.1055576801300049, "report/reward_neg_acc": 0.994979977607727, "report/reward_neg_loss": 0.02751072496175766, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 1.1833431720733643, "report/reward_pred": 0.019171003252267838, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 5.963460125713027e-07, "eval/cont_loss_std": 9.740808309288695e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00010841409675776958, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.730903834295532e-08, "eval/cont_pred": 0.995117723941803, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 16.59703826904297, "eval/dyn_loss_std": 10.67920970916748, "eval/image_loss_mean": 9.777511596679688, "eval/image_loss_std": 13.92371654510498, "eval/model_loss_mean": 19.808734893798828, "eval/model_loss_std": 18.08354949951172, "eval/post_ent_mag": 60.763912200927734, "eval/post_ent_max": 60.763912200927734, "eval/post_ent_mean": 43.4471435546875, "eval/post_ent_min": 21.664260864257812, "eval/post_ent_std": 7.730584144592285, "eval/prior_ent_mag": 70.30445098876953, "eval/prior_ent_max": 70.30445098876953, "eval/prior_ent_mean": 57.57142639160156, "eval/prior_ent_min": 41.21990966796875, "eval/prior_ent_std": 4.382615089416504, "eval/rep_loss_mean": 16.59703826904297, "eval/rep_loss_std": 10.67920970916748, "eval/reward_avg": 0.02880859375, "eval/reward_loss_mean": 0.07299990206956863, "eval/reward_loss_std": 0.5049673914909363, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0021939277648926, "eval/reward_neg_acc": 0.9939454793930054, "eval/reward_neg_loss": 0.0291113443672657, "eval/reward_pos_acc": 0.9090908765792847, "eval/reward_pos_loss": 1.390986442565918, "eval/reward_pred": 0.026876460760831833, "eval/reward_rate": 0.0322265625, "replay/size": 625889.0, "replay/inserts": 22120.0, "replay/samples": 22128.0, "replay/insert_wait_avg": 1.3607858964806224e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.264827871701895e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.174871484301082e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.9209010601044, "timer/env.step_count": 2765.0, "timer/env.step_total": 243.92298460006714, "timer/env.step_frac": 0.2436985623356663, "timer/env.step_avg": 0.08821807761304418, "timer/env.step_min": 0.024429798126220703, "timer/env.step_max": 3.492457389831543, "timer/replay._sample_count": 22128.0, "timer/replay._sample_total": 11.461962938308716, "timer/replay._sample_frac": 0.011451417315962747, "timer/replay._sample_avg": 0.0005179845868722305, "timer/replay._sample_min": 0.0004220008850097656, "timer/replay._sample_max": 0.011138439178466797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3343.0, "timer/agent.policy_total": 57.50453853607178, "timer/agent.policy_frac": 0.057451631267932415, "timer/agent.policy_avg": 0.017201477276719047, "timer/agent.policy_min": 0.009801387786865234, "timer/agent.policy_max": 0.11475515365600586, "timer/dataset_train_count": 1383.0, "timer/dataset_train_total": 0.1639547348022461, "timer/dataset_train_frac": 0.00016380388762847982, "timer/dataset_train_avg": 0.00011855006131760382, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.0006136894226074219, "timer/agent.train_count": 1383.0, "timer/agent.train_total": 626.1954345703125, "timer/agent.train_frac": 0.6256193010927145, "timer/agent.train_avg": 0.45278050222003796, "timer/agent.train_min": 0.43460917472839355, "timer/agent.train_max": 2.130263566970825, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4827132225036621, "timer/agent.report_frac": 0.0004822691003778686, "timer/agent.report_avg": 0.24135661125183105, "timer/agent.report_min": 0.2356095314025879, "timer/agent.report_max": 0.24710369110107422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.8583906542350726e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 22.099339763569976}
{"step": 627072, "time": 29411.01704096794, "episode/length": 157.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 627264, "time": 29419.625606298447, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 627264, "time": 29419.6346719265, "episode/length": 126.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 627712, "time": 29438.180414676666, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 627720, "time": 29439.927574396133, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 628288, "time": 29460.90755033493, "episode/length": 371.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 628544, "time": 29471.30369734764, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 628600, "time": 29474.664755821228, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 628752, "time": 29481.482584953308, "episode/length": 57.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 628888, "time": 29487.36497783661, "episode/length": 145.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 628904, "time": 29489.473875761032, "episode/length": 44.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 629136, "time": 29499.146466732025, "episode/length": 487.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9979508196721312, "episode/intrinsic_return": 0.0}
{"step": 629368, "time": 29508.578143835068, "episode/length": 57.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9482758620689655, "episode/intrinsic_return": 0.0}
{"step": 629440, "time": 29512.853283405304, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 29551.606767892838, "eval_episode/length": 60.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 630032, "time": 29557.901026964188, "eval_episode/length": 159.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 630032, "time": 29560.71701335907, "eval_episode/length": 184.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 630032, "time": 29562.582466602325, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 630032, "time": 29565.383315324783, "eval_episode/length": 217.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9862385321100917}
{"step": 630032, "time": 29567.002403736115, "eval_episode/length": 218.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 630032, "time": 29575.755046606064, "eval_episode/length": 192.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 630032, "time": 29578.423262119293, "eval_episode/length": 400.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9775561097256857}
{"step": 630048, "time": 29578.967244148254, "episode/length": 347.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 630192, "time": 29585.433648586273, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 630240, "time": 29588.558147907257, "episode/length": 204.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 630736, "time": 29607.016234874725, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 630736, "time": 29607.02590751648, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 630832, "time": 29615.19606566429, "episode/length": 97.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 631032, "time": 29623.482609033585, "episode/length": 579.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9982758620689656, "episode/intrinsic_return": 0.0}
{"step": 631272, "time": 29633.152751922607, "episode/length": 134.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 631288, "time": 29635.86028933525, "episode/length": 268.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 631600, "time": 29648.813494205475, "episode/length": 169.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 631672, "time": 29652.76870727539, "episode/length": 47.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 632000, "time": 29665.61898779869, "episode/length": 388.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9845758354755784, "episode/intrinsic_return": 0.0}
{"step": 632256, "time": 29675.86643719673, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 632336, "time": 29680.273774385452, "episode/length": 187.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 632376, "time": 29682.916313648224, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 632464, "time": 29687.661543130875, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 632472, "time": 29689.336314439774, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 632728, "time": 29699.44709801674, "episode/length": 31.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 632768, "time": 29702.645973205566, "episode/length": 48.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 632808, "time": 29705.456256389618, "episode/length": 141.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 632928, "time": 29711.482036828995, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 633192, "time": 29721.7221159935, "episode/length": 47.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 633472, "time": 29732.88561272621, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 633792, "time": 29745.30421090126, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 634104, "time": 29757.238151311874, "episode/length": 230.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 634208, "time": 29762.516573667526, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 634376, "time": 29769.771718740463, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 634920, "time": 29789.771856307983, "episode/length": 215.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 634960, "time": 29792.96681523323, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 635016, "time": 29796.18709731102, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 635544, "time": 29815.771076202393, "episode/length": 400.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 635560, "time": 29817.86674308777, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 635696, "time": 29824.31701374054, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 635720, "time": 29826.445648431778, "episode/length": 240.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 636616, "time": 29859.239609003067, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 636912, "time": 29871.2607254982, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 637056, "time": 29877.591948270798, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 637064, "time": 29879.26095700264, "episode/length": 335.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 637088, "time": 29881.892154216766, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 637240, "time": 29888.427040815353, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 637328, "time": 29893.356216430664, "episode/length": 288.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 638328, "time": 29928.53088903427, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 638408, "time": 29933.18906235695, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 638640, "time": 29942.8039624691, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 638680, "time": 29945.512753725052, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 638792, "time": 29950.95526123047, "episode/length": 182.0, "episode/score": 7.100000061094761, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 638992, "time": 29961.064614772797, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 639168, "time": 29968.50795865059, "episode/length": 525.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9980988593155894, "episode/intrinsic_return": 0.0}
{"step": 639248, "time": 29972.81561899185, "episode/length": 31.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 639848, "time": 29994.723431110382, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 640000, "time": 30001.63995552063, "episode/length": 366.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 30024.622411251068, "eval_episode/length": 134.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 640016, "time": 30028.040952444077, "eval_episode/length": 38.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 640016, "time": 30029.81137228012, "eval_episode/length": 176.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 640016, "time": 30032.627554655075, "eval_episode/length": 202.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 640016, "time": 30034.41142296791, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9710144927536232}
{"step": 640016, "time": 30036.135172128677, "eval_episode/length": 207.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 640016, "time": 30041.68510556221, "eval_episode/length": 240.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.966804979253112}
{"step": 640016, "time": 30043.67548251152, "eval_episode/length": 246.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9757085020242915}
{"step": 640136, "time": 30047.53357553482, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 640320, "time": 30055.52663087845, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 640360, "time": 30058.194365262985, "episode/length": 243.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 640536, "time": 30065.751477718353, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 640536, "time": 30065.761900663376, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 640960, "time": 30083.77099633217, "episode/length": 52.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 641088, "time": 30089.758865118027, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 641136, "time": 30092.911635160446, "episode/length": 292.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9897610921501706, "episode/intrinsic_return": 0.0}
{"step": 641696, "time": 30113.61371231079, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 642248, "time": 30133.737122297287, "episode/length": 138.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 642288, "time": 30136.92329287529, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 642408, "time": 30142.33767771721, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 642448, "time": 30145.42712688446, "episode/length": 265.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 642592, "time": 30151.803742408752, "episode/length": 42.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9069767441860465, "episode/intrinsic_return": 0.0}
{"step": 642656, "time": 30155.672517061234, "episode/length": 331.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 643232, "time": 30176.82007265091, "episode/length": 336.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 643352, "time": 30182.221017837524, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 643560, "time": 30190.92458128929, "episode/length": 158.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 643640, "time": 30195.13255763054, "episode/length": 318.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 643864, "time": 30204.327818393707, "episode/length": 181.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 644080, "time": 30213.404671430588, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 644304, "time": 30222.690017461777, "episode/length": 231.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 644528, "time": 30231.785338163376, "episode/length": 161.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 644672, "time": 30238.209380865097, "episode/length": 251.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 644832, "time": 30245.109140396118, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 644856, "time": 30247.21719455719, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 644984, "time": 30253.2162566185, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 645848, "time": 30284.065899848938, "episode/length": 146.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9727891156462585, "episode/intrinsic_return": 0.0}
{"step": 645944, "time": 30288.87072944641, "episode/length": 204.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 645952, "time": 30291.04356598854, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 646120, "time": 30298.443464756012, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 646248, "time": 30305.49432992935, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 646936, "time": 30330.469650268555, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 647096, "time": 30337.431270599365, "episode/length": 279.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 647408, "time": 30351.45796775818, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 647584, "time": 30358.97387456894, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 647744, "time": 30365.99297952652, "episode/length": 19.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.85, "episode/intrinsic_return": 0.0}
{"step": 647784, "time": 30368.750471830368, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 647872, "time": 30373.741243362427, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 648040, "time": 30380.82698893547, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 648185, "time": 30388.257115840912, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.947135476505055, "train/action_min": 0.0, "train/action_std": 3.8156182923737694, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.040128132492742115, "train/actor_opt_grad_steps": 39735.0, "train/actor_opt_loss": -1.5017727385548985, "train/adv_mag": 0.572857021847192, "train/adv_max": 0.5367690419011256, "train/adv_mean": 0.004125135867485262, "train/adv_min": -0.4188486852628343, "train/adv_std": 0.05864227168700274, "train/cont_avg": 0.9950022977941176, "train/cont_loss_mean": 0.0001673962703041412, "train/cont_loss_std": 0.0049134936517109444, "train/cont_neg_acc": 0.9938025224734756, "train/cont_neg_loss": 0.014430041071829644, "train/cont_pos_acc": 0.9999638677519911, "train/cont_pos_loss": 9.228416556496827e-05, "train/cont_pred": 0.9949899482376435, "train/cont_rate": 0.9950022977941176, "train/dyn_loss_mean": 13.913826907382292, "train/dyn_loss_std": 9.297587394714355, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9169248802696958, "train/extr_critic_critic_opt_grad_steps": 39735.0, "train/extr_critic_critic_opt_loss": 15893.676958869486, "train/extr_critic_mag": 6.88019061088562, "train/extr_critic_max": 6.88019061088562, "train/extr_critic_mean": 2.068053994985188, "train/extr_critic_min": -0.25279271076707277, "train/extr_critic_std": 1.630159960950122, "train/extr_return_normed_mag": 1.609162120258107, "train/extr_return_normed_max": 1.609162120258107, "train/extr_return_normed_mean": 0.40523214682060127, "train/extr_return_normed_min": -0.11767118196824894, "train/extr_return_normed_std": 0.3265245480134207, "train/extr_return_rate": 0.7890678070047322, "train/extr_return_raw_mag": 8.233493969720953, "train/extr_return_raw_max": 8.233493969720953, "train/extr_return_raw_mean": 2.089050861842492, "train/extr_return_raw_min": -0.5791497874785873, "train/extr_return_raw_std": 1.6666182568844627, "train/extr_reward_mag": 1.026370462249307, "train/extr_reward_max": 1.026370462249307, "train/extr_reward_mean": 0.030382951249039787, "train/extr_reward_min": -0.39793067995239706, "train/extr_reward_std": 0.16519935193526394, "train/image_loss_mean": 6.644530054400949, "train/image_loss_std": 11.201171138707329, "train/model_loss_mean": 15.047481677111458, "train/model_loss_std": 14.983195473166074, "train/model_opt_grad_norm": 56.72328395002029, "train/model_opt_grad_steps": 39698.25, "train/model_opt_loss": 19569.158325195312, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1305.1470588235295, "train/policy_entropy_mag": 2.376286480356665, "train/policy_entropy_max": 2.376286480356665, "train/policy_entropy_mean": 0.4866924250827116, "train/policy_entropy_min": 0.07937502565191072, "train/policy_entropy_std": 0.5441822979380103, "train/policy_logprob_mag": 7.43838379312964, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.486135022386032, "train/policy_logprob_min": -7.43838379312964, "train/policy_logprob_std": 1.046445857076084, "train/policy_randomness_mag": 0.8387248476638514, "train/policy_randomness_max": 0.8387248476638514, "train/policy_randomness_mean": 0.1717810679007979, "train/policy_randomness_min": 0.028015900649787748, "train/policy_randomness_std": 0.1920724703985102, "train/post_ent_mag": 60.64021107729744, "train/post_ent_max": 60.64021107729744, "train/post_ent_mean": 43.49645163031185, "train/post_ent_min": 21.040643509696512, "train/post_ent_std": 7.641764170983258, "train/prior_ent_mag": 70.34134023329791, "train/prior_ent_max": 70.34134023329791, "train/prior_ent_mean": 57.47672086603501, "train/prior_ent_min": 42.3875358244952, "train/prior_ent_std": 4.419350073618047, "train/rep_loss_mean": 13.913826907382292, "train/rep_loss_std": 9.297587394714355, "train/reward_avg": 0.02657686096876312, "train/reward_loss_mean": 0.054487989475841034, "train/reward_loss_std": 0.2472194995292846, "train/reward_max_data": 1.0183823573238708, "train/reward_max_pred": 1.0135541260242462, "train/reward_neg_acc": 0.992770324296811, "train/reward_neg_loss": 0.028941212276763776, "train/reward_pos_acc": 0.9656753049177282, "train/reward_pos_loss": 0.8552573099732399, "train/reward_pred": 0.025818045935867465, "train/reward_rate": 0.031328986672794115, "train_stats/sum_log_reward": 7.166666766007741, "train_stats/max_log_achievement_collect_coal": 0.1523809523809524, "train_stats/max_log_achievement_collect_drink": 5.914285714285715, "train_stats/max_log_achievement_collect_sapling": 1.7714285714285714, "train_stats/max_log_achievement_collect_stone": 2.1142857142857143, "train_stats/max_log_achievement_collect_wood": 12.80952380952381, "train_stats/max_log_achievement_defeat_skeleton": 0.009523809523809525, "train_stats/max_log_achievement_defeat_zombie": 0.49523809523809526, "train_stats/max_log_achievement_eat_cow": 0.14285714285714285, "train_stats/max_log_achievement_make_stone_sword": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4476190476190476, "train_stats/max_log_achievement_make_wood_sword": 1.7333333333333334, "train_stats/max_log_achievement_place_furnace": 0.02857142857142857, "train_stats/max_log_achievement_place_plant": 1.7523809523809524, "train_stats/max_log_achievement_place_stone": 0.09523809523809523, "train_stats/max_log_achievement_place_table": 3.380952380952381, "train_stats/max_log_achievement_wake_up": 1.0571428571428572, "train_stats/mean_log_entropy": 0.4380615113746552, "eval_stats/sum_log_reward": 7.475000113248825, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_sapling": 2.5, "eval_stats/max_log_achievement_collect_stone": 1.5625, "eval_stats/max_log_achievement_collect_wood": 12.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.6875, "eval_stats/max_log_achievement_make_wood_sword": 2.8125, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.5, "eval_stats/max_log_achievement_place_stone": 0.125, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.038562555157114e-06, "report/cont_loss_std": 0.00011776753672165796, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.000546891416888684, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.394534127844963e-06, "report/cont_pred": 0.9951146245002747, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.038820266723633, "report/dyn_loss_std": 8.965209007263184, "report/image_loss_mean": 5.61673641204834, "report/image_loss_std": 11.897076606750488, "report/model_loss_mean": 14.089526176452637, "report/model_loss_std": 15.7893648147583, "report/post_ent_mag": 61.354148864746094, "report/post_ent_max": 61.354148864746094, "report/post_ent_mean": 43.15590286254883, "report/post_ent_min": 22.00177764892578, "report/post_ent_std": 7.313000202178955, "report/prior_ent_mag": 70.04399871826172, "report/prior_ent_max": 70.04399871826172, "report/prior_ent_mean": 57.343666076660156, "report/prior_ent_min": 43.3553352355957, "report/prior_ent_std": 4.096392631530762, "report/rep_loss_mean": 14.038820266723633, "report/rep_loss_std": 8.965209007263184, "report/reward_avg": 0.02998046949505806, "report/reward_loss_mean": 0.04948879033327103, "report/reward_loss_std": 0.20290809869766235, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0039870738983154, "report/reward_neg_acc": 0.9949442744255066, "report/reward_neg_loss": 0.02327023074030876, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.7903503179550171, "report/reward_pred": 0.028382999822497368, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0001677784021012485, "eval/cont_loss_std": 0.004332639276981354, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.03415869548916817, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.927565542966477e-07, "eval/cont_pred": 0.9952740669250488, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.825559616088867, "eval/dyn_loss_std": 10.526435852050781, "eval/image_loss_mean": 14.765741348266602, "eval/image_loss_std": 17.970069885253906, "eval/model_loss_mean": 26.75029754638672, "eval/model_loss_std": 22.01724624633789, "eval/post_ent_mag": 59.27728271484375, "eval/post_ent_max": 59.27728271484375, "eval/post_ent_mean": 40.98736572265625, "eval/post_ent_min": 22.907344818115234, "eval/post_ent_std": 7.056507587432861, "eval/prior_ent_mag": 70.04399871826172, "eval/prior_ent_max": 70.04399871826172, "eval/prior_ent_mean": 58.009395599365234, "eval/prior_ent_min": 41.30113983154297, "eval/prior_ent_std": 4.111143589019775, "eval/rep_loss_mean": 19.825559616088867, "eval/rep_loss_std": 10.526435852050781, "eval/reward_avg": 0.02988281100988388, "eval/reward_loss_mean": 0.08905205130577087, "eval/reward_loss_std": 0.4091172516345978, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0021512508392334, "eval/reward_neg_acc": 0.9817814230918884, "eval/reward_neg_loss": 0.06204704940319061, "eval/reward_pos_acc": 1.0, "eval/reward_pos_loss": 0.8301893472671509, "eval/reward_pred": 0.03670318052172661, "eval/reward_rate": 0.03515625, "replay/size": 647681.0, "replay/inserts": 21792.0, "replay/samples": 21792.0, "replay/insert_wait_avg": 1.3425267915543656e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.262620281718026e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5184.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1776976379347436e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3191184997559, "timer/env.step_count": 2724.0, "timer/env.step_total": 247.28942227363586, "timer/env.step_frac": 0.24721053281927874, "timer/env.step_avg": 0.090781726238486, "timer/env.step_min": 0.024282455444335938, "timer/env.step_max": 3.4011640548706055, "timer/replay._sample_count": 21792.0, "timer/replay._sample_total": 11.300756216049194, "timer/replay._sample_frac": 0.011297151086143068, "timer/replay._sample_avg": 0.0005185736149068095, "timer/replay._sample_min": 0.00041413307189941406, "timer/replay._sample_max": 0.01025080680847168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3372.0, "timer/agent.policy_total": 59.15065574645996, "timer/agent.policy_frac": 0.05913178569971958, "timer/agent.policy_avg": 0.01754171285482205, "timer/agent.policy_min": 0.009536266326904297, "timer/agent.policy_max": 0.1409142017364502, "timer/dataset_train_count": 1362.0, "timer/dataset_train_total": 0.1616230010986328, "timer/dataset_train_frac": 0.0001615714406628851, "timer/dataset_train_avg": 0.00011866593325890809, "timer/dataset_train_min": 0.00010275840759277344, "timer/dataset_train_max": 0.00030493736267089844, "timer/agent.train_count": 1362.0, "timer/agent.train_total": 615.8115508556366, "timer/agent.train_frac": 0.6156150966895539, "timer/agent.train_avg": 0.4521377025371781, "timer/agent.train_min": 0.43917369842529297, "timer/agent.train_max": 1.6242153644561768, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48490142822265625, "timer/agent.report_frac": 0.0004847467365713201, "timer/agent.report_avg": 0.24245071411132812, "timer/agent.report_min": 0.23479008674621582, "timer/agent.report_max": 0.25011134147644043, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 8.106231689453125e-05, "timer/dataset_eval_frac": 8.103645666205572e-08, "timer/dataset_eval_avg": 8.106231689453125e-05, "timer/dataset_eval_min": 8.106231689453125e-05, "timer/dataset_eval_max": 8.106231689453125e-05, "fps": 21.78472473574348}
{"step": 648496, "time": 30398.861234903336, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 648984, "time": 30416.868356704712, "episode/length": 138.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9568345323741008, "episode/intrinsic_return": 0.0}
{"step": 649120, "time": 30423.33509039879, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 649184, "time": 30427.13936495781, "episode/length": 221.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 649208, "time": 30429.317826271057, "episode/length": 182.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 649744, "time": 30449.362713336945, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 649856, "time": 30454.976541042328, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 30476.240772247314, "eval_episode/length": 41.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 650000, "time": 30478.019929647446, "eval_episode/length": 46.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 650000, "time": 30484.76591348648, "eval_episode/length": 160.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9751552795031055}
{"step": 650000, "time": 30487.273348093033, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 650000, "time": 30489.10576558113, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 650000, "time": 30491.406383037567, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9635416666666666}
{"step": 650000, "time": 30494.233926534653, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 650000, "time": 30498.879451990128, "eval_episode/length": 243.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9795081967213115}
{"step": 650120, "time": 30502.704240322113, "episode/length": 520.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9865642994241842, "episode/intrinsic_return": 0.0}
{"step": 650248, "time": 30508.6582403183, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 650480, "time": 30518.244411706924, "episode/length": 169.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 651136, "time": 30542.19332575798, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 651520, "time": 30556.947234153748, "episode/length": 174.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 651688, "time": 30564.478625535965, "episode/length": 228.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 651752, "time": 30568.31401205063, "episode/length": 495.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 651896, "time": 30575.584610939026, "episode/length": 205.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 652136, "time": 30585.712075710297, "episode/length": 365.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 652648, "time": 30604.82389163971, "episode/length": 188.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 652688, "time": 30608.007927417755, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 653312, "time": 30630.874244213104, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 653352, "time": 30633.58913230896, "episode/length": 181.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 653416, "time": 30637.348272800446, "episode/length": 236.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 653432, "time": 30639.410300016403, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 653952, "time": 30658.982530593872, "episode/length": 282.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 654080, "time": 30664.980234384537, "episode/length": 611.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 654648, "time": 30685.72671198845, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 654704, "time": 30689.396033763885, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 654768, "time": 30693.185219049454, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 654832, "time": 30697.00300502777, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 654864, "time": 30699.800706863403, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 655400, "time": 30720.96777200699, "episode/length": 260.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 655648, "time": 30731.34343314171, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 656112, "time": 30748.599908590317, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 656240, "time": 30754.56049466133, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 656456, "time": 30763.38025045395, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 656624, "time": 30770.8190202713, "episode/length": 219.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 656936, "time": 30782.691717863083, "episode/length": 160.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 657144, "time": 30791.400958776474, "episode/length": 217.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 657336, "time": 30799.373437404633, "episode/length": 406.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 657480, "time": 30805.761685609818, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 657552, "time": 30810.220649003983, "episode/length": 136.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 657672, "time": 30815.605511188507, "episode/length": 377.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9894179894179894, "episode/intrinsic_return": 0.0}
{"step": 658016, "time": 30829.218254566193, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 658248, "time": 30838.326785087585, "episode/length": 250.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 658392, "time": 30844.699556589127, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 658552, "time": 30851.739901542664, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 658672, "time": 30857.487693548203, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 658896, "time": 30866.639340639114, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 659136, "time": 30876.3124628067, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 659272, "time": 30882.26935362816, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 659472, "time": 30890.80868935585, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 660040, "time": 30911.326734304428, "episode/length": 205.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 660088, "time": 30931.660270929337, "eval_episode/length": 42.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9069767441860465}
{"step": 660088, "time": 30939.97642326355, "eval_episode/length": 151.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 660088, "time": 30943.329383850098, "eval_episode/length": 184.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 660088, "time": 30945.681907892227, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 660088, "time": 30949.94753718376, "eval_episode/length": 255.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.98046875}
{"step": 660088, "time": 30952.21569752693, "eval_episode/length": 271.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9816176470588235}
{"step": 660088, "time": 30954.974101781845, "eval_episode/length": 296.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9966329966329966}
{"step": 660088, "time": 30957.473326683044, "eval_episode/length": 274.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9745454545454545}
{"step": 660144, "time": 30959.589648485184, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 660160, "time": 30961.64145731926, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 660312, "time": 30968.066657304764, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 660320, "time": 30970.19165301323, "episode/length": 330.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 660496, "time": 30977.604873657227, "episode/length": 169.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 660664, "time": 30984.577520608902, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 660880, "time": 30993.754366874695, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 661512, "time": 31016.595010995865, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 661600, "time": 31021.348412036896, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 661720, "time": 31026.712178707123, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 661744, "time": 31029.345390558243, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 661776, "time": 31032.13678908348, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 661872, "time": 31037.062975406647, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 661904, "time": 31039.705045461655, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 662440, "time": 31059.097477197647, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 662824, "time": 31073.877534151077, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 662960, "time": 31080.32606101036, "episode/length": 147.0, "episode/score": 9.099999956786633, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 663056, "time": 31085.172914266586, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 663384, "time": 31097.784608364105, "episode/length": 188.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 664200, "time": 31128.251769304276, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 664248, "time": 31131.489738464355, "episode/length": 315.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 664272, "time": 31134.081160783768, "episode/length": 344.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 664464, "time": 31142.030586004257, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 665328, "time": 31172.94189310074, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 665600, "time": 31183.795716285706, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 665792, "time": 31191.88165998459, "episode/length": 418.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9976133651551312, "episode/intrinsic_return": 0.0}
{"step": 665816, "time": 31194.152155160904, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 665888, "time": 31198.430218458176, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 665976, "time": 31202.75770354271, "episode/length": 508.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823182711198428, "episode/intrinsic_return": 0.0}
{"step": 666232, "time": 31213.212767362595, "episode/length": 408.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 666792, "time": 31233.525414705276, "episode/length": 317.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 666840, "time": 31236.751590013504, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 667120, "time": 31247.99977350235, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 667192, "time": 31251.8176612854, "episode/length": 151.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 667472, "time": 31263.14807319641, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 667536, "time": 31266.834616422653, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 667864, "time": 31279.34677004814, "episode/length": 246.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 667944, "time": 31283.668359041214, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 668360, "time": 31299.186116456985, "episode/length": 189.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 668408, "time": 31302.519743442535, "episode/length": 201.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 668624, "time": 31311.685804605484, "episode/length": 178.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9553072625698324, "episode/intrinsic_return": 0.0}
{"step": 668776, "time": 31318.20098567009, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 668952, "time": 31325.757431030273, "episode/length": 228.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 668952, "time": 31325.7666182518, "episode/length": 135.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 669272, "time": 31339.95264196396, "episode/length": 165.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 669288, "time": 31342.198308706284, "episode/length": 218.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 669744, "time": 31359.40638399124, "episode/length": 56.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 669760, "time": 31361.645335674286, "episode/length": 168.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 670024, "time": 31371.934993982315, "episode/length": 174.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 670032, "time": 31374.033771038055, "episode/length": 208.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 31392.455206632614, "eval_episode/length": 56.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 670072, "time": 31394.240548849106, "eval_episode/length": 59.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9333333333333333}
{"step": 670072, "time": 31400.340871810913, "eval_episode/length": 163.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 670072, "time": 31402.17605781555, "eval_episode/length": 169.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 670072, "time": 31405.83163166046, "eval_episode/length": 152.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 670072, "time": 31409.200136184692, "eval_episode/length": 194.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 670072, "time": 31411.708780765533, "eval_episode/length": 272.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 670072, "time": 31413.849016666412, "eval_episode/length": 284.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9964912280701754}
{"step": 670073, "time": 31414.907802581787, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.922856908645073, "train/action_min": 0.0, "train/action_std": 3.8361575516471027, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039593739856551166, "train/actor_opt_grad_steps": 41100.0, "train/actor_opt_loss": -8.14780401292998, "train/adv_mag": 0.5262922468411662, "train/adv_max": 0.4836160575386381, "train/adv_mean": 0.002091684281175113, "train/adv_min": -0.4101359086097592, "train/adv_std": 0.05671435037124766, "train/cont_avg": 0.994803546989051, "train/cont_loss_mean": 0.0001491990906416889, "train/cont_loss_std": 0.004546499775415628, "train/cont_neg_acc": 0.9960171571549248, "train/cont_neg_loss": 0.01863636304167926, "train/cont_pos_acc": 0.9999784727166169, "train/cont_pos_loss": 5.568432491090382e-05, "train/cont_pred": 0.9948033816622992, "train/cont_rate": 0.994803546989051, "train/dyn_loss_mean": 13.717177001229167, "train/dyn_loss_std": 9.34471642013884, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9042065626513349, "train/extr_critic_critic_opt_grad_steps": 41100.0, "train/extr_critic_critic_opt_loss": 15543.956931455292, "train/extr_critic_mag": 7.121522426605225, "train/extr_critic_max": 7.121522426605225, "train/extr_critic_mean": 2.127609066719556, "train/extr_critic_min": -0.2567711946738027, "train/extr_critic_std": 1.647467512283882, "train/extr_return_normed_mag": 1.5896546788459276, "train/extr_return_normed_max": 1.5896546788459276, "train/extr_return_normed_mean": 0.4013544334112293, "train/extr_return_normed_min": -0.1112412014146791, "train/extr_return_normed_std": 0.3197195648494428, "train/extr_return_rate": 0.8060271687751269, "train/extr_return_raw_mag": 8.370936376334978, "train/extr_return_raw_max": 8.370936376334978, "train/extr_return_raw_mean": 2.138576657232577, "train/extr_return_raw_min": -0.5502181792781301, "train/extr_return_raw_std": 1.6770585523034534, "train/extr_reward_mag": 1.0239752765989651, "train/extr_reward_max": 1.0239752765989651, "train/extr_reward_mean": 0.03151754818747948, "train/extr_reward_min": -0.40941283998698214, "train/extr_reward_std": 0.1672576332505602, "train/image_loss_mean": 6.492675885666896, "train/image_loss_std": 11.14421175518175, "train/model_loss_mean": 14.778529195019798, "train/model_loss_std": 14.945963845635852, "train/model_opt_grad_norm": 57.185898430207196, "train/model_opt_grad_steps": 41061.88321167883, "train/model_opt_loss": 20108.305564267794, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 1350.3649635036497, "train/policy_entropy_mag": 2.3829819634012934, "train/policy_entropy_max": 2.3829819634012934, "train/policy_entropy_mean": 0.4674144524292354, "train/policy_entropy_min": 0.07937502409637409, "train/policy_entropy_std": 0.5231815024013937, "train/policy_logprob_mag": 7.4383838298547005, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4672297678724693, "train/policy_logprob_min": -7.4383838298547005, "train/policy_logprob_std": 1.0398127223453382, "train/policy_randomness_mag": 0.8410880613501055, "train/policy_randomness_max": 0.8410880613501055, "train/policy_randomness_mean": 0.16497678913339212, "train/policy_randomness_min": 0.028015900131342183, "train/policy_randomness_std": 0.1846601121181989, "train/post_ent_mag": 60.558041370698135, "train/post_ent_max": 60.558041370698135, "train/post_ent_mean": 43.68234695657326, "train/post_ent_min": 20.91748454797007, "train/post_ent_std": 7.680291677043385, "train/prior_ent_mag": 70.26597166409458, "train/prior_ent_max": 70.26597166409458, "train/prior_ent_mean": 57.49642688166486, "train/prior_ent_min": 42.29992366707238, "train/prior_ent_std": 4.424522159743483, "train/rep_loss_mean": 13.717177001229167, "train/rep_loss_std": 9.34471642013884, "train/reward_avg": 0.027283160219879917, "train/reward_loss_mean": 0.05539798502721926, "train/reward_loss_std": 0.2497226384869457, "train/reward_max_data": 1.0160583979892035, "train/reward_max_pred": 1.010665883112998, "train/reward_neg_acc": 0.9928456531823987, "train/reward_neg_loss": 0.029034885917756246, "train/reward_pos_acc": 0.9638875074630237, "train/reward_pos_loss": 0.8562303115851688, "train/reward_pred": 0.02643197546475125, "train/reward_rate": 0.03194856295620438, "train_stats/sum_log_reward": 7.78316843627703, "train_stats/max_log_achievement_collect_coal": 0.21782178217821782, "train_stats/max_log_achievement_collect_drink": 6.475247524752476, "train_stats/max_log_achievement_collect_sapling": 2.0792079207920793, "train_stats/max_log_achievement_collect_stone": 2.0396039603960396, "train_stats/max_log_achievement_collect_wood": 13.584158415841584, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5544554455445545, "train_stats/max_log_achievement_eat_cow": 0.18811881188118812, "train_stats/max_log_achievement_make_stone_sword": 0.009900990099009901, "train_stats/max_log_achievement_make_wood_pickaxe": 2.0297029702970297, "train_stats/max_log_achievement_make_wood_sword": 1.4752475247524752, "train_stats/max_log_achievement_place_furnace": 0.06930693069306931, "train_stats/max_log_achievement_place_plant": 2.0594059405940595, "train_stats/max_log_achievement_place_stone": 0.21782178217821782, "train_stats/max_log_achievement_place_table": 3.9405940594059405, "train_stats/max_log_achievement_wake_up": 1.1782178217821782, "train_stats/mean_log_entropy": 0.4504068788915577, "eval_stats/sum_log_reward": 7.141666829586029, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 5.083333333333333, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 0.625, "eval_stats/max_log_achievement_collect_wood": 10.916666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.3333333333333333, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.2083333333333335, "eval_stats/max_log_achievement_place_stone": 0.041666666666666664, "eval_stats/max_log_achievement_place_table": 3.125, "eval_stats/max_log_achievement_wake_up": 0.9166666666666666, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_eat_plant": 0.011363636363636364, "eval_stats/max_log_achievement_eat_plant": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.655972472595749e-07, "report/cont_loss_std": 3.989203378296224e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.583798600942828e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.945878231410461e-07, "report/cont_pred": 0.9921872615814209, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.463579177856445, "report/dyn_loss_std": 9.450108528137207, "report/image_loss_mean": 4.257523536682129, "report/image_loss_std": 8.888042449951172, "report/model_loss_mean": 11.182126998901367, "report/model_loss_std": 13.159733772277832, "report/post_ent_mag": 61.49248123168945, "report/post_ent_max": 61.49248123168945, "report/post_ent_mean": 45.09983825683594, "report/post_ent_min": 21.279897689819336, "report/post_ent_std": 7.495534420013428, "report/prior_ent_mag": 70.13272094726562, "report/prior_ent_max": 70.13272094726562, "report/prior_ent_mean": 56.726314544677734, "report/prior_ent_min": 40.219539642333984, "report/prior_ent_std": 4.73922872543335, "report/rep_loss_mean": 11.463579177856445, "report/rep_loss_std": 9.450108528137207, "report/reward_avg": 0.02734375, "report/reward_loss_mean": 0.04645456746220589, "report/reward_loss_std": 0.20852595567703247, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020732879638672, "report/reward_neg_acc": 0.996966540813446, "report/reward_neg_loss": 0.02049645408987999, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.7799566984176636, "report/reward_pred": 0.02618582546710968, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.6469324438949116e-06, "eval/cont_loss_std": 4.546466516330838e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.198445367364911e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.6393197458673967e-06, "eval/cont_pred": 0.9951146841049194, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.431211471557617, "eval/dyn_loss_std": 11.034339904785156, "eval/image_loss_mean": 13.767250061035156, "eval/image_loss_std": 17.719402313232422, "eval/model_loss_mean": 24.923913955688477, "eval/model_loss_std": 21.843687057495117, "eval/post_ent_mag": 62.94029235839844, "eval/post_ent_max": 62.94029235839844, "eval/post_ent_mean": 41.62297439575195, "eval/post_ent_min": 21.773359298706055, "eval/post_ent_std": 7.772658824920654, "eval/prior_ent_mag": 70.13272094726562, "eval/prior_ent_max": 70.13272094726562, "eval/prior_ent_mean": 57.46878433227539, "eval/prior_ent_min": 44.96918487548828, "eval/prior_ent_std": 4.459684371948242, "eval/rep_loss_mean": 18.431211471557617, "eval/rep_loss_std": 11.034339904785156, "eval/reward_avg": 0.04160156100988388, "eval/reward_loss_mean": 0.09793604910373688, "eval/reward_loss_std": 0.5174213647842407, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0125479698181152, "eval/reward_neg_acc": 0.9877300262451172, "eval/reward_neg_loss": 0.04282064363360405, "eval/reward_pos_acc": 0.8913043737411499, "eval/reward_pos_loss": 1.2697376012802124, "eval/reward_pred": 0.0388781800866127, "eval/reward_rate": 0.044921875, "replay/size": 669569.0, "replay/inserts": 21888.0, "replay/samples": 21888.0, "replay/insert_wait_avg": 1.3516377113018817e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.289042424040231e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7112.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1713754205521368e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.940696716308594e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1026.6313109397888, "timer/env.step_count": 2736.0, "timer/env.step_total": 240.77828288078308, "timer/env.step_frac": 0.23453237819171147, "timer/env.step_avg": 0.08800375836285931, "timer/env.step_min": 0.024552583694458008, "timer/env.step_max": 3.397341728210449, "timer/replay._sample_count": 21888.0, "timer/replay._sample_total": 11.398636817932129, "timer/replay._sample_frac": 0.011102950685867646, "timer/replay._sample_avg": 0.0005207710534508466, "timer/replay._sample_min": 0.00036787986755371094, "timer/replay._sample_max": 0.011657476425170898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3625.0, "timer/agent.policy_total": 63.38840436935425, "timer/agent.policy_frac": 0.06174407861311755, "timer/agent.policy_avg": 0.017486456377752896, "timer/agent.policy_min": 0.009594917297363281, "timer/agent.policy_max": 0.15452122688293457, "timer/dataset_train_count": 1368.0, "timer/dataset_train_total": 0.16219067573547363, "timer/dataset_train_frac": 0.00015798337144714848, "timer/dataset_train_avg": 0.00011856043547914739, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.0005021095275878906, "timer/agent.train_count": 1368.0, "timer/agent.train_total": 614.6584346294403, "timer/agent.train_frac": 0.5987138986310243, "timer/agent.train_avg": 0.4493117212203511, "timer/agent.train_min": 0.4366939067840576, "timer/agent.train_max": 1.6016106605529785, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.484713077545166, "timer/agent.report_frac": 0.000472139386730232, "timer/agent.report_avg": 0.242356538772583, "timer/agent.report_min": 0.2332608699798584, "timer/agent.report_max": 0.2514522075653076, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.8332534124411253e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 21.31990343511371}
{"step": 670472, "time": 31428.276301383972, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 670832, "time": 31442.313266038895, "episode/length": 135.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 670848, "time": 31444.46227145195, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 670984, "time": 31450.508167505264, "episode/length": 213.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.985981308411215, "episode/intrinsic_return": 0.0}
{"step": 671088, "time": 31455.776384353638, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 671200, "time": 31461.291921377182, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 671568, "time": 31475.27249097824, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 671912, "time": 31489.851529598236, "episode/length": 132.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 672112, "time": 31498.523479938507, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 672208, "time": 31503.90313434601, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 672248, "time": 31507.18547964096, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675090252707581, "episode/intrinsic_return": 0.0}
{"step": 672376, "time": 31513.538253307343, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 672736, "time": 31527.485647201538, "episode/length": 191.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 672856, "time": 31532.838059425354, "episode/length": 59.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 673512, "time": 31556.620658397675, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 673808, "time": 31568.37767124176, "episode/length": 236.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 674016, "time": 31577.230329036713, "episode/length": 365.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 674064, "time": 31580.42485308647, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 674104, "time": 31583.316688776016, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 674424, "time": 31595.76931977272, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 674736, "time": 31608.255727291107, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 674792, "time": 31611.50248503685, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880597014925373, "episode/intrinsic_return": 0.0}
{"step": 674792, "time": 31611.51341485977, "episode/length": 322.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 675616, "time": 31643.0492272377, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 675848, "time": 31652.25143313408, "episode/length": 228.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 675952, "time": 31657.589584350586, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 676176, "time": 31666.795124530792, "episode/length": 172.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 676384, "time": 31675.464063167572, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 676608, "time": 31684.503202199936, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 676696, "time": 31688.73553466797, "episode/length": 360.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9889196675900277, "episode/intrinsic_return": 0.0}
{"step": 677112, "time": 31704.52877855301, "episode/length": 186.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 677240, "time": 31710.51347374916, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 677520, "time": 31721.87495112419, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 677680, "time": 31728.965130329132, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 677712, "time": 31731.564259052277, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 678168, "time": 31748.305475234985, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 678272, "time": 31754.02959370613, "episode/length": 289.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9896551724137931, "episode/intrinsic_return": 0.0}
{"step": 678808, "time": 31773.67000889778, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 679128, "time": 31786.171426534653, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 679136, "time": 31788.251673460007, "episode/length": 181.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 679728, "time": 31809.729469060898, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 679744, "time": 31812.000886917114, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 679984, "time": 31823.181071281433, "episode/length": 421.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31847.58709859848, "eval_episode/length": 164.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 680056, "time": 31850.488530397415, "eval_episode/length": 192.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9689119170984456}
{"step": 680056, "time": 31852.283592939377, "eval_episode/length": 196.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 680056, "time": 31854.121235847473, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 680056, "time": 31859.934537172318, "eval_episode/length": 212.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 680056, "time": 31862.51543545723, "eval_episode/length": 233.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 680056, "time": 31865.345616579056, "eval_episode/length": 259.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 680056, "time": 31870.81146621704, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9606741573033708}
{"step": 680296, "time": 31878.89298772812, "episode/length": 322.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9907120743034056, "episode/intrinsic_return": 0.0}
{"step": 680392, "time": 31883.638121843338, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 680752, "time": 31897.451414108276, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975247524752475, "episode/intrinsic_return": 0.0}
{"step": 681032, "time": 31908.321099042892, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 681312, "time": 31919.500895023346, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 681568, "time": 31929.903374910355, "episode/length": 304.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 681688, "time": 31935.152604579926, "episode/length": 242.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9835390946502057, "episode/intrinsic_return": 0.0}
{"step": 681728, "time": 31938.376819849014, "episode/length": 364.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9972602739726028, "episode/intrinsic_return": 0.0}
{"step": 682512, "time": 31966.558473825455, "episode/length": 264.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 682576, "time": 31970.281901597977, "episode/length": 284.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 682944, "time": 31984.240087985992, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 682984, "time": 31986.871393442154, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 683096, "time": 31992.227043390274, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 683240, "time": 31999.37352991104, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 683296, "time": 32003.16618704796, "episode/length": 317.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 683440, "time": 32009.5564558506, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 684056, "time": 32031.651455402374, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 684416, "time": 32045.579615831375, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 684608, "time": 32053.72254705429, "episode/length": 261.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 684728, "time": 32059.073664188385, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 685336, "time": 32081.295803785324, "episode/length": 293.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9829931972789115, "episode/intrinsic_return": 0.0}
{"step": 685392, "time": 32085.056246995926, "episode/length": 243.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 685488, "time": 32089.778243541718, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 685512, "time": 32092.028215885162, "episode/length": 301.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9966887417218543, "episode/intrinsic_return": 0.0}
{"step": 685800, "time": 32103.27794790268, "episode/length": 319.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 685952, "time": 32110.278918027878, "episode/length": 57.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 686488, "time": 32129.529942035675, "episode/length": 234.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 686832, "time": 32143.04430794716, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 687016, "time": 32150.655616760254, "episode/length": 151.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 687264, "time": 32160.800441265106, "episode/length": 163.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 687288, "time": 32162.93776488304, "episode/length": 319.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 687472, "time": 32171.138535022736, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 687816, "time": 32183.95575070381, "episode/length": 287.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 687920, "time": 32189.172694921494, "episode/length": 437.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.997716894977169, "episode/intrinsic_return": 0.0}
{"step": 688120, "time": 32197.32507634163, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 688560, "time": 32215.80870604515, "episode/length": 161.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 688592, "time": 32218.517594575882, "episode/length": 219.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 688624, "time": 32221.16707110405, "episode/length": 62.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 688776, "time": 32227.723185300827, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 688800, "time": 32230.517342329025, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 689120, "time": 32242.77240920067, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 689560, "time": 32258.81083369255, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 689944, "time": 32273.329515218735, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 690016, "time": 32277.428030490875, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 32299.969826459885, "eval_episode/length": 154.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 690040, "time": 32302.55548286438, "eval_episode/length": 176.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96045197740113}
{"step": 690040, "time": 32304.150857686996, "eval_episode/length": 178.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 690040, "time": 32305.81174659729, "eval_episode/length": 181.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 690040, "time": 32307.670280218124, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 690040, "time": 32310.084711313248, "eval_episode/length": 205.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 690040, "time": 32314.87972521782, "eval_episode/length": 237.0, "eval_episode/score": 12.100000023841858, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 690040, "time": 32317.67931652069, "eval_episode/length": 264.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9962264150943396}
{"step": 690048, "time": 32318.175051689148, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 690272, "time": 32327.323465824127, "episode/length": 349.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 690400, "time": 32333.24251651764, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 690840, "time": 32350.01622390747, "episode/length": 257.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 690952, "time": 32356.011371850967, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 691432, "time": 32374.239879131317, "episode/length": 176.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 691528, "time": 32379.158836841583, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 691528, "time": 32379.175324201584, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 691592, "time": 32384.926642894745, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 691864, "time": 32395.80167412758, "episode/length": 53.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 691912, "time": 32398.982301473618, "episode/length": 47.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 691960, "time": 32402.12849712372, "episode/length": 354.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9915492957746479, "episode/intrinsic_return": 0.0}
{"step": 692080, "time": 32407.85610127449, "episode/length": 209.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 692136, "time": 32411.310860157013, "episode/length": 161.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 692169, "time": 32415.013021230698, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.9726836715919385, "train/action_min": 0.0, "train/action_std": 3.860717448635378, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03977091776450043, "train/actor_opt_grad_steps": 42475.0, "train/actor_opt_loss": -3.8789041671308055, "train/adv_mag": 0.5382470248833947, "train/adv_max": 0.4920560864434726, "train/adv_mean": 0.0031768624739933384, "train/adv_min": -0.4254566919112551, "train/adv_std": 0.05777577977573526, "train/cont_avg": 0.9948765851449275, "train/cont_loss_mean": 0.00024552156305396875, "train/cont_loss_std": 0.007405109042017586, "train/cont_neg_acc": 0.9906027165875919, "train/cont_neg_loss": 0.025220783783297982, "train/cont_pos_acc": 0.9999786701755248, "train/cont_pos_loss": 9.613244392299094e-05, "train/cont_pred": 0.9949014549670012, "train/cont_rate": 0.9948765851449275, "train/dyn_loss_mean": 13.836461910303088, "train/dyn_loss_std": 9.33555229159369, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8797824570666188, "train/extr_critic_critic_opt_grad_steps": 42475.0, "train/extr_critic_critic_opt_loss": 15643.9696911798, "train/extr_critic_mag": 7.244752586751744, "train/extr_critic_max": 7.244752586751744, "train/extr_critic_mean": 2.0868035978165227, "train/extr_critic_min": -0.25379584319349646, "train/extr_critic_std": 1.6599194537038389, "train/extr_return_normed_mag": 1.598358947297801, "train/extr_return_normed_max": 1.598358947297801, "train/extr_return_normed_mean": 0.39520952785792557, "train/extr_return_normed_min": -0.11158058541300504, "train/extr_return_normed_std": 0.32266863597475964, "train/extr_return_rate": 0.7893418302570564, "train/extr_return_raw_mag": 8.412995096566021, "train/extr_return_raw_max": 8.412995096566021, "train/extr_return_raw_mean": 2.103452044120733, "train/extr_return_raw_min": -0.553623136618863, "train/extr_return_raw_std": 1.6923784682716148, "train/extr_reward_mag": 1.0270543530367422, "train/extr_reward_max": 1.0270543530367422, "train/extr_reward_mean": 0.033106080195664064, "train/extr_reward_min": -0.3869672193043474, "train/extr_reward_std": 0.17152853974181673, "train/image_loss_mean": 6.607964239258697, "train/image_loss_std": 11.426187746766685, "train/model_loss_mean": 14.96597261014192, "train/model_loss_std": 15.231450364209604, "train/model_opt_grad_norm": 58.19157272836436, "train/model_opt_grad_steps": 42435.55072463768, "train/model_opt_loss": 18839.782467164856, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1259.0579710144928, "train/policy_entropy_mag": 2.3893486399581465, "train/policy_entropy_max": 2.3893486399581465, "train/policy_entropy_mean": 0.49741925903852435, "train/policy_entropy_min": 0.07937502202348433, "train/policy_entropy_std": 0.5617426519376644, "train/policy_logprob_mag": 7.438383748565895, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.498756120386331, "train/policy_logprob_min": -7.438383748565895, "train/policy_logprob_std": 1.0596821800522183, "train/policy_randomness_mag": 0.843335219051527, "train/policy_randomness_max": 0.843335219051527, "train/policy_randomness_mean": 0.17556717160387317, "train/policy_randomness_min": 0.028015899444943752, "train/policy_randomness_std": 0.19827050575311633, "train/post_ent_mag": 60.56149717690288, "train/post_ent_max": 60.56149717690288, "train/post_ent_mean": 43.673570163008094, "train/post_ent_min": 21.042675391487453, "train/post_ent_std": 7.656295465386433, "train/prior_ent_mag": 70.37362720655358, "train/prior_ent_max": 70.37362720655358, "train/prior_ent_mean": 57.586237644803695, "train/prior_ent_min": 42.162667924079344, "train/prior_ent_std": 4.368034627126611, "train/rep_loss_mean": 13.836461910303088, "train/rep_loss_std": 9.33555229159369, "train/reward_avg": 0.02761761178734942, "train/reward_loss_mean": 0.055885807557058506, "train/reward_loss_std": 0.2538320342807666, "train/reward_max_data": 1.0181159463481626, "train/reward_max_pred": 1.011839496916619, "train/reward_neg_acc": 0.993020990188571, "train/reward_neg_loss": 0.02932391751665568, "train/reward_pos_acc": 0.9661977679833121, "train/reward_pos_loss": 0.8575777804505997, "train/reward_pred": 0.02695703043507925, "train/reward_rate": 0.03233271059782609, "train_stats/sum_log_reward": 7.8920793533325195, "train_stats/max_log_achievement_collect_coal": 0.13861386138613863, "train_stats/max_log_achievement_collect_drink": 7.306930693069307, "train_stats/max_log_achievement_collect_sapling": 2.217821782178218, "train_stats/max_log_achievement_collect_stone": 1.99009900990099, "train_stats/max_log_achievement_collect_wood": 13.653465346534654, "train_stats/max_log_achievement_defeat_skeleton": 0.039603960396039604, "train_stats/max_log_achievement_defeat_zombie": 0.6633663366336634, "train_stats/max_log_achievement_eat_cow": 0.09900990099009901, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.019801980198019802, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7524752475247525, "train_stats/max_log_achievement_make_wood_sword": 1.702970297029703, "train_stats/max_log_achievement_place_furnace": 0.0297029702970297, "train_stats/max_log_achievement_place_plant": 2.1683168316831685, "train_stats/max_log_achievement_place_stone": 0.4158415841584158, "train_stats/max_log_achievement_place_table": 3.9207920792079207, "train_stats/max_log_achievement_wake_up": 1.198019801980198, "train_stats/mean_log_entropy": 0.5117781418975037, "eval_stats/sum_log_reward": 8.162500113248825, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 6.125, "eval_stats/max_log_achievement_collect_sapling": 2.375, "eval_stats/max_log_achievement_collect_stone": 0.9375, "eval_stats/max_log_achievement_collect_wood": 13.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 1.5, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.375, "eval_stats/max_log_achievement_place_table": 3.5, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.045454545454545456, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0002536923566367477, "report/cont_loss_std": 0.008095918223261833, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03242899104952812, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.435615667513048e-07, "report/cont_pred": 0.99241042137146, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 14.221648216247559, "report/dyn_loss_std": 9.216658592224121, "report/image_loss_mean": 5.5306396484375, "report/image_loss_std": 12.779325485229492, "report/model_loss_mean": 14.120832443237305, "report/model_loss_std": 16.707124710083008, "report/post_ent_mag": 58.11637878417969, "report/post_ent_max": 58.11637878417969, "report/post_ent_mean": 43.05681228637695, "report/post_ent_min": 18.611103057861328, "report/post_ent_std": 7.507000923156738, "report/prior_ent_mag": 69.95863342285156, "report/prior_ent_max": 69.95863342285156, "report/prior_ent_mean": 57.47381591796875, "report/prior_ent_min": 42.547760009765625, "report/prior_ent_std": 4.151122093200684, "report/rep_loss_mean": 14.221648216247559, "report/rep_loss_std": 9.216658592224121, "report/reward_avg": 0.03232421725988388, "report/reward_loss_mean": 0.056950025260448456, "report/reward_loss_std": 0.2250753939151764, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0050768852233887, "report/reward_neg_acc": 0.9908537268638611, "report/reward_neg_loss": 0.0271814726293087, "report/reward_pos_acc": 0.9750000238418579, "report/reward_pos_loss": 0.7892565131187439, "report/reward_pred": 0.03098406083881855, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 9.380860888086318e-08, "eval/cont_loss_std": 2.2835676816157502e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.1555380246572895e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 8.481234203827626e-08, "eval/cont_pred": 0.9970703125, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.089916229248047, "eval/dyn_loss_std": 10.840622901916504, "eval/image_loss_mean": 10.949919700622559, "eval/image_loss_std": 14.437851905822754, "eval/model_loss_mean": 22.5673828125, "eval/model_loss_std": 18.777780532836914, "eval/post_ent_mag": 61.32888412475586, "eval/post_ent_max": 61.32888412475586, "eval/post_ent_mean": 41.544551849365234, "eval/post_ent_min": 22.01510238647461, "eval/post_ent_std": 7.869083404541016, "eval/prior_ent_mag": 69.95863342285156, "eval/prior_ent_max": 69.95863342285156, "eval/prior_ent_mean": 58.026283264160156, "eval/prior_ent_min": 45.497344970703125, "eval/prior_ent_std": 4.124107360839844, "eval/rep_loss_mean": 19.089916229248047, "eval/rep_loss_std": 10.840622901916504, "eval/reward_avg": 0.03896484524011612, "eval/reward_loss_mean": 0.16351403295993805, "eval/reward_loss_std": 0.8846701383590698, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0017783641815186, "eval/reward_neg_acc": 0.983690083026886, "eval/reward_neg_loss": 0.06051279231905937, "eval/reward_pos_acc": 0.6744186282157898, "eval/reward_pos_loss": 2.5133795738220215, "eval/reward_pred": 0.02905181050300598, "eval/reward_rate": 0.0419921875, "replay/size": 691665.0, "replay/inserts": 22096.0, "replay/samples": 22096.0, "replay/insert_wait_avg": 1.3336161614154924e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.245676142853468e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4864.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2130721619254665e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0989229679108, "timer/env.step_count": 2762.0, "timer/env.step_total": 242.76521635055542, "timer/env.step_frac": 0.24274120367025412, "timer/env.step_avg": 0.08789471989520471, "timer/env.step_min": 0.02468729019165039, "timer/env.step_max": 3.632258176803589, "timer/replay._sample_count": 22096.0, "timer/replay._sample_total": 11.554191589355469, "timer/replay._sample_frac": 0.011553048727486928, "timer/replay._sample_avg": 0.0005229087431822714, "timer/replay._sample_min": 0.0004220008850097656, "timer/replay._sample_max": 0.021529674530029297, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3370.0, "timer/agent.policy_total": 59.39094281196594, "timer/agent.policy_frac": 0.059385068264763606, "timer/agent.policy_avg": 0.017623425166755472, "timer/agent.policy_min": 0.009526968002319336, "timer/agent.policy_max": 0.13090252876281738, "timer/dataset_train_count": 1381.0, "timer/dataset_train_total": 0.16366100311279297, "timer/dataset_train_frac": 0.00016364481488202162, "timer/dataset_train_avg": 0.000118509053666034, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0010852813720703125, "timer/agent.train_count": 1381.0, "timer/agent.train_total": 621.3396537303925, "timer/agent.train_frac": 0.6212781950474401, "timer/agent.train_avg": 0.44992009683591055, "timer/agent.train_min": 0.43508124351501465, "timer/agent.train_max": 1.6810948848724365, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48311805725097656, "timer/agent.report_frac": 0.00048307027050610866, "timer/agent.report_avg": 0.24155902862548828, "timer/agent.report_min": 0.23415565490722656, "timer/agent.report_max": 0.24896240234375, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075295453056737e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.0935127583944}
{"step": 692320, "time": 32420.14281630516, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 693208, "time": 32451.620409727097, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 693232, "time": 32454.24280333519, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 693344, "time": 32459.697930574417, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 693456, "time": 32465.09081220627, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 693680, "time": 32474.484839200974, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 693704, "time": 32476.967489004135, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 693720, "time": 32479.245620250702, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 694288, "time": 32500.158856868744, "episode/length": 302.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.0}
{"step": 694840, "time": 32520.163865804672, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 694856, "time": 32522.230054616928, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 694920, "time": 32526.02122068405, "episode/length": 213.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 694976, "time": 32529.865728139877, "episode/length": 161.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 695112, "time": 32535.755751371384, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 695144, "time": 32538.264157772064, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 695240, "time": 32543.005544424057, "episode/length": 39.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 695568, "time": 32555.835609436035, "episode/length": 291.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9828767123287672, "episode/intrinsic_return": 0.0}
{"step": 695704, "time": 32561.913949728012, "episode/length": 57.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 696080, "time": 32576.274568080902, "episode/length": 223.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 696504, "time": 32593.76481938362, "episode/length": 173.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 696544, "time": 32596.992599487305, "episode/length": 212.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 696544, "time": 32597.00248503685, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 696672, "time": 32604.677662611008, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 696792, "time": 32610.052868127823, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 697272, "time": 32627.86345744133, "episode/length": 195.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 697400, "time": 32633.804789066315, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 697576, "time": 32641.348073720932, "episode/length": 250.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 698040, "time": 32658.671335458755, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 698264, "time": 32667.84153151512, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 698584, "time": 32680.317843437195, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 698704, "time": 32686.122822999954, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 699032, "time": 32698.58272075653, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 699104, "time": 32702.830709934235, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9835526315789473, "episode/intrinsic_return": 0.0}
{"step": 699240, "time": 32708.70667552948, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 699568, "time": 32721.659205198288, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 699824, "time": 32731.85051035881, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32755.0120677948, "eval_episode/length": 47.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 700024, "time": 32762.187055826187, "eval_episode/length": 174.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 700024, "time": 32765.11786556244, "eval_episode/length": 202.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 700024, "time": 32766.670824050903, "eval_episode/length": 155.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 700024, "time": 32768.28737783432, "eval_episode/length": 205.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 700024, "time": 32770.464775800705, "eval_episode/length": 213.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 700024, "time": 32772.11679434776, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 700024, "time": 32774.28439307213, "eval_episode/length": 227.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 700072, "time": 32775.88604593277, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 700096, "time": 32778.53529930115, "episode/length": 448.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799554565701559, "episode/intrinsic_return": 0.0}
{"step": 700136, "time": 32781.28833222389, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 700216, "time": 32785.53502321243, "episode/length": 147.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 700432, "time": 32794.56305599213, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 700512, "time": 32798.93950676918, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 700648, "time": 32805.040783166885, "episode/length": 192.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 701104, "time": 32822.168025016785, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 701248, "time": 32828.65643668175, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 701496, "time": 32838.64526581764, "episode/length": 48.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 701504, "time": 32841.2382543087, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 701680, "time": 32849.361018419266, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 701872, "time": 32857.439240932465, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 701952, "time": 32861.78318619728, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 702208, "time": 32874.368740558624, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 702272, "time": 32878.07903265953, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 702576, "time": 32889.978528022766, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 702928, "time": 32903.44712162018, "episode/length": 177.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 703320, "time": 32918.02409172058, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 703424, "time": 32923.47479605675, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 703888, "time": 32940.85585093498, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 704248, "time": 32954.32817363739, "episode/length": 246.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 704296, "time": 32957.50421714783, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 704520, "time": 32966.85719156265, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 704728, "time": 32977.15870523453, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9602272727272727, "episode/intrinsic_return": 0.0}
{"step": 704936, "time": 32985.91322898865, "episode/length": 188.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 705312, "time": 33000.339703798294, "episode/length": 387.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9922680412371134, "episode/intrinsic_return": 0.0}
{"step": 705408, "time": 33005.15305304527, "episode/length": 58.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 705576, "time": 33012.20793962479, "episode/length": 509.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 705640, "time": 33016.430582523346, "episode/length": 167.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 705872, "time": 33026.421889305115, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 706056, "time": 33033.87807106972, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 706320, "time": 33044.5346364975, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 706488, "time": 33051.557012319565, "episode/length": 134.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 706856, "time": 33065.433497190475, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 706904, "time": 33068.64436626434, "episode/length": 157.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 707448, "time": 33088.61385679245, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 707520, "time": 33092.911878585815, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 707560, "time": 33095.56698155403, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 708048, "time": 33114.025533914566, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 708192, "time": 33120.48688483238, "episode/length": 537.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9981412639405205, "episode/intrinsic_return": 0.0}
{"step": 708216, "time": 33122.69092082977, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 708536, "time": 33135.92636632919, "episode/length": 203.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 708552, "time": 33137.993030786514, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 708816, "time": 33148.63810992241, "episode/length": 170.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 709056, "time": 33158.33658647537, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 709072, "time": 33160.6166369915, "episode/length": 188.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 709480, "time": 33175.66980957985, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 709528, "time": 33178.870023965836, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 709800, "time": 33189.53225040436, "episode/length": 200.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 33214.0941119194, "eval_episode/length": 64.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9230769230769231}
{"step": 710008, "time": 33219.91188001633, "eval_episode/length": 156.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 710008, "time": 33222.04443478584, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 710008, "time": 33223.71093773842, "eval_episode/length": 169.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 710008, "time": 33226.96022820473, "eval_episode/length": 207.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 710008, "time": 33228.879219055176, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 710008, "time": 33231.08680391312, "eval_episode/length": 226.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 710008, "time": 33233.41337108612, "eval_episode/length": 241.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9710743801652892}
{"step": 710160, "time": 33238.829105615616, "episode/length": 137.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 710184, "time": 33241.018010139465, "episode/length": 170.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 710952, "time": 33268.53453373909, "episode/length": 177.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 711224, "time": 33279.32398033142, "episode/length": 268.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 711440, "time": 33288.523624658585, "episode/length": 244.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 711440, "time": 33288.53562402725, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9889196675900277, "episode/intrinsic_return": 0.0}
{"step": 711480, "time": 33293.10645055771, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 712056, "time": 33314.123427152634, "episode/length": 439.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 712432, "time": 33328.782232522964, "episode/length": 283.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 712648, "time": 33337.39775753021, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 712672, "time": 33340.25866150856, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 712768, "time": 33348.57214283943, "episode/length": 160.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 713128, "time": 33362.39305639267, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 713480, "time": 33375.98274254799, "episode/length": 254.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 713768, "time": 33387.5348443985, "episode/length": 351.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9857954545454546, "episode/intrinsic_return": 0.0}
{"step": 714384, "time": 33410.684059381485, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 714457, "time": 33415.4509305954, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.856804936909847, "train/action_min": 0.0, "train/action_std": 3.7457670084864114, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03995261586559334, "train/actor_opt_grad_steps": 43860.0, "train/actor_opt_loss": -2.8346274773851574, "train/adv_mag": 0.5422475818249819, "train/adv_max": 0.5176836434456942, "train/adv_mean": 0.0033911821914928055, "train/adv_min": -0.4061928949982142, "train/adv_std": 0.0580137243641795, "train/cont_avg": 0.9950258543165468, "train/cont_loss_mean": 0.00015406203378892446, "train/cont_loss_std": 0.004617660212275405, "train/cont_neg_acc": 0.9934052769228708, "train/cont_neg_loss": 0.021426150365771706, "train/cont_pos_acc": 0.999992930203033, "train/cont_pos_loss": 3.438410810903972e-05, "train/cont_pred": 0.9950390458106995, "train/cont_rate": 0.9950258543165468, "train/dyn_loss_mean": 13.565950640671545, "train/dyn_loss_std": 9.341810164691733, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9044109921661212, "train/extr_critic_critic_opt_grad_steps": 43860.0, "train/extr_critic_critic_opt_loss": 15897.25654788669, "train/extr_critic_mag": 7.417293356476928, "train/extr_critic_max": 7.417293356476928, "train/extr_critic_mean": 2.092998659010414, "train/extr_critic_min": -0.26692812905894764, "train/extr_critic_std": 1.6671231479095898, "train/extr_return_normed_mag": 1.591253152854151, "train/extr_return_normed_max": 1.591253152854151, "train/extr_return_normed_mean": 0.3896939441454496, "train/extr_return_normed_min": -0.11386892191476101, "train/extr_return_normed_std": 0.3187276514099656, "train/extr_return_rate": 0.7978750227166594, "train/extr_return_raw_mag": 8.513409902723573, "train/extr_return_raw_max": 8.513409902723573, "train/extr_return_raw_mean": 2.111060829471341, "train/extr_return_raw_min": -0.5723434954667262, "train/extr_return_raw_std": 1.6983496876929303, "train/extr_reward_mag": 1.0254958585011873, "train/extr_reward_max": 1.0254958585011873, "train/extr_reward_mean": 0.03207122825970538, "train/extr_reward_min": -0.3783711692412123, "train/extr_reward_std": 0.16905196413076182, "train/image_loss_mean": 6.451386544344237, "train/image_loss_std": 11.21567799204545, "train/model_loss_mean": 14.646326318919229, "train/model_loss_std": 14.985346485384934, "train/model_opt_grad_norm": 57.95656676258115, "train/model_opt_grad_steps": 43819.08633093525, "train/model_opt_loss": 16681.971865866682, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1137.589928057554, "train/policy_entropy_mag": 2.3582263284449954, "train/policy_entropy_max": 2.3582263284449954, "train/policy_entropy_mean": 0.5026718622488942, "train/policy_entropy_min": 0.07937502491173984, "train/policy_entropy_std": 0.5640339643406354, "train/policy_logprob_mag": 7.438383833109904, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5021306419972893, "train/policy_logprob_min": -7.438383833109904, "train/policy_logprob_std": 1.0576970139853388, "train/policy_randomness_mag": 0.8323504062865278, "train/policy_randomness_max": 0.8323504062865278, "train/policy_randomness_mean": 0.17742110847783604, "train/policy_randomness_min": 0.02801590049706346, "train/policy_randomness_std": 0.19907923685989792, "train/post_ent_mag": 60.73889717266714, "train/post_ent_max": 60.73889717266714, "train/post_ent_mean": 43.90556253117623, "train/post_ent_min": 21.00094253210713, "train/post_ent_std": 7.688598420122545, "train/prior_ent_mag": 70.36683512077057, "train/prior_ent_max": 70.36683512077057, "train/prior_ent_mean": 57.54892969474518, "train/prior_ent_min": 42.00788117827271, "train/prior_ent_std": 4.441807398693167, "train/rep_loss_mean": 13.565950640671545, "train/rep_loss_std": 9.341810164691733, "train/reward_avg": 0.02652526386886192, "train/reward_loss_mean": 0.055215380764264854, "train/reward_loss_std": 0.2507190284111517, "train/reward_max_data": 1.0201438896947628, "train/reward_max_pred": 1.013977641681973, "train/reward_neg_acc": 0.9923760475014611, "train/reward_neg_loss": 0.029738929819503275, "train/reward_pos_acc": 0.9677832817002167, "train/reward_pos_loss": 0.8488904259187712, "train/reward_pred": 0.025969905075248625, "train/reward_rate": 0.03107435926258993, "train_stats/sum_log_reward": 7.992156942685445, "train_stats/max_log_achievement_collect_coal": 0.16666666666666666, "train_stats/max_log_achievement_collect_drink": 5.205882352941177, "train_stats/max_log_achievement_collect_sapling": 1.892156862745098, "train_stats/max_log_achievement_collect_stone": 2.6470588235294117, "train_stats/max_log_achievement_collect_wood": 13.07843137254902, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 0.7058823529411765, "train_stats/max_log_achievement_eat_cow": 0.09803921568627451, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.029411764705882353, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4705882352941178, "train_stats/max_log_achievement_make_wood_sword": 1.8137254901960784, "train_stats/max_log_achievement_place_furnace": 0.049019607843137254, "train_stats/max_log_achievement_place_plant": 1.8529411764705883, "train_stats/max_log_achievement_place_stone": 1.8137254901960784, "train_stats/max_log_achievement_place_table": 3.715686274509804, "train_stats/max_log_achievement_wake_up": 1.196078431372549, "train_stats/mean_log_entropy": 0.498058212007962, "eval_stats/sum_log_reward": 7.412499934434891, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 2.4375, "eval_stats/max_log_achievement_collect_wood": 11.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 1.75, "eval_stats/max_log_achievement_place_table": 3.375, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 2.228660605396726e-06, "report/cont_loss_std": 1.8467051631887443e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.648811828810722e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.951698095581378e-06, "report/cont_pred": 0.9970687627792358, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.796514511108398, "report/dyn_loss_std": 9.500907897949219, "report/image_loss_mean": 4.469838619232178, "report/image_loss_std": 9.225883483886719, "report/model_loss_mean": 12.195074081420898, "report/model_loss_std": 13.292867660522461, "report/post_ent_mag": 63.62177658081055, "report/post_ent_max": 63.62177658081055, "report/post_ent_mean": 45.15719223022461, "report/post_ent_min": 20.05473518371582, "report/post_ent_std": 8.516504287719727, "report/prior_ent_mag": 70.7516098022461, "report/prior_ent_max": 70.7516098022461, "report/prior_ent_mean": 57.44011688232422, "report/prior_ent_min": 40.080421447753906, "report/prior_ent_std": 4.57285737991333, "report/rep_loss_mean": 12.796514511108398, "report/rep_loss_std": 9.500907897949219, "report/reward_avg": 0.02558593824505806, "report/reward_loss_mean": 0.047325097024440765, "report/reward_loss_std": 0.2212940901517868, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0041773319244385, "report/reward_neg_acc": 0.991959810256958, "report/reward_neg_loss": 0.024043211713433266, "report/reward_pos_acc": 0.9655172228813171, "report/reward_pos_loss": 0.8461347222328186, "report/reward_pred": 0.02517807111144066, "report/reward_rate": 0.0283203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 2.9341559638851322e-05, "eval/cont_loss_std": 0.0008489133324474096, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.009162519127130508, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.505586508050328e-06, "eval/cont_pred": 0.9970943927764893, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.96283721923828, "eval/dyn_loss_std": 11.081660270690918, "eval/image_loss_mean": 10.972112655639648, "eval/image_loss_std": 16.78826904296875, "eval/model_loss_mean": 22.454288482666016, "eval/model_loss_std": 21.36188316345215, "eval/post_ent_mag": 61.18206787109375, "eval/post_ent_max": 61.18206787109375, "eval/post_ent_mean": 42.3050651550293, "eval/post_ent_min": 22.402151107788086, "eval/post_ent_std": 8.354208946228027, "eval/prior_ent_mag": 70.7516098022461, "eval/prior_ent_max": 70.7516098022461, "eval/prior_ent_mean": 58.02238845825195, "eval/prior_ent_min": 44.92286682128906, "eval/prior_ent_std": 4.299111366271973, "eval/rep_loss_mean": 18.96283721923828, "eval/rep_loss_std": 11.081660270690918, "eval/reward_avg": 0.02597656100988388, "eval/reward_loss_mean": 0.1044449508190155, "eval/reward_loss_std": 0.6466030478477478, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0315418243408203, "eval/reward_neg_acc": 0.9919517040252686, "eval/reward_neg_loss": 0.043607890605926514, "eval/reward_pos_acc": 0.7666667103767395, "eval/reward_pos_loss": 2.1201796531677246, "eval/reward_pred": 0.02174648642539978, "eval/reward_rate": 0.029296875, "replay/size": 713953.0, "replay/inserts": 22288.0, "replay/samples": 22288.0, "replay/insert_wait_avg": 1.3603487206463838e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.246799462147951e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3760.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1479600946953956e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3709068298339844e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4212820529938, "timer/env.step_count": 2786.0, "timer/env.step_total": 247.86143350601196, "timer/env.step_frac": 0.24775705790401445, "timer/env.step_avg": 0.08896677440991096, "timer/env.step_min": 0.024169206619262695, "timer/env.step_max": 3.460090160369873, "timer/replay._sample_count": 22288.0, "timer/replay._sample_total": 11.785109519958496, "timer/replay._sample_frac": 0.01178014675554875, "timer/replay._sample_avg": 0.000528764784635611, "timer/replay._sample_min": 0.0004229545593261719, "timer/replay._sample_max": 0.011361360549926758, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3256.0, "timer/agent.policy_total": 55.77125692367554, "timer/agent.policy_frac": 0.055747771388095335, "timer/agent.policy_avg": 0.017128764411448262, "timer/agent.policy_min": 0.009523630142211914, "timer/agent.policy_max": 0.11644148826599121, "timer/dataset_train_count": 1393.0, "timer/dataset_train_total": 0.16477560997009277, "timer/dataset_train_frac": 0.00016470622219466575, "timer/dataset_train_avg": 0.00011828830579331857, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.0004467964172363281, "timer/agent.train_count": 1393.0, "timer/agent.train_total": 625.2678232192993, "timer/agent.train_frac": 0.6250045200319698, "timer/agent.train_avg": 0.44886419470157884, "timer/agent.train_min": 0.43702054023742676, "timer/agent.train_max": 1.650197982788086, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4836766719818115, "timer/agent.report_frac": 0.0004834729934865485, "timer/agent.report_avg": 0.24183833599090576, "timer/agent.report_min": 0.23291516304016113, "timer/agent.report_max": 0.2507615089416504, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.31262270101944e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 22.278317495406736}
{"step": 714472, "time": 33415.53893446922, "episode/length": 254.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 715032, "time": 33436.5723733902, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 715056, "time": 33439.17882657051, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 715360, "time": 33450.863399744034, "episode/length": 278.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 715536, "time": 33458.35853481293, "episode/length": 434.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 715536, "time": 33458.36983156204, "episode/length": 360.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9889196675900277, "episode/intrinsic_return": 0.0}
{"step": 715856, "time": 33472.499886751175, "episode/length": 397.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 716384, "time": 33492.14026761055, "episode/length": 238.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 716408, "time": 33494.29424285889, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 716648, "time": 33503.86530256271, "episode/length": 198.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 716800, "time": 33510.814026117325, "episode/length": 301.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 717048, "time": 33520.58534526825, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 717296, "time": 33530.70400762558, "episode/length": 61.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 717784, "time": 33548.5597755909, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 717960, "time": 33556.305621147156, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 717976, "time": 33558.36565923691, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 717984, "time": 33560.36384797096, "episode/length": 166.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 718312, "time": 33572.66723322868, "episode/length": 43.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8863636363636364, "episode/intrinsic_return": 0.0}
{"step": 718456, "time": 33579.08552360535, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 718592, "time": 33585.59954166412, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975247524752475, "episode/intrinsic_return": 0.0}
{"step": 719024, "time": 33601.86609911919, "episode/length": 246.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 719304, "time": 33612.70526456833, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 719592, "time": 33623.96670246124, "episode/length": 397.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 719832, "time": 33633.697048425674, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 719952, "time": 33639.63501119614, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9853658536585366, "episode/intrinsic_return": 0.0}
{"step": 720016, "time": 33643.51411366463, "episode/length": 254.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33666.382420778275, "eval_episode/length": 115.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9568965517241379}
{"step": 720096, "time": 33670.30917787552, "eval_episode/length": 163.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 720096, "time": 33673.0901863575, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 720096, "time": 33674.76932811737, "eval_episode/length": 189.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 720096, "time": 33678.7995467186, "eval_episode/length": 242.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9794238683127572}
{"step": 720096, "time": 33684.422286987305, "eval_episode/length": 169.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 720096, "time": 33687.427629709244, "eval_episode/length": 362.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9972451790633609}
{"step": 720096, "time": 33691.09293174744, "eval_episode/length": 406.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9926289926289926}
{"step": 720576, "time": 33707.32911133766, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 720928, "time": 33722.49226665497, "episode/length": 136.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 721136, "time": 33731.21806716919, "episode/length": 263.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 721144, "time": 33732.784507513046, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 721672, "time": 33752.05437016487, "episode/length": 206.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 721680, "time": 33754.2168674469, "episode/length": 402.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9950372208436724, "episode/intrinsic_return": 0.0}
{"step": 721872, "time": 33762.38360905647, "episode/length": 91.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9347826086956522, "episode/intrinsic_return": 0.0}
{"step": 721920, "time": 33765.58125925064, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 721960, "time": 33768.28925180435, "episode/length": 295.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 722216, "time": 33778.50790643692, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9609756097560975, "episode/intrinsic_return": 0.0}
{"step": 722504, "time": 33789.98980307579, "episode/length": 169.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 722752, "time": 33799.99676656723, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692982456140351, "episode/intrinsic_return": 0.0}
{"step": 723264, "time": 33818.992295503616, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 723600, "time": 33832.12181997299, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 723632, "time": 33834.88251566887, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 723808, "time": 33842.445164203644, "episode/length": 266.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 724040, "time": 33851.69309639931, "episode/length": 160.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 724096, "time": 33855.42826652527, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 724440, "time": 33868.33021402359, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 724728, "time": 33879.6873691082, "episode/length": 136.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 724920, "time": 33887.85282039642, "episode/length": 59.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 725024, "time": 33893.113753557205, "episode/length": 314.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 725184, "time": 33900.037472486496, "episode/length": 56.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 725264, "time": 33904.28554606438, "episode/length": 249.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 725376, "time": 33909.64778256416, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 725400, "time": 33911.88860440254, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 726176, "time": 33940.03371477127, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 726232, "time": 33943.34195971489, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 726592, "time": 33959.313889980316, "episode/length": 175.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 726648, "time": 33962.54952573776, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 726864, "time": 33971.88335800171, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 727008, "time": 33978.27761602402, "episode/length": 51.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 727016, "time": 33979.85610604286, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 727752, "time": 34006.24800825119, "episode/length": 196.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 727952, "time": 34014.8203868866, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 728088, "time": 34020.59711551666, "episode/length": 560.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 728424, "time": 34033.57803273201, "episode/length": 83.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 728712, "time": 34044.84883117676, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 728768, "time": 34048.55783820152, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 728800, "time": 34051.33701324463, "episode/length": 441.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 728888, "time": 34055.6867454052, "episode/length": 252.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 729216, "time": 34070.29450964928, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 729416, "time": 34078.470353364944, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 729576, "time": 34085.46996450424, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 729976, "time": 34100.690601587296, "episode/length": 235.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 34121.35096001625, "eval_episode/length": 46.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8936170212765957}
{"step": 730080, "time": 34124.36508822441, "eval_episode/length": 77.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 730080, "time": 34131.46494913101, "eval_episode/length": 158.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 730080, "time": 34134.06784725189, "eval_episode/length": 182.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 730080, "time": 34136.509061574936, "eval_episode/length": 200.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 730080, "time": 34142.952682971954, "eval_episode/length": 305.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9967320261437909}
{"step": 730080, "time": 34146.40815639496, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9679144385026738}
{"step": 730080, "time": 34149.10888314247, "eval_episode/length": 371.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758064516129032}
{"step": 730280, "time": 34155.73049211502, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 730416, "time": 34162.09975481033, "episode/length": 54.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 730456, "time": 34164.82832098007, "episode/length": 109.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 730512, "time": 34168.47328925133, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 730600, "time": 34173.02028918266, "episode/length": 235.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 730664, "time": 34176.79492354393, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 730752, "time": 34181.59788942337, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 730856, "time": 34186.55810022354, "episode/length": 179.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 730992, "time": 34193.57110738754, "episode/length": 29.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 731720, "time": 34220.149493694305, "episode/length": 157.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 731800, "time": 34224.40727329254, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 732120, "time": 34236.74995970726, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 732320, "time": 34245.52275633812, "episode/length": 182.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 732552, "time": 34255.10530948639, "episode/length": 266.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9737827715355806, "episode/intrinsic_return": 0.0}
{"step": 732680, "time": 34260.94423317909, "episode/length": 251.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 733272, "time": 34282.59740328789, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 733464, "time": 34290.68371415138, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.989159891598916, "episode/intrinsic_return": 0.0}
{"step": 733968, "time": 34309.59814667702, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 734184, "time": 34318.20828485489, "episode/length": 398.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 734240, "time": 34321.824318647385, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9901639344262295, "episode/intrinsic_return": 0.0}
{"step": 734272, "time": 34325.777363061905, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 735016, "time": 34352.391689777374, "episode/length": 361.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972375690607734, "episode/intrinsic_return": 0.0}
{"step": 735600, "time": 34374.19415473938, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 735600, "time": 34374.204338788986, "episode/length": 290.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 735624, "time": 34377.96302962303, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 735888, "time": 34388.71108818054, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9950124688279302, "episode/intrinsic_return": 0.0}
{"step": 735984, "time": 34393.69264101982, "episode/length": 314.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 736256, "time": 34404.33543539047, "episode/length": 247.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 736312, "time": 34407.71807336807, "episode/length": 161.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 736473, "time": 34415.56278800964, "train_stats/sum_log_reward": 8.400000199079514, "train_stats/max_log_achievement_collect_coal": 0.26, "train_stats/max_log_achievement_collect_drink": 4.85, "train_stats/max_log_achievement_collect_sapling": 1.71, "train_stats/max_log_achievement_collect_stone": 6.73, "train_stats/max_log_achievement_collect_wood": 12.75, "train_stats/max_log_achievement_defeat_skeleton": 0.02, "train_stats/max_log_achievement_defeat_zombie": 0.65, "train_stats/max_log_achievement_eat_cow": 0.13, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01, "train_stats/max_log_achievement_make_stone_sword": 0.03, "train_stats/max_log_achievement_make_wood_pickaxe": 2.01, "train_stats/max_log_achievement_make_wood_sword": 1.15, "train_stats/max_log_achievement_place_furnace": 0.02, "train_stats/max_log_achievement_place_plant": 1.69, "train_stats/max_log_achievement_place_stone": 5.03, "train_stats/max_log_achievement_place_table": 3.57, "train_stats/max_log_achievement_wake_up": 1.09, "train_stats/mean_log_entropy": 0.542346214056015, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.837713269219882, "train/action_min": 0.0, "train/action_std": 3.616434641506361, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.039795261200355446, "train/actor_opt_grad_steps": 45245.0, "train/actor_opt_loss": -3.80452525175676, "train/adv_mag": 0.5281688847403595, "train/adv_max": 0.4796385384988094, "train/adv_mean": 0.003385872178193455, "train/adv_min": -0.4181371825760689, "train/adv_std": 0.05774673447012901, "train/cont_avg": 0.9949615036231884, "train/cont_loss_mean": 0.00014805711262717023, "train/cont_loss_std": 0.004327014372034662, "train/cont_neg_acc": 0.9989572476296529, "train/cont_neg_loss": 0.0072429430147632, "train/cont_pos_acc": 0.999971497318019, "train/cont_pos_loss": 0.00010606922011862954, "train/cont_pred": 0.9949359211368837, "train/cont_rate": 0.9949615036231884, "train/dyn_loss_mean": 13.7696271357329, "train/dyn_loss_std": 9.30648558381675, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9252019001953844, "train/extr_critic_critic_opt_grad_steps": 45245.0, "train/extr_critic_critic_opt_loss": 15834.498245018116, "train/extr_critic_mag": 7.61452077091604, "train/extr_critic_max": 7.61452077091604, "train/extr_critic_mean": 2.2776415961376135, "train/extr_critic_min": -0.25605084498723346, "train/extr_critic_std": 1.72994045243747, "train/extr_return_normed_mag": 1.5745864337769107, "train/extr_return_normed_max": 1.5745864337769107, "train/extr_return_normed_mean": 0.40895391309606854, "train/extr_return_normed_min": -0.11302505063729873, "train/extr_return_normed_std": 0.3240882811554964, "train/extr_return_rate": 0.8169964772203694, "train/extr_return_raw_mag": 8.643782923187034, "train/extr_return_raw_max": 8.643782923187034, "train/extr_return_raw_mean": 2.296063066392705, "train/extr_return_raw_min": -0.5460011839218761, "train/extr_return_raw_std": 1.7647213002909785, "train/extr_reward_mag": 1.0300394037495488, "train/extr_reward_max": 1.0300394037495488, "train/extr_reward_mean": 0.03450433635895235, "train/extr_reward_min": -0.3788043804790663, "train/extr_reward_std": 0.17444992659316547, "train/image_loss_mean": 6.650550213412962, "train/image_loss_std": 11.58965269724528, "train/model_loss_mean": 14.967577257018158, "train/model_loss_std": 15.365163174228393, "train/model_opt_grad_norm": 57.082422173541524, "train/model_opt_grad_steps": 45203.0, "train/model_opt_loss": 13725.630279098732, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 919.3840579710145, "train/policy_entropy_mag": 2.3771957832833994, "train/policy_entropy_max": 2.3771957832833994, "train/policy_entropy_mean": 0.4939079442317935, "train/policy_entropy_min": 0.07937502369716548, "train/policy_entropy_std": 0.5607962696880534, "train/policy_logprob_mag": 7.438383810762046, "train/policy_logprob_max": -0.009455658421190321, "train/policy_logprob_mean": -0.493666168788205, "train/policy_logprob_min": -7.438383810762046, "train/policy_logprob_std": 1.0543333667775858, "train/policy_randomness_mag": 0.8390457902265631, "train/policy_randomness_max": 0.8390457902265631, "train/policy_randomness_mean": 0.17432783047358194, "train/policy_randomness_min": 0.0280159000793229, "train/policy_randomness_std": 0.1979364733333173, "train/post_ent_mag": 60.31966803730398, "train/post_ent_max": 60.31966803730398, "train/post_ent_mean": 43.59326464887978, "train/post_ent_min": 20.917373961296633, "train/post_ent_std": 7.60730699179829, "train/prior_ent_mag": 70.4348789712657, "train/prior_ent_max": 70.4348789712657, "train/prior_ent_mean": 57.46066947605299, "train/prior_ent_min": 42.55369902348173, "train/prior_ent_std": 4.391293952430504, "train/rep_loss_mean": 13.7696271357329, "train/rep_loss_std": 9.30648558381675, "train/reward_avg": 0.028008944530417954, "train/reward_loss_mean": 0.055102836502634964, "train/reward_loss_std": 0.2447520200757013, "train/reward_max_data": 1.0195652220560156, "train/reward_max_pred": 1.011737300865892, "train/reward_neg_acc": 0.9929502818031587, "train/reward_neg_loss": 0.028701908926924934, "train/reward_pos_acc": 0.9687391385652017, "train/reward_pos_loss": 0.8437762018563091, "train/reward_pred": 0.027030482328078455, "train/reward_rate": 0.03242470561594203, "eval_stats/sum_log_reward": 7.975000187754631, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.375, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 6.5, "eval_stats/max_log_achievement_collect_wood": 11.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.75, "eval_stats/max_log_achievement_make_wood_sword": 0.9375, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 4.3125, "eval_stats/max_log_achievement_place_table": 3.3125, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.000259900203673169, "report/cont_loss_std": 0.0054931361228227615, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006452889647334814, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0002576287661213428, "report/cont_pred": 0.9939028024673462, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.059929847717285, "report/dyn_loss_std": 9.046178817749023, "report/image_loss_mean": 6.066125869750977, "report/image_loss_std": 10.567452430725098, "report/model_loss_mean": 13.946538925170898, "report/model_loss_std": 14.290440559387207, "report/post_ent_mag": 60.64448547363281, "report/post_ent_max": 60.64448547363281, "report/post_ent_mean": 43.9859619140625, "report/post_ent_min": 20.81934928894043, "report/post_ent_std": 7.668713092803955, "report/prior_ent_mag": 70.14772033691406, "report/prior_ent_max": 70.14772033691406, "report/prior_ent_mean": 57.134796142578125, "report/prior_ent_min": 39.165252685546875, "report/prior_ent_std": 4.460801601409912, "report/rep_loss_mean": 13.059929847717285, "report/rep_loss_std": 9.046178817749023, "report/reward_avg": 0.011328124441206455, "report/reward_loss_mean": 0.04419475048780441, "report/reward_loss_std": 0.19461731612682343, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002922534942627, "report/reward_neg_acc": 0.995029866695404, "report/reward_neg_loss": 0.032605621963739395, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6918983459472656, "report/reward_pred": 0.012964263558387756, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.4666064089396968e-05, "eval/cont_loss_std": 0.00021972770628053695, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0007021952769719064, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.2645900824281853e-05, "eval/cont_pred": 0.9970598220825195, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.438858032226562, "eval/dyn_loss_std": 11.047593116760254, "eval/image_loss_mean": 12.563108444213867, "eval/image_loss_std": 15.214716911315918, "eval/model_loss_mean": 23.7303466796875, "eval/model_loss_std": 20.10717010498047, "eval/post_ent_mag": 61.20848083496094, "eval/post_ent_max": 61.20848083496094, "eval/post_ent_mean": 42.743263244628906, "eval/post_ent_min": 20.602718353271484, "eval/post_ent_std": 7.930986404418945, "eval/prior_ent_mag": 70.14772033691406, "eval/prior_ent_max": 70.14772033691406, "eval/prior_ent_mean": 58.38032531738281, "eval/prior_ent_min": 43.18827438354492, "eval/prior_ent_std": 4.271932125091553, "eval/rep_loss_mean": 18.438858032226562, "eval/rep_loss_std": 11.047593116760254, "eval/reward_avg": 0.02333984337747097, "eval/reward_loss_mean": 0.10391010344028473, "eval/reward_loss_std": 0.6620040535926819, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030076503753662, "eval/reward_neg_acc": 0.9909456372261047, "eval/reward_neg_loss": 0.04534972086548805, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 2.044210910797119, "eval/reward_pred": 0.0204448439180851, "eval/reward_rate": 0.029296875, "replay/size": 735969.0, "replay/inserts": 22016.0, "replay/samples": 22016.0, "replay/insert_wait_avg": 2.6727983251560567e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.961852831895961e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6232.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.166881431511033e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0990433692932, "timer/env.step_count": 2752.0, "timer/env.step_total": 240.08986616134644, "timer/env.step_frac": 0.24006608920701833, "timer/env.step_avg": 0.08724195718072182, "timer/env.step_min": 0.02465653419494629, "timer/env.step_max": 3.434251546859741, "timer/replay._sample_count": 22016.0, "timer/replay._sample_total": 11.368223905563354, "timer/replay._sample_frac": 0.011367098069871429, "timer/replay._sample_avg": 0.0005163619143151959, "timer/replay._sample_min": 0.00038623809814453125, "timer/replay._sample_max": 0.010785579681396484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3531.0, "timer/agent.policy_total": 61.55691909790039, "timer/agent.policy_frac": 0.0615508228970179, "timer/agent.policy_avg": 0.017433282100793087, "timer/agent.policy_min": 0.009554147720336914, "timer/agent.policy_max": 0.1264934539794922, "timer/dataset_train_count": 1376.0, "timer/dataset_train_total": 0.16052889823913574, "timer/dataset_train_frac": 0.00016051300049075177, "timer/dataset_train_avg": 0.000116663443487744, "timer/dataset_train_min": 0.00010180473327636719, "timer/dataset_train_max": 0.0004019737243652344, "timer/agent.train_count": 1376.0, "timer/agent.train_total": 619.6842832565308, "timer/agent.train_frac": 0.6196229137154651, "timer/agent.train_avg": 0.4503519500410834, "timer/agent.train_min": 0.43685317039489746, "timer/agent.train_max": 2.395052433013916, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47934889793395996, "timer/agent.report_frac": 0.00047930142630579157, "timer/agent.report_avg": 0.23967444896697998, "timer/agent.report_min": 0.2332301139831543, "timer/agent.report_max": 0.24611878395080566, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.765381624864617e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.013519816664694}
{"step": 737064, "time": 34435.53075480461, "episode/length": 359.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 737256, "time": 34443.6982152462, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 737368, "time": 34452.21078848839, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 737400, "time": 34454.9455845356, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 737400, "time": 34454.95458030701, "episode/length": 142.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 737680, "time": 34467.695003032684, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 738328, "time": 34490.769294023514, "episode/length": 133.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 738632, "time": 34502.36651134491, "episode/length": 195.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 738648, "time": 34504.389088630676, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 738656, "time": 34506.32186150551, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829351535836177, "episode/intrinsic_return": 0.0}
{"step": 738824, "time": 34513.444150686264, "episode/length": 399.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 739160, "time": 34526.215698480606, "episode/length": 184.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 739464, "time": 34537.98751473427, "episode/length": 257.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 739688, "time": 34547.19487166405, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 739872, "time": 34555.06072592735, "episode/length": 312.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 739920, "time": 34558.23018121719, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 34582.099781274796, "eval_episode/length": 104.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9904761904761905}
{"step": 740064, "time": 34587.014883995056, "eval_episode/length": 182.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9617486338797814}
{"step": 740064, "time": 34589.0856013298, "eval_episode/length": 194.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 740064, "time": 34591.438210487366, "eval_episode/length": 213.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.985981308411215}
{"step": 740064, "time": 34591.44671034813, "eval_episode/length": 213.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 740064, "time": 34596.20089006424, "eval_episode/length": 246.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 740064, "time": 34598.39943361282, "eval_episode/length": 47.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 740064, "time": 34601.94706964493, "eval_episode/length": 302.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9900990099009901}
{"step": 740144, "time": 34604.61053609848, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 740480, "time": 34617.255118370056, "episode/length": 164.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 740760, "time": 34628.006482601166, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 741104, "time": 34641.32050561905, "episode/length": 305.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 741400, "time": 34652.5856320858, "episode/length": 241.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 741616, "time": 34661.557744026184, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 742040, "time": 34677.066628456116, "episode/length": 293.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 742216, "time": 34684.38527679443, "episode/length": 258.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 742256, "time": 34687.398517131805, "episode/length": 186.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 742600, "time": 34700.31760954857, "episode/length": 340.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941348973607038, "episode/intrinsic_return": 0.0}
{"step": 742624, "time": 34702.92966079712, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 742656, "time": 34705.59239125252, "episode/length": 271.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 743400, "time": 34731.827655792236, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 743760, "time": 34745.58467125893, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 744048, "time": 34756.72801709175, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848942598187311, "episode/intrinsic_return": 0.0}
{"step": 744120, "time": 34760.548542022705, "episode/length": 237.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 744744, "time": 34782.969187021255, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 745160, "time": 34798.34087014198, "episode/length": 316.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 745240, "time": 34802.527680397034, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 745320, "time": 34806.68737530708, "episode/length": 149.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 745336, "time": 34808.65594148636, "episode/length": 334.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 745760, "time": 34826.192852020264, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 746096, "time": 34838.74187421799, "episode/length": 436.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954233409610984, "episode/intrinsic_return": 0.0}
{"step": 746208, "time": 34844.15035319328, "episode/length": 305.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 746448, "time": 34853.69272637367, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 746496, "time": 34856.873767614365, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 746648, "time": 34863.36427807808, "episode/length": 175.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 747144, "time": 34881.53383708, "episode/length": 80.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9382716049382716, "episode/intrinsic_return": 0.0}
{"step": 747608, "time": 34898.56438493729, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 747672, "time": 34902.32296991348, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 748032, "time": 34916.14668750763, "episode/length": 410.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 748136, "time": 34921.072115659714, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 748440, "time": 34932.97583913803, "episode/length": 50.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 748504, "time": 34936.57319808006, "episode/length": 103.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 748648, "time": 34942.87158083916, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 749160, "time": 34961.682159900665, "episode/length": 479.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 749224, "time": 34965.40773272514, "episode/length": 321.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984472049689441, "episode/intrinsic_return": 0.0}
{"step": 749344, "time": 34971.31487751007, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 749656, "time": 34983.07790899277, "episode/length": 486.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9835728952772074, "episode/intrinsic_return": 0.0}
{"step": 749768, "time": 34988.39265680313, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 749768, "time": 34988.399025440216, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 35017.025327920914, "eval_episode/length": 58.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9152542372881356}
{"step": 750048, "time": 35023.21432995796, "eval_episode/length": 163.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 750048, "time": 35024.93456888199, "eval_episode/length": 167.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 750048, "time": 35026.61465668678, "eval_episode/length": 169.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9588235294117647}
{"step": 750048, "time": 35028.45256638527, "eval_episode/length": 175.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 750048, "time": 35031.39767241478, "eval_episode/length": 205.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 750048, "time": 35033.45962929726, "eval_episode/length": 216.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 750048, "time": 35039.50291752815, "eval_episode/length": 155.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 750168, "time": 35043.23237800598, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 750416, "time": 35053.37484741211, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 750792, "time": 35067.25071692467, "episode/length": 180.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 750808, "time": 35069.46704864502, "episode/length": 205.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 751384, "time": 35090.37744784355, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 751744, "time": 35104.09139537811, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 751840, "time": 35109.036329984665, "episode/length": 272.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 752112, "time": 35119.72707271576, "episode/length": 162.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 752128, "time": 35121.7465338707, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 752320, "time": 35129.618827581406, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 752632, "time": 35141.52504301071, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 752704, "time": 35145.69417023659, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 752720, "time": 35147.88945031166, "episode/length": 49.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 753032, "time": 35159.62377309799, "episode/length": 407.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 753376, "time": 35172.924290180206, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 753880, "time": 35192.61141347885, "episode/length": 218.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 753904, "time": 35195.21110868454, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 753960, "time": 35198.484126091, "episode/length": 276.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 754088, "time": 35204.398055553436, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 754576, "time": 35222.443870306015, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 754600, "time": 35224.52438926697, "episode/length": 234.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 754952, "time": 35237.94946670532, "episode/length": 280.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 755392, "time": 35254.491850852966, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 755552, "time": 35261.56303477287, "episode/length": 271.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 756040, "time": 35279.266939878464, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 756048, "time": 35281.36982321739, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 756144, "time": 35286.13588142395, "episode/length": 256.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9844357976653697, "episode/intrinsic_return": 0.0}
{"step": 756160, "time": 35288.23871135712, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 756256, "time": 35293.34418082237, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 756408, "time": 35305.30267715454, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 756816, "time": 35320.81295323372, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 757296, "time": 35338.762637615204, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 757448, "time": 35345.21615219116, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 757488, "time": 35348.32483649254, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 757688, "time": 35356.69161558151, "episode/length": 205.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 757872, "time": 35364.66582155228, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 758040, "time": 35371.5554728508, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 758304, "time": 35382.642785310745, "episode/length": 185.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 758456, "time": 35389.03747463226, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 758888, "time": 35404.993639707565, "episode/length": 149.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 758904, "time": 35407.12832260132, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 759081, "time": 35415.65926837921, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.686775802720523, "train/action_min": 0.0, "train/action_std": 3.517314763779336, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03850820967068909, "train/actor_opt_grad_steps": 46640.0, "train/actor_opt_loss": -3.5097527147818965, "train/adv_mag": 0.5193560277739315, "train/adv_max": 0.47501250298310677, "train/adv_mean": 0.003296204398122801, "train/adv_min": -0.39998830062277774, "train/adv_std": 0.055527239905815595, "train/cont_avg": 0.9951033355496454, "train/cont_loss_mean": 5.460817957202915e-05, "train/cont_loss_std": 0.0015682332413249204, "train/cont_neg_acc": 1.0, "train/cont_neg_loss": 0.004291989508354015, "train/cont_pos_acc": 0.9999860529358505, "train/cont_pos_loss": 4.180740523528986e-05, "train/cont_pred": 0.9950862788984961, "train/cont_rate": 0.9951033355496454, "train/dyn_loss_mean": 13.564613910431557, "train/dyn_loss_std": 9.332245332974914, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9149677284220432, "train/extr_critic_critic_opt_grad_steps": 46640.0, "train/extr_critic_critic_opt_loss": 15992.238364361701, "train/extr_critic_mag": 7.874510582457197, "train/extr_critic_max": 7.874510582457197, "train/extr_critic_mean": 2.303379030092388, "train/extr_critic_min": -0.2443511663599217, "train/extr_critic_std": 1.7768048749747851, "train/extr_return_normed_mag": 1.5428362230882577, "train/extr_return_normed_max": 1.5428362230882577, "train/extr_return_normed_mean": 0.39491071895504676, "train/extr_return_normed_min": -0.1088704747669663, "train/extr_return_normed_std": 0.31857746120885755, "train/extr_return_rate": 0.8203808775184848, "train/extr_return_raw_mag": 8.837033048589179, "train/extr_return_raw_max": 8.837033048589179, "train/extr_return_raw_mean": 2.322076807630823, "train/extr_return_raw_min": -0.5371004601953723, "train/extr_return_raw_std": 1.808161069315376, "train/extr_reward_mag": 1.0311823973418972, "train/extr_reward_max": 1.0311823973418972, "train/extr_reward_mean": 0.0348586194904138, "train/extr_reward_min": -0.3885056515957447, "train/extr_reward_std": 0.17569355286182242, "train/image_loss_mean": 6.384442080842688, "train/image_loss_std": 11.207956919433377, "train/model_loss_mean": 14.578619280605452, "train/model_loss_std": 15.004718827863112, "train/model_opt_grad_norm": 56.30722424662705, "train/model_opt_grad_steps": 46597.2695035461, "train/model_opt_loss": 18788.718673814274, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1294.3262411347519, "train/policy_entropy_mag": 2.4034749311758272, "train/policy_entropy_max": 2.4034749311758272, "train/policy_entropy_mean": 0.48731823339529917, "train/policy_entropy_min": 0.07937501524145721, "train/policy_entropy_std": 0.562809815432163, "train/policy_logprob_mag": 7.438383799072699, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4868263908734558, "train/policy_logprob_min": -7.438383799072699, "train/policy_logprob_std": 1.0527385963615796, "train/policy_randomness_mag": 0.8483211765898034, "train/policy_randomness_max": 0.8483211765898034, "train/policy_randomness_mean": 0.17200195060131399, "train/policy_randomness_min": 0.028015897166750108, "train/policy_randomness_std": 0.19864716734869262, "train/post_ent_mag": 60.79303676524061, "train/post_ent_max": 60.79303676524061, "train/post_ent_mean": 43.907301990698414, "train/post_ent_min": 20.929089918204234, "train/post_ent_std": 7.693474894719766, "train/prior_ent_mag": 70.44740051918842, "train/prior_ent_max": 70.44740051918842, "train/prior_ent_mean": 57.537403864217985, "train/prior_ent_min": 42.218576390692526, "train/prior_ent_std": 4.396324362315185, "train/rep_loss_mean": 13.564613910431557, "train/rep_loss_std": 9.332245332974914, "train/reward_avg": 0.026881094586024893, "train/reward_loss_mean": 0.055354302180997024, "train/reward_loss_std": 0.2537918716457719, "train/reward_max_data": 1.0156028405994388, "train/reward_max_pred": 1.0120841374634006, "train/reward_neg_acc": 0.9927652727627585, "train/reward_neg_loss": 0.029125858520996487, "train/reward_pos_acc": 0.9662209613948849, "train/reward_pos_loss": 0.8622212190154597, "train/reward_pred": 0.02611306174294957, "train/reward_rate": 0.03151318705673759, "train_stats/sum_log_reward": 8.75306143809338, "train_stats/max_log_achievement_collect_coal": 0.23469387755102042, "train_stats/max_log_achievement_collect_drink": 4.846938775510204, "train_stats/max_log_achievement_collect_sapling": 1.5714285714285714, "train_stats/max_log_achievement_collect_stone": 8.040816326530612, "train_stats/max_log_achievement_collect_wood": 13.5, "train_stats/max_log_achievement_defeat_skeleton": 0.030612244897959183, "train_stats/max_log_achievement_defeat_zombie": 0.6122448979591837, "train_stats/max_log_achievement_eat_cow": 0.16326530612244897, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.01020408163265306, "train_stats/max_log_achievement_make_wood_pickaxe": 2.357142857142857, "train_stats/max_log_achievement_make_wood_sword": 0.8571428571428571, "train_stats/max_log_achievement_place_furnace": 0.07142857142857142, "train_stats/max_log_achievement_place_plant": 1.5510204081632653, "train_stats/max_log_achievement_place_stone": 6.428571428571429, "train_stats/max_log_achievement_place_table": 3.693877551020408, "train_stats/max_log_achievement_wake_up": 1.2040816326530612, "train_stats/mean_log_entropy": 0.5705499278039349, "eval_stats/sum_log_reward": 8.350000202655792, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 7.6875, "eval_stats/max_log_achievement_collect_wood": 12.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.9375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 4.8125, "eval_stats/max_log_achievement_place_table": 3.25, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 8.627590091236925e-07, "report/cont_loss_std": 1.4141805877443403e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.641145591856912e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.1158804719998443e-07, "report/cont_pred": 0.9931641817092896, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 11.335721015930176, "report/dyn_loss_std": 9.258218765258789, "report/image_loss_mean": 5.021530628204346, "report/image_loss_std": 10.618060111999512, "report/model_loss_mean": 11.878435134887695, "report/model_loss_std": 14.236128807067871, "report/post_ent_mag": 59.44975280761719, "report/post_ent_max": 59.44975280761719, "report/post_ent_mean": 45.1173210144043, "report/post_ent_min": 16.191057205200195, "report/post_ent_std": 7.791723728179932, "report/prior_ent_mag": 71.02554321289062, "report/prior_ent_max": 71.02554321289062, "report/prior_ent_mean": 56.88318634033203, "report/prior_ent_min": 42.48761749267578, "report/prior_ent_std": 4.406345844268799, "report/rep_loss_mean": 11.335721015930176, "report/rep_loss_std": 9.258218765258789, "report/reward_avg": 0.02949218638241291, "report/reward_loss_mean": 0.05547083169221878, "report/reward_loss_std": 0.23248526453971863, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001617431640625, "report/reward_neg_acc": 0.9939271211624146, "report/reward_neg_loss": 0.03272320702672005, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6797668933868408, "report/reward_pred": 0.029395846650004387, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.331159743742319e-06, "eval/cont_loss_std": 7.119282963685691e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.5634026340194396e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.344740318629192e-06, "eval/cont_pred": 0.9951128959655762, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 19.216793060302734, "eval/dyn_loss_std": 10.309042930603027, "eval/image_loss_mean": 13.276782035827637, "eval/image_loss_std": 14.644235610961914, "eval/model_loss_mean": 24.89077377319336, "eval/model_loss_std": 18.14091682434082, "eval/post_ent_mag": 65.84811401367188, "eval/post_ent_max": 65.84811401367188, "eval/post_ent_mean": 42.08140563964844, "eval/post_ent_min": 19.579755783081055, "eval/post_ent_std": 8.044820785522461, "eval/prior_ent_mag": 71.02554321289062, "eval/prior_ent_max": 71.02554321289062, "eval/prior_ent_mean": 59.09225082397461, "eval/prior_ent_min": 45.15131378173828, "eval/prior_ent_std": 4.218822002410889, "eval/rep_loss_mean": 19.216793060302734, "eval/rep_loss_std": 10.309042930603027, "eval/reward_avg": 0.02900390699505806, "eval/reward_loss_mean": 0.08391153812408447, "eval/reward_loss_std": 0.45058995485305786, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.001662254333496, "eval/reward_neg_acc": 0.9949392676353455, "eval/reward_neg_loss": 0.045468173921108246, "eval/reward_pos_acc": 0.9166666865348816, "eval/reward_pos_loss": 1.1389683485031128, "eval/reward_pred": 0.024316702038049698, "eval/reward_rate": 0.03515625, "replay/size": 758577.0, "replay/inserts": 22608.0, "replay/samples": 22608.0, "replay/insert_wait_avg": 1.315836862562737e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.915277736202167e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1196201532648617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0848603248596, "timer/env.step_count": 2826.0, "timer/env.step_total": 235.0721402168274, "timer/env.step_frac": 0.23505219361131857, "timer/env.step_avg": 0.08318193213617388, "timer/env.step_min": 0.02349257469177246, "timer/env.step_max": 3.485623598098755, "timer/replay._sample_count": 22608.0, "timer/replay._sample_total": 11.402421712875366, "timer/replay._sample_frac": 0.011401454181769629, "timer/replay._sample_avg": 0.0005043534020203188, "timer/replay._sample_min": 0.0004067420959472656, "timer/replay._sample_max": 0.011016607284545898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3449.0, "timer/agent.policy_total": 56.752185583114624, "timer/agent.policy_frac": 0.05674736998286295, "timer/agent.policy_avg": 0.016454678336652543, "timer/agent.policy_min": 0.009405136108398438, "timer/agent.policy_max": 0.10207557678222656, "timer/dataset_train_count": 1413.0, "timer/dataset_train_total": 0.15836501121520996, "timer/dataset_train_frac": 0.00015835157344924503, "timer/dataset_train_avg": 0.00011207714877226465, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0010769367218017578, "timer/agent.train_count": 1413.0, "timer/agent.train_total": 631.1168270111084, "timer/agent.train_frac": 0.6310632747766038, "timer/agent.train_avg": 0.44665026681607106, "timer/agent.train_min": 0.43198180198669434, "timer/agent.train_max": 1.6486682891845703, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48005032539367676, "timer/agent.report_frac": 0.00048000959162379584, "timer/agent.report_avg": 0.24002516269683838, "timer/agent.report_min": 0.23422670364379883, "timer/agent.report_max": 0.24582362174987793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8369403476290865e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 22.605782492508187}
{"step": 759448, "time": 35427.74179959297, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 759800, "time": 35441.13304710388, "episode/length": 219.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 759824, "time": 35443.783254146576, "episode/length": 296.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 35468.95742058754, "eval_episode/length": 77.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 760032, "time": 35476.039516448975, "eval_episode/length": 159.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 760032, "time": 35478.51518011093, "eval_episode/length": 175.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 760032, "time": 35480.93673491478, "eval_episode/length": 181.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 760032, "time": 35484.91119503975, "eval_episode/length": 217.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.963302752293578}
{"step": 760032, "time": 35487.11406373978, "eval_episode/length": 220.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9819004524886877}
{"step": 760032, "time": 35492.6439602375, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 760032, "time": 35494.83035445213, "eval_episode/length": 290.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9759450171821306}
{"step": 760224, "time": 35501.32625770569, "episode/length": 365.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 760256, "time": 35504.04352092743, "episode/length": 53.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 760328, "time": 35507.816571474075, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 760464, "time": 35514.12838077545, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 760600, "time": 35521.2193338871, "episode/length": 42.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 760752, "time": 35528.18561029434, "episode/length": 232.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 760800, "time": 35531.407054424286, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 761584, "time": 35559.2046751976, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 762104, "time": 35579.53954267502, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 762144, "time": 35582.64771294594, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 762224, "time": 35586.95209097862, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 762488, "time": 35597.16880273819, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 762760, "time": 35607.77075338364, "episode/length": 303.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 762776, "time": 35609.84446334839, "episode/length": 35.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 762888, "time": 35615.360409498215, "episode/length": 429.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 763208, "time": 35628.24197721481, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 763784, "time": 35649.18351507187, "episode/length": 414.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 763800, "time": 35651.42424225807, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 763896, "time": 35656.22173023224, "episode/length": 218.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 763968, "time": 35660.46113777161, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 764488, "time": 35679.09944629669, "episode/length": 215.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 765016, "time": 35698.29425954819, "episode/length": 279.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 765088, "time": 35702.47149014473, "episode/length": 274.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 765112, "time": 35704.81281161308, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 765536, "time": 35721.04110479355, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 765576, "time": 35723.79813694954, "episode/length": 209.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 765808, "time": 35733.36821055412, "episode/length": 33.0, "episode/score": 1.1000000163912773, "episode/reward_rate": 0.9117647058823529, "episode/intrinsic_return": 0.0}
{"step": 765896, "time": 35737.67406654358, "episode/length": 240.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 766536, "time": 35760.83418536186, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 766760, "time": 35769.99616479874, "episode/length": 208.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 766848, "time": 35774.663544893265, "episode/length": 294.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9932203389830508, "episode/intrinsic_return": 0.0}
{"step": 767352, "time": 35793.874608039856, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 767368, "time": 35796.02918100357, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 767400, "time": 35798.66380524635, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 767968, "time": 35819.35828256607, "episode/length": 368.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.986449864498645, "episode/intrinsic_return": 0.0}
{"step": 767976, "time": 35820.950555324554, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 767992, "time": 35823.09255003929, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 768096, "time": 35828.37960553169, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 768112, "time": 35830.65097475052, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 768536, "time": 35845.97598338127, "episode/length": 141.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 768760, "time": 35854.96335315704, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 769080, "time": 35867.17746281624, "episode/length": 135.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 769496, "time": 35882.64572286606, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 769496, "time": 35882.656932115555, "episode/length": 190.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 769656, "time": 35891.4336411953, "episode/length": 139.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35923.094302892685, "eval_episode/length": 115.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9568965517241379}
{"step": 770016, "time": 35926.67703795433, "eval_episode/length": 161.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 770016, "time": 35930.01614832878, "eval_episode/length": 201.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9752475247524752}
{"step": 770016, "time": 35934.637558460236, "eval_episode/length": 267.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.996268656716418}
{"step": 770016, "time": 35937.34711766243, "eval_episode/length": 177.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 770016, "time": 35940.68325352669, "eval_episode/length": 335.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 770016, "time": 35942.62221336365, "eval_episode/length": 185.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9623655913978495}
{"step": 770016, "time": 35945.99901795387, "eval_episode/length": 386.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9974160206718347}
{"step": 770072, "time": 35949.22464323044, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 770560, "time": 35967.28420495987, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 770760, "time": 35975.25580382347, "episode/length": 347.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 770960, "time": 35983.91139340401, "episode/length": 355.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9915730337078652, "episode/intrinsic_return": 0.0}
{"step": 771048, "time": 35988.15038347244, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 771224, "time": 35995.50796341896, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 771248, "time": 35998.04840874672, "episode/length": 486.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9897330595482546, "episode/intrinsic_return": 0.0}
{"step": 771432, "time": 36005.556522130966, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 771568, "time": 36011.984957933426, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 772144, "time": 36033.260325193405, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9939577039274925, "episode/intrinsic_return": 0.0}
{"step": 772232, "time": 36037.6435649395, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 772656, "time": 36053.75557017326, "episode/length": 178.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 772776, "time": 36059.13758301735, "episode/length": 190.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 772928, "time": 36065.987221717834, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 773000, "time": 36070.01282429695, "episode/length": 243.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 773144, "time": 36076.36326336861, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 773672, "time": 36095.51058602333, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 773792, "time": 36101.316042900085, "episode/length": 141.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 774112, "time": 36113.57845854759, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 774368, "time": 36123.6652803421, "episode/length": 170.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 774512, "time": 36133.27653861046, "episode/length": 170.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 775136, "time": 36155.744317770004, "episode/length": 275.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 775392, "time": 36166.42097520828, "episode/length": 199.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 775464, "time": 36170.39440083504, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 775848, "time": 36184.92678356171, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 775912, "time": 36188.70623612404, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 776080, "time": 36196.11036014557, "episode/length": 245.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 776272, "time": 36204.04873394966, "episode/length": 324.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 776720, "time": 36220.75234293938, "episode/length": 55.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 777048, "time": 36233.01800227165, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 777176, "time": 36238.87805938721, "episode/length": 254.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 777232, "time": 36242.620539188385, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 777600, "time": 36256.7198035717, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 777600, "time": 36256.72777438164, "episode/length": 45.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 778056, "time": 36275.02312850952, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 778352, "time": 36288.940193891525, "episode/length": 162.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.950920245398773, "episode/intrinsic_return": 0.0}
{"step": 778720, "time": 36303.29537320137, "episode/length": 406.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 779168, "time": 36319.966997385025, "episode/length": 248.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 779552, "time": 36334.87186598778, "episode/length": 243.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 779592, "time": 36337.613600730896, "episode/length": 1002.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9990029910269193, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 36374.2022562027, "eval_episode/length": 177.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 780000, "time": 36376.58361029625, "eval_episode/length": 195.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 780000, "time": 36378.53529715538, "eval_episode/length": 203.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 780000, "time": 36384.4944794178, "eval_episode/length": 220.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9683257918552036}
{"step": 780000, "time": 36387.54890012741, "eval_episode/length": 242.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 780000, "time": 36390.196692705154, "eval_episode/length": 47.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 780000, "time": 36393.29865813255, "eval_episode/length": 301.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9834437086092715}
{"step": 780000, "time": 36397.07333803177, "eval_episode/length": 175.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 780344, "time": 36408.39263343811, "episode/length": 248.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 780448, "time": 36413.584413290024, "episode/length": 215.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 780449, "time": 36415.788743019104, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.766437131967118, "train/action_min": 0.0, "train/action_std": 3.6071258641001003, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03903367783207057, "train/actor_opt_grad_steps": 48015.0, "train/actor_opt_loss": -7.000941847687337, "train/adv_mag": 0.5010870152444982, "train/adv_max": 0.46091943934782226, "train/adv_mean": 0.00261821363941391, "train/adv_min": -0.3867914237415613, "train/adv_std": 0.05557480712991152, "train/cont_avg": 0.9949058418843284, "train/cont_loss_mean": 0.00016294054882964125, "train/cont_loss_std": 0.004981822747262605, "train/cont_neg_acc": 0.9929726372903852, "train/cont_neg_loss": 0.013232848085152257, "train/cont_pos_acc": 0.9999779618498105, "train/cont_pos_loss": 9.767684985061868e-05, "train/cont_pred": 0.9949079276020847, "train/cont_rate": 0.9949058418843284, "train/dyn_loss_mean": 13.60676746937766, "train/dyn_loss_std": 9.360978425438724, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8748888582436006, "train/extr_critic_critic_opt_grad_steps": 48015.0, "train/extr_critic_critic_opt_loss": 15865.045716243003, "train/extr_critic_mag": 7.895556400071329, "train/extr_critic_max": 7.895556400071329, "train/extr_critic_mean": 2.336110232481316, "train/extr_critic_min": -0.2410205602645874, "train/extr_critic_std": 1.8194883216672868, "train/extr_return_normed_mag": 1.5533671129995317, "train/extr_return_normed_max": 1.5533671129995317, "train/extr_return_normed_mean": 0.3972306636287205, "train/extr_return_normed_min": -0.10742372569085946, "train/extr_return_normed_std": 0.32278639422868616, "train/extr_return_rate": 0.815139675763116, "train/extr_return_raw_mag": 8.9881651864123, "train/extr_return_raw_max": 8.9881651864123, "train/extr_return_raw_mean": 2.351179540157318, "train/extr_return_raw_min": -0.5456295147982996, "train/extr_return_raw_std": 1.8531730023782644, "train/extr_reward_mag": 1.0253702918095375, "train/extr_reward_max": 1.0253702918095375, "train/extr_reward_mean": 0.036332596760632385, "train/extr_reward_min": -0.4125668726750274, "train/extr_reward_std": 0.179053663651445, "train/image_loss_mean": 6.4036499208478785, "train/image_loss_std": 11.391764050099388, "train/model_loss_mean": 14.623281749326791, "train/model_loss_std": 15.201838941716437, "train/model_opt_grad_norm": 57.56736669967424, "train/model_opt_grad_steps": 47970.79104477612, "train/model_opt_loss": 19279.726788421176, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1315.2985074626865, "train/policy_entropy_mag": 2.3882101204857897, "train/policy_entropy_max": 2.3882101204857897, "train/policy_entropy_mean": 0.5085689260888455, "train/policy_entropy_min": 0.07937501737875725, "train/policy_entropy_std": 0.590829658641744, "train/policy_logprob_mag": 7.438383920868831, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5091229063361439, "train/policy_logprob_min": -7.438383920868831, "train/policy_logprob_std": 1.0652033615468153, "train/policy_randomness_mag": 0.8429333665477696, "train/policy_randomness_max": 0.8429333665477696, "train/policy_randomness_mean": 0.17950251275923715, "train/policy_randomness_min": 0.028015897873399864, "train/policy_randomness_std": 0.20853694261454825, "train/post_ent_mag": 60.68793177248827, "train/post_ent_max": 60.68793177248827, "train/post_ent_mean": 43.90144368072054, "train/post_ent_min": 20.738172232215085, "train/post_ent_std": 7.718878002309087, "train/prior_ent_mag": 70.44638608106926, "train/prior_ent_max": 70.44638608106926, "train/prior_ent_mean": 57.59490505617056, "train/prior_ent_min": 42.38760121188947, "train/prior_ent_std": 4.396959185600281, "train/rep_loss_mean": 13.60676746937766, "train/rep_loss_std": 9.360978425438724, "train/reward_avg": 0.028066697613850458, "train/reward_loss_mean": 0.055408550481965295, "train/reward_loss_std": 0.24904781746775356, "train/reward_max_data": 1.0149253766928146, "train/reward_max_pred": 1.010004858472454, "train/reward_neg_acc": 0.993180527615903, "train/reward_neg_loss": 0.028745265107657483, "train/reward_pos_acc": 0.96605749005702, "train/reward_pos_loss": 0.8507109626905242, "train/reward_pred": 0.027255559722378628, "train/reward_rate": 0.03270026819029851, "train_stats/sum_log_reward": 8.466666875945197, "train_stats/max_log_achievement_collect_coal": 0.3, "train_stats/max_log_achievement_collect_drink": 5.555555555555555, "train_stats/max_log_achievement_collect_sapling": 1.6, "train_stats/max_log_achievement_collect_stone": 6.988888888888889, "train_stats/max_log_achievement_collect_wood": 12.333333333333334, "train_stats/max_log_achievement_defeat_skeleton": 0.011111111111111112, "train_stats/max_log_achievement_defeat_zombie": 0.4777777777777778, "train_stats/max_log_achievement_eat_cow": 0.14444444444444443, "train_stats/max_log_achievement_eat_plant": 0.044444444444444446, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011111111111111112, "train_stats/max_log_achievement_make_stone_sword": 0.022222222222222223, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5444444444444445, "train_stats/max_log_achievement_make_wood_sword": 1.0666666666666667, "train_stats/max_log_achievement_place_furnace": 0.06666666666666667, "train_stats/max_log_achievement_place_plant": 1.5777777777777777, "train_stats/max_log_achievement_place_stone": 5.8, "train_stats/max_log_achievement_place_table": 3.022222222222222, "train_stats/max_log_achievement_wake_up": 1.1555555555555554, "train_stats/mean_log_entropy": 0.5705237696568172, "eval_stats/sum_log_reward": 8.2666667898496, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 4.208333333333333, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 4.916666666666667, "eval_stats/max_log_achievement_collect_wood": 13.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.7083333333333334, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.125, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_stone": 3.25, "eval_stats/max_log_achievement_place_table": 3.625, "eval_stats/max_log_achievement_wake_up": 1.0416666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 1.7264301277464256e-05, "report/cont_loss_std": 0.0003494473348837346, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001727316528558731, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.873465958458837e-06, "report/cont_pred": 0.9951168298721313, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.194662094116211, "report/dyn_loss_std": 9.516740798950195, "report/image_loss_mean": 6.248279094696045, "report/image_loss_std": 11.98135757446289, "report/model_loss_mean": 14.82068157196045, "report/model_loss_std": 15.897058486938477, "report/post_ent_mag": 61.9764404296875, "report/post_ent_max": 61.9764404296875, "report/post_ent_mean": 44.204891204833984, "report/post_ent_min": 18.515974044799805, "report/post_ent_std": 7.739532470703125, "report/prior_ent_mag": 70.71318054199219, "report/prior_ent_max": 70.71318054199219, "report/prior_ent_mean": 58.325992584228516, "report/prior_ent_min": 39.733604431152344, "report/prior_ent_std": 4.450239658355713, "report/rep_loss_mean": 14.194662094116211, "report/rep_loss_std": 9.516740798950195, "report/reward_avg": 0.02128906175494194, "report/reward_loss_mean": 0.05558851733803749, "report/reward_loss_std": 0.20233505964279175, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0029876232147217, "report/reward_neg_acc": 0.9879518747329712, "report/reward_neg_loss": 0.0333748497068882, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8457606434822083, "report/reward_pred": 0.02123471349477768, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.239951471798122e-05, "eval/cont_loss_std": 0.0017388463020324707, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.012660454027354717, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.837380854245566e-07, "eval/cont_pred": 0.9951770305633545, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.514938354492188, "eval/dyn_loss_std": 11.21540641784668, "eval/image_loss_mean": 11.596345901489258, "eval/image_loss_std": 17.74394416809082, "eval/model_loss_mean": 22.20332908630371, "eval/model_loss_std": 21.984243392944336, "eval/post_ent_mag": 59.85882568359375, "eval/post_ent_max": 59.85882568359375, "eval/post_ent_mean": 42.81203079223633, "eval/post_ent_min": 21.841630935668945, "eval/post_ent_std": 8.19912052154541, "eval/prior_ent_mag": 70.71318054199219, "eval/prior_ent_max": 70.71318054199219, "eval/prior_ent_mean": 57.74169158935547, "eval/prior_ent_min": 45.217838287353516, "eval/prior_ent_std": 4.049824237823486, "eval/rep_loss_mean": 17.514938354492188, "eval/rep_loss_std": 11.21540641784668, "eval/reward_avg": 0.02763671800494194, "eval/reward_loss_mean": 0.09795811027288437, "eval/reward_loss_std": 0.6640229225158691, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047214031219482, "eval/reward_neg_acc": 0.9868819117546082, "eval/reward_neg_loss": 0.03292654827237129, "eval/reward_pos_acc": 0.8181818127632141, "eval/reward_pos_loss": 2.050875425338745, "eval/reward_pred": 0.024903519079089165, "eval/reward_rate": 0.0322265625, "replay/size": 779945.0, "replay/inserts": 21368.0, "replay/samples": 21360.0, "replay/insert_wait_avg": 1.3337180838518846e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.960125898154041e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.186692668486011e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.854534149169922e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1162369251251, "timer/env.step_count": 2671.0, "timer/env.step_total": 221.88211703300476, "timer/env.step_frac": 0.2218563291354865, "timer/env.step_avg": 0.08307080383115116, "timer/env.step_min": 0.023349523544311523, "timer/env.step_max": 3.406198263168335, "timer/replay._sample_count": 21360.0, "timer/replay._sample_total": 10.789288997650146, "timer/replay._sample_frac": 0.01078803502963016, "timer/replay._sample_avg": 0.0005051165261072166, "timer/replay._sample_min": 0.0003998279571533203, "timer/replay._sample_max": 0.013751506805419922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3703.0, "timer/agent.policy_total": 63.49792695045471, "timer/agent.policy_frac": 0.0634905470044964, "timer/agent.policy_avg": 0.01714769833930724, "timer/agent.policy_min": 0.009488344192504883, "timer/agent.policy_max": 0.12935686111450195, "timer/dataset_train_count": 1335.0, "timer/dataset_train_total": 0.15015721321105957, "timer/dataset_train_frac": 0.0001501397614268523, "timer/dataset_train_avg": 0.00011247731326671129, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0009982585906982422, "timer/agent.train_count": 1335.0, "timer/agent.train_total": 595.9933743476868, "timer/agent.train_frac": 0.5959241059620018, "timer/agent.train_avg": 0.44643698453010244, "timer/agent.train_min": 0.43259596824645996, "timer/agent.train_max": 1.641676664352417, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48723340034484863, "timer/agent.report_frac": 0.00048717677241483074, "timer/agent.report_avg": 0.24361670017242432, "timer/agent.report_min": 0.23583292961120605, "timer/agent.report_max": 0.2514004707336426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.003724952927238e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.365224729078236}
{"step": 780688, "time": 36423.96940112114, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 780736, "time": 36427.15336847305, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.991044776119403, "episode/intrinsic_return": 0.0}
{"step": 781176, "time": 36443.23354482651, "episode/length": 202.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 781528, "time": 36456.7203233242, "episode/length": 680.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9985315712187959, "episode/intrinsic_return": 0.0}
{"step": 781544, "time": 36458.83770227432, "episode/length": 243.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 781720, "time": 36466.46910619736, "episode/length": 514.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9922330097087378, "episode/intrinsic_return": 0.0}
{"step": 781912, "time": 36474.50026535988, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 782160, "time": 36484.63989543915, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 782336, "time": 36492.30166721344, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 782376, "time": 36495.03817105293, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9533333333333334, "episode/intrinsic_return": 0.0}
{"step": 782384, "time": 36497.072578430176, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 783160, "time": 36524.27792787552, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 783632, "time": 36541.8492667675, "episode/length": 156.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 783688, "time": 36545.078853845596, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 783760, "time": 36549.323419094086, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 783912, "time": 36555.78902244568, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 783952, "time": 36558.98424124718, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 784832, "time": 36589.801731824875, "episode/length": 410.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975669099756691, "episode/intrinsic_return": 0.0}
{"step": 785152, "time": 36602.028232336044, "episode/length": 351.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 785160, "time": 36603.70737910271, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 785184, "time": 36606.25198125839, "episode/length": 252.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 785384, "time": 36614.31304860115, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 785432, "time": 36617.61706805229, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 785848, "time": 36632.93868684769, "episode/length": 260.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9693486590038314, "episode/intrinsic_return": 0.0}
{"step": 786408, "time": 36653.28416252136, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 786416, "time": 36655.44943976402, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 786464, "time": 36660.350568532944, "episode/length": 159.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 786680, "time": 36668.85756278038, "episode/length": 340.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9853372434017595, "episode/intrinsic_return": 0.0}
{"step": 786704, "time": 36671.59355664253, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8888888888888888, "episode/intrinsic_return": 0.0}
{"step": 786776, "time": 36675.325165987015, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 787128, "time": 36688.66572165489, "episode/length": 159.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 787248, "time": 36694.461178064346, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 787728, "time": 36712.25096154213, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 787744, "time": 36714.30496430397, "episode/length": 288.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 788192, "time": 36730.818873643875, "episode/length": 55.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 788352, "time": 36737.67104935646, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 788496, "time": 36744.15251040459, "episode/length": 223.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 788760, "time": 36754.57199001312, "episode/length": 50.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9215686274509803, "episode/intrinsic_return": 0.0}
{"step": 788784, "time": 36757.61164855957, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 788816, "time": 36761.34752345085, "episode/length": 254.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 789232, "time": 36777.42606687546, "episode/length": 262.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 789416, "time": 36784.91938281059, "episode/length": 368.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 790040, "time": 36807.401767253876, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 790080, "time": 36810.59645462036, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 36830.204261779785, "eval_episode/length": 56.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 790088, "time": 36839.724162817, "eval_episode/length": 174.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 790088, "time": 36842.23586368561, "eval_episode/length": 196.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 790088, "time": 36844.65840673447, "eval_episode/length": 213.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 790088, "time": 36846.91067171097, "eval_episode/length": 52.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 790088, "time": 36848.910942554474, "eval_episode/length": 235.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 790088, "time": 36851.858317136765, "eval_episode/length": 59.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 790088, "time": 36851.868025541306, "eval_episode/length": 256.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9961089494163424}
{"step": 790256, "time": 36857.69220137596, "episode/length": 315.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 790608, "time": 36870.978142261505, "episode/length": 43.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 791024, "time": 36886.6220304966, "episode/length": 315.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 791360, "time": 36899.552540540695, "episode/length": 242.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 791408, "time": 36902.80524969101, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 791656, "time": 36912.70505404472, "episode/length": 358.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 791664, "time": 36915.28476047516, "episode/length": 303.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 792176, "time": 36934.50077295303, "episode/length": 266.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 792480, "time": 36946.344148397446, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 792592, "time": 36951.68455028534, "episode/length": 549.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9945454545454545, "episode/intrinsic_return": 0.0}
{"step": 792952, "time": 36965.03588962555, "episode/length": 58.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 793040, "time": 36969.98917722702, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769736842105263, "episode/intrinsic_return": 0.0}
{"step": 793256, "time": 36978.73602056503, "episode/length": 82.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 793336, "time": 36982.9790494442, "episode/length": 240.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 793608, "time": 36993.653077840805, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 794008, "time": 37008.71111702919, "episode/length": 292.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9897610921501706, "episode/intrinsic_return": 0.0}
{"step": 794248, "time": 37018.275804042816, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 794448, "time": 37026.80938196182, "episode/length": 385.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9974093264248705, "episode/intrinsic_return": 0.0}
{"step": 794784, "time": 37041.30837416649, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 795160, "time": 37055.414863824844, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 795240, "time": 37060.323551654816, "episode/length": 274.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 795496, "time": 37070.902346372604, "episode/length": 279.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 796056, "time": 37091.29838204384, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 796144, "time": 37095.95651388168, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 796152, "time": 37097.64098215103, "episode/length": 561.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9839857651245552, "episode/intrinsic_return": 0.0}
{"step": 796344, "time": 37105.60644221306, "episode/length": 261.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732824427480916, "episode/intrinsic_return": 0.0}
{"step": 796496, "time": 37116.71069741249, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 796576, "time": 37121.119183540344, "episode/length": 320.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 797000, "time": 37136.459327697754, "episode/length": 117.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 797264, "time": 37147.02948999405, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 797272, "time": 37148.58757662773, "episode/length": 96.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9896907216494846, "episode/intrinsic_return": 0.0}
{"step": 797768, "time": 37167.01739382744, "episode/length": 201.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 797928, "time": 37173.88013291359, "episode/length": 335.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 798552, "time": 37196.211399793625, "episode/length": 97.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9489795918367347, "episode/intrinsic_return": 0.0}
{"step": 798600, "time": 37199.45173954964, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 798704, "time": 37204.69238901138, "episode/length": 179.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 798704, "time": 37204.70219683647, "episode/length": 265.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981203007518797, "episode/intrinsic_return": 0.0}
{"step": 798896, "time": 37214.73778438568, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 799464, "time": 37234.74918150902, "episode/length": 414.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 799472, "time": 37236.90841007233, "episode/length": 390.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.989769820971867, "episode/intrinsic_return": 0.0}
{"step": 799632, "time": 37243.92866587639, "episode/length": 212.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9906103286384976, "episode/intrinsic_return": 0.0}
{"step": 799632, "time": 37243.93776392937, "episode/length": 134.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 800032, "time": 37260.486015081406, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 37278.82392311096, "eval_episode/length": 64.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9384615384615385}
{"step": 800072, "time": 37283.977499485016, "eval_episode/length": 145.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 800072, "time": 37285.946569919586, "eval_episode/length": 153.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 800072, "time": 37288.087700366974, "eval_episode/length": 166.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 800072, "time": 37290.04119157791, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9540229885057471}
{"step": 800072, "time": 37292.81117296219, "eval_episode/length": 197.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 800072, "time": 37294.66571354866, "eval_episode/length": 204.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 800072, "time": 37300.0323369503, "eval_episode/length": 288.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9896193771626297}
{"step": 800328, "time": 37308.48896551132, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 800560, "time": 37317.95882678032, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 800736, "time": 37325.33608627319, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 801096, "time": 37338.61629796028, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 801136, "time": 37341.69280385971, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 801168, "time": 37344.41190338135, "episode/length": 307.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 801824, "time": 37367.886845350266, "episode/length": 186.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 801944, "time": 37373.22161889076, "episode/length": 238.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 802112, "time": 37380.53276705742, "episode/length": 438.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 802344, "time": 37389.65458869934, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 802360, "time": 37391.88853883743, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 802592, "time": 37401.45827293396, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 802672, "time": 37405.72724223137, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 802857, "time": 37415.92980360985, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.743821498325893, "train/action_min": 0.0, "train/action_std": 3.449288730961936, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0387946304066905, "train/actor_opt_grad_steps": 49385.0, "train/actor_opt_loss": -2.9937809637880752, "train/adv_mag": 0.4983556917735508, "train/adv_max": 0.4500145062804222, "train/adv_mean": 0.0035034257170212055, "train/adv_min": -0.3825647172118936, "train/adv_std": 0.05577029202665602, "train/cont_avg": 0.9951311383928572, "train/cont_loss_mean": 0.0001733740867913574, "train/cont_loss_std": 0.005212867279721779, "train/cont_neg_acc": 0.9965741698690456, "train/cont_neg_loss": 0.008906817262657556, "train/cont_pos_acc": 0.9999508900301797, "train/cont_pos_loss": 0.00013192246167901902, "train/cont_pred": 0.9950985499790737, "train/cont_rate": 0.9951311383928572, "train/dyn_loss_mean": 13.69645060811724, "train/dyn_loss_std": 9.315855360031128, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.93474286539214, "train/extr_critic_critic_opt_grad_steps": 49385.0, "train/extr_critic_critic_opt_loss": 16155.286955915179, "train/extr_critic_mag": 7.987448249544416, "train/extr_critic_max": 7.987448249544416, "train/extr_critic_mean": 2.3561012625694273, "train/extr_critic_min": -0.22226844600268772, "train/extr_critic_std": 1.8120542764663696, "train/extr_return_normed_mag": 1.5391672262123652, "train/extr_return_normed_max": 1.5391672262123652, "train/extr_return_normed_mean": 0.39583516184772766, "train/extr_return_normed_min": -0.0993475107210023, "train/extr_return_normed_std": 0.31545538625546865, "train/extr_return_rate": 0.8271582475730351, "train/extr_return_raw_mag": 9.055738639831542, "train/extr_return_raw_max": 9.055738639831542, "train/extr_return_raw_mean": 2.376594819341387, "train/extr_return_raw_min": -0.5162933075002262, "train/extr_return_raw_std": 1.8430775097438268, "train/extr_reward_mag": 1.0275993534496852, "train/extr_reward_max": 1.0275993534496852, "train/extr_reward_mean": 0.03789172700739333, "train/extr_reward_min": -0.38637636048453194, "train/extr_reward_std": 0.18291630830083574, "train/image_loss_mean": 6.307128696782248, "train/image_loss_std": 11.435803811890738, "train/model_loss_mean": 14.579653092793055, "train/model_loss_std": 15.23115051133292, "train/model_opt_grad_norm": 55.77675215857369, "train/model_opt_grad_steps": 49339.55714285714, "train/model_opt_loss": 18991.217138671876, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1303.5714285714287, "train/policy_entropy_mag": 2.37706869159426, "train/policy_entropy_max": 2.37706869159426, "train/policy_entropy_mean": 0.47822929812329157, "train/policy_entropy_min": 0.07937501599746091, "train/policy_entropy_std": 0.5527460145098823, "train/policy_logprob_mag": 7.438383787018912, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47859710646527154, "train/policy_logprob_min": -7.438383787018912, "train/policy_logprob_std": 1.047074699827603, "train/policy_randomness_mag": 0.8390009352139064, "train/policy_randomness_max": 0.8390009352139064, "train/policy_randomness_mean": 0.16879395565816335, "train/policy_randomness_min": 0.02801589740972434, "train/policy_randomness_std": 0.19509508716208593, "train/post_ent_mag": 60.4666043145316, "train/post_ent_max": 60.4666043145316, "train/post_ent_mean": 43.84298351832798, "train/post_ent_min": 20.95613064084734, "train/post_ent_std": 7.6915977716445925, "train/prior_ent_mag": 70.56188485281808, "train/prior_ent_max": 70.56188485281808, "train/prior_ent_mean": 57.627700860159734, "train/prior_ent_min": 42.63836740766253, "train/prior_ent_std": 4.381769733769553, "train/rep_loss_mean": 13.69645060811724, "train/rep_loss_std": 9.315855360031128, "train/reward_avg": 0.028549106964575393, "train/reward_loss_mean": 0.05448068061045238, "train/reward_loss_std": 0.2431293906910079, "train/reward_max_data": 1.0150000035762787, "train/reward_max_pred": 1.011527430159705, "train/reward_neg_acc": 0.9926557055541447, "train/reward_neg_loss": 0.028284390826177383, "train/reward_pos_acc": 0.970986459510667, "train/reward_pos_loss": 0.8293889479977744, "train/reward_pred": 0.027894610479207976, "train/reward_rate": 0.03281947544642857, "train_stats/sum_log_reward": 8.250000172257423, "train_stats/max_log_achievement_collect_coal": 0.27, "train_stats/max_log_achievement_collect_drink": 4.68, "train_stats/max_log_achievement_collect_sapling": 1.4, "train_stats/max_log_achievement_collect_stone": 6.91, "train_stats/max_log_achievement_collect_wood": 12.28, "train_stats/max_log_achievement_defeat_skeleton": 0.03, "train_stats/max_log_achievement_defeat_zombie": 0.56, "train_stats/max_log_achievement_eat_cow": 0.13, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.04, "train_stats/max_log_achievement_make_wood_pickaxe": 2.18, "train_stats/max_log_achievement_make_wood_sword": 0.68, "train_stats/max_log_achievement_place_furnace": 0.05, "train_stats/max_log_achievement_place_plant": 1.36, "train_stats/max_log_achievement_place_stone": 5.91, "train_stats/max_log_achievement_place_table": 3.31, "train_stats/max_log_achievement_wake_up": 1.2, "train_stats/mean_log_entropy": 0.5413802918791771, "eval_stats/sum_log_reward": 7.03750017285347, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 2.25, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_stone": 7.0, "eval_stats/max_log_achievement_collect_wood": 8.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.4375, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 5.0, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 0.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.7913054054806707e-06, "report/cont_loss_std": 4.7716395783936605e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001578539377078414, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.030448740697466e-06, "report/cont_pred": 0.9951159954071045, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.374860763549805, "report/dyn_loss_std": 9.502543449401855, "report/image_loss_mean": 7.200238227844238, "report/image_loss_std": 13.7328462600708, "report/model_loss_mean": 15.28711223602295, "report/model_loss_std": 17.475305557250977, "report/post_ent_mag": 62.681026458740234, "report/post_ent_max": 62.681026458740234, "report/post_ent_mean": 44.7863883972168, "report/post_ent_min": 21.666973114013672, "report/post_ent_std": 7.890200138092041, "report/prior_ent_mag": 70.47586059570312, "report/prior_ent_max": 70.47586059570312, "report/prior_ent_mean": 58.01355743408203, "report/prior_ent_min": 47.32695770263672, "report/prior_ent_std": 4.151268005371094, "report/rep_loss_mean": 13.374860763549805, "report/rep_loss_std": 9.502543449401855, "report/reward_avg": 0.02099609375, "report/reward_loss_mean": 0.06195501983165741, "report/reward_loss_std": 0.32183077931404114, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0001938343048096, "report/reward_neg_acc": 0.99698805809021, "report/reward_neg_loss": 0.03737132251262665, "report/reward_pos_acc": 0.9285714626312256, "report/reward_pos_loss": 0.936432421207428, "report/reward_pred": 0.0192014928907156, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.396863790949283e-07, "eval/cont_loss_std": 1.1587157132453285e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00011693283886415884, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.700438415104145e-07, "eval/cont_pred": 0.9951175451278687, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 20.18393898010254, "eval/dyn_loss_std": 10.792617797851562, "eval/image_loss_mean": 12.21824836730957, "eval/image_loss_std": 18.953998565673828, "eval/model_loss_mean": 24.485733032226562, "eval/model_loss_std": 23.097820281982422, "eval/post_ent_mag": 57.46209716796875, "eval/post_ent_max": 57.46209716796875, "eval/post_ent_mean": 40.24576950073242, "eval/post_ent_min": 20.654525756835938, "eval/post_ent_std": 7.519392490386963, "eval/prior_ent_mag": 70.47586059570312, "eval/prior_ent_max": 70.47586059570312, "eval/prior_ent_mean": 57.592063903808594, "eval/prior_ent_min": 46.97077178955078, "eval/prior_ent_std": 3.974703788757324, "eval/rep_loss_mean": 20.18393898010254, "eval/rep_loss_std": 10.792617797851562, "eval/reward_avg": 0.04423827677965164, "eval/reward_loss_mean": 0.15711888670921326, "eval/reward_loss_std": 0.8009733557701111, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006299018859863, "eval/reward_neg_acc": 0.9876797199249268, "eval/reward_neg_loss": 0.07748807221651077, "eval/reward_pos_acc": 0.85999995470047, "eval/reward_pos_loss": 1.7083269357681274, "eval/reward_pred": 0.04077575355768204, "eval/reward_rate": 0.048828125, "replay/size": 802353.0, "replay/inserts": 22408.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3347844148014155e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.126711675901229e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2400167765634837e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.258487701416016e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1239206790924, "timer/env.step_count": 2801.0, "timer/env.step_total": 241.8247995376587, "timer/env.step_frac": 0.24179483615736103, "timer/env.step_avg": 0.08633516584707558, "timer/env.step_min": 0.023787260055541992, "timer/env.step_max": 3.6597096920013428, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.429083108901978, "timer/replay._sample_frac": 0.011427666984648798, "timer/replay._sample_avg": 0.0005098627368353844, "timer/replay._sample_min": 0.00042319297790527344, "timer/replay._sample_max": 0.03094315528869629, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3347.0, "timer/agent.policy_total": 58.30682587623596, "timer/agent.policy_frac": 0.058299601350045846, "timer/agent.policy_avg": 0.01742062320771914, "timer/agent.policy_min": 0.009533166885375977, "timer/agent.policy_max": 0.13486146926879883, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.15790200233459473, "timer/dataset_train_frac": 0.00015788243743573093, "timer/dataset_train_avg": 0.00011270663978200908, "timer/dataset_train_min": 9.560585021972656e-05, "timer/dataset_train_max": 0.0010633468627929688, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 624.235604763031, "timer/agent.train_frac": 0.6241582586477582, "timer/agent.train_avg": 0.44556431460601786, "timer/agent.train_min": 0.4337632656097412, "timer/agent.train_max": 1.6696383953094482, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.484774112701416, "timer/agent.report_frac": 0.00048471404660759476, "timer/agent.report_avg": 0.242387056350708, "timer/agent.report_min": 0.23531055450439453, "timer/agent.report_max": 0.24946355819702148, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.1944131061195255e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 22.404910824973733}
{"step": 802992, "time": 37420.60762882233, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 803272, "time": 37431.424183130264, "episode/length": 34.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 803560, "time": 37443.666482925415, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 803664, "time": 37448.98531007767, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 803776, "time": 37454.43286156654, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 804016, "time": 37464.208557128906, "episode/length": 431.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 804088, "time": 37467.94490766525, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 804224, "time": 37474.85124349594, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 804424, "time": 37483.21744275093, "episode/length": 324.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 804664, "time": 37492.84254741669, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 805328, "time": 37516.96290540695, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 805464, "time": 37522.92201256752, "episode/length": 180.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 805640, "time": 37530.28303694725, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 805704, "time": 37534.07749772072, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 805744, "time": 37537.19186472893, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 806032, "time": 37548.63283920288, "episode/length": 242.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 806448, "time": 37564.17894768715, "episode/length": 222.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 806944, "time": 37582.272037267685, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 806984, "time": 37585.120528936386, "episode/length": 414.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951807228915662, "episode/intrinsic_return": 0.0}
{"step": 807488, "time": 37604.04788637161, "episode/length": 181.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 807880, "time": 37618.48024058342, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 808280, "time": 37633.5652282238, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 808304, "time": 37636.23614668846, "episode/length": 371.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 808320, "time": 37638.356706142426, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 808352, "time": 37641.06865000725, "episode/length": 170.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 808632, "time": 37651.73549294472, "episode/length": 272.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 808784, "time": 37658.55938243866, "episode/length": 379.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 809040, "time": 37668.80135798454, "episode/length": 446.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 809144, "time": 37673.542521476746, "episode/length": 44.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 809416, "time": 37684.19765639305, "episode/length": 240.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 809800, "time": 37698.66243100166, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 809824, "time": 37701.22337222099, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 37726.09557509422, "eval_episode/length": 57.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 810056, "time": 37728.352720975876, "eval_episode/length": 71.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 810056, "time": 37734.441224098206, "eval_episode/length": 175.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 810056, "time": 37736.583142995834, "eval_episode/length": 186.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 810056, "time": 37739.188973903656, "eval_episode/length": 207.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9663461538461539}
{"step": 810056, "time": 37741.28382921219, "eval_episode/length": 161.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 810056, "time": 37745.967517375946, "eval_episode/length": 218.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 810056, "time": 37749.197851896286, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9605263157894737}
{"step": 810232, "time": 37756.60389280319, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 810352, "time": 37762.458357572556, "episode/length": 163.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 811008, "time": 37786.04268884659, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 811008, "time": 37786.08220767975, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 811360, "time": 37803.15495443344, "episode/length": 194.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 811688, "time": 37815.515741586685, "episode/length": 420.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 811696, "time": 37817.64597320557, "episode/length": 233.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 811944, "time": 37827.27396821976, "episode/length": 413.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975845410628019, "episode/intrinsic_return": 0.0}
{"step": 812584, "time": 37850.44351863861, "episode/length": 278.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 812608, "time": 37853.13167929649, "episode/length": 199.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 812912, "time": 37864.7489593029, "episode/length": 37.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 813016, "time": 37869.566135168076, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 813272, "time": 37879.954580545425, "episode/length": 282.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 813384, "time": 37885.176567316055, "episode/length": 393.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 813656, "time": 37895.98545837402, "episode/length": 245.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 813880, "time": 37905.85220742226, "episode/length": 61.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9193548387096774, "episode/intrinsic_return": 0.0}
{"step": 814160, "time": 37917.155680418015, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 814768, "time": 37939.29001879692, "episode/length": 272.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 814920, "time": 37945.69568514824, "episode/length": 444.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977528089887641, "episode/intrinsic_return": 0.0}
{"step": 815208, "time": 37956.92126870155, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 815488, "time": 37968.27637267113, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 815520, "time": 37970.92426156998, "episode/length": 446.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 815624, "time": 37975.85264825821, "episode/length": 325.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 815704, "time": 37980.62349796295, "episode/length": 303.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 816168, "time": 37998.427798748016, "episode/length": 57.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 816296, "time": 38004.28191256523, "episode/length": 266.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9925093632958801, "episode/intrinsic_return": 0.0}
{"step": 816808, "time": 38023.48070645332, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 816904, "time": 38028.38169193268, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 816912, "time": 38030.51832842827, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 817000, "time": 38034.86545872688, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 817032, "time": 38037.45414710045, "episode/length": 282.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 817464, "time": 38053.75961017609, "episode/length": 69.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 817824, "time": 38067.679842710495, "episode/length": 190.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 818120, "time": 38078.966619729996, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 818152, "time": 38081.70340466499, "episode/length": 154.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 818456, "time": 38093.45859527588, "episode/length": 181.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 818656, "time": 38101.919378995895, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 818808, "time": 38108.38042664528, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 818944, "time": 38114.839973926544, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 819080, "time": 38120.72055006027, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 819440, "time": 38136.35347652435, "episode/length": 44.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 819832, "time": 38151.03849864006, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 819864, "time": 38153.64202237129, "episode/length": 131.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 819984, "time": 38159.48410511017, "episode/length": 165.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 38183.2139275074, "eval_episode/length": 160.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 820040, "time": 38185.67265415192, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9615384615384616}
{"step": 820040, "time": 38188.15091729164, "eval_episode/length": 203.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 820040, "time": 38189.896580696106, "eval_episode/length": 204.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 820040, "time": 38191.86703705788, "eval_episode/length": 213.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9719626168224299}
{"step": 820040, "time": 38197.42012810707, "eval_episode/length": 277.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9964028776978417}
{"step": 820040, "time": 38201.27172780037, "eval_episode/length": 147.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 820040, "time": 38204.95348119736, "eval_episode/length": 153.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 820232, "time": 38211.36027479172, "episode/length": 49.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 820488, "time": 38221.507069826126, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 820584, "time": 38226.27382564545, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 820880, "time": 38237.98427248001, "episode/length": 179.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 821120, "time": 38247.67225193977, "episode/length": 411.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 821208, "time": 38251.923744916916, "episode/length": 385.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9922279792746114, "episode/intrinsic_return": 0.0}
{"step": 821440, "time": 38261.5973572731, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 821640, "time": 38269.66973924637, "episode/length": 64.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 822016, "time": 38284.15023612976, "episode/length": 253.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9803149606299213, "episode/intrinsic_return": 0.0}
{"step": 822064, "time": 38287.32627105713, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 822280, "time": 38295.992305994034, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 822472, "time": 38303.965908527374, "episode/length": 235.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 822480, "time": 38306.086753606796, "episode/length": 158.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 823280, "time": 38334.90410733223, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 823416, "time": 38340.79836511612, "episode/length": 443.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 823560, "time": 38347.224692583084, "episode/length": 264.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 823776, "time": 38356.32565355301, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 823976, "time": 38364.46740913391, "episode/length": 186.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 824440, "time": 38382.165065050125, "episode/length": 144.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 825184, "time": 38408.944053411484, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 825248, "time": 38412.81520438194, "episode/length": 210.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 825273, "time": 38416.04270482063, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.625933837890625, "train/action_min": 0.0, "train/action_std": 3.3310111931392123, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03819890791284186, "train/actor_opt_grad_steps": 50785.0, "train/actor_opt_loss": -8.388513901475484, "train/adv_mag": 0.4757183960505894, "train/adv_max": 0.4388790601066181, "train/adv_mean": 0.0025693793554475114, "train/adv_min": -0.3829577780195645, "train/adv_std": 0.05491042142467839, "train/cont_avg": 0.9949637276785714, "train/cont_loss_mean": 0.00023711260134453888, "train/cont_loss_std": 0.007407832621992887, "train/cont_neg_acc": 0.991896259358951, "train/cont_neg_loss": 0.023918205854254537, "train/cont_pos_acc": 0.9999719709157944, "train/cont_pos_loss": 0.00010770190799393373, "train/cont_pred": 0.9949702620506287, "train/cont_rate": 0.9949637276785714, "train/dyn_loss_mean": 13.589392593928746, "train/dyn_loss_std": 9.348885461262293, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9010430876697813, "train/extr_critic_critic_opt_grad_steps": 50785.0, "train/extr_critic_critic_opt_loss": 15697.626025390626, "train/extr_critic_mag": 8.052040679114205, "train/extr_critic_max": 8.052040679114205, "train/extr_critic_mean": 2.4599910199642183, "train/extr_critic_min": -0.2260784992149898, "train/extr_critic_std": 1.8561854975564138, "train/extr_return_normed_mag": 1.5290987585272109, "train/extr_return_normed_max": 1.5290987585272109, "train/extr_return_normed_mean": 0.4052253933889525, "train/extr_return_normed_min": -0.10453234807189021, "train/extr_return_normed_std": 0.3196629804159914, "train/extr_return_rate": 0.8322354427405766, "train/extr_return_raw_mag": 9.108616140910557, "train/extr_return_raw_max": 9.108616140910557, "train/extr_return_raw_mean": 2.4751702274594987, "train/extr_return_raw_min": -0.533428114333323, "train/extr_return_raw_std": 1.8866379823003496, "train/extr_reward_mag": 1.0308871473584855, "train/extr_reward_max": 1.0308871473584855, "train/extr_reward_mean": 0.03753784840394344, "train/extr_reward_min": -0.4024513414927891, "train/extr_reward_std": 0.18227644647870744, "train/image_loss_mean": 6.371047759056092, "train/image_loss_std": 11.356957081386021, "train/model_loss_mean": 14.58046385220119, "train/model_loss_std": 15.154706648417882, "train/model_opt_grad_norm": 54.321860218048094, "train/model_opt_grad_steps": 50738.28571428572, "train/model_opt_loss": 18455.98413783482, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.857142857143, "train/policy_entropy_mag": 2.397093171732766, "train/policy_entropy_max": 2.397093171732766, "train/policy_entropy_mean": 0.46225511516843526, "train/policy_entropy_min": 0.07937501674251897, "train/policy_entropy_std": 0.543692081102303, "train/policy_logprob_mag": 7.438383844920567, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.46104019454547335, "train/policy_logprob_min": -7.438383844920567, "train/policy_logprob_std": 1.0348579330103738, "train/policy_randomness_mag": 0.846068698167801, "train/policy_randomness_max": 0.846068698167801, "train/policy_randomness_mean": 0.1631557706743479, "train/policy_randomness_min": 0.028015897649207287, "train/policy_randomness_std": 0.1918994478881359, "train/post_ent_mag": 60.66253098079137, "train/post_ent_max": 60.66253098079137, "train/post_ent_mean": 43.97458280835833, "train/post_ent_min": 20.714800589425224, "train/post_ent_std": 7.752753012520927, "train/prior_ent_mag": 70.63664011274065, "train/prior_ent_max": 70.63664011274065, "train/prior_ent_mean": 57.632900319780624, "train/prior_ent_min": 42.453178024291994, "train/prior_ent_std": 4.400571768624442, "train/rep_loss_mean": 13.589392593928746, "train/rep_loss_std": 9.348885461262293, "train/reward_avg": 0.02752371633292309, "train/reward_loss_mean": 0.05554346029779741, "train/reward_loss_std": 0.24723026071275983, "train/reward_max_data": 1.0228571483067104, "train/reward_max_pred": 1.0132323707853044, "train/reward_neg_acc": 0.9926354369946888, "train/reward_neg_loss": 0.02964580828057868, "train/reward_pos_acc": 0.9694049852234977, "train/reward_pos_loss": 0.8396931465182985, "train/reward_pred": 0.02692527242803148, "train/reward_rate": 0.032107979910714284, "train_stats/sum_log_reward": 8.306185751846156, "train_stats/max_log_achievement_collect_coal": 0.36082474226804123, "train_stats/max_log_achievement_collect_drink": 4.721649484536083, "train_stats/max_log_achievement_collect_sapling": 1.5876288659793814, "train_stats/max_log_achievement_collect_stone": 9.22680412371134, "train_stats/max_log_achievement_collect_wood": 11.154639175257731, "train_stats/max_log_achievement_defeat_skeleton": 0.020618556701030927, "train_stats/max_log_achievement_defeat_zombie": 0.4329896907216495, "train_stats/max_log_achievement_eat_cow": 0.1134020618556701, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010309278350515464, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5154639175257731, "train_stats/max_log_achievement_make_wood_sword": 0.711340206185567, "train_stats/max_log_achievement_place_furnace": 0.010309278350515464, "train_stats/max_log_achievement_place_plant": 1.5360824742268042, "train_stats/max_log_achievement_place_stone": 8.072164948453608, "train_stats/max_log_achievement_place_table": 2.8247422680412373, "train_stats/max_log_achievement_wake_up": 1.3195876288659794, "train_stats/mean_log_entropy": 0.5071691480494037, "eval_stats/sum_log_reward": 7.787500083446503, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.25, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 4.9375, "eval_stats/max_log_achievement_collect_wood": 9.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.5, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 4.375, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 3.888031278620474e-05, "report/cont_loss_std": 0.0006483956822194159, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0016561392694711685, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.9348339012358338e-05, "report/cont_pred": 0.9941213726997375, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.48609447479248, "report/dyn_loss_std": 9.078930854797363, "report/image_loss_mean": 5.1758623123168945, "report/image_loss_std": 6.6031107902526855, "report/model_loss_mean": 13.33353042602539, "report/model_loss_std": 10.58808708190918, "report/post_ent_mag": 63.98072814941406, "report/post_ent_max": 63.98072814941406, "report/post_ent_mean": 43.416385650634766, "report/post_ent_min": 19.087095260620117, "report/post_ent_std": 7.599519729614258, "report/prior_ent_mag": 71.00579071044922, "report/prior_ent_max": 71.00579071044922, "report/prior_ent_mean": 57.108673095703125, "report/prior_ent_min": 42.946006774902344, "report/prior_ent_std": 4.570963382720947, "report/rep_loss_mean": 13.48609447479248, "report/rep_loss_std": 9.078930854797363, "report/reward_avg": 0.03173828125, "report/reward_loss_mean": 0.0659717470407486, "report/reward_loss_std": 0.3439667522907257, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000797986984253, "report/reward_neg_acc": 0.9929006099700928, "report/reward_neg_loss": 0.04082915186882019, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7183558344841003, "report/reward_pred": 0.030753377825021744, "report/reward_rate": 0.037109375, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 5.560008139582351e-05, "eval/cont_loss_std": 0.0014130561612546444, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.006716363597661257, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 9.754124221217353e-06, "eval/cont_pred": 0.993199348449707, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 17.315107345581055, "eval/dyn_loss_std": 10.525224685668945, "eval/image_loss_mean": 9.717732429504395, "eval/image_loss_std": 11.544754981994629, "eval/model_loss_mean": 20.209278106689453, "eval/model_loss_std": 15.336374282836914, "eval/post_ent_mag": 59.81932830810547, "eval/post_ent_max": 59.81932830810547, "eval/post_ent_mean": 43.316612243652344, "eval/post_ent_min": 19.585208892822266, "eval/post_ent_std": 8.425031661987305, "eval/prior_ent_mag": 71.00579071044922, "eval/prior_ent_max": 71.00579071044922, "eval/prior_ent_mean": 58.45203399658203, "eval/prior_ent_min": 44.915443420410156, "eval/prior_ent_std": 4.175356864929199, "eval/rep_loss_mean": 17.315107345581055, "eval/rep_loss_std": 10.525224685668945, "eval/reward_avg": 0.02275390550494194, "eval/reward_loss_mean": 0.10242602974176407, "eval/reward_loss_std": 0.5857056379318237, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.00296950340271, "eval/reward_neg_acc": 0.9899497628211975, "eval/reward_neg_loss": 0.04670194163918495, "eval/reward_pos_acc": 0.7931034564971924, "eval/reward_pos_loss": 2.014338493347168, "eval/reward_pred": 0.017481379210948944, "eval/reward_rate": 0.0283203125, "replay/size": 824769.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3321914645623173e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.063001500632745e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5496.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1612060635718022e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1031556129456, "timer/env.step_count": 2802.0, "timer/env.step_total": 238.1887083053589, "timer/env.step_frac": 0.23816414033748073, "timer/env.step_avg": 0.08500667676850782, "timer/env.step_min": 0.023601055145263672, "timer/env.step_max": 5.338378667831421, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.300936937332153, "timer/replay._sample_frac": 0.0112997713024973, "timer/replay._sample_avg": 0.0005041460089816271, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.00995326042175293, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3489.0, "timer/agent.policy_total": 58.95182013511658, "timer/agent.policy_frac": 0.05894573955122264, "timer/agent.policy_avg": 0.016896480405593745, "timer/agent.policy_min": 0.00928497314453125, "timer/agent.policy_max": 0.13605642318725586, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.15445566177368164, "timer/dataset_train_frac": 0.00015443973044862406, "timer/dataset_train_avg": 0.00011024672503474778, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.0002651214599609375, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 627.4142272472382, "timer/agent.train_frac": 0.6273495126237324, "timer/agent.train_avg": 0.44783313864899227, "timer/agent.train_min": 0.43298816680908203, "timer/agent.train_max": 1.6624557971954346, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4829139709472656, "timer/agent.report_frac": 0.000482864160798789, "timer/agent.report_avg": 0.2414569854736328, "timer/agent.report_min": 0.2356255054473877, "timer/agent.report_max": 0.24728846549987793, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3851946214160753e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 22.41337364118325}
{"step": 825616, "time": 38427.61038374901, "episode/length": 449.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 825800, "time": 38435.23831796646, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 825872, "time": 38439.495975255966, "episode/length": 528.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9905482041587902, "episode/intrinsic_return": 0.0}
{"step": 825960, "time": 38443.95935487747, "episode/length": 272.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 826296, "time": 38456.9484667778, "episode/length": 231.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 826992, "time": 38482.84220743179, "episode/length": 217.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 827016, "time": 38485.14175534248, "episode/length": 228.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 827288, "time": 38495.88694190979, "episode/length": 413.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 827288, "time": 38495.89746975899, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 827328, "time": 38501.800364255905, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 827920, "time": 38524.878593206406, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 828144, "time": 38533.953290462494, "episode/length": 315.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 828160, "time": 38536.15038442612, "episode/length": 108.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 828200, "time": 38538.8453848362, "episode/length": 150.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 828512, "time": 38551.21993160248, "episode/length": 318.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 828928, "time": 38566.924719810486, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.965, "episode/intrinsic_return": 0.0}
{"step": 829408, "time": 38584.634884119034, "episode/length": 264.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773584905660377, "episode/intrinsic_return": 0.0}
{"step": 829448, "time": 38587.41394352913, "episode/length": 303.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 829608, "time": 38594.386481285095, "episode/length": 182.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 829808, "time": 38602.96864485741, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 829832, "time": 38605.14917087555, "episode/length": 238.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 38633.004719257355, "eval_episode/length": 153.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.961038961038961}
{"step": 830024, "time": 38635.59770441055, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 830024, "time": 38638.56844615936, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 830024, "time": 38640.366569042206, "eval_episode/length": 214.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9627906976744186}
{"step": 830024, "time": 38644.56743192673, "eval_episode/length": 272.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9816849816849816}
{"step": 830024, "time": 38649.16003060341, "eval_episode/length": 342.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9941690962099126}
{"step": 830024, "time": 38650.955036878586, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 830024, "time": 38652.85682415962, "eval_episode/length": 198.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 830192, "time": 38658.71432065964, "episode/length": 157.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 830248, "time": 38661.924461603165, "episode/length": 255.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 830272, "time": 38664.55954027176, "episode/length": 219.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9863636363636363, "episode/intrinsic_return": 0.0}
{"step": 830680, "time": 38679.91715884209, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 830760, "time": 38684.13779640198, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 830936, "time": 38691.59161877632, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 831232, "time": 38703.2827064991, "episode/length": 119.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 831536, "time": 38715.15528512001, "episode/length": 37.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 831616, "time": 38719.42811989784, "episode/length": 170.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 832000, "time": 38733.81203746796, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 832440, "time": 38750.06433606148, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 832504, "time": 38753.78383612633, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 832624, "time": 38759.62139105797, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 832664, "time": 38762.44144177437, "episode/length": 308.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 832968, "time": 38774.26093673706, "episode/length": 391.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 834112, "time": 38814.65190243721, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 834152, "time": 38817.33656287193, "episode/length": 316.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747634069400631, "episode/intrinsic_return": 0.0}
{"step": 834368, "time": 38826.37374854088, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 834544, "time": 38834.083565711975, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 835008, "time": 38851.18745350838, "episode/length": 433.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 835032, "time": 38853.52018904686, "episode/length": 378.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9920844327176781, "episode/intrinsic_return": 0.0}
{"step": 835592, "time": 38874.21017861366, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 835768, "time": 38883.42684626579, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 835952, "time": 38891.420867204666, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 835960, "time": 38893.07165288925, "episode/length": 373.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 836056, "time": 38897.82260680199, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 836080, "time": 38900.384026288986, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 836400, "time": 38912.79074335098, "episode/length": 39.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 836416, "time": 38916.7037229538, "episode/length": 44.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 836704, "time": 38927.9600982666, "episode/length": 211.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 836712, "time": 38929.573414087296, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 836920, "time": 38938.24202919006, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 837464, "time": 38958.092614889145, "episode/length": 188.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 837840, "time": 38972.68705248833, "episode/length": 258.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 838064, "time": 38981.847373485565, "episode/length": 168.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 838192, "time": 38987.88265490532, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 838344, "time": 38994.353323698044, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 838560, "time": 39003.3995578289, "episode/length": 231.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 839192, "time": 39027.20351290703, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9777227722772277, "episode/intrinsic_return": 0.0}
{"step": 839264, "time": 39031.3715775013, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 839448, "time": 39038.825773477554, "episode/length": 247.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 839448, "time": 39038.83544301987, "episode/length": 31.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 839552, "time": 39046.141323804855, "episode/length": 328.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.993920972644377, "episode/intrinsic_return": 0.0}
{"step": 839568, "time": 39048.18618083, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 839584, "time": 39050.297023296356, "episode/length": 173.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 839872, "time": 39061.426503658295, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 840008, "time": 39082.84146428108, "eval_episode/length": 53.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 840008, "time": 39088.12528061867, "eval_episode/length": 137.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 840008, "time": 39090.84376215935, "eval_episode/length": 161.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 840008, "time": 39093.976194381714, "eval_episode/length": 198.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 840008, "time": 39096.867112636566, "eval_episode/length": 65.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9242424242424242}
{"step": 840008, "time": 39099.97835445404, "eval_episode/length": 260.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9731800766283525}
{"step": 840008, "time": 39102.127880096436, "eval_episode/length": 208.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 840008, "time": 39104.60402059555, "eval_episode/length": 271.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9779411764705882}
{"step": 840456, "time": 39119.567170619965, "episode/length": 263.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 840640, "time": 39127.62849402428, "episode/length": 171.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 840936, "time": 39139.05003428459, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 841688, "time": 39165.71568083763, "episode/length": 279.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 841736, "time": 39168.956532001495, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 841880, "time": 39175.41613698006, "episode/length": 303.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 841968, "time": 39180.25561833382, "episode/length": 188.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 842096, "time": 39186.138331890106, "episode/length": 317.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9874213836477987, "episode/intrinsic_return": 0.0}
{"step": 842144, "time": 39189.331755399704, "episode/length": 50.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 842408, "time": 39199.530430316925, "episode/length": 38.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8974358974358975, "episode/intrinsic_return": 0.0}
{"step": 842576, "time": 39206.88850021362, "episode/length": 375.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 842592, "time": 39208.96153450012, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 842928, "time": 39221.887568712234, "episode/length": 285.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 843408, "time": 39239.48402452469, "episode/length": 59.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 843496, "time": 39243.83129429817, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 843744, "time": 39254.06311631203, "episode/length": 256.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 843768, "time": 39256.31181669235, "episode/length": 146.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 843792, "time": 39260.55396938324, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 844096, "time": 39272.269132852554, "episode/length": 210.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 844160, "time": 39275.9114882946, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 845120, "time": 39309.64974784851, "episode/length": 404.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9901234567901235, "episode/intrinsic_return": 0.0}
{"step": 845448, "time": 39322.22500681877, "episode/length": 160.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 845568, "time": 39328.04783177376, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 845656, "time": 39332.413234233856, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 845688, "time": 39335.128475904465, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 845832, "time": 39341.637813806534, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 845960, "time": 39347.33538508415, "episode/length": 307.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 846104, "time": 39353.72844982147, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 846216, "time": 39359.03342151642, "episode/length": 136.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 846784, "time": 39379.81945323944, "episode/length": 166.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 847056, "time": 39390.63537144661, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 847128, "time": 39394.32557988167, "episode/length": 183.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 847248, "time": 39400.37018418312, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 847280, "time": 39403.140244960785, "episode/length": 198.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 847432, "time": 39409.95616054535, "episode/length": 183.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 847545, "time": 39416.33655691147, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.533739268350944, "train/action_min": 0.0, "train/action_std": 3.3635528053311137, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038257515379529206, "train/actor_opt_grad_steps": 52180.0, "train/actor_opt_loss": -4.334070876991149, "train/adv_mag": 0.48663245731120486, "train/adv_max": 0.4467580134062458, "train/adv_mean": 0.0033695218912824123, "train/adv_min": -0.383430456729244, "train/adv_std": 0.05438103668874116, "train/cont_avg": 0.995222571942446, "train/cont_loss_mean": 0.00014271880831682565, "train/cont_loss_std": 0.004094001353817057, "train/cont_neg_acc": 0.9934092487977899, "train/cont_neg_loss": 0.017844987731592297, "train/cont_pos_acc": 0.9999717199545113, "train/cont_pos_loss": 6.055626299814183e-05, "train/cont_pred": 0.9952359782706062, "train/cont_rate": 0.995222571942446, "train/dyn_loss_mean": 13.356463185317224, "train/dyn_loss_std": 9.360958147392, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.896473113581431, "train/extr_critic_critic_opt_grad_steps": 52180.0, "train/extr_critic_critic_opt_loss": 15850.117840883544, "train/extr_critic_mag": 8.157035731583191, "train/extr_critic_max": 8.157035731583191, "train/extr_critic_mean": 2.5459184449353662, "train/extr_critic_min": -0.24048144011188755, "train/extr_critic_std": 1.9205073692815766, "train/extr_return_normed_mag": 1.5303277626312037, "train/extr_return_normed_max": 1.5303277626312037, "train/extr_return_normed_mean": 0.4118512345732545, "train/extr_return_normed_min": -0.09853767641156698, "train/extr_return_normed_std": 0.31975110111047894, "train/extr_return_rate": 0.8258955783123593, "train/extr_return_raw_mag": 9.398416752437894, "train/extr_return_raw_max": 9.398416752437894, "train/extr_return_raw_mean": 2.566502256359128, "train/extr_return_raw_min": -0.5517597768804152, "train/extr_return_raw_std": 1.9537788852513265, "train/extr_reward_mag": 1.0391341473558824, "train/extr_reward_max": 1.0391341473558824, "train/extr_reward_mean": 0.03933271217635639, "train/extr_reward_min": -0.4082721394600628, "train/extr_reward_std": 0.18702468093779448, "train/image_loss_mean": 6.278977634237824, "train/image_loss_std": 11.434875272160811, "train/model_loss_mean": 14.349260090066375, "train/model_loss_std": 15.241323553400932, "train/model_opt_grad_norm": 52.59446829643802, "train/model_opt_grad_steps": 52131.8417266187, "train/model_opt_loss": 19816.441026866007, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 1366.9064748201438, "train/policy_entropy_mag": 2.398073179258717, "train/policy_entropy_max": 2.398073179258717, "train/policy_entropy_mean": 0.4555868099061705, "train/policy_entropy_min": 0.07937501928360342, "train/policy_entropy_std": 0.534934014081955, "train/policy_logprob_mag": 7.438383877706185, "train/policy_logprob_max": -0.009455658415024229, "train/policy_logprob_mean": -0.45580295221411066, "train/policy_logprob_min": -7.438383877706185, "train/policy_logprob_std": 1.0332607185240272, "train/policy_randomness_mag": 0.846414596485577, "train/policy_randomness_max": 0.846414596485577, "train/policy_randomness_mean": 0.16080215090899158, "train/policy_randomness_min": 0.028015898487014735, "train/policy_randomness_std": 0.18880823340347344, "train/post_ent_mag": 60.76151865677868, "train/post_ent_max": 60.76151865677868, "train/post_ent_mean": 44.113816762142044, "train/post_ent_min": 20.512304690244388, "train/post_ent_std": 7.763914149442165, "train/prior_ent_mag": 70.55287702821141, "train/prior_ent_max": 70.55287702821141, "train/prior_ent_mean": 57.54959707465961, "train/prior_ent_min": 42.34384179972916, "train/prior_ent_std": 4.3933515480096395, "train/rep_loss_mean": 13.356463185317224, "train/rep_loss_std": 9.360958147392, "train/reward_avg": 0.029503428236507683, "train/reward_loss_mean": 0.05626196655438101, "train/reward_loss_std": 0.25057044636002546, "train/reward_max_data": 1.0143884926391162, "train/reward_max_pred": 1.0116799186459549, "train/reward_neg_acc": 0.9927269426181162, "train/reward_neg_loss": 0.029013579242306648, "train/reward_pos_acc": 0.968941780303022, "train/reward_pos_loss": 0.8382866228227135, "train/reward_pred": 0.028806813644151465, "train/reward_rate": 0.03379327787769784, "train_stats/sum_log_reward": 8.570588409900665, "train_stats/max_log_achievement_collect_coal": 0.5294117647058824, "train_stats/max_log_achievement_collect_drink": 5.411764705882353, "train_stats/max_log_achievement_collect_sapling": 1.5098039215686274, "train_stats/max_log_achievement_collect_stone": 10.441176470588236, "train_stats/max_log_achievement_collect_wood": 11.882352941176471, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 0.6274509803921569, "train_stats/max_log_achievement_eat_cow": 0.08823529411764706, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7352941176470589, "train_stats/max_log_achievement_make_wood_sword": 0.6568627450980392, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.4607843137254901, "train_stats/max_log_achievement_place_stone": 9.372549019607844, "train_stats/max_log_achievement_place_table": 2.9607843137254903, "train_stats/max_log_achievement_wake_up": 1.088235294117647, "train_stats/mean_log_entropy": 0.4951754497254596, "eval_stats/sum_log_reward": 8.225000113248825, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 10.9375, "eval_stats/max_log_achievement_collect_wood": 9.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 0.3125, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 9.125, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.642438178350858e-06, "report/cont_loss_std": 4.021747736260295e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.4022359361406416e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3926547808296164e-06, "report/cont_pred": 0.994139552116394, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 11.795753479003906, "report/dyn_loss_std": 8.868629455566406, "report/image_loss_mean": 5.851163387298584, "report/image_loss_std": 9.267938613891602, "report/model_loss_mean": 12.988954544067383, "report/model_loss_std": 13.029817581176758, "report/post_ent_mag": 62.22482681274414, "report/post_ent_max": 62.22482681274414, "report/post_ent_mean": 45.77995300292969, "report/post_ent_min": 21.517894744873047, "report/post_ent_std": 7.814993381500244, "report/prior_ent_mag": 70.65599060058594, "report/prior_ent_max": 70.65599060058594, "report/prior_ent_mean": 57.818878173828125, "report/prior_ent_min": 39.195377349853516, "report/prior_ent_std": 4.78700065612793, "report/rep_loss_mean": 11.795753479003906, "report/rep_loss_std": 8.868629455566406, "report/reward_avg": 0.03955078125, "report/reward_loss_mean": 0.060338012874126434, "report/reward_loss_std": 0.2358720600605011, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0028808116912842, "report/reward_neg_acc": 0.9928498864173889, "report/reward_neg_loss": 0.024582896381616592, "report/reward_pos_acc": 0.9555555582046509, "report/reward_pos_loss": 0.83821040391922, "report/reward_pred": 0.03798873722553253, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 1.242560074388166e-06, "eval/cont_loss_std": 2.718928226386197e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00016561920347157866, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.1115738374201101e-07, "eval/cont_pred": 0.993165135383606, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 18.24795913696289, "eval/dyn_loss_std": 10.918327331542969, "eval/image_loss_mean": 12.94948673248291, "eval/image_loss_std": 16.94257926940918, "eval/model_loss_mean": 24.038394927978516, "eval/model_loss_std": 21.260101318359375, "eval/post_ent_mag": 63.72352981567383, "eval/post_ent_max": 63.72352981567383, "eval/post_ent_mean": 42.47127914428711, "eval/post_ent_min": 19.243728637695312, "eval/post_ent_std": 8.366692543029785, "eval/prior_ent_mag": 70.65599060058594, "eval/prior_ent_max": 70.65599060058594, "eval/prior_ent_mean": 58.69696044921875, "eval/prior_ent_min": 46.06632614135742, "eval/prior_ent_std": 3.951899766921997, "eval/rep_loss_mean": 18.24795913696289, "eval/rep_loss_std": 10.918327331542969, "eval/reward_avg": 0.02744140662252903, "eval/reward_loss_mean": 0.14013098180294037, "eval/reward_loss_std": 0.8192383050918579, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011913776397705, "eval/reward_neg_acc": 0.9919028878211975, "eval/reward_neg_loss": 0.07266915589570999, "eval/reward_pos_acc": 0.8333333134651184, "eval/reward_pos_loss": 1.9915833473205566, "eval/reward_pred": 0.02168199047446251, "eval/reward_rate": 0.03515625, "replay/size": 847041.0, "replay/inserts": 22272.0, "replay/samples": 22272.0, "replay/insert_wait_avg": 1.3396700565842377e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.064349349887892e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5000.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1409282684326172e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2790644168854, "timer/env.step_count": 2784.0, "timer/env.step_total": 242.58149027824402, "timer/env.step_frac": 0.24251381330234814, "timer/env.step_avg": 0.08713415599074857, "timer/env.step_min": 0.023748397827148438, "timer/env.step_max": 4.352223873138428, "timer/replay._sample_count": 22272.0, "timer/replay._sample_total": 11.381492853164673, "timer/replay._sample_frac": 0.011378317569606973, "timer/replay._sample_avg": 0.0005110224880192472, "timer/replay._sample_min": 0.00036072731018066406, "timer/replay._sample_max": 0.02841663360595703, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3409.0, "timer/agent.policy_total": 56.90523147583008, "timer/agent.policy_frac": 0.056889355680959985, "timer/agent.policy_avg": 0.016692646370146693, "timer/agent.policy_min": 0.009616374969482422, "timer/agent.policy_max": 0.08886551856994629, "timer/dataset_train_count": 1392.0, "timer/dataset_train_total": 0.1557910442352295, "timer/dataset_train_frac": 0.0001557475806274604, "timer/dataset_train_avg": 0.00011191885361726256, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.00044035911560058594, "timer/agent.train_count": 1392.0, "timer/agent.train_total": 625.4292669296265, "timer/agent.train_frac": 0.6252547805688822, "timer/agent.train_avg": 0.44930263428852474, "timer/agent.train_min": 0.435382604598999, "timer/agent.train_max": 1.703536033630371, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4860832691192627, "timer/agent.report_frac": 0.00048594765841932907, "timer/agent.report_avg": 0.24304163455963135, "timer/agent.report_min": 0.23585724830627441, "timer/agent.report_max": 0.2502260208129883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6457079050935597e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 22.26548808750057}
{"step": 847656, "time": 39419.87005400658, "episode/length": 50.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9019607843137255, "episode/intrinsic_return": 0.0}
{"step": 847952, "time": 39431.5239238739, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 847976, "time": 39433.715769052505, "episode/length": 148.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 847984, "time": 39435.75880432129, "episode/length": 40.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 848376, "time": 39450.10820102692, "episode/length": 269.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 848712, "time": 39463.044274806976, "episode/length": 178.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 849048, "time": 39475.93261837959, "episode/length": 239.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 849400, "time": 39489.23806357384, "episode/length": 180.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 849456, "time": 39493.02244281769, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 849944, "time": 39510.71132397652, "episode/length": 195.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 39537.607734680176, "eval_episode/length": 150.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 850096, "time": 39539.659417152405, "eval_episode/length": 160.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 850096, "time": 39545.48630404472, "eval_episode/length": 185.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 850096, "time": 39547.59147143364, "eval_episode/length": 194.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9692307692307692}
{"step": 850096, "time": 39549.668598651886, "eval_episode/length": 203.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 850096, "time": 39553.03112864494, "eval_episode/length": 47.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 850096, "time": 39555.72469997406, "eval_episode/length": 266.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9887640449438202}
{"step": 850096, "time": 39560.40752744675, "eval_episode/length": 314.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9873015873015873}
{"step": 850112, "time": 39561.766676425934, "episode/length": 334.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 850208, "time": 39566.74301147461, "episode/length": 393.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9923857868020305, "episode/intrinsic_return": 0.0}
{"step": 850424, "time": 39575.21977210045, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 850448, "time": 39577.792358636856, "episode/length": 308.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9935275080906149, "episode/intrinsic_return": 0.0}
{"step": 850720, "time": 39588.56188774109, "episode/length": 157.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 851352, "time": 39611.08688163757, "episode/length": 287.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 851424, "time": 39615.36353754997, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 851840, "time": 39630.76487660408, "episode/length": 203.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 851952, "time": 39636.11316204071, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 852120, "time": 39644.91846084595, "episode/length": 250.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 852256, "time": 39651.279994249344, "episode/length": 103.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 852944, "time": 39676.09008812904, "episode/length": 277.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 853280, "time": 39688.94264340401, "episode/length": 240.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.970954356846473, "episode/intrinsic_return": 0.0}
{"step": 853544, "time": 39699.29414701462, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 853808, "time": 39710.68504047394, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 854000, "time": 39718.81730246544, "episode/length": 443.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 854264, "time": 39729.24799633026, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 854920, "time": 39754.86597967148, "episode/length": 370.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973045822102425, "episode/intrinsic_return": 0.0}
{"step": 855096, "time": 39762.42651939392, "episode/length": 406.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 855192, "time": 39767.15211224556, "episode/length": 595.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9983221476510067, "episode/intrinsic_return": 0.0}
{"step": 855248, "time": 39770.83203411102, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 855488, "time": 39780.5048892498, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 855568, "time": 39784.77038168907, "episode/length": 252.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 855800, "time": 39793.94083070755, "episode/length": 314.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 855880, "time": 39798.20163726807, "episode/length": 201.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 856336, "time": 39815.216752529144, "episode/length": 176.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 856568, "time": 39824.37487959862, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 857032, "time": 39841.9290728569, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 857136, "time": 39847.32391953468, "episode/length": 166.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9820359281437125, "episode/intrinsic_return": 0.0}
{"step": 857424, "time": 39858.60206079483, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 857784, "time": 39871.88386750221, "episode/length": 237.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 857800, "time": 39874.01834106445, "episode/length": 318.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9780564263322884, "episode/intrinsic_return": 0.0}
{"step": 858096, "time": 39885.833003759384, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9581151832460733, "episode/intrinsic_return": 0.0}
{"step": 858192, "time": 39890.54796361923, "episode/length": 337.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 858312, "time": 39895.83390498161, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 858616, "time": 39907.59798645973, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 858656, "time": 39910.76246929169, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 858912, "time": 39920.87375378609, "episode/length": 185.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 859488, "time": 39941.82824778557, "episode/length": 146.0, "episode/score": 6.1000000461936, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 859680, "time": 39949.80977225304, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 859864, "time": 39957.40572357178, "episode/length": 440.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 859936, "time": 39961.78319811821, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39988.222727537155, "eval_episode/length": 156.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 860080, "time": 39991.51267004013, "eval_episode/length": 191.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 860080, "time": 39991.52101898193, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 860080, "time": 39995.164719343185, "eval_episode/length": 197.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 860080, "time": 39996.95304059982, "eval_episode/length": 201.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 860080, "time": 39998.68498754501, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 860080, "time": 40008.82828760147, "eval_episode/length": 237.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9957983193277311}
{"step": 860080, "time": 40013.33735728264, "eval_episode/length": 283.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 860104, "time": 40013.93715620041, "episode/length": 52.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 860712, "time": 40037.71334862709, "episode/length": 256.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 861080, "time": 40051.555710315704, "episode/length": 307.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.987012987012987, "episode/intrinsic_return": 0.0}
{"step": 861120, "time": 40054.7208006382, "episode/length": 275.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9818840579710145, "episode/intrinsic_return": 0.0}
{"step": 861168, "time": 40057.79447197914, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 861240, "time": 40061.648331165314, "episode/length": 171.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 861680, "time": 40077.977227687836, "episode/length": 435.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9977064220183486, "episode/intrinsic_return": 0.0}
{"step": 862064, "time": 40092.56845283508, "episode/length": 265.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9699248120300752, "episode/intrinsic_return": 0.0}
{"step": 862144, "time": 40096.84063529968, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 862512, "time": 40110.80690860748, "episode/length": 167.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 862552, "time": 40113.494198322296, "episode/length": 305.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 862752, "time": 40122.19679427147, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 862944, "time": 40130.18553733826, "episode/length": 232.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9656652360515021, "episode/intrinsic_return": 0.0}
{"step": 863936, "time": 40164.895818948746, "episode/length": 177.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 864000, "time": 40168.559467077255, "episode/length": 131.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 864112, "time": 40173.89108920097, "episode/length": 245.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 864136, "time": 40176.11661410332, "episode/length": 197.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 864200, "time": 40180.061878442764, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 864304, "time": 40185.38623046875, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 864312, "time": 40187.04560184479, "episode/length": 383.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9973958333333334, "episode/intrinsic_return": 0.0}
{"step": 865336, "time": 40222.628870010376, "episode/length": 149.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 865408, "time": 40227.019555568695, "episode/length": 175.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 865536, "time": 40232.85731053352, "episode/length": 433.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792626728110599, "episode/intrinsic_return": 0.0}
{"step": 865640, "time": 40237.583928108215, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 865696, "time": 40241.26087164879, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 866000, "time": 40252.9319190979, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 866104, "time": 40257.86143231392, "episode/length": 50.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 866672, "time": 40278.7233710289, "episode/length": 141.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 866792, "time": 40284.14718699455, "episode/length": 172.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 866880, "time": 40288.913402080536, "episode/length": 320.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9844236760124611, "episode/intrinsic_return": 0.0}
{"step": 866936, "time": 40292.18484330177, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 867056, "time": 40297.941692113876, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 867136, "time": 40302.24531626701, "episode/length": 353.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 867624, "time": 40319.87863469124, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 868280, "time": 40343.60951280594, "episode/length": 200.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 868536, "time": 40355.625324726105, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 868536, "time": 40355.63729381561, "episode/length": 316.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9779179810725552, "episode/intrinsic_return": 0.0}
{"step": 868904, "time": 40372.22173857689, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 869080, "time": 40379.604687452316, "episode/length": 252.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 869272, "time": 40387.50976014137, "episode/length": 45.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 869632, "time": 40401.4065425396, "episode/length": 311.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 870017, "time": 40416.36322808266, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.710185023716518, "train/action_min": 0.0, "train/action_std": 3.404216950280326, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.037474360596388576, "train/actor_opt_grad_steps": 53575.0, "train/actor_opt_loss": -6.42106095126697, "train/adv_mag": 0.4919659431491579, "train/adv_max": 0.43237894475460054, "train/adv_mean": 0.0025975510042241822, "train/adv_min": -0.403951203503779, "train/adv_std": 0.05325719474681786, "train/cont_avg": 0.9952497209821428, "train/cont_loss_mean": 0.00015637755315403012, "train/cont_loss_std": 0.004774859496821803, "train/cont_neg_acc": 0.99586330943828, "train/cont_neg_loss": 0.012654145464456822, "train/cont_pos_acc": 0.9999929713351386, "train/cont_pos_loss": 8.763269434677312e-05, "train/cont_pred": 0.9952609798737935, "train/cont_rate": 0.9952497209821428, "train/dyn_loss_mean": 13.370836482729231, "train/dyn_loss_std": 9.315878902162824, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9076479426452092, "train/extr_critic_critic_opt_grad_steps": 53575.0, "train/extr_critic_critic_opt_loss": 15910.767347935267, "train/extr_critic_mag": 8.394084971291678, "train/extr_critic_max": 8.394084971291678, "train/extr_critic_mean": 2.6270984768867494, "train/extr_critic_min": -0.22205362745693752, "train/extr_critic_std": 1.9825849422386714, "train/extr_return_normed_mag": 1.4938888098512377, "train/extr_return_normed_max": 1.4938888098512377, "train/extr_return_normed_mean": 0.4082617147692612, "train/extr_return_normed_min": -0.09640768127782004, "train/extr_return_normed_std": 0.31719944221632823, "train/extr_return_rate": 0.826297007713999, "train/extr_return_raw_mag": 9.52918827193124, "train/extr_return_raw_max": 9.52918827193124, "train/extr_return_raw_mean": 2.6435694634914397, "train/extr_return_raw_min": -0.5568992704153061, "train/extr_return_raw_std": 2.0119710862636566, "train/extr_reward_mag": 1.0377161196299962, "train/extr_reward_max": 1.0377161196299962, "train/extr_reward_mean": 0.04078342913250838, "train/extr_reward_min": -0.4354505274977003, "train/extr_reward_std": 0.19028726166912488, "train/image_loss_mean": 6.153001257351467, "train/image_loss_std": 11.315943956375122, "train/model_loss_mean": 14.231322615487235, "train/model_loss_std": 15.130874804088048, "train/model_opt_grad_norm": 55.12466200419835, "train/model_opt_grad_steps": 53525.55, "train/model_opt_loss": 18050.692082868303, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1267.857142857143, "train/policy_entropy_mag": 2.420639978136335, "train/policy_entropy_max": 2.420639978136335, "train/policy_entropy_mean": 0.441135847568512, "train/policy_entropy_min": 0.07937501562493188, "train/policy_entropy_std": 0.5314299404621124, "train/policy_logprob_mag": 7.438383844920567, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4405858340007918, "train/policy_logprob_min": -7.438383844920567, "train/policy_logprob_std": 1.0241191029548644, "train/policy_randomness_mag": 0.8543796862874712, "train/policy_randomness_max": 0.8543796862874712, "train/policy_randomness_mean": 0.15570159586412566, "train/policy_randomness_min": 0.028015897263373647, "train/policy_randomness_std": 0.18757144819412913, "train/post_ent_mag": 60.49576952798026, "train/post_ent_max": 60.49576952798026, "train/post_ent_mean": 44.08321634020124, "train/post_ent_min": 20.898880999428886, "train/post_ent_std": 7.732596087455749, "train/prior_ent_mag": 70.62191390991211, "train/prior_ent_max": 70.62191390991211, "train/prior_ent_mean": 57.551440184456965, "train/prior_ent_min": 42.42647886276245, "train/prior_ent_std": 4.361877463545118, "train/rep_loss_mean": 13.370836482729231, "train/rep_loss_std": 9.315878902162824, "train/reward_avg": 0.029468470944889955, "train/reward_loss_mean": 0.05566315823899848, "train/reward_loss_std": 0.25192645394376345, "train/reward_max_data": 1.0228571483067104, "train/reward_max_pred": 1.0136559418269566, "train/reward_neg_acc": 0.9923940803323473, "train/reward_neg_loss": 0.027643499526727414, "train/reward_pos_acc": 0.9635779184954507, "train/reward_pos_loss": 0.8611960087503706, "train/reward_pred": 0.028531418228521944, "train/reward_rate": 0.03378208705357143, "train_stats/sum_log_reward": 8.981720603922362, "train_stats/max_log_achievement_collect_coal": 0.5376344086021505, "train_stats/max_log_achievement_collect_drink": 5.118279569892473, "train_stats/max_log_achievement_collect_sapling": 1.3978494623655915, "train_stats/max_log_achievement_collect_stone": 10.978494623655914, "train_stats/max_log_achievement_collect_wood": 11.365591397849462, "train_stats/max_log_achievement_defeat_skeleton": 0.06451612903225806, "train_stats/max_log_achievement_defeat_zombie": 0.5913978494623656, "train_stats/max_log_achievement_eat_cow": 0.12903225806451613, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010752688172043012, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4086021505376345, "train_stats/max_log_achievement_make_wood_sword": 1.4838709677419355, "train_stats/max_log_achievement_place_furnace": 0.043010752688172046, "train_stats/max_log_achievement_place_plant": 1.3763440860215055, "train_stats/max_log_achievement_place_stone": 9.408602150537634, "train_stats/max_log_achievement_place_table": 3.247311827956989, "train_stats/max_log_achievement_wake_up": 1.2688172043010753, "train_stats/mean_log_entropy": 0.5248019099235535, "eval_stats/sum_log_reward": 8.85000029206276, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 7.5, "eval_stats/max_log_achievement_collect_wood": 13.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 1.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 6.25, "eval_stats/max_log_achievement_place_table": 3.875, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 5.1136870752088726e-05, "report/cont_loss_std": 0.0014170928625389934, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00032322839251719415, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.926406836602837e-05, "report/cont_pred": 0.993118405342102, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.708812713623047, "report/dyn_loss_std": 8.816871643066406, "report/image_loss_mean": 6.010309219360352, "report/image_loss_std": 8.344630241394043, "report/model_loss_mean": 13.688562393188477, "report/model_loss_std": 11.809195518493652, "report/post_ent_mag": 61.74424743652344, "report/post_ent_max": 61.74424743652344, "report/post_ent_mean": 44.09508514404297, "report/post_ent_min": 18.373353958129883, "report/post_ent_std": 7.731266975402832, "report/prior_ent_mag": 70.35722351074219, "report/prior_ent_max": 70.35722351074219, "report/prior_ent_mean": 57.21324920654297, "report/prior_ent_min": 41.28929901123047, "report/prior_ent_std": 5.01957893371582, "report/rep_loss_mean": 12.708812713623047, "report/rep_loss_std": 8.816871643066406, "report/reward_avg": 0.02509765699505806, "report/reward_loss_mean": 0.0529150664806366, "report/reward_loss_std": 0.205827534198761, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023407936096191, "report/reward_neg_acc": 0.9959636330604553, "report/reward_neg_loss": 0.02783389762043953, "report/reward_pos_acc": 0.939393937587738, "report/reward_pos_loss": 0.8061100840568542, "report/reward_pred": 0.02415008842945099, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.7263189369696192e-06, "eval/cont_loss_std": 8.100757986539975e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012510812375694513, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.122111528839014e-08, "eval/cont_pred": 0.9970740079879761, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.413063049316406, "eval/dyn_loss_std": 10.753177642822266, "eval/image_loss_mean": 10.69561767578125, "eval/image_loss_std": 15.301945686340332, "eval/model_loss_mean": 22.41200828552246, "eval/model_loss_std": 19.343578338623047, "eval/post_ent_mag": 59.14248275756836, "eval/post_ent_max": 59.14248275756836, "eval/post_ent_mean": 41.19150924682617, "eval/post_ent_min": 21.776260375976562, "eval/post_ent_std": 7.804405212402344, "eval/prior_ent_mag": 70.35722351074219, "eval/prior_ent_max": 70.35722351074219, "eval/prior_ent_mean": 58.33017349243164, "eval/prior_ent_min": 48.5179443359375, "eval/prior_ent_std": 4.096756935119629, "eval/rep_loss_mean": 19.413063049316406, "eval/rep_loss_std": 10.753177642822266, "eval/reward_avg": 0.03789062798023224, "eval/reward_loss_mean": 0.06854994595050812, "eval/reward_loss_std": 0.37293919920921326, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.006427526473999, "eval/reward_neg_acc": 0.9918616414070129, "eval/reward_neg_loss": 0.03283780813217163, "eval/reward_pos_acc": 0.9512194991111755, "eval/reward_pos_loss": 0.9247701168060303, "eval/reward_pred": 0.03703625500202179, "eval/reward_rate": 0.0400390625, "replay/size": 869513.0, "replay/inserts": 22472.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.3415607195725514e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.121990888546675e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4792.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1650767668658784e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0163266658783, "timer/env.step_count": 2809.0, "timer/env.step_total": 228.38010716438293, "timer/env.step_frac": 0.22837637853955603, "timer/env.step_avg": 0.08130299293854858, "timer/env.step_min": 0.023778676986694336, "timer/env.step_max": 4.2903032302856445, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.500783443450928, "timer/replay._sample_frac": 0.011500595677067908, "timer/replay._sample_avg": 0.0005119650749399452, "timer/replay._sample_min": 0.00042366981506347656, "timer/replay._sample_max": 0.017678260803222656, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3408.0, "timer/agent.policy_total": 58.431058168411255, "timer/agent.policy_frac": 0.05843010419962275, "timer/agent.policy_avg": 0.01714526354706903, "timer/agent.policy_min": 0.009476184844970703, "timer/agent.policy_max": 0.14344477653503418, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.15643763542175293, "timer/dataset_train_frac": 0.00015643508135844794, "timer/dataset_train_avg": 0.00011142281725196077, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.0002722740173339844, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 630.7242097854614, "timer/agent.train_frac": 0.6307139123301501, "timer/agent.train_avg": 0.44923376765346257, "timer/agent.train_min": 0.4351620674133301, "timer/agent.train_max": 2.5114028453826904, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47847676277160645, "timer/agent.report_frac": 0.00047846895096891084, "timer/agent.report_avg": 0.23923838138580322, "timer/agent.report_min": 0.2312769889831543, "timer/agent.report_max": 0.24719977378845215, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.051707988283317e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 22.47133124507634}
{"step": 870032, "time": 40417.05604052544, "episode/length": 218.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 40435.66614317894, "eval_episode/length": 56.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 870064, "time": 40438.39247441292, "eval_episode/length": 83.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9880952380952381}
{"step": 870064, "time": 40443.03733539581, "eval_episode/length": 152.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 870064, "time": 40445.070163965225, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 870064, "time": 40447.01911354065, "eval_episode/length": 174.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 870064, "time": 40451.2425532341, "eval_episode/length": 57.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9137931034482759}
{"step": 870064, "time": 40454.92032980919, "eval_episode/length": 278.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.982078853046595}
{"step": 870064, "time": 40457.834196805954, "eval_episode/length": 306.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9837133550488599}
{"step": 870176, "time": 40461.5741686821, "episode/length": 404.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 870176, "time": 40461.583781957626, "episode/length": 204.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 870232, "time": 40466.605793237686, "episode/length": 429.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 870496, "time": 40477.18551516533, "episode/length": 244.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 870512, "time": 40479.43081641197, "episode/length": 59.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 871008, "time": 40497.753469228745, "episode/length": 63.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 871136, "time": 40503.58097457886, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 871152, "time": 40505.81600570679, "episode/length": 258.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 871320, "time": 40513.014585494995, "episode/length": 142.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 871656, "time": 40525.835483789444, "episode/length": 62.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9365079365079365, "episode/intrinsic_return": 0.0}
{"step": 871840, "time": 40533.87148094177, "episode/length": 320.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9781931464174455, "episode/intrinsic_return": 0.0}
{"step": 872056, "time": 40542.63287973404, "episode/length": 227.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 872632, "time": 40563.495413303375, "episode/length": 186.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 872744, "time": 40568.80613422394, "episode/length": 320.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 872760, "time": 40571.18820595741, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 872992, "time": 40580.85599255562, "episode/length": 166.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 873000, "time": 40582.54968428612, "episode/length": 209.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 873696, "time": 40607.52160573006, "episode/length": 132.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 873888, "time": 40615.660231113434, "episode/length": 255.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 873936, "time": 40618.92001271248, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 874128, "time": 40626.9500143528, "episode/length": 258.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 874328, "time": 40635.63537335396, "episode/length": 197.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 874456, "time": 40641.51255893707, "episode/length": 94.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 874896, "time": 40658.02628540993, "episode/length": 125.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 874952, "time": 40661.36278152466, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 875312, "time": 40675.24122810364, "episode/length": 318.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9749216300940439, "episode/intrinsic_return": 0.0}
{"step": 875464, "time": 40681.68152332306, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 875536, "time": 40685.83582472801, "episode/length": 150.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 876176, "time": 40708.830059051514, "episode/length": 397.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 876184, "time": 40710.585661411285, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 876280, "time": 40715.32868552208, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 876304, "time": 40717.92668771744, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 876568, "time": 40729.73145484924, "episode/length": 47.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 877112, "time": 40749.66152691841, "episode/length": 372.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9919571045576407, "episode/intrinsic_return": 0.0}
{"step": 877336, "time": 40759.440603494644, "episode/length": 252.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 877608, "time": 40770.13167023659, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 877624, "time": 40772.181428432465, "episode/length": 167.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 878104, "time": 40789.99256205559, "episode/length": 240.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 878128, "time": 40792.67177796364, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 878320, "time": 40800.57244682312, "episode/length": 122.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 878952, "time": 40823.155737400055, "episode/length": 435.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9885321100917431, "episode/intrinsic_return": 0.0}
{"step": 878952, "time": 40823.16854715347, "episode/length": 167.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 878976, "time": 40827.34812784195, "episode/length": 429.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 879016, "time": 40830.14676427841, "episode/length": 237.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 879208, "time": 40837.946811676025, "episode/length": 137.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 879704, "time": 40856.27556347847, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 879872, "time": 40863.844034194946, "episode/length": 280.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786476868327402, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 40886.4222304821, "eval_episode/length": 47.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 880048, "time": 40890.91588687897, "eval_episode/length": 114.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.991304347826087}
{"step": 880048, "time": 40895.33828043938, "eval_episode/length": 177.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 880048, "time": 40898.03533387184, "eval_episode/length": 202.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 880048, "time": 40899.939628362656, "eval_episode/length": 205.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 880048, "time": 40901.74793434143, "eval_episode/length": 162.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 880048, "time": 40906.22498989105, "eval_episode/length": 161.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 880048, "time": 40908.084196805954, "eval_episode/length": 283.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9964788732394366}
{"step": 880392, "time": 40919.347135066986, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 880464, "time": 40923.58682513237, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 880760, "time": 40934.78721547127, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 881120, "time": 40948.538167238235, "episode/length": 373.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 881536, "time": 40964.286771297455, "episode/length": 142.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 881560, "time": 40966.42074084282, "episode/length": 293.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 881816, "time": 40976.616431713104, "episode/length": 31.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 881912, "time": 40981.4542324543, "episode/length": 143.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 882056, "time": 40987.942903757095, "episode/length": 379.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 882128, "time": 40992.79660773277, "episode/length": 302.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9834983498349835, "episode/intrinsic_return": 0.0}
{"step": 882640, "time": 41011.56898474693, "episode/length": 189.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 883088, "time": 41028.40920853615, "episode/length": 401.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 883216, "time": 41034.38511776924, "episode/length": 144.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 883328, "time": 41040.95872402191, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 883472, "time": 41047.33971786499, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 883472, "time": 41047.35349011421, "episode/length": 375.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9973404255319149, "episode/intrinsic_return": 0.0}
{"step": 883976, "time": 41067.45701575279, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 884376, "time": 41082.54555153847, "episode/length": 216.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 884960, "time": 41105.61619305611, "episode/length": 392.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 885040, "time": 41109.99974822998, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 885200, "time": 41117.031525850296, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 885424, "time": 41126.188876628876, "episode/length": 243.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 885536, "time": 41131.48109984398, "episode/length": 275.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 885664, "time": 41137.370557785034, "episode/length": 321.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906832298136646, "episode/intrinsic_return": 0.0}
{"step": 885840, "time": 41144.86645913124, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 885848, "time": 41146.503566265106, "episode/length": 38.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 885968, "time": 41152.31274557114, "episode/length": 248.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 886208, "time": 41162.039649009705, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 886648, "time": 41178.34600567818, "episode/length": 54.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 886768, "time": 41184.11803436279, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 886776, "time": 41185.690661907196, "episode/length": 100.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 886776, "time": 41185.70090842247, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 886968, "time": 41195.55274486542, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 887608, "time": 41218.77708745003, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 887760, "time": 41225.73788046837, "episode/length": 239.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 887936, "time": 41233.47258257866, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 888544, "time": 41255.47522878647, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 888592, "time": 41258.80947756767, "episode/length": 202.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 888632, "time": 41261.728924274445, "episode/length": 247.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 888736, "time": 41267.06993842125, "episode/length": 244.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 888968, "time": 41276.238112449646, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 889120, "time": 41283.114787101746, "episode/length": 147.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 889360, "time": 41292.76060962677, "episode/length": 323.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9969135802469136, "episode/intrinsic_return": 0.0}
{"step": 889936, "time": 41313.65719771385, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 41333.40071940422, "eval_episode/length": 38.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8974358974358975}
{"step": 890032, "time": 41335.79750466347, "eval_episode/length": 55.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 890032, "time": 41337.4703745842, "eval_episode/length": 56.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 890032, "time": 41346.529462099075, "eval_episode/length": 188.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 890032, "time": 41348.22169828415, "eval_episode/length": 192.0, "eval_episode/score": 10.099999964237213, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 890032, "time": 41350.66101336479, "eval_episode/length": 209.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 890032, "time": 41352.67528581619, "eval_episode/length": 217.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.963302752293578}
{"step": 890032, "time": 41355.18543410301, "eval_episode/length": 236.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9704641350210971}
{"step": 890136, "time": 41358.42300057411, "episode/length": 192.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 890224, "time": 41363.12041258812, "episode/length": 307.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 890392, "time": 41370.121663331985, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 890456, "time": 41373.82160234451, "episode/length": 28.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.896551724137931, "episode/intrinsic_return": 0.0}
{"step": 890704, "time": 41384.08165860176, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 891016, "time": 41395.96613264084, "episode/length": 236.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 891184, "time": 41403.308177948, "episode/length": 305.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9869281045751634, "episode/intrinsic_return": 0.0}
{"step": 891513, "time": 41416.79837560654, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.637059190538195, "train/action_min": 0.0, "train/action_std": 3.3692778869911475, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03659252042847651, "train/actor_opt_grad_steps": 54950.0, "train/actor_opt_loss": -6.314438314128805, "train/adv_mag": 0.47034284008873833, "train/adv_max": 0.4247128868544543, "train/adv_mean": 0.002552760259304368, "train/adv_min": -0.3822307966373585, "train/adv_std": 0.052355095744132996, "train/cont_avg": 0.9952039930555555, "train/cont_loss_mean": 0.00015664552701258677, "train/cont_loss_std": 0.0046199832681875375, "train/cont_neg_acc": 0.9941639824021131, "train/cont_neg_loss": 0.009844802973836173, "train/cont_pos_acc": 0.9999636027548048, "train/cont_pos_loss": 9.808515413120042e-05, "train/cont_pred": 0.9951814466052585, "train/cont_rate": 0.9952039930555555, "train/dyn_loss_mean": 13.628331700077764, "train/dyn_loss_std": 9.436269046642161, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9246477537684971, "train/extr_critic_critic_opt_grad_steps": 54950.0, "train/extr_critic_critic_opt_loss": 15957.569538483796, "train/extr_critic_mag": 8.49485679909035, "train/extr_critic_max": 8.49485679909035, "train/extr_critic_mean": 2.558016030876725, "train/extr_critic_min": -0.23151445653703479, "train/extr_critic_std": 1.9574406102851585, "train/extr_return_normed_mag": 1.5016841853106464, "train/extr_return_normed_max": 1.5016841853106464, "train/extr_return_normed_mean": 0.3930201676156786, "train/extr_return_normed_min": -0.09740966420482707, "train/extr_return_normed_std": 0.31332078344292114, "train/extr_return_rate": 0.8287529384648359, "train/extr_return_raw_mag": 9.595460167637578, "train/extr_return_raw_max": 9.595460167637578, "train/extr_return_raw_mean": 2.5741759097134627, "train/extr_return_raw_min": -0.5318854078098579, "train/extr_return_raw_std": 1.9844825232470478, "train/extr_reward_mag": 1.04339973838241, "train/extr_reward_max": 1.04339973838241, "train/extr_reward_mean": 0.03929192437617867, "train/extr_reward_min": -0.38410712436393457, "train/extr_reward_std": 0.18734179150175165, "train/image_loss_mean": 6.388135583312423, "train/image_loss_std": 11.43686949412028, "train/model_loss_mean": 14.620327052363644, "train/model_loss_std": 15.299582382484719, "train/model_opt_grad_norm": 55.334372993751806, "train/model_opt_grad_steps": 54899.27407407408, "train/model_opt_loss": 18275.408875868055, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1250.0, "train/policy_entropy_mag": 2.412237455226757, "train/policy_entropy_max": 2.412237455226757, "train/policy_entropy_mean": 0.44369569729875635, "train/policy_entropy_min": 0.07937501514399493, "train/policy_entropy_std": 0.5377940723189601, "train/policy_logprob_mag": 7.43838382297092, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4428662578264872, "train/policy_logprob_min": -7.43838382297092, "train/policy_logprob_std": 1.021194291556323, "train/policy_randomness_mag": 0.8514139625761245, "train/policy_randomness_max": 0.8514139625761245, "train/policy_randomness_mean": 0.15660510984835802, "train/policy_randomness_min": 0.02801589709189203, "train/policy_randomness_std": 0.18981770839956072, "train/post_ent_mag": 60.715882534450955, "train/post_ent_max": 60.715882534450955, "train/post_ent_mean": 43.95563589025427, "train/post_ent_min": 20.673652705439814, "train/post_ent_std": 7.80133087016918, "train/prior_ent_mag": 70.67782253689236, "train/prior_ent_max": 70.67782253689236, "train/prior_ent_mean": 57.642186426233366, "train/prior_ent_min": 42.23649286340784, "train/prior_ent_std": 4.4203642156389025, "train/rep_loss_mean": 13.628331700077764, "train/rep_loss_std": 9.436269046642161, "train/reward_avg": 0.027851562167483346, "train/reward_loss_mean": 0.05503581951337832, "train/reward_loss_std": 0.2437506632672416, "train/reward_max_data": 1.0207407456857187, "train/reward_max_pred": 1.0177409993277655, "train/reward_neg_acc": 0.9923627376556396, "train/reward_neg_loss": 0.028847782099964442, "train/reward_pos_acc": 0.9669721484184265, "train/reward_pos_loss": 0.8453745718355532, "train/reward_pred": 0.027122600183442785, "train/reward_rate": 0.03225549768518519, "train_stats/sum_log_reward": 9.07979816619796, "train_stats/max_log_achievement_collect_coal": 0.494949494949495, "train_stats/max_log_achievement_collect_drink": 5.737373737373737, "train_stats/max_log_achievement_collect_sapling": 1.4141414141414141, "train_stats/max_log_achievement_collect_stone": 12.02020202020202, "train_stats/max_log_achievement_collect_wood": 11.848484848484848, "train_stats/max_log_achievement_defeat_skeleton": 0.09090909090909091, "train_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "train_stats/max_log_achievement_eat_cow": 0.12121212121212122, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010101010101010102, "train_stats/max_log_achievement_make_stone_sword": 0.010101010101010102, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2121212121212122, "train_stats/max_log_achievement_make_wood_sword": 1.6161616161616161, "train_stats/max_log_achievement_place_furnace": 0.04040404040404041, "train_stats/max_log_achievement_place_plant": 1.3737373737373737, "train_stats/max_log_achievement_place_stone": 10.151515151515152, "train_stats/max_log_achievement_place_table": 3.323232323232323, "train_stats/max_log_achievement_wake_up": 1.1414141414141414, "train_stats/mean_log_entropy": 0.5054199343377893, "eval_stats/sum_log_reward": 8.058333506186804, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "eval_stats/max_log_achievement_collect_stone": 6.75, "eval_stats/max_log_achievement_collect_wood": 10.208333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.2916666666666667, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0416666666666667, "eval_stats/max_log_achievement_make_wood_sword": 1.3333333333333333, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.4583333333333333, "eval_stats/max_log_achievement_place_stone": 5.208333333333333, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 0.8333333333333334, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 6.879956515604135e-08, "report/cont_loss_std": 5.243558689471683e-07, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.191140760667622e-06, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.450286539281478e-08, "report/cont_pred": 0.994140625, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.945642471313477, "report/dyn_loss_std": 8.959925651550293, "report/image_loss_mean": 6.683533668518066, "report/image_loss_std": 11.876436233520508, "report/model_loss_mean": 15.10593032836914, "report/model_loss_std": 15.63203239440918, "report/post_ent_mag": 62.250152587890625, "report/post_ent_max": 62.250152587890625, "report/post_ent_mean": 43.91688537597656, "report/post_ent_min": 20.744253158569336, "report/post_ent_std": 7.389035224914551, "report/prior_ent_mag": 70.65313720703125, "report/prior_ent_max": 70.65313720703125, "report/prior_ent_mean": 58.33420181274414, "report/prior_ent_min": 46.25728225708008, "report/prior_ent_std": 4.468286037445068, "report/rep_loss_mean": 13.945642471313477, "report/rep_loss_std": 8.959925651550293, "report/reward_avg": 0.0400390625, "report/reward_loss_mean": 0.05501151084899902, "report/reward_loss_std": 0.20171582698822021, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002546787261963, "report/reward_neg_acc": 0.9969356656074524, "report/reward_neg_loss": 0.020693015307188034, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8016294836997986, "report/reward_pred": 0.03671608865261078, "report/reward_rate": 0.0439453125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 4.8624634985117154e-08, "eval/cont_loss_std": 2.610482283671445e-07, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.108208370074863e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.872329656928741e-08, "eval/cont_pred": 0.998046875, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.133880615234375, "eval/dyn_loss_std": 10.873997688293457, "eval/image_loss_mean": 12.637746810913086, "eval/image_loss_std": 17.522340774536133, "eval/model_loss_mean": 24.236412048339844, "eval/model_loss_std": 21.738174438476562, "eval/post_ent_mag": 58.74583435058594, "eval/post_ent_max": 58.74583435058594, "eval/post_ent_mean": 41.655155181884766, "eval/post_ent_min": 21.87088394165039, "eval/post_ent_std": 7.700122833251953, "eval/prior_ent_mag": 70.65313720703125, "eval/prior_ent_max": 70.65313720703125, "eval/prior_ent_mean": 58.75931930541992, "eval/prior_ent_min": 45.48760223388672, "eval/prior_ent_std": 4.184760570526123, "eval/rep_loss_mean": 19.133880615234375, "eval/rep_loss_std": 10.873997688293457, "eval/reward_avg": 0.03281249850988388, "eval/reward_loss_mean": 0.11833898723125458, "eval/reward_loss_std": 0.682867705821991, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006077289581299, "eval/reward_neg_acc": 0.9888550639152527, "eval/reward_neg_loss": 0.05109556019306183, "eval/reward_pos_acc": 0.7837837338447571, "eval/reward_pos_loss": 1.9121026992797852, "eval/reward_pred": 0.026221517473459244, "eval/reward_rate": 0.0361328125, "replay/size": 891009.0, "replay/inserts": 21496.0, "replay/samples": 21504.0, "replay/insert_wait_avg": 1.3566766922740986e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.17916658946446e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1730885160142097e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.705522537231445e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.410462141037, "timer/env.step_count": 2687.0, "timer/env.step_total": 235.9020848274231, "timer/env.step_frac": 0.23580529568089006, "timer/env.step_avg": 0.08779385367600413, "timer/env.step_min": 0.024100303649902344, "timer/env.step_max": 3.496399164199829, "timer/replay._sample_count": 21504.0, "timer/replay._sample_total": 11.077655553817749, "timer/replay._sample_frac": 0.01107311046118991, "timer/replay._sample_avg": 0.0005151439524654831, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.025699853897094727, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3515.0, "timer/agent.policy_total": 60.53213572502136, "timer/agent.policy_frac": 0.060507299769209724, "timer/agent.policy_avg": 0.017221091244671794, "timer/agent.policy_min": 0.009539365768432617, "timer/agent.policy_max": 0.12903761863708496, "timer/dataset_train_count": 1344.0, "timer/dataset_train_total": 0.1510026454925537, "timer/dataset_train_frac": 0.00015094069005374466, "timer/dataset_train_avg": 0.00011235315884862627, "timer/dataset_train_min": 9.846687316894531e-05, "timer/dataset_train_max": 0.00029754638671875, "timer/agent.train_count": 1344.0, "timer/agent.train_total": 601.410242319107, "timer/agent.train_frac": 0.6011634874669282, "timer/agent.train_avg": 0.4474778588683832, "timer/agent.train_min": 0.43517017364501953, "timer/agent.train_max": 1.6490845680236816, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4831116199493408, "timer/agent.report_frac": 0.0004829134022803054, "timer/agent.report_avg": 0.2415558099746704, "timer/agent.report_min": 0.23548269271850586, "timer/agent.report_max": 0.24762892723083496, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.002841543910379e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.486891801162432}
{"step": 891632, "time": 41420.90405201912, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 891792, "time": 41427.89319252968, "episode/length": 303.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 891960, "time": 41435.011946201324, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 892496, "time": 41455.009979486465, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 892496, "time": 41455.01968193054, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 892728, "time": 41466.04911804199, "episode/length": 136.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 893264, "time": 41487.71575164795, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 893480, "time": 41496.3373439312, "episode/length": 210.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 893712, "time": 41506.54092311859, "episode/length": 151.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 893744, "time": 41509.09928011894, "episode/length": 410.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951338199513382, "episode/intrinsic_return": 0.0}
{"step": 893960, "time": 41517.69804477692, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 893984, "time": 41520.423906326294, "episode/length": 29.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 894096, "time": 41525.755066394806, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 894256, "time": 41532.84507036209, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 894288, "time": 41535.421234846115, "episode/length": 100.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 894416, "time": 41541.21423006058, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 894720, "time": 41552.95403504372, "episode/length": 181.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 895144, "time": 41568.57491207123, "episode/length": 147.0, "episode/score": 6.099999949336052, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 895432, "time": 41579.85377240181, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 895712, "time": 41591.30554652214, "episode/length": 177.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 896000, "time": 41602.628667116165, "episode/length": 601.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9950166112956811, "episode/intrinsic_return": 0.0}
{"step": 896264, "time": 41612.885440826416, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 896296, "time": 41615.48757123947, "episode/length": 274.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 896424, "time": 41621.45026016235, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 897104, "time": 41646.20270347595, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 897616, "time": 41665.18871974945, "episode/length": 237.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 897640, "time": 41667.346799612045, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 897688, "time": 41670.52849030495, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 897936, "time": 41680.76210832596, "episode/length": 439.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 897952, "time": 41682.8856549263, "episode/length": 243.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 898152, "time": 41691.052174806595, "episode/length": 235.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.961864406779661, "episode/intrinsic_return": 0.0}
{"step": 898632, "time": 41708.515607357025, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 898688, "time": 41712.37725019455, "episode/length": 495.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9899193548387096, "episode/intrinsic_return": 0.0}
{"step": 899120, "time": 41728.22886109352, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 899520, "time": 41743.26122927666, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 899688, "time": 41750.292593717575, "episode/length": 191.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 899736, "time": 41753.43858098984, "episode/length": 222.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 41786.099475860596, "eval_episode/length": 184.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 900016, "time": 41789.67389154434, "eval_episode/length": 228.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9737991266375546}
{"step": 900016, "time": 41792.99977993965, "eval_episode/length": 266.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 900016, "time": 41797.127422332764, "eval_episode/length": 324.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9815384615384616}
{"step": 900016, "time": 41798.812727212906, "eval_episode/length": 326.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9877675840978594}
{"step": 900016, "time": 41802.660348415375, "eval_episode/length": 375.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976063829787234}
{"step": 900016, "time": 41805.435621738434, "eval_episode/length": 404.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9950617283950617}
{"step": 900016, "time": 41807.66133260727, "eval_episode/length": 231.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 900040, "time": 41808.253236055374, "episode/length": 262.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 900072, "time": 41810.95642518997, "episode/length": 172.0, "episode/score": 9.1000000461936, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 900072, "time": 41810.96659040451, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 900368, "time": 41824.302361249924, "episode/length": 334.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 900696, "time": 41836.72527575493, "episode/length": 125.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 900784, "time": 41841.45471191406, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 901440, "time": 41866.57432293892, "episode/length": 239.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 901848, "time": 41881.45265221596, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 901920, "time": 41885.80314421654, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 902248, "time": 41898.320419073105, "episode/length": 271.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 902264, "time": 41900.55296397209, "episode/length": 315.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 902616, "time": 41913.883786439896, "episode/length": 228.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 902888, "time": 41924.74514698982, "episode/length": 129.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 902968, "time": 41929.06126213074, "episode/length": 283.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 903440, "time": 41946.698175907135, "episode/length": 148.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 903608, "time": 41953.90170145035, "episode/length": 441.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 903880, "time": 41964.645431518555, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9653465346534653, "episode/intrinsic_return": 0.0}
{"step": 904064, "time": 41972.56051445007, "episode/length": 146.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 904152, "time": 41976.84135913849, "episode/length": 147.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 904176, "time": 41979.391726732254, "episode/length": 281.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 904616, "time": 41995.59147977829, "episode/length": 396.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9924433249370277, "episode/intrinsic_return": 0.0}
{"step": 905176, "time": 42015.87531256676, "episode/length": 319.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 905688, "time": 42034.69593214989, "episode/length": 280.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 905880, "time": 42042.87982368469, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 905904, "time": 42045.65796661377, "episode/length": 252.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 906024, "time": 42050.979669332504, "episode/length": 233.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 906312, "time": 42062.16567492485, "episode/length": 337.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 907224, "time": 42094.117762327194, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 907784, "time": 42114.44400835037, "episode/length": 450.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955654101995566, "episode/intrinsic_return": 0.0}
{"step": 907952, "time": 42121.922548532486, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 908040, "time": 42126.17903780937, "episode/length": 427.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 908184, "time": 42132.678164720535, "episode/length": 284.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 908472, "time": 42143.94719481468, "episode/length": 411.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9878640776699029, "episode/intrinsic_return": 0.0}
{"step": 908880, "time": 42159.36517286301, "episode/length": 398.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 909032, "time": 42166.50485539436, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 909224, "time": 42174.59694600105, "episode/length": 249.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 909304, "time": 42178.9059009552, "episode/length": 52.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 909328, "time": 42183.28800010681, "episode/length": 160.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9813664596273292, "episode/intrinsic_return": 0.0}
{"step": 909704, "time": 42197.47572016716, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 909744, "time": 42200.66167640686, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 909888, "time": 42207.14654970169, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 909896, "time": 42208.860030412674, "episode/length": 242.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 42236.511112213135, "eval_episode/length": 189.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 910000, "time": 42238.70079421997, "eval_episode/length": 192.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 910000, "time": 42240.84754157066, "eval_episode/length": 194.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 910000, "time": 42243.83663105965, "eval_episode/length": 214.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 910000, "time": 42246.38646888733, "eval_episode/length": 223.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 910000, "time": 42248.914766311646, "eval_episode/length": 229.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 910000, "time": 42251.11398053169, "eval_episode/length": 230.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 910000, "time": 42253.975811481476, "eval_episode/length": 58.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 910576, "time": 42273.651165008545, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 910816, "time": 42283.49539256096, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 910904, "time": 42287.82391548157, "episode/length": 233.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 911288, "time": 42302.397965192795, "episode/length": 173.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 911608, "time": 42314.68764925003, "episode/length": 39.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 911696, "time": 42319.45686984062, "episode/length": 402.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950372208436724, "episode/intrinsic_return": 0.0}
{"step": 912016, "time": 42331.82858109474, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 912160, "time": 42338.320383787155, "episode/length": 156.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 912232, "time": 42342.27844238281, "episode/length": 310.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 912816, "time": 42363.54861879349, "episode/length": 139.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 912824, "time": 42365.193305015564, "episode/length": 366.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9836512261580381, "episode/intrinsic_return": 0.0}
{"step": 913120, "time": 42376.985953330994, "episode/length": 426.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 913296, "time": 42384.38809418678, "episode/length": 309.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 913504, "time": 42392.96308708191, "episode/length": 236.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 913624, "time": 42398.29175782204, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 913712, "time": 42403.20277571678, "episode/length": 193.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 914057, "time": 42417.19525694847, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.611184411015071, "train/action_min": 0.0, "train/action_std": 3.37303363854158, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0380567175382418, "train/actor_opt_grad_steps": 56330.0, "train/actor_opt_loss": -5.303552580640671, "train/adv_mag": 0.47963156366179177, "train/adv_max": 0.43988107958583966, "train/adv_mean": 0.0031048373252331733, "train/adv_min": -0.3879605830772549, "train/adv_std": 0.05427132745055442, "train/cont_avg": 0.9948193705673759, "train/cont_loss_mean": 0.00027484906254505716, "train/cont_loss_std": 0.00810218671196841, "train/cont_neg_acc": 0.9842986612455219, "train/cont_neg_loss": 0.049135159857033255, "train/cont_pos_acc": 0.9999581118847461, "train/cont_pos_loss": 0.00011856930508610198, "train/cont_pred": 0.9948413431221712, "train/cont_rate": 0.9948193705673759, "train/dyn_loss_mean": 13.564041759950895, "train/dyn_loss_std": 9.41323799782611, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9157868395460412, "train/extr_critic_critic_opt_grad_steps": 56330.0, "train/extr_critic_critic_opt_loss": 15835.461720135196, "train/extr_critic_mag": 8.554087463000142, "train/extr_critic_max": 8.554087463000142, "train/extr_critic_mean": 2.737112947389589, "train/extr_critic_min": -0.21391592634485124, "train/extr_critic_std": 1.9856204969663147, "train/extr_return_normed_mag": 1.5042161493436665, "train/extr_return_normed_max": 1.5042161493436665, "train/extr_return_normed_mean": 0.422456959672008, "train/extr_return_normed_min": -0.0949564590416056, "train/extr_return_normed_std": 0.3187133088602242, "train/extr_return_rate": 0.836197037646111, "train/extr_return_raw_mag": 9.60145821131713, "train/extr_return_raw_max": 9.60145821131713, "train/extr_return_raw_mean": 2.7567586112529674, "train/extr_return_raw_min": -0.5177589876854674, "train/extr_return_raw_std": 2.016797810581559, "train/extr_reward_mag": 1.0470007446640772, "train/extr_reward_max": 1.0470007446640772, "train/extr_reward_mean": 0.043904463687898417, "train/extr_reward_min": -0.3980406869387796, "train/extr_reward_std": 0.19728744325908362, "train/image_loss_mean": 6.2402003978161105, "train/image_loss_std": 11.393189355836693, "train/model_loss_mean": 14.435376187588306, "train/model_loss_std": 15.206737504783252, "train/model_opt_grad_norm": 52.81380587097601, "train/model_opt_grad_steps": 56277.964539007095, "train/model_opt_loss": 20039.92479083555, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1400.709219858156, "train/policy_entropy_mag": 2.4504504812524672, "train/policy_entropy_max": 2.4504504812524672, "train/policy_entropy_mean": 0.4722419305050627, "train/policy_entropy_min": 0.07937501624543616, "train/policy_entropy_std": 0.5931475995280219, "train/policy_logprob_mag": 7.438383819363642, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.47221737846415096, "train/policy_logprob_min": -7.438383819363642, "train/policy_logprob_std": 1.045967624965289, "train/policy_randomness_mag": 0.8649014851725694, "train/policy_randomness_max": 0.8649014851725694, "train/policy_randomness_mean": 0.16668067766842268, "train/policy_randomness_min": 0.02801589749700634, "train/policy_randomness_std": 0.20935507372338721, "train/post_ent_mag": 61.04876451965765, "train/post_ent_max": 61.04876451965765, "train/post_ent_mean": 43.97369952912026, "train/post_ent_min": 20.592884117829882, "train/post_ent_std": 7.869614645098964, "train/prior_ent_mag": 70.7442192456401, "train/prior_ent_max": 70.7442192456401, "train/prior_ent_mean": 57.60765741226521, "train/prior_ent_min": 42.143119541465815, "train/prior_ent_std": 4.443198975096357, "train/rep_loss_mean": 13.564041759950895, "train/rep_loss_std": 9.41323799782611, "train/reward_avg": 0.029925753369081952, "train/reward_loss_mean": 0.0564759613298778, "train/reward_loss_std": 0.24812120326021883, "train/reward_max_data": 1.0241134809264054, "train/reward_max_pred": 1.0181681695559346, "train/reward_neg_acc": 0.9928010258268802, "train/reward_neg_loss": 0.029036993193869473, "train/reward_pos_acc": 0.9731727179060591, "train/reward_pos_loss": 0.8239090459566589, "train/reward_pred": 0.02923229620758946, "train/reward_rate": 0.03443594858156029, "train_stats/sum_log_reward": 8.931579140612953, "train_stats/max_log_achievement_collect_coal": 0.37894736842105264, "train_stats/max_log_achievement_collect_drink": 6.947368421052632, "train_stats/max_log_achievement_collect_sapling": 1.231578947368421, "train_stats/max_log_achievement_collect_stone": 12.147368421052631, "train_stats/max_log_achievement_collect_wood": 12.557894736842105, "train_stats/max_log_achievement_defeat_skeleton": 0.042105263157894736, "train_stats/max_log_achievement_defeat_zombie": 0.6, "train_stats/max_log_achievement_eat_cow": 0.1368421052631579, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1894736842105262, "train_stats/max_log_achievement_make_wood_sword": 1.694736842105263, "train_stats/max_log_achievement_place_furnace": 0.07368421052631578, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_stone": 9.936842105263159, "train_stats/max_log_achievement_place_table": 3.663157894736842, "train_stats/max_log_achievement_wake_up": 1.2105263157894737, "train_stats/mean_log_entropy": 0.5076505899429321, "eval_stats/sum_log_reward": 9.975000232458115, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 5.4375, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 11.125, "eval_stats/max_log_achievement_collect_wood": 13.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 1.0, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 2.1875, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 9.5, "eval_stats/max_log_achievement_place_table": 4.0625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.215757816287805e-07, "report/cont_loss_std": 1.3684350960829761e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.899444320471957e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.852025424246676e-07, "report/cont_pred": 0.9951168894767761, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.936117172241211, "report/dyn_loss_std": 9.144505500793457, "report/image_loss_mean": 6.687487602233887, "report/image_loss_std": 11.812054634094238, "report/model_loss_mean": 15.106574058532715, "report/model_loss_std": 15.542850494384766, "report/post_ent_mag": 58.791927337646484, "report/post_ent_max": 58.791927337646484, "report/post_ent_mean": 43.17169952392578, "report/post_ent_min": 20.791194915771484, "report/post_ent_std": 7.3915581703186035, "report/prior_ent_mag": 71.08545684814453, "report/prior_ent_max": 71.08545684814453, "report/prior_ent_mean": 57.18988800048828, "report/prior_ent_min": 42.412109375, "report/prior_ent_std": 4.490603923797607, "report/rep_loss_mean": 13.936117172241211, "report/rep_loss_std": 9.144505500793457, "report/reward_avg": 0.02607421763241291, "report/reward_loss_mean": 0.05741603672504425, "report/reward_loss_std": 0.2445903867483139, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0800070762634277, "report/reward_neg_acc": 0.9889112710952759, "report/reward_neg_loss": 0.03321177512407303, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.8077479600906372, "report/reward_pred": 0.025122448801994324, "report/reward_rate": 0.03125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0027109929360449314, "eval/cont_loss_std": 0.08651389926671982, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.6925477981567383, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.751640856033191e-06, "eval/cont_pred": 0.9970037937164307, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.668718338012695, "eval/dyn_loss_std": 11.290663719177246, "eval/image_loss_mean": 9.736433029174805, "eval/image_loss_std": 14.79594898223877, "eval/model_loss_mean": 21.038259506225586, "eval/model_loss_std": 19.475770950317383, "eval/post_ent_mag": 59.74653625488281, "eval/post_ent_max": 59.74653625488281, "eval/post_ent_mean": 41.46226119995117, "eval/post_ent_min": 21.21120262145996, "eval/post_ent_std": 7.599060535430908, "eval/prior_ent_mag": 71.08545684814453, "eval/prior_ent_max": 71.08545684814453, "eval/prior_ent_mean": 57.413734436035156, "eval/prior_ent_min": 43.18297576904297, "eval/prior_ent_std": 4.460487365722656, "eval/rep_loss_mean": 18.668718338012695, "eval/rep_loss_std": 11.290663719177246, "eval/reward_avg": 0.03525390475988388, "eval/reward_loss_mean": 0.09788306057453156, "eval/reward_loss_std": 0.5363640785217285, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0083599090576172, "eval/reward_neg_acc": 0.9857868552207947, "eval/reward_neg_loss": 0.045871932059526443, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.4114974737167358, "eval/reward_pred": 0.035790495574474335, "eval/reward_rate": 0.0380859375, "replay/size": 913553.0, "replay/inserts": 22544.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.3678927553554558e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.095342836454458e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.211379383419369e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3914248943329, "timer/env.step_count": 2818.0, "timer/env.step_total": 231.73776960372925, "timer/env.step_frac": 0.23164709716319962, "timer/env.step_avg": 0.0822348366230409, "timer/env.step_min": 0.023781299591064453, "timer/env.step_max": 3.531630516052246, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.601410865783691, "timer/replay._sample_frac": 0.011596871561558116, "timer/replay._sample_avg": 0.0005146119085248267, "timer/replay._sample_min": 0.0003943443298339844, "timer/replay._sample_max": 0.008811473846435547, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3484.0, "timer/agent.policy_total": 59.003209590911865, "timer/agent.policy_frac": 0.05898012330238049, "timer/agent.policy_avg": 0.01693547921667964, "timer/agent.policy_min": 0.009356260299682617, "timer/agent.policy_max": 0.12573552131652832, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.15987920761108398, "timer/dataset_train_frac": 0.00015981665139519897, "timer/dataset_train_avg": 0.0001134699841100667, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0010809898376464844, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 632.7090566158295, "timer/agent.train_frac": 0.6324614954418065, "timer/agent.train_avg": 0.44904830135970863, "timer/agent.train_min": 0.4347536563873291, "timer/agent.train_max": 1.741075038909912, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48529911041259766, "timer/agent.report_frac": 0.00048510922658484177, "timer/agent.report_avg": 0.24264955520629883, "timer/agent.report_min": 0.23484325408935547, "timer/agent.report_max": 0.2504558563232422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.956390380859375e-05, "timer/dataset_eval_frac": 2.955233628848474e-08, "timer/dataset_eval_avg": 2.956390380859375e-05, "timer/dataset_eval_min": 2.956390380859375e-05, "timer/dataset_eval_max": 2.956390380859375e-05, "fps": 22.534858328635245}
{"step": 914408, "time": 42428.8680768013, "episode/length": 298.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 914488, "time": 42433.3001101017, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 915136, "time": 42456.917392492294, "episode/length": 251.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 915200, "time": 42460.708223342896, "episode/length": 237.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 915368, "time": 42467.66246795654, "episode/length": 206.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 915608, "time": 42477.175721645355, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 915848, "time": 42486.86713767052, "episode/length": 378.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9868073878627969, "episode/intrinsic_return": 0.0}
{"step": 916216, "time": 42500.8816306591, "episode/length": 323.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9845679012345679, "episode/intrinsic_return": 0.0}
{"step": 916352, "time": 42507.251056194305, "episode/length": 355.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9971910112359551, "episode/intrinsic_return": 0.0}
{"step": 916776, "time": 42522.96667432785, "episode/length": 295.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 916984, "time": 42532.048233270645, "episode/length": 141.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 917160, "time": 42540.28638601303, "episode/length": 244.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 917616, "time": 42559.14131307602, "episode/length": 174.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 917680, "time": 42562.884763002396, "episode/length": 258.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 917776, "time": 42567.74765944481, "episode/length": 300.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9833887043189369, "episode/intrinsic_return": 0.0}
{"step": 917896, "time": 42573.04853987694, "episode/length": 113.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 918136, "time": 42582.67565560341, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 918344, "time": 42591.17291331291, "episode/length": 481.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9813278008298755, "episode/intrinsic_return": 0.0}
{"step": 918856, "time": 42609.90774226189, "episode/length": 134.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9703703703703703, "episode/intrinsic_return": 0.0}
{"step": 918960, "time": 42615.13484239578, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 919120, "time": 42622.03425526619, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 919136, "time": 42624.09969043732, "episode/length": 246.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 919296, "time": 42630.956293821335, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 919328, "time": 42633.60800361633, "episode/length": 318.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 42682.18596982956, "eval_episode/length": 192.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 920088, "time": 42686.87595510483, "eval_episode/length": 260.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9846743295019157}
{"step": 920088, "time": 42689.33594751358, "eval_episode/length": 266.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9812734082397003}
{"step": 920088, "time": 42695.74886870384, "eval_episode/length": 336.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9940652818991098}
{"step": 920088, "time": 42699.050798654556, "eval_episode/length": 376.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.986737400530504}
{"step": 920088, "time": 42701.633660793304, "eval_episode/length": 394.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9949367088607595}
{"step": 920088, "time": 42703.53733611107, "eval_episode/length": 400.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9925187032418953}
{"step": 920088, "time": 42706.25975871086, "eval_episode/length": 425.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9788732394366197}
{"step": 920144, "time": 42708.38430404663, "episode/length": 224.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 920152, "time": 42710.02602863312, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 920280, "time": 42715.81456875801, "episode/length": 267.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9813432835820896, "episode/intrinsic_return": 0.0}
{"step": 920304, "time": 42718.42396044731, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 920560, "time": 42728.57381653786, "episode/length": 50.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 920856, "time": 42739.98811841011, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9641025641025641, "episode/intrinsic_return": 0.0}
{"step": 920960, "time": 42745.30253243446, "episode/length": 229.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 921008, "time": 42748.43715929985, "episode/length": 55.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 921280, "time": 42758.984585523605, "episode/length": 267.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 921576, "time": 42770.222276210785, "episode/length": 280.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 921720, "time": 42776.66216468811, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 922264, "time": 42796.411403656006, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 922288, "time": 42799.08747053146, "episode/length": 267.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 922400, "time": 42804.39297890663, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 922464, "time": 42808.14962029457, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 922720, "time": 42818.28602695465, "episode/length": 179.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 923104, "time": 42832.74213409424, "episode/length": 47.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 923664, "time": 42853.171796798706, "episode/length": 260.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 923744, "time": 42857.37601542473, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9567567567567568, "episode/intrinsic_return": 0.0}
{"step": 923792, "time": 42860.59892678261, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 923808, "time": 42862.76801800728, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 924128, "time": 42874.98882198334, "episode/length": 408.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9877750611246944, "episode/intrinsic_return": 0.0}
{"step": 924264, "time": 42881.44861340523, "episode/length": 317.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 924616, "time": 42894.78819608688, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 924976, "time": 42908.54674220085, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808917197452229, "episode/intrinsic_return": 0.0}
{"step": 925248, "time": 42919.31327843666, "episode/length": 197.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 925552, "time": 42931.17133641243, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 925832, "time": 42943.74092102051, "episode/length": 252.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 925864, "time": 42946.408136844635, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768339768339769, "episode/intrinsic_return": 0.0}
{"step": 926272, "time": 42961.98203539848, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 926280, "time": 42963.573650598526, "episode/length": 251.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 926536, "time": 42973.79288029671, "episode/length": 122.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 926776, "time": 42983.281180143356, "episode/length": 224.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 926904, "time": 42989.16851782799, "episode/length": 346.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 926960, "time": 42992.67534852028, "episode/length": 213.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 927096, "time": 42998.50582623482, "episode/length": 157.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 927336, "time": 43008.31050992012, "episode/length": 183.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 927664, "time": 43021.0339744091, "episode/length": 110.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 927864, "time": 43029.24060368538, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 927880, "time": 43031.467529296875, "episode/length": 167.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 928712, "time": 43060.79394841194, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 928952, "time": 43070.44359779358, "episode/length": 29.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 929296, "time": 43083.61706328392, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 929352, "time": 43086.9677233696, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 929656, "time": 43098.83174157143, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 929864, "time": 43107.40724873543, "episode/length": 369.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 929952, "time": 43112.10371899605, "episode/length": 373.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9866310160427807, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 43137.94363951683, "eval_episode/length": 172.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 930072, "time": 43139.88865804672, "eval_episode/length": 181.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.967032967032967}
{"step": 930072, "time": 43141.932257175446, "eval_episode/length": 190.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 930072, "time": 43145.22284936905, "eval_episode/length": 227.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 930072, "time": 43147.13442635536, "eval_episode/length": 235.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 930072, "time": 43151.82636618614, "eval_episode/length": 304.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9901639344262295}
{"step": 930072, "time": 43156.65323829651, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 930072, "time": 43158.735122680664, "eval_episode/length": 390.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.989769820971867}
{"step": 930248, "time": 43164.58749675751, "episode/length": 295.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 930480, "time": 43174.058769226074, "episode/length": 326.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 930832, "time": 43187.571868658066, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 930952, "time": 43192.892919778824, "episode/length": 58.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 931088, "time": 43199.21353435516, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 931160, "time": 43203.031859874725, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 931256, "time": 43207.81017613411, "episode/length": 173.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 931304, "time": 43211.070120573044, "episode/length": 58.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 931560, "time": 43221.37382864952, "episode/length": 49.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 932264, "time": 43246.6097369194, "episode/length": 288.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 932432, "time": 43254.151502370834, "episode/length": 434.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 932432, "time": 43254.16073656082, "episode/length": 184.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 932520, "time": 43260.37439894676, "episode/length": 178.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 932624, "time": 43265.62377977371, "episode/length": 44.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 932904, "time": 43276.36638689041, "episode/length": 47.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 933032, "time": 43282.273686409, "episode/length": 183.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 933104, "time": 43286.51743865013, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 933200, "time": 43291.42992711067, "episode/length": 368.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 933680, "time": 43309.26145243645, "episode/length": 155.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 933712, "time": 43312.385258197784, "episode/length": 159.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 934144, "time": 43330.70399188995, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 934264, "time": 43335.996066093445, "episode/length": 153.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 934648, "time": 43350.46893262863, "episode/length": 120.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 934720, "time": 43354.663584947586, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 934728, "time": 43356.40631866455, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 934800, "time": 43360.65840315819, "episode/length": 442.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 935248, "time": 43377.18649029732, "episode/length": 255.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 935784, "time": 43396.50378537178, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 935848, "time": 43400.32346200943, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 935920, "time": 43404.503947496414, "episode/length": 148.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 936233, "time": 43417.39901304245, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.5688162541043935, "train/action_min": 0.0, "train/action_std": 3.3944794941639556, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0375985712001937, "train/actor_opt_grad_steps": 57725.0, "train/actor_opt_loss": -6.927900033854488, "train/adv_mag": 0.492818683385849, "train/adv_max": 0.4367210361836613, "train/adv_mean": 0.0024994551613022136, "train/adv_min": -0.4046725913666297, "train/adv_std": 0.05312754532349282, "train/cont_avg": 0.9950039628623188, "train/cont_loss_mean": 0.00021636488920640605, "train/cont_loss_std": 0.00665701437065826, "train/cont_neg_acc": 0.9858609399069911, "train/cont_neg_loss": 0.036055884233288794, "train/cont_pos_acc": 0.9999857562175696, "train/cont_pos_loss": 5.108226240832232e-05, "train/cont_pred": 0.9950302912705187, "train/cont_rate": 0.9950039628623188, "train/dyn_loss_mean": 13.4211639183155, "train/dyn_loss_std": 9.37952182603919, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9180218162743942, "train/extr_critic_critic_opt_grad_steps": 57725.0, "train/extr_critic_critic_opt_loss": 15726.983936254528, "train/extr_critic_mag": 8.71705378656802, "train/extr_critic_max": 8.71705378656802, "train/extr_critic_mean": 2.7407136231228924, "train/extr_critic_min": -0.2148577104444089, "train/extr_critic_std": 2.0209933579831882, "train/extr_return_normed_mag": 1.5016893960427546, "train/extr_return_normed_max": 1.5016893960427546, "train/extr_return_normed_mean": 0.4161600172519684, "train/extr_return_normed_min": -0.0972594427673713, "train/extr_return_normed_std": 0.320863323799078, "train/extr_return_rate": 0.8356771244518999, "train/extr_return_raw_mag": 9.688414414723715, "train/extr_return_raw_max": 9.688414414723715, "train/extr_return_raw_mean": 2.756692033746968, "train/extr_return_raw_min": -0.5223652001308359, "train/extr_return_raw_std": 2.0493050813674927, "train/extr_reward_mag": 1.0444830258687336, "train/extr_reward_max": 1.0444830258687336, "train/extr_reward_mean": 0.04429347382561452, "train/extr_reward_min": -0.4150132441866225, "train/extr_reward_std": 0.19794655072948206, "train/image_loss_mean": 6.071689652360004, "train/image_loss_std": 11.422046972357709, "train/model_loss_mean": 14.182309095410334, "train/model_loss_std": 15.214304606119791, "train/model_opt_grad_norm": 54.50124332870262, "train/model_opt_grad_steps": 57671.65217391304, "train/model_opt_loss": 19331.377632472828, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1358.695652173913, "train/policy_entropy_mag": 2.4342361308526304, "train/policy_entropy_max": 2.4342361308526304, "train/policy_entropy_mean": 0.45159686540347943, "train/policy_entropy_min": 0.07937501430295515, "train/policy_entropy_std": 0.5643061466407084, "train/policy_logprob_mag": 7.4383838349494384, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4518929886213247, "train/policy_logprob_min": -7.4383838349494384, "train/policy_logprob_std": 1.0321473574292832, "train/policy_randomness_mag": 0.8591785275417826, "train/policy_randomness_max": 0.8591785275417826, "train/policy_randomness_mean": 0.1593938765750415, "train/policy_randomness_min": 0.0280158968264426, "train/policy_randomness_std": 0.19917530760816907, "train/post_ent_mag": 60.91692974256433, "train/post_ent_max": 60.91692974256433, "train/post_ent_mean": 44.17247028627257, "train/post_ent_min": 20.520577969758406, "train/post_ent_std": 7.879946795062742, "train/prior_ent_mag": 70.78124319988748, "train/prior_ent_max": 70.78124319988748, "train/prior_ent_mean": 57.66170291624208, "train/prior_ent_min": 42.394156055174015, "train/prior_ent_std": 4.427750917448514, "train/rep_loss_mean": 13.4211639183155, "train/rep_loss_std": 9.37952182603919, "train/reward_avg": 0.030618772605784994, "train/reward_loss_mean": 0.05770484061128851, "train/reward_loss_std": 0.252116407605185, "train/reward_max_data": 1.0217391356177952, "train/reward_max_pred": 1.0160191171411155, "train/reward_neg_acc": 0.992668949175572, "train/reward_neg_loss": 0.029507660914374435, "train/reward_pos_acc": 0.9719017083230226, "train/reward_pos_loss": 0.8304693361987239, "train/reward_pred": 0.029746757347838604, "train/reward_rate": 0.035142096920289856, "train_stats/sum_log_reward": 8.991089355827558, "train_stats/max_log_achievement_collect_coal": 0.49504950495049505, "train_stats/max_log_achievement_collect_drink": 6.376237623762377, "train_stats/max_log_achievement_collect_sapling": 1.316831683168317, "train_stats/max_log_achievement_collect_stone": 13.089108910891088, "train_stats/max_log_achievement_collect_wood": 11.742574257425742, "train_stats/max_log_achievement_defeat_skeleton": 0.0594059405940594, "train_stats/max_log_achievement_defeat_zombie": 0.7623762376237624, "train_stats/max_log_achievement_eat_cow": 0.13861386138613863, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.188118811881188, "train_stats/max_log_achievement_make_wood_sword": 1.6732673267326732, "train_stats/max_log_achievement_place_furnace": 0.04950495049504951, "train_stats/max_log_achievement_place_plant": 1.297029702970297, "train_stats/max_log_achievement_place_stone": 10.742574257425742, "train_stats/max_log_achievement_place_table": 3.4653465346534653, "train_stats/max_log_achievement_wake_up": 1.0594059405940595, "train_stats/mean_log_entropy": 0.4701932659833738, "eval_stats/sum_log_reward": 9.350000202655792, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 9.375, "eval_stats/max_log_achievement_collect_sapling": 0.875, "eval_stats/max_log_achievement_collect_stone": 15.5, "eval_stats/max_log_achievement_collect_wood": 13.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.1875, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 2.0625, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 0.875, "eval_stats/max_log_achievement_place_stone": 13.0, "eval_stats/max_log_achievement_place_table": 4.125, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 5.386419616115745e-06, "report/cont_loss_std": 8.716063894098625e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0003891916712746024, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.364331066928571e-06, "report/cont_pred": 0.9921882152557373, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.611470222473145, "report/dyn_loss_std": 9.576261520385742, "report/image_loss_mean": 7.581185817718506, "report/image_loss_std": 12.30678653717041, "report/model_loss_mean": 15.818389892578125, "report/model_loss_std": 16.030109405517578, "report/post_ent_mag": 59.713714599609375, "report/post_ent_max": 59.713714599609375, "report/post_ent_mean": 44.637237548828125, "report/post_ent_min": 21.111343383789062, "report/post_ent_std": 8.01026439666748, "report/prior_ent_mag": 70.74491119384766, "report/prior_ent_max": 70.74491119384766, "report/prior_ent_mean": 58.31839370727539, "report/prior_ent_min": 45.74584197998047, "report/prior_ent_std": 4.678929328918457, "report/rep_loss_mean": 13.611470222473145, "report/rep_loss_std": 9.576261520385742, "report/reward_avg": 0.02978515625, "report/reward_loss_mean": 0.07031629979610443, "report/reward_loss_std": 0.32012370228767395, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0783171653747559, "report/reward_neg_acc": 0.9919028878211975, "report/reward_neg_loss": 0.035250525921583176, "report/reward_pos_acc": 0.9166666865348816, "report/reward_pos_loss": 1.0326769351959229, "report/reward_pred": 0.02936117723584175, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 3.9836821088101715e-05, "eval/cont_loss_std": 0.0011579053243622184, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.418440948938951e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.98240408685524e-05, "eval/cont_pred": 0.9970313906669617, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.41667366027832, "eval/dyn_loss_std": 10.883061408996582, "eval/image_loss_mean": 13.285654067993164, "eval/image_loss_std": 18.0522518157959, "eval/model_loss_mean": 24.413040161132812, "eval/model_loss_std": 22.328916549682617, "eval/post_ent_mag": 58.47229766845703, "eval/post_ent_max": 58.47229766845703, "eval/post_ent_mean": 42.746429443359375, "eval/post_ent_min": 21.62969970703125, "eval/post_ent_std": 7.872668266296387, "eval/prior_ent_mag": 70.74491119384766, "eval/prior_ent_max": 70.74491119384766, "eval/prior_ent_mean": 59.25563049316406, "eval/prior_ent_min": 45.174678802490234, "eval/prior_ent_std": 4.320065021514893, "eval/rep_loss_mean": 18.41667366027832, "eval/rep_loss_std": 10.883061408996582, "eval/reward_avg": 0.02568359486758709, "eval/reward_loss_mean": 0.07733974605798721, "eval/reward_loss_std": 0.4300689697265625, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.000880479812622, "eval/reward_neg_acc": 0.9959757924079895, "eval/reward_neg_loss": 0.03171372786164284, "eval/reward_pos_acc": 0.7333333492279053, "eval/reward_pos_loss": 1.589081883430481, "eval/reward_pred": 0.018910571932792664, "eval/reward_rate": 0.029296875, "replay/size": 935729.0, "replay/inserts": 22176.0, "replay/samples": 22176.0, "replay/insert_wait_avg": 1.3389220141401194e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.108907506923483e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6536.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2201078081072616e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1859006881714, "timer/env.step_count": 2772.0, "timer/env.step_total": 239.33855199813843, "timer/env.step_frac": 0.23929406706639544, "timer/env.step_avg": 0.08634146897479741, "timer/env.step_min": 0.0240323543548584, "timer/env.step_max": 3.5263936519622803, "timer/replay._sample_count": 22176.0, "timer/replay._sample_total": 11.347437381744385, "timer/replay._sample_frac": 0.011345328277410084, "timer/replay._sample_avg": 0.000511699016132052, "timer/replay._sample_min": 0.00042510032653808594, "timer/replay._sample_max": 0.010829925537109375, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3589.0, "timer/agent.policy_total": 60.360843896865845, "timer/agent.policy_frac": 0.060349624860073475, "timer/agent.policy_avg": 0.016818290302832502, "timer/agent.policy_min": 0.0095367431640625, "timer/agent.policy_max": 0.13649249076843262, "timer/dataset_train_count": 1386.0, "timer/dataset_train_total": 0.15620923042297363, "timer/dataset_train_frac": 0.00015618019641698097, "timer/dataset_train_avg": 0.00011270507245524794, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.001743316650390625, "timer/agent.train_count": 1386.0, "timer/agent.train_total": 621.0537793636322, "timer/agent.train_frac": 0.6209383464977063, "timer/agent.train_avg": 0.4480907499016105, "timer/agent.train_min": 0.43262696266174316, "timer/agent.train_max": 1.754133939743042, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4833223819732666, "timer/agent.report_frac": 0.00048323254870991463, "timer/agent.report_avg": 0.2416611909866333, "timer/agent.report_min": 0.23618054389953613, "timer/agent.report_max": 0.24714183807373047, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.3372397122627726e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 22.17155623084415}
{"step": 936312, "time": 43420.02762007713, "episode/length": 207.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 936560, "time": 43430.08248877525, "episode/length": 219.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 936664, "time": 43434.89908909798, "episode/length": 109.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 937312, "time": 43458.57822775841, "episode/length": 323.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 937424, "time": 43464.47909164429, "episode/length": 271.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 937480, "time": 43468.175560474396, "episode/length": 416.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976019184652278, "episode/intrinsic_return": 0.0}
{"step": 937528, "time": 43471.96509003639, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9601990049751243, "episode/intrinsic_return": 0.0}
{"step": 937592, "time": 43476.134021520615, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 937704, "time": 43481.5113735199, "episode/length": 34.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 937968, "time": 43492.154806137085, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 938568, "time": 43513.488184690475, "episode/length": 135.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9485294117647058, "episode/intrinsic_return": 0.0}
{"step": 938912, "time": 43526.749118089676, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 939080, "time": 43533.65321087837, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 939176, "time": 43538.49542546272, "episode/length": 415.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 939192, "time": 43540.713030815125, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 939232, "time": 43543.92362213135, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 939456, "time": 43552.99312353134, "episode/length": 361.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 939520, "time": 43556.67734003067, "episode/length": 40.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9024390243902439, "episode/intrinsic_return": 0.0}
{"step": 939640, "time": 43562.041605472565, "episode/length": 57.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 43596.05374765396, "eval_episode/length": 121.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9918032786885246}
{"step": 940056, "time": 43598.710787296295, "eval_episode/length": 147.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9594594594594594}
{"step": 940056, "time": 43600.462903022766, "eval_episode/length": 148.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 940056, "time": 43603.85793375969, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 940056, "time": 43608.16626167297, "eval_episode/length": 248.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 940056, "time": 43610.80755805969, "eval_episode/length": 151.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 940056, "time": 43612.729447841644, "eval_episode/length": 280.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9786476868327402}
{"step": 940056, "time": 43614.293112039566, "eval_episode/length": 281.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9716312056737588}
{"step": 940520, "time": 43629.99528861046, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 940704, "time": 43637.97050833702, "episode/length": 147.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 940856, "time": 43644.604016542435, "episode/length": 285.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 941376, "time": 43664.55002427101, "episode/length": 267.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 941552, "time": 43672.0191757679, "episode/length": 238.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 941768, "time": 43680.62175774574, "episode/length": 474.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9810526315789474, "episode/intrinsic_return": 0.0}
{"step": 942000, "time": 43690.30665111542, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 942120, "time": 43697.47366261482, "episode/length": 176.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 942152, "time": 43700.093022584915, "episode/length": 404.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9851851851851852, "episode/intrinsic_return": 0.0}
{"step": 942256, "time": 43705.39486002922, "episode/length": 60.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 942792, "time": 43724.64020562172, "episode/length": 416.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976019184652278, "episode/intrinsic_return": 0.0}
{"step": 942968, "time": 43732.071138858795, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 943248, "time": 43743.242007017136, "episode/length": 298.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 943368, "time": 43748.645567178726, "episode/length": 151.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 943400, "time": 43751.41805768013, "episode/length": 230.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 943624, "time": 43760.513724803925, "episode/length": 202.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 943696, "time": 43764.67694425583, "episode/length": 40.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8780487804878049, "episode/intrinsic_return": 0.0}
{"step": 943784, "time": 43768.93303346634, "episode/length": 207.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 944120, "time": 43781.71318793297, "episode/length": 232.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 944632, "time": 43800.43948054314, "episode/length": 229.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 945336, "time": 43826.191833496094, "episode/length": 193.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 945472, "time": 43832.55610895157, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 945640, "time": 43839.66153860092, "episode/length": 279.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 946064, "time": 43855.61163306236, "episode/length": 295.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 946112, "time": 43858.80210518837, "episode/length": 392.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 946360, "time": 43868.471354961395, "episode/length": 279.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 946600, "time": 43878.22797346115, "episode/length": 418.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 946928, "time": 43891.057804346085, "episode/length": 286.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 946944, "time": 43893.111063718796, "episode/length": 162.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 947008, "time": 43896.81966114044, "episode/length": 117.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 947400, "time": 43911.360763549805, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 947456, "time": 43914.97185969353, "episode/length": 247.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 948032, "time": 43935.663326501846, "episode/length": 208.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 948088, "time": 43938.93353128433, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 948184, "time": 43943.81452345848, "episode/length": 355.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 948528, "time": 43957.12954711914, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 948704, "time": 43964.76304745674, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 948920, "time": 43973.36777162552, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 949008, "time": 43977.9593975544, "episode/length": 200.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9850746268656716, "episode/intrinsic_return": 0.0}
{"step": 949552, "time": 43997.735911369324, "episode/length": 189.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 949888, "time": 44010.58495402336, "episode/length": 212.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 44033.348057985306, "eval_episode/length": 76.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.922077922077922}
{"step": 950040, "time": 44038.276200056076, "eval_episode/length": 149.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 950040, "time": 44040.399520397186, "eval_episode/length": 161.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 950040, "time": 44042.12738108635, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 950040, "time": 44044.02077460289, "eval_episode/length": 172.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 950040, "time": 44045.85161280632, "eval_episode/length": 179.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 950040, "time": 44047.80610871315, "eval_episode/length": 186.0, "eval_episode/score": 11.100000016391277, "eval_episode/reward_rate": 0.983957219251337}
{"step": 950040, "time": 44052.469428539276, "eval_episode/length": 38.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 950120, "time": 44055.14411020279, "episode/length": 138.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 950120, "time": 44055.15402030945, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 950232, "time": 44062.32355308533, "episode/length": 412.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975786924939467, "episode/intrinsic_return": 0.0}
{"step": 950440, "time": 44072.40885472298, "episode/length": 189.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 951520, "time": 44110.50935816765, "episode/length": 373.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9919786096256684, "episode/intrinsic_return": 0.0}
{"step": 951656, "time": 44116.311223745346, "episode/length": 262.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 951672, "time": 44118.40924215317, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 951760, "time": 44123.09404325485, "episode/length": 164.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 952160, "time": 44137.880907058716, "episode/length": 508.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9921414538310412, "episode/intrinsic_return": 0.0}
{"step": 952544, "time": 44152.30214428902, "episode/length": 331.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 952872, "time": 44164.619960308075, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 953112, "time": 44174.30654883385, "episode/length": 359.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9805555555555555, "episode/intrinsic_return": 0.0}
{"step": 954128, "time": 44210.16733622551, "episode/length": 245.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 954392, "time": 44220.39680981636, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 954512, "time": 44226.159769535065, "episode/length": 204.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 954944, "time": 44242.23899078369, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 955080, "time": 44248.18317985535, "episode/length": 427.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 955120, "time": 44251.31544828415, "episode/length": 321.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 955440, "time": 44263.6605694294, "episode/length": 459.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9934782608695653, "episode/intrinsic_return": 0.0}
{"step": 955560, "time": 44269.03557944298, "episode/length": 178.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 955816, "time": 44279.26438117027, "episode/length": 711.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9803370786516854, "episode/intrinsic_return": 0.0}
{"step": 956064, "time": 44289.38589644432, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 956208, "time": 44295.99880003929, "episode/length": 226.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 956592, "time": 44311.06296014786, "episode/length": 183.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 956912, "time": 44323.38564777374, "episode/length": 168.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 957064, "time": 44329.96511387825, "episode/length": 58.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 957208, "time": 44336.560817956924, "episode/length": 142.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 957368, "time": 44343.53103137016, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 957408, "time": 44346.63157224655, "episode/length": 290.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 957528, "time": 44352.013506650925, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 957560, "time": 44354.62841796875, "episode/length": 168.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 957648, "time": 44359.390424489975, "episode/length": 228.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 958416, "time": 44386.585268735886, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 958432, "time": 44388.77878284454, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 958992, "time": 44410.823006629944, "episode/length": 202.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 959129, "time": 44417.702360630035, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.769878680889423, "train/action_min": 0.0, "train/action_std": 3.5988403216942206, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.038356925132912355, "train/actor_opt_grad_steps": 59130.0, "train/actor_opt_loss": -2.8675321613054177, "train/adv_mag": 0.4495777731592005, "train/adv_max": 0.41218578169395875, "train/adv_mean": 0.0033104381594572653, "train/adv_min": -0.3644623432334486, "train/adv_std": 0.053348421685762336, "train/cont_avg": 0.9951445039335665, "train/cont_loss_mean": 0.00010564509190499098, "train/cont_loss_std": 0.003271242692996615, "train/cont_neg_acc": 0.996009390119096, "train/cont_neg_loss": 0.01097587218593207, "train/cont_pos_acc": 0.9999793951327984, "train/cont_pos_loss": 5.187803206761988e-05, "train/cont_pred": 0.9951428904400005, "train/cont_rate": 0.9951445039335665, "train/dyn_loss_mean": 13.604201050071449, "train/dyn_loss_std": 9.450164508152675, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9297288797952078, "train/extr_critic_critic_opt_grad_steps": 59130.0, "train/extr_critic_critic_opt_loss": 15743.379507211539, "train/extr_critic_mag": 8.895280784660287, "train/extr_critic_max": 8.895280784660287, "train/extr_critic_mean": 2.791125129152845, "train/extr_critic_min": -0.19629740631663717, "train/extr_critic_std": 2.0342630406359694, "train/extr_return_normed_mag": 1.4855903370397074, "train/extr_return_normed_max": 1.4855903370397074, "train/extr_return_normed_mean": 0.4150003959665765, "train/extr_return_normed_min": -0.09101485921447719, "train/extr_return_normed_std": 0.317306069748385, "train/extr_return_rate": 0.8332978670413678, "train/extr_return_raw_mag": 9.792974331995824, "train/extr_return_raw_max": 9.792974331995824, "train/extr_return_raw_mean": 2.8126275656106587, "train/extr_return_raw_min": -0.48588874300459883, "train/extr_return_raw_std": 2.06907988511599, "train/extr_reward_mag": 1.045272528708398, "train/extr_reward_max": 1.045272528708398, "train/extr_reward_mean": 0.046018155864798106, "train/extr_reward_min": -0.39369277603976377, "train/extr_reward_std": 0.20025867994848665, "train/image_loss_mean": 6.202733349966836, "train/image_loss_std": 11.570877578708675, "train/model_loss_mean": 14.422457461590534, "train/model_loss_std": 15.425160701458271, "train/model_opt_grad_norm": 54.11885041250309, "train/model_opt_grad_steps": 59075.41958041958, "train/model_opt_loss": 19086.50917149257, "train/model_opt_model_opt_grad_overflow": 0.006993006993006993, "train/model_opt_model_opt_grad_scale": 1319.93006993007, "train/policy_entropy_mag": 2.396199716554655, "train/policy_entropy_max": 2.396199716554655, "train/policy_entropy_mean": 0.47862914850661803, "train/policy_entropy_min": 0.07937501459480166, "train/policy_entropy_std": 0.5847039080999948, "train/policy_logprob_mag": 7.438383842681671, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.4798433397199724, "train/policy_logprob_min": -7.438383842681671, "train/policy_logprob_std": 1.049991666437029, "train/policy_randomness_mag": 0.845753345039341, "train/policy_randomness_max": 0.845753345039341, "train/policy_randomness_mean": 0.1689350867604876, "train/policy_randomness_min": 0.028015896925455207, "train/policy_randomness_std": 0.20637482102517482, "train/post_ent_mag": 60.551724387215565, "train/post_ent_max": 60.551724387215565, "train/post_ent_mean": 43.9565744733477, "train/post_ent_min": 20.585691171926218, "train/post_ent_std": 7.81907199312757, "train/prior_ent_mag": 70.77694472733077, "train/prior_ent_max": 70.77694472733077, "train/prior_ent_mean": 57.624706321662956, "train/prior_ent_min": 42.40378949358747, "train/prior_ent_std": 4.409834983465555, "train/rep_loss_mean": 13.604201050071449, "train/rep_loss_std": 9.450164508152675, "train/reward_avg": 0.03015461091238719, "train/reward_loss_mean": 0.05709802406234341, "train/reward_loss_std": 0.2494257607243278, "train/reward_max_data": 1.0258741320429983, "train/reward_max_pred": 1.0196914189345354, "train/reward_neg_acc": 0.992025085679301, "train/reward_neg_loss": 0.02926727876692385, "train/reward_pos_acc": 0.9703557212035973, "train/reward_pos_loss": 0.837961934663199, "train/reward_pred": 0.029583301212820972, "train/reward_rate": 0.034527972027972025, "train_stats/sum_log_reward": 9.2157896907706, "train_stats/max_log_achievement_collect_coal": 0.5157894736842106, "train_stats/max_log_achievement_collect_drink": 5.894736842105263, "train_stats/max_log_achievement_collect_sapling": 1.3263157894736841, "train_stats/max_log_achievement_collect_stone": 11.378947368421052, "train_stats/max_log_achievement_collect_wood": 11.821052631578947, "train_stats/max_log_achievement_defeat_skeleton": 0.042105263157894736, "train_stats/max_log_achievement_defeat_zombie": 0.7684210526315789, "train_stats/max_log_achievement_eat_cow": 0.23157894736842105, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.263157894736842, "train_stats/max_log_achievement_make_wood_sword": 1.6210526315789473, "train_stats/max_log_achievement_place_furnace": 0.010526315789473684, "train_stats/max_log_achievement_place_plant": 1.305263157894737, "train_stats/max_log_achievement_place_stone": 10.08421052631579, "train_stats/max_log_achievement_place_table": 3.4842105263157896, "train_stats/max_log_achievement_wake_up": 1.5157894736842106, "train_stats/mean_log_entropy": 0.5180158279444042, "eval_stats/sum_log_reward": 8.85000017285347, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 4.3125, "eval_stats/max_log_achievement_collect_sapling": 1.3125, "eval_stats/max_log_achievement_collect_stone": 5.5, "eval_stats/max_log_achievement_collect_wood": 11.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.4375, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 5.1875, "eval_stats/max_log_achievement_place_table": 3.0625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.326162527628185e-07, "report/cont_loss_std": 2.2890305899636587e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.1670350431813858e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.8815455266339995e-07, "report/cont_pred": 0.9960936307907104, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.823921203613281, "report/dyn_loss_std": 9.17556381225586, "report/image_loss_mean": 5.875585079193115, "report/image_loss_std": 8.96481990814209, "report/model_loss_mean": 13.62591552734375, "report/model_loss_std": 12.679305076599121, "report/post_ent_mag": 59.84648895263672, "report/post_ent_max": 59.84648895263672, "report/post_ent_mean": 44.694122314453125, "report/post_ent_min": 22.54456329345703, "report/post_ent_std": 7.821962356567383, "report/prior_ent_mag": 70.87531280517578, "report/prior_ent_max": 70.87531280517578, "report/prior_ent_mean": 57.89992904663086, "report/prior_ent_min": 46.183311462402344, "report/prior_ent_std": 4.169709205627441, "report/rep_loss_mean": 12.823921203613281, "report/rep_loss_std": 9.17556381225586, "report/reward_avg": 0.02949218824505806, "report/reward_loss_mean": 0.055978983640670776, "report/reward_loss_std": 0.2366901934146881, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001251220703125, "report/reward_neg_acc": 0.9909090399742126, "report/reward_neg_loss": 0.032339997589588165, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7442904710769653, "report/reward_pred": 0.03035612404346466, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.864321402284986e-07, "eval/cont_loss_std": 1.4902221892043599e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.069944028131431e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.455968228787242e-07, "eval/cont_pred": 0.9960936903953552, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.254037857055664, "eval/dyn_loss_std": 10.742656707763672, "eval/image_loss_mean": 8.110831260681152, "eval/image_loss_std": 9.742903709411621, "eval/model_loss_mean": 18.557575225830078, "eval/model_loss_std": 13.624770164489746, "eval/post_ent_mag": 61.87959671020508, "eval/post_ent_max": 61.87959671020508, "eval/post_ent_mean": 43.10845947265625, "eval/post_ent_min": 19.848663330078125, "eval/post_ent_std": 8.37396240234375, "eval/prior_ent_mag": 70.87531280517578, "eval/prior_ent_max": 70.87531280517578, "eval/prior_ent_mean": 58.677337646484375, "eval/prior_ent_min": 43.17961120605469, "eval/prior_ent_std": 3.782870054244995, "eval/rep_loss_mean": 17.254037857055664, "eval/rep_loss_std": 10.742656707763672, "eval/reward_avg": 0.04355468600988388, "eval/reward_loss_mean": 0.09432299435138702, "eval/reward_loss_std": 0.46736934781074524, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016345977783203, "eval/reward_neg_acc": 0.9887179136276245, "eval/reward_neg_loss": 0.043653689324855804, "eval/reward_pos_acc": 0.918367326259613, "eval/reward_pos_loss": 1.1025385856628418, "eval/reward_pred": 0.041798435151576996, "eval/reward_rate": 0.0478515625, "replay/size": 958625.0, "replay/inserts": 22896.0, "replay/samples": 22896.0, "replay/insert_wait_avg": 1.3380951184979857e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.44482439202416e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2357104645084272e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2937042713165, "timer/env.step_count": 2862.0, "timer/env.step_total": 233.1519696712494, "timer/env.step_frac": 0.2330835120481874, "timer/env.step_avg": 0.08146469939596415, "timer/env.step_min": 0.023716449737548828, "timer/env.step_max": 3.4754040241241455, "timer/replay._sample_count": 22896.0, "timer/replay._sample_total": 11.792096138000488, "timer/replay._sample_frac": 0.011788633765910455, "timer/replay._sample_avg": 0.0005150286573200772, "timer/replay._sample_min": 0.00042319297790527344, "timer/replay._sample_max": 0.011077404022216797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3356.0, "timer/agent.policy_total": 58.025922536849976, "timer/agent.policy_frac": 0.05800888507952781, "timer/agent.policy_avg": 0.017290203378084023, "timer/agent.policy_min": 0.009542703628540039, "timer/agent.policy_max": 0.1788768768310547, "timer/dataset_train_count": 1431.0, "timer/dataset_train_total": 0.1607205867767334, "timer/dataset_train_frac": 0.00016067339631394906, "timer/dataset_train_avg": 0.0001123134778314, "timer/dataset_train_min": 9.822845458984375e-05, "timer/dataset_train_max": 0.0005409717559814453, "timer/agent.train_count": 1431.0, "timer/agent.train_total": 641.2276182174683, "timer/agent.train_frac": 0.6410393422245749, "timer/agent.train_avg": 0.4480975668885173, "timer/agent.train_min": 0.43337583541870117, "timer/agent.train_max": 1.6439573764801025, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4827890396118164, "timer/agent.report_frac": 0.00048264728404295366, "timer/agent.report_avg": 0.2413945198059082, "timer/agent.report_min": 0.23337697982788086, "timer/agent.report_max": 0.24941205978393555, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7648434712411e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.888945564180606}
{"step": 959288, "time": 44422.87911391258, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 959608, "time": 44435.19304728508, "episode/length": 259.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 959936, "time": 44448.231243133545, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 44468.04624199867, "eval_episode/length": 53.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 960024, "time": 44474.24564027786, "eval_episode/length": 154.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 960024, "time": 44476.315189123154, "eval_episode/length": 166.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 960024, "time": 44478.70016622543, "eval_episode/length": 186.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 960024, "time": 44480.628994226456, "eval_episode/length": 192.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9585492227979274}
{"step": 960024, "time": 44482.79531478882, "eval_episode/length": 206.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 960024, "time": 44484.48156452179, "eval_episode/length": 207.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 960024, "time": 44486.556403160095, "eval_episode/length": 165.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 960040, "time": 44487.1005051136, "episode/length": 390.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9948849104859335, "episode/intrinsic_return": 0.0}
{"step": 960192, "time": 44494.04831933975, "episode/length": 221.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 960384, "time": 44502.15948677063, "episode/length": 173.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 960408, "time": 44504.28030085564, "episode/length": 374.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9893333333333333, "episode/intrinsic_return": 0.0}
{"step": 960688, "time": 44515.24092292786, "episode/length": 93.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 960848, "time": 44522.118893146515, "episode/length": 410.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 961328, "time": 44539.89158463478, "episode/length": 214.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 961664, "time": 44553.05076050758, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 961848, "time": 44561.364995241165, "episode/length": 319.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 962144, "time": 44573.14704966545, "episode/length": 181.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 962216, "time": 44576.96578359604, "episode/length": 170.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 962272, "time": 44580.668031454086, "episode/length": 235.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 962632, "time": 44594.22222185135, "episode/length": 323.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 962712, "time": 44598.61763000488, "episode/length": 54.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 963000, "time": 44609.80759882927, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9665071770334929, "episode/intrinsic_return": 0.0}
{"step": 963368, "time": 44623.82754158974, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 963552, "time": 44631.79719853401, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 963704, "time": 44638.30489420891, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 963936, "time": 44648.439482450485, "episode/length": 47.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 964016, "time": 44652.92588829994, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 964368, "time": 44666.40130496025, "episode/length": 277.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 964600, "time": 44675.46933698654, "episode/length": 245.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 965040, "time": 44692.21541762352, "episode/length": 352.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9915014164305949, "episode/intrinsic_return": 0.0}
{"step": 965688, "time": 44715.87163710594, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 965776, "time": 44720.53909420967, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 965856, "time": 44724.770960092545, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 966376, "time": 44743.509544849396, "episode/length": 333.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 966576, "time": 44751.954947948456, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 966592, "time": 44754.06529593468, "episode/length": 448.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9955456570155902, "episode/intrinsic_return": 0.0}
{"step": 966648, "time": 44757.30036044121, "episode/length": 108.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 966968, "time": 44771.4171359539, "episode/length": 449.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 967056, "time": 44776.12148785591, "episode/length": 50.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 967072, "time": 44778.28216791153, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 968024, "time": 44811.494314432144, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 968232, "time": 44820.1461417675, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 968272, "time": 44823.36244392395, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 968456, "time": 44830.95226025581, "episode/length": 174.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 968584, "time": 44836.91346144676, "episode/length": 188.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 969040, "time": 44853.95915412903, "episode/length": 397.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 969808, "time": 44881.121049165726, "episode/length": 403.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925742574257426, "episode/intrinsic_return": 0.0}
{"step": 969984, "time": 44888.59567117691, "episode/length": 190.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 969992, "time": 44890.37302303314, "episode/length": 219.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 44909.63417553902, "eval_episode/length": 88.0, "eval_episode/score": 6.100000023841858, "eval_episode/reward_rate": 0.9887640449438202}
{"step": 970008, "time": 44914.89592766762, "eval_episode/length": 168.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 970008, "time": 44918.580411195755, "eval_episode/length": 210.0, "eval_episode/score": 11.100000031292439, "eval_episode/reward_rate": 0.990521327014218}
{"step": 970008, "time": 44920.91704916954, "eval_episode/length": 221.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9774774774774775}
{"step": 970008, "time": 44923.31109547615, "eval_episode/length": 236.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 970008, "time": 44926.62339639664, "eval_episode/length": 187.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9680851063829787}
{"step": 970008, "time": 44929.680119752884, "eval_episode/length": 310.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9967845659163987}
{"step": 970008, "time": 44933.02873110771, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 970072, "time": 44935.21744847298, "episode/length": 255.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 970184, "time": 44940.507103443146, "episode/length": 401.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900497512437811, "episode/intrinsic_return": 0.0}
{"step": 970320, "time": 44946.80698299408, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 970472, "time": 44953.400223731995, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 971032, "time": 44973.690727710724, "episode/length": 305.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 971184, "time": 44980.804384708405, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 971392, "time": 44989.36728477478, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974358974358974, "episode/intrinsic_return": 0.0}
{"step": 971808, "time": 45004.9422519207, "episode/length": 216.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 971816, "time": 45006.58103466034, "episode/length": 167.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 971816, "time": 45006.59075808525, "episode/length": 227.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 972656, "time": 45038.302966594696, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 972656, "time": 45038.31233930588, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 973136, "time": 45058.09119844437, "episode/length": 351.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 973272, "time": 45064.00018310547, "episode/length": 234.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 973640, "time": 45077.918756484985, "episode/length": 431.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 973904, "time": 45089.0297703743, "episode/length": 260.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 974128, "time": 45097.98644042015, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 974208, "time": 45102.407767772675, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979933110367893, "episode/intrinsic_return": 0.0}
{"step": 974632, "time": 45117.98203206062, "episode/length": 352.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 974968, "time": 45132.68185210228, "episode/length": 41.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 975424, "time": 45149.82898187637, "episode/length": 151.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 975536, "time": 45155.25593042374, "episode/length": 236.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 975696, "time": 45162.247515678406, "episode/length": 319.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996875, "episode/intrinsic_return": 0.0}
{"step": 975800, "time": 45167.078292131424, "episode/length": 315.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9841772151898734, "episode/intrinsic_return": 0.0}
{"step": 975808, "time": 45169.179805755615, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 976312, "time": 45187.464933395386, "episode/length": 167.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 976896, "time": 45208.79329752922, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 976976, "time": 45213.17475557327, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 977152, "time": 45220.84922623634, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 977208, "time": 45224.11965584755, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 977752, "time": 45244.09601354599, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 977848, "time": 45248.9051194191, "episode/length": 648.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9861325115562404, "episode/intrinsic_return": 0.0}
{"step": 978080, "time": 45258.61808896065, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 978560, "time": 45276.23274254799, "episode/length": 581.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 978896, "time": 45289.21205353737, "episode/length": 217.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 979016, "time": 45294.60737013817, "episode/length": 254.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 979440, "time": 45310.71982383728, "episode/length": 278.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 979736, "time": 45321.84543347359, "episode/length": 354.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9887323943661972, "episode/intrinsic_return": 0.0}
{"step": 979824, "time": 45326.50418782234, "episode/length": 246.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 979856, "time": 45329.09650158882, "episode/length": 221.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 45360.04570746422, "eval_episode/length": 176.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 980096, "time": 45361.676742076874, "eval_episode/length": 177.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 980096, "time": 45364.815618515015, "eval_episode/length": 210.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 980096, "time": 45367.03728079796, "eval_episode/length": 213.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 980096, "time": 45370.255653619766, "eval_episode/length": 233.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 980096, "time": 45372.179913043976, "eval_episode/length": 234.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9957446808510638}
{"step": 980096, "time": 45376.094696998596, "eval_episode/length": 273.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9963503649635036}
{"step": 980096, "time": 45381.86522555351, "eval_episode/length": 192.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 980216, "time": 45385.668496608734, "episode/length": 44.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 980336, "time": 45391.70057582855, "episode/length": 179.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 980608, "time": 45402.587492227554, "episode/length": 356.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859943977591037, "episode/intrinsic_return": 0.0}
{"step": 980616, "time": 45404.298046827316, "episode/length": 256.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 980776, "time": 45411.20136594772, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 980905, "time": 45418.06986737251, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.628975304373859, "train/action_min": 0.0, "train/action_std": 3.469692891531617, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03751209734456382, "train/actor_opt_grad_steps": 60530.0, "train/actor_opt_loss": -3.9264796732986063, "train/adv_mag": 0.4668096832550355, "train/adv_max": 0.40739303827285767, "train/adv_mean": 0.0031306662082505993, "train/adv_min": -0.3843957125923059, "train/adv_std": 0.052028265203872735, "train/cont_avg": 0.9952953923357665, "train/cont_loss_mean": 0.0001919601469572306, "train/cont_loss_std": 0.005632469256202588, "train/cont_neg_acc": 0.9980448388705289, "train/cont_neg_loss": 0.00815390570793223, "train/cont_pos_acc": 0.9999426794748236, "train/cont_pos_loss": 0.0001430666914404976, "train/cont_pred": 0.9952452491669759, "train/cont_rate": 0.9952953923357665, "train/dyn_loss_mean": 13.532493006573976, "train/dyn_loss_std": 9.40472255484031, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9712543117738989, "train/extr_critic_critic_opt_grad_steps": 60530.0, "train/extr_critic_critic_opt_loss": 15769.101277372263, "train/extr_critic_mag": 9.159953486310304, "train/extr_critic_max": 9.159953486310304, "train/extr_critic_mean": 2.797985659898633, "train/extr_critic_min": -0.2153003241894019, "train/extr_critic_std": 2.10425786206322, "train/extr_return_normed_mag": 1.467900046466911, "train/extr_return_normed_max": 1.467900046466911, "train/extr_return_normed_mean": 0.4030158078148417, "train/extr_return_normed_min": -0.08937450710439333, "train/extr_return_normed_std": 0.31638651226993897, "train/extr_return_rate": 0.8250836817017437, "train/extr_return_raw_mag": 10.013142871160577, "train/extr_return_raw_max": 10.013142871160577, "train/extr_return_raw_mean": 2.8191497647849313, "train/extr_return_raw_min": -0.5080296803999992, "train/extr_return_raw_std": 2.1377994874968147, "train/extr_reward_mag": 1.0449763545154656, "train/extr_reward_max": 1.0449763545154656, "train/extr_reward_mean": 0.04749570495999642, "train/extr_reward_min": -0.411838616767939, "train/extr_reward_std": 0.2034967722248857, "train/image_loss_mean": 6.396200963180431, "train/image_loss_std": 11.580737072185878, "train/model_loss_mean": 14.57302791706837, "train/model_loss_std": 15.41211702527791, "train/model_opt_grad_norm": 50.57739665734507, "train/model_opt_grad_steps": 60474.07299270073, "train/model_opt_loss": 18909.218593179743, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1304.7445255474452, "train/policy_entropy_mag": 2.485404670673565, "train/policy_entropy_max": 2.485404670673565, "train/policy_entropy_mean": 0.4999815789017364, "train/policy_entropy_min": 0.0793750150142795, "train/policy_entropy_std": 0.6020429950125896, "train/policy_logprob_mag": 7.438383822893575, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5001701649523129, "train/policy_logprob_min": -7.438383822893575, "train/policy_logprob_std": 1.0643142848989389, "train/policy_randomness_mag": 0.8772387774321284, "train/policy_randomness_max": 0.8772387774321284, "train/policy_randomness_mean": 0.17647155716906499, "train/policy_randomness_min": 0.028015897099445335, "train/policy_randomness_std": 0.21249475716239344, "train/post_ent_mag": 60.784546343949586, "train/post_ent_max": 60.784546343949586, "train/post_ent_mean": 44.0097556288225, "train/post_ent_min": 20.81178431267286, "train/post_ent_std": 7.819378108003714, "train/prior_ent_mag": 70.69470003225507, "train/prior_ent_max": 70.69470003225507, "train/prior_ent_mean": 57.61107810918432, "train/prior_ent_min": 42.167440790329536, "train/prior_ent_std": 4.458863190490834, "train/rep_loss_mean": 13.532493006573976, "train/rep_loss_std": 9.40472255484031, "train/reward_avg": 0.0302356576723774, "train/reward_loss_mean": 0.057139354193732686, "train/reward_loss_std": 0.24921802654318567, "train/reward_max_data": 1.0233576698024778, "train/reward_max_pred": 1.0163108684720785, "train/reward_neg_acc": 0.9921207706423572, "train/reward_neg_loss": 0.029467284815372342, "train/reward_pos_acc": 0.9694501105016166, "train/reward_pos_loss": 0.8380876105197155, "train/reward_pred": 0.029473107056624263, "train/reward_rate": 0.03452896897810219, "train_stats/sum_log_reward": 8.911111303170522, "train_stats/max_log_achievement_collect_coal": 0.4111111111111111, "train_stats/max_log_achievement_collect_drink": 5.655555555555556, "train_stats/max_log_achievement_collect_sapling": 1.2555555555555555, "train_stats/max_log_achievement_collect_stone": 10.188888888888888, "train_stats/max_log_achievement_collect_wood": 12.2, "train_stats/max_log_achievement_defeat_skeleton": 0.08888888888888889, "train_stats/max_log_achievement_defeat_zombie": 0.9222222222222223, "train_stats/max_log_achievement_eat_cow": 0.08888888888888889, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.011111111111111112, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5444444444444445, "train_stats/max_log_achievement_make_wood_sword": 1.5222222222222221, "train_stats/max_log_achievement_place_furnace": 0.022222222222222223, "train_stats/max_log_achievement_place_plant": 1.2, "train_stats/max_log_achievement_place_stone": 9.155555555555555, "train_stats/max_log_achievement_place_table": 3.6222222222222222, "train_stats/max_log_achievement_wake_up": 1.7, "train_stats/mean_log_entropy": 0.5312237858772277, "eval_stats/sum_log_reward": 9.30833355585734, "eval_stats/max_log_achievement_collect_coal": 0.5833333333333334, "eval_stats/max_log_achievement_collect_drink": 3.9166666666666665, "eval_stats/max_log_achievement_collect_sapling": 1.5416666666666667, "eval_stats/max_log_achievement_collect_stone": 6.416666666666667, "eval_stats/max_log_achievement_collect_wood": 10.583333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.2083333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 5.583333333333333, "eval_stats/max_log_achievement_place_table": 3.0416666666666665, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0008444626000709832, "report/cont_loss_std": 0.02647119201719761, "report/cont_neg_acc": 0.875, "report/cont_neg_loss": 0.10611375421285629, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.557075302116573e-05, "report/cont_pred": 0.9927317500114441, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 11.460636138916016, "report/dyn_loss_std": 9.276525497436523, "report/image_loss_mean": 6.132689476013184, "report/image_loss_std": 7.857072830200195, "report/model_loss_mean": 13.084628105163574, "report/model_loss_std": 11.714205741882324, "report/post_ent_mag": 60.686851501464844, "report/post_ent_max": 60.686851501464844, "report/post_ent_mean": 45.686981201171875, "report/post_ent_min": 18.243074417114258, "report/post_ent_std": 8.062515258789062, "report/prior_ent_mag": 70.47305297851562, "report/prior_ent_max": 70.47305297851562, "report/prior_ent_mean": 57.580467224121094, "report/prior_ent_min": 42.176937103271484, "report/prior_ent_std": 4.106549263000488, "report/rep_loss_mean": 11.460636138916016, "report/rep_loss_std": 9.276525497436523, "report/reward_avg": 0.03642578423023224, "report/reward_loss_mean": 0.07471150159835815, "report/reward_loss_std": 0.2797587215900421, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0065295696258545, "report/reward_neg_acc": 0.9989795684814453, "report/reward_neg_loss": 0.04543853923678398, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7267002463340759, "report/reward_pred": 0.036407746374607086, "report/reward_rate": 0.04296875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 4.8534595407545567e-05, "eval/cont_loss_std": 0.0012881122529506683, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.009174548089504242, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.755330908461474e-06, "eval/cont_pred": 0.9951574802398682, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.21993637084961, "eval/dyn_loss_std": 10.251605033874512, "eval/image_loss_mean": 10.645740509033203, "eval/image_loss_std": 15.836076736450195, "eval/model_loss_mean": 21.73288345336914, "eval/model_loss_std": 19.258296966552734, "eval/post_ent_mag": 61.25408172607422, "eval/post_ent_max": 61.25408172607422, "eval/post_ent_mean": 42.35732650756836, "eval/post_ent_min": 20.391326904296875, "eval/post_ent_std": 7.8697614669799805, "eval/prior_ent_mag": 70.47305297851562, "eval/prior_ent_max": 70.47305297851562, "eval/prior_ent_mean": 58.599525451660156, "eval/prior_ent_min": 40.278133392333984, "eval/prior_ent_std": 4.001126766204834, "eval/rep_loss_mean": 18.21993637084961, "eval/rep_loss_std": 10.251605033874512, "eval/reward_avg": 0.03955078125, "eval/reward_loss_mean": 0.155133455991745, "eval/reward_loss_std": 0.759816586971283, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047481060028076, "eval/reward_neg_acc": 0.9846625328063965, "eval/reward_neg_loss": 0.10049542039632797, "eval/reward_pos_acc": 0.9130434989929199, "eval/reward_pos_loss": 1.316785216331482, "eval/reward_pred": 0.04397878795862198, "eval/reward_rate": 0.044921875, "replay/size": 980401.0, "replay/inserts": 21776.0, "replay/samples": 21776.0, "replay/insert_wait_avg": 1.3258639369967402e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.094529339007645e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7528.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.182369927417459e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.3560056686401367e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3479635715485, "timer/env.step_count": 2722.0, "timer/env.step_total": 222.81552076339722, "timer/env.step_frac": 0.2227380160478136, "timer/env.step_avg": 0.08185728169118194, "timer/env.step_min": 0.023925065994262695, "timer/env.step_max": 3.6874215602874756, "timer/replay._sample_count": 21776.0, "timer/replay._sample_total": 11.326311111450195, "timer/replay._sample_frac": 0.01132237133868079, "timer/replay._sample_avg": 0.0005201281737440391, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.02850508689880371, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3663.0, "timer/agent.policy_total": 61.3115029335022, "timer/agent.policy_frac": 0.061290176184896066, "timer/agent.policy_avg": 0.01673805703890314, "timer/agent.policy_min": 0.009492874145507812, "timer/agent.policy_max": 0.09673738479614258, "timer/dataset_train_count": 1361.0, "timer/dataset_train_total": 0.15387201309204102, "timer/dataset_train_frac": 0.00015381848986093882, "timer/dataset_train_avg": 0.0001130580551741668, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0009007453918457031, "timer/agent.train_count": 1361.0, "timer/agent.train_total": 609.1340534687042, "timer/agent.train_frac": 0.6089221707353801, "timer/agent.train_avg": 0.4475635954950068, "timer/agent.train_min": 0.4344611167907715, "timer/agent.train_max": 1.6991374492645264, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48053956031799316, "timer/agent.report_frac": 0.00048037240821915587, "timer/agent.report_avg": 0.24026978015899658, "timer/agent.report_min": 0.23314332962036133, "timer/agent.report_max": 0.24739623069763184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.123283386230469e-05, "timer/dataset_eval_frac": 3.1221969754198235e-08, "timer/dataset_eval_avg": 3.123283386230469e-05, "timer/dataset_eval_min": 3.123283386230469e-05, "timer/dataset_eval_max": 3.123283386230469e-05, "fps": 21.76810702260328}
{"step": 981104, "time": 45424.99239754677, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 981344, "time": 45435.17316484451, "episode/length": 200.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 981536, "time": 45443.25041627884, "episode/length": 94.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9894736842105263, "episode/intrinsic_return": 0.0}
{"step": 981824, "time": 45454.47212982178, "episode/length": 151.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 981920, "time": 45459.22870540619, "episode/length": 197.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 982432, "time": 45477.87979769707, "episode/length": 276.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9855595667870036, "episode/intrinsic_return": 0.0}
{"step": 982552, "time": 45483.28301215172, "episode/length": 180.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 982600, "time": 45486.39898490906, "episode/length": 346.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 982608, "time": 45488.63926243782, "episode/length": 133.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 982880, "time": 45499.45767664909, "episode/length": 191.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 982936, "time": 45502.756533145905, "episode/length": 289.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 983160, "time": 45513.65404367447, "episode/length": 166.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 983536, "time": 45528.07542157173, "episode/length": 81.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 983728, "time": 45536.074467897415, "episode/length": 225.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 984080, "time": 45549.30669426918, "episode/length": 183.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 984616, "time": 45568.83027100563, "episode/length": 257.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 984672, "time": 45572.50345158577, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691119691119691, "episode/intrinsic_return": 0.0}
{"step": 984912, "time": 45582.21161055565, "episode/length": 309.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 984984, "time": 45586.04937505722, "episode/length": 255.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 985032, "time": 45589.23346400261, "episode/length": 44.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 985248, "time": 45598.378088235855, "episode/length": 189.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 985304, "time": 45601.59008979797, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 985856, "time": 45621.77565860748, "episode/length": 221.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 985944, "time": 45626.07797026634, "episode/length": 347.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 986576, "time": 45649.1466281414, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 986832, "time": 45659.48877930641, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 986912, "time": 45663.705654621124, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 987056, "time": 45670.21831917763, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 987464, "time": 45685.15824151039, "episode/length": 50.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 987528, "time": 45688.79194736481, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 987560, "time": 45691.37314391136, "episode/length": 367.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9972826086956522, "episode/intrinsic_return": 0.0}
{"step": 987744, "time": 45699.29745197296, "episode/length": 353.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 988088, "time": 45712.29010057449, "episode/length": 188.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 988288, "time": 45720.69167160988, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 989048, "time": 45747.56317734718, "episode/length": 387.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9871134020618557, "episode/intrinsic_return": 0.0}
{"step": 989216, "time": 45754.90254354477, "episode/length": 218.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 989232, "time": 45757.08994984627, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 989240, "time": 45758.82264113426, "episode/length": 213.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 989984, "time": 45785.647198200226, "episode/length": 279.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 45813.48488497734, "eval_episode/length": 161.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 990080, "time": 45816.11505031586, "eval_episode/length": 181.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 990080, "time": 45816.12404584885, "eval_episode/length": 181.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 990080, "time": 45821.49603056908, "eval_episode/length": 223.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 990080, "time": 45823.379419088364, "eval_episode/length": 232.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 990080, "time": 45825.26823735237, "eval_episode/length": 238.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9832635983263598}
{"step": 990080, "time": 45833.10773563385, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 990080, "time": 45835.681772232056, "eval_episode/length": 224.0, "eval_episode/score": 10.100000016391277, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 990320, "time": 45843.66096448898, "episode/length": 253.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 990560, "time": 45853.425595760345, "episode/length": 188.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 990680, "time": 45859.62621188164, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 991032, "time": 45872.97539496422, "episode/length": 524.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9980952380952381, "episode/intrinsic_return": 0.0}
{"step": 991480, "time": 45891.39643406868, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 991520, "time": 45894.45746135712, "episode/length": 428.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 991880, "time": 45907.929600954056, "episode/length": 329.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 992272, "time": 45923.37566781044, "episode/length": 381.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 992328, "time": 45926.716584682465, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 992760, "time": 45942.76307177544, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 992832, "time": 45947.000323057175, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 993144, "time": 45958.684908390045, "episode/length": 322.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9876160990712074, "episode/intrinsic_return": 0.0}
{"step": 993280, "time": 45964.97114300728, "episode/length": 64.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9384615384615385, "episode/intrinsic_return": 0.0}
{"step": 993392, "time": 45970.52592730522, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 993616, "time": 45979.43833374977, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 994176, "time": 45999.84635877609, "episode/length": 128.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689922480620154, "episode/intrinsic_return": 0.0}
{"step": 994280, "time": 46004.79603075981, "episode/length": 243.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 994544, "time": 46015.9418053627, "episode/length": 438.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977220956719818, "episode/intrinsic_return": 0.0}
{"step": 994792, "time": 46025.5429854393, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 994856, "time": 46029.35498690605, "episode/length": 421.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786729857819905, "episode/intrinsic_return": 0.0}
{"step": 995000, "time": 46035.95075106621, "episode/length": 56.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 995032, "time": 46038.61611223221, "episode/length": 218.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 995296, "time": 46049.10245347023, "episode/length": 36.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 995344, "time": 46052.23764562607, "episode/length": 313.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 995824, "time": 46070.17964911461, "episode/length": 205.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 996096, "time": 46080.856701374054, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 996096, "time": 46080.866710186005, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 996552, "time": 46099.47490262985, "episode/length": 56.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 996624, "time": 46103.87720274925, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 996704, "time": 46108.07283473015, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 997000, "time": 46119.38536262512, "episode/length": 206.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 997336, "time": 46132.3073015213, "episode/length": 317.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 997440, "time": 46137.55538249016, "episode/length": 267.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 997512, "time": 46141.358842134476, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9548022598870056, "episode/intrinsic_return": 0.0}
{"step": 997544, "time": 46143.95797896385, "episode/length": 214.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 998208, "time": 46170.27636504173, "episode/length": 187.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 998600, "time": 46184.9389424324, "episode/length": 246.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 998648, "time": 46188.19013881683, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 999016, "time": 46202.124561309814, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 999192, "time": 46209.8529920578, "episode/length": 273.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 999776, "time": 46233.68852972984, "episode/length": 146.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 46260.62228131294, "eval_episode/length": 59.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 1000064, "time": 46262.36499261856, "eval_episode/length": 63.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9375}
{"step": 1000064, "time": 46267.523669958115, "eval_episode/length": 146.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9727891156462585}
{"step": 1000064, "time": 46270.491127729416, "eval_episode/length": 175.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1000064, "time": 46272.224905729294, "eval_episode/length": 180.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 1000064, "time": 46274.927035570145, "eval_episode/length": 205.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 1000064, "time": 46278.18456697464, "eval_episode/length": 184.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 1000064, "time": 46284.79933190346, "eval_episode/length": 276.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9891696750902527}
{"step": 1000080, "time": 46285.34402990341, "episode/length": 329.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 1000656, "time": 46306.17412209511, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 1000736, "time": 46310.29787015915, "episode/length": 260.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 1000960, "time": 46319.34577918053, "episode/length": 452.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9977924944812362, "episode/intrinsic_return": 0.0}
{"step": 1000992, "time": 46322.0333135128, "episode/length": 246.0, "episode/score": 12.1000000461936, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 1001296, "time": 46333.98760652542, "episode/length": 385.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974093264248705, "episode/intrinsic_return": 0.0}
{"step": 1001800, "time": 46352.24186348915, "episode/length": 214.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 1002176, "time": 46366.73189496994, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 1002400, "time": 46375.92659449577, "episode/length": 175.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 1002992, "time": 46397.64375114441, "episode/length": 401.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9975124378109452, "episode/intrinsic_return": 0.0}
{"step": 1003240, "time": 46407.3630194664, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9555555555555556, "episode/intrinsic_return": 0.0}
{"step": 1003304, "time": 46411.1451458931, "episode/length": 843.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 1003449, "time": 46418.58253955841, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.511163766043527, "train/action_min": 0.0, "train/action_std": 3.4018504210880827, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03712556859744447, "train/actor_opt_grad_steps": 61915.0, "train/actor_opt_loss": -6.0938225392983965, "train/adv_mag": 0.48495946058205197, "train/adv_max": 0.41189052079405103, "train/adv_mean": 0.0028586646485369523, "train/adv_min": -0.40807970549379075, "train/adv_std": 0.05190326584769147, "train/cont_avg": 0.9950892857142857, "train/cont_loss_mean": 0.00014017492528982497, "train/cont_loss_std": 0.003978107118964707, "train/cont_neg_acc": 0.9946859906549039, "train/cont_neg_loss": 0.015248609261581569, "train/cont_pos_acc": 0.9999789680753436, "train/cont_pos_loss": 7.655491931107658e-05, "train/cont_pred": 0.9950902032000678, "train/cont_rate": 0.9950892857142857, "train/dyn_loss_mean": 13.26131695338658, "train/dyn_loss_std": 9.351879562650408, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9431949113096509, "train/extr_critic_critic_opt_grad_steps": 61915.0, "train/extr_critic_critic_opt_loss": 15777.722781808036, "train/extr_critic_mag": 9.248761187280927, "train/extr_critic_max": 9.248761187280927, "train/extr_critic_mean": 2.9200059516089305, "train/extr_critic_min": -0.19537099174090794, "train/extr_critic_std": 2.1807539275714327, "train/extr_return_normed_mag": 1.4678879507950373, "train/extr_return_normed_max": 1.4678879507950373, "train/extr_return_normed_mean": 0.4161394274660519, "train/extr_return_normed_min": -0.08306566255965403, "train/extr_return_normed_std": 0.3209822780319623, "train/extr_return_rate": 0.8285779838051115, "train/extr_return_raw_mag": 10.195199813161578, "train/extr_return_raw_max": 10.195199813161578, "train/extr_return_raw_mean": 2.9397622695990973, "train/extr_return_raw_min": -0.5035292958574635, "train/extr_return_raw_std": 2.214239306109292, "train/extr_reward_mag": 1.0418595961162023, "train/extr_reward_max": 1.0418595961162023, "train/extr_reward_mean": 0.049028641863593035, "train/extr_reward_min": -0.41928718175206864, "train/extr_reward_std": 0.20745535886713437, "train/image_loss_mean": 6.04378514119557, "train/image_loss_std": 11.227473163604737, "train/model_loss_mean": 14.057027571541923, "train/model_loss_std": 15.027520833696638, "train/model_opt_grad_norm": 51.410923440115795, "train/model_opt_grad_steps": 61857.62857142857, "train/model_opt_loss": 17724.991203962054, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9285714285713, "train/policy_entropy_mag": 2.503320666721889, "train/policy_entropy_max": 2.503320666721889, "train/policy_entropy_mean": 0.4806298745529992, "train/policy_entropy_min": 0.07937501498631068, "train/policy_entropy_std": 0.6014919902597154, "train/policy_logprob_mag": 7.438383868762425, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.48001853057316374, "train/policy_logprob_min": -7.438383868762425, "train/policy_logprob_std": 1.0529346440519605, "train/policy_randomness_mag": 0.8835623387779509, "train/policy_randomness_max": 0.8835623387779509, "train/policy_randomness_mean": 0.16964125580021314, "train/policy_randomness_min": 0.028015897077109133, "train/policy_randomness_std": 0.21230027803352902, "train/post_ent_mag": 60.81955212184361, "train/post_ent_max": 60.81955212184361, "train/post_ent_mean": 44.25359390803746, "train/post_ent_min": 20.394105311802456, "train/post_ent_std": 7.867677191325597, "train/prior_ent_mag": 70.82544108799526, "train/prior_ent_max": 70.82544108799526, "train/prior_ent_mean": 57.61325127737863, "train/prior_ent_min": 42.3002171925136, "train/prior_ent_std": 4.379906942163195, "train/rep_loss_mean": 13.26131695338658, "train/rep_loss_std": 9.351879562650408, "train/reward_avg": 0.02960309694255037, "train/reward_loss_mean": 0.05631222685000726, "train/reward_loss_std": 0.24221172024096763, "train/reward_max_data": 1.0185714329992022, "train/reward_max_pred": 1.0121392735413142, "train/reward_neg_acc": 0.9921045303344727, "train/reward_neg_loss": 0.02983986229103591, "train/reward_pos_acc": 0.9778280858482633, "train/reward_pos_loss": 0.8081832570689065, "train/reward_pred": 0.02915755471081606, "train/reward_rate": 0.03408203125, "train_stats/sum_log_reward": 9.284782820259748, "train_stats/max_log_achievement_collect_coal": 0.43478260869565216, "train_stats/max_log_achievement_collect_drink": 6.934782608695652, "train_stats/max_log_achievement_collect_sapling": 1.2717391304347827, "train_stats/max_log_achievement_collect_stone": 10.478260869565217, "train_stats/max_log_achievement_collect_wood": 11.98913043478261, "train_stats/max_log_achievement_defeat_skeleton": 0.06521739130434782, "train_stats/max_log_achievement_defeat_zombie": 0.8478260869565217, "train_stats/max_log_achievement_eat_cow": 0.25, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7065217391304348, "train_stats/max_log_achievement_make_wood_sword": 1.4021739130434783, "train_stats/max_log_achievement_place_furnace": 0.021739130434782608, "train_stats/max_log_achievement_place_plant": 1.2608695652173914, "train_stats/max_log_achievement_place_stone": 9.195652173913043, "train_stats/max_log_achievement_place_table": 3.619565217391304, "train_stats/max_log_achievement_wake_up": 1.358695652173913, "train_stats/mean_log_entropy": 0.5167489064776379, "eval_stats/sum_log_reward": 9.037500262260437, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 9.375, "eval_stats/max_log_achievement_collect_wood": 12.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.625, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 8.25, "eval_stats/max_log_achievement_place_table": 3.4375, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 4.573762998916209e-05, "report/cont_loss_std": 0.0012371522607281804, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014112457574810833, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.526958946371451e-05, "report/cont_pred": 0.9950735569000244, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.788137435913086, "report/dyn_loss_std": 9.386130332946777, "report/image_loss_mean": 6.952035903930664, "report/image_loss_std": 10.533254623413086, "report/model_loss_mean": 15.287452697753906, "report/model_loss_std": 14.603291511535645, "report/post_ent_mag": 61.312721252441406, "report/post_ent_max": 61.312721252441406, "report/post_ent_mean": 44.4802360534668, "report/post_ent_min": 20.815196990966797, "report/post_ent_std": 7.63891077041626, "report/prior_ent_mag": 70.44816589355469, "report/prior_ent_max": 70.44816589355469, "report/prior_ent_mean": 58.271217346191406, "report/prior_ent_min": 45.9594841003418, "report/prior_ent_std": 4.223905086517334, "report/rep_loss_mean": 13.788137435913086, "report/rep_loss_std": 9.386130332946777, "report/reward_avg": 0.02304687537252903, "report/reward_loss_mean": 0.06248893961310387, "report/reward_loss_std": 0.28503838181495667, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017058849334717, "report/reward_neg_acc": 0.9889668822288513, "report/reward_neg_loss": 0.04096727445721626, "report/reward_pos_acc": 0.9629629850387573, "report/reward_pos_loss": 0.8571962714195251, "report/reward_pred": 0.02617337368428707, "report/reward_rate": 0.0263671875, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 7.352870397880906e-06, "eval/cont_loss_std": 6.709616718580946e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005892239860258996, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 5.071022769698175e-06, "eval/cont_pred": 0.9960910081863403, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.583139419555664, "eval/dyn_loss_std": 11.262978553771973, "eval/image_loss_mean": 13.669081687927246, "eval/image_loss_std": 17.260366439819336, "eval/model_loss_mean": 24.945940017700195, "eval/model_loss_std": 21.753454208374023, "eval/post_ent_mag": 60.82927703857422, "eval/post_ent_max": 60.82927703857422, "eval/post_ent_mean": 42.46015930175781, "eval/post_ent_min": 20.088064193725586, "eval/post_ent_std": 8.459181785583496, "eval/prior_ent_mag": 70.44816589355469, "eval/prior_ent_max": 70.44816589355469, "eval/prior_ent_mean": 58.69089889526367, "eval/prior_ent_min": 44.907310485839844, "eval/prior_ent_std": 4.115875244140625, "eval/rep_loss_mean": 18.583139419555664, "eval/rep_loss_std": 11.262978553771973, "eval/reward_avg": 0.05654297024011612, "eval/reward_loss_mean": 0.12696589529514313, "eval/reward_loss_std": 0.565133810043335, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0046789646148682, "eval/reward_neg_acc": 0.9854319095611572, "eval/reward_neg_loss": 0.04385584220290184, "eval/reward_pos_acc": 0.888888955116272, "eval/reward_pos_loss": 1.3947242498397827, "eval/reward_pred": 0.049713823944330215, "eval/reward_rate": 0.0615234375, "replay/size": 1000000.0, "replay/inserts": 22544.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.3329506428043752e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.949398177494133e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.224604519930753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 6.556510925292969e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4878678321838, "timer/env.step_count": 2818.0, "timer/env.step_total": 226.54789352416992, "timer/env.step_frac": 0.22643742198997838, "timer/env.step_avg": 0.08039314887301985, "timer/env.step_min": 0.024034976959228516, "timer/env.step_max": 3.425401210784912, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.723729848861694, "timer/replay._sample_frac": 0.01171801300725834, "timer/replay._sample_avg": 0.0005200376973412746, "timer/replay._sample_min": 0.00040435791015625, "timer/replay._sample_max": 0.03482985496520996, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3566.0, "timer/agent.policy_total": 62.005942821502686, "timer/agent.policy_frac": 0.061975706867745055, "timer/agent.policy_avg": 0.017388093892737714, "timer/agent.policy_min": 0.009477376937866211, "timer/agent.policy_max": 0.14558863639831543, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.15944790840148926, "timer/dataset_train_frac": 0.00015937015682856252, "timer/dataset_train_avg": 0.00011316388105144731, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0004324913024902344, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 634.787318944931, "timer/agent.train_frac": 0.6344777776469815, "timer/agent.train_avg": 0.45052329236687794, "timer/agent.train_min": 0.4338407516479492, "timer/agent.train_max": 2.8325612545013428, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4841599464416504, "timer/agent.report_frac": 0.0004839238555592966, "timer/agent.report_avg": 0.2420799732208252, "timer/agent.report_min": 0.23458313941955566, "timer/agent.report_max": 0.24957680702209473, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.431553394546879e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 22.532684990647592}
{"step": 1003984, "time": 46436.877173662186, "episode/length": 405.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975369458128078, "episode/intrinsic_return": 0.0}
{"step": 1004112, "time": 46442.88281965256, "episode/length": 213.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 1004176, "time": 46446.76841711998, "episode/length": 249.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 1004416, "time": 46456.66113090515, "episode/length": 431.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 1004536, "time": 46462.118247032166, "episode/length": 161.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1004760, "time": 46471.3031771183, "episode/length": 432.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 1004816, "time": 46475.042293787, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 1005176, "time": 46488.70688509941, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9706959706959707, "episode/intrinsic_return": 0.0}
{"step": 1005872, "time": 46514.314915418625, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 1005928, "time": 46517.570551395416, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1006232, "time": 46529.53978276253, "episode/length": 280.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 1006768, "time": 46549.80112862587, "episode/length": 331.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9909638554216867, "episode/intrinsic_return": 0.0}
{"step": 1006792, "time": 46551.991585969925, "episode/length": 326.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9847094801223242, "episode/intrinsic_return": 0.0}
{"step": 1007456, "time": 46576.60535764694, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 1007536, "time": 46580.93028974533, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9855907780979827, "episode/intrinsic_return": 0.0}
{"step": 1007736, "time": 46590.94647049904, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 1007776, "time": 46594.10060048103, "episode/length": 324.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9815384615384616, "episode/intrinsic_return": 0.0}
{"step": 1008408, "time": 46617.08918619156, "episode/length": 448.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9955456570155902, "episode/intrinsic_return": 0.0}
{"step": 1008744, "time": 46630.128595113754, "episode/length": 243.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1008848, "time": 46635.500144958496, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 1009016, "time": 46642.58797812462, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 1009072, "time": 46646.40005660057, "episode/length": 161.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1009264, "time": 46654.53536319733, "episode/length": 311.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 1009464, "time": 46662.77830839157, "episode/length": 215.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 1009504, "time": 46665.916179418564, "episode/length": 60.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 1009568, "time": 46670.7265226841, "episode/length": 61.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 1009768, "time": 46678.85475683212, "episode/length": 441.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796380090497737, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 46710.29932427406, "eval_episode/length": 153.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 1010048, "time": 46713.40370988846, "eval_episode/length": 184.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 1010048, "time": 46715.17206120491, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 1010048, "time": 46717.52274465561, "eval_episode/length": 203.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 1010048, "time": 46719.49451184273, "eval_episode/length": 59.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 1010048, "time": 46721.604486465454, "eval_episode/length": 220.0, "eval_episode/score": 10.099999971687794, "eval_episode/reward_rate": 0.995475113122172}
{"step": 1010048, "time": 46724.41794800758, "eval_episode/length": 248.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 1010048, "time": 46727.52868652344, "eval_episode/length": 94.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 1010112, "time": 46729.69959616661, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 1010184, "time": 46733.48469519615, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 1010248, "time": 46737.328307151794, "episode/length": 174.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 1010952, "time": 46762.73035168648, "episode/length": 210.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 1011080, "time": 46768.65774726868, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 1011464, "time": 46783.50644612312, "episode/length": 236.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 1011680, "time": 46792.63994383812, "episode/length": 271.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 1011816, "time": 46798.67811822891, "episode/length": 255.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 1011856, "time": 46801.79360437393, "episode/length": 217.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1011920, "time": 46805.46967411041, "episode/length": 216.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 1012736, "time": 46834.53723716736, "episode/length": 310.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 1013080, "time": 46847.68426012993, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 1013096, "time": 46849.88683986664, "episode/length": 176.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 1013320, "time": 46859.35450100899, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1013448, "time": 46865.21110057831, "episode/length": 203.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 1013584, "time": 46871.857157707214, "episode/length": 312.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9968051118210862, "episode/intrinsic_return": 0.0}
{"step": 1013760, "time": 46879.35180234909, "episode/length": 350.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.98005698005698, "episode/intrinsic_return": 0.0}
{"step": 1014592, "time": 46909.184124708176, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 1014624, "time": 46911.81953668594, "episode/length": 235.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 1014752, "time": 46917.596670627594, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 1015072, "time": 46930.09652519226, "episode/length": 218.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 1015192, "time": 46935.40871953964, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 1015232, "time": 46938.632192611694, "episode/length": 205.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 1015568, "time": 46951.61613559723, "episode/length": 455.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9802631578947368, "episode/intrinsic_return": 0.0}
{"step": 1015584, "time": 46953.876603126526, "episode/length": 266.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 1015984, "time": 46971.07002520561, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1016144, "time": 46978.68667888641, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 1016592, "time": 46995.72917842865, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972, "episode/intrinsic_return": 0.0}
{"step": 1016624, "time": 46998.3083922863, "episode/length": 59.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 1016632, "time": 46999.9302341938, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 1016712, "time": 47004.14641618729, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 1017016, "time": 47016.06819272041, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 1017144, "time": 47022.51363372803, "episode/length": 196.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 1017608, "time": 47039.89796972275, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 1017904, "time": 47051.939210653305, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 1017976, "time": 47055.716879844666, "episode/length": 298.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9665551839464883, "episode/intrinsic_return": 0.0}
{"step": 1018056, "time": 47060.16170525551, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 1018248, "time": 47068.24291729927, "episode/length": 191.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 1018504, "time": 47078.641283750534, "episode/length": 169.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 1018856, "time": 47092.43506026268, "episode/length": 229.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 1018984, "time": 47098.31785607338, "episode/length": 294.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 1019424, "time": 47115.16879987717, "episode/length": 348.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994269340974212, "episode/intrinsic_return": 0.0}
{"step": 1019640, "time": 47123.9589612484, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 1019880, "time": 47133.68921470642, "episode/length": 203.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
