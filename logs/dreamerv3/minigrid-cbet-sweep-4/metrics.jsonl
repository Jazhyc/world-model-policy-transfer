{"step": 1560, "time": 169.88275289535522, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 1560, "time": 170.55493450164795, "eval_episode/length": 267.0, "eval_episode/score": 0.16562500596046448, "eval_episode/reward_rate": 0.0037313432835820895}
{"step": 1560, "time": 171.3005301952362, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 171.308678150177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 171.31521081924438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 171.32158970832825, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 171.3278625011444, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1560, "time": 171.33408904075623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 1561, "time": 297.5593378543854, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.88677978515625, "train/action_min": 0.0, "train/action_std": 1.9996485710144043, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00015179540787357837, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.5749422907829285, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 1.0, "train/cont_loss_mean": 0.9404886364936829, "train/cont_loss_std": 0.3200794756412506, "train/cont_neg_acc": NaN, "train/cont_neg_loss": NaN, "train/cont_pos_acc": 0.232421875, "train/cont_pos_loss": 0.9404886364936829, "train/cont_pred": 0.40968751907348633, "train/cont_rate": 1.0, "train/dyn_loss_mean": 9.797386169433594, "train/dyn_loss_std": 0.3861061632633209, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 2.956554889678955, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 11970.705078125, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 5225.84716796875, "train/image_loss_std": 41.504913330078125, "train/model_loss_mean": 5238.20751953125, "train/model_loss_std": 41.52021026611328, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 52382076.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 1.9427846670150757, "train/policy_entropy_max": 1.9427846670150757, "train/policy_entropy_mean": 1.776031494140625, "train/policy_entropy_min": 1.0721937417984009, "train/policy_entropy_std": 0.0926838144659996, "train/policy_logprob_mag": 4.822768688201904, "train/policy_logprob_max": -0.3315717875957489, "train/policy_logprob_mean": -1.7820796966552734, "train/policy_logprob_min": -4.822768688201904, "train/policy_logprob_std": 0.5633659958839417, "train/policy_randomness_mag": 0.9983938932418823, "train/policy_randomness_max": 0.9983938932418823, "train/policy_randomness_mean": 0.9126996994018555, "train/policy_randomness_min": 0.5509986281394958, "train/policy_randomness_std": 0.04763006046414375, "train/post_ent_mag": 106.57528686523438, "train/post_ent_max": 106.57528686523438, "train/post_ent_mean": 106.26737976074219, "train/post_ent_min": 105.992919921875, "train/post_ent_std": 0.10888165980577469, "train/prior_ent_mag": 106.39289855957031, "train/prior_ent_max": 106.39289855957031, "train/prior_ent_mean": 105.662109375, "train/prior_ent_min": 104.6519775390625, "train/prior_ent_std": 0.27982717752456665, "train/rep_loss_mean": 9.797386169433594, "train/rep_loss_std": 0.3861061632633209, "train/reward_avg": 0.00027401154511608183, "train/reward_loss_mean": 5.541263580322266, "train/reward_loss_std": 2.6697622956817213e-07, "train/reward_max_data": 0.0012499999720603228, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263580322266, "train/reward_pos_acc": NaN, "train/reward_pos_loss": NaN, "train/reward_pred": 0.0, "train/reward_rate": 0.0, "train/params_agent/wm/model_opt": 181559683.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9454599.0, "report/cont_avg": 1.0, "report/cont_loss_mean": 0.91762375831604, "report/cont_loss_std": 0.3411291539669037, "report/cont_neg_acc": NaN, "report/cont_neg_loss": NaN, "report/cont_pos_acc": 0.275390625, "report/cont_pos_loss": 0.91762375831604, "report/cont_pred": 0.42176932096481323, "report/cont_rate": 1.0, "report/dyn_loss_mean": 9.853763580322266, "report/dyn_loss_std": 0.33785441517829895, "report/image_loss_mean": 5221.07080078125, "report/image_loss_std": 40.07432556152344, "report/model_loss_mean": 5233.4423828125, "report/model_loss_std": 40.06289291381836, "report/post_ent_mag": 106.60090637207031, "report/post_ent_max": 106.60090637207031, "report/post_ent_mean": 106.2497329711914, "report/post_ent_min": 105.88716125488281, "report/post_ent_std": 0.11687138676643372, "report/prior_ent_mag": 106.40736389160156, "report/prior_ent_max": 106.40736389160156, "report/prior_ent_mean": 105.63368225097656, "report/prior_ent_min": 104.77804565429688, "report/prior_ent_std": 0.2640596926212311, "report/rep_loss_mean": 9.853763580322266, "report/rep_loss_std": 0.33785441517829895, "report/reward_avg": 0.00027401154511608183, "report/reward_loss_mean": 5.541263580322266, "report/reward_loss_std": 2.6697622956817213e-07, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263580322266, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.9125118255615234, "eval/cont_loss_std": 0.3084537088871002, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 0.2607421875, "eval/cont_pos_loss": 0.9125118255615234, "eval/cont_pred": 0.4201265871524811, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 9.845649719238281, "eval/dyn_loss_std": 0.3501335084438324, "eval/image_loss_mean": 5227.25341796875, "eval/image_loss_std": 41.02838897705078, "eval/model_loss_mean": 5239.615234375, "eval/model_loss_std": 40.99220657348633, "eval/post_ent_mag": 106.52020263671875, "eval/post_ent_max": 106.52020263671875, "eval/post_ent_mean": 106.25013732910156, "eval/post_ent_min": 105.76416778564453, "eval/post_ent_std": 0.11284571886062622, "eval/prior_ent_mag": 106.43462371826172, "eval/prior_ent_max": 106.43462371826172, "eval/prior_ent_mean": 105.65797424316406, "eval/prior_ent_min": 104.73089599609375, "eval/prior_ent_std": 0.2632763683795929, "eval/rep_loss_mean": 9.845649719238281, "eval/rep_loss_std": 0.3501335084438324, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 5.756556818591274e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.727316447666713e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3368.0, "eval_replay/inserts": 3368.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.3185934895857497e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 154.92155575752258, "timer/env.step_count": 196.0, "timer/env.step_total": 2.0481643676757812, "timer/env.step_frac": 0.013220654528421413, "timer/env.step_avg": 0.010449818202427455, "timer/env.step_min": 0.008555889129638672, "timer/env.step_max": 0.02614283561706543, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.10512924194335938, "timer/replay._sample_frac": 0.000678596606064967, "timer/replay._sample_avg": 0.0009386539459228516, "timer/replay._sample_min": 0.0003387928009033203, "timer/replay._sample_max": 0.01348423957824707, "timer/agent.save_count": 1.0, "timer/agent.save_total": 2.154324531555176, "timer/agent.save_frac": 0.013905905611527965, "timer/agent.save_avg": 2.154324531555176, "timer/agent.save_min": 2.154324531555176, "timer/agent.save_max": 2.154324531555176, "timer/agent.policy_count": 290.0, "timer/agent.policy_total": 22.58393669128418, "timer/agent.policy_frac": 0.14577659371451002, "timer/agent.policy_avg": 0.0778756437630489, "timer/agent.policy_min": 0.009219884872436523, "timer/agent.policy_max": 17.166834592819214, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.314018249511719e-05, "timer/dataset_train_frac": 2.1391589009722418e-07, "timer/dataset_train_avg": 3.314018249511719e-05, "timer/dataset_train_min": 3.314018249511719e-05, "timer/dataset_train_max": 3.314018249511719e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 91.65811467170715, "timer/agent.train_frac": 0.5916421005684128, "timer/agent.train_avg": 91.65811467170715, "timer/agent.train_min": 91.65811467170715, "timer/agent.train_max": 91.65811467170715, "timer/agent.report_count": 2.0, "timer/agent.report_total": 32.08089470863342, "timer/agent.report_frac": 0.2070783149043845, "timer/agent.report_avg": 16.04044735431671, "timer/agent.report_min": 7.9938647747039795, "timer/agent.report_max": 24.087029933929443, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 2.400782651450861e-07, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05}
{"step": 2312, "time": 321.3646819591522, "episode/length": 288.0, "episode/score": 0.08381309585092822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08381309585092822}
{"step": 2312, "time": 321.37249207496643, "episode/length": 288.0, "episode/score": 0.06816193430972817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06816193430972817}
{"step": 2312, "time": 321.37946915626526, "episode/length": 288.0, "episode/score": 0.07081862694576557, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07081862694576557}
{"step": 2312, "time": 321.38638043403625, "episode/length": 288.0, "episode/score": 0.07734972244679739, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07734972244679739}
{"step": 2312, "time": 321.3930959701538, "episode/length": 288.0, "episode/score": 0.07872819611179693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07872819611179693}
{"step": 2312, "time": 321.3998191356659, "episode/length": 288.0, "episode/score": 0.05941564476779604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05941564476779604}
{"step": 2312, "time": 321.4064745903015, "episode/length": 288.0, "episode/score": 0.059240242621172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059240242621172}
{"step": 2312, "time": 321.4133756160736, "episode/length": 288.0, "episode/score": 0.0998358421697958, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0998358421697958}
{"step": 4624, "time": 395.65479612350464, "episode/length": 288.0, "episode/score": 0.05147858867780997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05147858867780997}
{"step": 4624, "time": 395.6631922721863, "episode/length": 288.0, "episode/score": 0.049888434729041364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049888434729041364}
{"step": 4624, "time": 395.67089104652405, "episode/length": 288.0, "episode/score": 0.04803448391373877, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04803448391373877}
{"step": 4624, "time": 395.6786136627197, "episode/length": 288.0, "episode/score": 0.04952047662527548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04952047662527548}
{"step": 4624, "time": 395.68692326545715, "episode/length": 288.0, "episode/score": 0.04803701097296198, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04803701097296198}
{"step": 4624, "time": 395.69453382492065, "episode/length": 288.0, "episode/score": 0.05535015238820051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05535015238820051}
{"step": 4624, "time": 395.70158314704895, "episode/length": 288.0, "episode/score": 0.056502935753428574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056502935753428574}
{"step": 4624, "time": 395.7087998390198, "episode/length": 288.0, "episode/score": 0.05760787030646952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05760787030646952}
{"step": 6936, "time": 469.40287137031555, "episode/length": 288.0, "episode/score": 0.054619367501572924, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054619367501572924}
{"step": 6936, "time": 469.41081500053406, "episode/length": 288.0, "episode/score": 0.05095309031423767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05095309031423767}
{"step": 6936, "time": 469.41847014427185, "episode/length": 288.0, "episode/score": 0.06443621630182861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06443621630182861}
{"step": 6936, "time": 469.42754006385803, "episode/length": 288.0, "episode/score": 0.04910803828511234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04910803828511234}
{"step": 6936, "time": 469.4347267150879, "episode/length": 288.0, "episode/score": 0.07901064775899158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07901064775899158}
{"step": 6936, "time": 469.4418692588806, "episode/length": 288.0, "episode/score": 0.05215445283329245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05215445283329245}
{"step": 6936, "time": 469.449010848999, "episode/length": 288.0, "episode/score": 0.05806231509677673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05806231509677673}
{"step": 6936, "time": 469.4560217857361, "episode/length": 288.0, "episode/score": 0.05438103354788382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05438103354788382}
{"step": 9248, "time": 544.220546245575, "episode/length": 288.0, "episode/score": 0.04520465365828841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04520465365828841}
{"step": 9248, "time": 544.2286674976349, "episode/length": 288.0, "episode/score": 0.057980788307986586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057980788307986586}
{"step": 9248, "time": 544.2361867427826, "episode/length": 288.0, "episode/score": 0.06717918792071487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06717918792071487}
{"step": 9248, "time": 544.2439568042755, "episode/length": 288.0, "episode/score": 0.05642276208595831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05642276208595831}
{"step": 9248, "time": 544.2519264221191, "episode/length": 288.0, "episode/score": 0.043017587009558156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043017587009558156}
{"step": 9248, "time": 544.2590656280518, "episode/length": 288.0, "episode/score": 0.06773264893479336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06773264893479336}
{"step": 9248, "time": 544.2661786079407, "episode/length": 288.0, "episode/score": 0.03844461397420673, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03844461397420673}
{"step": 9248, "time": 544.2732443809509, "episode/length": 288.0, "episode/score": 0.0548078209689038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0548078209689038}
{"step": 10088, "time": 575.5630974769592, "eval_episode/length": 237.0, "eval_episode/score": 0.2593750059604645, "eval_episode/reward_rate": 0.004201680672268907}
{"step": 10088, "time": 576.579430103302, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.5984828472137, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.6325953006744, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.6523656845093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.6830508708954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.6899573802948, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 10088, "time": 576.697505235672, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 11560, "time": 623.7620544433594, "episode/length": 288.0, "episode/score": 0.06366739654822595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06366739654822595}
{"step": 11560, "time": 623.7704162597656, "episode/length": 288.0, "episode/score": 0.05537555325508947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05537555325508947}
{"step": 11560, "time": 623.7778584957123, "episode/length": 288.0, "episode/score": 0.06829372390967592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06829372390967592}
{"step": 11560, "time": 623.7849159240723, "episode/length": 288.0, "episode/score": 0.027148322780021772, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027148322780021772}
{"step": 11560, "time": 623.791716337204, "episode/length": 288.0, "episode/score": 0.06836412899070865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06836412899070865}
{"step": 11560, "time": 623.7990188598633, "episode/length": 288.0, "episode/score": 0.05255424198776382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05255424198776382}
{"step": 11560, "time": 623.8062455654144, "episode/length": 288.0, "episode/score": 0.06160780963085699, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06160780963085699}
{"step": 11560, "time": 623.8134865760803, "episode/length": 288.0, "episode/score": 0.06276809346138634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06276809346138634}
{"step": 12880, "time": 666.2149965763092, "episode/length": 164.0, "episode/score": 0.520205074171372, "episode/reward_rate": 0.006060606060606061, "episode/intrinsic_return": 0.032705063414596225}
{"step": 13872, "time": 697.9765577316284, "episode/length": 288.0, "episode/score": 0.055148197074572636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055148197074572636}
{"step": 13872, "time": 697.9862101078033, "episode/length": 288.0, "episode/score": 0.05719848013086448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05719848013086448}
{"step": 13872, "time": 697.9940941333771, "episode/length": 288.0, "episode/score": 0.06199719933204051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06199719933204051}
{"step": 13872, "time": 698.0171349048615, "episode/length": 288.0, "episode/score": 0.05119387297486355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05119387297486355}
{"step": 13872, "time": 698.0319194793701, "episode/length": 288.0, "episode/score": 0.04638385046644089, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04638385046644089}
{"step": 13872, "time": 698.0419578552246, "episode/length": 288.0, "episode/score": 0.05839541678881233, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05839541678881233}
{"step": 13872, "time": 698.0497965812683, "episode/length": 288.0, "episode/score": 0.05321793710641032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05321793710641032}
{"step": 15192, "time": 740.0440809726715, "episode/length": 288.0, "episode/score": 0.04160047956116841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04160047956116841}
{"step": 15904, "time": 763.1595737934113, "episode/length": 253.0, "episode/score": 0.24559674466024717, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.0362217514356189}
{"step": 16184, "time": 771.9857749938965, "episode/length": 288.0, "episode/score": 0.051586727345920735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051586727345920735}
{"step": 16184, "time": 771.9955203533173, "episode/length": 288.0, "episode/score": 0.03503462136109192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03503462136109192}
{"step": 16184, "time": 772.0037229061127, "episode/length": 288.0, "episode/score": 0.04421325854667657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04421325854667657}
{"step": 16184, "time": 772.022629737854, "episode/length": 288.0, "episode/score": 0.05511237122300372, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05511237122300372}
{"step": 16184, "time": 772.0290856361389, "episode/length": 288.0, "episode/score": 0.049997514535391474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049997514535391474}
{"step": 16184, "time": 772.0421283245087, "episode/length": 288.0, "episode/score": 0.03860680050115661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03860680050115661}
{"step": 17504, "time": 814.9642639160156, "episode/length": 288.0, "episode/score": 0.041554624891603, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041554624891603}
{"step": 18216, "time": 837.5450143814087, "episode/length": 288.0, "episode/score": 0.057145991066079205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057145991066079205}
{"step": 18496, "time": 846.7157790660858, "episode/length": 288.0, "episode/score": 0.05552433715894267, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05552433715894267}
{"step": 18496, "time": 846.7268102169037, "episode/length": 288.0, "episode/score": 0.045617844666594465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045617844666594465}
{"step": 18496, "time": 846.7339479923248, "episode/length": 288.0, "episode/score": 0.05464768468226566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05464768468226566}
{"step": 18496, "time": 846.7419004440308, "episode/length": 288.0, "episode/score": 0.05130819065976766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05130819065976766}
{"step": 18496, "time": 846.7489068508148, "episode/length": 288.0, "episode/score": 0.04104708958283254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04104708958283254}
{"step": 18496, "time": 846.7557463645935, "episode/length": 288.0, "episode/score": 0.058008913444041355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058008913444041355}
{"step": 19816, "time": 888.8563392162323, "episode/length": 288.0, "episode/score": 0.05215161515928912, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05215161515928912}
{"step": 20072, "time": 903.6929264068604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.7260727882385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.7514786720276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.7775468826294, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.8058393001556, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.8406772613525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.8785226345062, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20072, "time": 903.9094562530518, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 20528, "time": 918.6365077495575, "episode/length": 288.0, "episode/score": 0.0421555820647086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0421555820647086}
{"step": 20808, "time": 927.40713763237, "episode/length": 288.0, "episode/score": 0.06315215603865454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06315215603865454}
{"step": 20808, "time": 927.4151165485382, "episode/length": 288.0, "episode/score": 0.06192840941139366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06192840941139366}
{"step": 20808, "time": 927.4220209121704, "episode/length": 288.0, "episode/score": 0.038526099557088855, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038526099557088855}
{"step": 20808, "time": 927.4286515712738, "episode/length": 288.0, "episode/score": 0.04782065079325548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04782065079325548}
{"step": 20808, "time": 927.4350891113281, "episode/length": 288.0, "episode/score": 0.05192475190801815, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05192475190801815}
{"step": 20808, "time": 927.4417314529419, "episode/length": 288.0, "episode/score": 0.05232006375365472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05232006375365472}
{"step": 22128, "time": 969.7216589450836, "episode/length": 288.0, "episode/score": 0.03963960334351668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03963960334351668}
{"step": 22368, "time": 977.4038527011871, "episode/length": 194.0, "episode/score": 0.41818183375931994, "episode/reward_rate": 0.005128205128205128, "episode/intrinsic_return": 0.024431823002544206}
{"step": 22840, "time": 992.3909065723419, "episode/length": 288.0, "episode/score": 0.05074979133189572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05074979133189572}
{"step": 23120, "time": 1001.4976618289948, "episode/length": 288.0, "episode/score": 0.028496101736777746, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028496101736777746}
{"step": 23120, "time": 1001.505931854248, "episode/length": 288.0, "episode/score": 0.04342205777749086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04342205777749086}
{"step": 23120, "time": 1001.5130498409271, "episode/length": 288.0, "episode/score": 0.028307369254832793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028307369254832793}
{"step": 23120, "time": 1001.5206806659698, "episode/length": 288.0, "episode/score": 0.023076682081637045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023076682081637045}
{"step": 23120, "time": 1001.5282618999481, "episode/length": 288.0, "episode/score": 0.05268531105582497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05268531105582497}
{"step": 24440, "time": 1043.6234300136566, "episode/length": 288.0, "episode/score": 0.040232346633104044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040232346633104044}
{"step": 24680, "time": 1051.7793986797333, "episode/length": 288.0, "episode/score": 0.04204611743710984, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04204611743710984}
{"step": 25152, "time": 1067.0668284893036, "episode/length": 288.0, "episode/score": 0.02274722292139586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02274722292139586}
{"step": 25432, "time": 1075.868370294571, "episode/length": 288.0, "episode/score": 0.04214873117632578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04214873117632578}
{"step": 25432, "time": 1075.8762905597687, "episode/length": 288.0, "episode/score": 0.023638112872959027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.023638112872959027}
{"step": 25432, "time": 1075.8832204341888, "episode/length": 288.0, "episode/score": 0.04870955758514128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04870955758514128}
{"step": 25432, "time": 1075.8898525238037, "episode/length": 288.0, "episode/score": 0.03685443012545875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03685443012545875}
{"step": 25432, "time": 1075.8967156410217, "episode/length": 288.0, "episode/score": 0.0549087308567664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0549087308567664}
{"step": 26752, "time": 1118.2982096672058, "episode/length": 288.0, "episode/score": 0.04376651346362337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04376651346362337}
{"step": 26992, "time": 1125.9717228412628, "episode/length": 288.0, "episode/score": 0.044426063847538444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044426063847538444}
{"step": 27464, "time": 1140.896164894104, "episode/length": 288.0, "episode/score": 0.04191412938237704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04191412938237704}
{"step": 27744, "time": 1150.0498723983765, "episode/length": 288.0, "episode/score": 0.05597846987086541, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05597846987086541}
{"step": 27744, "time": 1150.0582637786865, "episode/length": 288.0, "episode/score": 0.04282364821708029, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04282364821708029}
{"step": 27744, "time": 1150.0680413246155, "episode/length": 288.0, "episode/score": 0.033317667078705426, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.033317667078705426}
{"step": 27744, "time": 1150.0794277191162, "episode/length": 288.0, "episode/score": 0.05381998213212569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05381998213212569}
{"step": 27744, "time": 1150.089075088501, "episode/length": 288.0, "episode/score": 0.04630330582119768, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04630330582119768}
{"step": 29064, "time": 1192.3269515037537, "episode/length": 288.0, "episode/score": 0.056431260639328684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056431260639328684}
{"step": 29304, "time": 1200.018651008606, "episode/length": 288.0, "episode/score": 0.06251231952865055, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06251231952865055}
{"step": 29776, "time": 1215.277101278305, "episode/length": 288.0, "episode/score": 0.05763607552319172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05763607552319172}
{"step": 30056, "time": 1224.0571155548096, "episode/length": 288.0, "episode/score": 0.06952205754407714, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06952205754407714}
{"step": 30056, "time": 1224.0650753974915, "episode/length": 288.0, "episode/score": 0.06731723134976164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06731723134976164}
{"step": 30056, "time": 1224.0721061229706, "episode/length": 288.0, "episode/score": 0.08188426502385937, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08188426502385937}
{"step": 30056, "time": 1224.0804328918457, "episode/length": 288.0, "episode/score": 0.08058595984243766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08058595984243766}
{"step": 30056, "time": 1224.087337255478, "episode/length": 288.0, "episode/score": 0.06057317089107528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06057317089107528}
{"step": 30056, "time": 1229.5483779907227, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.555572271347, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.562021970749, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.568909406662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.5758321285248, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.5829446315765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.589998960495, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30056, "time": 1229.5971319675446, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 30656, "time": 1249.1746981143951, "episode/length": 74.0, "episode/score": 0.7868590556456638, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.018109015086565705}
{"step": 31161, "time": 1266.1289219856262, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0005070866765204, "train/action_min": 0.0, "train/action_std": 1.9982236475557895, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0005111892756021178, "train/actor_opt_grad_steps": 930.0, "train/actor_opt_loss": 12.646803810145403, "train/adv_mag": 0.0016341192053496835, "train/adv_max": 0.0016341192053496835, "train/adv_mean": 0.0009598662733233633, "train/adv_min": 0.00011777490355177327, "train/adv_std": 0.00044599251838435154, "train/cont_avg": 0.9969752956081082, "train/cont_loss_mean": 0.025553820171031427, "train/cont_loss_std": 0.2997108892533658, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.792004717567752, "train/cont_pos_acc": 0.9960831806466386, "train/cont_pos_loss": 0.008058806566549646, "train/cont_pred": 0.9937739620337616, "train/cont_rate": 0.9969752956081082, "train/dyn_loss_mean": 1.0618667944057567, "train/dyn_loss_std": 0.005000838116521245, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 4.540061575415972, "train/extr_critic_critic_opt_grad_steps": 930.0, "train/extr_critic_critic_opt_loss": 10619.682271431588, "train/extr_critic_mag": 0.014516443175238532, "train/extr_critic_max": 0.01451644059774038, "train/extr_critic_mean": 0.014476841312180832, "train/extr_critic_min": 0.014445715337186246, "train/extr_critic_std": 9.430428116783828e-06, "train/extr_return_normed_mag": 0.0030154379472132615, "train/extr_return_normed_max": 0.0030154366704278524, "train/extr_return_normed_mean": 0.0023629648658106714, "train/extr_return_normed_min": 0.001535220200414519, "train/extr_return_normed_std": 0.00044589458884159664, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.016089173142116376, "train/extr_return_raw_max": 0.016089171857237416, "train/extr_return_raw_mean": 0.015436700731648979, "train/extr_return_raw_min": 0.014608955386869165, "train/extr_return_raw_std": 0.000445894586545737, "train/extr_reward_mag": 0.00019539240244272592, "train/extr_reward_max": 0.00019539240244272592, "train/extr_reward_mean": 0.00019519984849048833, "train/extr_reward_min": 0.00019471516480316987, "train/extr_reward_std": 8.262588717246745e-08, "train/image_loss_mean": 29.376098915370736, "train/image_loss_std": 0.3985128157042168, "train/model_loss_mean": 30.160947706570497, "train/model_loss_std": 0.6460368207580335, "train/model_opt_grad_norm": 100.69240525494452, "train/model_opt_grad_steps": 920.0, "train/model_opt_loss": 575.0916453077987, "train/model_opt_model_opt_grad_overflow": 0.005405405405405406, "train/model_opt_model_opt_grad_scale": 14.199746621621621, "train/policy_entropy_mag": 1.9457826788361008, "train/policy_entropy_max": 1.9457826788361008, "train/policy_entropy_mean": 1.9411838280188072, "train/policy_entropy_min": 1.8837745937141213, "train/policy_entropy_std": 0.0030049456742818692, "train/policy_logprob_mag": 2.4452850019609604, "train/policy_logprob_max": -1.5275743333069054, "train/policy_logprob_mean": -1.9412555295067864, "train/policy_logprob_min": -2.4452850019609604, "train/policy_logprob_std": 0.08734833547795141, "train/policy_randomness_mag": 0.9999345518447257, "train/policy_randomness_max": 0.9999345518447257, "train/policy_randomness_mean": 0.9975712083481454, "train/policy_randomness_min": 0.968068697001483, "train/policy_randomness_std": 0.0015442366532452808, "train/post_ent_mag": 83.2815043268977, "train/post_ent_max": 83.2815043268977, "train/post_ent_mean": 83.18066501101931, "train/post_ent_min": 83.09834211194837, "train/post_ent_std": 0.026141956677610004, "train/prior_ent_mag": 88.27331316148913, "train/prior_ent_max": 88.27331316148913, "train/prior_ent_mean": 88.13585275186075, "train/prior_ent_min": 87.96545026624526, "train/prior_ent_std": 0.04657972108673405, "train/rep_loss_mean": 1.0618667944057567, "train/rep_loss_std": 0.005000838116521245, "train/reward_avg": 0.00022617605840472655, "train/reward_loss_mean": 0.12217101320070592, "train/reward_loss_std": 0.03491418964492224, "train/reward_max_data": 0.027847973359245305, "train/reward_max_pred": 0.0001953853143228067, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.12150322630800106, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.650424520174662, "train/reward_pred": 0.0001950651822561348, "train/reward_rate": 6.862331081081081e-05, "train_stats/mean_log_entropy": 1.930163262003944, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02559509128332138, "report/cont_loss_std": 0.3542864918708801, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.683096408843994, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0034088080283254385, "report/cont_pred": 0.9965971112251282, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.24380898475646973, "report/image_loss_std": 0.08822140097618103, "report/model_loss_mean": 0.8779729008674622, "report/model_loss_std": 0.3649587631225586, "report/post_ent_mag": 70.72681427001953, "report/post_ent_max": 70.72681427001953, "report/post_ent_mean": 70.47787475585938, "report/post_ent_min": 70.44927215576172, "report/post_ent_std": 0.039319638162851334, "report/prior_ent_mag": 73.67788696289062, "report/prior_ent_max": 73.67788696289062, "report/prior_ent_mean": 73.4019775390625, "report/prior_ent_min": 73.34080505371094, "report/prior_ent_std": 0.05267959088087082, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001598060771357268, "report/reward_loss_mean": 0.00856885127723217, "report/reward_loss_std": 0.01438163872808218, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00021636486053466797, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.00856885127723217, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.000215985463000834, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003408808493986726, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003408808493986726, "eval/cont_pred": 0.9965971112251282, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23682932555675507, "eval/image_loss_std": 0.08432275056838989, "eval/model_loss_mean": 0.842007040977478, "eval/model_loss_std": 0.08432259410619736, "eval/post_ent_mag": 70.72198486328125, "eval/post_ent_max": 70.72198486328125, "eval/post_ent_mean": 70.47613525390625, "eval/post_ent_min": 70.45117950439453, "eval/post_ent_std": 0.0354042686522007, "eval/prior_ent_mag": 73.67788696289062, "eval/prior_ent_max": 73.67788696289062, "eval/prior_ent_mean": 73.39872741699219, "eval/prior_ent_min": 73.33378601074219, "eval/prior_ent_std": 0.048082999885082245, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0017688809894025326, "eval/reward_loss_std": 3.237535111111356e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00021636486053466797, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0017688809894025326, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002160066505894065, "eval/reward_rate": 0.0, "replay/size": 30657.0, "replay/inserts": 29600.0, "replay/samples": 29600.0, "replay/insert_wait_avg": 1.4002661447267276e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.084231144673115e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10304.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.265206551469321e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 968.557067155838, "timer/env.step_count": 3700.0, "timer/env.step_total": 37.64461159706116, "timer/env.step_frac": 0.038866694460868816, "timer/env.step_avg": 0.01017421935055707, "timer/env.step_min": 0.008594751358032227, "timer/env.step_max": 0.03687930107116699, "timer/replay._sample_count": 29600.0, "timer/replay._sample_total": 15.121607780456543, "timer/replay._sample_frac": 0.0156125109126105, "timer/replay._sample_avg": 0.0005108651277181264, "timer/replay._sample_min": 0.0003376007080078125, "timer/replay._sample_max": 0.0184018611907959, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4567.0, "timer/agent.policy_total": 47.333200454711914, "timer/agent.policy_frac": 0.04886981062840785, "timer/agent.policy_avg": 0.010364177896805762, "timer/agent.policy_min": 0.008853435516357422, "timer/agent.policy_max": 0.08778977394104004, "timer/dataset_train_count": 1850.0, "timer/dataset_train_total": 0.2065424919128418, "timer/dataset_train_frac": 0.0002132476225890877, "timer/dataset_train_avg": 0.00011164459022315773, "timer/dataset_train_min": 8.416175842285156e-05, "timer/dataset_train_max": 0.0006287097930908203, "timer/agent.train_count": 1850.0, "timer/agent.train_total": 834.0077283382416, "timer/agent.train_frac": 0.861082693647882, "timer/agent.train_avg": 0.4508149882909414, "timer/agent.train_min": 0.43505430221557617, "timer/agent.train_max": 0.8385999202728271, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4821774959564209, "timer/agent.report_frac": 0.0004978307549521395, "timer/agent.report_avg": 0.24108874797821045, "timer/agent.report_min": 0.23738622665405273, "timer/agent.report_max": 0.24479126930236816, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.3969876460280714e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 30.560480673614506}
{"step": 31376, "time": 1272.9727058410645, "episode/length": 288.0, "episode/score": 0.07669516355662154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07669516355662154}
{"step": 31616, "time": 1280.6170182228088, "episode/length": 288.0, "episode/score": 0.030950523685419284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030950523685419284}
{"step": 32088, "time": 1295.5554330348969, "episode/length": 288.0, "episode/score": 0.05190769414235774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05190769414235774}
{"step": 32368, "time": 1304.6924397945404, "episode/length": 288.0, "episode/score": 0.06874462386804225, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06874462386804225}
{"step": 32368, "time": 1304.7027015686035, "episode/length": 288.0, "episode/score": 0.058597935689931546, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058597935689931546}
{"step": 32368, "time": 1304.7098665237427, "episode/length": 288.0, "episode/score": 0.049121928990587094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049121928990587094}
{"step": 32368, "time": 1304.717430114746, "episode/length": 288.0, "episode/score": 0.0701009221975255, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0701009221975255}
{"step": 32968, "time": 1324.239367723465, "episode/length": 288.0, "episode/score": 0.06052043378616645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06052043378616645}
{"step": 33688, "time": 1347.274736404419, "episode/length": 288.0, "episode/score": 0.04712074441260938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04712074441260938}
{"step": 33928, "time": 1354.9383096694946, "episode/length": 288.0, "episode/score": 0.06719076569663684, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06719076569663684}
{"step": 34400, "time": 1370.1849603652954, "episode/length": 288.0, "episode/score": 0.0692663228580841, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0692663228580841}
{"step": 34680, "time": 1378.9639389514923, "episode/length": 288.0, "episode/score": 0.043321892087419656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043321892087419656}
{"step": 34680, "time": 1378.9720215797424, "episode/length": 288.0, "episode/score": 0.059425666903905494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059425666903905494}
{"step": 34680, "time": 1378.9790346622467, "episode/length": 288.0, "episode/score": 0.07589926449702489, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07589926449702489}
{"step": 34680, "time": 1378.9861307144165, "episode/length": 288.0, "episode/score": 0.06070167143559502, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06070167143559502}
{"step": 35280, "time": 1398.2175931930542, "episode/length": 288.0, "episode/score": 0.054977194350669834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054977194350669834}
{"step": 36000, "time": 1421.097615480423, "episode/length": 288.0, "episode/score": 0.04901060959329584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04901060959329584}
{"step": 36240, "time": 1428.6899557113647, "episode/length": 288.0, "episode/score": 0.062112376624327226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062112376624327226}
{"step": 36712, "time": 1443.4814960956573, "episode/length": 288.0, "episode/score": 0.05758443242640965, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05758443242640965}
{"step": 36992, "time": 1452.6257479190826, "episode/length": 288.0, "episode/score": 0.04459301152007811, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04459301152007811}
{"step": 36992, "time": 1452.633817434311, "episode/length": 288.0, "episode/score": 0.05522129788624852, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05522129788624852}
{"step": 36992, "time": 1452.6409080028534, "episode/length": 288.0, "episode/score": 0.06758492958744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06758492958744}
{"step": 36992, "time": 1452.6491599082947, "episode/length": 288.0, "episode/score": 0.039561016752458045, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039561016752458045}
{"step": 37552, "time": 1470.521258354187, "episode/length": 69.0, "episode/score": 0.8013672946029828, "episode/reward_rate": 0.014285714285714285, "episode/intrinsic_return": 0.016992254043884714}
{"step": 37592, "time": 1471.5786578655243, "episode/length": 288.0, "episode/score": 0.04627218525627086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04627218525627086}
{"step": 38312, "time": 1494.5867319107056, "episode/length": 288.0, "episode/score": 0.043835919976686455, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043835919976686455}
{"step": 38552, "time": 1502.2203481197357, "episode/length": 288.0, "episode/score": 0.08142838449271039, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08142838449271039}
{"step": 38992, "time": 1516.377839565277, "episode/length": 54.0, "episode/score": 0.8429407494339785, "episode/reward_rate": 0.01818181818181818, "episode/intrinsic_return": 0.011690708874880329}
{"step": 39024, "time": 1517.4021527767181, "episode/length": 288.0, "episode/score": 0.06170563875537027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06170563875537027}
{"step": 39120, "time": 1520.4564969539642, "episode/length": 195.0, "episode/score": 0.4381186341723833, "episode/reward_rate": 0.00510204081632653, "episode/intrinsic_return": 0.0474936353365365}
{"step": 39304, "time": 1526.17995262146, "episode/length": 288.0, "episode/score": 0.061521029490052115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061521029490052115}
{"step": 39304, "time": 1526.1881432533264, "episode/length": 288.0, "episode/score": 0.06012127733322359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06012127733322359}
{"step": 39304, "time": 1526.19522690773, "episode/length": 288.0, "episode/score": 0.05829097057744548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05829097057744548}
{"step": 39904, "time": 1545.4792635440826, "episode/length": 288.0, "episode/score": 0.07491413716962825, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07491413716962825}
{"step": 40040, "time": 1555.2839376926422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.2912356853485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.2978279590607, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.3042454719543, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.3107526302338, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.3172080516815, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.3233590126038, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40040, "time": 1555.3295447826385, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 40624, "time": 1574.0706174373627, "episode/length": 288.0, "episode/score": 0.05224476846285597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05224476846285597}
{"step": 41304, "time": 1595.9704716205597, "episode/length": 288.0, "episode/score": 0.05685723841935442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05685723841935442}
{"step": 41336, "time": 1596.9904816150665, "episode/length": 288.0, "episode/score": 0.07024846461860079, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07024846461860079}
{"step": 41432, "time": 1600.0442786216736, "episode/length": 288.0, "episode/score": 0.07534642794718138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07534642794718138}
{"step": 41616, "time": 1606.0997097492218, "episode/length": 288.0, "episode/score": 0.05986556603880899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05986556603880899}
{"step": 41616, "time": 1606.1078634262085, "episode/length": 288.0, "episode/score": 0.05826200772196444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05826200772196444}
{"step": 41616, "time": 1606.115254163742, "episode/length": 288.0, "episode/score": 0.057625895331341326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057625895331341326}
{"step": 42216, "time": 1625.0523884296417, "episode/length": 288.0, "episode/score": 0.05499772639922185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05499772639922185}
{"step": 42936, "time": 1647.962289571762, "episode/length": 288.0, "episode/score": 0.04029597643352645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04029597643352645}
{"step": 43072, "time": 1652.5130581855774, "episode/length": 181.0, "episode/score": 0.4675968855069641, "episode/reward_rate": 0.005494505494505495, "episode/intrinsic_return": 0.03322189824280031}
{"step": 43616, "time": 1669.7223987579346, "episode/length": 288.0, "episode/score": 0.06194779659460892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06194779659460892}
{"step": 43648, "time": 1670.7522580623627, "episode/length": 288.0, "episode/score": 0.043760836275680504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043760836275680504}
{"step": 43744, "time": 1673.8889937400818, "episode/length": 288.0, "episode/score": 0.07679354823483209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07679354823483209}
{"step": 43928, "time": 1679.4669501781464, "episode/length": 288.0, "episode/score": 0.05359696488395116, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05359696488395116}
{"step": 43928, "time": 1679.474889755249, "episode/length": 288.0, "episode/score": 0.08221005063137454, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08221005063137454}
{"step": 44528, "time": 1698.6378192901611, "episode/length": 288.0, "episode/score": 0.04210230202710363, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04210230202710363}
{"step": 45248, "time": 1721.5171105861664, "episode/length": 288.0, "episode/score": 0.03214871161989663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03214871161989663}
{"step": 45384, "time": 1725.5743284225464, "episode/length": 288.0, "episode/score": 0.05841976412148142, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05841976412148142}
{"step": 45928, "time": 1742.88720536232, "episode/length": 288.0, "episode/score": 0.0497184256654748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0497184256654748}
{"step": 45960, "time": 1743.902281999588, "episode/length": 288.0, "episode/score": 0.057118243365039234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057118243365039234}
{"step": 46056, "time": 1746.9428939819336, "episode/length": 288.0, "episode/score": 0.06847493917493352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06847493917493352}
{"step": 46240, "time": 1752.9821863174438, "episode/length": 288.0, "episode/score": 0.05960316678940103, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05960316678940103}
{"step": 46240, "time": 1752.990413427353, "episode/length": 288.0, "episode/score": 0.07512475510011996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07512475510011996}
{"step": 46840, "time": 1771.9120049476624, "episode/length": 288.0, "episode/score": 0.025566584670855264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025566584670855264}
{"step": 47560, "time": 1794.8272845745087, "episode/length": 288.0, "episode/score": 0.06605031909012382, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06605031909012382}
{"step": 47696, "time": 1799.3316140174866, "episode/length": 288.0, "episode/score": 0.06135901961164336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06135901961164336}
{"step": 48240, "time": 1816.4763848781586, "episode/length": 288.0, "episode/score": 0.04904130081644098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04904130081644098}
{"step": 48272, "time": 1817.5037927627563, "episode/length": 288.0, "episode/score": 0.025212003998575483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025212003998575483}
{"step": 48368, "time": 1820.5162463188171, "episode/length": 288.0, "episode/score": 0.06772796090575639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06772796090575639}
{"step": 48552, "time": 1826.2274615764618, "episode/length": 288.0, "episode/score": 0.049951551168874175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049951551168874175}
{"step": 48552, "time": 1826.6515753269196, "episode/length": 288.0, "episode/score": 0.056181286218219384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056181286218219384}
{"step": 49152, "time": 1845.935965538025, "episode/length": 288.0, "episode/score": 0.051224860069680744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051224860069680744}
{"step": 49872, "time": 1869.238614320755, "episode/length": 288.0, "episode/score": 0.01650037201650889, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01650037201650889}
{"step": 50008, "time": 1873.3036799430847, "episode/length": 288.0, "episode/score": 0.058600848394121385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058600848394121385}
{"step": 50024, "time": 1876.9772732257843, "eval_episode/length": 167.0, "eval_episode/score": 0.4781250059604645, "eval_episode/reward_rate": 0.005952380952380952}
{"step": 50024, "time": 1877.1809368133545, "eval_episode/length": 178.0, "eval_episode/score": 0.4437499940395355, "eval_episode/reward_rate": 0.00558659217877095}
{"step": 50024, "time": 1879.1402163505554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1879.1471383571625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1879.1532368659973, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1879.161029100418, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1879.16703414917, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50024, "time": 1879.172958612442, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 50552, "time": 1895.9614737033844, "episode/length": 288.0, "episode/score": 0.05944256054695529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05944256054695529}
{"step": 50584, "time": 1896.9729146957397, "episode/length": 288.0, "episode/score": 0.04248883507227674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04248883507227674}
{"step": 50680, "time": 1900.0204572677612, "episode/length": 288.0, "episode/score": 0.06344871148783682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06344871148783682}
{"step": 50864, "time": 1906.082596540451, "episode/length": 288.0, "episode/score": 0.06456851129152597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06456851129152597}
{"step": 50864, "time": 1906.09113240242, "episode/length": 288.0, "episode/score": 0.030864445973321608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030864445973321608}
{"step": 51464, "time": 1925.0104863643646, "episode/length": 288.0, "episode/score": 0.06523914087929938, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06523914087929938}
{"step": 52184, "time": 1947.892173051834, "episode/length": 288.0, "episode/score": 0.07664799589193194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07664799589193194}
{"step": 52320, "time": 1952.4045038223267, "episode/length": 288.0, "episode/score": 0.05762061960760434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05762061960760434}
{"step": 52416, "time": 1955.4370031356812, "episode/length": 11.0, "episode/score": 0.970360650422549, "episode/reward_rate": 0.08333333333333333, "episode/intrinsic_return": 0.00473566315838525}
{"step": 52864, "time": 1969.6547751426697, "episode/length": 288.0, "episode/score": 0.080660982260369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.080660982260369}
{"step": 52896, "time": 1970.6744933128357, "episode/length": 288.0, "episode/score": 0.042903548989471574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042903548989471574}
{"step": 52992, "time": 1973.8264400959015, "episode/length": 288.0, "episode/score": 0.08153437365784555, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08153437365784555}
{"step": 53176, "time": 1979.428632259369, "episode/length": 288.0, "episode/score": 0.07861945092038525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07861945092038525}
{"step": 53176, "time": 1979.4366822242737, "episode/length": 288.0, "episode/score": 0.05995401002752487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05995401002752487}
{"step": 53776, "time": 1998.6231310367584, "episode/length": 288.0, "episode/score": 0.053229301707148124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053229301707148124}
{"step": 54168, "time": 2010.9695348739624, "episode/length": 123.0, "episode/score": 0.6542441511044927, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.038619098624465664}
{"step": 54496, "time": 2021.5205171108246, "episode/length": 288.0, "episode/score": 0.053809180079241514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053809180079241514}
{"step": 54728, "time": 2028.6453173160553, "episode/length": 288.0, "episode/score": 0.051635532397881434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051635532397881434}
{"step": 55176, "time": 2042.915313243866, "episode/length": 288.0, "episode/score": 0.08660527879285951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08660527879285951}
{"step": 55208, "time": 2043.9303889274597, "episode/length": 288.0, "episode/score": 0.05723411631387876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05723411631387876}
{"step": 55304, "time": 2046.9558753967285, "episode/length": 288.0, "episode/score": 0.059918877950906335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059918877950906335}
{"step": 55488, "time": 2053.0248939990997, "episode/length": 288.0, "episode/score": 0.073548487816538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.073548487816538}
{"step": 56088, "time": 2071.828530550003, "episode/length": 288.0, "episode/score": 0.07622713513201518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07622713513201518}
{"step": 56480, "time": 2084.434759616852, "episode/length": 288.0, "episode/score": 0.06820590473682842, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06820590473682842}
{"step": 56808, "time": 2094.670126914978, "episode/length": 288.0, "episode/score": 0.07901972268507507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07901972268507507}
{"step": 57040, "time": 2102.2121574878693, "episode/length": 288.0, "episode/score": 0.06502237762708774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06502237762708774}
{"step": 57488, "time": 2116.8923671245575, "episode/length": 288.0, "episode/score": 0.059850769815284366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059850769815284366}
{"step": 57520, "time": 2117.9053189754486, "episode/length": 288.0, "episode/score": 0.057982596287274646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057982596287274646}
{"step": 57616, "time": 2121.0317947864532, "episode/length": 288.0, "episode/score": 0.060335703430837384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060335703430837384}
{"step": 57800, "time": 2126.6812818050385, "episode/length": 288.0, "episode/score": 0.06436684970412898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06436684970412898}
{"step": 58400, "time": 2145.8434336185455, "episode/length": 288.0, "episode/score": 0.05810409754263901, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05810409754263901}
{"step": 58792, "time": 2158.1207807064056, "episode/length": 288.0, "episode/score": 0.06008868284601476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06008868284601476}
{"step": 59120, "time": 2168.729667901993, "episode/length": 288.0, "episode/score": 0.08184887608211966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08184887608211966}
{"step": 59352, "time": 2175.9137060642242, "episode/length": 288.0, "episode/score": 0.08513004872361307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08513004872361307}
{"step": 59800, "time": 2190.1968910694122, "episode/length": 288.0, "episode/score": 0.0626060382991227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0626060382991227}
{"step": 59832, "time": 2191.234104156494, "episode/length": 288.0, "episode/score": 0.09613479831176619, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09613479831176619}
{"step": 59928, "time": 2194.2533507347107, "episode/length": 288.0, "episode/score": 0.07295954304680663, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07295954304680663}
{"step": 60008, "time": 2202.850739002228, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.8583195209503, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.8648014068604, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.8711540699005, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.877729654312, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.883940219879, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.890058994293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60008, "time": 2202.8963873386383, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 60112, "time": 2206.41783952713, "episode/length": 288.0, "episode/score": 0.06802920164284387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06802920164284387}
{"step": 60712, "time": 2225.269368171692, "episode/length": 288.0, "episode/score": 0.05261333401381307, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05261333401381307}
{"step": 61080, "time": 2236.908800840378, "episode/length": 244.0, "episode/score": 0.30345089824248817, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.06595090238687362}
{"step": 61104, "time": 2237.8929069042206, "episode/length": 288.0, "episode/score": 0.028442655901869784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028442655901869784}
{"step": 61664, "time": 2255.6754043102264, "episode/length": 288.0, "episode/score": 0.06548434846251894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06548434846251894}
{"step": 61977, "time": 2266.307629585266, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9995641708374023, "train/action_min": 0.0, "train/action_std": 2.0011121723800898, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00032622566038753575, "train/actor_opt_grad_steps": 2815.0, "train/actor_opt_loss": 8.138825171937546, "train/adv_mag": 0.0012931079448511202, "train/adv_max": 0.0012931079448511202, "train/adv_mean": 0.0007245419997161662, "train/adv_min": 1.7932460953791935e-05, "train/adv_std": 0.00033872945156569284, "train/cont_avg": 0.9965159098307291, "train/cont_loss_mean": 0.023295836229105287, "train/cont_loss_std": 0.32439139532349753, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.69844627631338, "train/cont_pos_acc": 0.9999999850988388, "train/cont_pos_loss": 0.0034339993635512656, "train/cont_pred": 0.9965721794093648, "train/cont_rate": 0.9965159098307291, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.08565149503798845, "train/extr_critic_critic_opt_grad_steps": 2815.0, "train/extr_critic_critic_opt_loss": 11445.33354695638, "train/extr_critic_mag": 0.04488416636983553, "train/extr_critic_max": 0.04488416636983553, "train/extr_critic_mean": 0.044773814510942124, "train/extr_critic_min": 0.0447124590476354, "train/extr_critic_std": 2.4795795692963973e-05, "train/extr_return_normed_mag": 0.0025427486883321158, "train/extr_return_normed_max": 0.0025427486883321158, "train/extr_return_normed_mean": 0.002027744001679821, "train/extr_return_normed_min": 0.0013669409963767976, "train/extr_return_normed_std": 0.00033771531502679863, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.04601336097888028, "train/extr_return_raw_max": 0.04601336097888028, "train/extr_return_raw_mean": 0.045498358619321756, "train/extr_return_raw_min": 0.04483755328692496, "train/extr_return_raw_std": 0.00033771531578471087, "train/extr_reward_mag": 0.0002493467181921005, "train/extr_reward_max": 0.0002493467181921005, "train/extr_reward_mean": 0.00024907437462691934, "train/extr_reward_min": 0.00024867864946524304, "train/extr_reward_std": 1.0312430109733299e-07, "train/image_loss_mean": 0.2706162651690344, "train/image_loss_std": 0.0858804335584864, "train/model_loss_mean": 0.9055955257887641, "train/model_loss_std": 0.38728910812642425, "train/model_opt_grad_norm": 81.34488266706467, "train/model_opt_grad_steps": 2805.0, "train/model_opt_loss": 47.85939034819603, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 52.897135416666664, "train/policy_entropy_mag": 1.9458829530825217, "train/policy_entropy_max": 1.9458829530825217, "train/policy_entropy_mean": 1.9446805740396182, "train/policy_entropy_min": 1.9257242660969496, "train/policy_entropy_std": 0.0008335671658035911, "train/policy_logprob_mag": 2.238722794999679, "train/policy_logprob_max": -1.7001887373626232, "train/policy_logprob_mean": -1.9446858745068312, "train/policy_logprob_min": -2.238722794999679, "train/policy_logprob_std": 0.04923807920810456, "train/policy_randomness_mag": 0.9999860851094127, "train/policy_randomness_max": 0.9999860851094127, "train/policy_randomness_mean": 0.9993681780373057, "train/policy_randomness_min": 0.9896265662585696, "train/policy_randomness_std": 0.0004283688038716112, "train/post_ent_mag": 58.87177560726801, "train/post_ent_max": 58.87177560726801, "train/post_ent_mean": 58.5626850326856, "train/post_ent_min": 58.53233907620112, "train/post_ent_std": 0.047929852871069066, "train/prior_ent_mag": 62.90451308091482, "train/prior_ent_max": 62.90451308091482, "train/prior_ent_mean": 62.499060889085136, "train/prior_ent_min": 62.290030340353645, "train/prior_ent_std": 0.0990719121764414, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0003056176369682362, "train/reward_loss_mean": 0.011683405995427165, "train/reward_loss_std": 0.0775336031219922, "train/reward_max_data": 0.11728081975403863, "train/reward_max_pred": 0.0002488940954208374, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009571521295583807, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.72213784456253, "train/reward_pred": 0.0002485318600520259, "train/reward_rate": 0.00021870930989583334, "train_stats/mean_log_entropy": 1.9359050664034756, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02560122311115265, "report/cont_loss_std": 0.3550175428390503, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.694775581359863, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0033691611606627703, "report/cont_pred": 0.9966364502906799, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25046831369400024, "report/image_loss_std": 0.08596547693014145, "report/model_loss_mean": 0.8863681554794312, "report/model_loss_std": 0.3665427565574646, "report/post_ent_mag": 50.63102340698242, "report/post_ent_max": 50.63102340698242, "report/post_ent_mean": 50.243797302246094, "report/post_ent_min": 50.21038818359375, "report/post_ent_std": 0.06213822588324547, "report/prior_ent_mag": 51.72344207763672, "report/prior_ent_max": 51.72344207763672, "report/prior_ent_mean": 51.62892150878906, "report/prior_ent_min": 50.733821868896484, "report/prior_ent_std": 0.15352089703083038, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002072075876640156, "report/reward_loss_mean": 0.010298581793904305, "report/reward_loss_std": 0.016923118382692337, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002570152282714844, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010298582725226879, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002570152282714844, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.003369161393493414, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.003369161393493414, "eval/cont_pred": 0.9966364502906799, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24849633872509003, "eval/image_loss_std": 0.08055867999792099, "eval/model_loss_mean": 0.85328209400177, "eval/model_loss_std": 0.08055867999792099, "eval/post_ent_mag": 50.63102340698242, "eval/post_ent_max": 50.63102340698242, "eval/post_ent_mean": 50.24104309082031, "eval/post_ent_min": 50.20802307128906, "eval/post_ent_std": 0.05569899454712868, "eval/prior_ent_mag": 51.726375579833984, "eval/prior_ent_max": 51.726375579833984, "eval/prior_ent_mean": 51.636871337890625, "eval/prior_ent_min": 50.733821868896484, "eval/prior_ent_std": 0.13690948486328125, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.001416570506989956, "eval/reward_loss_std": 2.0366599073895486e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002570152282714844, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.001416570506989956, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002570152282714844, "eval/reward_rate": 0.0, "replay/size": 61473.0, "replay/inserts": 30816.0, "replay/samples": 30816.0, "replay/insert_wait_avg": 1.3742414095196273e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.194542561983641e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17240.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2171859697212123e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.475214958190918e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1645607948303, "timer/env.step_count": 3852.0, "timer/env.step_total": 38.46588158607483, "timer/env.step_frac": 0.03845955265152168, "timer/env.step_avg": 0.00998595056751683, "timer/env.step_min": 0.008516311645507812, "timer/env.step_max": 0.04463076591491699, "timer/replay._sample_count": 30816.0, "timer/replay._sample_total": 15.42511773109436, "timer/replay._sample_frac": 0.015422579779107576, "timer/replay._sample_avg": 0.0005005554819280361, "timer/replay._sample_min": 0.00035381317138671875, "timer/replay._sample_max": 0.023222923278808594, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4719.0, "timer/agent.policy_total": 47.77215766906738, "timer/agent.policy_frac": 0.04776429753829997, "timer/agent.policy_avg": 0.01012336462578245, "timer/agent.policy_min": 0.008570432662963867, "timer/agent.policy_max": 0.09876322746276855, "timer/dataset_train_count": 1926.0, "timer/dataset_train_total": 0.21141481399536133, "timer/dataset_train_frac": 0.00021138002912975647, "timer/dataset_train_avg": 0.00010976885461856767, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.00029397010803222656, "timer/agent.train_count": 1926.0, "timer/agent.train_total": 863.519894361496, "timer/agent.train_frac": 0.8633778162218196, "timer/agent.train_avg": 0.4483488548086687, "timer/agent.train_min": 0.43850159645080566, "timer/agent.train_max": 0.6027989387512207, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4663963317871094, "timer/agent.report_frac": 0.0004663195938640981, "timer/agent.report_avg": 0.2331981658935547, "timer/agent.report_min": 0.22299623489379883, "timer/agent.report_max": 0.24340009689331055, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.194283306161162e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 30.810417107499234}
{"step": 62112, "time": 2270.5819702148438, "episode/length": 288.0, "episode/score": 0.057963910887792736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057963910887792736}
{"step": 62144, "time": 2271.734838485718, "episode/length": 288.0, "episode/score": 0.06446016128023757, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06446016128023757}
{"step": 62240, "time": 2274.7715911865234, "episode/length": 288.0, "episode/score": 0.060554839323913257, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060554839323913257}
{"step": 62424, "time": 2280.3150568008423, "episode/length": 288.0, "episode/score": 0.04806927395762273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04806927395762273}
{"step": 62648, "time": 2287.3468205928802, "episode/length": 50.0, "episode/score": 0.8663425702653456, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.022592541627176388}
{"step": 63024, "time": 2299.3443298339844, "episode/length": 288.0, "episode/score": 0.05832436480957881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05832436480957881}
{"step": 63392, "time": 2310.9613580703735, "episode/length": 288.0, "episode/score": 0.05395298909351709, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05395298909351709}
{"step": 63416, "time": 2311.5060436725616, "episode/length": 288.0, "episode/score": 0.06210021954402123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06210021954402123}
{"step": 63976, "time": 2329.171255350113, "episode/length": 288.0, "episode/score": 0.0590098322498136, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0590098322498136}
{"step": 64424, "time": 2343.362323999405, "episode/length": 288.0, "episode/score": 0.057379211542468056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057379211542468056}
{"step": 64456, "time": 2344.3771991729736, "episode/length": 288.0, "episode/score": 0.07791915439281638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07791915439281638}
{"step": 64736, "time": 2353.3941888809204, "episode/length": 288.0, "episode/score": 0.0601936662216076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0601936662216076}
{"step": 64960, "time": 2360.488827228546, "episode/length": 288.0, "episode/score": 0.07544570393480399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07544570393480399}
{"step": 65336, "time": 2372.196402311325, "episode/length": 288.0, "episode/score": 0.06280612961063525, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06280612961063525}
{"step": 65704, "time": 2384.2021152973175, "episode/length": 288.0, "episode/score": 0.06147293110049645, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06147293110049645}
{"step": 65728, "time": 2385.2091765403748, "episode/length": 288.0, "episode/score": 0.04636754416000599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04636754416000599}
{"step": 66288, "time": 2402.796301841736, "episode/length": 288.0, "episode/score": 0.06802538504655331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06802538504655331}
{"step": 66736, "time": 2416.864198207855, "episode/length": 288.0, "episode/score": 0.04689990276199296, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04689990276199296}
{"step": 66768, "time": 2417.8765835762024, "episode/length": 288.0, "episode/score": 0.049503599280342314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049503599280342314}
{"step": 67048, "time": 2426.5508711338043, "episode/length": 288.0, "episode/score": 0.05480666920686872, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05480666920686872}
{"step": 67272, "time": 2433.574951171875, "episode/length": 288.0, "episode/score": 0.07552361143268627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07552361143268627}
{"step": 67648, "time": 2445.6365411281586, "episode/length": 288.0, "episode/score": 0.06371842269300032, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06371842269300032}
{"step": 68016, "time": 2457.319603919983, "episode/length": 288.0, "episode/score": 0.09049089774123331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09049089774123331}
{"step": 68040, "time": 2457.8609008789062, "episode/length": 288.0, "episode/score": 0.06518907097580495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06518907097580495}
{"step": 68600, "time": 2475.4233872890472, "episode/length": 288.0, "episode/score": 0.07316395323704228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07316395323704228}
{"step": 69048, "time": 2489.540952205658, "episode/length": 288.0, "episode/score": 0.07018169998679014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07018169998679014}
{"step": 69080, "time": 2490.5611097812653, "episode/length": 288.0, "episode/score": 0.08183096413097246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08183096413097246}
{"step": 69360, "time": 2499.582350730896, "episode/length": 288.0, "episode/score": 0.0709400167449985, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0709400167449985}
{"step": 69584, "time": 2506.6562979221344, "episode/length": 288.0, "episode/score": 0.04594837673954544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04594837673954544}
{"step": 69960, "time": 2518.3945813179016, "episode/length": 288.0, "episode/score": 0.08121435332702731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08121435332702731}
{"step": 70096, "time": 2528.686433315277, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.6939833164215, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.7004857063293, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.706791639328, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.7130823135376, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.719467163086, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.7256977558136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70096, "time": 2528.7321791648865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 70328, "time": 2535.7820415496826, "episode/length": 288.0, "episode/score": 0.06104899341869441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06104899341869441}
{"step": 70352, "time": 2536.7780034542084, "episode/length": 288.0, "episode/score": 0.06418295974560806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06418295974560806}
{"step": 70912, "time": 2554.379175424576, "episode/length": 288.0, "episode/score": 0.06330208687273853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06330208687273853}
{"step": 71360, "time": 2568.4695041179657, "episode/length": 288.0, "episode/score": 0.08080461377539905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08080461377539905}
{"step": 71392, "time": 2569.483987569809, "episode/length": 288.0, "episode/score": 0.06929534641841428, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06929534641841428}
{"step": 71672, "time": 2578.1171128749847, "episode/length": 288.0, "episode/score": 0.06020258815658508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06020258815658508}
{"step": 71896, "time": 2585.172117471695, "episode/length": 288.0, "episode/score": 0.07106671693452427, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07106671693452427}
{"step": 72272, "time": 2597.2470703125, "episode/length": 288.0, "episode/score": 0.06443404458343593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06443404458343593}
{"step": 72640, "time": 2608.87931060791, "episode/length": 288.0, "episode/score": 0.06893546483979662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06893546483979662}
{"step": 72664, "time": 2609.414150953293, "episode/length": 288.0, "episode/score": 0.1010268821171394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1010268821171394}
{"step": 73224, "time": 2626.9861929416656, "episode/length": 288.0, "episode/score": 0.09027371451009003, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09027371451009003}
{"step": 73672, "time": 2641.129046678543, "episode/length": 288.0, "episode/score": 0.06270341480706065, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06270341480706065}
{"step": 73704, "time": 2642.2022562026978, "episode/length": 288.0, "episode/score": 0.04841766694198668, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04841766694198668}
{"step": 73984, "time": 2651.8720054626465, "episode/length": 288.0, "episode/score": 0.06246228723398417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06246228723398417}
{"step": 74208, "time": 2658.9757330417633, "episode/length": 288.0, "episode/score": 0.05917352607866633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05917352607866633}
{"step": 74584, "time": 2670.775494337082, "episode/length": 288.0, "episode/score": 0.03721467996422234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03721467996422234}
{"step": 74952, "time": 2682.4189116954803, "episode/length": 288.0, "episode/score": 0.06846267122523386, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06846267122523386}
{"step": 74976, "time": 2683.4037477970123, "episode/length": 288.0, "episode/score": 0.051609136757406304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051609136757406304}
{"step": 75536, "time": 2701.1850214004517, "episode/length": 288.0, "episode/score": 0.0678611826833162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0678611826833162}
{"step": 75984, "time": 2715.3430876731873, "episode/length": 288.0, "episode/score": 0.0707028719605205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0707028719605205}
{"step": 76016, "time": 2716.356728553772, "episode/length": 288.0, "episode/score": 0.06740678622026053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06740678622026053}
{"step": 76296, "time": 2725.1157219409943, "episode/length": 288.0, "episode/score": 0.07056491009751653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07056491009751653}
{"step": 76520, "time": 2732.1540627479553, "episode/length": 288.0, "episode/score": 0.07407237350184914, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07407237350184914}
{"step": 76896, "time": 2744.2299194335938, "episode/length": 288.0, "episode/score": 0.07826666156842066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07826666156842066}
{"step": 77264, "time": 2755.992719888687, "episode/length": 288.0, "episode/score": 0.06724860454903592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06724860454903592}
{"step": 77288, "time": 2756.535953760147, "episode/length": 288.0, "episode/score": 0.06941065560158677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06941065560158677}
{"step": 77848, "time": 2774.163098335266, "episode/length": 288.0, "episode/score": 0.06465480484359887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06465480484359887}
{"step": 78296, "time": 2788.5035026073456, "episode/length": 288.0, "episode/score": 0.08260522120974656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08260522120974656}
{"step": 78328, "time": 2789.525588274002, "episode/length": 288.0, "episode/score": 0.08220645289577533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08220645289577533}
{"step": 78608, "time": 2798.6028349399567, "episode/length": 288.0, "episode/score": 0.08332675983854188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08332675983854188}
{"step": 78832, "time": 2805.6920125484467, "episode/length": 288.0, "episode/score": 0.07393147580171444, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07393147580171444}
{"step": 79208, "time": 2817.5226645469666, "episode/length": 288.0, "episode/score": 0.05679193977346131, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05679193977346131}
{"step": 79576, "time": 2829.788476705551, "episode/length": 288.0, "episode/score": 0.05680256062692024, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05680256062692024}
{"step": 79600, "time": 2830.7693104743958, "episode/length": 288.0, "episode/score": 0.03955528867118119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03955528867118119}
{"step": 80080, "time": 2850.99205493927, "eval_episode/length": 266.0, "eval_episode/score": 0.16875000298023224, "eval_episode/reward_rate": 0.003745318352059925}
{"step": 80080, "time": 2851.4141993522644, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2851.4230999946594, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2851.429470539093, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2851.435661792755, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2851.4417045116425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2851.447810649872, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80080, "time": 2851.4543521404266, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 80160, "time": 2853.9982986450195, "episode/length": 288.0, "episode/score": 0.04399390118385327, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04399390118385327}
{"step": 80608, "time": 2868.2030050754547, "episode/length": 288.0, "episode/score": 0.06738738976747527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06738738976747527}
{"step": 80640, "time": 2869.2193932533264, "episode/length": 288.0, "episode/score": 0.07279817663726362, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07279817663726362}
{"step": 80920, "time": 2877.9796674251556, "episode/length": 288.0, "episode/score": 0.05648409301454649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05648409301454649}
{"step": 81144, "time": 2885.0593757629395, "episode/length": 288.0, "episode/score": 0.08004626617235999, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08004626617235999}
{"step": 81520, "time": 2897.1377518177032, "episode/length": 288.0, "episode/score": 0.07327602592857829, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07327602592857829}
{"step": 81888, "time": 2908.8959136009216, "episode/length": 288.0, "episode/score": 0.045585694900353246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045585694900353246}
{"step": 81912, "time": 2909.4412438869476, "episode/length": 288.0, "episode/score": 0.06724931359656239, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06724931359656239}
{"step": 82472, "time": 2927.642944574356, "episode/length": 288.0, "episode/score": 0.09087954148407107, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09087954148407107}
{"step": 82592, "time": 2931.7683005332947, "episode/length": 243.0, "episode/score": 0.3091513010047038, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.06852630812932148}
{"step": 82920, "time": 2941.8461258411407, "episode/length": 288.0, "episode/score": 0.05484748808731865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05484748808731865}
{"step": 83232, "time": 2951.939530134201, "episode/length": 288.0, "episode/score": 0.05609236756811242, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05609236756811242}
{"step": 83456, "time": 2959.0419158935547, "episode/length": 288.0, "episode/score": 0.0689227888736923, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0689227888736923}
{"step": 83832, "time": 2970.8904888629913, "episode/length": 288.0, "episode/score": 0.03801519599903713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03801519599903713}
{"step": 84200, "time": 2982.610214948654, "episode/length": 288.0, "episode/score": 0.053647129463001875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053647129463001875}
{"step": 84224, "time": 2983.604343891144, "episode/length": 288.0, "episode/score": 0.06029686478916574, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06029686478916574}
{"step": 84784, "time": 3001.46395111084, "episode/length": 288.0, "episode/score": 0.03474569504467695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03474569504467695}
{"step": 84904, "time": 3005.0399239063263, "episode/length": 288.0, "episode/score": 0.050575275723332425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050575275723332425}
{"step": 85232, "time": 3015.6301367282867, "episode/length": 288.0, "episode/score": 0.05193693864342208, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05193693864342208}
{"step": 85544, "time": 3025.3304781913757, "episode/length": 288.0, "episode/score": 0.024415030394749238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024415030394749238}
{"step": 85768, "time": 3032.3942053318024, "episode/length": 288.0, "episode/score": 0.06833292889962195, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06833292889962195}
{"step": 86144, "time": 3044.463450908661, "episode/length": 288.0, "episode/score": 0.05517521890317312, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05517521890317312}
{"step": 86512, "time": 3056.2218260765076, "episode/length": 288.0, "episode/score": 0.04008724399739094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04008724399739094}
{"step": 86536, "time": 3056.7720396518707, "episode/length": 288.0, "episode/score": 0.04700900357482851, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04700900357482851}
{"step": 87096, "time": 3074.3584032058716, "episode/length": 288.0, "episode/score": 0.03588009543690873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03588009543690873}
{"step": 87216, "time": 3078.3548727035522, "episode/length": 288.0, "episode/score": 0.052561206646799974, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052561206646799974}
{"step": 87544, "time": 3088.6417615413666, "episode/length": 288.0, "episode/score": 0.06880408363701918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06880408363701918}
{"step": 87856, "time": 3098.7138016223907, "episode/length": 288.0, "episode/score": 0.05336332480712258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05336332480712258}
{"step": 88080, "time": 3105.8010680675507, "episode/length": 288.0, "episode/score": 0.05477751937399944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05477751937399944}
{"step": 88456, "time": 3117.5755836963654, "episode/length": 288.0, "episode/score": 0.04959947191889569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04959947191889569}
{"step": 88568, "time": 3121.1204419136047, "episode/length": 253.0, "episode/score": 0.25019972450658656, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.04082473163120426}
{"step": 88824, "time": 3129.2744381427765, "episode/length": 288.0, "episode/score": 0.03572056728688722, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03572056728688722}
{"step": 89408, "time": 3148.0783591270447, "episode/length": 288.0, "episode/score": 0.048085887120919324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048085887120919324}
{"step": 89528, "time": 3151.650047302246, "episode/length": 288.0, "episode/score": 0.04459784106410325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04459784106410325}
{"step": 89856, "time": 3162.2137429714203, "episode/length": 288.0, "episode/score": 0.0634527999667398, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0634527999667398}
{"step": 90064, "time": 3171.0411422252655, "eval_episode/length": 111.0, "eval_episode/score": 0.653124988079071, "eval_episode/reward_rate": 0.008928571428571428}
{"step": 90064, "time": 3174.907327890396, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3174.91433429718, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3174.920530796051, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3174.9265365600586, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3174.932400226593, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3174.9383957386017, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90064, "time": 3174.9447112083435, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 90168, "time": 3178.482770681381, "episode/length": 288.0, "episode/score": 0.027651586776642034, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027651586776642034}
{"step": 90232, "time": 3180.513799905777, "episode/length": 207.0, "episode/score": 0.3757775962657206, "episode/reward_rate": 0.004807692307692308, "episode/intrinsic_return": 0.02265259112016338}
{"step": 90392, "time": 3185.584528207779, "episode/length": 288.0, "episode/score": 0.03686051253359324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03686051253359324}
{"step": 90768, "time": 3197.660511493683, "episode/length": 288.0, "episode/score": 0.03774619769990295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03774619769990295}
{"step": 91136, "time": 3209.3671181201935, "episode/length": 288.0, "episode/score": 0.030145381450751074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.030145381450751074}
{"step": 91720, "time": 3227.5747747421265, "episode/length": 288.0, "episode/score": 0.04519436016668976, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04519436016668976}
{"step": 91840, "time": 3231.7247002124786, "episode/length": 288.0, "episode/score": 0.0478740546945744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0478740546945744}
{"step": 92168, "time": 3241.820070743561, "episode/length": 288.0, "episode/score": 0.07405412314244586, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07405412314244586}
{"step": 92480, "time": 3251.912056207657, "episode/length": 288.0, "episode/score": 0.03130516291720653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03130516291720653}
{"step": 92544, "time": 3253.9183015823364, "episode/length": 288.0, "episode/score": 0.05157139288648693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05157139288648693}
{"step": 92704, "time": 3258.970427751541, "episode/length": 288.0, "episode/score": 0.06008555807055416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06008555807055416}
{"step": 92921, "time": 3266.6783061027527, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 3.0020062948010633, "train/action_min": 0.0, "train/action_std": 1.9996652744480015, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0001814970025791518, "train/actor_opt_grad_steps": 4745.0, "train/actor_opt_loss": 2.5905017852495167, "train/adv_mag": 0.0008221673443145358, "train/adv_max": 0.0008221673443145358, "train/adv_mean": 0.00043387228303340495, "train/adv_min": -5.0873236404251805e-05, "train/adv_std": 0.00020882140575174827, "train/cont_avg": 0.9965467944587629, "train/cont_loss_mean": 0.023088678626401217, "train/cont_loss_std": 0.31880922401179895, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.6570678651332855, "train/cont_pos_acc": 0.9999999861741803, "train/cont_pos_loss": 0.0035502892407617464, "train/cont_pred": 0.9964561745063546, "train/cont_rate": 0.9965467944587629, "train/dyn_loss_mean": 1.0000000012289618, "train/dyn_loss_std": 4.425966891954586e-08, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.03466491413197106, "train/extr_critic_critic_opt_grad_steps": 4745.0, "train/extr_critic_critic_opt_loss": 13237.922609938789, "train/extr_critic_mag": 0.06815437373426772, "train/extr_critic_max": 0.06815437373426772, "train/extr_critic_mean": 0.06801996049807243, "train/extr_critic_min": 0.06794554548165233, "train/extr_critic_std": 3.0558039595347164e-05, "train/extr_return_normed_mag": 0.0015736694073246926, "train/extr_return_normed_max": 0.0015736694073246926, "train/extr_return_normed_mean": 0.00124318152036009, "train/extr_return_normed_min": 0.0008161695309213756, "train/extr_return_normed_std": 0.00020504840242360797, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.06878427729087393, "train/extr_return_raw_max": 0.06878427729087393, "train/extr_return_raw_mean": 0.06845379286666506, "train/extr_return_raw_min": 0.06802677741447061, "train/extr_return_raw_std": 0.0002050484010921827, "train/extr_reward_mag": 0.00027322953509301254, "train/extr_reward_max": 0.00027322953509301254, "train/extr_reward_mean": 0.00027302590219217555, "train/extr_reward_min": 0.0002727232028528587, "train/extr_reward_std": 7.570809062137145e-08, "train/image_loss_mean": 0.26104387425884756, "train/image_loss_std": 0.08402277544601676, "train/model_loss_mean": 0.8956488085161779, "train/model_loss_std": 0.3691345898376912, "train/model_opt_grad_norm": 66.54793633136552, "train/model_opt_grad_steps": 4735.0, "train/model_opt_loss": 181.7478587750307, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 202.96391752577318, "train/policy_entropy_mag": 1.9458965444073235, "train/policy_entropy_max": 1.9458965444073235, "train/policy_entropy_mean": 1.9452363240350152, "train/policy_entropy_min": 1.9348508986001163, "train/policy_entropy_std": 0.00047112129956901496, "train/policy_logprob_mag": 2.155405118293369, "train/policy_logprob_max": -1.757952693196916, "train/policy_logprob_mean": -1.9452252019311964, "train/policy_logprob_min": -2.155405118293369, "train/policy_logprob_std": 0.03658779635641378, "train/policy_randomness_mag": 0.9999930698847034, "train/policy_randomness_max": 0.9999930698847034, "train/policy_randomness_mean": 0.9996537805832538, "train/policy_randomness_min": 0.9943167284591911, "train/policy_randomness_std": 0.00024210846271502699, "train/post_ent_mag": 44.51501376358504, "train/post_ent_max": 44.51501376358504, "train/post_ent_mean": 44.25236745224785, "train/post_ent_min": 44.22335133110125, "train/post_ent_std": 0.03934664439563591, "train/prior_ent_mag": 51.629655838012695, "train/prior_ent_max": 51.629655838012695, "train/prior_ent_mean": 51.54753266167395, "train/prior_ent_min": 50.732868410877344, "train/prior_ent_std": 0.14377591232817197, "train/rep_loss_mean": 1.0000000012289618, "train/rep_loss_std": 4.425966891954586e-08, "train/reward_avg": 0.00028758682355587133, "train/reward_loss_mean": 0.011516236397677782, "train/reward_loss_std": 0.06250786237879512, "train/reward_max_data": 0.08446842944609557, "train/reward_max_pred": 0.00027312384438268916, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009873793954893793, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.28954444393035, "train/reward_pred": 0.0002727218670770526, "train/reward_rate": 0.000176183956185567, "train_stats/mean_log_entropy": 1.9382138208909467, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020014122128486633, "report/cont_loss_std": 0.31436067819595337, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.819380760192871, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0029738624580204487, "report/cont_pred": 0.9970303177833557, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2677482068538666, "report/image_loss_std": 0.08236218988895416, "report/model_loss_mean": 0.8976044058799744, "report/model_loss_std": 0.32697662711143494, "report/post_ent_mag": 41.08805847167969, "report/post_ent_max": 41.08805847167969, "report/post_ent_mean": 40.964263916015625, "report/post_ent_min": 40.91368865966797, "report/post_ent_std": 0.019182248041033745, "report/prior_ent_mag": 50.20967102050781, "report/prior_ent_max": 50.20967102050781, "report/prior_ent_mean": 50.13235092163086, "report/prior_ent_min": 49.41986083984375, "report/prior_ent_std": 0.1297702193260193, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001990343735087663, "report/reward_loss_mean": 0.009842048399150372, "report/reward_loss_std": 0.016337767243385315, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002579689025878906, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009842049330472946, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00025701895356178284, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0029738624580204487, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0029738624580204487, "eval/cont_pred": 0.9970303177833557, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24266932904720306, "eval/image_loss_std": 0.07261990755796432, "eval/model_loss_mean": 0.8470418453216553, "eval/model_loss_std": 0.07261992990970612, "eval/post_ent_mag": 41.08879852294922, "eval/post_ent_max": 41.08879852294922, "eval/post_ent_mean": 40.96449279785156, "eval/post_ent_min": 40.91995620727539, "eval/post_ent_std": 0.017815744504332542, "eval/prior_ent_mag": 50.2054443359375, "eval/prior_ent_max": 50.2054443359375, "eval/prior_ent_mean": 50.13706970214844, "eval/prior_ent_min": 49.41986083984375, "eval/prior_ent_std": 0.118573397397995, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0013985787518322468, "eval/reward_loss_std": 2.834890722169803e-07, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002579689025878906, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0013985787518322468, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002570180222392082, "eval/reward_rate": 0.0, "replay/size": 92417.0, "replay/inserts": 30944.0, "replay/samples": 30944.0, "replay/insert_wait_avg": 1.4137072178545757e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.075454373640753e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 24176.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2392197513250331e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1920928955078125e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3533627986908, "timer/env.step_count": 3868.0, "timer/env.step_total": 38.585715532302856, "timer/env.step_frac": 0.03857208559218666, "timer/env.step_avg": 0.009975624491288226, "timer/env.step_min": 0.008432149887084961, "timer/env.step_max": 0.0564875602722168, "timer/replay._sample_count": 30944.0, "timer/replay._sample_total": 15.792088747024536, "timer/replay._sample_frac": 0.015786510381534554, "timer/replay._sample_avg": 0.0005103441296220442, "timer/replay._sample_min": 0.00034046173095703125, "timer/replay._sample_max": 0.022718191146850586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4735.0, "timer/agent.policy_total": 48.28598165512085, "timer/agent.policy_frac": 0.04826892521261792, "timer/agent.policy_avg": 0.010197673000025522, "timer/agent.policy_min": 0.008779287338256836, "timer/agent.policy_max": 0.0931708812713623, "timer/dataset_train_count": 1934.0, "timer/dataset_train_total": 0.2199859619140625, "timer/dataset_train_frac": 0.00021990825451779087, "timer/dataset_train_avg": 0.00011374661939713676, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0010802745819091797, "timer/agent.train_count": 1934.0, "timer/agent.train_total": 863.5006127357483, "timer/agent.train_frac": 0.8631955915257092, "timer/agent.train_avg": 0.4464842878675017, "timer/agent.train_min": 0.4340665340423584, "timer/agent.train_max": 0.973395586013794, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4820983409881592, "timer/agent.report_frac": 0.00048192804554521773, "timer/agent.report_avg": 0.2410491704940796, "timer/agent.report_min": 0.23440861701965332, "timer/agent.report_max": 0.24768972396850586, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.744529724121094e-05, "timer/dataset_eval_frac": 4.742853776037012e-08, "timer/dataset_eval_avg": 4.744529724121094e-05, "timer/dataset_eval_min": 4.744529724121094e-05, "timer/dataset_eval_max": 4.744529724121094e-05, "fps": 30.932539417682868}
{"step": 93080, "time": 3271.4548585414886, "episode/length": 288.0, "episode/score": 0.05009013524455952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05009013524455952}
{"step": 93448, "time": 3283.13427066803, "episode/length": 288.0, "episode/score": 0.036915192016095943, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036915192016095943}
{"step": 94032, "time": 3301.977400302887, "episode/length": 288.0, "episode/score": 0.04043120866275274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04043120866275274}
{"step": 94152, "time": 3305.53395318985, "episode/length": 288.0, "episode/score": 0.04619097563161745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04619097563161745}
{"step": 94480, "time": 3316.091645002365, "episode/length": 288.0, "episode/score": 0.053769127672694594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053769127672694594}
{"step": 94792, "time": 3325.8047709465027, "episode/length": 288.0, "episode/score": 0.05076930791568657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05076930791568657}
{"step": 94856, "time": 3327.8309054374695, "episode/length": 288.0, "episode/score": 0.06312527675551394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06312527675551394}
{"step": 95016, "time": 3332.8657281398773, "episode/length": 288.0, "episode/score": 0.05119525454924201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05119525454924201}
{"step": 95392, "time": 3344.886347770691, "episode/length": 288.0, "episode/score": 0.061983311824576504, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061983311824576504}
{"step": 95760, "time": 3356.5210888385773, "episode/length": 288.0, "episode/score": 0.05651882336195513, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05651882336195513}
{"step": 96344, "time": 3374.6680517196655, "episode/length": 288.0, "episode/score": 0.05669763152323526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05669763152323526}
{"step": 96464, "time": 3378.6601116657257, "episode/length": 288.0, "episode/score": 0.04241745211878367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04241745211878367}
{"step": 96792, "time": 3388.841461658478, "episode/length": 288.0, "episode/score": 0.034648107071575396, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034648107071575396}
{"step": 97104, "time": 3398.8716287612915, "episode/length": 288.0, "episode/score": 0.06354888412758442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06354888412758442}
{"step": 97168, "time": 3400.8850071430206, "episode/length": 288.0, "episode/score": 0.06122300506221734, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06122300506221734}
{"step": 97328, "time": 3405.9164295196533, "episode/length": 288.0, "episode/score": 0.04642886192321782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04642886192321782}
{"step": 97704, "time": 3417.607565879822, "episode/length": 288.0, "episode/score": 0.04025023992301158, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04025023992301158}
{"step": 98072, "time": 3429.226893901825, "episode/length": 288.0, "episode/score": 0.058461860094126905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058461860094126905}
{"step": 98656, "time": 3448.4312727451324, "episode/length": 288.0, "episode/score": 0.06476819781492793, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06476819781492793}
{"step": 98776, "time": 3451.99569606781, "episode/length": 288.0, "episode/score": 0.03712966871346168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03712966871346168}
{"step": 99104, "time": 3462.5710129737854, "episode/length": 288.0, "episode/score": 0.05758758207528558, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05758758207528558}
{"step": 99416, "time": 3472.3460624217987, "episode/length": 288.0, "episode/score": 0.04699339835335081, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04699339835335081}
{"step": 99480, "time": 3474.3820054531097, "episode/length": 288.0, "episode/score": 0.06389650615066955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06389650615066955}
{"step": 99640, "time": 3479.415378332138, "episode/length": 288.0, "episode/score": 0.042654595938884654, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042654595938884654}
{"step": 100016, "time": 3491.4353427886963, "episode/length": 288.0, "episode/score": 0.06410163461271168, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06410163461271168}
{"step": 100048, "time": 3495.7597699165344, "eval_episode/length": 174.0, "eval_episode/score": 0.45625001192092896, "eval_episode/reward_rate": 0.005714285714285714}
{"step": 100048, "time": 3497.8169469833374, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3497.825261592865, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3497.8316118717194, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3497.838022708893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3497.8443615436554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3497.8505651950836, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100048, "time": 3497.8568596839905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 100384, "time": 3508.544063806534, "episode/length": 288.0, "episode/score": 0.0560802119481707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0560802119481707}
{"step": 100968, "time": 3526.7394585609436, "episode/length": 288.0, "episode/score": 0.049686390309759076, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049686390309759076}
{"step": 101088, "time": 3530.8069229125977, "episode/length": 288.0, "episode/score": 0.0566454044794682, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0566454044794682}
{"step": 101416, "time": 3541.0128173828125, "episode/length": 288.0, "episode/score": 0.04134303434271658, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04134303434271658}
{"step": 101728, "time": 3551.077177286148, "episode/length": 288.0, "episode/score": 0.057633095209695284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057633095209695284}
{"step": 101792, "time": 3553.0931465625763, "episode/length": 288.0, "episode/score": 0.06929183830989416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06929183830989416}
{"step": 101952, "time": 3558.1404654979706, "episode/length": 288.0, "episode/score": 0.054693790971739986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054693790971739986}
{"step": 102328, "time": 3569.81515955925, "episode/length": 288.0, "episode/score": 0.054629929789101084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054629929789101084}
{"step": 102696, "time": 3581.3792312145233, "episode/length": 288.0, "episode/score": 0.06166293478133866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06166293478133866}
{"step": 103280, "time": 3600.0499320030212, "episode/length": 288.0, "episode/score": 0.057920514869749695, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057920514869749695}
{"step": 103400, "time": 3603.600673675537, "episode/length": 288.0, "episode/score": 0.04898641574948215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04898641574948215}
{"step": 103712, "time": 3613.6342470645905, "episode/length": 126.0, "episode/score": 0.6346280622507976, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.028378045533557383}
{"step": 103728, "time": 3614.1451988220215, "episode/length": 288.0, "episode/score": 0.04969842511395939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04969842511395939}
{"step": 104040, "time": 3623.8732800483704, "episode/length": 288.0, "episode/score": 0.04327339726259538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04327339726259538}
{"step": 104104, "time": 3625.9060714244843, "episode/length": 288.0, "episode/score": 0.04613966827649563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04613966827649563}
{"step": 104264, "time": 3630.9591937065125, "episode/length": 288.0, "episode/score": 0.06327357563064595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06327357563064595}
{"step": 104640, "time": 3643.0312099456787, "episode/length": 288.0, "episode/score": 0.05497321855533244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05497321855533244}
{"step": 105592, "time": 3672.889020204544, "episode/length": 288.0, "episode/score": 0.04191525316251443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04191525316251443}
{"step": 105712, "time": 3676.884068250656, "episode/length": 288.0, "episode/score": 0.06386753466904338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06386753466904338}
{"step": 106024, "time": 3686.5930740833282, "episode/length": 288.0, "episode/score": 0.03327530121001132, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03327530121001132}
{"step": 106040, "time": 3687.122405052185, "episode/length": 288.0, "episode/score": 0.0726569767135743, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0726569767135743}
{"step": 106352, "time": 3697.190702676773, "episode/length": 288.0, "episode/score": 0.05666185026431947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05666185026431947}
{"step": 106416, "time": 3699.2178337574005, "episode/length": 288.0, "episode/score": 0.05547558117844176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05547558117844176}
{"step": 106576, "time": 3704.798520565033, "episode/length": 288.0, "episode/score": 0.06192407651853671, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06192407651853671}
{"step": 106952, "time": 3716.5234241485596, "episode/length": 288.0, "episode/score": 0.04564637731752441, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04564637731752441}
{"step": 107904, "time": 3746.887853384018, "episode/length": 288.0, "episode/score": 0.05521821143943839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05521821143943839}
{"step": 108024, "time": 3750.4460396766663, "episode/length": 288.0, "episode/score": 0.055369062986102335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055369062986102335}
{"step": 108336, "time": 3760.515428543091, "episode/length": 288.0, "episode/score": 0.046289106272510594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046289106272510594}
{"step": 108352, "time": 3761.0255827903748, "episode/length": 288.0, "episode/score": 0.061151204321774344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061151204321774344}
{"step": 108664, "time": 3770.6566908359528, "episode/length": 288.0, "episode/score": 0.04496038912060385, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04496038912060385}
{"step": 108728, "time": 3772.782518863678, "episode/length": 288.0, "episode/score": 0.03550668390739986, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03550668390739986}
{"step": 108888, "time": 3777.850473165512, "episode/length": 288.0, "episode/score": 0.051480590936321846, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051480590936321846}
{"step": 109264, "time": 3789.941219806671, "episode/length": 288.0, "episode/score": 0.05899849292799786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05899849292799786}
{"step": 110032, "time": 3819.994079351425, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.0015099048615, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.0079572200775, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.0149335861206, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.021936416626, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.029375076294, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.0357553958893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110032, "time": 3820.04736661911, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 110216, "time": 3825.602017879486, "episode/length": 288.0, "episode/score": 0.05582269812375529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05582269812375529}
{"step": 110336, "time": 3829.5914912223816, "episode/length": 288.0, "episode/score": 0.043380434294377324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043380434294377324}
{"step": 110648, "time": 3839.305552482605, "episode/length": 288.0, "episode/score": 0.054285741449696445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054285741449696445}
{"step": 110664, "time": 3839.813719511032, "episode/length": 288.0, "episode/score": 0.07254213694421452, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07254213694421452}
{"step": 110976, "time": 3849.847811460495, "episode/length": 288.0, "episode/score": 0.06383824771850755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06383824771850755}
{"step": 111040, "time": 3851.879690885544, "episode/length": 288.0, "episode/score": 0.07346356113472297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07346356113472297}
{"step": 111200, "time": 3856.891929626465, "episode/length": 288.0, "episode/score": 0.06282103991783572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06282103991783572}
{"step": 111576, "time": 3868.5199966430664, "episode/length": 288.0, "episode/score": 0.06703617421435126, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06703617421435126}
{"step": 112528, "time": 3898.7130422592163, "episode/length": 288.0, "episode/score": 0.05555490985698697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05555490985698697}
{"step": 112648, "time": 3902.2561163902283, "episode/length": 288.0, "episode/score": 0.04626716652867913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04626716652867913}
{"step": 112960, "time": 3912.2665996551514, "episode/length": 288.0, "episode/score": 0.049485015550629896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049485015550629896}
{"step": 112976, "time": 3912.7749950885773, "episode/length": 288.0, "episode/score": 0.03709258677095306, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03709258677095306}
{"step": 113288, "time": 3922.503268480301, "episode/length": 288.0, "episode/score": 0.05024541190366705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05024541190366705}
{"step": 113352, "time": 3924.5023217201233, "episode/length": 288.0, "episode/score": 0.04014604816939027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04014604816939027}
{"step": 113512, "time": 3929.521098613739, "episode/length": 288.0, "episode/score": 0.07269245516887679, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07269245516887679}
{"step": 113888, "time": 3941.5298500061035, "episode/length": 288.0, "episode/score": 0.053998427282955674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053998427282955674}
{"step": 114840, "time": 3971.8636853694916, "episode/length": 288.0, "episode/score": 0.04605539124165858, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04605539124165858}
{"step": 114960, "time": 3975.8600709438324, "episode/length": 288.0, "episode/score": 0.04693901341983775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04693901341983775}
{"step": 115272, "time": 3985.5100843906403, "episode/length": 288.0, "episode/score": 0.04435961131763122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04435961131763122}
{"step": 115288, "time": 3986.018062353134, "episode/length": 288.0, "episode/score": 0.059856355174730425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059856355174730425}
{"step": 115600, "time": 3996.029765844345, "episode/length": 288.0, "episode/score": 0.07987530319053349, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07987530319053349}
{"step": 115664, "time": 3998.051778793335, "episode/length": 288.0, "episode/score": 0.05598800743957355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05598800743957355}
{"step": 115704, "time": 3999.0892050266266, "episode/length": 53.0, "episode/score": 0.8526322271046425, "episode/reward_rate": 0.018518518518518517, "episode/intrinsic_return": 0.018257204077691824}
{"step": 115824, "time": 4003.0914068222046, "episode/length": 288.0, "episode/score": 0.047216670131305705, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047216670131305705}
{"step": 116200, "time": 4014.7644186019897, "episode/length": 288.0, "episode/score": 0.03429875813228733, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03429875813228733}
{"step": 117152, "time": 4045.092151403427, "episode/length": 288.0, "episode/score": 0.06694746142027697, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06694746142027697}
{"step": 117272, "time": 4048.6490314006805, "episode/length": 288.0, "episode/score": 0.0695939396401073, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0695939396401073}
{"step": 117584, "time": 4058.6731448173523, "episode/length": 172.0, "episode/score": 0.5111184096522194, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.04861840485590818}
{"step": 117600, "time": 4059.1815350055695, "episode/length": 288.0, "episode/score": 0.040001394279151725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040001394279151725}
{"step": 117912, "time": 4068.739577770233, "episode/length": 288.0, "episode/score": 0.04912786426619675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04912786426619675}
{"step": 117976, "time": 4070.7399559020996, "episode/length": 288.0, "episode/score": 0.06290598277055892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06290598277055892}
{"step": 118016, "time": 4072.326773405075, "episode/length": 288.0, "episode/score": 0.060787684852250834, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060787684852250834}
{"step": 118136, "time": 4075.8990840911865, "episode/length": 288.0, "episode/score": 0.06427484778264869, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06427484778264869}
{"step": 119464, "time": 4117.75741481781, "episode/length": 288.0, "episode/score": 0.06857391777168687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06857391777168687}
{"step": 119584, "time": 4121.775455713272, "episode/length": 288.0, "episode/score": 0.05619355612020627, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05619355612020627}
{"step": 119896, "time": 4131.493465423584, "episode/length": 288.0, "episode/score": 0.05898587413844325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05898587413844325}
{"step": 119912, "time": 4131.998710870743, "episode/length": 288.0, "episode/score": 0.06941119909299687, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06941119909299687}
{"step": 120016, "time": 4140.648006439209, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.65641450882, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.665274620056, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.672593832016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.6803414821625, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.685811519623, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.693782567978, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120016, "time": 4140.701959848404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 120224, "time": 4147.238652229309, "episode/length": 288.0, "episode/score": 0.04448309888016411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04448309888016411}
{"step": 120288, "time": 4149.263466358185, "episode/length": 288.0, "episode/score": 0.03918225568907019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03918225568907019}
{"step": 120328, "time": 4150.2971131801605, "episode/length": 288.0, "episode/score": 0.05443476740981623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05443476740981623}
{"step": 120448, "time": 4154.285301446915, "episode/length": 288.0, "episode/score": 0.06041369039382971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06041369039382971}
{"step": 121776, "time": 4196.243557214737, "episode/length": 288.0, "episode/score": 0.07038413190707615, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07038413190707615}
{"step": 121896, "time": 4199.794288158417, "episode/length": 288.0, "episode/score": 0.0892116588584031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0892116588584031}
{"step": 122208, "time": 4209.818392276764, "episode/length": 288.0, "episode/score": 0.06568361928907507, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06568361928907507}
{"step": 122224, "time": 4210.324491739273, "episode/length": 288.0, "episode/score": 0.07772146332325747, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07772146332325747}
{"step": 122536, "time": 4219.911794662476, "episode/length": 288.0, "episode/score": 0.06412572535049321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06412572535049321}
{"step": 122600, "time": 4222.070558309555, "episode/length": 288.0, "episode/score": 0.06156691116422053, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06156691116422053}
{"step": 122640, "time": 4223.566293954849, "episode/length": 288.0, "episode/score": 0.0533491390862082, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0533491390862082}
{"step": 122760, "time": 4227.121828317642, "episode/length": 288.0, "episode/score": 0.057561116899989884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057561116899989884}
{"step": 123977, "time": 4266.952030420303, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.999133552472616, "train/action_min": 0.0, "train/action_std": 2.0001739748974434, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 8.212831078745909e-05, "train/actor_opt_grad_steps": 6685.0, "train/actor_opt_loss": -2.9970804715298653, "train/adv_mag": 0.00037854391428613173, "train/adv_max": 0.00034836748826135066, "train/adv_mean": 0.00014130422213965335, "train/adv_min": -0.00012427218949671872, "train/adv_std": 9.269994677534791e-05, "train/cont_avg": 0.9965467944587629, "train/cont_loss_mean": 0.023046548557515766, "train/cont_loss_std": 0.3208575557602915, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.667162887713048, "train/cont_pos_acc": 0.9999999855596995, "train/cont_pos_loss": 0.0035035792562976174, "train/cont_pred": 0.9965026839492247, "train/cont_rate": 0.9965467944587629, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.020828670727271473, "train/extr_critic_critic_opt_grad_steps": 6685.0, "train/extr_critic_critic_opt_loss": 13511.308377295425, "train/extr_critic_mag": 0.07848758672930531, "train/extr_critic_max": 0.07848758672930531, "train/extr_critic_mean": 0.07834342517650005, "train/extr_critic_min": 0.0782777273777834, "train/extr_critic_std": 3.072559707219473e-05, "train/extr_return_normed_mag": 0.0006092839019814718, "train/extr_return_normed_max": 0.0005813416900094022, "train/extr_return_normed_mean": 0.00042951272632176977, "train/extr_return_normed_min": 0.00024153192325965646, "train/extr_return_normed_std": 8.294198067036182e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.07863655563482304, "train/extr_return_raw_max": 0.07863655563482304, "train/extr_return_raw_mean": 0.07848473089103847, "train/extr_return_raw_min": 0.0782967458680733, "train/extr_return_raw_std": 8.294198111924903e-05, "train/extr_reward_mag": 0.00025797504739663037, "train/extr_reward_max": 0.00025797504739663037, "train/extr_reward_mean": 0.0002577649511201259, "train/extr_reward_min": 0.0002575627307301944, "train/extr_reward_std": 8.584857520570499e-08, "train/image_loss_mean": 0.255681170784321, "train/image_loss_std": 0.08468681295431152, "train/model_loss_mean": 0.8908061348285872, "train/model_loss_std": 0.3859243014654548, "train/model_opt_grad_norm": 56.90940335853813, "train/model_opt_grad_steps": 6675.0, "train/model_opt_loss": 696.6836484928721, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 782.860824742268, "train/policy_entropy_mag": 1.945893207161697, "train/policy_entropy_max": 1.945893207161697, "train/policy_entropy_mean": 1.9453290664043623, "train/policy_entropy_min": 1.937885080416178, "train/policy_entropy_std": 0.0003841013720225466, "train/policy_logprob_mag": 2.1139779938864955, "train/policy_logprob_max": -1.781104028839426, "train/policy_logprob_mean": -1.9453190110393406, "train/policy_logprob_min": -2.1139779938864955, "train/policy_logprob_std": 0.03303962317055341, "train/policy_randomness_mag": 0.9999913533323819, "train/policy_randomness_max": 0.9999913533323819, "train/policy_randomness_mean": 0.9997014434067244, "train/policy_randomness_min": 0.9958759905751219, "train/policy_randomness_std": 0.00019738907216491236, "train/post_ent_mag": 42.27113365881222, "train/post_ent_max": 42.27113365881222, "train/post_ent_mean": 42.224789648940884, "train/post_ent_min": 42.03993394202793, "train/post_ent_std": 0.04455938387167707, "train/prior_ent_mag": 50.43239141247936, "train/prior_ent_max": 50.43239141247936, "train/prior_ent_mean": 50.34994819483806, "train/prior_ent_min": 49.66199343966455, "train/prior_ent_std": 0.13202510951518936, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0003148834284823436, "train/reward_loss_mean": 0.012078395300573603, "train/reward_loss_std": 0.08083578771383491, "train/reward_max_data": 0.11216065654718346, "train/reward_max_pred": 0.00025815324685008254, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009834611382738678, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.51335464521896, "train/reward_pred": 0.00025784220131229343, "train/reward_rate": 0.00023658988402061856, "train_stats/mean_log_entropy": 1.9383476560360917, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.037146106362342834, "report/cont_loss_std": 0.4463046193122864, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.850539207458496, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0028824990149587393, "report/cont_pred": 0.9971217513084412, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.2463664710521698, "report/image_loss_std": 0.07662620395421982, "report/model_loss_mean": 0.894128680229187, "report/model_loss_std": 0.4533984959125519, "report/post_ent_mag": 50.19587707519531, "report/post_ent_max": 50.19587707519531, "report/post_ent_mean": 50.188358306884766, "report/post_ent_min": 50.181190490722656, "report/post_ent_std": 0.0024942748714238405, "report/prior_ent_mag": 50.66032409667969, "report/prior_ent_max": 50.66032409667969, "report/prior_ent_mean": 50.64802551269531, "report/prior_ent_min": 50.61137390136719, "report/prior_ent_std": 0.007075641304254532, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021762787946499884, "report/reward_loss_mean": 0.010616099461913109, "report/reward_loss_std": 0.01759812794625759, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002181529998779297, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010616099461913109, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002181529998779297, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0028824990149587393, "eval/cont_loss_std": 4.656612873077393e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0028824990149587393, "eval/cont_pred": 0.9971217513084412, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.23978398740291595, "eval/image_loss_std": 0.07559175044298172, "eval/model_loss_mean": 0.8438805341720581, "eval/model_loss_std": 0.07559175044298172, "eval/post_ent_mag": 50.19498062133789, "eval/post_ent_max": 50.19498062133789, "eval/post_ent_mean": 50.18806838989258, "eval/post_ent_min": 50.18162155151367, "eval/post_ent_std": 0.0023896703496575356, "eval/prior_ent_mag": 50.66093444824219, "eval/prior_ent_max": 50.66093444824219, "eval/prior_ent_mean": 50.6481819152832, "eval/prior_ent_min": 50.614280700683594, "eval/prior_ent_std": 0.0061935740523040295, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012140274047851562, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002181529998779297, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012140274047851562, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002181529998779297, "eval/reward_rate": 0.0, "replay/size": 123473.0, "replay/inserts": 31056.0, "replay/samples": 31056.0, "replay/insert_wait_avg": 1.4146276505444236e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.568820236025245e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31112.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2166016104587084e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2598991394043, "timer/env.step_count": 3882.0, "timer/env.step_total": 38.48865580558777, "timer/env.step_frac": 0.038478655236206444, "timer/env.step_avg": 0.009914646008652182, "timer/env.step_min": 0.008158206939697266, "timer/env.step_max": 0.03949880599975586, "timer/replay._sample_count": 31056.0, "timer/replay._sample_total": 15.524183750152588, "timer/replay._sample_frac": 0.015520150076504279, "timer/replay._sample_avg": 0.0004998771171481384, "timer/replay._sample_min": 0.0003509521484375, "timer/replay._sample_max": 0.010670661926269531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4749.0, "timer/agent.policy_total": 48.05347156524658, "timer/agent.policy_frac": 0.04804098575439288, "timer/agent.policy_avg": 0.010118650571751228, "timer/agent.policy_min": 0.008906841278076172, "timer/agent.policy_max": 0.0731966495513916, "timer/dataset_train_count": 1941.0, "timer/dataset_train_total": 0.21637320518493652, "timer/dataset_train_frac": 0.00021631698458680389, "timer/dataset_train_avg": 0.00011147511859089981, "timer/dataset_train_min": 9.608268737792969e-05, "timer/dataset_train_max": 0.0009531974792480469, "timer/agent.train_count": 1941.0, "timer/agent.train_total": 863.5961515903473, "timer/agent.train_frac": 0.8633717620124143, "timer/agent.train_avg": 0.44492331354474357, "timer/agent.train_min": 0.43509960174560547, "timer/agent.train_max": 0.607722282409668, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754753112792969, "timer/agent.report_frac": 0.0004753517677639407, "timer/agent.report_avg": 0.23773765563964844, "timer/agent.report_min": 0.22954988479614258, "timer/agent.report_max": 0.2459254264831543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.9577484130859375e-05, "timer/dataset_eval_frac": 3.956720064946194e-08, "timer/dataset_eval_avg": 3.9577484130859375e-05, "timer/dataset_eval_min": 3.9577484130859375e-05, "timer/dataset_eval_max": 3.9577484130859375e-05, "fps": 31.047461908002923}
{"step": 124088, "time": 4270.196996688843, "episode/length": 288.0, "episode/score": 0.08808772453284064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08808772453284064}
{"step": 124208, "time": 4274.195216417313, "episode/length": 288.0, "episode/score": 0.059806448180779626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059806448180779626}
{"step": 124520, "time": 4283.9164407253265, "episode/length": 288.0, "episode/score": 0.05330291181371649, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05330291181371649}
{"step": 124536, "time": 4284.426380634308, "episode/length": 288.0, "episode/score": 0.060139174215805724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060139174215805724}
{"step": 124848, "time": 4294.447627544403, "episode/length": 288.0, "episode/score": 0.08359119153311667, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08359119153311667}
{"step": 124912, "time": 4296.492644071579, "episode/length": 288.0, "episode/score": 0.07852346578155789, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07852346578155789}
{"step": 124952, "time": 4297.53898024559, "episode/length": 288.0, "episode/score": 0.07718726837359213, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07718726837359213}
{"step": 125072, "time": 4301.536656856537, "episode/length": 288.0, "episode/score": 0.0675342478917571, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0675342478917571}
{"step": 126400, "time": 4343.5140426158905, "episode/length": 288.0, "episode/score": 0.0588329335028277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0588329335028277}
{"step": 126520, "time": 4347.074121236801, "episode/length": 288.0, "episode/score": 0.07219501880945245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07219501880945245}
{"step": 126832, "time": 4357.086420297623, "episode/length": 288.0, "episode/score": 0.057353091292355884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057353091292355884}
{"step": 126848, "time": 4357.604807138443, "episode/length": 288.0, "episode/score": 0.04332507045043599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04332507045043599}
{"step": 127160, "time": 4367.217760801315, "episode/length": 288.0, "episode/score": 0.06989845110149417, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06989845110149417}
{"step": 127224, "time": 4369.2393617630005, "episode/length": 288.0, "episode/score": 0.04544802262165604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04544802262165604}
{"step": 127264, "time": 4370.713759422302, "episode/length": 288.0, "episode/score": 0.039343180810618605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039343180810618605}
{"step": 127384, "time": 4374.4023950099945, "episode/length": 288.0, "episode/score": 0.0835073742431689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0835073742431689}
{"step": 128712, "time": 4416.303920269012, "episode/length": 288.0, "episode/score": 0.051474721331857154, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051474721331857154}
{"step": 128832, "time": 4420.3130424022675, "episode/length": 288.0, "episode/score": 0.06214484509126805, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06214484509126805}
{"step": 129144, "time": 4429.893012523651, "episode/length": 288.0, "episode/score": 0.050474516634295696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050474516634295696}
{"step": 129160, "time": 4430.399112701416, "episode/length": 288.0, "episode/score": 0.05369197968744288, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05369197968744288}
{"step": 129472, "time": 4440.54168844223, "episode/length": 288.0, "episode/score": 0.050564773451213796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050564773451213796}
{"step": 129536, "time": 4442.546990871429, "episode/length": 288.0, "episode/score": 0.03231003880131311, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03231003880131311}
{"step": 129576, "time": 4443.607387304306, "episode/length": 288.0, "episode/score": 0.04892906969513433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04892906969513433}
{"step": 129696, "time": 4447.607476472855, "episode/length": 288.0, "episode/score": 0.07367523531812026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07367523531812026}
{"step": 130000, "time": 4463.352510929108, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.360518693924, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.367302179337, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.374320268631, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.380810022354, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.388155460358, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.394156455994, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 130000, "time": 4463.40248632431, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 131024, "time": 4495.589456319809, "episode/length": 288.0, "episode/score": 0.04110517901898447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04110517901898447}
{"step": 131144, "time": 4499.622448205948, "episode/length": 288.0, "episode/score": 0.05438587261468797, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05438587261468797}
{"step": 131456, "time": 4509.659631967545, "episode/length": 288.0, "episode/score": 0.05395776163763344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05395776163763344}
{"step": 131472, "time": 4510.184777259827, "episode/length": 288.0, "episode/score": 0.058989006313822756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058989006313822756}
{"step": 131784, "time": 4519.761901378632, "episode/length": 288.0, "episode/score": 0.034573694290543244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034573694290543244}
{"step": 131848, "time": 4521.911978006363, "episode/length": 288.0, "episode/score": 0.021904842598985397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021904842598985397}
{"step": 131888, "time": 4523.400785923004, "episode/length": 288.0, "episode/score": 0.05533987157343745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05533987157343745}
{"step": 132008, "time": 4526.982288122177, "episode/length": 288.0, "episode/score": 0.04646395480767751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04646395480767751}
{"step": 133336, "time": 4569.287019491196, "episode/length": 288.0, "episode/score": 0.04048677129874534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04048677129874534}
{"step": 133456, "time": 4573.273626327515, "episode/length": 288.0, "episode/score": 0.05510303958322993, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05510303958322993}
{"step": 133768, "time": 4582.906726360321, "episode/length": 288.0, "episode/score": 0.056707989283594884, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.056707989283594884}
{"step": 133784, "time": 4583.415668010712, "episode/length": 288.0, "episode/score": 0.061847925350051014, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061847925350051014}
{"step": 134096, "time": 4593.414922237396, "episode/length": 288.0, "episode/score": 0.035300101429271535, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035300101429271535}
{"step": 134160, "time": 4595.419485330582, "episode/length": 288.0, "episode/score": 0.03198610013681957, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03198610013681957}
{"step": 134200, "time": 4596.47652387619, "episode/length": 288.0, "episode/score": 0.040737764531669995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040737764531669995}
{"step": 134320, "time": 4600.45295715332, "episode/length": 288.0, "episode/score": 0.05381178364928019, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05381178364928019}
{"step": 135648, "time": 4642.448417901993, "episode/length": 288.0, "episode/score": 0.06375140436234972, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06375140436234972}
{"step": 135768, "time": 4646.010601758957, "episode/length": 288.0, "episode/score": 0.034734979997850246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034734979997850246}
{"step": 136080, "time": 4656.010791063309, "episode/length": 288.0, "episode/score": 0.049085619199559005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049085619199559005}
{"step": 136096, "time": 4656.51682472229, "episode/length": 288.0, "episode/score": 0.039696694903966545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039696694903966545}
{"step": 136336, "time": 4664.016153812408, "episode/length": 251.0, "episode/score": 0.2720439738852889, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.05641897206920987}
{"step": 136408, "time": 4666.047444820404, "episode/length": 288.0, "episode/score": 0.08297256177374379, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08297256177374379}
{"step": 136472, "time": 4668.072275876999, "episode/length": 288.0, "episode/score": 0.058376369862102706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058376369862102706}
{"step": 136512, "time": 4669.551098823547, "episode/length": 288.0, "episode/score": 0.06478140816457767, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06478140816457767}
{"step": 137960, "time": 4714.961301803589, "episode/length": 288.0, "episode/score": 0.09869441197838569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09869441197838569}
{"step": 138080, "time": 4718.989397287369, "episode/length": 288.0, "episode/score": 0.0684504124965315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0684504124965315}
{"step": 138392, "time": 4728.586309909821, "episode/length": 288.0, "episode/score": 0.07942891518018769, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07942891518018769}
{"step": 138408, "time": 4729.094480037689, "episode/length": 288.0, "episode/score": 0.058499949540191665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058499949540191665}
{"step": 138648, "time": 4736.7754101753235, "episode/length": 288.0, "episode/score": 0.03593557616363796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03593557616363796}
{"step": 138720, "time": 4739.257231235504, "episode/length": 288.0, "episode/score": 0.06277380653909859, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06277380653909859}
{"step": 138784, "time": 4741.251096963882, "episode/length": 288.0, "episode/score": 0.06815603327868303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06815603327868303}
{"step": 138824, "time": 4742.289746999741, "episode/length": 288.0, "episode/score": 0.05200914724719041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05200914724719041}
{"step": 140088, "time": 4788.008837938309, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.015835762024, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.023960590363, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.029913902283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.036304950714, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.043200016022, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.049181699753, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140088, "time": 4788.055743217468, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 140272, "time": 4794.250249862671, "episode/length": 288.0, "episode/score": 0.08829390787502689, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08829390787502689}
{"step": 140392, "time": 4797.767153263092, "episode/length": 288.0, "episode/score": 0.06604942760975518, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06604942760975518}
{"step": 140704, "time": 4807.78066277504, "episode/length": 288.0, "episode/score": 0.0394097738843584, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0394097738843584}
{"step": 140720, "time": 4808.28634095192, "episode/length": 288.0, "episode/score": 0.05866245147910831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05866245147910831}
{"step": 140960, "time": 4815.818578958511, "episode/length": 288.0, "episode/score": 0.047829313089437164, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047829313089437164}
{"step": 141032, "time": 4817.836931705475, "episode/length": 288.0, "episode/score": 0.0513174147972677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0513174147972677}
{"step": 141096, "time": 4819.849786520004, "episode/length": 288.0, "episode/score": 0.08163637028178528, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08163637028178528}
{"step": 141136, "time": 4821.439178705215, "episode/length": 288.0, "episode/score": 0.07226181771977735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07226181771977735}
{"step": 141296, "time": 4826.427102327347, "episode/length": 73.0, "episode/score": 0.7937000767408335, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.021825024260806458}
{"step": 141816, "time": 4842.484324216843, "episode/length": 64.0, "episode/score": 0.8228487241007088, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.022848712994687048}
{"step": 142584, "time": 4866.6621334552765, "episode/length": 288.0, "episode/score": 0.044212109583043, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044212109583043}
{"step": 142704, "time": 4870.651217460632, "episode/length": 288.0, "episode/score": 0.06180615379184928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06180615379184928}
{"step": 143032, "time": 4880.727714538574, "episode/length": 288.0, "episode/score": 0.05125870251822562, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05125870251822562}
{"step": 143272, "time": 4888.312685728073, "episode/length": 288.0, "episode/score": 0.05450719709358509, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05450719709358509}
{"step": 143344, "time": 4890.795962572098, "episode/length": 288.0, "episode/score": 0.0781112875295662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0781112875295662}
{"step": 143408, "time": 4892.798432350159, "episode/length": 288.0, "episode/score": 0.05912572422073481, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05912572422073481}
{"step": 143448, "time": 4893.833288908005, "episode/length": 288.0, "episode/score": 0.05707203064423538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05707203064423538}
{"step": 144128, "time": 4915.577310323715, "episode/length": 288.0, "episode/score": 0.07445948546529735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07445948546529735}
{"step": 144896, "time": 4939.626212596893, "episode/length": 288.0, "episode/score": 0.06480101904088542, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06480101904088542}
{"step": 145016, "time": 4943.302122116089, "episode/length": 288.0, "episode/score": 0.054498556677572196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054498556677572196}
{"step": 145344, "time": 4953.803015470505, "episode/length": 288.0, "episode/score": 0.058647502849453303, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058647502849453303}
{"step": 145472, "time": 4957.888129234314, "episode/length": 167.0, "episode/score": 0.5431804502105706, "episode/reward_rate": 0.005952380952380952, "episode/intrinsic_return": 0.06505544541425934}
{"step": 145584, "time": 4961.423384666443, "episode/length": 288.0, "episode/score": 0.08280743805801194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08280743805801194}
{"step": 145656, "time": 4963.465109348297, "episode/length": 288.0, "episode/score": 0.04929829333082125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04929829333082125}
{"step": 145720, "time": 4965.493321895599, "episode/length": 288.0, "episode/score": 0.051787829832278476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051787829832278476}
{"step": 145760, "time": 4966.9780995845795, "episode/length": 288.0, "episode/score": 0.06742024387517631, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06742024387517631}
{"step": 146976, "time": 5005.268084287643, "episode/length": 259.0, "episode/score": 0.26955805838701963, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.07893306218215912}
{"step": 147328, "time": 5016.293769359589, "episode/length": 288.0, "episode/score": 0.06526991787632141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06526991787632141}
{"step": 147432, "time": 5019.331453323364, "episode/length": 230.0, "episode/score": 0.31235136231958904, "episode/reward_rate": 0.004329004329004329, "episode/intrinsic_return": 0.03110136348374226}
{"step": 147656, "time": 5026.86653137207, "episode/length": 288.0, "episode/score": 0.06872058257494018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06872058257494018}
{"step": 147720, "time": 5028.883798837662, "episode/length": 249.0, "episode/score": 0.28327137832889093, "episode/reward_rate": 0.004, "episode/intrinsic_return": 0.06139638247327639}
{"step": 147784, "time": 5030.947121143341, "episode/length": 288.0, "episode/score": 0.03570630764994576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03570630764994576}
{"step": 147968, "time": 5037.016007423401, "episode/length": 288.0, "episode/score": 0.04313155165982607, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04313155165982607}
{"step": 148072, "time": 5040.050605297089, "episode/length": 288.0, "episode/score": 0.06033950472874494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06033950472874494}
{"step": 149288, "time": 5078.367833137512, "episode/length": 288.0, "episode/score": 0.055420124392185244, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055420124392185244}
{"step": 149640, "time": 5089.482515573502, "episode/length": 288.0, "episode/score": 0.06404093338881012, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06404093338881012}
{"step": 149744, "time": 5093.099518060684, "episode/length": 288.0, "episode/score": 0.05354856491129567, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05354856491129567}
{"step": 149968, "time": 5100.091347455978, "episode/length": 288.0, "episode/score": 0.039734017238401975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039734017238401975}
{"step": 150032, "time": 5102.121883392334, "episode/length": 288.0, "episode/score": 0.05292232893123128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05292232893123128}
{"step": 150072, "time": 5108.372772216797, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.380610704422, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.387657165527, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.395070314407, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.402393579483, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.409105062485, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.416392326355, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150072, "time": 5108.4233367443085, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 150096, "time": 5109.402311563492, "episode/length": 288.0, "episode/score": 0.05081133556865325, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05081133556865325}
{"step": 150280, "time": 5114.949504613876, "episode/length": 288.0, "episode/score": 0.05077393865792601, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05077393865792601}
{"step": 150384, "time": 5118.426797389984, "episode/length": 288.0, "episode/score": 0.05825065193948831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05825065193948831}
{"step": 151600, "time": 5156.706045866013, "episode/length": 288.0, "episode/score": 0.052971041361900006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052971041361900006}
{"step": 151952, "time": 5167.73801445961, "episode/length": 288.0, "episode/score": 0.05121529718425677, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05121529718425677}
{"step": 152056, "time": 5170.765815973282, "episode/length": 288.0, "episode/score": 0.04787449396712873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04787449396712873}
{"step": 152280, "time": 5177.84001159668, "episode/length": 288.0, "episode/score": 0.08375353771955929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08375353771955929}
{"step": 152344, "time": 5179.8313772678375, "episode/length": 288.0, "episode/score": 0.054985505263573486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054985505263573486}
{"step": 152408, "time": 5181.967092752457, "episode/length": 288.0, "episode/score": 0.05456382340418031, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05456382340418031}
{"step": 152592, "time": 5188.022862195969, "episode/length": 288.0, "episode/score": 0.0352976042819364, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0352976042819364}
{"step": 152696, "time": 5191.073126077652, "episode/length": 288.0, "episode/score": 0.04374073674048873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04374073674048873}
{"step": 153216, "time": 5207.584171533585, "episode/length": 108.0, "episode/score": 0.6731398974488911, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.010639874421940476}
{"step": 153912, "time": 5229.310656547546, "episode/length": 288.0, "episode/score": 0.07016606081873533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07016606081873533}
{"step": 154264, "time": 5240.317496299744, "episode/length": 288.0, "episode/score": 0.06382832557636675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06382832557636675}
{"step": 154368, "time": 5243.931012868881, "episode/length": 288.0, "episode/score": 0.04488261286138595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04488261286138595}
{"step": 154592, "time": 5250.920070409775, "episode/length": 288.0, "episode/score": 0.04953879184222387, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04953879184222387}
{"step": 154720, "time": 5254.9528958797455, "episode/length": 288.0, "episode/score": 0.046799249574974056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046799249574974056}
{"step": 154904, "time": 5260.518416881561, "episode/length": 288.0, "episode/score": 0.061218707483476464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061218707483476464}
{"step": 155008, "time": 5264.008542299271, "episode/length": 288.0, "episode/score": 0.059693985270200756, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059693985270200756}
{"step": 155081, "time": 5267.033235788345, "train_stats/mean_log_entropy": 1.9376892552041172, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.9991458224267076, "train/action_min": 0.0, "train/action_std": 2.0010887046450194, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 6.237785556109397e-05, "train/actor_opt_grad_steps": 8625.0, "train/actor_opt_loss": -4.1569928817988675, "train/adv_mag": 0.00035585117401535976, "train/adv_max": 0.00031232369161143743, "train/adv_mean": 8.055044868436282e-05, "train/adv_min": -0.00019003247323724412, "train/adv_std": 8.201615769066098e-05, "train/cont_avg": 0.9965920989046392, "train/cont_loss_mean": 0.022775723852130787, "train/cont_loss_std": 0.3169766987959576, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.65838110636151, "train/cont_pos_acc": 0.9999999883248634, "train/cont_pos_loss": 0.0035303797424031595, "train/cont_pred": 0.9964759865986932, "train/cont_rate": 0.9965920989046392, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.017585327949005265, "train/extr_critic_critic_opt_grad_steps": 8625.0, "train/extr_critic_critic_opt_loss": 13529.244125523517, "train/extr_critic_mag": 0.08223653146901082, "train/extr_critic_max": 0.08223653146901082, "train/extr_critic_mean": 0.08208468172353567, "train/extr_critic_min": 0.08198008033418164, "train/extr_critic_std": 4.022652001953547e-05, "train/extr_return_normed_mag": 0.0004423496879867672, "train/extr_return_normed_max": 0.00039786860807654783, "train/extr_return_normed_mean": 0.00026052560438297265, "train/extr_return_normed_min": 8.910521864891052e-05, "train/extr_return_normed_std": 6.723712802331366e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.08230260321774434, "train/extr_return_raw_max": 0.08230260321774434, "train/extr_return_raw_mean": 0.0821652647453485, "train/extr_return_raw_min": 0.08199383982831669, "train/extr_return_raw_std": 6.723712823076283e-05, "train/extr_reward_mag": 0.00025945348837940965, "train/extr_reward_max": 0.00025945348837940965, "train/extr_reward_mean": 0.0002593052641461008, "train/extr_reward_min": 0.0002591388741719354, "train/extr_reward_std": 6.13408832342374e-08, "train/image_loss_mean": 0.2506570613261351, "train/image_loss_std": 0.08406427990376335, "train/model_loss_mean": 0.8848543225489941, "train/model_loss_std": 0.36973626811787025, "train/model_opt_grad_norm": 51.35664516903576, "train/model_opt_grad_steps": 8614.731958762886, "train/model_opt_loss": 2085.061350399686, "train/model_opt_model_opt_grad_overflow": 0.005154639175257732, "train/model_opt_model_opt_grad_scale": 2345.360824742268, "train/policy_entropy_mag": 1.9458919499338287, "train/policy_entropy_max": 1.9458919499338287, "train/policy_entropy_mean": 1.9450153419651937, "train/policy_entropy_min": 1.927943595291413, "train/policy_entropy_std": 0.0006300113568941765, "train/policy_logprob_mag": 2.1892373107143284, "train/policy_logprob_max": -1.7106375061359602, "train/policy_logprob_mean": -1.9449960743029093, "train/policy_logprob_min": -2.1892373107143284, "train/policy_logprob_std": 0.04222292412725306, "train/policy_randomness_mag": 0.9999907068985024, "train/policy_randomness_max": 0.9999907068985024, "train/policy_randomness_mean": 0.9995402223670605, "train/policy_randomness_min": 0.9907670749216965, "train/policy_randomness_std": 0.0003237618130725357, "train/post_ent_mag": 51.084393884717805, "train/post_ent_max": 51.084393884717805, "train/post_ent_mean": 51.0440613461524, "train/post_ent_min": 51.03609944373062, "train/post_ent_std": 0.006309592873146085, "train/prior_ent_mag": 52.48804487641325, "train/prior_ent_max": 52.48804487641325, "train/prior_ent_mean": 52.466145269649545, "train/prior_ent_min": 52.360586834937024, "train/prior_ent_std": 0.026060518009357693, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.000303811517819527, "train/reward_loss_mean": 0.011421519641274797, "train/reward_loss_std": 0.06329661675911281, "train/reward_max_data": 0.09729811255868102, "train/reward_max_pred": 0.00025972324548308385, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.00972130320505383, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.630476268132528, "train/reward_pred": 0.0002594243059386067, "train/reward_rate": 0.000176183956185567, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.02002877928316593, "report/cont_loss_std": 0.30971601605415344, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.73370885848999, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0032402994111180305, "report/cont_pred": 0.9967650771141052, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.25038856267929077, "report/image_loss_std": 0.08114299923181534, "report/model_loss_mean": 0.8809731006622314, "report/model_loss_std": 0.3209782838821411, "report/post_ent_mag": 52.07428741455078, "report/post_ent_max": 52.07428741455078, "report/post_ent_mean": 52.02610778808594, "report/post_ent_min": 52.01586151123047, "report/post_ent_std": 0.007615836802870035, "report/prior_ent_mag": 52.54279708862305, "report/prior_ent_max": 52.54279708862305, "report/prior_ent_mean": 52.521400451660156, "report/prior_ent_min": 52.434383392333984, "report/prior_ent_std": 0.020588509738445282, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00021641046623699367, "report/reward_loss_mean": 0.010555739514529705, "report/reward_loss_std": 0.017278259620070457, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.00023376941680908203, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.01055574044585228, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00023376941680908203, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0032402994111180305, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0032402994111180305, "eval/cont_pred": 0.9967650771141052, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22953283786773682, "eval/image_loss_std": 0.07883311063051224, "eval/model_loss_mean": 0.8340262770652771, "eval/model_loss_std": 0.07883311808109283, "eval/post_ent_mag": 52.073062896728516, "eval/post_ent_max": 52.073062896728516, "eval/post_ent_mean": 52.025611877441406, "eval/post_ent_min": 52.01673889160156, "eval/post_ent_std": 0.007158993743360043, "eval/prior_ent_mag": 52.54606246948242, "eval/prior_ent_max": 52.54606246948242, "eval/prior_ent_mean": 52.52248764038086, "eval/prior_ent_min": 52.43394470214844, "eval/prior_ent_std": 0.019913604483008385, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0012531280517578125, "eval/reward_loss_std": 0.0, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.00023376941680908203, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012531280517578125, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00023376941680908203, "eval/reward_rate": 0.0, "replay/size": 154577.0, "replay/inserts": 31104.0, "replay/samples": 31104.0, "replay/insert_wait_avg": 1.3370266176545572e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.89255639653147e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38048.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1723278028054771e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0637373924255, "timer/env.step_count": 3888.0, "timer/env.step_total": 38.18146300315857, "timer/env.step_frac": 0.03817902957136835, "timer/env.step_avg": 0.009820335134557245, "timer/env.step_min": 0.008040904998779297, "timer/env.step_max": 0.03987288475036621, "timer/replay._sample_count": 31104.0, "timer/replay._sample_total": 15.468419551849365, "timer/replay._sample_frac": 0.015467433697957942, "timer/replay._sample_avg": 0.000497312871394334, "timer/replay._sample_min": 0.00035119056701660156, "timer/replay._sample_max": 0.02873396873474121, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4755.0, "timer/agent.policy_total": 47.92037510871887, "timer/agent.policy_frac": 0.04791732098362736, "timer/agent.policy_avg": 0.010077891715818901, "timer/agent.policy_min": 0.008506536483764648, "timer/agent.policy_max": 0.0840294361114502, "timer/dataset_train_count": 1944.0, "timer/dataset_train_total": 0.20872831344604492, "timer/dataset_train_frac": 0.00020871501049551586, "timer/dataset_train_avg": 0.0001073705316080478, "timer/dataset_train_min": 9.322166442871094e-05, "timer/dataset_train_max": 0.0007455348968505859, "timer/agent.train_count": 1944.0, "timer/agent.train_total": 864.5561821460724, "timer/agent.train_frac": 0.8645010811014139, "timer/agent.train_avg": 0.4447305463714364, "timer/agent.train_min": 0.4356253147125244, "timer/agent.train_max": 1.0595006942749023, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4755845069885254, "timer/agent.report_frac": 0.00047555419640408955, "timer/agent.report_avg": 0.2377922534942627, "timer/agent.report_min": 0.23135066032409668, "timer/agent.report_max": 0.2442338466644287, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.86102294921875e-05, "timer/dataset_eval_frac": 2.860840606698334e-08, "timer/dataset_eval_avg": 2.86102294921875e-05, "timer/dataset_eval_min": 2.86102294921875e-05, "timer/dataset_eval_max": 2.86102294921875e-05, "fps": 31.101512800830925}
{"step": 155528, "time": 5281.041691541672, "episode/length": 288.0, "episode/score": 0.04509388376879997, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04509388376879997}
{"step": 156224, "time": 5303.739576816559, "episode/length": 288.0, "episode/score": 0.08859137639331038, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08859137639331038}
{"step": 156576, "time": 5314.77498793602, "episode/length": 288.0, "episode/score": 0.06500748660016598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06500748660016598}
{"step": 156680, "time": 5317.826684951782, "episode/length": 288.0, "episode/score": 0.029850871685084712, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029850871685084712}
{"step": 156904, "time": 5324.905126810074, "episode/length": 288.0, "episode/score": 0.055748423746763365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055748423746763365}
{"step": 157032, "time": 5328.94776558876, "episode/length": 288.0, "episode/score": 0.04953942920826648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04953942920826648}
{"step": 157216, "time": 5335.096553564072, "episode/length": 288.0, "episode/score": 0.040070039550187175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040070039550187175}
{"step": 157320, "time": 5338.207520723343, "episode/length": 288.0, "episode/score": 0.06003985665836353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06003985665836353}
{"step": 157840, "time": 5354.874173641205, "episode/length": 288.0, "episode/score": 0.059604710775488456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059604710775488456}
{"step": 158536, "time": 5376.790771007538, "episode/length": 288.0, "episode/score": 0.05787132007742457, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05787132007742457}
{"step": 158888, "time": 5387.918867111206, "episode/length": 288.0, "episode/score": 0.04715503794034248, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04715503794034248}
{"step": 158992, "time": 5391.538789510727, "episode/length": 288.0, "episode/score": 0.057542928236330226, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057542928236330226}
{"step": 159216, "time": 5398.56116938591, "episode/length": 288.0, "episode/score": 0.05865073680251953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05865073680251953}
{"step": 159344, "time": 5402.5876297950745, "episode/length": 288.0, "episode/score": 0.05999538613809818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05999538613809818}
{"step": 159528, "time": 5408.1830332279205, "episode/length": 288.0, "episode/score": 0.06409734173587367, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06409734173587367}
{"step": 159632, "time": 5411.673242092133, "episode/length": 288.0, "episode/score": 0.05687927776580182, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05687927776580182}
{"step": 160056, "time": 5430.006542444229, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.018524885178, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.0323712825775, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.041915893555, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.048941612244, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.0552768707275, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.061581611633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160056, "time": 5430.068623781204, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 160152, "time": 5433.083019256592, "episode/length": 288.0, "episode/score": 0.052976788690443755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052976788690443755}
{"step": 160848, "time": 5455.299422979355, "episode/length": 288.0, "episode/score": 0.04939632217485723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04939632217485723}
{"step": 161200, "time": 5466.459185361862, "episode/length": 288.0, "episode/score": 0.08111782903841913, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08111782903841913}
{"step": 161304, "time": 5469.515983343124, "episode/length": 288.0, "episode/score": 0.04767671296565368, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04767671296565368}
{"step": 161528, "time": 5476.528974533081, "episode/length": 288.0, "episode/score": 0.060387856103432114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060387856103432114}
{"step": 161656, "time": 5480.520797491074, "episode/length": 288.0, "episode/score": 0.06106692301057137, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06106692301057137}
{"step": 161840, "time": 5486.625278711319, "episode/length": 288.0, "episode/score": 0.05390360064671995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05390360064671995}
{"step": 161944, "time": 5489.665918588638, "episode/length": 288.0, "episode/score": 0.04866161326276597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04866161326276597}
{"step": 162464, "time": 5506.2413721084595, "episode/length": 288.0, "episode/score": 0.06147935057134646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06147935057134646}
{"step": 163160, "time": 5528.135934114456, "episode/length": 288.0, "episode/score": 0.05377189869591348, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05377189869591348}
{"step": 163512, "time": 5539.238585948944, "episode/length": 288.0, "episode/score": 0.04554736552211125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04554736552211125}
{"step": 163616, "time": 5542.855967760086, "episode/length": 288.0, "episode/score": 0.04585118701106694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04585118701106694}
{"step": 163840, "time": 5550.091424465179, "episode/length": 288.0, "episode/score": 0.039113089615682384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039113089615682384}
{"step": 163968, "time": 5554.520324707031, "episode/length": 288.0, "episode/score": 0.0809049057073139, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0809049057073139}
{"step": 164152, "time": 5560.06863617897, "episode/length": 288.0, "episode/score": 0.0526083145230416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0526083145230416}
{"step": 164256, "time": 5563.552856683731, "episode/length": 288.0, "episode/score": 0.0566046343369635, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0566046343369635}
{"step": 164776, "time": 5579.801576137543, "episode/length": 288.0, "episode/score": 0.06551479895708212, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06551479895708212}
{"step": 165472, "time": 5602.023482322693, "episode/length": 288.0, "episode/score": 0.06871702866138207, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06871702866138207}
{"step": 165824, "time": 5613.127391815186, "episode/length": 288.0, "episode/score": 0.06421156088936186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06421156088936186}
{"step": 165928, "time": 5616.210418701172, "episode/length": 288.0, "episode/score": 0.045532373234067336, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045532373234067336}
{"step": 166152, "time": 5623.296595096588, "episode/length": 288.0, "episode/score": 0.07584977493544898, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07584977493544898}
{"step": 166280, "time": 5627.331896781921, "episode/length": 288.0, "episode/score": 0.058327452748528685, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058327452748528685}
{"step": 166464, "time": 5633.43075466156, "episode/length": 288.0, "episode/score": 0.08157473134002657, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08157473134002657}
{"step": 166568, "time": 5636.474762201309, "episode/length": 288.0, "episode/score": 0.05073309006195359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05073309006195359}
{"step": 167088, "time": 5653.00851726532, "episode/length": 288.0, "episode/score": 0.0633906797109205, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0633906797109205}
{"step": 167784, "time": 5674.825581550598, "episode/length": 288.0, "episode/score": 0.0561718837512899, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0561718837512899}
{"step": 168136, "time": 5685.876976013184, "episode/length": 288.0, "episode/score": 0.07171663603821798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07171663603821798}
{"step": 168240, "time": 5689.366178035736, "episode/length": 288.0, "episode/score": 0.06957259968203289, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06957259968203289}
{"step": 168464, "time": 5696.506615400314, "episode/length": 288.0, "episode/score": 0.061854753959323716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061854753959323716}
{"step": 168592, "time": 5700.526496648788, "episode/length": 288.0, "episode/score": 0.07754697638222297, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07754697638222297}
{"step": 168776, "time": 5706.118327617645, "episode/length": 288.0, "episode/score": 0.05563847752307538, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05563847752307538}
{"step": 168880, "time": 5709.627468109131, "episode/length": 288.0, "episode/score": 0.06415357908770147, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06415357908770147}
{"step": 169400, "time": 5725.925973653793, "episode/length": 288.0, "episode/score": 0.0618661211261724, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0618661211261724}
{"step": 170040, "time": 5748.880212306976, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 170040, "time": 5752.114112615585, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5752.120936393738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5752.127946853638, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5752.134437799454, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5752.145179510117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5752.151949167252, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170040, "time": 5752.158069372177, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 170096, "time": 5754.144350528717, "episode/length": 288.0, "episode/score": 0.06148903209839318, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06148903209839318}
{"step": 170448, "time": 5765.244201421738, "episode/length": 288.0, "episode/score": 0.05712373059526499, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05712373059526499}
{"step": 170552, "time": 5768.3273594379425, "episode/length": 288.0, "episode/score": 0.08102326785842706, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08102326785842706}
{"step": 170776, "time": 5775.391873598099, "episode/length": 288.0, "episode/score": 0.052261141200858674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052261141200858674}
{"step": 170904, "time": 5779.412965774536, "episode/length": 288.0, "episode/score": 0.09095168795846575, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09095168795846575}
{"step": 171088, "time": 5785.535412788391, "episode/length": 288.0, "episode/score": 0.06625212887092857, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06625212887092857}
{"step": 171192, "time": 5788.624876260757, "episode/length": 288.0, "episode/score": 0.04931384989600929, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04931384989600929}
{"step": 171712, "time": 5805.238574981689, "episode/length": 288.0, "episode/score": 0.04179875846818959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04179875846818959}
{"step": 172408, "time": 5827.411523580551, "episode/length": 288.0, "episode/score": 0.053568310769264826, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053568310769264826}
{"step": 172760, "time": 5838.489112615585, "episode/length": 288.0, "episode/score": 0.0769581491945246, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0769581491945246}
{"step": 172864, "time": 5842.049693346024, "episode/length": 288.0, "episode/score": 0.08081351367968637, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08081351367968637}
{"step": 173088, "time": 5849.072016000748, "episode/length": 288.0, "episode/score": 0.06474484655632295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06474484655632295}
{"step": 173216, "time": 5853.0784730911255, "episode/length": 288.0, "episode/score": 0.07151734522005881, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07151734522005881}
{"step": 173400, "time": 5858.6720724105835, "episode/length": 288.0, "episode/score": 0.028726285351581282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028726285351581282}
{"step": 173504, "time": 5862.165009498596, "episode/length": 288.0, "episode/score": 0.05003161618765262, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05003161618765262}
{"step": 174024, "time": 5878.433314800262, "episode/length": 288.0, "episode/score": 0.05358819990840402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05358819990840402}
{"step": 174720, "time": 5900.503115653992, "episode/length": 288.0, "episode/score": 0.06901392491658953, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06901392491658953}
{"step": 175072, "time": 5911.636991024017, "episode/length": 288.0, "episode/score": 0.057917897541244656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057917897541244656}
{"step": 175176, "time": 5914.687360048294, "episode/length": 288.0, "episode/score": 0.07422709647954662, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07422709647954662}
{"step": 175400, "time": 5921.729494810104, "episode/length": 288.0, "episode/score": 0.057907962719013995, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057907962719013995}
{"step": 175528, "time": 5925.787983179092, "episode/length": 288.0, "episode/score": 0.0437563105469394, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0437563105469394}
{"step": 175712, "time": 5931.919749498367, "episode/length": 288.0, "episode/score": 0.04114245667972227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04114245667972227}
{"step": 175816, "time": 5934.973687648773, "episode/length": 288.0, "episode/score": 0.047640542050714885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047640542050714885}
{"step": 176336, "time": 5951.474536895752, "episode/length": 288.0, "episode/score": 0.07330240097633123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07330240097633123}
{"step": 177032, "time": 5973.330283880234, "episode/length": 288.0, "episode/score": 0.06561168426759423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06561168426759423}
{"step": 177384, "time": 5984.442065954208, "episode/length": 288.0, "episode/score": 0.07212354859387915, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07212354859387915}
{"step": 177488, "time": 5987.930919647217, "episode/length": 288.0, "episode/score": 0.029700543008175373, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029700543008175373}
{"step": 177712, "time": 5995.017420530319, "episode/length": 288.0, "episode/score": 0.03216538121068879, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03216538121068879}
{"step": 177840, "time": 5999.017323970795, "episode/length": 288.0, "episode/score": 0.07114099286980036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07114099286980036}
{"step": 178024, "time": 6004.573002576828, "episode/length": 288.0, "episode/score": 0.05450800649600751, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05450800649600751}
{"step": 178128, "time": 6008.13653922081, "episode/length": 288.0, "episode/score": 0.0606046168762191, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0606046168762191}
{"step": 178648, "time": 6024.371090173721, "episode/length": 288.0, "episode/score": 0.05154899204188723, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05154899204188723}
{"step": 179344, "time": 6046.629393815994, "episode/length": 288.0, "episode/score": 0.05710696750716693, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05710696750716693}
{"step": 179696, "time": 6057.845577478409, "episode/length": 288.0, "episode/score": 0.03906566513080634, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03906566513080634}
{"step": 179800, "time": 6060.9190447330475, "episode/length": 288.0, "episode/score": 0.053974098827438866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053974098827438866}
{"step": 180024, "time": 6067.988224029541, "episode/length": 288.0, "episode/score": 0.06953112021159313, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06953112021159313}
{"step": 180024, "time": 6073.2401304244995, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.247467041016, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.253915786743, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.260195732117, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.266288757324, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.27254319191, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.2791538238525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180024, "time": 6073.285729169846, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 180152, "time": 6077.360446214676, "episode/length": 288.0, "episode/score": 0.07993959329249378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07993959329249378}
{"step": 180336, "time": 6083.994667053223, "episode/length": 288.0, "episode/score": 0.06172552844481061, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06172552844481061}
{"step": 180440, "time": 6087.089243173599, "episode/length": 288.0, "episode/score": 0.0546402043716796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0546402043716796}
{"step": 180960, "time": 6103.749529361725, "episode/length": 288.0, "episode/score": 0.05205765102201099, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05205765102201099}
{"step": 181656, "time": 6125.492850780487, "episode/length": 288.0, "episode/score": 0.04693215348945046, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04693215348945046}
{"step": 182008, "time": 6136.60115814209, "episode/length": 288.0, "episode/score": 0.034534237080606545, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034534237080606545}
{"step": 182112, "time": 6140.106153488159, "episode/length": 288.0, "episode/score": 0.044128224304472496, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044128224304472496}
{"step": 182336, "time": 6147.310333013535, "episode/length": 288.0, "episode/score": 0.05671569871398674, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05671569871398674}
{"step": 182464, "time": 6151.352893590927, "episode/length": 288.0, "episode/score": 0.058749160276050816, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058749160276050816}
{"step": 182648, "time": 6156.945081233978, "episode/length": 288.0, "episode/score": 0.04861355956376201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04861355956376201}
{"step": 182752, "time": 6160.51034784317, "episode/length": 288.0, "episode/score": 0.05268449257809493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05268449257809493}
{"step": 183272, "time": 6176.8176527023315, "episode/length": 288.0, "episode/score": 0.05994186616433694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05994186616433694}
{"step": 183968, "time": 6198.992013454437, "episode/length": 288.0, "episode/score": 0.06292107444167527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06292107444167527}
{"step": 184320, "time": 6210.168037652969, "episode/length": 288.0, "episode/score": 0.06517708323346483, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06517708323346483}
{"step": 184424, "time": 6213.230411291122, "episode/length": 288.0, "episode/score": 0.05916142420642245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05916142420642245}
{"step": 184648, "time": 6220.330099821091, "episode/length": 288.0, "episode/score": 0.05803426272564138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05803426272564138}
{"step": 184776, "time": 6224.361022949219, "episode/length": 288.0, "episode/score": 0.053987657452552185, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053987657452552185}
{"step": 184912, "time": 6228.887500762939, "episode/length": 117.0, "episode/score": 0.6541685477179726, "episode/reward_rate": 0.00847457627118644, "episode/intrinsic_return": 0.019793542921661356}
{"step": 184960, "time": 6230.409795999527, "episode/length": 288.0, "episode/score": 0.05122145351097629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05122145351097629}
{"step": 185064, "time": 6233.559946298599, "episode/length": 288.0, "episode/score": 0.03419008212341623, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03419008212341623}
{"step": 185584, "time": 6250.275460958481, "episode/length": 288.0, "episode/score": 0.06345797860180369, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06345797860180369}
{"step": 186105, "time": 6267.5036444664, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.99603271484375, "train/action_min": 0.0, "train/action_std": 2.00154832159121, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.00012028834433144813, "train/actor_opt_grad_steps": 10565.0, "train/actor_opt_loss": -4.517924918437895, "train/adv_mag": 0.0005212708462759392, "train/adv_max": 0.0004573031568650118, "train/adv_mean": 6.126242395597864e-05, "train/adv_min": -0.00034428433966390864, "train/adv_std": 0.00011639638010191701, "train/cont_avg": 0.9963907458118557, "train/cont_loss_mean": 0.023928210852168424, "train/cont_loss_std": 0.329359492387853, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.671828143298626, "train/cont_pos_acc": 0.9999999849452186, "train/cont_pos_loss": 0.0034702454007125086, "train/cont_pred": 0.9965358490181953, "train/cont_rate": 0.9963907458118557, "train/dyn_loss_mean": 1.0, "train/dyn_loss_std": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.012181078022005055, "train/extr_critic_critic_opt_grad_steps": 10565.0, "train/extr_critic_critic_opt_loss": 13517.546220602448, "train/extr_critic_mag": 0.08466977372611921, "train/extr_critic_max": 0.08466977372611921, "train/extr_critic_mean": 0.08444805858061485, "train/extr_critic_min": 0.08418703325015982, "train/extr_critic_std": 7.261450155196726e-05, "train/extr_return_normed_mag": 0.0005441675941968701, "train/extr_return_normed_max": 0.0004716392644901866, "train/extr_return_normed_mean": 0.00025092169153872795, "train/extr_return_normed_min": -1.8547605915167897e-05, "train/extr_return_normed_std": 8.922403406630991e-05, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0847300254192549, "train/extr_return_raw_max": 0.0847300254192549, "train/extr_return_raw_mean": 0.08450931149352457, "train/extr_return_raw_min": 0.08423983854884953, "train/extr_return_raw_std": 8.922403427493112e-05, "train/extr_reward_mag": 0.0002633554419291388, "train/extr_reward_max": 0.0002633554419291388, "train/extr_reward_mean": 0.0002631678361626889, "train/extr_reward_min": 0.00026298675340475497, "train/extr_reward_std": 8.041295013309182e-08, "train/image_loss_mean": 0.2424113679792463, "train/image_loss_std": 0.08418064695043662, "train/model_loss_mean": 0.8781507602057506, "train/model_loss_std": 0.386257452602239, "train/model_opt_grad_norm": 47.18243571409245, "train/model_opt_grad_steps": 10553.335051546392, "train/model_opt_loss": 2697.8885598723423, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3079.896907216495, "train/policy_entropy_mag": 1.9458521149822117, "train/policy_entropy_max": 1.9458521149822117, "train/policy_entropy_mean": 1.9424960607105923, "train/policy_entropy_min": 1.9073673922991015, "train/policy_entropy_std": 0.002663226393123455, "train/policy_logprob_mag": 2.3165839025654744, "train/policy_logprob_max": -1.5907142617038845, "train/policy_logprob_mean": -1.942495682190374, "train/policy_logprob_min": -2.3165839025654744, "train/policy_logprob_std": 0.07310817930271331, "train/policy_randomness_mag": 0.9999702357754265, "train/policy_randomness_max": 0.9999702357754265, "train/policy_randomness_mean": 0.9982455676978397, "train/policy_randomness_min": 0.9801929974064385, "train/policy_randomness_std": 0.0013686277096210163, "train/post_ent_mag": 53.4021329388176, "train/post_ent_max": 53.4021329388176, "train/post_ent_mean": 53.341963836827226, "train/post_ent_min": 53.31082684231787, "train/post_ent_std": 0.015743681277657292, "train/prior_ent_mag": 52.91355770150411, "train/prior_ent_max": 52.91355770150411, "train/prior_ent_mean": 52.65357725399057, "train/prior_ent_min": 52.520163880181066, "train/prior_ent_std": 0.05490449859194227, "train/rep_loss_mean": 1.0, "train/rep_loss_std": 0.0, "train/reward_avg": 0.0003056322159479641, "train/reward_loss_mean": 0.01181116216268736, "train/reward_loss_std": 0.07199395402843498, "train/reward_max_data": 0.09826031129581604, "train/reward_max_pred": 0.0002631901465740401, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009833270796699468, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.387778939427557, "train/reward_pred": 0.00026292528011404053, "train/reward_rate": 0.00021142074742268042, "train_stats/mean_log_entropy": 1.9360048523489035, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.020054301247000694, "report/cont_loss_std": 0.3063381016254425, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.671418190002441, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0034489219542592764, "report/cont_pred": 0.9965570569038391, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.23049652576446533, "report/image_loss_std": 0.09396619349718094, "report/model_loss_mean": 0.8609901666641235, "report/model_loss_std": 0.32618048787117004, "report/post_ent_mag": 56.88684844970703, "report/post_ent_max": 56.88684844970703, "report/post_ent_mean": 56.700660705566406, "report/post_ent_min": 56.54890441894531, "report/post_ent_std": 0.06729288399219513, "report/prior_ent_mag": 54.680301666259766, "report/prior_ent_max": 54.680301666259766, "report/prior_ent_mean": 53.305992126464844, "report/prior_ent_min": 52.865108489990234, "report/prior_ent_std": 0.3313058018684387, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002143769816029817, "report/reward_loss_mean": 0.010439307428896427, "report/reward_loss_std": 0.017236649990081787, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0002510547637939453, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010439307428896427, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002498030662536621, "report/reward_rate": 0.0, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 0.0034489219542592764, "eval/cont_loss_std": 6.984919309616089e-10, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0034489219542592764, "eval/cont_pred": 0.9965570569038391, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.24627001583576202, "eval/image_loss_std": 0.08668892830610275, "eval/model_loss_mean": 0.8511250019073486, "eval/model_loss_std": 0.08668889105319977, "eval/post_ent_mag": 56.891143798828125, "eval/post_ent_max": 56.891143798828125, "eval/post_ent_mean": 56.68943786621094, "eval/post_ent_min": 56.560787200927734, "eval/post_ent_std": 0.06195680797100067, "eval/prior_ent_mag": 55.078182220458984, "eval/prior_ent_max": 55.078182220458984, "eval/prior_ent_mean": 53.26036071777344, "eval/prior_ent_min": 52.825836181640625, "eval/prior_ent_std": 0.28474828600883484, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014060605317354202, "eval/reward_loss_std": 5.1315678319951985e-06, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0002510547637939453, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014060605317354202, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002499036490917206, "eval/reward_rate": 0.0, "replay/size": 185601.0, "replay/inserts": 31024.0, "replay/samples": 31024.0, "replay/insert_wait_avg": 1.3259574271404234e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.991141545028647e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 44984.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1678247990767712e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4544970989227, "timer/env.step_count": 3878.0, "timer/env.step_total": 37.301013231277466, "timer/env.step_frac": 0.037284067730657844, "timer/env.step_avg": 0.009618621256131374, "timer/env.step_min": 0.007861137390136719, "timer/env.step_max": 0.04701828956604004, "timer/replay._sample_count": 31024.0, "timer/replay._sample_total": 15.699483871459961, "timer/replay._sample_frac": 0.01569235174311744, "timer/replay._sample_avg": 0.0005060431882239544, "timer/replay._sample_min": 0.00037384033203125, "timer/replay._sample_max": 0.011178731918334961, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4745.0, "timer/agent.policy_total": 47.91225290298462, "timer/agent.policy_frac": 0.0478904868156609, "timer/agent.policy_avg": 0.010097418946888223, "timer/agent.policy_min": 0.008701562881469727, "timer/agent.policy_max": 0.09734702110290527, "timer/dataset_train_count": 1939.0, "timer/dataset_train_total": 0.20936846733093262, "timer/dataset_train_frac": 0.00020927335319902184, "timer/dataset_train_avg": 0.0001079775489071339, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0005633831024169922, "timer/agent.train_count": 1939.0, "timer/agent.train_total": 865.7406885623932, "timer/agent.train_frac": 0.8653473906837671, "timer/agent.train_avg": 0.44648823546281236, "timer/agent.train_min": 0.4347057342529297, "timer/agent.train_max": 0.5923786163330078, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47826242446899414, "timer/agent.report_frac": 0.00047804515433319566, "timer/agent.report_avg": 0.23913121223449707, "timer/agent.report_min": 0.23170256614685059, "timer/agent.report_max": 0.24655985832214355, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.170967102050781e-05, "timer/dataset_eval_frac": 3.169526561423656e-08, "timer/dataset_eval_avg": 3.170967102050781e-05, "timer/dataset_eval_min": 3.170967102050781e-05, "timer/dataset_eval_max": 3.170967102050781e-05, "fps": 31.009391487605797}
{"step": 186632, "time": 6283.864855051041, "episode/length": 288.0, "episode/score": 0.04588545606128491, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04588545606128491}
{"step": 186736, "time": 6287.395569562912, "episode/length": 288.0, "episode/score": 0.051902096790627184, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051902096790627184}
{"step": 186960, "time": 6294.5404443740845, "episode/length": 288.0, "episode/score": 0.06595098179775505, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06595098179775505}
{"step": 187088, "time": 6298.590385913849, "episode/length": 288.0, "episode/score": 0.05298382089856091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05298382089856091}
{"step": 187224, "time": 6302.685818195343, "episode/length": 288.0, "episode/score": 0.062137565559055474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.062137565559055474}
{"step": 187272, "time": 6304.207376718521, "episode/length": 288.0, "episode/score": 0.06422779581734517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06422779581734517}
{"step": 187376, "time": 6307.738209724426, "episode/length": 288.0, "episode/score": 0.057387711106159145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057387711106159145}
{"step": 187896, "time": 6324.023202896118, "episode/length": 288.0, "episode/score": 0.07424787631904906, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07424787631904906}
{"step": 188944, "time": 6357.884409427643, "episode/length": 288.0, "episode/score": 0.046090134488608214, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046090134488608214}
{"step": 189048, "time": 6360.936286449432, "episode/length": 288.0, "episode/score": 0.06104340521163465, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06104340521163465}
{"step": 189272, "time": 6367.9896647930145, "episode/length": 288.0, "episode/score": 0.054010581179937844, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054010581179937844}
{"step": 189400, "time": 6372.012222766876, "episode/length": 288.0, "episode/score": 0.08114506544181666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08114506544181666}
{"step": 189536, "time": 6376.498941898346, "episode/length": 288.0, "episode/score": 0.026023972586926902, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026023972586926902}
{"step": 189584, "time": 6378.024611234665, "episode/length": 288.0, "episode/score": 0.047410514739681275, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047410514739681275}
{"step": 189688, "time": 6381.177883148193, "episode/length": 288.0, "episode/score": 0.057610369173119125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057610369173119125}
{"step": 190008, "time": 6391.857709169388, "eval_episode/length": 31.0, "eval_episode/score": 0.903124988079071, "eval_episode/reward_rate": 0.03125}
{"step": 190008, "time": 6395.305864095688, "eval_episode/length": 222.0, "eval_episode/score": 0.3062500059604645, "eval_episode/reward_rate": 0.004484304932735426}
{"step": 190008, "time": 6396.555089712143, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6396.563176870346, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6396.57030916214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6396.576562404633, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6396.584389925003, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190008, "time": 6396.590880393982, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 190208, "time": 6403.163256406784, "episode/length": 288.0, "episode/score": 0.05909883663076698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05909883663076698}
{"step": 191256, "time": 6436.010504245758, "episode/length": 288.0, "episode/score": 0.05953796159282376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05953796159282376}
{"step": 191360, "time": 6439.508584260941, "episode/length": 288.0, "episode/score": 0.04778155482338775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04778155482338775}
{"step": 191584, "time": 6446.704505205154, "episode/length": 288.0, "episode/score": 0.06290780342291669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06290780342291669}
{"step": 191712, "time": 6450.74037194252, "episode/length": 288.0, "episode/score": 0.11073856451716324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11073856451716324}
{"step": 191848, "time": 6454.806050777435, "episode/length": 288.0, "episode/score": 0.07281255282254051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07281255282254051}
{"step": 191896, "time": 6456.321485280991, "episode/length": 288.0, "episode/score": 0.11057372029141277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11057372029141277}
{"step": 192000, "time": 6459.837435245514, "episode/length": 288.0, "episode/score": 0.08693787769357186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08693787769357186}
{"step": 192520, "time": 6476.20765042305, "episode/length": 288.0, "episode/score": 0.10865395155190072, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10865395155190072}
{"step": 193568, "time": 6509.58717751503, "episode/length": 288.0, "episode/score": 0.07800528324753486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07800528324753486}
{"step": 193672, "time": 6512.641688585281, "episode/length": 288.0, "episode/score": 0.09328237879591939, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09328237879591939}
{"step": 193896, "time": 6519.739309549332, "episode/length": 288.0, "episode/score": 0.08056222657457113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08056222657457113}
{"step": 194024, "time": 6523.786478996277, "episode/length": 288.0, "episode/score": 0.09830411622050406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09830411622050406}
{"step": 194160, "time": 6528.307318210602, "episode/length": 288.0, "episode/score": 0.1084386353790876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1084386353790876}
{"step": 194208, "time": 6529.82728099823, "episode/length": 288.0, "episode/score": 0.08804779278808894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08804779278808894}
{"step": 194312, "time": 6532.947840213776, "episode/length": 288.0, "episode/score": 0.08632921544085548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08632921544085548}
{"step": 194832, "time": 6549.508381128311, "episode/length": 288.0, "episode/score": 0.10805974524009798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10805974524009798}
{"step": 195880, "time": 6583.239022731781, "episode/length": 288.0, "episode/score": 0.07451657827016334, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07451657827016334}
{"step": 195984, "time": 6586.802300453186, "episode/length": 288.0, "episode/score": 0.08294026132841736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08294026132841736}
{"step": 196208, "time": 6594.018016338348, "episode/length": 288.0, "episode/score": 0.10692634763336173, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10692634763336173}
{"step": 196336, "time": 6598.068693399429, "episode/length": 288.0, "episode/score": 0.14400890019828694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14400890019828694}
{"step": 196472, "time": 6602.1275725364685, "episode/length": 288.0, "episode/score": 0.09109803605167599, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09109803605167599}
{"step": 196520, "time": 6603.639070034027, "episode/length": 288.0, "episode/score": 0.09027165502925527, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09027165502925527}
{"step": 196624, "time": 6607.632689714432, "episode/length": 288.0, "episode/score": 0.11970704900261353, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11970704900261353}
{"step": 197144, "time": 6623.984505176544, "episode/length": 288.0, "episode/score": 0.10434117615875493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10434117615875493}
{"step": 198192, "time": 6657.428211450577, "episode/length": 288.0, "episode/score": 0.10042997068615023, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10042997068615023}
{"step": 198296, "time": 6660.479182243347, "episode/length": 288.0, "episode/score": 0.11432039422254547, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11432039422254547}
{"step": 198520, "time": 6667.549337148666, "episode/length": 288.0, "episode/score": 0.1045762233258074, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1045762233258074}
{"step": 198648, "time": 6671.582487821579, "episode/length": 288.0, "episode/score": 0.04445596840685084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04445596840685084}
{"step": 198784, "time": 6676.110376834869, "episode/length": 288.0, "episode/score": 0.07381348669457566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07381348669457566}
{"step": 198832, "time": 6677.644109010696, "episode/length": 288.0, "episode/score": 0.09907034522836966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09907034522836966}
{"step": 198936, "time": 6680.68896150589, "episode/length": 288.0, "episode/score": 0.12006062572447718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12006062572447718}
{"step": 199456, "time": 6697.313414096832, "episode/length": 288.0, "episode/score": 0.11822912751449621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11822912751449621}
{"step": 200096, "time": 6719.054973602295, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 200096, "time": 6723.817742586136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6723.825006723404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6723.831520557404, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6723.84010219574, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6723.846779346466, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6723.854622840881, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200096, "time": 6723.860840082169, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 200504, "time": 6736.459819316864, "episode/length": 288.0, "episode/score": 0.11603200803864411, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11603200803864411}
{"step": 200608, "time": 6739.972188711166, "episode/length": 288.0, "episode/score": 0.09158355210178115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09158355210178115}
{"step": 200832, "time": 6747.079980611801, "episode/length": 288.0, "episode/score": 0.12158749509677591, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12158749509677591}
{"step": 200960, "time": 6751.093870639801, "episode/length": 288.0, "episode/score": 0.11618985654320113, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11618985654320113}
{"step": 201096, "time": 6755.222053289413, "episode/length": 288.0, "episode/score": 0.10949484578600277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10949484578600277}
{"step": 201144, "time": 6756.729500293732, "episode/length": 288.0, "episode/score": 0.08739774322413041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08739774322413041}
{"step": 201248, "time": 6760.233327388763, "episode/length": 288.0, "episode/score": 0.11670673794776576, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11670673794776576}
{"step": 201768, "time": 6776.534771203995, "episode/length": 288.0, "episode/score": 0.0935388868194309, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0935388868194309}
{"step": 202816, "time": 6809.919488191605, "episode/length": 288.0, "episode/score": 0.06467380846669357, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06467380846669357}
{"step": 202920, "time": 6813.023227453232, "episode/length": 288.0, "episode/score": 0.07526698692765876, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07526698692765876}
{"step": 203144, "time": 6820.037998199463, "episode/length": 288.0, "episode/score": 0.1081308742964211, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1081308742964211}
{"step": 203272, "time": 6824.059103965759, "episode/length": 288.0, "episode/score": 0.14308368412901018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.14308368412901018}
{"step": 203408, "time": 6828.57386136055, "episode/length": 288.0, "episode/score": 0.10258104278705105, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10258104278705105}
{"step": 203456, "time": 6830.077272176743, "episode/length": 288.0, "episode/score": 0.09271504262551389, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09271504262551389}
{"step": 203560, "time": 6833.242409229279, "episode/length": 288.0, "episode/score": 0.09144476963138004, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09144476963138004}
{"step": 204080, "time": 6849.893483161926, "episode/length": 288.0, "episode/score": 0.11993073571011337, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11993073571011337}
{"step": 205128, "time": 6883.44025850296, "episode/length": 288.0, "episode/score": 0.08033676548143376, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08033676548143376}
{"step": 205232, "time": 6886.950253248215, "episode/length": 288.0, "episode/score": 0.11270208187511344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11270208187511344}
{"step": 205456, "time": 6894.089327812195, "episode/length": 288.0, "episode/score": 0.09454979569773059, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09454979569773059}
{"step": 205584, "time": 6898.117662191391, "episode/length": 288.0, "episode/score": 0.07620140649078166, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07620140649078166}
{"step": 205720, "time": 6902.211078643799, "episode/length": 288.0, "episode/score": 0.06788607262831192, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06788607262831192}
{"step": 205768, "time": 6903.722574472427, "episode/length": 288.0, "episode/score": 0.11340778336523272, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11340778336523272}
{"step": 205872, "time": 6907.23427939415, "episode/length": 288.0, "episode/score": 0.09208698726729381, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09208698726729381}
{"step": 206392, "time": 6923.474396944046, "episode/length": 288.0, "episode/score": 0.10123103696480484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10123103696480484}
{"step": 207440, "time": 6956.847915887833, "episode/length": 288.0, "episode/score": 0.07003789035184127, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07003789035184127}
{"step": 207544, "time": 6959.929365873337, "episode/length": 288.0, "episode/score": 0.09757724074563612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09757724074563612}
{"step": 207768, "time": 6966.998371124268, "episode/length": 288.0, "episode/score": 0.09842646485515161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09842646485515161}
{"step": 207896, "time": 6971.050875663757, "episode/length": 288.0, "episode/score": 0.07699494170390153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07699494170390153}
{"step": 208032, "time": 6975.577832460403, "episode/length": 288.0, "episode/score": 0.09860208774205148, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09860208774205148}
{"step": 208080, "time": 6977.096236228943, "episode/length": 288.0, "episode/score": 0.11161690268852453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11161690268852453}
{"step": 208184, "time": 6980.153470754623, "episode/length": 288.0, "episode/score": 0.059600917064130954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059600917064130954}
{"step": 208704, "time": 6996.99099612236, "episode/length": 288.0, "episode/score": 0.06370780893200845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06370780893200845}
{"step": 209752, "time": 7030.069226026535, "episode/length": 288.0, "episode/score": 0.08442444307593178, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08442444307593178}
{"step": 209856, "time": 7033.594625234604, "episode/length": 288.0, "episode/score": 0.10219185940513853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10219185940513853}
{"step": 210080, "time": 7040.707790613174, "episode/length": 288.0, "episode/score": 0.09216692186453201, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09216692186453201}
{"step": 210080, "time": 7046.11031627655, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.118176460266, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.125406742096, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.131537914276, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.137917995453, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.143914461136, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.150258779526, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210080, "time": 7046.163211345673, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 210208, "time": 7050.211309671402, "episode/length": 288.0, "episode/score": 0.08899559353335462, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08899559353335462}
{"step": 210344, "time": 7054.259668588638, "episode/length": 288.0, "episode/score": 0.07974643532577375, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07974643532577375}
{"step": 210392, "time": 7055.785340547562, "episode/length": 288.0, "episode/score": 0.06082442538206578, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06082442538206578}
{"step": 210496, "time": 7059.272364139557, "episode/length": 288.0, "episode/score": 0.06248170615424442, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06248170615424442}
{"step": 211016, "time": 7075.567432641983, "episode/length": 288.0, "episode/score": 0.07836106035983903, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07836106035983903}
{"step": 212064, "time": 7108.96847486496, "episode/length": 288.0, "episode/score": 0.06985693267483839, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06985693267483839}
{"step": 212168, "time": 7112.052217245102, "episode/length": 288.0, "episode/score": 0.07595554175475172, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07595554175475172}
{"step": 212392, "time": 7119.105003356934, "episode/length": 288.0, "episode/score": 0.055131065955947633, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055131065955947633}
{"step": 212520, "time": 7123.173505067825, "episode/length": 288.0, "episode/score": 0.06813301364729796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06813301364729796}
{"step": 212656, "time": 7127.69026350975, "episode/length": 288.0, "episode/score": 0.07575883497531777, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07575883497531777}
{"step": 212704, "time": 7129.20605635643, "episode/length": 288.0, "episode/score": 0.11764502786104458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11764502786104458}
{"step": 212808, "time": 7132.370700120926, "episode/length": 288.0, "episode/score": 0.07938272311929495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07938272311929495}
{"step": 213328, "time": 7149.480347156525, "episode/length": 288.0, "episode/score": 0.09208324817109315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09208324817109315}
{"step": 214376, "time": 7182.279368638992, "episode/length": 288.0, "episode/score": 0.07965046474180326, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07965046474180326}
{"step": 214480, "time": 7185.770236253738, "episode/length": 288.0, "episode/score": 0.11356887328724952, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11356887328724952}
{"step": 214704, "time": 7192.973929405212, "episode/length": 288.0, "episode/score": 0.06483751990475639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06483751990475639}
{"step": 214832, "time": 7197.019767522812, "episode/length": 288.0, "episode/score": 0.05334076535274335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05334076535274335}
{"step": 214848, "time": 7197.534672737122, "episode/length": 273.0, "episode/score": 0.2197728656655613, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.07289787279017901}
{"step": 215016, "time": 7202.577735900879, "episode/length": 288.0, "episode/score": 0.08674861275682133, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08674861275682133}
{"step": 215120, "time": 7206.066154241562, "episode/length": 288.0, "episode/score": 0.12321102661667283, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12321102661667283}
{"step": 215640, "time": 7222.337071418762, "episode/length": 288.0, "episode/score": 0.13401052144382675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.13401052144382675}
{"step": 216688, "time": 7255.566506385803, "episode/length": 288.0, "episode/score": 0.11535175290453026, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11535175290453026}
{"step": 216792, "time": 7258.61797952652, "episode/length": 288.0, "episode/score": 0.08734341764107967, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08734341764107967}
{"step": 217016, "time": 7265.643767595291, "episode/length": 288.0, "episode/score": 0.09875899606379335, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09875899606379335}
{"step": 217049, "time": 7267.6595067977905, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.236877125161917, "train/action_min": 0.0, "train/action_std": 1.8410763326704194, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0005802474561608228, "train/actor_opt_grad_steps": 12500.0, "train/actor_opt_loss": 2.442540618393165, "train/adv_mag": 0.0029888797763715754, "train/adv_max": 0.002957009859962167, "train/adv_mean": 0.0005291236223461221, "train/adv_min": -0.001399243047818001, "train/adv_std": 0.0005771856967792871, "train/cont_avg": 0.9963163860103627, "train/cont_loss_mean": 0.024359435780417812, "train/cont_loss_std": 0.330021196703663, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.641600984744925, "train/cont_pos_acc": 0.9999999833230527, "train/cont_pos_loss": 0.003580661829551344, "train/cont_pred": 0.9964258077848761, "train/cont_rate": 0.9963163860103627, "train/dyn_loss_mean": 1.000001960467798, "train/dyn_loss_std": 6.164389242022419e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.09102447331615197, "train/extr_critic_critic_opt_grad_steps": 12500.0, "train/extr_critic_critic_opt_loss": 13195.291789791127, "train/extr_critic_mag": 0.09697154581237952, "train/extr_critic_max": 0.09697154581237952, "train/extr_critic_mean": 0.09616205574934965, "train/extr_critic_min": 0.0946243476373544, "train/extr_critic_std": 0.0003052776855225988, "train/extr_return_normed_mag": 0.004333019526820109, "train/extr_return_normed_max": 0.0042469270257134515, "train/extr_return_normed_mean": 0.0019165868006970593, "train/extr_return_normed_min": 1.332530549153145e-05, "train/extr_return_normed_std": 0.0005992879233639108, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.09902156665535171, "train/extr_return_raw_max": 0.09902156665535171, "train/extr_return_raw_mean": 0.09669123288880976, "train/extr_return_raw_min": 0.09478796493512978, "train/extr_return_raw_std": 0.0005992879226853241, "train/extr_reward_mag": 0.0008947336611970101, "train/extr_reward_max": 0.0008947336611970101, "train/extr_reward_mean": 0.00038518966846662654, "train/extr_reward_min": 8.937299560388752e-05, "train/extr_reward_std": 0.00020909218856461436, "train/image_loss_mean": 0.20526284295969058, "train/image_loss_std": 0.0963289052093585, "train/model_loss_mean": 0.8402759052928865, "train/model_loss_std": 0.3792590713562743, "train/model_opt_grad_norm": 42.98587874180295, "train/model_opt_grad_steps": 12486.943005181347, "train/model_opt_loss": 2636.689740274854, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3147.6683937823836, "train/policy_entropy_mag": 1.916202264746236, "train/policy_entropy_max": 1.916202264746236, "train/policy_entropy_mean": 1.7305817190229584, "train/policy_entropy_min": 1.30625126553323, "train/policy_entropy_std": 0.07219095901137343, "train/policy_logprob_mag": 3.505598978675091, "train/policy_logprob_max": -0.5147843228102965, "train/policy_logprob_mean": -1.730771964695787, "train/policy_logprob_min": -3.505598978675091, "train/policy_logprob_std": 0.6157914337562156, "train/policy_randomness_mag": 0.9847332266945913, "train/policy_randomness_max": 0.9847332266945913, "train/policy_randomness_mean": 0.8893431329356574, "train/policy_randomness_min": 0.6712803993509223, "train/policy_randomness_std": 0.03709881640536412, "train/post_ent_mag": 59.193412108742514, "train/post_ent_max": 59.193412108742514, "train/post_ent_mean": 58.70269273352746, "train/post_ent_min": 58.331542059547544, "train/post_ent_std": 0.17204563068756784, "train/prior_ent_mag": 59.16998854325843, "train/prior_ent_max": 59.16998854325843, "train/prior_ent_mean": 55.43715798175397, "train/prior_ent_min": 53.97555039954309, "train/prior_ent_std": 0.7776222179590729, "train/rep_loss_mean": 1.000001960467798, "train/rep_loss_std": 6.164389242022419e-05, "train/reward_avg": 0.0002876402776437411, "train/reward_loss_mean": 0.010652428982692525, "train/reward_loss_std": 0.057507821768908306, "train/reward_max_data": 0.08417746354343245, "train/reward_max_pred": 0.0008426144950748108, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009238751622042353, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 9.67530505997794, "train/reward_pred": 0.00026489954461087834, "train/reward_rate": 0.00014673737046632125, "train_stats/mean_log_entropy": 1.742513119617355, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.02557527832686901, "report/cont_loss_std": 0.35136252641677856, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.6363844871521, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035721089225262403, "report/cont_pred": 0.996434211730957, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.1806289404630661, "report/image_loss_std": 0.1010635644197464, "report/model_loss_mean": 0.8146302700042725, "report/model_loss_std": 0.36149948835372925, "report/post_ent_mag": 58.556236267089844, "report/post_ent_max": 58.556236267089844, "report/post_ent_mean": 57.98463439941406, "report/post_ent_min": 57.55799102783203, "report/post_ent_std": 0.19964319467544556, "report/prior_ent_mag": 58.75447463989258, "report/prior_ent_max": 58.75447463989258, "report/prior_ent_mean": 56.1810188293457, "report/prior_ent_min": 54.41423034667969, "report/prior_ent_std": 0.6187204718589783, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001891822466859594, "report/reward_loss_mean": 0.008426005952060223, "report/reward_loss_std": 0.014517196454107761, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0009099245071411133, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008426005952060223, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002368034329265356, "report/reward_rate": 0.0, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.01457369513809681, "eval/cont_loss_std": 0.2486942559480667, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.6363844871521, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0035721093881875277, "eval/cont_pred": 0.996434211730957, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.19510120153427124, "eval/image_loss_std": 0.10106712579727173, "eval/model_loss_mean": 0.8108670711517334, "eval/model_loss_std": 0.2797761857509613, "eval/post_ent_mag": 58.53186798095703, "eval/post_ent_max": 58.53186798095703, "eval/post_ent_mean": 57.94657516479492, "eval/post_ent_min": 57.55681610107422, "eval/post_ent_std": 0.18455472588539124, "eval/prior_ent_mag": 58.16205978393555, "eval/prior_ent_max": 58.16205978393555, "eval/prior_ent_mean": 56.18907165527344, "eval/prior_ent_min": 54.40888595581055, "eval/prior_ent_std": 0.5136449933052063, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0011921841651201248, "eval/reward_loss_std": 0.0013520955108106136, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0008518695831298828, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0011921841651201248, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.0002047596499323845, "eval/reward_rate": 0.0, "replay/size": 216545.0, "replay/inserts": 30944.0, "replay/samples": 30944.0, "replay/insert_wait_avg": 1.3204478305276202e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.046781141484289e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51920.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.163906154610569e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.137204170227, "timer/env.step_count": 3868.0, "timer/env.step_total": 37.08447051048279, "timer/env.step_frac": 0.037079383064496894, "timer/env.step_avg": 0.009587505302606719, "timer/env.step_min": 0.008023500442504883, "timer/env.step_max": 0.03669166564941406, "timer/replay._sample_count": 30944.0, "timer/replay._sample_total": 15.83491063117981, "timer/replay._sample_frac": 0.01583273831345709, "timer/replay._sample_avg": 0.0005117279805836289, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.025665760040283203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4735.0, "timer/agent.policy_total": 47.944830656051636, "timer/agent.policy_frac": 0.04793825332778166, "timer/agent.policy_avg": 0.010125624214583238, "timer/agent.policy_min": 0.008678913116455078, "timer/agent.policy_max": 0.0820460319519043, "timer/dataset_train_count": 1934.0, "timer/dataset_train_total": 0.21172785758972168, "timer/dataset_train_frac": 0.00021169881162993393, "timer/dataset_train_avg": 0.00010947665852622631, "timer/dataset_train_min": 9.72747802734375e-05, "timer/dataset_train_max": 0.001085519790649414, "timer/agent.train_count": 1934.0, "timer/agent.train_total": 866.2302212715149, "timer/agent.train_frac": 0.8661113871773131, "timer/agent.train_avg": 0.4478956676688288, "timer/agent.train_min": 0.43604159355163574, "timer/agent.train_max": 1.219209909439087, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47844743728637695, "timer/agent.report_frac": 0.00047838180130827673, "timer/agent.report_avg": 0.23922371864318848, "timer/agent.report_min": 0.23340749740600586, "timer/agent.report_max": 0.2450399398803711, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3850793762352185e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 30.93921440303493}
{"step": 217144, "time": 7270.458657741547, "episode/length": 288.0, "episode/score": 0.1146010939817188, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1146010939817188}
{"step": 217160, "time": 7270.967730998993, "episode/length": 288.0, "episode/score": 0.10556412451825281, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10556412451825281}
{"step": 217328, "time": 7276.515456914902, "episode/length": 288.0, "episode/score": 0.1339338786863209, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1339338786863209}
{"step": 217432, "time": 7279.596263408661, "episode/length": 288.0, "episode/score": 0.07333347703627169, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07333347703627169}
{"step": 217952, "time": 7296.390038728714, "episode/length": 288.0, "episode/score": 0.05882781098188161, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05882781098188161}
{"step": 219000, "time": 7329.286004781723, "episode/length": 288.0, "episode/score": 0.0894039006212779, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0894039006212779}
{"step": 219104, "time": 7332.784969329834, "episode/length": 288.0, "episode/score": 0.07533673843965971, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07533673843965971}
{"step": 219328, "time": 7339.859828233719, "episode/length": 288.0, "episode/score": 0.10366780419508359, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10366780419508359}
{"step": 219456, "time": 7343.977650642395, "episode/length": 288.0, "episode/score": 0.1251302229879343, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1251302229879343}
{"step": 219472, "time": 7344.50381731987, "episode/length": 288.0, "episode/score": 0.07695994902371694, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07695994902371694}
{"step": 219640, "time": 7349.573312044144, "episode/length": 288.0, "episode/score": 0.08713743614271152, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08713743614271152}
{"step": 219744, "time": 7353.074997186661, "episode/length": 288.0, "episode/score": 0.08030433270840831, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08030433270840831}
{"step": 220064, "time": 7365.146554231644, "eval_episode/length": 102.0, "eval_episode/score": 0.6812499761581421, "eval_episode/reward_rate": 0.009708737864077669}
{"step": 220064, "time": 7368.701584100723, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7368.709952116013, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7368.717195034027, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7368.724094867706, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7368.731805324554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7368.738662481308, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220064, "time": 7368.745310783386, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 220264, "time": 7374.937742948532, "episode/length": 288.0, "episode/score": 0.0843554093722787, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0843554093722787}
{"step": 221312, "time": 7408.805357933044, "episode/length": 288.0, "episode/score": 0.09593089967373203, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09593089967373203}
{"step": 221416, "time": 7411.900797843933, "episode/length": 288.0, "episode/score": 0.07462523595134485, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07462523595134485}
{"step": 221640, "time": 7418.94903087616, "episode/length": 288.0, "episode/score": 0.1070206418736177, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1070206418736177}
{"step": 221768, "time": 7423.016854286194, "episode/length": 288.0, "episode/score": 0.07964355226076236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07964355226076236}
{"step": 221784, "time": 7423.529940128326, "episode/length": 288.0, "episode/score": 0.08969172630821731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08969172630821731}
{"step": 221952, "time": 7429.04398059845, "episode/length": 288.0, "episode/score": 0.07883247630775259, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07883247630775259}
{"step": 222056, "time": 7432.247800827026, "episode/length": 288.0, "episode/score": 0.08877207738163406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08877207738163406}
{"step": 222576, "time": 7448.788084030151, "episode/length": 288.0, "episode/score": 0.07256195626186468, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07256195626186468}
{"step": 223624, "time": 7481.6374361515045, "episode/length": 288.0, "episode/score": 0.05881552138660595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05881552138660595}
{"step": 223728, "time": 7485.153804063797, "episode/length": 288.0, "episode/score": 0.07937924729526458, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07937924729526458}
{"step": 223952, "time": 7492.379064083099, "episode/length": 288.0, "episode/score": 0.09458856435358598, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09458856435358598}
{"step": 224080, "time": 7496.4127514362335, "episode/length": 288.0, "episode/score": 0.08665259290856397, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08665259290856397}
{"step": 224096, "time": 7496.924949645996, "episode/length": 288.0, "episode/score": 0.0931015678316669, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0931015678316669}
{"step": 224264, "time": 7502.006999254227, "episode/length": 288.0, "episode/score": 0.08750808333573445, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08750808333573445}
{"step": 224368, "time": 7505.542373418808, "episode/length": 288.0, "episode/score": 0.09246299987472639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09246299987472639}
{"step": 224888, "time": 7521.898906707764, "episode/length": 288.0, "episode/score": 0.0888897501714041, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0888897501714041}
{"step": 225936, "time": 7555.294408082962, "episode/length": 288.0, "episode/score": 0.1190375329572646, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1190375329572646}
{"step": 226040, "time": 7558.376529932022, "episode/length": 288.0, "episode/score": 0.07602413469899716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07602413469899716}
{"step": 226264, "time": 7565.460315942764, "episode/length": 288.0, "episode/score": 0.06918323978266017, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06918323978266017}
{"step": 226392, "time": 7569.551476240158, "episode/length": 288.0, "episode/score": 0.02978000565184402, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02978000565184402}
{"step": 226408, "time": 7570.068705320358, "episode/length": 288.0, "episode/score": 0.07949642524877731, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07949642524877731}
{"step": 226576, "time": 7575.637660503387, "episode/length": 288.0, "episode/score": 0.05666461172779691, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05666461172779691}
{"step": 226680, "time": 7578.714237213135, "episode/length": 288.0, "episode/score": 0.03773613229600414, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03773613229600414}
{"step": 227200, "time": 7595.412718296051, "episode/length": 288.0, "episode/score": 0.09596033530092996, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09596033530092996}
{"step": 228248, "time": 7628.4143834114075, "episode/length": 288.0, "episode/score": 0.09711232337409115, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09711232337409115}
{"step": 228352, "time": 7631.931891441345, "episode/length": 288.0, "episode/score": 0.0783979235524157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0783979235524157}
{"step": 228576, "time": 7638.995867729187, "episode/length": 288.0, "episode/score": 0.07657940988644896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07657940988644896}
{"step": 228704, "time": 7643.126369476318, "episode/length": 288.0, "episode/score": 0.08700889830191727, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08700889830191727}
{"step": 228720, "time": 7643.636244058609, "episode/length": 288.0, "episode/score": 0.015636077802895443, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015636077802895443}
{"step": 228888, "time": 7648.71013379097, "episode/length": 288.0, "episode/score": 0.07016665658574084, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07016665658574084}
{"step": 228992, "time": 7652.228695392609, "episode/length": 288.0, "episode/score": 0.06590999573532486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06590999573532486}
{"step": 229512, "time": 7668.93489074707, "episode/length": 288.0, "episode/score": 0.05235168575171656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05235168575171656}
{"step": 230048, "time": 7691.43146443367, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.439077615738, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.446215629578, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.452925443649, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.4593052864075, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.465768814087, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.471775531769, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230048, "time": 7691.478799104691, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 230560, "time": 7707.740260839462, "episode/length": 288.0, "episode/score": 0.05047558803181573, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05047558803181573}
{"step": 230664, "time": 7710.790596485138, "episode/length": 288.0, "episode/score": 0.07164595759289227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07164595759289227}
{"step": 230888, "time": 7717.834580183029, "episode/length": 288.0, "episode/score": 0.07735103355074102, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07735103355074102}
{"step": 231016, "time": 7721.882780313492, "episode/length": 288.0, "episode/score": 0.07307307038561817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07307307038561817}
{"step": 231032, "time": 7722.3927755355835, "episode/length": 288.0, "episode/score": 0.05797093445616497, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05797093445616497}
{"step": 231200, "time": 7727.898309707642, "episode/length": 288.0, "episode/score": 0.06626266184656515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06626266184656515}
{"step": 231304, "time": 7730.9884395599365, "episode/length": 288.0, "episode/score": 0.04696993094148638, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04696993094148638}
{"step": 231824, "time": 7747.679567575455, "episode/length": 288.0, "episode/score": 0.05263336619390202, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05263336619390202}
{"step": 232872, "time": 7780.682742595673, "episode/length": 288.0, "episode/score": 0.0373828458155856, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0373828458155856}
{"step": 232976, "time": 7784.21689748764, "episode/length": 288.0, "episode/score": 0.025079307761103564, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025079307761103564}
{"step": 233200, "time": 7791.391907691956, "episode/length": 288.0, "episode/score": 0.022961743313302918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022961743313302918}
{"step": 233328, "time": 7795.446186542511, "episode/length": 288.0, "episode/score": 0.012978964076836519, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012978964076836519}
{"step": 233344, "time": 7795.952580690384, "episode/length": 288.0, "episode/score": 0.029072630123351928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029072630123351928}
{"step": 233512, "time": 7801.007127285004, "episode/length": 288.0, "episode/score": 0.021356040945676114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021356040945676114}
{"step": 233616, "time": 7804.52082157135, "episode/length": 288.0, "episode/score": 0.036368542105364554, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036368542105364554}
{"step": 234136, "time": 7820.684190273285, "episode/length": 288.0, "episode/score": 0.010970383748741597, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010970383748741597}
{"step": 235184, "time": 7854.284517288208, "episode/length": 288.0, "episode/score": 0.014304872260154866, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014304872260154866}
{"step": 235288, "time": 7857.348826169968, "episode/length": 288.0, "episode/score": 0.014753982749340366, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014753982749340366}
{"step": 235512, "time": 7864.456520318985, "episode/length": 288.0, "episode/score": 0.010723998949742963, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.010723998949742963}
{"step": 235640, "time": 7868.4954562187195, "episode/length": 288.0, "episode/score": 0.020895147125102653, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020895147125102653}
{"step": 235656, "time": 7869.005612373352, "episode/length": 288.0, "episode/score": 0.00917030338716529, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.00917030338716529}
{"step": 235824, "time": 7874.497730016708, "episode/length": 288.0, "episode/score": 0.01210431317085181, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01210431317085181}
{"step": 235928, "time": 7877.52468252182, "episode/length": 288.0, "episode/score": 0.01395668299181807, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01395668299181807}
{"step": 236448, "time": 7894.279479503632, "episode/length": 288.0, "episode/score": 0.01380321628661818, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01380321628661818}
{"step": 237496, "time": 7927.301193237305, "episode/length": 288.0, "episode/score": 0.02425517370596708, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02425517370596708}
{"step": 237600, "time": 7931.310894012451, "episode/length": 288.0, "episode/score": 0.014158573266371377, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.014158573266371377}
{"step": 237824, "time": 7938.3640060424805, "episode/length": 288.0, "episode/score": 0.026210701109462775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026210701109462775}
{"step": 237952, "time": 7942.507395029068, "episode/length": 288.0, "episode/score": 0.03010349583423988, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03010349583423988}
{"step": 237968, "time": 7943.015517473221, "episode/length": 288.0, "episode/score": 0.02225850551434405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02225850551434405}
{"step": 238136, "time": 7948.105973243713, "episode/length": 288.0, "episode/score": 0.029538344469983713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029538344469983713}
{"step": 238240, "time": 7951.626970767975, "episode/length": 288.0, "episode/score": 0.021355450828465905, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021355450828465905}
{"step": 238760, "time": 7967.825408935547, "episode/length": 288.0, "episode/score": 0.03420428012901766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03420428012901766}
{"step": 238960, "time": 7974.510744810104, "episode/length": 125.0, "episode/score": 0.6391865565561261, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.029811527917956937}
{"step": 239488, "time": 7991.188037157059, "episode/length": 65.0, "episode/score": 0.8233124624259887, "episode/reward_rate": 0.015151515151515152, "episode/intrinsic_return": 0.026437433787819486}
{"step": 239808, "time": 8001.392639398575, "episode/length": 288.0, "episode/score": 0.04596174797768526, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04596174797768526}
{"step": 239912, "time": 8004.457508563995, "episode/length": 288.0, "episode/score": 0.031561379565516745, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031561379565516745}
{"step": 240032, "time": 8014.682030916214, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.689348697662, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.716549873352, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.746560096741, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.764180898666, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.771800279617, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.778248786926, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240032, "time": 8014.785542964935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 240136, "time": 8017.851272106171, "episode/length": 288.0, "episode/score": 0.06458714415290956, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06458714415290956}
{"step": 240280, "time": 8022.392038822174, "episode/length": 288.0, "episode/score": 0.0718323573357651, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0718323573357651}
{"step": 240448, "time": 8028.05628490448, "episode/length": 288.0, "episode/score": 0.055331424993070755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055331424993070755}
{"step": 240552, "time": 8031.251443147659, "episode/length": 288.0, "episode/score": 0.05644130781152512, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05644130781152512}
{"step": 241072, "time": 8047.885290622711, "episode/length": 288.0, "episode/score": 0.057444911363973006, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057444911363973006}
{"step": 241800, "time": 8070.667399644852, "episode/length": 288.0, "episode/score": 0.042836001156913994, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042836001156913994}
{"step": 242120, "time": 8080.7550740242, "episode/length": 288.0, "episode/score": 0.05534743140599119, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05534743140599119}
{"step": 242224, "time": 8084.2903175354, "episode/length": 288.0, "episode/score": 0.03390663356326229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03390663356326229}
{"step": 242448, "time": 8091.44354724884, "episode/length": 288.0, "episode/score": 0.06298024940629432, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06298024940629432}
{"step": 242592, "time": 8096.003696203232, "episode/length": 288.0, "episode/score": 0.053407782733472686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053407782733472686}
{"step": 242760, "time": 8101.087156534195, "episode/length": 288.0, "episode/score": 0.05656090303955352, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05656090303955352}
{"step": 242864, "time": 8104.619470834732, "episode/length": 288.0, "episode/score": 0.06621911129150249, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06621911129150249}
{"step": 242968, "time": 8107.68061041832, "episode/length": 236.0, "episode/score": 0.31910667800104875, "episode/reward_rate": 0.004219409282700422, "episode/intrinsic_return": 0.05660669108613092}
{"step": 244112, "time": 8144.089498758316, "episode/length": 288.0, "episode/score": 0.10330681622428983, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10330681622428983}
{"step": 244432, "time": 8154.300988197327, "episode/length": 288.0, "episode/score": 0.09319576509335548, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09319576509335548}
{"step": 244536, "time": 8157.355018615723, "episode/length": 288.0, "episode/score": 0.07916479463904125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07916479463904125}
{"step": 244760, "time": 8164.436742305756, "episode/length": 288.0, "episode/score": 0.07071344262283219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07071344262283219}
{"step": 244904, "time": 8168.970036268234, "episode/length": 288.0, "episode/score": 0.08358453567694824, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08358453567694824}
{"step": 245072, "time": 8174.4974846839905, "episode/length": 288.0, "episode/score": 0.0775271666534536, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0775271666534536}
{"step": 245176, "time": 8177.530436754227, "episode/length": 288.0, "episode/score": 0.08461357415933435, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08461357415933435}
{"step": 245280, "time": 8181.148509979248, "episode/length": 288.0, "episode/score": 0.10633069613186308, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10633069613186308}
{"step": 246424, "time": 8217.669125080109, "episode/length": 288.0, "episode/score": 0.11059593249876798, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11059593249876798}
{"step": 246744, "time": 8227.772092580795, "episode/length": 288.0, "episode/score": 0.12700100772013911, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.12700100772013911}
{"step": 246848, "time": 8231.294651985168, "episode/length": 288.0, "episode/score": 0.07726251398810291, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07726251398810291}
{"step": 247072, "time": 8238.380316495895, "episode/length": 288.0, "episode/score": 0.09737966337814896, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09737966337814896}
{"step": 247216, "time": 8243.03283405304, "episode/length": 288.0, "episode/score": 0.06611040067775775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06611040067775775}
{"step": 247384, "time": 8248.095453977585, "episode/length": 288.0, "episode/score": 0.07483406304993423, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07483406304993423}
{"step": 247488, "time": 8251.62004494667, "episode/length": 288.0, "episode/score": 0.08549585421263828, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08549585421263828}
{"step": 247592, "time": 8254.675752162933, "episode/length": 288.0, "episode/score": 0.1032840872380234, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.1032840872380234}
{"step": 247977, "time": 8267.783747196198, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.475077835554929, "train/action_min": 0.0, "train/action_std": 1.8867963466447653, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0011880567387201266, "train/actor_opt_grad_steps": 14435.0, "train/actor_opt_loss": -0.2842547590892339, "train/adv_mag": 0.00651448135523452, "train/adv_max": 0.006289753563625296, "train/adv_mean": 0.0006151883327002278, "train/adv_min": -0.0022591114735480435, "train/adv_std": 0.0010219789056117002, "train/cont_avg": 0.9967431137242269, "train/cont_loss_mean": 0.021968124796799625, "train/cont_loss_std": 0.3078370068840661, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.650709412085316, "train/cont_pos_acc": 0.9999999864814207, "train/cont_pos_loss": 0.0035464003461307472, "train/cont_pred": 0.9964599839805328, "train/cont_rate": 0.9967431137242269, "train/dyn_loss_mean": 1.0000007674866116, "train/dyn_loss_std": 2.4549015731665968e-05, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.07814056999512142, "train/extr_critic_critic_opt_grad_steps": 14435.0, "train/extr_critic_critic_opt_loss": 11439.357426908828, "train/extr_critic_mag": 0.12043965907440972, "train/extr_critic_max": 0.12043965907440972, "train/extr_critic_mean": 0.11951984223170378, "train/extr_critic_min": 0.11794543143400212, "train/extr_critic_std": 0.00035397067149085733, "train/extr_return_normed_mag": 0.008669161112959851, "train/extr_return_normed_max": 0.008666131799061274, "train/extr_return_normed_mean": 0.0028075774775080044, "train/extr_return_normed_min": -8.117649512192638e-05, "train/extr_return_normed_std": 0.0010629565847771166, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.12599360424372338, "train/extr_return_raw_max": 0.12599360424372338, "train/extr_return_raw_mean": 0.1201350570646758, "train/extr_return_raw_min": 0.11724629594954018, "train/extr_return_raw_std": 0.0010629565753258725, "train/extr_reward_mag": 0.001996002860904969, "train/extr_reward_max": 0.001996002860904969, "train/extr_reward_mean": 0.0004433442705872555, "train/extr_reward_min": 3.1842398889286e-05, "train/extr_reward_std": 0.00033064334256215663, "train/image_loss_mean": 0.19440851214620256, "train/image_loss_std": 0.10106250643730164, "train/model_loss_mean": 0.827115698880756, "train/model_loss_std": 0.3571241551376495, "train/model_opt_grad_norm": 38.91872660646734, "train/model_opt_grad_steps": 14420.432989690722, "train/model_opt_loss": 2451.421694411445, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 2976.8041237113403, "train/policy_entropy_mag": 1.9018498898781453, "train/policy_entropy_max": 1.9018498898781453, "train/policy_entropy_mean": 1.498584097654549, "train/policy_entropy_min": 0.7661728911562679, "train/policy_entropy_std": 0.19325196378163456, "train/policy_logprob_mag": 4.52698028087616, "train/policy_logprob_max": -0.2486736247719256, "train/policy_logprob_mean": -1.4987795838375682, "train/policy_logprob_min": -4.52698028087616, "train/policy_logprob_std": 0.7821595985250375, "train/policy_randomness_mag": 0.9773575645132163, "train/policy_randomness_max": 0.9773575645132163, "train/policy_randomness_mean": 0.770119930204657, "train/policy_randomness_min": 0.3937350016317724, "train/policy_randomness_std": 0.09931186967788591, "train/post_ent_mag": 57.88126605318994, "train/post_ent_max": 57.88126605318994, "train/post_ent_mean": 57.239292380736046, "train/post_ent_min": 56.81200605569427, "train/post_ent_std": 0.20355891298080228, "train/prior_ent_mag": 59.12961619662256, "train/prior_ent_max": 59.12961619662256, "train/prior_ent_mean": 56.20178319006851, "train/prior_ent_min": 53.800895848225075, "train/prior_ent_std": 0.824760427333645, "train/rep_loss_mean": 1.0000007674866116, "train/rep_loss_std": 2.4549015731665968e-05, "train/reward_avg": 0.00027659666997839014, "train/reward_loss_mean": 0.010738583008000223, "train/reward_loss_std": 0.05297382062627483, "train/reward_max_data": 0.06451031050798435, "train/reward_max_pred": 0.0014318455125867705, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009463332190187936, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.738245912960597, "train/reward_pred": 0.00026476416633627615, "train/reward_rate": 0.00014598099226804123, "train_stats/mean_log_entropy": 1.4634376360611483, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025581028312444687, "report/cont_loss_std": 0.35233715176582336, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.651954174041748, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0035168263129889965, "report/cont_pred": 0.9964894652366638, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.20641405880451202, "report/image_loss_std": 0.11661319434642792, "report/model_loss_mean": 0.8411340713500977, "report/model_loss_std": 0.3726005256175995, "report/post_ent_mag": 54.2156982421875, "report/post_ent_max": 54.2156982421875, "report/post_ent_mean": 53.625980377197266, "report/post_ent_min": 53.30125427246094, "report/post_ent_std": 0.1620929092168808, "report/prior_ent_mag": 56.38410186767578, "report/prior_ent_max": 56.38410186767578, "report/prior_ent_mean": 54.14238357543945, "report/prior_ent_min": 51.853614807128906, "report/prior_ent_std": 0.912860095500946, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0002058911049971357, "report/reward_loss_mean": 0.009138945490121841, "report/reward_loss_std": 0.014962954446673393, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.002192378044128418, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.009138945490121841, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.0002567323390394449, "report/reward_rate": 0.0, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.020064977928996086, "eval/cont_loss_std": 0.30528250336647034, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.651954174041748, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00351682654581964, "eval/cont_pred": 0.9964894652366638, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.20109064877033234, "eval/image_loss_std": 0.09328937530517578, "eval/model_loss_mean": 0.8226313591003418, "eval/model_loss_std": 0.31848394870758057, "eval/post_ent_mag": 54.28294372558594, "eval/post_ent_max": 54.28294372558594, "eval/post_ent_mean": 53.63821029663086, "eval/post_ent_min": 53.305328369140625, "eval/post_ent_std": 0.17217278480529785, "eval/prior_ent_mag": 56.74286651611328, "eval/prior_ent_max": 56.74286651611328, "eval/prior_ent_mean": 54.12886047363281, "eval/prior_ent_min": 51.3294792175293, "eval/prior_ent_std": 0.9251430630683899, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0014756983146071434, "eval/reward_loss_std": 0.0015474463580176234, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.0011957883834838867, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0014756983146071434, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00025085185188800097, "eval/reward_rate": 0.0, "replay/size": 247473.0, "replay/inserts": 30928.0, "replay/samples": 30928.0, "replay/insert_wait_avg": 1.3398788040682127e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.113848009815009e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 58856.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1882086251158753e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1075491905212, "timer/env.step_count": 3866.0, "timer/env.step_total": 37.005327463150024, "timer/env.step_frac": 0.03700134799812463, "timer/env.step_avg": 0.009571993653168655, "timer/env.step_min": 0.00784444808959961, "timer/env.step_max": 0.03598284721374512, "timer/replay._sample_count": 30928.0, "timer/replay._sample_total": 15.946879863739014, "timer/replay._sample_frac": 0.015945164974153315, "timer/replay._sample_avg": 0.0005156130323247224, "timer/replay._sample_min": 0.00035500526428222656, "timer/replay._sample_max": 0.018370866775512695, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4733.0, "timer/agent.policy_total": 47.97024202346802, "timer/agent.policy_frac": 0.047965083417573176, "timer/agent.policy_avg": 0.010135271925516167, "timer/agent.policy_min": 0.008718013763427734, "timer/agent.policy_max": 0.08667969703674316, "timer/dataset_train_count": 1933.0, "timer/dataset_train_total": 0.21243500709533691, "timer/dataset_train_frac": 0.00021241216233922047, "timer/dataset_train_avg": 0.00010989912420865852, "timer/dataset_train_min": 9.799003601074219e-05, "timer/dataset_train_max": 0.0010867118835449219, "timer/agent.train_count": 1933.0, "timer/agent.train_total": 865.3012342453003, "timer/agent.train_frac": 0.8652081818057147, "timer/agent.train_avg": 0.4476467844000519, "timer/agent.train_min": 0.43654322624206543, "timer/agent.train_max": 0.5982208251953125, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4704248905181885, "timer/agent.report_frac": 0.00047037430214275105, "timer/agent.report_avg": 0.23521244525909424, "timer/agent.report_min": 0.22524142265319824, "timer/agent.report_max": 0.24518346786499023, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9087066650390625e-05, "timer/dataset_eval_frac": 2.9083938696326666e-08, "timer/dataset_eval_avg": 2.9087066650390625e-05, "timer/dataset_eval_min": 2.9087066650390625e-05, "timer/dataset_eval_max": 2.9087066650390625e-05, "fps": 30.924146890214548}
{"step": 248320, "time": 8278.750059604645, "episode/length": 103.0, "episode/score": 0.7282036464612247, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.05007859398119763}
{"step": 248736, "time": 8291.868040561676, "episode/length": 288.0, "episode/score": 0.11755166368976688, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11755166368976688}
{"step": 249056, "time": 8302.043838262558, "episode/length": 288.0, "episode/score": 0.08603366103909593, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08603366103909593}
{"step": 249160, "time": 8305.107580900192, "episode/length": 288.0, "episode/score": 0.061547288882820794, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061547288882820794}
{"step": 249384, "time": 8312.237775325775, "episode/length": 288.0, "episode/score": 0.07094616536687681, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07094616536687681}
{"step": 249528, "time": 8316.818305253983, "episode/length": 288.0, "episode/score": 0.0702336884432384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0702336884432384}
{"step": 249696, "time": 8322.360278129578, "episode/length": 288.0, "episode/score": 0.059865067839609765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059865067839609765}
{"step": 249904, "time": 8328.9279358387, "episode/length": 288.0, "episode/score": 0.06501976134137522, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06501976134137522}
{"step": 250016, "time": 8332.542984962463, "episode/length": 60.0, "episode/score": 0.8311587412420636, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.018658726922978985}
{"step": 250016, "time": 8333.75421833992, "eval_episode/length": 66.0, "eval_episode/score": 0.793749988079071, "eval_episode/reward_rate": 0.014925373134328358}
{"step": 250016, "time": 8334.514824390411, "eval_episode/length": 109.0, "eval_episode/score": 0.659375011920929, "eval_episode/reward_rate": 0.00909090909090909}
{"step": 250016, "time": 8337.749464511871, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8337.756680250168, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8337.763357162476, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8337.772617340088, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8337.777524471283, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250016, "time": 8337.783543109894, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 250632, "time": 8357.035368919373, "episode/length": 288.0, "episode/score": 0.07453132199174206, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07453132199174206}
{"step": 250976, "time": 8368.221419334412, "episode/length": 133.0, "episode/score": 0.642345277315826, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.057970224835798945}
{"step": 251040, "time": 8370.250180244446, "episode/length": 234.0, "episode/score": 0.31780766887465006, "episode/reward_rate": 0.00425531914893617, "episode/intrinsic_return": 0.04905764263463652}
{"step": 251048, "time": 8370.288522720337, "episode/length": 288.0, "episode/score": 0.07264764536017765, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07264764536017765}
{"step": 251368, "time": 8380.448476791382, "episode/length": 288.0, "episode/score": 0.0665274353756331, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0665274353756331}
{"step": 251696, "time": 8391.165772676468, "episode/length": 288.0, "episode/score": 0.0604751478988419, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0604751478988419}
{"step": 252008, "time": 8400.742967367172, "episode/length": 288.0, "episode/score": 0.09379890471041108, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09379890471041108}
{"step": 252216, "time": 8407.26105260849, "episode/length": 274.0, "episode/score": 0.1965969138724688, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.05284691743477765}
{"step": 252480, "time": 8415.777526855469, "episode/length": 97.0, "episode/score": 0.7223539232339817, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.02547891768097088}
{"step": 252752, "time": 8424.454755067825, "episode/length": 213.0, "episode/score": 0.39058548358136136, "episode/reward_rate": 0.004672897196261682, "episode/intrinsic_return": 0.0562104960028762}
{"step": 252944, "time": 8430.485057115555, "episode/length": 288.0, "episode/score": 0.10813035969741236, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.10813035969741236}
{"step": 253288, "time": 8441.086665153503, "episode/length": 288.0, "episode/score": 0.07894583143601608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07894583143601608}
{"step": 253360, "time": 8443.59857416153, "episode/length": 288.0, "episode/score": 0.07289452621236592, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07289452621236592}
{"step": 253680, "time": 8453.797660827637, "episode/length": 288.0, "episode/score": 0.06381002644752698, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06381002644752698}
{"step": 254032, "time": 8465.40320467949, "episode/length": 226.0, "episode/score": 0.35221866808228697, "episode/reward_rate": 0.004405286343612335, "episode/intrinsic_return": 0.058468680818123175}
{"step": 254320, "time": 8474.499903678894, "episode/length": 288.0, "episode/score": 0.06776801342229533, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06776801342229533}
{"step": 254792, "time": 8489.300059556961, "episode/length": 288.0, "episode/score": 0.07900327593088718, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07900327593088718}
{"step": 255064, "time": 8497.867389440536, "episode/length": 288.0, "episode/score": 0.08523371684876224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08523371684876224}
{"step": 255256, "time": 8503.94713807106, "episode/length": 288.0, "episode/score": 0.0700080706712356, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0700080706712356}
{"step": 255600, "time": 8515.125314712524, "episode/length": 288.0, "episode/score": 0.09111539780451494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09111539780451494}
{"step": 255672, "time": 8517.202635288239, "episode/length": 288.0, "episode/score": 0.07394015743895466, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07394015743895466}
{"step": 255992, "time": 8527.317121505737, "episode/length": 288.0, "episode/score": 0.08221583395831544, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08221583395831544}
{"step": 256344, "time": 8538.403632640839, "episode/length": 288.0, "episode/score": 0.07376964876334569, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07376964876334569}
{"step": 256632, "time": 8547.638685941696, "episode/length": 288.0, "episode/score": 0.07619234131814778, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07619234131814778}
{"step": 257104, "time": 8562.75823187828, "episode/length": 288.0, "episode/score": 0.07054747960717123, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07054747960717123}
{"step": 257296, "time": 8568.816596508026, "episode/length": 211.0, "episode/score": 0.37660991236393215, "episode/reward_rate": 0.0047169811320754715, "episode/intrinsic_return": 0.035984924692314735}
{"step": 257376, "time": 8571.450578689575, "episode/length": 288.0, "episode/score": 0.07629748802972358, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07629748802972358}
{"step": 257568, "time": 8577.53203177452, "episode/length": 288.0, "episode/score": 0.06799299753822652, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06799299753822652}
{"step": 257768, "time": 8583.633341550827, "episode/length": 261.0, "episode/score": 0.25316669017630034, "episode/reward_rate": 0.003816793893129771, "episode/intrinsic_return": 0.0687916877781447}
{"step": 257944, "time": 8589.19358420372, "episode/length": 104.0, "episode/score": 0.7214198753405867, "episode/reward_rate": 0.009523809523809525, "episode/intrinsic_return": 0.04641983478148859}
{"step": 258304, "time": 8600.753649950027, "episode/length": 288.0, "episode/score": 0.07990827863238792, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07990827863238792}
{"step": 258656, "time": 8612.021002054214, "episode/length": 288.0, "episode/score": 0.04383184552119701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04383184552119701}
{"step": 258680, "time": 8612.577732801437, "episode/length": 113.0, "episode/score": 0.6975386316464096, "episode/reward_rate": 0.008771929824561403, "episode/intrinsic_return": 0.050663584463279676}
{"step": 258944, "time": 8621.114228963852, "episode/length": 288.0, "episode/score": 0.07939602149144775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07939602149144775}
{"step": 259456, "time": 8637.335613012314, "episode/length": 188.0, "episode/score": 0.48019060164892835, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.06769059943121647}
{"step": 259608, "time": 8641.880613327026, "episode/length": 288.0, "episode/score": 0.05162620937349516, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05162620937349516}
{"step": 259688, "time": 8644.42836022377, "episode/length": 288.0, "episode/score": 0.08364624333094639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08364624333094639}
{"step": 259880, "time": 8650.499144077301, "episode/length": 288.0, "episode/score": 0.08818296541622317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08818296541622317}
{"step": 260000, "time": 8659.68143248558, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.688898086548, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.696053266525, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.703372240067, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.709765672684, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.716680526733, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.72288608551, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260000, "time": 8659.73016834259, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 260616, "time": 8679.035607814789, "episode/length": 288.0, "episode/score": 0.05883188313347887, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05883188313347887}
{"step": 260968, "time": 8690.15903043747, "episode/length": 288.0, "episode/score": 0.05562410405886453, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05562410405886453}
{"step": 260992, "time": 8691.262343406677, "episode/length": 288.0, "episode/score": 0.05865830518914095, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05865830518914095}
{"step": 261256, "time": 8699.34376001358, "episode/length": 288.0, "episode/score": 0.05926567512301517, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05926567512301517}
{"step": 261768, "time": 8715.508942365646, "episode/length": 288.0, "episode/score": 0.07410354553115894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07410354553115894}
{"step": 261920, "time": 8720.537648439407, "episode/length": 288.0, "episode/score": 0.044442526132428384, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044442526132428384}
{"step": 262000, "time": 8723.190705299377, "episode/length": 288.0, "episode/score": 0.05212112835133098, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05212112835133098}
{"step": 262192, "time": 8729.756509304047, "episode/length": 288.0, "episode/score": 0.061600023369265955, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061600023369265955}
{"step": 262928, "time": 8753.023155450821, "episode/length": 288.0, "episode/score": 0.07605312118712959, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07605312118712959}
{"step": 263280, "time": 8764.12845826149, "episode/length": 288.0, "episode/score": 0.06661528198758049, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06661528198758049}
{"step": 263304, "time": 8764.667500019073, "episode/length": 288.0, "episode/score": 0.07228002733756966, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07228002733756966}
{"step": 263544, "time": 8772.240047454834, "episode/length": 32.0, "episode/score": 0.9059006714527413, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.005900696109506498}
{"step": 263568, "time": 8773.225301980972, "episode/length": 288.0, "episode/score": 0.07539270702861245, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07539270702861245}
{"step": 264080, "time": 8789.47453379631, "episode/length": 288.0, "episode/score": 0.039578711624116636, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039578711624116636}
{"step": 264232, "time": 8794.04270863533, "episode/length": 288.0, "episode/score": 0.03374677722557351, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03374677722557351}
{"step": 264312, "time": 8796.599990844727, "episode/length": 288.0, "episode/score": 0.06504530583055157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06504530583055157}
{"step": 264504, "time": 8802.663036823273, "episode/length": 288.0, "episode/score": 0.08334434964575621, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08334434964575621}
{"step": 265240, "time": 8825.896563529968, "episode/length": 288.0, "episode/score": 0.07175898513067125, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07175898513067125}
{"step": 265432, "time": 8831.955709695816, "episode/length": 232.0, "episode/score": 0.3348063864101931, "episode/reward_rate": 0.004291845493562232, "episode/intrinsic_return": 0.05980637227155228}
{"step": 265616, "time": 8838.982948064804, "episode/length": 288.0, "episode/score": 0.0641355633395051, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0641355633395051}
{"step": 265856, "time": 8846.619080781937, "episode/length": 288.0, "episode/score": 0.05089072643615111, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05089072643615111}
{"step": 266392, "time": 8863.329668521881, "episode/length": 288.0, "episode/score": 0.03599835397223217, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03599835397223217}
{"step": 266472, "time": 8865.840117454529, "episode/length": 106.0, "episode/score": 0.6915103597639529, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.02276035736579729}
{"step": 266544, "time": 8868.33805680275, "episode/length": 288.0, "episode/score": 0.05947875148386572, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05947875148386572}
{"step": 266624, "time": 8870.874017477036, "episode/length": 288.0, "episode/score": 0.04486434336477885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04486434336477885}
{"step": 266816, "time": 8877.055982589722, "episode/length": 288.0, "episode/score": 0.05443554785630056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05443554785630056}
{"step": 267552, "time": 8900.172240257263, "episode/length": 288.0, "episode/score": 0.07855029005038716, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07855029005038716}
{"step": 267744, "time": 8906.290421247482, "episode/length": 288.0, "episode/score": 0.03959976335511328, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03959976335511328}
{"step": 268168, "time": 8919.369593143463, "episode/length": 288.0, "episode/score": 0.06036008760189304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06036008760189304}
{"step": 268704, "time": 8936.55314540863, "episode/length": 288.0, "episode/score": 0.048164486506721005, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048164486506721005}
{"step": 268784, "time": 8939.065431833267, "episode/length": 288.0, "episode/score": 0.053206220402231, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053206220402231}
{"step": 268856, "time": 8941.100501298904, "episode/length": 288.0, "episode/score": 0.05608004035342162, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05608004035342162}
{"step": 268936, "time": 8943.629487991333, "episode/length": 288.0, "episode/score": 0.049402500236510605, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049402500236510605}
{"step": 269048, "time": 8947.137463092804, "episode/length": 162.0, "episode/score": 0.5307697944263907, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.037019788873379866}
{"step": 269128, "time": 8949.660294294357, "episode/length": 288.0, "episode/score": 0.04870745923180664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04870745923180664}
{"step": 269864, "time": 8973.037714481354, "episode/length": 288.0, "episode/score": 0.08065095736772321, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08065095736772321}
{"step": 270088, "time": 8985.965901136398, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.973376989365, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.980078220367, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8985.986912727356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8986.003947734833, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8986.02080130577, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8986.03187584877, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270088, "time": 8986.040301561356, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 270480, "time": 8999.156615257263, "episode/length": 288.0, "episode/score": 0.07779059281571676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07779059281571676}
{"step": 271016, "time": 9015.773231983185, "episode/length": 288.0, "episode/score": 0.11281551380372434, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.11281551380372434}
{"step": 271096, "time": 9018.267018079758, "episode/length": 288.0, "episode/score": 0.09720648781537022, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09720648781537022}
{"step": 271168, "time": 9020.740706920624, "episode/length": 288.0, "episode/score": 0.08874099892342713, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08874099892342713}
{"step": 271248, "time": 9023.349738121033, "episode/length": 288.0, "episode/score": 0.08441403072792752, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08441403072792752}
{"step": 271304, "time": 9024.890933275223, "episode/length": 271.0, "episode/score": 0.23603985693436869, "episode/reward_rate": 0.003676470588235294, "episode/intrinsic_return": 0.08291485511828967}
{"step": 271360, "time": 9026.889755010605, "episode/length": 288.0, "episode/score": 0.09307982731799314, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09307982731799314}
{"step": 272176, "time": 9052.566813230515, "episode/length": 288.0, "episode/score": 0.0956252540765945, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0956252540765945}
{"step": 272792, "time": 9071.66587805748, "episode/length": 288.0, "episode/score": 0.08252101867788042, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08252101867788042}
{"step": 272800, "time": 9072.146372556686, "episode/length": 212.0, "episode/score": 0.3835413740580407, "episode/reward_rate": 0.004694835680751174, "episode/intrinsic_return": 0.046041369261729415}
{"step": 272944, "time": 9076.711954116821, "episode/length": 197.0, "episode/score": 0.4463538994532428, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.061978894656931516}
{"step": 273328, "time": 9088.895060300827, "episode/length": 288.0, "episode/score": 0.07912194799757799, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07912194799757799}
{"step": 273480, "time": 9093.470945835114, "episode/length": 288.0, "episode/score": 0.07297022535283304, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07297022535283304}
{"step": 273560, "time": 9096.010315656662, "episode/length": 288.0, "episode/score": 0.04416578178063446, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04416578178063446}
{"step": 273616, "time": 9098.008720636368, "episode/length": 288.0, "episode/score": 0.09438865444030853, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09438865444030853}
{"step": 274488, "time": 9125.312212705612, "episode/length": 288.0, "episode/score": 0.08568821460664822, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08568821460664822}
{"step": 275104, "time": 9145.068343639374, "episode/length": 288.0, "episode/score": 0.06433069828074167, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06433069828074167}
{"step": 275112, "time": 9145.107176303864, "episode/length": 288.0, "episode/score": 0.08381697185325265, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08381697185325265}
{"step": 275256, "time": 9149.641861200333, "episode/length": 288.0, "episode/score": 0.07546950474147707, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07546950474147707}
{"step": 275512, "time": 9157.73485994339, "episode/length": 272.0, "episode/score": 0.21198994184055664, "episode/reward_rate": 0.003663003663003663, "episode/intrinsic_return": 0.06198993704424538}
{"step": 275792, "time": 9166.804244041443, "episode/length": 288.0, "episode/score": 0.05624205504989277, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05624205504989277}
{"step": 275872, "time": 9169.322806358337, "episode/length": 288.0, "episode/score": 0.050335457629103075, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050335457629103075}
{"step": 275928, "time": 9170.921656608582, "episode/length": 288.0, "episode/score": 0.09332427201718474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09332427201718474}
{"step": 276736, "time": 9196.757128953934, "episode/length": 152.0, "episode/score": 0.5589092833240557, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.03390930798082081}
{"step": 276800, "time": 9198.794041872025, "episode/length": 288.0, "episode/score": 0.05926176150813944, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05926176150813944}
{"step": 277032, "time": 9205.985303401947, "episode/length": 28.0, "episode/score": 0.9258684527725336, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.013368414611591106}
{"step": 277416, "time": 9218.07934165001, "episode/length": 288.0, "episode/score": 0.07817141741963951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07817141741963951}
{"step": 277424, "time": 9218.560857534409, "episode/length": 288.0, "episode/score": 0.052541600495430885, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052541600495430885}
{"step": 277560, "time": 9222.635999202728, "episode/length": 203.0, "episode/score": 0.4273093973426967, "episode/reward_rate": 0.004901960784313725, "episode/intrinsic_return": 0.061684404118068414}
{"step": 277568, "time": 9223.11906337738, "episode/length": 288.0, "episode/score": 0.04861335577953696, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04861335577953696}
{"step": 278104, "time": 9239.941042900085, "episode/length": 288.0, "episode/score": 0.037152082875650194, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037152082875650194}
{"step": 278184, "time": 9242.447566270828, "episode/length": 288.0, "episode/score": 0.04461644655066266, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04461644655066266}
{"step": 278216, "time": 9243.477284908295, "episode/length": 147.0, "episode/score": 0.5880300873593569, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.047405112016122075}
{"step": 278872, "time": 9264.767337799072, "episode/length": 180.0, "episode/score": 0.4804076812891367, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.042907666970052105}
{"step": 278945, "time": 9267.804610967636, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.2493596052258744, "train/action_min": 0.0, "train/action_std": 1.8015881474153983, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0014187923816232966, "train/actor_opt_grad_steps": 16370.0, "train/actor_opt_loss": 5.892172314149419, "train/adv_mag": 0.009718340450000269, "train/adv_max": 0.009554690184370841, "train/adv_mean": 0.0013553720837975976, "train/adv_min": -0.003290361613807283, "train/adv_std": 0.0016968557520629596, "train/cont_avg": 0.9964024044689119, "train/cont_loss_mean": 0.023857179929024582, "train/cont_loss_std": 0.3285993270819839, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.647043762406754, "train/cont_pos_acc": 0.9999999833230527, "train/cont_pos_loss": 0.0035550959789498173, "train/cont_pred": 0.996451306528378, "train/cont_rate": 0.9964024044689119, "train/dyn_loss_mean": 1.0000064786851715, "train/dyn_loss_std": 0.00013329475444628146, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.13847098175202222, "train/extr_critic_critic_opt_grad_steps": 16370.0, "train/extr_critic_critic_opt_loss": 5424.9806877492, "train/extr_critic_mag": 0.1547727677488574, "train/extr_critic_max": 0.1547727677488574, "train/extr_critic_mean": 0.15384484310224267, "train/extr_critic_min": 0.15155189889700302, "train/extr_critic_std": 0.0004673361328657876, "train/extr_return_normed_mag": 0.013066069295369282, "train/extr_return_normed_max": 0.013035806040689735, "train/extr_return_normed_mean": 0.004556173705097789, "train/extr_return_normed_min": -0.0003206078638684564, "train/extr_return_normed_std": 0.001801222003031271, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.16367983509221842, "train/extr_return_raw_max": 0.16367983509221842, "train/extr_return_raw_mean": 0.155200209333489, "train/extr_return_raw_min": 0.15032342118766023, "train/extr_return_raw_std": 0.0018012220072535885, "train/extr_reward_mag": 0.0053479609711800215, "train/extr_reward_max": 0.0053479609711800215, "train/extr_reward_mean": 0.0006342446656205204, "train/extr_reward_min": 1.4844953704992106e-05, "train/extr_reward_std": 0.0008838238116773569, "train/image_loss_mean": 0.1847769990949433, "train/image_loss_std": 0.10419227456953858, "train/model_loss_mean": 0.8192730672618885, "train/model_loss_std": 0.37036758340856574, "train/model_opt_grad_norm": 36.515915529715585, "train/model_opt_grad_steps": 16354.005181347151, "train/model_opt_loss": 3030.921233656493, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3704.663212435233, "train/policy_entropy_mag": 1.8541753255023858, "train/policy_entropy_max": 1.8541753255023858, "train/policy_entropy_mean": 1.2280541717079636, "train/policy_entropy_min": 0.17200218936322267, "train/policy_entropy_std": 0.33226725343286684, "train/policy_logprob_mag": 5.898470992251381, "train/policy_logprob_max": -0.033469506471847314, "train/policy_logprob_mean": -1.2283096755106833, "train/policy_logprob_min": -5.898470992251381, "train/policy_logprob_std": 0.945246508393263, "train/policy_randomness_mag": 0.9528576827419855, "train/policy_randomness_max": 0.9528576827419855, "train/policy_randomness_mean": 0.6310950378679858, "train/policy_randomness_min": 0.08839164539167918, "train/policy_randomness_std": 0.1707516010908574, "train/post_ent_mag": 50.9611584164318, "train/post_ent_max": 50.9611584164318, "train/post_ent_mean": 50.44228673351861, "train/post_ent_min": 50.13828315141905, "train/post_ent_std": 0.13972084590962514, "train/prior_ent_mag": 52.75131373825469, "train/prior_ent_max": 52.75131373825469, "train/prior_ent_mean": 50.24267528711823, "train/prior_ent_min": 48.109694209123525, "train/prior_ent_std": 0.7900602802093782, "train/rep_loss_mean": 1.0000064786851715, "train/rep_loss_std": 0.00013329475444628146, "train/reward_avg": 0.0002788285892354228, "train/reward_loss_mean": 0.01063498334688921, "train/reward_loss_std": 0.0453865858798586, "train/reward_max_data": 0.0638149224108307, "train/reward_max_pred": 0.0035474609216877835, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009602520723436318, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 8.086207211017609, "train/reward_pred": 0.0002802295080709411, "train/reward_rate": 0.00012649773316062175, "train_stats/mean_log_entropy": 1.1965999440250235, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9990234375, "report/cont_loss_mean": 0.00994168221950531, "report/cont_loss_std": 0.17299328744411469, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.542984962463379, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.004533038474619389, "report/cont_pred": 0.9954780340194702, "report/cont_rate": 0.9990234375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.16931632161140442, "report/image_loss_std": 0.10451996326446533, "report/model_loss_mean": 0.7876083850860596, "report/model_loss_std": 0.20954224467277527, "report/post_ent_mag": 46.606590270996094, "report/post_ent_max": 46.606590270996094, "report/post_ent_mean": 46.30298614501953, "report/post_ent_min": 46.07027053833008, "report/post_ent_std": 0.10615098476409912, "report/prior_ent_mag": 48.26515197753906, "report/prior_ent_max": 48.26515197753906, "report/prior_ent_mean": 46.5355110168457, "report/prior_ent_min": 44.66207504272461, "report/prior_ent_std": 0.5629604458808899, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.00018827150051947683, "report/reward_loss_mean": 0.008350399322807789, "report/reward_loss_std": 0.014031692408025265, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.002493619918823242, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008350399322807789, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00024741748347878456, "report/reward_rate": 0.0, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.02564680576324463, "eval/cont_loss_std": 0.33712542057037354, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 5.406895637512207, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.004543869290500879, "eval/cont_pred": 0.9954665899276733, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.15445111691951752, "eval/image_loss_std": 0.09497371315956116, "eval/model_loss_mean": 0.7898544073104858, "eval/model_loss_std": 0.5440395474433899, "eval/post_ent_mag": 46.58183288574219, "eval/post_ent_max": 46.58183288574219, "eval/post_ent_mean": 46.27915954589844, "eval/post_ent_min": 46.0479621887207, "eval/post_ent_std": 0.10375429689884186, "eval/prior_ent_mag": 49.24150466918945, "eval/prior_ent_max": 49.24150466918945, "eval/prior_ent_mean": 46.65234375, "eval/prior_ent_min": 45.068626403808594, "eval/prior_ent_std": 0.5334292650222778, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0006378173711709678, "eval/reward_loss_mean": 0.0097564198076725, "eval/reward_loss_std": 0.27076229453086853, "eval/reward_max_data": 0.653124988079071, "eval/reward_max_pred": 0.0020924806594848633, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0012910973746329546, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 8.669780731201172, "eval/reward_pred": 0.0002240233588963747, "eval/reward_rate": 0.0009765625, "replay/size": 278441.0, "replay/inserts": 30968.0, "replay/samples": 30960.0, "replay/insert_wait_avg": 1.3381558405709371e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.950553815186178e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 65792.0, "eval_replay/inserts": 6936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1751808509694665e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0056788921356, "timer/env.step_count": 3871.0, "timer/env.step_total": 37.09977602958679, "timer/env.step_frac": 0.03709956534515692, "timer/env.step_avg": 0.009584028940735415, "timer/env.step_min": 0.007926702499389648, "timer/env.step_max": 0.03940010070800781, "timer/replay._sample_count": 30960.0, "timer/replay._sample_total": 15.861405849456787, "timer/replay._sample_frac": 0.015861315774755372, "timer/replay._sample_avg": 0.0005123193103829712, "timer/replay._sample_min": 0.0003609657287597656, "timer/replay._sample_max": 0.03281378746032715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4738.0, "timer/agent.policy_total": 47.68688750267029, "timer/agent.policy_frac": 0.04768661669551776, "timer/agent.policy_avg": 0.010064771528634506, "timer/agent.policy_min": 0.008634090423583984, "timer/agent.policy_max": 0.09057402610778809, "timer/dataset_train_count": 1935.0, "timer/dataset_train_total": 0.211838960647583, "timer/dataset_train_frac": 0.0002118377576438071, "timer/dataset_train_avg": 0.00010947749904267856, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0004868507385253906, "timer/agent.train_count": 1935.0, "timer/agent.train_total": 866.2727103233337, "timer/agent.train_frac": 0.8662677908819888, "timer/agent.train_avg": 0.44768615520585725, "timer/agent.train_min": 0.43480992317199707, "timer/agent.train_max": 1.4026646614074707, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4660451412200928, "timer/agent.report_frac": 0.00046604249461503524, "timer/agent.report_avg": 0.2330225706100464, "timer/agent.report_min": 0.22371912002563477, "timer/agent.report_max": 0.242326021194458, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.796287536621094e-05, "timer/dataset_eval_frac": 7.796243262596542e-08, "timer/dataset_eval_avg": 7.796287536621094e-05, "timer/dataset_eval_min": 7.796287536621094e-05, "timer/dataset_eval_max": 7.796287536621094e-05, "fps": 30.96726922836931}
{"step": 279008, "time": 9269.983988046646, "episode/length": 198.0, "episode/score": 0.4333743701021717, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.05212436174355162}
{"step": 279048, "time": 9271.009267807007, "episode/length": 288.0, "episode/score": 0.03298085154625596, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03298085154625596}
{"step": 279192, "time": 9275.51178908348, "episode/length": 202.0, "episode/score": 0.42267887666173465, "episode/reward_rate": 0.0049261083743842365, "episode/intrinsic_return": 0.053928871516177423}
{"step": 279464, "time": 9283.99919128418, "episode/length": 159.0, "episode/score": 0.5653841288623767, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.062259102622363116}
{"step": 279536, "time": 9286.50291967392, "episode/length": 178.0, "episode/score": 0.5043434436648795, "episode/reward_rate": 0.00558659217877095, "episode/intrinsic_return": 0.06059345003279759}
{"step": 279872, "time": 9297.126684427261, "episode/length": 288.0, "episode/score": 0.0537110262960141, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0537110262960141}
{"step": 280072, "time": 9308.526631116867, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.53429555893, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.542356729507, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.549432992935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.556204557419, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.563564777374, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.570542573929, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280072, "time": 9308.577748298645, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 280360, "time": 9317.596452474594, "episode/length": 102.0, "episode/score": 0.710701815987477, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.029451832669792566}
{"step": 280488, "time": 9321.769955158234, "episode/length": 161.0, "episode/score": 0.5419179652260482, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.045042978311130355}
{"step": 280528, "time": 9323.24136853218, "episode/length": 288.0, "episode/score": 0.0635125614017511, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0635125614017511}
{"step": 280664, "time": 9327.27135181427, "episode/length": 223.0, "episode/score": 0.36412469828627536, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.060999689927655254}
{"step": 281320, "time": 9347.733074188232, "episode/length": 288.0, "episode/score": 0.07786018397104044, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07786018397104044}
{"step": 281360, "time": 9349.204220056534, "episode/length": 288.0, "episode/score": 0.06935781860022416, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06935781860022416}
{"step": 281376, "time": 9349.710583686829, "episode/length": 238.0, "episode/score": 0.340118329592201, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.0838683367168187}
{"step": 281536, "time": 9354.76346373558, "episode/length": 125.0, "episode/score": 0.6425375890189571, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.03316258983386433}
{"step": 281544, "time": 9354.798832893372, "episode/length": 131.0, "episode/score": 0.6392631839707974, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.048638167253557185}
{"step": 281656, "time": 9358.305287837982, "episode/length": 123.0, "episode/score": 0.6417209279163671, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.026095904889416488}
{"step": 281664, "time": 9358.781902551651, "episode/length": 162.0, "episode/score": 0.5373415570979887, "episode/reward_rate": 0.006134969325153374, "episode/intrinsic_return": 0.04359154295934786}
{"step": 281952, "time": 9367.794766426086, "episode/length": 259.0, "episode/score": 0.23533368108661534, "episode/reward_rate": 0.0038461538461538464, "episode/intrinsic_return": 0.04470869052789794}
{"step": 282688, "time": 9390.940348386765, "episode/length": 142.0, "episode/score": 0.592036355807295, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.03578635630788085}
{"step": 283080, "time": 9403.008586406708, "episode/length": 140.0, "episode/score": 0.5851927810505231, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.022692799182209455}
{"step": 283328, "time": 9411.088611602783, "episode/length": 79.0, "episode/score": 0.7765135339178642, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.023388514837392904}
{"step": 283632, "time": 9420.615715265274, "episode/length": 288.0, "episode/score": 0.05926404192166501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05926404192166501}
{"step": 283672, "time": 9421.650720119476, "episode/length": 288.0, "episode/score": 0.05031290341446493, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05031290341446493}
{"step": 283688, "time": 9422.159710168839, "episode/length": 288.0, "episode/score": 0.03844806695110492, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03844806695110492}
{"step": 283848, "time": 9427.187870979309, "episode/length": 288.0, "episode/score": 0.05046013024059448, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05046013024059448}
{"step": 283968, "time": 9431.172708511353, "episode/length": 288.0, "episode/score": 0.0795943223940867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0795943223940867}
{"step": 283976, "time": 9431.208673000336, "episode/length": 288.0, "episode/score": 0.05395068501377409, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05395068501377409}
{"step": 284160, "time": 9437.181289196014, "episode/length": 103.0, "episode/score": 0.7041210103251387, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.025996006623131507}
{"step": 285392, "time": 9475.828352451324, "episode/length": 288.0, "episode/score": 0.026263773362018128, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026263773362018128}
{"step": 285944, "time": 9492.950674295425, "episode/length": 288.0, "episode/score": 0.024230506270612295, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024230506270612295}
{"step": 285984, "time": 9494.436738729477, "episode/length": 288.0, "episode/score": 0.022165058841665086, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.022165058841665086}
{"step": 286000, "time": 9494.947520494461, "episode/length": 288.0, "episode/score": 0.026969234202113057, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026969234202113057}
{"step": 286160, "time": 9499.956261873245, "episode/length": 288.0, "episode/score": 0.007037167020882862, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.007037167020882862}
{"step": 286280, "time": 9503.58327794075, "episode/length": 288.0, "episode/score": 0.03346736070574252, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03346736070574252}
{"step": 286288, "time": 9504.056406497955, "episode/length": 288.0, "episode/score": 0.021982658989202264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021982658989202264}
{"step": 286472, "time": 9509.581250667572, "episode/length": 288.0, "episode/score": 0.026240803768246224, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026240803768246224}
{"step": 286816, "time": 9521.137069225311, "episode/length": 108.0, "episode/score": 0.6992531519632053, "episode/reward_rate": 0.009174311926605505, "episode/intrinsic_return": 0.03675314826119802}
{"step": 287216, "time": 9533.758817434311, "episode/length": 92.0, "episode/score": 0.7413895474612673, "episode/reward_rate": 0.010752688172043012, "episode/intrinsic_return": 0.02888958943481157}
{"step": 287248, "time": 9534.756496667862, "episode/length": 231.0, "episode/score": 0.33504765434247474, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.05692266648168243}
{"step": 287592, "time": 9545.29338312149, "episode/length": 198.0, "episode/score": 0.429289432515759, "episode/reward_rate": 0.005025125628140704, "episode/intrinsic_return": 0.048039444937273856}
{"step": 288152, "time": 9562.920537471771, "episode/length": 112.0, "episode/score": 0.6978277319281574, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.04782772637514654}
{"step": 288296, "time": 9567.44005703926, "episode/length": 288.0, "episode/score": 0.05744146379549875, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05744146379549875}
{"step": 288472, "time": 9572.93135690689, "episode/length": 288.0, "episode/score": 0.04575278792469817, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04575278792469817}
{"step": 288592, "time": 9576.926878452301, "episode/length": 288.0, "episode/score": 0.040787550405809725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040787550405809725}
{"step": 288600, "time": 9576.964948892593, "episode/length": 288.0, "episode/score": 0.03165847200693861, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03165847200693861}
{"step": 289128, "time": 9593.584375858307, "episode/length": 288.0, "episode/score": 0.04764808988437608, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04764808988437608}
{"step": 289128, "time": 9593.590781211853, "episode/length": 81.0, "episode/score": 0.7802313171472974, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.03335632089005003}
{"step": 289528, "time": 9606.132670879364, "episode/length": 288.0, "episode/score": 0.05005565152816871, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05005565152816871}
{"step": 289672, "time": 9610.643882513046, "episode/length": 134.0, "episode/score": 0.6051545911808489, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.02390458007482721}
{"step": 289904, "time": 9618.102108716965, "episode/length": 288.0, "episode/score": 0.06022499909175849, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06022499909175849}
{"step": 290048, "time": 9622.716392040253, "episode/length": 64.0, "episode/score": 0.8203177685345509, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.02031775742852915}
{"step": 290056, "time": 9624.380519390106, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 290056, "time": 9624.567527532578, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 290056, "time": 9624.884678125381, "eval_episode/length": 115.0, "eval_episode/score": 0.640625, "eval_episode/reward_rate": 0.008620689655172414}
{"step": 290056, "time": 9625.121858596802, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 290056, "time": 9625.188701629639, "eval_episode/length": 130.0, "eval_episode/score": 0.59375, "eval_episode/reward_rate": 0.007633587786259542}
{"step": 290056, "time": 9625.567029953003, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 290056, "time": 9626.353575706482, "eval_episode/length": 103.0, "eval_episode/score": 0.6781250238418579, "eval_episode/reward_rate": 0.009615384615384616}
{"step": 290056, "time": 9626.667174339294, "eval_episode/length": 93.0, "eval_episode/score": 0.7093750238418579, "eval_episode/reward_rate": 0.010638297872340425}
{"step": 290464, "time": 9639.595851898193, "episode/length": 288.0, "episode/score": 0.0605709760156401, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0605709760156401}
{"step": 290608, "time": 9644.09600687027, "episode/length": 288.0, "episode/score": 0.0659083836968648, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0659083836968648}
{"step": 290656, "time": 9645.599055051804, "episode/length": 93.0, "episode/score": 0.7402081787242878, "episode/reward_rate": 0.010638297872340425, "episode/intrinsic_return": 0.030833155697337133}
{"step": 290912, "time": 9653.75886631012, "episode/length": 288.0, "episode/score": 0.058913700303435235, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.058913700303435235}
{"step": 291088, "time": 9659.28911280632, "episode/length": 77.0, "episode/score": 0.7756676099936612, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.016292605197349985}
{"step": 291440, "time": 9670.310776233673, "episode/length": 288.0, "episode/score": 0.06811284946098795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06811284946098795}
{"step": 291440, "time": 9670.319063425064, "episode/length": 288.0, "episode/score": 0.05956595538680176, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05956595538680176}
{"step": 291496, "time": 9671.882422685623, "episode/length": 72.0, "episode/score": 0.8015817944697119, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.02658179497029778}
{"step": 291696, "time": 9678.343437194824, "episode/length": 129.0, "episode/score": 0.6463894908804377, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.049514464640424194}
{"step": 291976, "time": 9687.000658750534, "episode/length": 59.0, "episode/score": 0.8351138022462692, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.019488776006255648}
{"step": 291984, "time": 9687.48040485382, "episode/length": 288.0, "episode/score": 0.05271428279593238, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05271428279593238}
{"step": 292360, "time": 9699.019641160965, "episode/length": 288.0, "episode/score": 0.04507417827403515, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04507417827403515}
{"step": 292576, "time": 9706.019587278366, "episode/length": 26.0, "episode/score": 0.9286687739520403, "episode/reward_rate": 0.037037037037037035, "episode/intrinsic_return": 0.009918762531697212}
{"step": 292920, "time": 9716.743234157562, "episode/length": 288.0, "episode/score": 0.0355772598012436, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0355772598012436}
{"step": 293104, "time": 9722.677297353745, "episode/length": 251.0, "episode/score": 0.23834109646600155, "episode/reward_rate": 0.003968253968253968, "episode/intrinsic_return": 0.02271609430067656}
{"step": 293752, "time": 9742.814925193787, "episode/length": 288.0, "episode/score": 0.03549541085612873, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03549541085612873}
{"step": 293752, "time": 9742.823863744736, "episode/length": 288.0, "episode/score": 0.05330480661280035, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05330480661280035}
{"step": 294008, "time": 9750.788648843765, "episode/length": 288.0, "episode/score": 0.042499518810359405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042499518810359405}
{"step": 294288, "time": 9759.745928287506, "episode/length": 288.0, "episode/score": 0.06839020730376433, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06839020730376433}
{"step": 294296, "time": 9759.783068656921, "episode/length": 288.0, "episode/score": 0.03301834922274338, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03301834922274338}
{"step": 294712, "time": 9772.873422384262, "episode/length": 119.0, "episode/score": 0.6612935672110325, "episode/reward_rate": 0.008333333333333333, "episode/intrinsic_return": 0.033168540971018956}
{"step": 294888, "time": 9778.363954544067, "episode/length": 288.0, "episode/score": 0.04799243494579741, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04799243494579741}
{"step": 295232, "time": 9789.87063574791, "episode/length": 288.0, "episode/score": 0.03909592713125676, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03909592713125676}
{"step": 295384, "time": 9794.397386312485, "episode/length": 61.0, "episode/score": 0.8268043148876245, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.017429303467281443}
{"step": 295416, "time": 9795.396398305893, "episode/length": 288.0, "episode/score": 0.02911071786991215, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02911071786991215}
{"step": 296016, "time": 9814.475280284882, "episode/length": 282.0, "episode/score": 0.16039003256975093, "episode/reward_rate": 0.0035335689045936395, "episode/intrinsic_return": 0.041640034467320675}
{"step": 296208, "time": 9820.495219707489, "episode/length": 274.0, "episode/score": 0.20385270613707007, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.06010271028145553}
{"step": 296248, "time": 9821.529121398926, "episode/length": 28.0, "episode/score": 0.928662974468125, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.016162921988097878}
{"step": 296528, "time": 9830.563306808472, "episode/length": 138.0, "episode/score": 0.6104418271029886, "episode/reward_rate": 0.007194244604316547, "episode/intrinsic_return": 0.041691774622961475}
{"step": 296600, "time": 9832.752571582794, "episode/length": 288.0, "episode/score": 0.02733311487878609, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02733311487878609}
{"step": 296608, "time": 9833.22707080841, "episode/length": 288.0, "episode/score": 0.05811598012473951, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05811598012473951}
{"step": 296968, "time": 9844.296548366547, "episode/length": 94.0, "episode/score": 0.7401465053717402, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.0338964942657185}
{"step": 297024, "time": 9846.284384727478, "episode/length": 288.0, "episode/score": 0.055938214113780305, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.055938214113780305}
{"step": 297304, "time": 9854.84218621254, "episode/length": 131.0, "episode/score": 0.6235818679165277, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.03295688065236391}
{"step": 297544, "time": 9862.455763339996, "episode/length": 288.0, "episode/score": 0.06709141489494641, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06709141489494641}
{"step": 297696, "time": 9867.42040014267, "episode/length": 288.0, "episode/score": 0.053257381404705484, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053257381404705484}
{"step": 297848, "time": 9871.959118843079, "episode/length": 102.0, "episode/score": 0.7133388430538616, "episode/reward_rate": 0.009708737864077669, "episode/intrinsic_return": 0.03208883825755038}
{"step": 298208, "time": 9883.432566165924, "episode/length": 154.0, "episode/score": 0.5581877879781132, "episode/reward_rate": 0.0064516129032258064, "episode/intrinsic_return": 0.03943774741901507}
{"step": 298840, "time": 9903.097310304642, "episode/length": 288.0, "episode/score": 0.043551196448106566, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043551196448106566}
{"step": 298912, "time": 9905.590549230576, "episode/length": 288.0, "episode/score": 0.07468583648915228, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07468583648915228}
{"step": 298920, "time": 9905.629730701447, "episode/length": 288.0, "episode/score": 0.06107982951220947, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06107982951220947}
{"step": 299616, "time": 9927.751110076904, "episode/length": 288.0, "episode/score": 0.06939573541751543, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06939573541751543}
{"step": 299776, "time": 9932.753434181213, "episode/length": 107.0, "episode/score": 0.694474104104188, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.028849113626961298}
{"step": 299856, "time": 9935.261962890625, "episode/length": 288.0, "episode/score": 0.0429011477496033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0429011477496033}
{"step": 300008, "time": 9939.78369474411, "episode/length": 48.0, "episode/score": 0.8663265524481858, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.016326499968158714}
{"step": 300008, "time": 9939.791878461838, "episode/length": 288.0, "episode/score": 0.05148960297992744, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05148960297992744}
{"step": 300040, "time": 9941.842484474182, "eval_episode/length": 56.0, "eval_episode/score": 0.824999988079071, "eval_episode/reward_rate": 0.017543859649122806}
{"step": 300040, "time": 9942.94652915001, "eval_episode/length": 114.0, "eval_episode/score": 0.643750011920929, "eval_episode/reward_rate": 0.008695652173913044}
{"step": 300040, "time": 9943.528129339218, "eval_episode/length": 143.0, "eval_episode/score": 0.5531250238418579, "eval_episode/reward_rate": 0.006944444444444444}
{"step": 300040, "time": 9944.534537792206, "eval_episode/length": 198.0, "eval_episode/score": 0.3812499940395355, "eval_episode/reward_rate": 0.005025125628140704}
{"step": 300040, "time": 9944.577946424484, "eval_episode/length": 85.0, "eval_episode/score": 0.734375, "eval_episode/reward_rate": 0.011627906976744186}
{"step": 300040, "time": 9946.192245483398, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9946.200160980225, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9946.207174539566, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300040, "time": 9946.21344780922, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 300160, "time": 9950.173743486404, "episode/length": 288.0, "episode/score": 0.052839241243077595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052839241243077595}
{"step": 300520, "time": 9961.253257751465, "episode/length": 288.0, "episode/score": 0.06995324436013561, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06995324436013561}
{"step": 300536, "time": 9961.75469994545, "episode/length": 201.0, "episode/score": 0.41845535886545804, "episode/reward_rate": 0.0049504950495049506, "episode/intrinsic_return": 0.04658035646730241}
{"step": 300872, "time": 9972.254232168198, "episode/length": 126.0, "episode/score": 0.65162406956631, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.0453740671681544}
{"step": 301152, "time": 9981.346583604813, "episode/length": 288.0, "episode/score": 0.049208222984759686, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049208222984759686}
{"step": 301208, "time": 9982.863890886307, "episode/length": 83.0, "episode/score": 0.7551202037793701, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.014495180752419401}
{"step": 302088, "time": 10010.497816801071, "episode/length": 288.0, "episode/score": 0.0603763384271474, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0603763384271474}
{"step": 302200, "time": 10014.125854253769, "episode/length": 123.0, "episode/score": 0.6408627381167094, "episode/reward_rate": 0.008064516129032258, "episode/intrinsic_return": 0.025237690933579415}
{"step": 302232, "time": 10015.128342866898, "episode/length": 277.0, "episode/score": 0.1576539301546518, "episode/reward_rate": 0.0035971223021582736, "episode/intrinsic_return": 0.02327892477626392}
{"step": 302320, "time": 10018.099906682968, "episode/length": 288.0, "episode/score": 0.035302097593501, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035302097593501}
{"step": 302472, "time": 10022.65050148964, "episode/length": 288.0, "episode/score": 0.05642803586522405, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05642803586522405}
{"step": 302504, "time": 10023.652345895767, "episode/length": 247.0, "episode/score": 0.26581318870040604, "episode/reward_rate": 0.004032258064516129, "episode/intrinsic_return": 0.0376881894629264}
{"step": 302736, "time": 10031.16379737854, "episode/length": 197.0, "episode/score": 0.425248126370775, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.040873106091225964}
{"step": 302784, "time": 10032.668921232224, "episode/length": 238.0, "episode/score": 0.3057753316808203, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.04952534410233511}
{"step": 302880, "time": 10035.695779561996, "episode/length": 50.0, "episode/score": 0.857641845522096, "episode/reward_rate": 0.0196078431372549, "episode/intrinsic_return": 0.01389181612722723}
{"step": 303448, "time": 10053.850946903229, "episode/length": 151.0, "episode/score": 0.5709156012999301, "episode/reward_rate": 0.006578947368421052, "episode/intrinsic_return": 0.04279058458268992}
{"step": 304400, "time": 10083.889487743378, "episode/length": 288.0, "episode/score": 0.04195466907128775, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04195466907128775}
{"step": 304512, "time": 10087.416736602783, "episode/length": 288.0, "episode/score": 0.03852200512807258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03852200512807258}
{"step": 304632, "time": 10090.948038816452, "episode/length": 288.0, "episode/score": 0.039845756417662415, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.039845756417662415}
{"step": 304816, "time": 10096.896443843842, "episode/length": 288.0, "episode/score": 0.028093137784765077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028093137784765077}
{"step": 305048, "time": 10104.018946886063, "episode/length": 288.0, "episode/score": 0.021485012057837594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021485012057837594}
{"step": 305056, "time": 10104.495105028152, "episode/length": 67.0, "episode/score": 0.8182909812958314, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.027665976499520184}
{"step": 305096, "time": 10105.550203084946, "episode/length": 288.0, "episode/score": 0.04415208141938365, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04415208141938365}
{"step": 305192, "time": 10108.539521932602, "episode/length": 288.0, "episode/score": 0.04139207271248324, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04139207271248324}
{"step": 305760, "time": 10126.550614118576, "episode/length": 288.0, "episode/score": 0.025573051360879617, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025573051360879617}
{"step": 306712, "time": 10156.195442199707, "episode/length": 288.0, "episode/score": 0.026233141090187928, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026233141090187928}
{"step": 306944, "time": 10163.79932975769, "episode/length": 288.0, "episode/score": 0.034322312355755, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034322312355755}
{"step": 307128, "time": 10169.361552000046, "episode/length": 288.0, "episode/score": 0.015679854649420122, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015679854649420122}
{"step": 307360, "time": 10176.889491796494, "episode/length": 288.0, "episode/score": 0.024290073923737054, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.024290073923737054}
{"step": 307368, "time": 10176.927325487137, "episode/length": 288.0, "episode/score": 0.027145590650718532, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027145590650718532}
{"step": 307408, "time": 10178.407772302628, "episode/length": 288.0, "episode/score": 0.025687463411145472, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025687463411145472}
{"step": 307504, "time": 10181.43565583229, "episode/length": 288.0, "episode/score": 0.03891828095635219, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03891828095635219}
{"step": 307616, "time": 10184.943952798843, "episode/length": 60.0, "episode/score": 0.82888546285335, "episode/reward_rate": 0.01639344262295082, "episode/intrinsic_return": 0.01638544853426538}
{"step": 307944, "time": 10195.106985569, "episode/length": 71.0, "episode/score": 0.7960543701599931, "episode/reward_rate": 0.013888888888888888, "episode/intrinsic_return": 0.017929353442752927}
{"step": 308072, "time": 10199.109983682632, "episode/length": 288.0, "episode/score": 0.025772647571443486, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025772647571443486}
{"step": 308088, "time": 10199.613963127136, "episode/length": 90.0, "episode/score": 0.7408400316928123, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.02209000835154029}
{"step": 308192, "time": 10203.074000358582, "episode/length": 155.0, "episode/score": 0.5536860262751588, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.03806100293388681}
{"step": 308480, "time": 10212.095434188843, "episode/length": 121.0, "episode/score": 0.6593528521159442, "episode/reward_rate": 0.00819672131147541, "episode/intrinsic_return": 0.03747784971778856}
{"step": 309024, "time": 10229.249077796936, "episode/length": 288.0, "episode/score": 0.043404992468822456, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043404992468822456}
{"step": 309720, "time": 10250.910886526108, "episode/length": 288.0, "episode/score": 0.02676728217085156, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02676728217085156}
{"step": 309928, "time": 10257.51636004448, "episode/length": 288.0, "episode/score": 0.04018218221398229, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04018218221398229}
{"step": 309992, "time": 10259.516359329224, "episode/length": 188.0, "episode/score": 0.4485987829147575, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.03609879003937522}
{"step": 310024, "time": 10261.352941513062, "eval_episode/length": 46.0, "eval_episode/score": 0.856249988079071, "eval_episode/reward_rate": 0.02127659574468085}
{"step": 310024, "time": 10262.122349262238, "eval_episode/length": 90.0, "eval_episode/score": 0.71875, "eval_episode/reward_rate": 0.01098901098901099}
{"step": 310024, "time": 10262.576147079468, "eval_episode/length": 116.0, "eval_episode/score": 0.637499988079071, "eval_episode/reward_rate": 0.008547008547008548}
{"step": 310024, "time": 10262.726049900055, "eval_episode/length": 33.0, "eval_episode/score": 0.8968750238418579, "eval_episode/reward_rate": 0.029411764705882353}
{"step": 310024, "time": 10264.643983125687, "eval_episode/length": 150.0, "eval_episode/score": 0.53125, "eval_episode/reward_rate": 0.006622516556291391}
{"step": 310024, "time": 10264.74092912674, "eval_episode/length": 202.0, "eval_episode/score": 0.3687500059604645, "eval_episode/reward_rate": 0.0049261083743842365}
{"step": 310024, "time": 10265.637521982193, "eval_episode/length": 127.0, "eval_episode/score": 0.6031249761581421, "eval_episode/reward_rate": 0.0078125}
{"step": 310024, "time": 10266.275267362595, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10266.282016515732, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10266.288717269897, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310024, "time": 10266.294664382935, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 310048, "time": 10267.276317596436, "episode/length": 244.0, "episode/score": 0.2689508383292605, "episode/reward_rate": 0.004081632653061225, "episode/intrinsic_return": 0.031450841891569326}
{"step": 310049, "time": 10267.837366819382, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.4726524939903847, "train/action_min": 0.0, "train/action_std": 1.825973675189874, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.002404228259379474, "train/actor_opt_grad_steps": 18310.0, "train/actor_opt_loss": 14.365565967406981, "train/adv_mag": 0.018063957416094265, "train/adv_max": 0.0168469345722443, "train/adv_mean": 0.003473347919834151, "train/adv_min": -0.007025179037680992, "train/adv_std": 0.0030349352068673725, "train/cont_avg": 0.9962439903846154, "train/cont_loss_mean": 0.024373993028003055, "train/cont_loss_std": 0.32821890217317745, "train/cont_neg_acc": 0.0, "train/cont_neg_loss": 5.494243281403768, "train/cont_pos_acc": 0.9999999828827687, "train/cont_pos_loss": 0.0036851341251092845, "train/cont_pred": 0.9963199691894727, "train/cont_rate": 0.9962439903846154, "train/dyn_loss_mean": 1.0000044205249885, "train/dyn_loss_std": 0.0001333963333402211, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.1786821945092808, "train/extr_critic_critic_opt_grad_steps": 18310.0, "train/extr_critic_critic_opt_loss": 9891.245709385015, "train/extr_critic_mag": 0.2351642492489937, "train/extr_critic_max": 0.2351642492489937, "train/extr_critic_mean": 0.22980964680512747, "train/extr_critic_min": 0.22274018984574537, "train/extr_critic_std": 0.00190184590815662, "train/extr_return_normed_mag": 0.027809064586957297, "train/extr_return_normed_max": 0.026966124773025513, "train/extr_return_normed_mean": 0.011622782387525942, "train/extr_return_normed_min": 0.0013481791202838605, "train/extr_return_normed_std": 0.0035920734027734933, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.24862635410748996, "train/extr_return_raw_max": 0.24862635410748996, "train/extr_return_raw_mean": 0.2332830241857431, "train/extr_return_raw_min": 0.2230084084547483, "train/extr_return_raw_std": 0.0035920734045644985, "train/extr_reward_mag": 0.01180717089237311, "train/extr_reward_max": 0.01180717089237311, "train/extr_reward_mean": 0.0011657929692703943, "train/extr_reward_min": 1.2060312124399038e-05, "train/extr_reward_std": 0.002268936675047884, "train/image_loss_mean": 0.16991271055661716, "train/image_loss_std": 0.10631958532791871, "train/model_loss_mean": 0.806148815766359, "train/model_loss_std": 0.3845342096609947, "train/model_opt_grad_norm": 34.76467508658385, "train/model_opt_grad_steps": 18292.17435897436, "train/model_opt_loss": 2991.6831073467547, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.5897435897436, "train/policy_entropy_mag": 1.7518365438167864, "train/policy_entropy_max": 1.7518365438167864, "train/policy_entropy_mean": 0.66102550304853, "train/policy_entropy_min": 0.06711513579655916, "train/policy_entropy_std": 0.37001748375403576, "train/policy_logprob_mag": 6.522323982532208, "train/policy_logprob_max": -0.008987690169268694, "train/policy_logprob_mean": -0.6616753987776928, "train/policy_logprob_min": -6.522323982532208, "train/policy_logprob_std": 0.9617435488945398, "train/policy_randomness_mag": 0.900265949506026, "train/policy_randomness_max": 0.900265949506026, "train/policy_randomness_mean": 0.33969992995262144, "train/policy_randomness_min": 0.0344903589059145, "train/policy_randomness_std": 0.19015138302093898, "train/post_ent_mag": 45.182725505339796, "train/post_ent_max": 45.182725505339796, "train/post_ent_mean": 44.80641776842949, "train/post_ent_min": 44.5544323065342, "train/post_ent_std": 0.11230264095923839, "train/prior_ent_mag": 46.37461138994266, "train/prior_ent_max": 46.37461138994266, "train/prior_ent_mean": 44.267154067601915, "train/prior_ent_min": 42.77374729254307, "train/prior_ent_std": 0.5832367571500632, "train/rep_loss_mean": 1.0000044205249885, "train/rep_loss_std": 0.0001333963333402211, "train/reward_avg": 0.00036082443182702914, "train/reward_loss_mean": 0.011859438004784095, "train/reward_loss_std": 0.06723028211734998, "train/reward_max_data": 0.1298097712942996, "train/reward_max_pred": 0.008232204730694111, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 0.009932324658028591, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 6.100800118356381, "train/reward_pred": 0.0003456556847175727, "train/reward_rate": 0.0003155048076923077, "train_stats/mean_log_entropy": 0.6685613498091698, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.025471100583672523, "report/cont_loss_std": 0.3656023442745209, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 5.854589939117432, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.002611811039969325, "report/cont_pred": 0.9973907470703125, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.14672496914863586, "report/image_loss_std": 0.09359928965568542, "report/model_loss_mean": 0.7809998989105225, "report/model_loss_std": 0.37948188185691833, "report/post_ent_mag": 42.59297561645508, "report/post_ent_max": 42.59297561645508, "report/post_ent_mean": 42.20301818847656, "report/post_ent_min": 41.975067138671875, "report/post_ent_std": 0.11119765043258667, "report/prior_ent_mag": 42.6285285949707, "report/prior_ent_max": 42.6285285949707, "report/prior_ent_mean": 41.03228759765625, "report/prior_ent_min": 39.65247344970703, "report/prior_ent_std": 0.5199036002159119, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0001931925944518298, "report/reward_loss_mean": 0.0088037783280015, "report/reward_loss_std": 0.013879302889108658, "report/reward_max_data": 0.0012499999720603228, "report/reward_max_pred": 0.0065228939056396484, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.008803779259324074, "report/reward_pos_acc": NaN, "report/reward_pos_loss": NaN, "report/reward_pred": 0.00031578075140714645, "report/reward_rate": 0.0, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.03798363357782364, "eval/cont_loss_std": 0.4608955383300781, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 6.039523124694824, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0026111023034900427, "eval/cont_pred": 0.9973939657211304, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.1758333146572113, "eval/image_loss_std": 0.10188347846269608, "eval/model_loss_mean": 0.8153373003005981, "eval/model_loss_std": 0.4712297022342682, "eval/post_ent_mag": 42.591583251953125, "eval/post_ent_max": 42.591583251953125, "eval/post_ent_mean": 42.202293395996094, "eval/post_ent_min": 41.97939682006836, "eval/post_ent_std": 0.11196867376565933, "eval/prior_ent_mag": 42.98765563964844, "eval/prior_ent_max": 42.98765563964844, "eval/prior_ent_mean": 40.988494873046875, "eval/prior_ent_min": 39.686649322509766, "eval/prior_ent_std": 0.5104195475578308, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015203249640762806, "eval/reward_loss_std": 0.0017751872073858976, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.005469560623168945, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015203249640762806, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00026114413049072027, "eval/reward_rate": 0.0, "replay/size": 309545.0, "replay/inserts": 31104.0, "replay/samples": 31104.0, "replay/insert_wait_avg": 1.3346044124399193e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.914325582637708e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 74408.0, "eval_replay/inserts": 8616.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1724460534509289e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0135173797607, "timer/env.step_count": 3888.0, "timer/env.step_total": 36.96668219566345, "timer/env.step_frac": 0.03696618250973616, "timer/env.step_avg": 0.009507891511230313, "timer/env.step_min": 0.007921457290649414, "timer/env.step_max": 0.036298513412475586, "timer/replay._sample_count": 31104.0, "timer/replay._sample_total": 15.750811100006104, "timer/replay._sample_frac": 0.01575059819318887, "timer/replay._sample_avg": 0.00050639181777283, "timer/replay._sample_min": 0.0003750324249267578, "timer/replay._sample_max": 0.01063394546508789, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4965.0, "timer/agent.policy_total": 49.63213801383972, "timer/agent.policy_frac": 0.04963146712645049, "timer/agent.policy_avg": 0.009996402419705886, "timer/agent.policy_min": 0.008523702621459961, "timer/agent.policy_max": 0.08571934700012207, "timer/dataset_train_count": 1944.0, "timer/dataset_train_total": 0.21240854263305664, "timer/dataset_train_frac": 0.00021240567146493211, "timer/dataset_train_avg": 0.00010926365361782749, "timer/dataset_train_min": 9.632110595703125e-05, "timer/dataset_train_max": 0.0003452301025390625, "timer/agent.train_count": 1944.0, "timer/agent.train_total": 862.1427595615387, "timer/agent.train_frac": 0.8621311058079779, "timer/agent.train_avg": 0.44348907384852815, "timer/agent.train_min": 0.43358778953552246, "timer/agent.train_max": 0.6063954830169678, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4678788185119629, "timer/agent.report_frac": 0.0004678724941017805, "timer/agent.report_avg": 0.23393940925598145, "timer/agent.report_min": 0.22242522239685059, "timer/agent.report_max": 0.2454535961151123, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.218607310733774e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 31.10306613027333}
{"step": 310256, "time": 10274.465360164642, "episode/length": 288.0, "episode/score": 0.05686240701004408, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05686240701004408}
{"step": 310384, "time": 10278.495667696, "episode/length": 288.0, "episode/score": 0.04451285109212222, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04451285109212222}
{"step": 310392, "time": 10278.532128810883, "episode/length": 274.0, "episode/score": 0.19322496684435464, "episode/reward_rate": 0.0036363636363636364, "episode/intrinsic_return": 0.04947497063949413}
{"step": 310560, "time": 10284.084748029709, "episode/length": 78.0, "episode/score": 0.7863387166885332, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.030088678527590673}
{"step": 310776, "time": 10290.619032144547, "episode/length": 47.0, "episode/score": 0.8682483450087943, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.015123369665559494}
{"step": 311088, "time": 10300.647825956345, "episode/length": 103.0, "episode/score": 0.7049514693733272, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.026826422190197263}
{"step": 311336, "time": 10308.660346508026, "episode/length": 288.0, "episode/score": 0.028689483739867683, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028689483739867683}
{"step": 312016, "time": 10330.299080610275, "episode/length": 115.0, "episode/score": 0.6799907213829783, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.039365692744809166}
{"step": 312032, "time": 10330.80229473114, "episode/length": 288.0, "episode/score": 0.034939203989154066, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034939203989154066}
{"step": 312216, "time": 10336.332128763199, "episode/length": 270.0, "episode/score": 0.18864551351293812, "episode/reward_rate": 0.0036900369003690036, "episode/intrinsic_return": 0.03239551392039175}
{"step": 312304, "time": 10339.323409795761, "episode/length": 288.0, "episode/score": 0.03368057546123282, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03368057546123282}
{"step": 312424, "time": 10342.937161684036, "episode/length": 48.0, "episode/score": 0.8649617218463277, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.014961674663197755}
{"step": 312696, "time": 10351.462782859802, "episode/length": 288.0, "episode/score": 0.027966476993242395, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027966476993242395}
{"step": 312800, "time": 10354.940460443497, "episode/length": 61.0, "episode/score": 0.8286876520667192, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.019312634592779432}
{"step": 312872, "time": 10356.980492591858, "episode/length": 288.0, "episode/score": 0.015688716887666487, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.015688716887666487}
{"step": 313088, "time": 10363.95972943306, "episode/length": 288.0, "episode/score": 0.026834930347490626, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026834930347490626}
{"step": 313288, "time": 10369.971038341522, "episode/length": 73.0, "episode/score": 0.789470757005347, "episode/reward_rate": 0.013513513513513514, "episode/intrinsic_return": 0.017595703768620297}
{"step": 313488, "time": 10376.507697105408, "episode/length": 76.0, "episode/score": 0.7786046865020353, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.016104669028095486}
{"step": 313568, "time": 10379.021554470062, "episode/length": 59.0, "episode/score": 0.825693683591112, "episode/reward_rate": 0.016666666666666666, "episode/intrinsic_return": 0.010068648328910967}
{"step": 313648, "time": 10381.520552873611, "episode/length": 288.0, "episode/score": 0.020075476482816157, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020075476482816157}
{"step": 313896, "time": 10389.08015012741, "episode/length": 136.0, "episode/score": 0.6112083887723543, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.03620840150819049}
{"step": 314056, "time": 10394.050716400146, "episode/length": 95.0, "episode/score": 0.7138491043741055, "episode/reward_rate": 0.010416666666666666, "episode/intrinsic_return": 0.01072410518901279}
{"step": 314104, "time": 10395.54059791565, "episode/length": 209.0, "episode/score": 0.38161717053748134, "episode/reward_rate": 0.004761904761904762, "episode/intrinsic_return": 0.0347421442974678}
{"step": 314104, "time": 10395.547998189926, "episode/length": 66.0, "episode/score": 0.8029532138040167, "episode/reward_rate": 0.014925373134328358, "episode/intrinsic_return": 0.009203196330076935}
{"step": 314328, "time": 10402.59831404686, "episode/length": 288.0, "episode/score": 0.035093526407820264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.035093526407820264}
{"step": 314344, "time": 10403.102381944656, "episode/length": 86.0, "episode/score": 0.7498031590007486, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.018553147580405493}
{"step": 314360, "time": 10403.625387430191, "episode/length": 267.0, "episode/score": 0.18792967089751755, "episode/reward_rate": 0.0037313432835820895, "episode/intrinsic_return": 0.022304671398103437}
{"step": 314696, "time": 10414.107254266739, "episode/length": 45.0, "episode/score": 0.8756431003062062, "episode/reward_rate": 0.021739130434782608, "episode/intrinsic_return": 0.01626809212802982}
{"step": 315168, "time": 10429.041124105453, "episode/length": 132.0, "episode/score": 0.6167828298644054, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.02928284552808691}
{"step": 315200, "time": 10430.042087316513, "episode/length": 142.0, "episode/score": 0.5849354694519207, "episode/reward_rate": 0.006993006993006993, "episode/intrinsic_return": 0.02868548613423627}
{"step": 315560, "time": 10441.231830835342, "episode/length": 258.0, "episode/score": 0.25287298542093595, "episode/reward_rate": 0.003861003861003861, "episode/intrinsic_return": 0.059122997842450786}
{"step": 315640, "time": 10443.74739766121, "episode/length": 159.0, "episode/score": 0.5427004271410283, "episode/reward_rate": 0.00625, "episode/intrinsic_return": 0.03957540806055704}
{"step": 315648, "time": 10444.219764947891, "episode/length": 55.0, "episode/score": 0.8414550280790536, "episode/reward_rate": 0.017857142857142856, "episode/intrinsic_return": 0.013330028893960844}
{"step": 315648, "time": 10444.228017807007, "episode/length": 218.0, "episode/score": 0.36752833232185367, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.04877832661168213}
{"step": 315704, "time": 10445.760308980942, "episode/length": 199.0, "episode/score": 0.4163572533760771, "episode/reward_rate": 0.005, "episode/intrinsic_return": 0.03823223429560585}
{"step": 315952, "time": 10453.735225915909, "episode/length": 30.0, "episode/score": 0.9125505690169575, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.006300584121845532}
{"step": 315992, "time": 10454.777747154236, "episode/length": 161.0, "episode/score": 0.5533582790124001, "episode/reward_rate": 0.006172839506172839, "episode/intrinsic_return": 0.05648327661424446}
{"step": 316336, "time": 10465.888758182526, "episode/length": 248.0, "episode/score": 0.25499485043883396, "episode/reward_rate": 0.004016064257028112, "episode/intrinsic_return": 0.02999485661757717}
{"step": 316368, "time": 10466.893386602402, "episode/length": 149.0, "episode/score": 0.5715271902762424, "episode/reward_rate": 0.006666666666666667, "episode/intrinsic_return": 0.03715217017713712}
{"step": 316656, "time": 10475.914234876633, "episode/length": 126.0, "episode/score": 0.6217336953037602, "episode/reward_rate": 0.007874015748031496, "episode/intrinsic_return": 0.015483730333130552}
{"step": 316672, "time": 10476.420733213425, "episode/length": 84.0, "episode/score": 0.7474017182144053, "episode/reward_rate": 0.011764705882352941, "episode/intrinsic_return": 0.009901699133934017}
{"step": 316888, "time": 10483.002678632736, "episode/length": 68.0, "episode/score": 0.8030125053010124, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.015512473280978156}
{"step": 317112, "time": 10490.049265146255, "episode/length": 182.0, "episode/score": 0.4612849164702766, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.030034898839176094}
{"step": 317720, "time": 10509.212373971939, "episode/length": 103.0, "episode/score": 0.7094049684685615, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.031279945441610835}
{"step": 317872, "time": 10514.223027706146, "episode/length": 288.0, "episode/score": 0.052816746844769114, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.052816746844769114}
{"step": 317960, "time": 10516.772869348526, "episode/length": 288.0, "episode/score": 0.0692264477999629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0692264477999629}
{"step": 318144, "time": 10522.936009407043, "episode/length": 273.0, "episode/score": 0.21543076554735308, "episode/reward_rate": 0.0036496350364963502, "episode/intrinsic_return": 0.06855577208989416}
{"step": 318320, "time": 10528.422038078308, "episode/length": 243.0, "episode/score": 0.2933513862668633, "episode/reward_rate": 0.004098360655737705, "episode/intrinsic_return": 0.052726385067785486}
{"step": 318584, "time": 10536.469960451126, "episode/length": 238.0, "episode/score": 0.3174161390629706, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.061166151484485454}
{"step": 318776, "time": 10542.47704076767, "episode/length": 56.0, "episode/score": 0.8411587981942148, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.01615878072027499}
{"step": 318968, "time": 10548.50171494484, "episode/length": 288.0, "episode/score": 0.09021892196250292, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.09021892196250292}
{"step": 319168, "time": 10555.077790260315, "episode/length": 180.0, "episode/score": 0.47932151824056746, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.041821506569931444}
{"step": 319424, "time": 10563.065723657608, "episode/length": 288.0, "episode/score": 0.08789198505132845, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.08789198505132845}
{"step": 319752, "time": 10573.592059373856, "episode/length": 223.0, "episode/score": 0.363268320586144, "episode/reward_rate": 0.004464285714285714, "episode/intrinsic_return": 0.060143319387066185}
{"step": 320000, "time": 10581.731219291687, "episode/length": 103.0, "episode/score": 0.7174341125524393, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.03930908892886009}
{"step": 320008, "time": 10581.767713785172, "episode/length": 153.0, "episode/score": 0.5610758528927704, "episode/reward_rate": 0.006493506493506494, "episode/intrinsic_return": 0.039200849190763165}
{"step": 320008, "time": 10581.984312534332, "eval_episode/length": 9.0, "eval_episode/score": 0.971875011920929, "eval_episode/reward_rate": 0.1}
{"step": 320008, "time": 10582.55839586258, "eval_episode/length": 37.0, "eval_episode/score": 0.8843749761581421, "eval_episode/reward_rate": 0.02631578947368421}
{"step": 320008, "time": 10582.783164262772, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 320008, "time": 10583.996903896332, "eval_episode/length": 110.0, "eval_episode/score": 0.65625, "eval_episode/reward_rate": 0.009009009009009009}
{"step": 320008, "time": 10584.463088989258, "eval_episode/length": 133.0, "eval_episode/score": 0.5843750238418579, "eval_episode/reward_rate": 0.007462686567164179}
{"step": 320008, "time": 10585.224155902863, "eval_episode/length": 123.0, "eval_episode/score": 0.6156250238418579, "eval_episode/reward_rate": 0.008064516129032258}
{"step": 320008, "time": 10585.611043691635, "eval_episode/length": 18.0, "eval_episode/score": 0.9437500238418579, "eval_episode/reward_rate": 0.05263157894736842}
{"step": 320008, "time": 10585.90827703476, "eval_episode/length": 72.0, "eval_episode/score": 0.7749999761581421, "eval_episode/reward_rate": 0.0136986301369863}
{"step": 320184, "time": 10591.44229388237, "episode/length": 288.0, "episode/score": 0.07138493184726258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07138493184726258}
{"step": 320376, "time": 10597.462829589844, "episode/length": 77.0, "episode/score": 0.7897900698403646, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.03041511181390888}
{"step": 320456, "time": 10599.999111175537, "episode/length": 288.0, "episode/score": 0.051893725738693774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.051893725738693774}
{"step": 320632, "time": 10605.499136209488, "episode/length": 31.0, "episode/score": 0.9163395675165589, "episode/reward_rate": 0.03125, "episode/intrinsic_return": 0.01321457125931147}
{"step": 320680, "time": 10607.007789611816, "episode/length": 61.0, "episode/score": 0.8371848792934315, "episode/reward_rate": 0.016129032258064516, "episode/intrinsic_return": 0.027809891432639233}
{"step": 320896, "time": 10614.103581428528, "episode/length": 288.0, "episode/score": 0.061205880507316124, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061205880507316124}
{"step": 321080, "time": 10619.622026443481, "episode/length": 77.0, "episode/score": 0.7720877436555043, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.01271278562904854}
{"step": 321184, "time": 10623.090464115143, "episode/length": 219.0, "episode/score": 0.3421189165499072, "episode/reward_rate": 0.004545454545454545, "episode/intrinsic_return": 0.02649389496650656}
{"step": 321272, "time": 10625.648459672928, "episode/length": 287.0, "episode/score": 0.1436369779235065, "episode/reward_rate": 0.003472222222222222, "episode/intrinsic_return": 0.04051198264414779}
{"step": 321432, "time": 10630.68861579895, "episode/length": 19.0, "episode/score": 0.9472206956918399, "episode/reward_rate": 0.05, "episode/intrinsic_return": 0.0065956988757989166}
{"step": 321568, "time": 10635.205221652985, "episode/length": 47.0, "episode/score": 0.863649239058816, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.010524258811585696}
{"step": 321592, "time": 10635.746146440506, "episode/length": 197.0, "episode/score": 0.44166783372918417, "episode/reward_rate": 0.005050505050505051, "episode/intrinsic_return": 0.057292816098083676}
{"step": 321688, "time": 10638.749282360077, "episode/length": 131.0, "episode/score": 0.6335920952546417, "episode/reward_rate": 0.007575757575757576, "episode/intrinsic_return": 0.04296711925366026}
{"step": 322064, "time": 10650.825285196304, "episode/length": 145.0, "episode/score": 0.5849550744094927, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03808008951438069}
{"step": 322080, "time": 10651.33766913414, "episode/length": 174.0, "episode/score": 0.49481325666727116, "episode/reward_rate": 0.005714285714285714, "episode/intrinsic_return": 0.038563230048907826}
{"step": 322240, "time": 10656.35901093483, "episode/length": 100.0, "episode/score": 0.7126246103425729, "episode/reward_rate": 0.009900990099009901, "episode/intrinsic_return": 0.025124636565124092}
{"step": 322312, "time": 10658.40761423111, "episode/length": 288.0, "episode/score": 0.06144604260646247, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06144604260646247}
{"step": 322472, "time": 10663.37547326088, "episode/length": 97.0, "episode/score": 0.7208378072944583, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.023962857358867495}
{"step": 322536, "time": 10665.396151542664, "episode/length": 120.0, "episode/score": 0.6636694097268219, "episode/reward_rate": 0.008264462809917356, "episode/intrinsic_return": 0.0386694099451006}
{"step": 322800, "time": 10673.93761396408, "episode/length": 40.0, "episode/score": 0.8861913034954227, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.011191299406334565}
{"step": 322928, "time": 10677.93792462349, "episode/length": 107.0, "episode/score": 0.6874279100463809, "episode/reward_rate": 0.009259259259259259, "episode/intrinsic_return": 0.021802948993126847}
{"step": 323112, "time": 10683.483969688416, "episode/length": 38.0, "episode/score": 0.8936262522690299, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.01237622433808383}
{"step": 323264, "time": 10688.492693901062, "episode/length": 147.0, "episode/score": 0.5755393462353595, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.034914380147142765}
{"step": 323392, "time": 10692.494744300842, "episode/length": 288.0, "episode/score": 0.038794651623334175, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038794651623334175}
{"step": 323416, "time": 10693.026551961899, "episode/length": 137.0, "episode/score": 0.6111351424167424, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.0392601813634883}
{"step": 323888, "time": 10708.050909996033, "episode/length": 96.0, "episode/score": 0.7226070203170991, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.022607041303871256}
{"step": 323904, "time": 10708.557569742203, "episode/length": 288.0, "episode/score": 0.044802305984120494, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.044802305984120494}
{"step": 324016, "time": 10712.070414304733, "episode/length": 74.0, "episode/score": 0.7856999407623277, "episode/reward_rate": 0.013333333333333334, "episode/intrinsic_return": 0.01694995194984017}
{"step": 324072, "time": 10713.596869468689, "episode/length": 191.0, "episode/score": 0.4173039792992199, "episode/reward_rate": 0.005208333333333333, "episode/intrinsic_return": 0.014178987640377727}
{"step": 324112, "time": 10715.087840080261, "episode/length": 27.0, "episode/score": 0.9255427367513107, "episode/reward_rate": 0.03571428571428571, "episode/intrinsic_return": 0.009917756504080444}
{"step": 324168, "time": 10716.627264022827, "episode/length": 112.0, "episode/score": 0.6702848907490591, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.020284931733073108}
{"step": 324536, "time": 10728.141105651855, "episode/length": 78.0, "episode/score": 0.7675512087936909, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.011301211174384207}
{"step": 324552, "time": 10728.647490262985, "episode/length": 288.0, "episode/score": 0.04033561572006761, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04033561572006761}
{"step": 325008, "time": 10743.312764406204, "episode/length": 58.0, "episode/score": 0.8347783765349277, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.01602836276299513}
{"step": 325032, "time": 10743.846657514572, "episode/length": 114.0, "episode/score": 0.6593025039716167, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.01555246393638754}
{"step": 325040, "time": 10744.325042963028, "episode/length": 263.0, "episode/score": 0.22206112380658283, "episode/reward_rate": 0.003787878787878788, "episode/intrinsic_return": 0.04393612694397575}
{"step": 325248, "time": 10750.898772239685, "episode/length": 231.0, "episode/score": 0.3101694084593305, "episode/reward_rate": 0.004310344827586207, "episode/intrinsic_return": 0.03204443453927297}
{"step": 325328, "time": 10753.393915176392, "episode/length": 39.0, "episode/score": 0.8864914461950661, "episode/reward_rate": 0.025, "episode/intrinsic_return": 0.008366444344062529}
{"step": 325536, "time": 10759.922493934631, "episode/length": 122.0, "episode/score": 0.6604143258703061, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.04166432159786382}
{"step": 325608, "time": 10762.080258846283, "episode/length": 179.0, "episode/score": 0.4869704964111463, "episode/reward_rate": 0.005555555555555556, "episode/intrinsic_return": 0.046345486178239526}
{"step": 325824, "time": 10769.111768722534, "episode/length": 225.0, "episode/score": 0.33397591623744916, "episode/reward_rate": 0.004424778761061947, "episode/intrinsic_return": 0.03710091265767801}
{"step": 326016, "time": 10775.179183959961, "episode/length": 122.0, "episode/score": 0.6446801355045011, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.02593013612877826}
{"step": 326112, "time": 10778.19916009903, "episode/length": 97.0, "episode/score": 0.7107553213159576, "episode/reward_rate": 0.01020408163265306, "episode/intrinsic_return": 0.013880328561356237}
{"step": 326144, "time": 10779.209741592407, "episode/length": 137.0, "episode/score": 0.5985799513840675, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.026704984291768596}
{"step": 326368, "time": 10786.28433418274, "episode/length": 139.0, "episode/score": 0.5938362695049477, "episode/reward_rate": 0.007142857142857143, "episode/intrinsic_return": 0.02821124098755945}
{"step": 326384, "time": 10786.791454076767, "episode/length": 96.0, "episode/score": 0.7184075931860434, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.018407631686045534}
{"step": 326384, "time": 10786.803099632263, "episode/length": 288.0, "episode/score": 0.045347559125360704, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.045347559125360704}
{"step": 326696, "time": 10796.549866437912, "episode/length": 38.0, "episode/score": 0.8854694370731124, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.004219431814050267}
{"step": 326776, "time": 10799.056938409805, "episode/length": 94.0, "episode/score": 0.7194882691254065, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.01323825728451311}
{"step": 327088, "time": 10809.032676696777, "episode/length": 89.0, "episode/score": 0.7315902524616433, "episode/reward_rate": 0.011111111111111112, "episode/intrinsic_return": 0.009715254699727893}
{"step": 327272, "time": 10814.571602582932, "episode/length": 180.0, "episode/score": 0.45289151269383865, "episode/reward_rate": 0.0055248618784530384, "episode/intrinsic_return": 0.015391512766598225}
{"step": 327848, "time": 10833.21211194992, "episode/length": 288.0, "episode/score": 0.046660460843924056, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.046660460843924056}
{"step": 327872, "time": 10834.185494661331, "episode/length": 136.0, "episode/score": 0.5943459991739246, "episode/reward_rate": 0.0072992700729927005, "episode/intrinsic_return": 0.019345982980553345}
{"step": 328032, "time": 10839.216412067413, "episode/length": 94.0, "episode/score": 0.7320060625173141, "episode/reward_rate": 0.010526315789473684, "episode/intrinsic_return": 0.025756022482084973}
{"step": 328344, "time": 10848.840037345886, "episode/length": 58.0, "episode/score": 0.825628429544679, "episode/reward_rate": 0.01694915254237288, "episode/intrinsic_return": 0.0068784228449771945}
{"step": 328424, "time": 10851.466460466385, "episode/length": 288.0, "episode/score": 0.028037944924051317, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.028037944924051317}
{"step": 328456, "time": 10852.485311985016, "episode/length": 288.0, "episode/score": 0.038128109352157935, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038128109352157935}
{"step": 328496, "time": 10853.96575641632, "episode/length": 224.0, "episode/score": 0.3475619621216026, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.047561960270599}
{"step": 328696, "time": 10860.028690814972, "episode/length": 288.0, "episode/score": 0.054256788276859425, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.054256788276859425}
{"step": 328912, "time": 10867.01800942421, "episode/length": 132.0, "episode/score": 0.6048903614781693, "episode/reward_rate": 0.007518796992481203, "episode/intrinsic_return": 0.01739035562684421}
{"step": 329048, "time": 10871.038853168488, "episode/length": 87.0, "episode/score": 0.7453653716948452, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.017240414119498837}
{"step": 329144, "time": 10874.043942213058, "episode/length": 80.0, "episode/score": 0.7661672134883304, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.016167191238452006}
{"step": 329312, "time": 10879.513597011566, "episode/length": 106.0, "episode/score": 0.6977343602143264, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.028984372215290932}
{"step": 329344, "time": 10880.516112089157, "episode/length": 114.0, "episode/score": 0.6645135374855897, "episode/reward_rate": 0.008695652173913044, "episode/intrinsic_return": 0.02076350284184514}
{"step": 329360, "time": 10881.106858491898, "episode/length": 82.0, "episode/score": 0.762305570444255, "episode/reward_rate": 0.012048192771084338, "episode/intrinsic_return": 0.018555571068532117}
{"step": 329400, "time": 10882.148836135864, "episode/length": 288.0, "episode/score": 0.034999244860131284, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034999244860131284}
{"step": 329568, "time": 10887.619958162308, "episode/length": 81.0, "episode/score": 0.7669451782191743, "episode/reward_rate": 0.012195121951219513, "episode/intrinsic_return": 0.020070160446920227}
{"step": 329664, "time": 10890.61817741394, "episode/length": 76.0, "episode/score": 0.7731542981384791, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.010654287809529706}
{"step": 329688, "time": 10891.154553890228, "episode/length": 40.0, "episode/score": 0.8864134741902205, "episode/reward_rate": 0.024390243902439025, "episode/intrinsic_return": 0.01141348022926536}
{"step": 329768, "time": 10893.665485858917, "episode/length": 77.0, "episode/score": 0.7846456845526006, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.025270691703411785}
{"step": 329944, "time": 10899.190164089203, "episode/length": 46.0, "episode/score": 0.8658986489818972, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.009648665937788792}
{"step": 330096, "time": 10905.047252178192, "eval_episode/length": 48.0, "eval_episode/score": 0.8500000238418579, "eval_episode/reward_rate": 0.02040816326530612}
{"step": 330096, "time": 10905.708038568497, "eval_episode/length": 82.0, "eval_episode/score": 0.7437499761581421, "eval_episode/reward_rate": 0.012048192771084338}
{"step": 330096, "time": 10905.82750082016, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 330096, "time": 10906.028892993927, "eval_episode/length": 98.0, "eval_episode/score": 0.6937500238418579, "eval_episode/reward_rate": 0.010101010101010102}
{"step": 330096, "time": 10907.420710086823, "eval_episode/length": 73.0, "eval_episode/score": 0.7718750238418579, "eval_episode/reward_rate": 0.013513513513513514}
{"step": 330096, "time": 10907.517270088196, "eval_episode/length": 88.0, "eval_episode/score": 0.7250000238418579, "eval_episode/reward_rate": 0.011235955056179775}
{"step": 330096, "time": 10908.777908563614, "eval_episode/length": 68.0, "eval_episode/score": 0.7875000238418579, "eval_episode/reward_rate": 0.014492753623188406}
{"step": 330096, "time": 10909.563704013824, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10909.57223033905, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10909.578424215317, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330096, "time": 10909.585695266724, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 330160, "time": 10911.71796965599, "episode/length": 105.0, "episode/score": 0.6968784529282175, "episode/reward_rate": 0.009433962264150943, "episode/intrinsic_return": 0.025003429710636738}
{"step": 330176, "time": 10912.371539831161, "episode/length": 28.0, "episode/score": 0.9228014628256176, "episode/reward_rate": 0.034482758620689655, "episode/intrinsic_return": 0.010301465562832846}
{"step": 330216, "time": 10913.430132627487, "episode/length": 68.0, "episode/score": 0.8050917413137313, "episode/reward_rate": 0.014492753623188406, "episode/intrinsic_return": 0.017591729026094072}
{"step": 330344, "time": 10917.41223692894, "episode/length": 288.0, "episode/score": 0.04149747951677796, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04149747951677796}
{"step": 330528, "time": 10923.423228263855, "episode/length": 140.0, "episode/score": 0.5809576048923191, "episode/reward_rate": 0.0070921985815602835, "episode/intrinsic_return": 0.018457623475114815}
{"step": 331016, "time": 10938.53779554367, "episode/length": 83.0, "episode/score": 0.7531896726725336, "episode/reward_rate": 0.011904761904761904, "episode/intrinsic_return": 0.012564634511591066}
{"step": 331072, "time": 10940.51431298256, "episode/length": 67.0, "episode/score": 0.8001108815923317, "episode/reward_rate": 0.014705882352941176, "episode/intrinsic_return": 0.009485897256013232}
{"step": 331656, "time": 10958.7116959095, "episode/length": 288.0, "episode/score": 0.042026494173853735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.042026494173853735}
{"step": 331752, "time": 10961.680370807648, "episode/length": 91.0, "episode/score": 0.7292375243541755, "episode/reward_rate": 0.010869565217391304, "episode/intrinsic_return": 0.013612506880235742}
{"step": 332000, "time": 10969.654612064362, "episode/length": 288.0, "episode/score": 0.040018585825208675, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.040018585825208675}
{"step": 332080, "time": 10972.253102064133, "episode/length": 288.0, "episode/score": 0.04201590985246639, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04201590985246639}
{"step": 332352, "time": 10980.758405923843, "episode/length": 86.0, "episode/score": 0.7470304498712039, "episode/reward_rate": 0.011494252873563218, "episode/intrinsic_return": 0.015780438450860856}
{"step": 332392, "time": 10981.794568300247, "episode/length": 48.0, "episode/score": 0.8585688437253793, "episode/reward_rate": 0.02040816326530612, "episode/intrinsic_return": 0.00856881170534507}
{"step": 332472, "time": 10984.331670761108, "episode/length": 288.0, "episode/score": 0.05970200790156355, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05970200790156355}
{"step": 332488, "time": 10984.840657711029, "episode/length": 288.0, "episode/score": 0.04268598513979782, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04268598513979782}
{"step": 332528, "time": 10986.326227664948, "episode/length": 288.0, "episode/score": 0.04856937543104323, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04856937543104323}
{"step": 333384, "time": 11013.055758714676, "episode/length": 288.0, "episode/score": 0.025436544733452138, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025436544733452138}
{"step": 333400, "time": 11013.58003783226, "episode/length": 125.0, "episode/score": 0.6293588441021711, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.01998384432044986}
{"step": 333424, "time": 11014.562296390533, "episode/length": 111.0, "episode/score": 0.6734885772498274, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.020363559775887552}
{"step": 333816, "time": 11026.534911870956, "episode/length": 257.0, "episode/score": 0.22156954522972683, "episode/reward_rate": 0.003875968992248062, "episode/intrinsic_return": 0.02469453985133896}
{"step": 333824, "time": 11027.010152816772, "episode/length": 183.0, "episode/score": 0.4457790138976634, "episode/reward_rate": 0.005434782608695652, "episode/intrinsic_return": 0.01765402631917823}
{"step": 334392, "time": 11044.577303171158, "episode/length": 288.0, "episode/score": 0.03705169624117843, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03705169624117843}
{"step": 334400, "time": 11045.051352024078, "episode/length": 72.0, "episode/score": 0.7941832889907801, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.019183283437769205}
{"step": 334432, "time": 11046.051732301712, "episode/length": 125.0, "episode/score": 0.6392625228812676, "episode/reward_rate": 0.007936507936507936, "episode/intrinsic_return": 0.029887514703091256}
{"step": 334456, "time": 11046.587034702301, "episode/length": 78.0, "episode/score": 0.7804076675390661, "episode/reward_rate": 0.012658227848101266, "episode/intrinsic_return": 0.024157663837058863}
{"step": 334696, "time": 11054.12659406662, "episode/length": 275.0, "episode/score": 0.17573577096709414, "episode/reward_rate": 0.0036231884057971015, "episode/intrinsic_return": 0.03511076380755185}
{"step": 334736, "time": 11055.613720417023, "episode/length": 166.0, "episode/score": 0.5109717233119682, "episode/reward_rate": 0.005988023952095809, "episode/intrinsic_return": 0.02972174169394748}
{"step": 334784, "time": 11057.128681898117, "episode/length": 288.0, "episode/score": 0.03662165989328514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03662165989328514}
{"step": 335160, "time": 11068.781197071075, "episode/length": 52.0, "episode/score": 0.85549205754387, "episode/reward_rate": 0.018867924528301886, "episode/intrinsic_return": 0.01799205199085918}
{"step": 335464, "time": 11078.249589204788, "episode/length": 133.0, "episode/score": 0.6137661629902595, "episode/reward_rate": 0.007462686567164179, "episode/intrinsic_return": 0.029391130970225277}
{"step": 335696, "time": 11085.691020011902, "episode/length": 288.0, "episode/score": 0.04172365026613534, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04172365026613534}
{"step": 335936, "time": 11093.7964656353, "episode/length": 96.0, "episode/score": 0.7310232197288542, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.031023223471606798}
{"step": 336040, "time": 11096.849641084671, "episode/length": 204.0, "episode/score": 0.4202533727995501, "episode/reward_rate": 0.004878048780487805, "episode/intrinsic_return": 0.05775335371907886}
{"step": 336216, "time": 11102.345856189728, "episode/length": 64.0, "episode/score": 0.8220808894051288, "episode/reward_rate": 0.015384615384615385, "episode/intrinsic_return": 0.022080870324657553}
{"step": 336288, "time": 11104.838671684265, "episode/length": 43.0, "episode/score": 0.8771146587814656, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.011489620620523056}
{"step": 336432, "time": 11109.358657121658, "episode/length": 17.0, "episode/score": 0.9575909881021403, "episode/reward_rate": 0.05555555555555555, "episode/intrinsic_return": 0.010715988602726156}
{"step": 336592, "time": 11114.356647491455, "episode/length": 46.0, "episode/score": 0.8732607303982718, "episode/reward_rate": 0.02127659574468085, "episode/intrinsic_return": 0.017010712924331983}
{"step": 336744, "time": 11118.838695764542, "episode/length": 288.0, "episode/score": 0.06992344922878146, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06992344922878146}
{"step": 336768, "time": 11119.82854771614, "episode/length": 288.0, "episode/score": 0.050641971603283764, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.050641971603283764}
{"step": 336976, "time": 11126.413945674896, "episode/length": 188.0, "episode/score": 0.4372290001672354, "episode/reward_rate": 0.005291005291005291, "episode/intrinsic_return": 0.024729012588750265}
{"step": 337008, "time": 11127.412779569626, "episode/length": 288.0, "episode/score": 0.05788102931245476, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05788102931245476}
{"step": 337096, "time": 11129.944780111313, "episode/length": 288.0, "episode/score": 0.057630920568954025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.057630920568954025}
{"step": 337144, "time": 11131.444897174835, "episode/length": 137.0, "episode/score": 0.6210768226648042, "episode/reward_rate": 0.007246376811594203, "episode/intrinsic_return": 0.04920181711179339}
{"step": 337152, "time": 11131.922620296478, "episode/length": 47.0, "episode/score": 0.8751995932495333, "episode/reward_rate": 0.020833333333333332, "episode/intrinsic_return": 0.022074608913214888}
{"step": 337176, "time": 11132.453476190567, "episode/length": 72.0, "episode/score": 0.7988806097047814, "episode/reward_rate": 0.0136986301369863, "episode/intrinsic_return": 0.02388065167832565}
{"step": 337712, "time": 11149.421646595001, "episode/length": 87.0, "episode/score": 0.7540128532590984, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.02588786994141401}
{"step": 337784, "time": 11151.554808139801, "episode/length": 129.0, "episode/score": 0.6389443594339923, "episode/reward_rate": 0.007692307692307693, "episode/intrinsic_return": 0.042069340353521056}
{"step": 337984, "time": 11158.008833169937, "episode/length": 103.0, "episode/score": 0.7200531352146413, "episode/reward_rate": 0.009615384615384616, "episode/intrinsic_return": 0.04192810421324111}
{"step": 338064, "time": 11160.53993320465, "episode/length": 135.0, "episode/score": 0.603557147364711, "episode/reward_rate": 0.007352941176470588, "episode/intrinsic_return": 0.025432167504561676}
{"step": 338232, "time": 11165.577763080597, "episode/length": 224.0, "episode/score": 0.3750894870888146, "episode/reward_rate": 0.0044444444444444444, "episode/intrinsic_return": 0.07508946349724965}
{"step": 338344, "time": 11169.081203699112, "episode/length": 145.0, "episode/score": 0.5832082847020388, "episode/reward_rate": 0.00684931506849315, "episode/intrinsic_return": 0.03633330484188946}
{"step": 338432, "time": 11172.077512741089, "episode/length": 80.0, "episode/score": 0.7824054356513557, "episode/reward_rate": 0.012345679012345678, "episode/intrinsic_return": 0.03240545378304205}
{"step": 338624, "time": 11178.124816417694, "episode/length": 79.0, "episode/score": 0.7861749459202656, "episode/reward_rate": 0.0125, "episode/intrinsic_return": 0.03304993421761537}
{"step": 338784, "time": 11183.251158952713, "episode/length": 210.0, "episode/score": 0.3858170376967678, "episode/reward_rate": 0.004739336492890996, "episode/intrinsic_return": 0.04206702602613177}
{"step": 339088, "time": 11192.744759321213, "episode/length": 171.0, "episode/score": 0.4974509566625329, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.0318259688017406}
{"step": 339264, "time": 11198.257508039474, "episode/length": 128.0, "episode/score": 0.6331086675594975, "episode/reward_rate": 0.007751937984496124, "episode/intrinsic_return": 0.03310865882252756}
{"step": 339272, "time": 11198.293127536774, "episode/length": 115.0, "episode/score": 0.6813979110130504, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.04077293115290104}
{"step": 339456, "time": 11204.264920711517, "episode/length": 288.0, "episode/score": 0.06828211123058736, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06828211123058736}
{"step": 339816, "time": 11215.494507074356, "episode/length": 172.0, "episode/score": 0.5073496270883879, "episode/reward_rate": 0.005780346820809248, "episode/intrinsic_return": 0.04484962194283071}
{"step": 339864, "time": 11216.993494033813, "episode/length": 96.0, "episode/score": 0.720946334894677, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.020946323474333894}
{"step": 339880, "time": 11217.500908613205, "episode/length": 156.0, "episode/score": 0.5511326711087463, "episode/reward_rate": 0.006369426751592357, "episode/intrinsic_return": 0.038632683844582516}
{"step": 339944, "time": 11219.510274410248, "episode/length": 144.0, "episode/score": 0.5902792529162753, "episode/reward_rate": 0.006896551724137931, "episode/intrinsic_return": 0.04027924181025355}
{"step": 340080, "time": 11224.865827083588, "eval_episode/length": 47.0, "eval_episode/score": 0.8531249761581421, "eval_episode/reward_rate": 0.020833333333333332}
{"step": 340080, "time": 11225.31572508812, "eval_episode/length": 70.0, "eval_episode/score": 0.78125, "eval_episode/reward_rate": 0.014084507042253521}
{"step": 340080, "time": 11226.451377868652, "eval_episode/length": 64.0, "eval_episode/score": 0.800000011920929, "eval_episode/reward_rate": 0.015384615384615385}
{"step": 340080, "time": 11226.800826787949, "eval_episode/length": 107.0, "eval_episode/score": 0.6656249761581421, "eval_episode/reward_rate": 0.009259259259259259}
{"step": 340080, "time": 11227.777242660522, "eval_episode/length": 75.0, "eval_episode/score": 0.765625, "eval_episode/reward_rate": 0.013157894736842105}
{"step": 340080, "time": 11229.180698156357, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11229.188371658325, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11229.1954600811, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11229.202402591705, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11229.20975446701, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340080, "time": 11229.217323303223, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 340312, "time": 11236.253151893616, "episode/length": 106.0, "episode/score": 0.6986597668774266, "episode/reward_rate": 0.009345794392523364, "episode/intrinsic_return": 0.02990975545708352}
{"step": 340376, "time": 11238.264662027359, "episode/length": 288.0, "episode/score": 0.05393210922125036, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05393210922125036}
{"step": 340432, "time": 11240.254599809647, "episode/length": 76.0, "episode/score": 0.7910918571860748, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.028591854787919146}
{"step": 340632, "time": 11246.379154920578, "episode/length": 85.0, "episode/score": 0.7642292035743594, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.029854174179490656}
{"step": 340784, "time": 11251.335953712463, "episode/length": 189.0, "episode/score": 0.4646211116520931, "episode/reward_rate": 0.005263157894736842, "episode/intrinsic_return": 0.055246106192214484}
{"step": 341024, "time": 11258.809478282928, "episode/length": 218.0, "episode/score": 0.3763243557683609, "episode/reward_rate": 0.0045662100456621, "episode/intrinsic_return": 0.05757436213627898}
{"step": 341288, "time": 11266.86138510704, "episode/length": 32.0, "episode/score": 0.9149925609042384, "episode/reward_rate": 0.030303030303030304, "episode/intrinsic_return": 0.014992576567919969}
{"step": 341289, "time": 11267.87522649765, "train/action_mag": 6.0, "train/action_max": 6.0, "train/action_mean": 2.3750682341746794, "train/action_min": 0.0, "train/action_std": 1.803003588700906, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.005761232139327778, "train/actor_opt_grad_steps": 20260.0, "train/actor_opt_loss": 13.81302159780111, "train/adv_mag": 0.1787967338011815, "train/adv_max": 0.11248918374379475, "train/adv_mean": 0.008227033308127702, "train/adv_min": -0.11873784019396855, "train/adv_std": 0.012647087749643012, "train/cont_avg": 0.9964893830128205, "train/cont_loss_mean": 0.021088110845392714, "train/cont_loss_std": 0.29048226467835214, "train/cont_neg_acc": 0.02748015895485878, "train/cont_neg_loss": 4.939364935950532, "train/cont_pos_acc": 0.999964794745812, "train/cont_pos_loss": 0.0036766198117477006, "train/cont_pred": 0.9962609728177388, "train/cont_rate": 0.9964893830128205, "train/dyn_loss_mean": 1.0000093264457508, "train/dyn_loss_std": 0.00025910749648643943, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9367249625520064, "train/extr_critic_critic_opt_grad_steps": 20260.0, "train/extr_critic_critic_opt_loss": 10270.186424529247, "train/extr_critic_mag": 0.42189130905346994, "train/extr_critic_max": 0.42189130905346994, "train/extr_critic_mean": 0.41401494863705757, "train/extr_critic_min": 0.40120509098737667, "train/extr_critic_std": 0.004160667820356022, "train/extr_return_normed_mag": 0.19035814083539523, "train/extr_return_normed_max": 0.1346253874974373, "train/extr_return_normed_mean": 0.025214346419297495, "train/extr_return_normed_min": -0.0992071529229482, "train/extr_return_normed_std": 0.0136225704372359, "train/extr_return_rate": 0.12042902413145967, "train/extr_return_raw_mag": 0.5316529883788182, "train/extr_return_raw_max": 0.5316529883788182, "train/extr_return_raw_mean": 0.4222419683749859, "train/extr_return_raw_min": 0.2978204479584327, "train/extr_return_raw_std": 0.013622570513055111, "train/extr_reward_mag": 0.1155834375283657, "train/extr_reward_max": 0.1155834375283657, "train/extr_reward_mean": 0.0023194623502114644, "train/extr_reward_min": 7.853141197791466e-06, "train/extr_reward_std": 0.007145386998458073, "train/image_loss_mean": 0.14846350627067761, "train/image_loss_std": 0.10845985313256581, "train/model_loss_mean": 0.7824807958725172, "train/model_loss_std": 0.37138635351871835, "train/model_opt_grad_norm": 33.015019392355896, "train/model_opt_grad_steps": 20240.43076923077, "train/model_opt_loss": 2927.0407689803687, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 3743.5897435897436, "train/policy_entropy_mag": 1.5806532511344322, "train/policy_entropy_max": 1.5806532511344322, "train/policy_entropy_mean": 0.27935951199287024, "train/policy_entropy_min": 0.06483132789532343, "train/policy_entropy_std": 0.27514398426581654, "train/policy_logprob_mag": 6.550686036623441, "train/policy_logprob_max": -0.008630741707598552, "train/policy_logprob_mean": -0.27863898919178887, "train/policy_logprob_min": -6.550686036623441, "train/policy_logprob_std": 0.7887495441314502, "train/policy_randomness_mag": 0.8122951333339398, "train/policy_randomness_max": 0.8122951333339398, "train/policy_randomness_mean": 0.14356239797213138, "train/policy_randomness_min": 0.03331671395362952, "train/policy_randomness_std": 0.14139604511169288, "train/post_ent_mag": 41.144946641188405, "train/post_ent_max": 41.144946641188405, "train/post_ent_mean": 40.74547735360952, "train/post_ent_min": 40.50891872308193, "train/post_ent_std": 0.11353967182147197, "train/prior_ent_mag": 41.66168944529998, "train/prior_ent_max": 41.66168944529998, "train/prior_ent_mean": 39.72325071677184, "train/prior_ent_min": 38.42713842147436, "train/prior_ent_std": 0.45918610095977785, "train/rep_loss_mean": 1.0000093264457508, "train/rep_loss_std": 0.00025910749648643943, "train/reward_avg": 0.000536925935646137, "train/reward_loss_mean": 0.012923559181105632, "train/reward_loss_std": 0.0916223310889342, "train/reward_max_data": 0.2674260824548606, "train/reward_max_pred": 0.02917590141296387, "train/reward_neg_acc": 0.9999699219679221, "train/reward_neg_loss": 0.009803398844236746, "train/reward_pos_acc": 0.029069767441860465, "train/reward_pos_loss": 5.1402526109717614, "train/reward_pred": 0.0004672408856164951, "train/reward_rate": 0.0006009615384615385, "train_stats/mean_log_entropy": 0.2366878806556366, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.01581861451268196, "report/cont_loss_std": 0.19564847648143768, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 3.008287191390991, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.004083442501723766, "report/cont_pred": 0.9957368969917297, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 1.0, "report/dyn_loss_std": 0.0, "report/image_loss_mean": 0.13142502307891846, "report/image_loss_std": 0.11994611471891403, "report/model_loss_mean": 0.7660001516342163, "report/model_loss_std": 0.36716964840888977, "report/post_ent_mag": 39.0788688659668, "report/post_ent_max": 39.0788688659668, "report/post_ent_mean": 38.64519500732422, "report/post_ent_min": 38.379817962646484, "report/post_ent_std": 0.12397472560405731, "report/prior_ent_mag": 40.151771545410156, "report/prior_ent_max": 40.151771545410156, "report/prior_ent_mean": 37.609153747558594, "report/prior_ent_min": 36.1264533996582, "report/prior_ent_std": 0.5069637894630432, "report/rep_loss_mean": 1.0, "report/rep_loss_std": 0.0, "report/reward_avg": 0.0007817918667569757, "report/reward_loss_mean": 0.018756486475467682, "report/reward_loss_std": 0.18321746587753296, "report/reward_max_data": 0.45645835995674133, "report/reward_max_pred": 0.05349373817443848, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.010696154087781906, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 4.137585639953613, "report/reward_pred": 0.0010906540555879474, "report/reward_rate": 0.001953125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.011804298497736454, "eval/cont_loss_std": 0.22363148629665375, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.141417026519775, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.004834979772567749, "eval/cont_pred": 0.9953328371047974, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 1.0, "eval/dyn_loss_std": 0.0, "eval/image_loss_mean": 0.22081665694713593, "eval/image_loss_std": 0.13347318768501282, "eval/model_loss_mean": 0.8341277837753296, "eval/model_loss_std": 0.2605544626712799, "eval/post_ent_mag": 39.071128845214844, "eval/post_ent_max": 39.071128845214844, "eval/post_ent_mean": 38.605499267578125, "eval/post_ent_min": 38.37186813354492, "eval/post_ent_std": 0.1261046826839447, "eval/prior_ent_mag": 39.583824157714844, "eval/prior_ent_max": 39.583824157714844, "eval/prior_ent_mean": 37.62516784667969, "eval/prior_ent_min": 35.94539260864258, "eval/prior_ent_std": 0.5125818848609924, "eval/rep_loss_mean": 1.0, "eval/rep_loss_std": 0.0, "eval/reward_avg": 0.0, "eval/reward_loss_mean": 0.0015067751519382, "eval/reward_loss_std": 0.001992195611819625, "eval/reward_max_data": 0.0, "eval/reward_max_pred": 0.010467171669006348, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.0015067751519382, "eval/reward_pos_acc": NaN, "eval/reward_pos_loss": NaN, "eval/reward_pred": 0.00027846370358020067, "eval/reward_rate": 0.0, "replay/size": 340785.0, "replay/inserts": 31240.0, "replay/samples": 31248.0, "replay/insert_wait_avg": 1.329244633184963e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.090498871029308e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 80688.0, "eval_replay/inserts": 6280.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1749707969130985e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.019357919693, "timer/env.step_count": 3905.0, "timer/env.step_total": 37.69935631752014, "timer/env.step_frac": 0.03769862655053484, "timer/env.step_avg": 0.00965412453713704, "timer/env.step_min": 0.007806301116943359, "timer/env.step_max": 0.0487217903137207, "timer/replay._sample_count": 31248.0, "timer/replay._sample_total": 15.914688348770142, "timer/replay._sample_frac": 0.015914380279474727, "timer/replay._sample_avg": 0.0005093026225284863, "timer/replay._sample_min": 0.0003478527069091797, "timer/replay._sample_max": 0.008750677108764648, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 4690.0, "timer/agent.policy_total": 46.69005513191223, "timer/agent.policy_frac": 0.046689151327070307, "timer/agent.policy_avg": 0.009955235635802182, "timer/agent.policy_min": 0.00867605209350586, "timer/agent.policy_max": 0.07917428016662598, "timer/dataset_train_count": 1953.0, "timer/dataset_train_total": 0.2142786979675293, "timer/dataset_train_frac": 0.000214274550057997, "timer/dataset_train_avg": 0.00010971771529315376, "timer/dataset_train_min": 9.703636169433594e-05, "timer/dataset_train_max": 0.00045228004455566406, "timer/agent.train_count": 1953.0, "timer/agent.train_total": 866.1415657997131, "timer/agent.train_frac": 0.8661247994254018, "timer/agent.train_avg": 0.44349286523282805, "timer/agent.train_min": 0.43163609504699707, "timer/agent.train_max": 0.600419282913208, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4705181121826172, "timer/agent.report_frac": 0.00047050900410710087, "timer/agent.report_avg": 0.2352590560913086, "timer/agent.report_min": 0.2248389720916748, "timer/agent.report_max": 0.24567914009094238, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7179191884964296e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 31.23885170907948}
{"step": 342032, "time": 11291.390363693237, "episode/length": 155.0, "episode/score": 0.5496203555260308, "episode/reward_rate": 0.00641025641025641, "episode/intrinsic_return": 0.03399537566588151}
{"step": 342176, "time": 11295.922448158264, "episode/length": 288.0, "episode/score": 0.059043349636226594, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059043349636226594}
{"step": 342192, "time": 11296.448471784592, "episode/length": 288.0, "episode/score": 0.05380498689680735, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05380498689680735}
{"step": 342232, "time": 11297.490188837051, "episode/length": 239.0, "episode/score": 0.3102003556351747, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.05707533553606936}
{"step": 342688, "time": 11312.108414888382, "episode/length": 288.0, "episode/score": 0.048795313319033085, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.048795313319033085}
{"step": 342744, "time": 11313.636764287949, "episode/length": 288.0, "episode/score": 0.038812476371731464, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038812476371731464}
{"step": 342944, "time": 11320.14572429657, "episode/length": 288.0, "episode/score": 0.06791292088325918, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06791292088325918}
{"step": 343600, "time": 11340.880675315857, "episode/length": 288.0, "episode/score": 0.037565977278063656, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.037565977278063656}
{"step": 344344, "time": 11364.599096298218, "episode/length": 288.0, "episode/score": 0.059021869464572774, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059021869464572774}
{"step": 344488, "time": 11369.116096258163, "episode/length": 288.0, "episode/score": 0.05165873816804378, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05165873816804378}
{"step": 344504, "time": 11369.627132177353, "episode/length": 288.0, "episode/score": 0.053160595386316345, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053160595386316345}
{"step": 344544, "time": 11371.11045217514, "episode/length": 288.0, "episode/score": 0.049197000689787274, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049197000689787274}
{"step": 345000, "time": 11385.250437021255, "episode/length": 288.0, "episode/score": 0.04135896688637786, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04135896688637786}
{"step": 345056, "time": 11388.322594881058, "episode/length": 288.0, "episode/score": 0.06152445383804661, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06152445383804661}
{"step": 345256, "time": 11394.492066144943, "episode/length": 288.0, "episode/score": 0.047588060921498254, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047588060921498254}
{"step": 345912, "time": 11415.042565584183, "episode/length": 288.0, "episode/score": 0.049025360455289047, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.049025360455289047}
{"step": 346656, "time": 11438.647759437561, "episode/length": 288.0, "episode/score": 0.03011302279855954, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03011302279855954}
{"step": 346800, "time": 11443.204312562943, "episode/length": 288.0, "episode/score": 0.02210240357840121, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02210240357840121}
{"step": 346816, "time": 11443.71580195427, "episode/length": 288.0, "episode/score": 0.02448457021705508, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02448457021705508}
{"step": 346856, "time": 11444.774924516678, "episode/length": 288.0, "episode/score": 0.0289299471708091, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0289299471708091}
{"step": 347312, "time": 11459.505886793137, "episode/length": 288.0, "episode/score": 0.03227393414931612, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03227393414931612}
{"step": 347368, "time": 11461.070818185806, "episode/length": 288.0, "episode/score": 0.02921399036688399, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02921399036688399}
{"step": 347568, "time": 11467.60137629509, "episode/length": 288.0, "episode/score": 0.047332110662296145, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.047332110662296145}
{"step": 348224, "time": 11488.4243414402, "episode/length": 288.0, "episode/score": 0.03925304403855989, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03925304403855989}
{"step": 348392, "time": 11493.504596471786, "episode/length": 134.0, "episode/score": 0.6211740056305644, "episode/reward_rate": 0.007407407407407408, "episode/intrinsic_return": 0.03992396507146623}
{"step": 348912, "time": 11510.127529382706, "episode/length": 85.0, "episode/score": 0.7667733760079045, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.03239834736973535}
{"step": 348968, "time": 11511.807802677155, "episode/length": 288.0, "episode/score": 0.06729174987367514, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06729174987367514}
{"step": 349112, "time": 11516.343016147614, "episode/length": 288.0, "episode/score": 0.07264438434378917, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07264438434378917}
{"step": 349128, "time": 11516.850289344788, "episode/length": 288.0, "episode/score": 0.07594577254758406, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07594577254758406}
{"step": 349168, "time": 11518.332357645035, "episode/length": 288.0, "episode/score": 0.06660631180614018, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06660631180614018}
{"step": 349680, "time": 11534.49529671669, "episode/length": 288.0, "episode/score": 0.059410660877688315, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.059410660877688315}
{"step": 349736, "time": 11536.059741020203, "episode/length": 77.0, "episode/score": 0.7844328386689767, "episode/reward_rate": 0.01282051282051282, "episode/intrinsic_return": 0.02505783387266547}
{"step": 349880, "time": 11540.606063365936, "episode/length": 288.0, "episode/score": 0.07469380067158227, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07469380067158227}
{"step": 350064, "time": 11549.25260925293, "eval_episode/length": 100.0, "eval_episode/score": 0.6875, "eval_episode/reward_rate": 0.009900990099009901}
{"step": 350064, "time": 11549.906567573547, "eval_episode/length": 135.0, "eval_episode/score": 0.578125, "eval_episode/reward_rate": 0.007352941176470588}
{"step": 350064, "time": 11551.19127869606, "eval_episode/length": 203.0, "eval_episode/score": 0.3656249940395355, "eval_episode/reward_rate": 0.004901960784313725}
{"step": 350064, "time": 11552.364129781723, "eval_episode/length": 267.0, "eval_episode/score": 0.16562500596046448, "eval_episode/reward_rate": 0.0037313432835820895}
{"step": 350064, "time": 11552.773605823517, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11552.781208992004, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11552.788233995438, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350064, "time": 11552.794697999954, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 350704, "time": 11573.004578351974, "episode/length": 288.0, "episode/score": 0.0909053149350143, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0909053149350143}
{"step": 351000, "time": 11582.068919420242, "episode/length": 253.0, "episode/score": 0.2611624630253573, "episode/reward_rate": 0.003937007874015748, "episode/intrinsic_return": 0.05178747014997498}
{"step": 351224, "time": 11589.134306669235, "episode/length": 288.0, "episode/score": 0.04990037937955094, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04990037937955094}
{"step": 351280, "time": 11591.115441322327, "episode/length": 268.0, "episode/score": 0.24174374698424117, "episode/reward_rate": 0.0037174721189591076, "episode/intrinsic_return": 0.0792437537596129}
{"step": 351480, "time": 11597.189043998718, "episode/length": 288.0, "episode/score": 0.05731267551601604, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05731267551601604}
{"step": 351992, "time": 11613.382473230362, "episode/length": 288.0, "episode/score": 0.05653544878271077, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05653544878271077}
{"step": 352048, "time": 11615.365787029266, "episode/length": 288.0, "episode/score": 0.04691354423243865, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.04691354423243865}
{"step": 352192, "time": 11619.910874128342, "episode/length": 288.0, "episode/score": 0.05386734180245867, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.05386734180245867}
{"step": 353016, "time": 11646.121186971664, "episode/length": 288.0, "episode/score": 0.03930630267984725, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03930630267984725}
{"step": 353032, "time": 11646.627213954926, "episode/length": 122.0, "episode/score": 0.643801490201156, "episode/reward_rate": 0.008130081300813009, "episode/intrinsic_return": 0.02505149070174184}
{"step": 353312, "time": 11655.661062002182, "episode/length": 288.0, "episode/score": 0.02698103942088892, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02698103942088892}
{"step": 353536, "time": 11662.80242228508, "episode/length": 288.0, "episode/score": 0.03189668010020341, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03189668010020341}
{"step": 353592, "time": 11664.347235441208, "episode/length": 288.0, "episode/score": 0.041924522949869925, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.041924522949869925}
{"step": 353664, "time": 11666.815010786057, "episode/length": 43.0, "episode/score": 0.8830134279477306, "episode/reward_rate": 0.022727272727272728, "episode/intrinsic_return": 0.017388404920779976}
{"step": 353744, "time": 11669.3297996521, "episode/length": 25.0, "episode/score": 0.9355066994993422, "episode/reward_rate": 0.038461538461538464, "episode/intrinsic_return": 0.013631685180257591}
{"step": 353792, "time": 11670.853901863098, "episode/length": 288.0, "episode/score": 0.060777806534190404, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.060777806534190404}
{"step": 354304, "time": 11686.921295881271, "episode/length": 288.0, "episode/score": 0.031176620569425495, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031176620569425495}
{"step": 354504, "time": 11693.109776496887, "episode/length": 288.0, "episode/score": 0.03242079546001264, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03242079546001264}
{"step": 355328, "time": 11719.29551076889, "episode/length": 288.0, "episode/score": 0.019531380289834033, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.019531380289834033}
{"step": 355344, "time": 11719.798901319504, "episode/length": 288.0, "episode/score": 0.012195289581910629, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.012195289581910629}
{"step": 355800, "time": 11734.064721345901, "episode/length": 56.0, "episode/score": 0.848641494775535, "episode/reward_rate": 0.017543859649122806, "episode/intrinsic_return": 0.023641507511371174}
{"step": 355904, "time": 11737.554925441742, "episode/length": 288.0, "episode/score": 0.026132500724514784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.026132500724514784}
{"step": 355976, "time": 11739.605532169342, "episode/length": 288.0, "episode/score": 0.011819236347690776, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.011819236347690776}
{"step": 356056, "time": 11742.100637435913, "episode/length": 288.0, "episode/score": 0.006840538696621934, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.006840538696621934}
{"step": 356104, "time": 11743.605493307114, "episode/length": 288.0, "episode/score": 0.02231567353595665, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02231567353595665}
{"step": 356368, "time": 11752.259772539139, "episode/length": 57.0, "episode/score": 0.8486870832806233, "episode/reward_rate": 0.017241379310344827, "episode/intrinsic_return": 0.02681208378120914}
{"step": 356616, "time": 11759.796909809113, "episode/length": 288.0, "episode/score": 0.01616733482495647, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.01616733482495647}
{"step": 356816, "time": 11766.32303929329, "episode/length": 288.0, "episode/score": 0.018814779451474806, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018814779451474806}
{"step": 357640, "time": 11792.204180955887, "episode/length": 288.0, "episode/score": 0.03806819853073762, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03806819853073762}
{"step": 358000, "time": 11803.77816581726, "episode/length": 147.0, "episode/score": 0.5712689073191939, "episode/reward_rate": 0.006756756756756757, "episode/intrinsic_return": 0.03064393197595905}
{"step": 358112, "time": 11807.327121973038, "episode/length": 288.0, "episode/score": 0.021345497161036064, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.021345497161036064}
{"step": 358288, "time": 11812.982488155365, "episode/length": 288.0, "episode/score": 0.020384687371745258, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020384687371745258}
{"step": 358368, "time": 11815.50835442543, "episode/length": 288.0, "episode/score": 0.03402955464557067, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03402955464557067}
{"step": 358416, "time": 11817.015830516815, "episode/length": 288.0, "episode/score": 0.02184500590928451, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.02184500590928451}
{"step": 358680, "time": 11825.1213722229, "episode/length": 288.0, "episode/score": 0.013725801522383563, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013725801522383563}
{"step": 358928, "time": 11833.140644073486, "episode/length": 288.0, "episode/score": 0.013859876549730643, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.013859876549730643}
{"step": 359952, "time": 11865.487629890442, "episode/length": 288.0, "episode/score": 0.027293937558624748, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.027293937558624748}
{"step": 360048, "time": 11873.912657260895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.920380830765, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.9280397892, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.934234380722, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.941226005554, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.947230815887, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.95337843895, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360048, "time": 11873.961565732956, "eval_episode/length": 288.0, "eval_episode/score": 0.0, "eval_episode/reward_rate": 0.0}
{"step": 360144, "time": 11876.981888532639, "episode/length": 182.0, "episode/score": 0.4608265564531564, "episode/reward_rate": 0.00546448087431694, "episode/intrinsic_return": 0.029576536173607337}
{"step": 360312, "time": 11882.052014827728, "episode/length": 288.0, "episode/score": 0.029233652818874134, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029233652818874134}
{"step": 360424, "time": 11885.566736221313, "episode/length": 288.0, "episode/score": 0.020031839359717196, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.020031839359717196}
{"step": 360600, "time": 11891.585709571838, "episode/length": 288.0, "episode/score": 0.016379267372570894, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.016379267372570894}
{"step": 360680, "time": 11894.07510304451, "episode/length": 288.0, "episode/score": 0.029850483798867344, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.029850483798867344}
{"step": 360728, "time": 11895.580608129501, "episode/length": 288.0, "episode/score": 0.018079323546629666, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.018079323546629666}
{"step": 361240, "time": 11911.770533800125, "episode/length": 288.0, "episode/score": 0.034310854471470975, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.034310854471470975}
{"step": 361416, "time": 11917.281775712967, "episode/length": 101.0, "episode/score": 0.7069973334860293, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.02262231676878912}
{"step": 361624, "time": 11923.814156770706, "episode/length": 163.0, "episode/score": 0.5200002503837737, "episode/reward_rate": 0.006097560975609756, "episode/intrinsic_return": 0.029375257508391428}
{"step": 362264, "time": 11944.006141901016, "episode/length": 288.0, "episode/score": 0.03918925138357565, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03918925138357565}
{"step": 362456, "time": 11950.016213655472, "episode/length": 288.0, "episode/score": 0.038366434617756795, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.038366434617756795}
{"step": 362704, "time": 11958.051857233047, "episode/length": 30.0, "episode/score": 0.9140911195875105, "episode/reward_rate": 0.03225806451612903, "episode/intrinsic_return": 0.007841105268425963}
{"step": 362736, "time": 11959.06107211113, "episode/length": 288.0, "episode/score": 0.036154768875348964, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.036154768875348964}
{"step": 362992, "time": 11967.299141407013, "episode/length": 288.0, "episode/score": 0.03270137900014447, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03270137900014447}
{"step": 363040, "time": 11968.806014299393, "episode/length": 288.0, "episode/score": 0.03931930146251261, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03931930146251261}
{"step": 363080, "time": 11969.8406291008, "episode/length": 101.0, "episode/score": 0.6999907499456413, "episode/reward_rate": 0.00980392156862745, "episode/intrinsic_return": 0.01561573322840104}
{"step": 363168, "time": 11972.878524065018, "episode/length": 240.0, "episode/score": 0.2798417892769294, "episode/reward_rate": 0.004149377593360996, "episode/intrinsic_return": 0.02984177495784479}
{"step": 363480, "time": 11982.46176147461, "episode/length": 96.0, "episode/score": 0.7333248192134079, "episode/reward_rate": 0.010309278350515464, "episode/intrinsic_return": 0.03332483194924407}
{"step": 363608, "time": 11986.485912561417, "episode/length": 76.0, "episode/score": 0.7916768722392362, "episode/reward_rate": 0.012987012987012988, "episode/intrinsic_return": 0.029176884975072426}
{"step": 363664, "time": 11988.481966733932, "episode/length": 115.0, "episode/score": 0.6680432702069083, "episode/reward_rate": 0.008620689655172414, "episode/intrinsic_return": 0.0274182710218156}
{"step": 363728, "time": 11990.4936773777, "episode/length": 288.0, "episode/score": 0.03955601872576153, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03955601872576153}
{"step": 363768, "time": 11991.61500620842, "episode/length": 90.0, "episode/score": 0.7435295266188859, "episode/reward_rate": 0.01098901098901099, "episode/intrinsic_return": 0.024779512299801354}
{"step": 363936, "time": 11997.127712249756, "episode/length": 288.0, "episode/score": 0.031070935665866273, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.031070935665866273}
{"step": 363984, "time": 11998.64880156517, "episode/length": 112.0, "episode/score": 0.6863493737951103, "episode/reward_rate": 0.008849557522123894, "episode/intrinsic_return": 0.03634938331788362}
{"step": 364672, "time": 12020.229499340057, "episode/length": 187.0, "episode/score": 0.4633686259662113, "episode/reward_rate": 0.005319148936170213, "episode/intrinsic_return": 0.047743626466797195}
{"step": 365392, "time": 12042.88258934021, "episode/length": 238.0, "episode/score": 0.3343159286306445, "episode/reward_rate": 0.0041841004184100415, "episode/intrinsic_return": 0.07806594105215936}
{"step": 365584, "time": 12048.874272346497, "episode/length": 239.0, "episode/score": 0.313275806991669, "episode/reward_rate": 0.004166666666666667, "episode/intrinsic_return": 0.060150795478193686}
{"step": 365776, "time": 12055.066948413849, "episode/length": 255.0, "episode/score": 0.27629808298780745, "episode/reward_rate": 0.00390625, "episode/intrinsic_return": 0.07317308356988406}
{"step": 365792, "time": 12055.579923152924, "episode/length": 49.0, "episode/score": 0.8601451705640102, "episode/reward_rate": 0.02, "episode/intrinsic_return": 0.013270151483538939}
{"step": 365920, "time": 12059.638017177582, "episode/length": 288.0, "episode/score": 0.07654080950703701, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.07654080950703701}
{"step": 366080, "time": 12064.686582803726, "episode/length": 288.0, "episode/score": 0.03348272228379301, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.03348272228379301}
{"step": 366136, "time": 12066.231300115585, "episode/length": 44.0, "episode/score": 0.8715496873804227, "episode/reward_rate": 0.022222222222222223, "episode/intrinsic_return": 0.009049646064624994}
{"step": 366248, "time": 12069.77669620514, "episode/length": 288.0, "episode/score": 0.06383871912635186, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.06383871912635186}
{"step": 366296, "time": 12071.289441108704, "episode/length": 288.0, "episode/score": 0.061987559747137766, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.061987559747137766}
{"step": 366448, "time": 12076.2995595932, "episode/length": 38.0, "episode/score": 0.8983993654639448, "episode/reward_rate": 0.02564102564102564, "episode/intrinsic_return": 0.01714933446254463}
{"step": 366608, "time": 12081.412420988083, "episode/length": 85.0, "episode/score": 0.7486794827916583, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.014304474613481943}
{"step": 366800, "time": 12087.435244560242, "episode/length": 62.0, "episode/score": 0.8198588506937767, "episode/reward_rate": 0.015873015873015872, "episode/intrinsic_return": 0.013608867376092348}
{"step": 366960, "time": 12092.471558332443, "episode/length": 171.0, "episode/score": 0.5134962022589775, "episode/reward_rate": 0.005813953488372093, "episode/intrinsic_return": 0.047871220640956835}
{"step": 366984, "time": 12093.011684656143, "episode/length": 288.0, "episode/score": 0.053632388453422664, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.053632388453422664}
{"step": 367672, "time": 12114.861452817917, "episode/length": 85.0, "episode/score": 0.7441461333307302, "episode/reward_rate": 0.011627906976744186, "episode/intrinsic_return": 0.009771151462416583}
{"step": 367856, "time": 12120.868185043335, "episode/length": 111.0, "episode/score": 0.6682752016791937, "episode/reward_rate": 0.008928571428571428, "episode/intrinsic_return": 0.015150231731809072}
{"step": 367912, "time": 12122.42419219017, "episode/length": 264.0, "episode/score": 0.21379785268896967, "episode/reward_rate": 0.0037735849056603774, "episode/intrinsic_return": 0.038797862392186744}
{"step": 368024, "time": 12125.967034339905, "episode/length": 152.0, "episode/score": 0.559611848246675, "episode/reward_rate": 0.006535947712418301, "episode/intrinsic_return": 0.0346118649289906}
{"step": 368392, "time": 12137.591722726822, "episode/length": 288.0, "episode/score": 0.025653257354690595, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.025653257354690595}
{"step": 368560, "time": 12143.315265655518, "episode/length": 288.0, "episode/score": 0.032697792221824784, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.032697792221824784}
{"step": 368616, "time": 12144.877374887466, "episode/length": 87.0, "episode/score": 0.7371314971566676, "episode/reward_rate": 0.011363636363636364, "episode/intrinsic_return": 0.009006512820349144}
{"step": 368760, "time": 12149.919553518295, "episode/length": 288.0, "episode/score": 0.043248505857548025, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.043248505857548025}
{"step": 368904, "time": 12154.472215652466, "episode/length": 109.0, "episode/score": 0.692193759157476, "episode/reward_rate": 0.00909090909090909, "episode/intrinsic_return": 0.032818740077004804}
{"step": 368920, "time": 12155.005118846893, "episode/length": 288.0, "episode/score": 0.0352037822266027, "episode/reward_rate": 0.0, "episode/intrinsic_return": 0.0352037822266027}
