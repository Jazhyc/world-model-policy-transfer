{"step": 928, "time": 148.7134289741516, "episode/length": 115.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 1224, "time": 151.2670760154724, "episode/length": 152.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 1288, "time": 152.91693353652954, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1336, "time": 154.53799438476562, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 172.25641226768494, "eval_episode/length": 154.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 1560, "time": 173.8456585407257, "eval_episode/length": 160.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 1560, "time": 175.23229098320007, "eval_episode/length": 165.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 1560, "time": 176.68519115447998, "eval_episode/length": 167.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 1560, "time": 178.5436704158783, "eval_episode/length": 184.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9621621621621622}
{"step": 1560, "time": 180.0458266735077, "eval_episode/length": 188.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 1560, "time": 181.63570308685303, "eval_episode/length": 192.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 1560, "time": 183.07706689834595, "train_stats/sum_log_reward": 0.599999975413084, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_collect_sapling": 1.0, "train_stats/max_log_achievement_place_plant": 1.0, "eval_stats/sum_log_reward": 1.0999999727521623, "eval_stats/max_log_achievement_collect_sapling": 0.8571428571428571, "eval_stats/max_log_achievement_place_plant": 0.8571428571428571, "eval_stats/max_log_achievement_wake_up": 2.142857142857143}
{"step": 1560, "time": 227.03933358192444, "eval_episode/length": 134.0, "eval_episode/score": 0.09999997168779373, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 1560, "time": 229.34501123428345, "eval_episode/length": 144.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 1560, "time": 231.70312190055847, "eval_episode/length": 151.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 1560, "time": 234.13773846626282, "eval_episode/length": 164.0, "eval_episode/score": 0.10000000149011612, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 1560, "time": 236.34716939926147, "eval_episode/length": 175.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 1560, "time": 238.07426261901855, "eval_episode/length": 179.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 1560, "time": 240.5584990978241, "eval_episode/length": 198.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 1560, "time": 245.8161325454712, "eval_episode/length": 278.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.985663082437276}
{"step": 1561, "time": 373.17497205734253, "eval_stats/sum_log_reward": 1.2249999940395355, "eval_stats/max_log_achievement_collect_sapling": 0.5, "eval_stats/max_log_achievement_place_plant": 0.5, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/max_log_achievement_collect_drink": 2.5714285714285716, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.4140625, "train/action_min": 0.0, "train/action_std": 4.330021381378174, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003233955358155072, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.830301821231842, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.99609375, "train/cont_loss_mean": 0.942281186580658, "train/cont_loss_std": 0.34567129611968994, "train/cont_neg_acc": 0.75, "train/cont_neg_loss": 0.6157612800598145, "train/cont_pos_acc": 0.2499999850988388, "train/cont_pos_loss": 0.9435616135597229, "train/cont_pred": 0.41239410638809204, "train/cont_rate": 0.99609375, "train/dyn_loss_mean": 10.959992408752441, "train/dyn_loss_std": 0.4401136040687561, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 3.1656434535980225, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 12568.1591796875, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3625.5537109375, "train/image_loss_std": 143.79383850097656, "train/model_loss_mean": 3638.61328125, "train/model_loss_std": 143.8167266845703, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36386132.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.75142502784729, "train/policy_entropy_max": 2.75142502784729, "train/policy_entropy_mean": 2.4541234970092773, "train/policy_entropy_min": 1.4166723489761353, "train/policy_entropy_std": 0.14569997787475586, "train/policy_logprob_mag": 6.0241217613220215, "train/policy_logprob_max": -0.46651560068130493, "train/policy_logprob_mean": -2.456962823867798, "train/policy_logprob_min": -6.0241217613220215, "train/policy_logprob_std": 0.8578368425369263, "train/policy_randomness_mag": 0.9711322784423828, "train/policy_randomness_max": 0.9711322784423828, "train/policy_randomness_mean": 0.8661980032920837, "train/policy_randomness_min": 0.5000231862068176, "train/policy_randomness_std": 0.05142569541931152, "train/post_ent_mag": 106.03781127929688, "train/post_ent_max": 106.03781127929688, "train/post_ent_mean": 105.4165267944336, "train/post_ent_min": 104.9970703125, "train/post_ent_std": 0.17987048625946045, "train/prior_ent_mag": 106.58589172363281, "train/prior_ent_max": 106.58589172363281, "train/prior_ent_mean": 105.64875793457031, "train/prior_ent_min": 104.6439208984375, "train/prior_ent_std": 0.2694712281227112, "train/rep_loss_mean": 10.959992408752441, "train/rep_loss_std": 0.4401136040687561, "train/reward_avg": 0.008984374813735485, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.5367431640625e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 0.9999999403953552, "train/reward_neg_loss": 5.541262626647949, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0126953125, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.9533053636550903, "report/cont_loss_std": 0.3789014220237732, "report/cont_neg_acc": 0.0, "report/cont_neg_loss": 1.041348934173584, "report/cont_pos_acc": 0.26764702796936035, "report/cont_pos_loss": 0.9529600143432617, "report/cont_pred": 0.41328489780426025, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.033242225646973, "report/dyn_loss_std": 0.4335837960243225, "report/image_loss_mean": 3627.5927734375, "report/image_loss_std": 142.0782012939453, "report/model_loss_mean": 3640.707275390625, "report/model_loss_std": 142.12939453125, "report/post_ent_mag": 105.974853515625, "report/post_ent_max": 105.974853515625, "report/post_ent_mean": 105.401611328125, "report/post_ent_min": 104.84375, "report/post_ent_std": 0.18056431412696838, "report/prior_ent_mag": 106.72209930419922, "report/prior_ent_max": 106.72209930419922, "report/prior_ent_mean": 105.59442138671875, "report/prior_ent_min": 104.5797119140625, "report/prior_ent_std": 0.29488369822502136, "report/rep_loss_mean": 11.033242225646973, "report/rep_loss_std": 0.4335837960243225, "report/reward_avg": 0.008984374813735485, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.5367431640625e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 0.9999999403953552, "report/reward_neg_loss": 5.541262626647949, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0126953125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.8902435302734375, "eval/cont_loss_std": 0.34394994378089905, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.3467678427696228, "eval/cont_pos_acc": 0.30039137601852417, "eval/cont_pos_loss": 0.89130699634552, "eval/cont_pred": 0.4324769675731659, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 11.04936408996582, "eval/dyn_loss_std": 0.43775230646133423, "eval/image_loss_mean": 3645.328857421875, "eval/image_loss_std": 183.38925170898438, "eval/model_loss_mean": 3658.39013671875, "eval/model_loss_std": 183.3782958984375, "eval/post_ent_mag": 105.79967498779297, "eval/post_ent_max": 105.79967498779297, "eval/post_ent_mean": 105.39482116699219, "eval/post_ent_min": 104.84617614746094, "eval/post_ent_std": 0.1428654044866562, "eval/prior_ent_mag": 106.83491516113281, "eval/prior_ent_max": 106.83491516113281, "eval/prior_ent_mean": 105.62411499023438, "eval/prior_ent_min": 104.77424621582031, "eval/prior_ent_std": 0.2908181846141815, "eval/rep_loss_mean": 11.04936408996582, "eval/rep_loss_std": 0.43775230646133423, "eval/reward_avg": 0.007324219215661287, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.5367431640625e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.009765625, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.8358456152389944e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.430306298392159e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 3288.0, "eval_replay/inserts": 3288.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 1.5627728761547673e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0281801223754883e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 241.36579728126526, "timer/env.step_count": 196.0, "timer/env.step_total": 24.693005323410034, "timer/env.step_frac": 0.10230532080995346, "timer/env.step_avg": 0.1259847210378063, "timer/env.step_min": 0.02367877960205078, "timer/env.step_max": 13.323679208755493, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.13164377212524414, "timer/replay._sample_frac": 0.0005454118752866991, "timer/replay._sample_avg": 0.0011753908225468227, "timer/replay._sample_min": 0.0003986358642578125, "timer/replay._sample_max": 0.014888525009155273, "timer/agent.save_count": 1.0, "timer/agent.save_total": 8.94423794746399, "timer/agent.save_frac": 0.037056774606060716, "timer/agent.save_avg": 8.94423794746399, "timer/agent.save_min": 8.94423794746399, "timer/agent.save_max": 8.94423794746399, "timer/agent.policy_count": 280.0, "timer/agent.policy_total": 27.74830937385559, "timer/agent.policy_frac": 0.11496371767007357, "timer/agent.policy_avg": 0.09910110490662712, "timer/agent.policy_min": 0.010820627212524414, "timer/agent.policy_max": 20.13764715194702, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.719329833984375e-05, "timer/dataset_train_frac": 1.5409514835485218e-07, "timer/dataset_train_avg": 3.719329833984375e-05, "timer/dataset_train_min": 3.719329833984375e-05, "timer/dataset_train_max": 3.719329833984375e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 97.7033007144928, "timer/agent.train_frac": 0.40479347867435606, "timer/agent.train_avg": 97.7033007144928, "timer/agent.train_min": 97.7033007144928, "timer/agent.train_max": 97.7033007144928, "timer/agent.report_count": 2.0, "timer/agent.report_total": 27.103160619735718, "timer/agent.report_frac": 0.11229080890923503, "timer/agent.report_avg": 13.551580309867859, "timer/agent.report_min": 0.24662518501281738, "timer/agent.report_max": 26.8565354347229, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.0531158447265625e-05, "timer/dataset_eval_frac": 1.6792420013028764e-07, "timer/dataset_eval_avg": 4.0531158447265625e-05, "timer/dataset_eval_min": 4.0531158447265625e-05, "timer/dataset_eval_max": 4.0531158447265625e-05}
{"step": 1592, "time": 374.0426290035248, "episode/length": 198.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 1608, "time": 376.38334369659424, "episode/length": 200.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 1696, "time": 381.31299352645874, "episode/length": 58.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 1696, "time": 381.3223395347595, "episode/length": 211.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 1712, "time": 385.477831363678, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 2248, "time": 405.2093527317047, "episode/length": 164.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 2400, "time": 412.3605794906616, "episode/length": 138.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 3008, "time": 434.8250696659088, "episode/length": 208.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 3008, "time": 434.83813738822937, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 3096, "time": 441.1092698574066, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 3232, "time": 447.6220374107361, "episode/length": 191.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 3304, "time": 451.5199203491211, "episode/length": 213.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 3736, "time": 467.8015184402466, "episode/length": 166.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 3848, "time": 473.335688829422, "episode/length": 279.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 4168, "time": 485.7694036960602, "episode/length": 144.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 4224, "time": 489.63469552993774, "episode/length": 246.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9919028340080972, "episode/intrinsic_return": 0.0}
{"step": 4416, "time": 497.88126826286316, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 4472, "time": 501.33902621269226, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 4616, "time": 507.8358130455017, "episode/length": 172.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 4632, "time": 510.01320791244507, "episode/length": 202.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 4912, "time": 521.4096367359161, "episode/length": 146.0, "episode/score": 0.09999999403953552, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 5416, "time": 540.1726417541504, "episode/length": 195.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 5648, "time": 549.9197344779968, "episode/length": 153.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 5792, "time": 556.548529624939, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 5800, "time": 558.2315094470978, "episode/length": 196.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 5856, "time": 562.1012284755707, "episode/length": 154.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 5984, "time": 568.2980561256409, "episode/length": 133.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 6072, "time": 572.8894503116608, "episode/length": 199.0, "episode/score": 1.0999999642372131, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 6376, "time": 584.9242804050446, "episode/length": 37.0, "episode/score": -0.9000000059604645, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 6416, "time": 588.010977268219, "episode/length": 69.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9285714285714286, "episode/intrinsic_return": 0.0}
{"step": 6912, "time": 606.860659122467, "episode/length": 284.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 6952, "time": 609.615484714508, "episode/length": 191.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 7256, "time": 621.7931475639343, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 7344, "time": 626.7765653133392, "episode/length": 211.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 7472, "time": 632.7774646282196, "episode/length": 185.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 7520, "time": 635.9931483268738, "episode/length": 137.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 7576, "time": 639.4065914154053, "episode/length": 221.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 8024, "time": 656.5876893997192, "episode/length": 205.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 8224, "time": 666.7424540519714, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 8464, "time": 677.1187160015106, "episode/length": 117.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 8528, "time": 680.9644281864166, "episode/length": 62.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 8640, "time": 686.3912403583527, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 8816, "time": 694.0171103477478, "episode/length": 232.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9828326180257511, "episode/intrinsic_return": 0.0}
{"step": 8968, "time": 700.6747674942017, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 9104, "time": 707.2269856929779, "episode/length": 230.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 9176, "time": 711.2101793289185, "episode/length": 66.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 9472, "time": 723.0817770957947, "episode/length": 249.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 9592, "time": 728.5733036994934, "episode/length": 140.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 9600, "time": 730.7516870498657, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 9904, "time": 742.8508651256561, "episode/length": 171.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 768.8076570034027, "eval_episode/length": 103.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9519230769230769}
{"step": 10088, "time": 773.038779258728, "eval_episode/length": 155.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 10088, "time": 775.0357139110565, "eval_episode/length": 162.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 10088, "time": 775.0438961982727, "eval_episode/length": 162.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 10088, "time": 778.5677030086517, "eval_episode/length": 164.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 10088, "time": 781.2994885444641, "eval_episode/length": 187.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 10088, "time": 783.138801574707, "eval_episode/length": 191.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 10088, "time": 783.1472127437592, "eval_episode/length": 191.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 10160, "time": 785.825945854187, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 10392, "time": 795.2997343540192, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 10688, "time": 807.3422181606293, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 10712, "time": 809.8323400020599, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 11040, "time": 822.898485660553, "episode/length": 179.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 11216, "time": 830.5473029613495, "episode/length": 202.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 11304, "time": 835.7076053619385, "episode/length": 265.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 11408, "time": 841.2275414466858, "episode/length": 45.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 11424, "time": 843.356748342514, "episode/length": 189.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 11512, "time": 847.832484960556, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 11848, "time": 860.9667904376984, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 11864, "time": 863.477236032486, "episode/length": 146.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 12312, "time": 881.0559957027435, "episode/length": 136.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 12368, "time": 884.9426803588867, "episode/length": 206.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 12576, "time": 893.7705669403076, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 12608, "time": 896.5515329837799, "episode/length": 149.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 12720, "time": 901.9366285800934, "episode/length": 161.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 12768, "time": 905.2185547351837, "episode/length": 112.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9469026548672567, "episode/intrinsic_return": 0.0}
{"step": 12944, "time": 913.3951857089996, "episode/length": 41.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 13240, "time": 925.1371607780457, "episode/length": 215.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 13496, "time": 935.5902407169342, "episode/length": 205.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 13544, "time": 938.9492919445038, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 13736, "time": 947.1297841072083, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 13904, "time": 955.0738370418549, "episode/length": 165.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 14088, "time": 962.982536315918, "episode/length": 142.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 14184, "time": 967.9599981307983, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 14256, "time": 972.2660617828369, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 14288, "time": 974.8866102695465, "episode/length": 130.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 14824, "time": 994.6775438785553, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 14904, "time": 999.0625803470612, "episode/length": 145.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 14960, "time": 1002.8107182979584, "episode/length": 176.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 15360, "time": 1018.2640323638916, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 15360, "time": 1018.2754113674164, "episode/length": 181.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 15448, "time": 1024.4185817241669, "episode/length": 148.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 15536, "time": 1029.325154542923, "episode/length": 155.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 15616, "time": 1033.6253244876862, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 16056, "time": 1050.2893676757812, "episode/length": 143.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 16152, "time": 1055.1358377933502, "episode/length": 165.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 16272, "time": 1061.100091934204, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 16304, "time": 1063.9045050144196, "episode/length": 106.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9532710280373832, "episode/intrinsic_return": 0.0}
{"step": 16576, "time": 1075.9564199447632, "episode/length": 151.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 16848, "time": 1086.8749992847443, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 16848, "time": 1086.888596534729, "episode/length": 153.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 16872, "time": 1090.7790250778198, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 16952, "time": 1094.9847872257233, "episode/length": 84.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 17272, "time": 1107.7246775627136, "episode/length": 151.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 17440, "time": 1115.3948969841003, "episode/length": 141.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 17552, "time": 1120.8040704727173, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 18000, "time": 1137.83256316185, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 18080, "time": 1142.1428065299988, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 18360, "time": 1153.0159542560577, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 18408, "time": 1156.512851715088, "episode/length": 181.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 18480, "time": 1160.8788616657257, "episode/length": 203.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 18640, "time": 1168.0549488067627, "episode/length": 135.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 18864, "time": 1177.2735149860382, "episode/length": 198.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 19280, "time": 1193.13409948349, "episode/length": 229.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 19424, "time": 1199.7100999355316, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 19600, "time": 1207.4613778591156, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 19616, "time": 1209.5816013813019, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 19632, "time": 1211.8483653068542, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 19792, "time": 1218.9219343662262, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 19928, "time": 1225.1032531261444, "episode/length": 40.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1247.6109883785248, "eval_episode/length": 60.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.9344262295081968}
{"step": 20072, "time": 1254.8740055561066, "eval_episode/length": 155.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 20072, "time": 1256.9969124794006, "eval_episode/length": 156.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 20072, "time": 1259.5098588466644, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 20072, "time": 1261.9604139328003, "eval_episode/length": 187.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 20072, "time": 1264.4991171360016, "eval_episode/length": 207.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 20072, "time": 1267.2364535331726, "eval_episode/length": 171.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 20072, "time": 1268.8703389167786, "eval_episode/length": 234.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9872340425531915}
{"step": 20152, "time": 1271.611094236374, "episode/length": 160.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 20248, "time": 1276.413244485855, "episode/length": 76.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 20464, "time": 1285.8584442138672, "episode/length": 227.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 20712, "time": 1295.6574034690857, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 21088, "time": 1310.323965549469, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 21112, "time": 1312.6645271778107, "episode/length": 186.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 21152, "time": 1315.845895767212, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 21264, "time": 1321.2703182697296, "episode/length": 247.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 21336, "time": 1325.0913338661194, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 21881, "time": 1346.5946357250214, "train_stats/sum_log_reward": 1.1413222793951507, "train_stats/max_log_achievement_collect_drink": 1.1735537190082646, "train_stats/max_log_achievement_collect_sapling": 8.297520661157025, "train_stats/max_log_achievement_collect_wood": 0.2231404958677686, "train_stats/max_log_achievement_place_plant": 0.5537190082644629, "train_stats/max_log_achievement_wake_up": 0.7851239669421488, "train_stats/mean_log_entropy": 0.8903005034470362, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.205772580124262, "train/action_min": 0.0, "train/action_std": 2.3856624625329896, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.017650112884296066, "train/actor_opt_grad_steps": 640.0, "train/actor_opt_loss": 199.13851147279965, "train/adv_mag": 1.7636297711915534, "train/adv_max": 1.7617194021696327, "train/adv_mean": 0.04308384744801987, "train/adv_min": -0.33743674934687695, "train/adv_std": 0.1539299504498687, "train/cont_avg": 0.9944174458661418, "train/cont_loss_mean": 0.031105686140459353, "train/cont_loss_std": 0.2682364736720333, "train/cont_neg_acc": 0.05048744005011761, "train/cont_neg_loss": 3.478510549922628, "train/cont_pos_acc": 0.9942439949418617, "train/cont_pos_loss": 0.012033298084563685, "train/cont_pred": 0.9904041337215994, "train/cont_rate": 0.9944174458661418, "train/dyn_loss_mean": 5.324755248122328, "train/dyn_loss_std": 7.756337276476574, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.675447361206445, "train/extr_critic_critic_opt_grad_steps": 640.0, "train/extr_critic_critic_opt_loss": 23366.343619279036, "train/extr_critic_mag": 0.2786656496093029, "train/extr_critic_max": 0.27866564773199126, "train/extr_critic_mean": 0.13288401388241622, "train/extr_critic_min": 0.004060561262716459, "train/extr_critic_std": 0.07642945001901733, "train/extr_return_normed_mag": 1.9979752262625257, "train/extr_return_normed_max": 1.9977302254181297, "train/extr_return_normed_mean": 0.1907369104034348, "train/extr_return_normed_min": -0.2347485234734729, "train/extr_return_normed_std": 0.1914001754815067, "train/extr_return_rate": 0.0979592202795146, "train/extr_return_raw_mag": 2.1995455224129303, "train/extr_return_raw_max": 2.1995455224129303, "train/extr_return_raw_mean": 0.1821113010432102, "train/extr_return_raw_min": -0.3072999736668146, "train/extr_return_raw_std": 0.22146183727895769, "train/extr_reward_mag": 0.5925374875857136, "train/extr_reward_max": 0.5925374875857136, "train/extr_reward_mean": 0.009286181793180817, "train/extr_reward_min": -0.07931669396678294, "train/extr_reward_std": 0.04128007923195242, "train/image_loss_mean": 99.13900010416828, "train/image_loss_std": 49.06103526137945, "train/model_loss_mean": 102.68558731980211, "train/model_loss_std": 50.54398324921375, "train/model_opt_grad_norm": 422.913499546802, "train/model_opt_grad_steps": 631.0, "train/model_opt_loss": 2125.8223852923534, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 23.683562992125985, "train/policy_entropy_mag": 1.4228421970615237, "train/policy_entropy_max": 1.4228421970615237, "train/policy_entropy_mean": 0.8623539327871143, "train/policy_entropy_min": 0.6478194674168984, "train/policy_entropy_std": 0.13467957196375868, "train/policy_logprob_mag": 6.786237697901688, "train/policy_logprob_max": -0.2984686893755643, "train/policy_logprob_mean": -0.8608485863903376, "train/policy_logprob_min": -6.786237697901688, "train/policy_logprob_std": 0.8376465066680758, "train/policy_randomness_mag": 0.5022008568928467, "train/policy_randomness_max": 0.5022008568928467, "train/policy_randomness_mean": 0.30437309624935227, "train/policy_randomness_min": 0.2286518432023957, "train/policy_randomness_std": 0.047535978627068494, "train/post_ent_mag": 54.82221002653828, "train/post_ent_max": 54.82221002653828, "train/post_ent_mean": 33.03157259723333, "train/post_ent_min": 14.954942049942618, "train/post_ent_std": 7.736682081668396, "train/prior_ent_mag": 59.295361676554045, "train/prior_ent_max": 59.295361676554045, "train/prior_ent_mean": 39.049025047482466, "train/prior_ent_min": 18.683991484754667, "train/prior_ent_std": 7.238167428712207, "train/rep_loss_mean": 5.324755248122328, "train/rep_loss_std": 7.756337276476574, "train/reward_avg": 0.0074026513034404495, "train/reward_loss_mean": 0.3206279308894488, "train/reward_loss_std": 0.6626561469743102, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.7086978418620553, "train/reward_neg_acc": 0.9970096499901119, "train/reward_neg_loss": 0.28662505745887756, "train/reward_pos_acc": 0.4752294421195984, "train/reward_pos_loss": 3.071986794941069, "train/reward_pred": 0.005423338820710485, "train/reward_rate": 0.012318528543307087, "train_stats/max_log_achievement_place_table": 0.017094017094017096, "train_stats/max_log_achievement_eat_cow": 0.1797752808988764, "train_stats/max_log_achievement_make_wood_pickaxe": 0.012987012987012988, "train_stats/max_log_achievement_defeat_zombie": 0.2, "eval_stats/sum_log_reward": 1.412499949336052, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 7.8125, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 1.0625, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.014265013858675957, "report/cont_loss_std": 0.17313286662101746, "report/cont_neg_acc": 0.20000000298023224, "report/cont_neg_loss": 2.1582343578338623, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0037450457457453012, "report/cont_pred": 0.9952349066734314, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 5.488258361816406, "report/dyn_loss_std": 5.215977668762207, "report/image_loss_mean": 19.179866790771484, "report/image_loss_std": 14.61298656463623, "report/model_loss_mean": 22.62833023071289, "report/model_loss_std": 16.199602127075195, "report/post_ent_mag": 41.399261474609375, "report/post_ent_max": 41.399261474609375, "report/post_ent_mean": 29.732444763183594, "report/post_ent_min": 10.292524337768555, "report/post_ent_std": 4.699429988861084, "report/prior_ent_mag": 49.961326599121094, "report/prior_ent_max": 49.961326599121094, "report/prior_ent_mean": 35.86252975463867, "report/prior_ent_min": 16.128267288208008, "report/prior_ent_std": 4.890446662902832, "report/rep_loss_mean": 5.488258361816406, "report/rep_loss_std": 5.215977668762207, "report/reward_avg": 0.0054687499068677425, "report/reward_loss_mean": 0.14124521613121033, "report/reward_loss_std": 0.4635363221168518, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9932149648666382, "report/reward_neg_acc": 0.9990128874778748, "report/reward_neg_loss": 0.12506303191184998, "report/reward_pos_acc": 0.7272727489471436, "report/reward_pos_loss": 1.6314772367477417, "report/reward_pred": 0.004240366630256176, "report/reward_rate": 0.0107421875, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.023021429777145386, "eval/cont_loss_std": 0.40336793661117554, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 7.439473628997803, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0012296990025788546, "eval/cont_pred": 0.998918890953064, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 9.062559127807617, "eval/dyn_loss_std": 9.184691429138184, "eval/image_loss_mean": 44.924659729003906, "eval/image_loss_std": 36.745697021484375, "eval/model_loss_mean": 50.58815002441406, "eval/model_loss_std": 39.28103256225586, "eval/post_ent_mag": 47.69384002685547, "eval/post_ent_max": 47.69384002685547, "eval/post_ent_mean": 28.851285934448242, "eval/post_ent_min": 11.144546508789062, "eval/post_ent_std": 6.220135688781738, "eval/prior_ent_mag": 54.46905517578125, "eval/prior_ent_max": 54.46905517578125, "eval/prior_ent_mean": 35.50176239013672, "eval/prior_ent_min": 15.572103500366211, "eval/prior_ent_std": 7.829495906829834, "eval/rep_loss_mean": 9.062559127807617, "eval/rep_loss_std": 9.184691429138184, "eval/reward_avg": 0.008691406808793545, "eval/reward_loss_mean": 0.2029331624507904, "eval/reward_loss_std": 0.8123238682746887, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9927085638046265, "eval/reward_neg_acc": 0.9930830597877502, "eval/reward_neg_loss": 0.18494294583797455, "eval/reward_pos_acc": 0.8333333730697632, "eval/reward_pos_loss": 1.7201087474822998, "eval/reward_pred": 0.008839244022965431, "eval/reward_rate": 0.01171875, "replay/size": 21377.0, "replay/inserts": 20320.0, "replay/samples": 20320.0, "replay/insert_wait_avg": 1.579124157822977e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0426823548444613e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6704.0, "eval_replay/inserts": 3416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.4940246206815125e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1473894119262695e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 973.4108145236969, "timer/env.step_count": 2540.0, "timer/env.step_total": 271.2904419898987, "timer/env.step_frac": 0.27870087114518527, "timer/env.step_avg": 0.10680726062594437, "timer/env.step_min": 0.023970842361450195, "timer/env.step_max": 3.608964204788208, "timer/replay._sample_count": 20320.0, "timer/replay._sample_total": 11.784374952316284, "timer/replay._sample_frac": 0.01210627083291913, "timer/replay._sample_avg": 0.0005799397122202896, "timer/replay._sample_min": 0.000370025634765625, "timer/replay._sample_max": 0.02580881118774414, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 2967.0, "timer/agent.policy_total": 54.409074783325195, "timer/agent.policy_frac": 0.055895284880257155, "timer/agent.policy_avg": 0.01833807710931082, "timer/agent.policy_min": 0.010237693786621094, "timer/agent.policy_max": 0.11958622932434082, "timer/dataset_train_count": 1270.0, "timer/dataset_train_total": 0.15980267524719238, "timer/dataset_train_frac": 0.00016416776232898748, "timer/dataset_train_avg": 0.00012582887814739557, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.0006561279296875, "timer/agent.train_count": 1270.0, "timer/agent.train_total": 579.3865866661072, "timer/agent.train_frac": 0.5952128104818816, "timer/agent.train_avg": 0.4562099107607143, "timer/agent.train_min": 0.4399759769439697, "timer/agent.train_max": 1.3167731761932373, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4744722843170166, "timer/agent.report_frac": 0.0004874327234069023, "timer/agent.report_avg": 0.2372361421585083, "timer/agent.report_min": 0.2293262481689453, "timer/agent.report_max": 0.2451460361480713, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.502514693984166e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 20.874805561924227}
{"step": 21928, "time": 1348.1300785541534, "episode/length": 82.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 22096, "time": 1355.620733499527, "episode/length": 122.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.959349593495935, "episode/intrinsic_return": 0.0}
{"step": 22176, "time": 1359.9633302688599, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 22328, "time": 1366.7005424499512, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 22344, "time": 1368.9490699768066, "episode/length": 234.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 22472, "time": 1375.0340015888214, "episode/length": 164.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 22776, "time": 1387.090453863144, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 23208, "time": 1403.6106741428375, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 23328, "time": 1409.6034662723541, "episode/length": 384.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766233766233766, "episode/intrinsic_return": 0.0}
{"step": 23392, "time": 1413.3513221740723, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 23544, "time": 1419.9495487213135, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 23688, "time": 1426.4731290340424, "episode/length": 167.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 23792, "time": 1432.0334386825562, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 24000, "time": 1440.724288225174, "episode/length": 227.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 24368, "time": 1455.0065069198608, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 24504, "time": 1461.1979629993439, "episode/length": 138.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 24632, "time": 1468.3772857189178, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 24672, "time": 1471.5718140602112, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 24872, "time": 1479.7297673225403, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 24880, "time": 1481.9041647911072, "episode/length": 135.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 24992, "time": 1487.2527148723602, "episode/length": 276.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9891696750902527, "episode/intrinsic_return": 0.0}
{"step": 24992, "time": 1487.2603197097778, "episode/length": 162.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 25416, "time": 1505.066748380661, "episode/length": 176.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 26072, "time": 1529.3032467365265, "episode/length": 148.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 26176, "time": 1534.5845680236816, "episode/length": 208.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 26200, "time": 1536.9189138412476, "episode/length": 190.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 26248, "time": 1540.1419129371643, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 26416, "time": 1547.7358338832855, "episode/length": 222.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 26848, "time": 1564.1473519802094, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 26888, "time": 1566.8145279884338, "episode/length": 251.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 27144, "time": 1577.1946456432343, "episode/length": 117.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 27216, "time": 1581.5439615249634, "episode/length": 120.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 27216, "time": 1581.5547137260437, "episode/length": 277.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9892086330935251, "episode/intrinsic_return": 0.0}
{"step": 27432, "time": 1592.310733795166, "episode/length": 156.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 27544, "time": 1597.8092935085297, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 27600, "time": 1601.417289018631, "episode/length": 88.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 27680, "time": 1605.8449115753174, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 28288, "time": 1628.3700685501099, "episode/length": 133.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 28336, "time": 1631.6814436912537, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 28440, "time": 1636.5061464309692, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 28896, "time": 1654.0306129455566, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 28960, "time": 1657.8837826251984, "episode/length": 217.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 29000, "time": 1660.607762336731, "episode/length": 174.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 29056, "time": 1664.3356325626373, "episode/length": 95.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 29424, "time": 1678.6197607517242, "episode/length": 217.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 29544, "time": 1684.1180715560913, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 29680, "time": 1690.5955193042755, "episode/length": 167.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1721.8030877113342, "eval_episode/length": 72.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9315068493150684}
{"step": 30056, "time": 1723.6148002147675, "eval_episode/length": 76.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.935064935064935}
{"step": 30056, "time": 1726.0855753421783, "eval_episode/length": 94.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 30056, "time": 1728.2839901447296, "eval_episode/length": 97.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9489795918367347}
{"step": 30056, "time": 1734.2041318416595, "eval_episode/length": 151.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.993421052631579}
{"step": 30056, "time": 1735.9358019828796, "eval_episode/length": 154.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 30056, "time": 1738.5888814926147, "eval_episode/length": 177.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 30056, "time": 1742.0613553524017, "eval_episode/length": 219.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 30120, "time": 1744.2480568885803, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 30168, "time": 1747.6853733062744, "episode/length": 150.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 30224, "time": 1751.425649881363, "episode/length": 145.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 30304, "time": 1755.7286398410797, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 30312, "time": 1757.3334035873413, "episode/length": 95.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9479166666666666, "episode/intrinsic_return": 0.0}
{"step": 30408, "time": 1762.389511346817, "episode/length": 357.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9748603351955307, "episode/intrinsic_return": 0.0}
{"step": 30672, "time": 1773.0897886753082, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 31176, "time": 1791.6032633781433, "episode/length": 107.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 31248, "time": 1795.8959336280823, "episode/length": 117.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9915254237288136, "episode/intrinsic_return": 0.0}
{"step": 31360, "time": 1801.4502229690552, "episode/length": 209.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 31560, "time": 1809.6003115177155, "episode/length": 179.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 31696, "time": 1816.15478348732, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 31712, "time": 1818.429927110672, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 32064, "time": 1832.075467824936, "episode/length": 62.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 32264, "time": 1840.24764919281, "episode/length": 198.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 32376, "time": 1845.7000501155853, "episode/length": 275.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 32472, "time": 1850.6184933185577, "episode/length": 96.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 32520, "time": 1854.1085398197174, "episode/length": 167.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 32576, "time": 1857.7916090488434, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 32704, "time": 1863.686250925064, "episode/length": 79.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 33152, "time": 1882.071398973465, "episode/length": 96.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 33232, "time": 1886.5356192588806, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 33496, "time": 1896.7888405323029, "episode/length": 266.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 34056, "time": 1917.5792343616486, "episode/length": 223.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 34176, "time": 1923.5020680427551, "episode/length": 206.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 34304, "time": 1929.5005300045013, "episode/length": 30.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 34312, "time": 1931.072847366333, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 34336, "time": 1933.7943522930145, "episode/length": 232.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9656652360515021, "episode/intrinsic_return": 0.0}
{"step": 34576, "time": 1943.844967365265, "episode/length": 167.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 34584, "time": 1945.4320290088654, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 34648, "time": 1949.2689023017883, "episode/length": 258.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 34768, "time": 1955.1506705284119, "episode/length": 53.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 35360, "time": 1976.9738547801971, "episode/length": 232.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 35400, "time": 1979.7551605701447, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.954248366013072, "episode/intrinsic_return": 0.0}
{"step": 35552, "time": 1986.8587419986725, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9551282051282052, "episode/intrinsic_return": 0.0}
{"step": 35880, "time": 1999.3999536037445, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 36072, "time": 2007.748705625534, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 36120, "time": 2011.7273037433624, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 36120, "time": 2011.7361538410187, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 36776, "time": 2038.6887829303741, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 36800, "time": 2041.349424123764, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 37008, "time": 2050.112889289856, "episode/length": 110.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 37240, "time": 2059.4980766773224, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 37272, "time": 2062.514205932617, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 37448, "time": 2070.1089057922363, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 37504, "time": 2073.7947297096252, "episode/length": 356.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 37984, "time": 2092.041926383972, "episode/length": 66.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9253731343283582, "episode/intrinsic_return": 0.0}
{"step": 38048, "time": 2095.8455464839935, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 38080, "time": 2098.4592797756195, "episode/length": 133.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 38216, "time": 2104.379012823105, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9508196721311475, "episode/intrinsic_return": 0.0}
{"step": 38712, "time": 2123.516995191574, "episode/length": 241.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 38728, "time": 2125.7582495212555, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 38760, "time": 2128.5014922618866, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 38936, "time": 2136.065814971924, "episode/length": 446.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 39416, "time": 2154.3030931949615, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 39464, "time": 2157.4849004745483, "episode/length": 172.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 39752, "time": 2168.8869001865387, "episode/length": 212.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2197.076371908188, "eval_episode/length": 70.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9295774647887324}
{"step": 40040, "time": 2202.298886537552, "eval_episode/length": 150.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9735099337748344}
{"step": 40040, "time": 2204.9323585033417, "eval_episode/length": 168.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 40040, "time": 2206.6780955791473, "eval_episode/length": 172.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.976878612716763}
{"step": 40040, "time": 2208.3296048641205, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 40040, "time": 2210.8512892723083, "eval_episode/length": 191.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 40040, "time": 2214.371458053589, "eval_episode/length": 231.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9956896551724138}
{"step": 40040, "time": 2216.1049621105194, "eval_episode/length": 162.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9754601226993865}
{"step": 40216, "time": 2222.0688219070435, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 40248, "time": 2224.7413103580475, "episode/length": 191.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 40376, "time": 2230.6841790676117, "episode/length": 269.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 40480, "time": 2236.0985131263733, "episode/length": 132.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 40544, "time": 2239.8732936382294, "episode/length": 222.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 40624, "time": 2244.379683494568, "episode/length": 236.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 41152, "time": 2265.36504983902, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 41440, "time": 2276.9798998832703, "episode/length": 246.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 41456, "time": 2279.158279657364, "episode/length": 134.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 41488, "time": 2281.8574426174164, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 41912, "time": 2297.824932575226, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 41912, "time": 2297.843249320984, "episode/length": 170.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 42512, "time": 2322.2438111305237, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 42808, "time": 2333.9664883613586, "episode/length": 290.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 42888, "time": 2338.9509303569794, "episode/length": 178.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 42952, "time": 2342.728568792343, "episode/length": 182.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 43001, "time": 2347.0137231349945, "train_stats/sum_log_reward": 2.5166665916641553, "train_stats/max_log_achievement_collect_drink": 11.741666666666667, "train_stats/max_log_achievement_collect_sapling": 2.4, "train_stats/max_log_achievement_collect_wood": 0.275, "train_stats/max_log_achievement_defeat_zombie": 0.11666666666666667, "train_stats/max_log_achievement_eat_cow": 0.125, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_place_plant": 2.1166666666666667, "train_stats/max_log_achievement_place_table": 0.016666666666666666, "train_stats/max_log_achievement_wake_up": 1.6083333333333334, "train_stats/mean_log_entropy": 0.33475629662474, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.758130622632576, "train/action_min": 0.0, "train/action_std": 2.549918936960625, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03375326521751104, "train/actor_opt_grad_steps": 1935.0, "train/actor_opt_loss": 14.539787203299277, "train/adv_mag": 1.446187962636803, "train/adv_max": 1.4399055156743887, "train/adv_mean": 0.011046382792163498, "train/adv_min": -0.6102472403735826, "train/adv_std": 0.12470652315426957, "train/cont_avg": 0.9940666429924242, "train/cont_loss_mean": 0.0073302600542595455, "train/cont_loss_std": 0.09811214907329652, "train/cont_neg_acc": 0.649849421203588, "train/cont_neg_loss": 0.8471609710466124, "train/cont_pos_acc": 0.9996573694727637, "train/cont_pos_loss": 0.002246559658990946, "train/cont_pred": 0.9943076268290029, "train/cont_rate": 0.9940666429924242, "train/dyn_loss_mean": 6.539739041617422, "train/dyn_loss_std": 5.810766144232317, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.6600387742122014, "train/extr_critic_critic_opt_grad_steps": 1935.0, "train/extr_critic_critic_opt_loss": 17907.248572147255, "train/extr_critic_mag": 1.5524078679807258, "train/extr_critic_max": 1.5524078679807258, "train/extr_critic_mean": 0.44993594339625403, "train/extr_critic_min": -0.36282199350270355, "train/extr_critic_std": 0.6260832211736477, "train/extr_return_normed_mag": 2.204085676055966, "train/extr_return_normed_max": 2.204085676055966, "train/extr_return_normed_mean": 0.4188479139949336, "train/extr_return_normed_min": -0.3254013340637991, "train/extr_return_normed_std": 0.35219195541558845, "train/extr_return_rate": 0.422646900356719, "train/extr_return_raw_mag": 4.111180345217387, "train/extr_return_raw_max": 4.111180345217387, "train/extr_return_raw_mean": 0.4724051622730313, "train/extr_return_raw_min": -1.0455817225756068, "train/extr_return_raw_std": 0.7185858835776647, "train/extr_reward_mag": 0.9964691743706212, "train/extr_reward_max": 0.9964691743706212, "train/extr_reward_mean": 0.011433124401237088, "train/extr_reward_min": -0.3581449841008042, "train/extr_reward_std": 0.09017943173195377, "train/image_loss_mean": 20.25363488630815, "train/image_loss_std": 20.124909736893393, "train/model_loss_mean": 24.278135458628338, "train/model_loss_std": 21.956270897027217, "train/model_opt_grad_norm": 155.40366591829243, "train/model_opt_grad_steps": 1926.0, "train/model_opt_loss": 1403.7405996611624, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 56.22632575757576, "train/policy_entropy_mag": 1.90293915253697, "train/policy_entropy_max": 1.90293915253697, "train/policy_entropy_mean": 0.3688393182149439, "train/policy_entropy_min": 0.07964145973550552, "train/policy_entropy_std": 0.32684222732981044, "train/policy_logprob_mag": 7.437733502099008, "train/policy_logprob_max": -0.009492731004050283, "train/policy_logprob_mean": -0.3689996973808968, "train/policy_logprob_min": -7.437733502099008, "train/policy_logprob_std": 0.9758890356981393, "train/policy_randomness_mag": 0.6716540123928677, "train/policy_randomness_max": 0.6716540123928677, "train/policy_randomness_mean": 0.13018409326446778, "train/policy_randomness_min": 0.02810994036157023, "train/policy_randomness_std": 0.11536096217054309, "train/post_ent_mag": 42.9126670143821, "train/post_ent_max": 42.9126670143821, "train/post_ent_mean": 29.80654170296409, "train/post_ent_min": 11.708102616396816, "train/post_ent_std": 4.649197195515488, "train/prior_ent_mag": 52.68188424543901, "train/prior_ent_max": 52.68188424543901, "train/prior_ent_mean": 36.463664921847254, "train/prior_ent_min": 15.719563339695785, "train/prior_ent_std": 5.548362188266985, "train/rep_loss_mean": 6.539739041617422, "train/rep_loss_std": 5.810766144232317, "train/reward_avg": 0.008894856680082299, "train/reward_loss_mean": 0.09332697051153942, "train/reward_loss_std": 0.41778053456183634, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.9955133416435935, "train/reward_neg_acc": 0.9960612627592954, "train/reward_neg_loss": 0.07392085838893597, "train/reward_pos_acc": 0.8455006597620068, "train/reward_pos_loss": 1.4642794750856631, "train/reward_pred": 0.00793520586254696, "train/reward_rate": 0.014285925662878788, "eval_stats/sum_log_reward": 2.7249999195337296, "eval_stats/max_log_achievement_collect_drink": 13.4375, "eval_stats/max_log_achievement_collect_sapling": 2.9375, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 2.6875, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00028383074095472693, "report/cont_loss_std": 0.0050978087820112705, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.015903661027550697, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00020718776795547456, "report/cont_pred": 0.9949983358383179, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 7.000866413116455, "report/dyn_loss_std": 6.360141277313232, "report/image_loss_mean": 21.85929298400879, "report/image_loss_std": 21.8610782623291, "report/model_loss_mean": 26.112056732177734, "report/model_loss_std": 24.1556453704834, "report/post_ent_mag": 44.97914505004883, "report/post_ent_max": 44.97914505004883, "report/post_ent_mean": 30.27386474609375, "report/post_ent_min": 10.033404350280762, "report/post_ent_std": 5.571090221405029, "report/prior_ent_mag": 52.771888732910156, "report/prior_ent_max": 52.771888732910156, "report/prior_ent_mean": 37.526588439941406, "report/prior_ent_min": 15.076312065124512, "report/prior_ent_std": 6.965236663818359, "report/rep_loss_mean": 7.000866413116455, "report/rep_loss_std": 6.360141277313232, "report/reward_avg": 0.01308593712747097, "report/reward_loss_mean": 0.05196056514978409, "report/reward_loss_std": 0.27524542808532715, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9986987113952637, "report/reward_neg_acc": 0.9970208406448364, "report/reward_neg_loss": 0.032605741173028946, "report/reward_pos_acc": 0.8235294222831726, "report/reward_pos_loss": 1.1984496116638184, "report/reward_pred": 0.010727431625127792, "report/reward_rate": 0.0166015625, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.001458532060496509, "eval/cont_loss_std": 0.04494602978229523, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001194489814224653, "eval/cont_pos_acc": 0.9990215301513672, "eval/cont_pos_loss": 0.0014611525693908334, "eval/cont_pred": 0.9972493648529053, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 10.308904647827148, "eval/dyn_loss_std": 7.827056407928467, "eval/image_loss_mean": 34.80091094970703, "eval/image_loss_std": 31.116762161254883, "eval/model_loss_mean": 41.18488311767578, "eval/model_loss_std": 33.521976470947266, "eval/post_ent_mag": 44.629600524902344, "eval/post_ent_max": 44.629600524902344, "eval/post_ent_mean": 27.76165771484375, "eval/post_ent_min": 11.842144012451172, "eval/post_ent_std": 5.741873264312744, "eval/prior_ent_mag": 55.181739807128906, "eval/prior_ent_max": 55.181739807128906, "eval/prior_ent_mean": 36.22462463378906, "eval/prior_ent_min": 14.645623207092285, "eval/prior_ent_std": 7.660411357879639, "eval/rep_loss_mean": 10.308904647827148, "eval/rep_loss_std": 7.827056407928467, "eval/reward_avg": 0.008496093563735485, "eval/reward_loss_mean": 0.19717451930046082, "eval/reward_loss_std": 0.9246981739997864, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999549388885498, "eval/reward_neg_acc": 0.9990118741989136, "eval/reward_neg_loss": 0.14813335239887238, "eval/reward_pos_acc": 0.5833333730697632, "eval/reward_pos_loss": 4.332982063293457, "eval/reward_pred": -0.0007112361490726471, "eval/reward_rate": 0.01171875, "replay/size": 42497.0, "replay/inserts": 21120.0, "replay/samples": 21120.0, "replay/insert_wait_avg": 1.537133798454747e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.076179923433246e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 10336.0, "eval_replay/inserts": 3632.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3660491825725539e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4045732021332, "timer/env.step_count": 2640.0, "timer/env.step_total": 271.0877344608307, "timer/env.step_frac": 0.2709781039815949, "timer/env.step_avg": 0.10268474790182981, "timer/env.step_min": 0.023901939392089844, "timer/env.step_max": 4.384281158447266, "timer/replay._sample_count": 21120.0, "timer/replay._sample_total": 12.315009593963623, "timer/replay._sample_frac": 0.012310029285997033, "timer/replay._sample_avg": 0.0005830970451687321, "timer/replay._sample_min": 0.0004162788391113281, "timer/replay._sample_max": 0.011445045471191406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3094.0, "timer/agent.policy_total": 57.34574294090271, "timer/agent.policy_frac": 0.05732255177257763, "timer/agent.policy_avg": 0.01853449998089939, "timer/agent.policy_min": 0.010121583938598633, "timer/agent.policy_max": 0.12413191795349121, "timer/dataset_train_count": 1320.0, "timer/dataset_train_total": 0.2004706859588623, "timer/dataset_train_frac": 0.00020038961369117704, "timer/dataset_train_avg": 0.0001518717317870169, "timer/dataset_train_min": 0.00010609626770019531, "timer/dataset_train_max": 0.035919189453125, "timer/agent.train_count": 1320.0, "timer/agent.train_total": 601.803590297699, "timer/agent.train_frac": 0.6015602151551778, "timer/agent.train_avg": 0.45591181083159016, "timer/agent.train_min": 0.44181156158447266, "timer/agent.train_max": 1.427253246307373, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47565174102783203, "timer/agent.report_frac": 0.00047545938290280675, "timer/agent.report_avg": 0.23782587051391602, "timer/agent.report_min": 0.23085451126098633, "timer/agent.report_max": 0.2447972297668457, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.552436828613281e-05, "timer/dataset_eval_frac": 3.551000189096003e-08, "timer/dataset_eval_avg": 3.552436828613281e-05, "timer/dataset_eval_min": 3.552436828613281e-05, "timer/dataset_eval_max": 3.552436828613281e-05, "fps": 21.111185173793498}
{"step": 43320, "time": 2357.810258626938, "episode/length": 234.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 43432, "time": 2363.2886707782745, "episode/length": 114.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 43616, "time": 2371.5018923282623, "episode/length": 100.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 43656, "time": 2374.1931717395782, "episode/length": 217.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 43712, "time": 2378.1502616405487, "episode/length": 432.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9792147806004619, "episode/intrinsic_return": 0.0}
{"step": 43912, "time": 2386.333023548126, "episode/length": 249.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 44224, "time": 2399.0034720897675, "episode/length": 166.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 44488, "time": 2409.3911595344543, "episode/length": 191.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 44528, "time": 2412.6224851608276, "episode/length": 108.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 44640, "time": 2418.074234008789, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 45072, "time": 2434.960935115814, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 45096, "time": 2437.2026419639587, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 45216, "time": 2443.1455492973328, "episode/length": 162.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9877300613496932, "episode/intrinsic_return": 0.0}
{"step": 45336, "time": 2448.660054922104, "episode/length": 237.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 45560, "time": 2458.0302929878235, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 45712, "time": 2465.0407054424286, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 46136, "time": 2480.948457956314, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 46280, "time": 2487.583086013794, "episode/length": 223.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 46512, "time": 2497.430989265442, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 46584, "time": 2501.380784511566, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 46944, "time": 2515.5997047424316, "episode/length": 153.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 46976, "time": 2518.3664281368256, "episode/length": 104.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 47048, "time": 2522.222925186157, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 47096, "time": 2525.4770636558533, "episode/length": 234.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 47216, "time": 2531.413199186325, "episode/length": 206.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 47544, "time": 2544.1772887706757, "episode/length": 119.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 47704, "time": 2551.27898144722, "episode/length": 177.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 48224, "time": 2570.6313614845276, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 48352, "time": 2576.7776839733124, "episode/length": 141.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 48384, "time": 2579.5270540714264, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 48440, "time": 2583.3215198516846, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 48520, "time": 2587.780794620514, "episode/length": 177.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 48720, "time": 2596.4612691402435, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 49456, "time": 2624.791877746582, "episode/length": 238.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 49464, "time": 2626.5554296970367, "episode/length": 219.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 49640, "time": 2634.34663438797, "episode/length": 156.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 49936, "time": 2646.311436891556, "episode/length": 213.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.985981308411215, "episode/intrinsic_return": 0.0}
{"step": 50016, "time": 2650.7569003105164, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2671.4668283462524, "eval_episode/length": 76.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.935064935064935}
{"step": 50024, "time": 2675.813375711441, "eval_episode/length": 138.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 50024, "time": 2678.054130077362, "eval_episode/length": 153.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 50024, "time": 2680.251034259796, "eval_episode/length": 163.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 50024, "time": 2681.9217863082886, "eval_episode/length": 164.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 50024, "time": 2681.9303102493286, "eval_episode/length": 164.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 50024, "time": 2687.720838546753, "eval_episode/length": 65.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9242424242424242}
{"step": 50024, "time": 2689.5708034038544, "eval_episode/length": 226.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9779735682819384}
{"step": 50032, "time": 2690.092797279358, "episode/length": 188.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 50072, "time": 2693.029445409775, "episode/length": 203.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 50512, "time": 2709.81143951416, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 50720, "time": 2718.466723203659, "episode/length": 249.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 50792, "time": 2722.4530680179596, "episode/length": 166.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 51008, "time": 2731.6810965538025, "episode/length": 170.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 51120, "time": 2737.190051794052, "episode/length": 135.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 51352, "time": 2746.459200143814, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 51672, "time": 2759.0875074863434, "episode/length": 109.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 51776, "time": 2764.4992480278015, "episode/length": 212.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 51808, "time": 2767.315668106079, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 51976, "time": 2774.4355924129486, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 52016, "time": 2777.6508519649506, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 52048, "time": 2780.197515964508, "episode/length": 86.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 52400, "time": 2794.2700605392456, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 52504, "time": 2799.1661417484283, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 52944, "time": 2815.8353374004364, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 53000, "time": 2819.1519396305084, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 53336, "time": 2832.2162878513336, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 53392, "time": 2835.9559528827667, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 53480, "time": 2840.4393446445465, "episode/length": 182.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 53664, "time": 2848.776859998703, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 53864, "time": 2857.0341811180115, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 54136, "time": 2867.910138607025, "episode/length": 216.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 54328, "time": 2876.1554169654846, "episode/length": 165.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 54400, "time": 2880.412987470627, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 54608, "time": 2889.0402278900146, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 54680, "time": 2892.9881908893585, "episode/length": 149.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 54848, "time": 2900.4458816051483, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 54888, "time": 2903.332019329071, "episode/length": 127.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.953125, "episode/intrinsic_return": 0.0}
{"step": 55296, "time": 2919.3661761283875, "episode/length": 203.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 55728, "time": 2935.920378446579, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 55792, "time": 2939.717702627182, "episode/length": 147.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 55800, "time": 2941.3324983119965, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 55944, "time": 2948.4448943138123, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 56104, "time": 2955.9109582901, "episode/length": 177.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 56112, "time": 2958.0445256233215, "episode/length": 152.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 56144, "time": 2960.930225133896, "episode/length": 161.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 56160, "time": 2963.252209186554, "episode/length": 45.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 56392, "time": 2972.621530532837, "episode/length": 30.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 56680, "time": 2984.0109603405, "episode/length": 35.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 57176, "time": 3002.6885113716125, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 57208, "time": 3005.5070984363556, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 57248, "time": 3008.7048575878143, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 57456, "time": 3018.8916988372803, "episode/length": 269.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 57520, "time": 3022.9138038158417, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 57608, "time": 3027.2753415107727, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 57928, "time": 3039.82475233078, "episode/length": 227.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 58080, "time": 3046.7226881980896, "episode/length": 174.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 58408, "time": 3059.4757080078125, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 58608, "time": 3068.2428205013275, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 58648, "time": 3070.9843242168427, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 58680, "time": 3073.684006690979, "episode/length": 33.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8823529411764706, "episode/intrinsic_return": 0.0}
{"step": 58800, "time": 3079.5757653713226, "episode/length": 193.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 59008, "time": 3088.443233013153, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 59080, "time": 3092.4693269729614, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 59248, "time": 3100.04079914093, "episode/length": 215.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 59416, "time": 3107.1331984996796, "episode/length": 185.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 59976, "time": 3128.095558643341, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9590643274853801, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3145.8235495090485, "eval_episode/length": 37.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 60008, "time": 3152.9443097114563, "eval_episode/length": 159.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9625}
{"step": 60008, "time": 3154.7289855480194, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 60008, "time": 3156.374931573868, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 60008, "time": 3159.1929726600647, "eval_episode/length": 32.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8787878787878788}
{"step": 60008, "time": 3161.0468125343323, "eval_episode/length": 197.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 60008, "time": 3163.802441596985, "eval_episode/length": 221.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 60008, "time": 3165.6247606277466, "eval_episode/length": 225.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9734513274336283}
{"step": 60016, "time": 3166.136557817459, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 60176, "time": 3173.4316668510437, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 60200, "time": 3175.5883543491364, "episode/length": 97.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 60208, "time": 3177.6283841133118, "episode/length": 175.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 60336, "time": 3183.5823333263397, "episode/length": 165.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 60432, "time": 3188.473414182663, "episode/length": 168.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 60648, "time": 3197.1338226795197, "episode/length": 174.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 61208, "time": 3218.1446034908295, "episode/length": 124.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 61272, "time": 3221.959673166275, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 61336, "time": 3225.767293214798, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 61584, "time": 3236.206752538681, "episode/length": 175.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 61800, "time": 3244.87637424469, "episode/length": 199.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 62248, "time": 3261.951342821121, "episode/length": 238.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 62648, "time": 3277.319891691208, "episode/length": 49.0, "episode/score": 0.10000002384185791, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 62808, "time": 3284.385232448578, "episode/length": 152.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 62824, "time": 3286.5309364795685, "episode/length": 271.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 62944, "time": 3292.5839881896973, "episode/length": 208.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 62984, "time": 3295.5286524295807, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 63016, "time": 3298.251802444458, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 63104, "time": 3303.0670516490936, "episode/length": 220.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 63800, "time": 3328.442003965378, "episode/length": 420.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 63976, "time": 3336.04829955101, "episode/length": 145.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.952054794520548, "episode/intrinsic_return": 0.0}
{"step": 64112, "time": 3342.5583357810974, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9875776397515528, "episode/intrinsic_return": 0.0}
{"step": 64185, "time": 3347.3720955848694, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.122432361949574, "train/action_min": 0.0, "train/action_std": 3.8983626148917456, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04185232329605655, "train/actor_opt_grad_steps": 3255.0, "train/actor_opt_loss": 23.86274881435163, "train/adv_mag": 1.357279256437764, "train/adv_max": 1.352046752969424, "train/adv_mean": 0.009282358351673323, "train/adv_min": -0.5602931077733184, "train/adv_std": 0.10643319096980673, "train/cont_avg": 0.9941850142045454, "train/cont_loss_mean": 0.0008315635634340534, "train/cont_loss_std": 0.02241133437067247, "train/cont_neg_acc": 0.9746993789167115, "train/cont_neg_loss": 0.08613299451632304, "train/cont_pos_acc": 0.9999106684417436, "train/cont_pos_loss": 0.0003121798642057473, "train/cont_pred": 0.9941727153279565, "train/cont_rate": 0.9941850142045454, "train/dyn_loss_mean": 7.667796283057242, "train/dyn_loss_std": 6.812798091859529, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2580546045845205, "train/extr_critic_critic_opt_grad_steps": 3255.0, "train/extr_critic_critic_opt_loss": 15623.520500414299, "train/extr_critic_mag": 1.9680449077577302, "train/extr_critic_max": 1.9680449077577302, "train/extr_critic_mean": 0.4879188159424247, "train/extr_critic_min": -0.2619015249339017, "train/extr_critic_std": 0.6881164739077742, "train/extr_return_normed_mag": 2.140376052170089, "train/extr_return_normed_max": 2.140376052170089, "train/extr_return_normed_mean": 0.3542795129346125, "train/extr_return_normed_min": -0.23274397945991068, "train/extr_return_normed_std": 0.3639919509490331, "train/extr_return_rate": 0.3420612569333929, "train/extr_return_raw_mag": 4.114563631288933, "train/extr_return_raw_max": 4.114563631288933, "train/extr_return_raw_mean": 0.506552756961548, "train/extr_return_raw_min": -0.6821683679114688, "train/extr_return_raw_std": 0.7363980687928923, "train/extr_reward_mag": 1.0015988828557911, "train/extr_reward_max": 1.0015988828557911, "train/extr_reward_mean": 0.013564097850273052, "train/extr_reward_min": -0.3865422281351956, "train/extr_reward_std": 0.09658740664070303, "train/image_loss_mean": 20.806611718553484, "train/image_loss_std": 22.75728276281646, "train/model_loss_mean": 25.470325087056015, "train/model_loss_std": 25.284903981468894, "train/model_opt_grad_norm": 132.16838813550544, "train/model_opt_grad_steps": 3246.0, "train/model_opt_loss": 3329.550839510831, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 131.39204545454547, "train/policy_entropy_mag": 2.524889637123455, "train/policy_entropy_max": 2.524889637123455, "train/policy_entropy_mean": 0.852627478991494, "train/policy_entropy_min": 0.07956290397454392, "train/policy_entropy_std": 0.6299160872444962, "train/policy_logprob_mag": 7.436770598093669, "train/policy_logprob_max": -0.009482000382955779, "train/policy_logprob_mean": -0.8515820381316271, "train/policy_logprob_min": -7.436770598093669, "train/policy_logprob_std": 1.2666968983231168, "train/policy_randomness_mag": 0.8911752398266937, "train/policy_randomness_max": 0.8911752398266937, "train/policy_randomness_mean": 0.3009400819287156, "train/policy_randomness_min": 0.028082213491540064, "train/policy_randomness_std": 0.2223327359692617, "train/post_ent_mag": 44.496130509810015, "train/post_ent_max": 44.496130509810015, "train/post_ent_mean": 30.801526907718543, "train/post_ent_min": 13.573361526836049, "train/post_ent_std": 5.240423827460318, "train/prior_ent_mag": 57.3269783077818, "train/prior_ent_max": 57.3269783077818, "train/prior_ent_mean": 38.672823905944824, "train/prior_ent_min": 15.916346167073105, "train/prior_ent_std": 7.07739152691581, "train/rep_loss_mean": 7.667796283057242, "train/rep_loss_std": 6.812798091859529, "train/reward_avg": 0.012377929556268182, "train/reward_loss_mean": 0.062204186832814506, "train/reward_loss_std": 0.31890177862210706, "train/reward_max_data": 1.0015151518763918, "train/reward_max_pred": 1.0000612835089366, "train/reward_neg_acc": 0.9948307971159617, "train/reward_neg_loss": 0.041841776484172, "train/reward_pos_acc": 0.9033998973441847, "train/reward_pos_loss": 1.1965200494636188, "train/reward_pred": 0.01116454399501284, "train/reward_rate": 0.017637310606060608, "train_stats/sum_log_reward": 2.933333264477551, "train_stats/max_log_achievement_collect_drink": 11.166666666666666, "train_stats/max_log_achievement_collect_sapling": 1.7583333333333333, "train_stats/max_log_achievement_collect_wood": 1.05, "train_stats/max_log_achievement_defeat_zombie": 0.10833333333333334, "train_stats/max_log_achievement_eat_cow": 0.06666666666666667, "train_stats/max_log_achievement_make_wood_pickaxe": 0.025, "train_stats/max_log_achievement_place_plant": 1.525, "train_stats/max_log_achievement_place_table": 0.1, "train_stats/max_log_achievement_wake_up": 2.2416666666666667, "train_stats/mean_log_entropy": 0.8607206491132577, "train_stats/max_log_achievement_defeat_skeleton": 0.008695652173913044, "eval_stats/sum_log_reward": 2.9124999046325684, "eval_stats/max_log_achievement_collect_drink": 6.0, "eval_stats/max_log_achievement_collect_sapling": 2.0625, "eval_stats/max_log_achievement_collect_wood": 0.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 0.25, "eval_stats/max_log_achievement_wake_up": 2.125, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "train_stats/max_log_achievement_make_wood_sword": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0003612196596805006, "report/cont_loss_std": 0.008966576308012009, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.051710501313209534, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.783120054227766e-06, "report/cont_pred": 0.9934729337692261, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 9.50694751739502, "report/dyn_loss_std": 7.525848865509033, "report/image_loss_mean": 22.321090698242188, "report/image_loss_std": 22.528583526611328, "report/model_loss_mean": 28.131120681762695, "report/model_loss_std": 25.593482971191406, "report/post_ent_mag": 45.82794189453125, "report/post_ent_max": 45.82794189453125, "report/post_ent_mean": 30.7563419342041, "report/post_ent_min": 14.666399002075195, "report/post_ent_std": 5.290169715881348, "report/prior_ent_mag": 57.53251647949219, "report/prior_ent_max": 57.53251647949219, "report/prior_ent_mean": 40.95352554321289, "report/prior_ent_min": 16.013385772705078, "report/prior_ent_std": 7.5296196937561035, "report/rep_loss_mean": 9.50694751739502, "report/rep_loss_std": 7.525848865509033, "report/reward_avg": 0.01962890662252903, "report/reward_loss_mean": 0.10550010949373245, "report/reward_loss_std": 0.40888890624046326, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0008049011230469, "report/reward_neg_acc": 0.9889559149742126, "report/reward_neg_loss": 0.08223709464073181, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.9329991936683655, "report/reward_pred": 0.02156134508550167, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00038846093229949474, "eval/cont_loss_std": 0.007375345099717379, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.050551265478134155, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00024106776982080191, "eval/cont_pred": 0.9969924688339233, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 12.640558242797852, "eval/dyn_loss_std": 7.440507411956787, "eval/image_loss_mean": 41.88299560546875, "eval/image_loss_std": 35.5155029296875, "eval/model_loss_mean": 49.58473205566406, "eval/model_loss_std": 38.20558166503906, "eval/post_ent_mag": 46.91164016723633, "eval/post_ent_max": 46.91164016723633, "eval/post_ent_mean": 29.905054092407227, "eval/post_ent_min": 16.7716007232666, "eval/post_ent_std": 5.603521347045898, "eval/prior_ent_mag": 55.69453048706055, "eval/prior_ent_max": 55.69453048706055, "eval/prior_ent_mean": 38.75135803222656, "eval/prior_ent_min": 16.729515075683594, "eval/prior_ent_std": 7.011125087738037, "eval/rep_loss_mean": 12.640558242797852, "eval/rep_loss_std": 7.440507411956787, "eval/reward_avg": 0.01035156287252903, "eval/reward_loss_mean": 0.11701115220785141, "eval/reward_loss_std": 0.7363150715827942, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0008354187011719, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 0.07528692483901978, "eval/reward_pos_acc": 0.5384615659713745, "eval/reward_pos_loss": 3.3618721961975098, "eval/reward_pred": 0.002283219713717699, "eval/reward_rate": 0.0126953125, "replay/size": 63681.0, "replay/inserts": 21184.0, "replay/samples": 21184.0, "replay/insert_wait_avg": 1.5368454405908499e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0888652138839676e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13960.0, "eval_replay/inserts": 3624.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3266967621860125e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2665987014770508e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3436155319214, "timer/env.step_count": 2648.0, "timer/env.step_total": 271.1932997703552, "timer/env.step_frac": 0.27110014554963824, "timer/env.step_avg": 0.1024143881307988, "timer/env.step_min": 0.02421879768371582, "timer/env.step_max": 2.0714223384857178, "timer/replay._sample_count": 21184.0, "timer/replay._sample_total": 12.482832193374634, "timer/replay._sample_frac": 0.012478544371712743, "timer/replay._sample_avg": 0.0005892575619984249, "timer/replay._sample_min": 0.0004181861877441406, "timer/replay._sample_max": 0.009793519973754883, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3101.0, "timer/agent.policy_total": 56.349714517593384, "timer/agent.policy_frac": 0.056330358531483264, "timer/agent.policy_avg": 0.01817146550067507, "timer/agent.policy_min": 0.009913444519042969, "timer/agent.policy_max": 0.0940713882446289, "timer/dataset_train_count": 1324.0, "timer/dataset_train_total": 0.1672654151916504, "timer/dataset_train_frac": 0.00016720795993955428, "timer/dataset_train_avg": 0.00012633339515985678, "timer/dataset_train_min": 0.00010776519775390625, "timer/dataset_train_max": 0.0010552406311035156, "timer/agent.train_count": 1324.0, "timer/agent.train_total": 603.0334458351135, "timer/agent.train_frac": 0.6028263053535433, "timer/agent.train_avg": 0.45546332767002534, "timer/agent.train_min": 0.4407639503479004, "timer/agent.train_max": 1.4849741458892822, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4762990474700928, "timer/agent.report_frac": 0.000476135439937632, "timer/agent.report_avg": 0.2381495237350464, "timer/agent.report_min": 0.22838902473449707, "timer/agent.report_max": 0.2479100227355957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.4332275390625e-05, "timer/dataset_eval_frac": 3.432048233983e-08, "timer/dataset_eval_avg": 3.4332275390625e-05, "timer/dataset_eval_min": 3.4332275390625e-05, "timer/dataset_eval_max": 3.4332275390625e-05, "fps": 21.176424801768285}
{"step": 64240, "time": 3349.351661682129, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 64368, "time": 3355.591002702713, "episode/length": 214.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 64576, "time": 3364.795140028, "episode/length": 183.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 64600, "time": 3367.1383345127106, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 64904, "time": 3379.0735251903534, "episode/length": 239.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 65288, "time": 3393.932348012924, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 65440, "time": 3400.996595144272, "episode/length": 149.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 65656, "time": 3411.583839416504, "episode/length": 134.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 65696, "time": 3415.312151193619, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 65776, "time": 3419.8117241859436, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 66072, "time": 3431.269315481186, "episode/length": 212.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 66112, "time": 3434.4880237579346, "episode/length": 41.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 66296, "time": 3442.2886033058167, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 66560, "time": 3453.170244216919, "episode/length": 244.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 66656, "time": 3458.102767467499, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 66704, "time": 3461.2849559783936, "episode/length": 157.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 66960, "time": 3471.782017469406, "episode/length": 162.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 67000, "time": 3474.597316265106, "episode/length": 115.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9568965517241379, "episode/intrinsic_return": 0.0}
{"step": 67160, "time": 3481.7562668323517, "episode/length": 182.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 67216, "time": 3485.571886777878, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 67520, "time": 3497.438412427902, "episode/length": 152.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 67888, "time": 3511.5340147018433, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 68208, "time": 3523.9900674819946, "episode/length": 193.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 68208, "time": 3523.998284101486, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 68416, "time": 3534.6212100982666, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 68496, "time": 3539.245980978012, "episode/length": 241.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 68528, "time": 3541.907961845398, "episode/length": 39.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 68536, "time": 3543.583264350891, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 68640, "time": 3548.9488158226013, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 69048, "time": 3564.3399379253387, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 69072, "time": 3566.978664159775, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 69552, "time": 3585.076073884964, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 69776, "time": 3594.3574965000153, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 69848, "time": 3598.1532366275787, "episode/length": 178.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 69888, "time": 3601.3538689613342, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3610.1166472434998, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3629.531169652939, "eval_episode/length": 135.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 70096, "time": 3632.205162525177, "eval_episode/length": 156.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 70096, "time": 3634.191426038742, "eval_episode/length": 165.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 70096, "time": 3636.128577709198, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 70096, "time": 3638.2999181747437, "eval_episode/length": 186.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 70096, "time": 3640.8989901542664, "eval_episode/length": 209.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 70096, "time": 3642.526187181473, "eval_episode/length": 210.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 70096, "time": 3647.195173740387, "eval_episode/length": 249.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 70128, "time": 3650.239764213562, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 70272, "time": 3657.285191297531, "episode/length": 149.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 70440, "time": 3664.315194606781, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 71032, "time": 3686.168208360672, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 71288, "time": 3696.4983723163605, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 71536, "time": 3706.7413535118103, "episode/length": 219.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 71592, "time": 3709.9358224868774, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 71600, "time": 3712.217619419098, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 71616, "time": 3714.435799598694, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 71792, "time": 3721.9800539016724, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 72704, "time": 3754.929177761078, "episode/length": 208.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 72808, "time": 3759.9618101119995, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 72824, "time": 3762.085892677307, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 72976, "time": 3769.07235455513, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 73216, "time": 3778.9823195934296, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 73352, "time": 3784.953509569168, "episode/length": 226.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.986784140969163, "episode/intrinsic_return": 0.0}
{"step": 73848, "time": 3805.049721479416, "episode/length": 425.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 73872, "time": 3807.7149045467377, "episode/length": 259.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9884615384615385, "episode/intrinsic_return": 0.0}
{"step": 74208, "time": 3820.8328313827515, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 74360, "time": 3827.55188536644, "episode/length": 206.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 74536, "time": 3835.3488459587097, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 74624, "time": 3840.1657042503357, "episode/length": 226.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 74656, "time": 3842.794233560562, "episode/length": 36.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 74720, "time": 3846.679522752762, "episode/length": 217.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 75096, "time": 3860.8537726402283, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 75288, "time": 3869.109831571579, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 75320, "time": 3871.696432828903, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 75504, "time": 3879.7096195220947, "episode/length": 109.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 75568, "time": 3883.5561695098877, "episode/length": 30.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8387096774193549, "episode/intrinsic_return": 0.0}
{"step": 75608, "time": 3886.3327853679657, "episode/length": 110.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 75904, "time": 3898.38667011261, "episode/length": 155.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 76064, "time": 3905.526430606842, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 76192, "time": 3911.3480801582336, "episode/length": 247.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9879032258064516, "episode/intrinsic_return": 0.0}
{"step": 76440, "time": 3921.273955821991, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 76600, "time": 3928.2260160446167, "episode/length": 136.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9708029197080292, "episode/intrinsic_return": 0.0}
{"step": 76968, "time": 3942.3009700775146, "episode/length": 169.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 77000, "time": 3944.9990091323853, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 77216, "time": 3954.2225806713104, "episode/length": 264.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 77264, "time": 3957.5378959178925, "episode/length": 36.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 77304, "time": 3960.225409269333, "episode/length": 174.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 77680, "time": 3974.7797470092773, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 77808, "time": 3980.7415754795074, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 78160, "time": 3994.4698462486267, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 78304, "time": 4000.9648089408875, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 78504, "time": 4009.0031282901764, "episode/length": 160.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 78848, "time": 4022.449074983597, "episode/length": 280.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9928825622775801, "episode/intrinsic_return": 0.0}
{"step": 79072, "time": 4031.5340044498444, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 79144, "time": 4035.381868124008, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 79192, "time": 4038.590085506439, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 79416, "time": 4047.9094688892365, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 79416, "time": 4047.9178001880646, "episode/length": 216.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 79856, "time": 4066.329653739929, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 4090.304663181305, "eval_episode/length": 32.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 80080, "time": 4098.015161037445, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 80080, "time": 4100.622700452805, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 80080, "time": 4102.640627861023, "eval_episode/length": 193.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 80080, "time": 4104.324272155762, "eval_episode/length": 162.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 80080, "time": 4105.954950809479, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695431472081218}
{"step": 80080, "time": 4108.8820877075195, "eval_episode/length": 227.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9780701754385965}
{"step": 80080, "time": 4112.834070920944, "eval_episode/length": 273.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9963503649635036}
{"step": 80136, "time": 4114.598690748215, "episode/length": 203.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 80344, "time": 4123.800451755524, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 80384, "time": 4126.886448383331, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 80480, "time": 4131.792968511581, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 80632, "time": 4138.40016913414, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 80656, "time": 4141.089645624161, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 80760, "time": 4145.960499048233, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 81616, "time": 4176.765330076218, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 81696, "time": 4181.01508140564, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 81696, "time": 4181.024594783783, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 81856, "time": 4189.941835165024, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 81992, "time": 4197.563184499741, "episode/length": 36.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 82040, "time": 4200.836170196533, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 82144, "time": 4206.145759820938, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 82248, "time": 4211.060858488083, "episode/length": 220.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 82280, "time": 4213.7547216415405, "episode/length": 241.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 83160, "time": 4245.111163139343, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 83328, "time": 4252.6350383758545, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 83352, "time": 4254.90704870224, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 83496, "time": 4261.894894838333, "episode/length": 151.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 83504, "time": 4264.084407329559, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 83536, "time": 4266.791100978851, "episode/length": 186.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 83864, "time": 4279.091605424881, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 83928, "time": 4282.880174875259, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 84224, "time": 4294.873711109161, "episode/length": 108.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.944954128440367, "episode/intrinsic_return": 0.0}
{"step": 84664, "time": 4311.26957321167, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 84912, "time": 4321.99804019928, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 85080, "time": 4329.220432758331, "episode/length": 106.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 85160, "time": 4333.647702932358, "episode/length": 206.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 85176, "time": 4335.688858032227, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 85184, "time": 4337.892860889435, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 85192, "time": 4339.604793071747, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 85280, "time": 4344.60344004631, "episode/length": 222.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 85297, "time": 4347.423846960068, "train_stats/sum_log_reward": 3.777685876720208, "train_stats/max_log_achievement_collect_drink": 5.090909090909091, "train_stats/max_log_achievement_collect_sapling": 2.4628099173553717, "train_stats/max_log_achievement_collect_wood": 1.7933884297520661, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.14049586776859505, "train_stats/max_log_achievement_eat_cow": 0.05785123966942149, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01652892561983471, "train_stats/max_log_achievement_make_wood_sword": 0.06611570247933884, "train_stats/max_log_achievement_place_plant": 2.371900826446281, "train_stats/max_log_achievement_place_table": 0.49586776859504134, "train_stats/max_log_achievement_wake_up": 1.9669421487603307, "train_stats/mean_log_entropy": 0.8875639881969484, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.991026444868608, "train/action_min": 0.0, "train/action_std": 3.971843999443632, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.050261139700358566, "train/actor_opt_grad_steps": 4575.0, "train/actor_opt_loss": 27.838083520080104, "train/adv_mag": 1.2358072007244283, "train/adv_max": 1.2325375631000057, "train/adv_mean": 0.009351230678930733, "train/adv_min": -0.5454086419759374, "train/adv_std": 0.10250092207482367, "train/cont_avg": 0.9941776160037878, "train/cont_loss_mean": 0.0008381852055193941, "train/cont_loss_std": 0.022940885308647314, "train/cont_neg_acc": 0.9746059134150996, "train/cont_neg_loss": 0.08399914420727907, "train/cont_pos_acc": 0.9998957447030328, "train/cont_pos_loss": 0.0002960227887186091, "train/cont_pred": 0.9942129665251934, "train/cont_rate": 0.9941776160037878, "train/dyn_loss_mean": 9.5556060220256, "train/dyn_loss_std": 7.672839460950909, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2370199172785787, "train/extr_critic_critic_opt_grad_steps": 4575.0, "train/extr_critic_critic_opt_loss": 14808.121818773674, "train/extr_critic_mag": 2.3164967912616152, "train/extr_critic_max": 2.3164967912616152, "train/extr_critic_mean": 0.6661766747182066, "train/extr_critic_min": -0.1897619330521786, "train/extr_critic_std": 0.6893544594446818, "train/extr_return_normed_mag": 2.139879861564347, "train/extr_return_normed_max": 2.139879861564347, "train/extr_return_normed_mean": 0.3735067004507238, "train/extr_return_normed_min": -0.23776386898349633, "train/extr_return_normed_std": 0.3607220606821956, "train/extr_return_rate": 0.4351345711585247, "train/extr_return_raw_mag": 4.293055498238766, "train/extr_return_raw_max": 4.293055498238766, "train/extr_return_raw_mean": 0.6853636182618864, "train/extr_return_raw_min": -0.5645448453724384, "train/extr_return_raw_std": 0.7368928334026625, "train/extr_reward_mag": 1.0025820542465558, "train/extr_reward_max": 1.0025820542465558, "train/extr_reward_mean": 0.015144843759833637, "train/extr_reward_min": -0.32978174090385437, "train/extr_reward_std": 0.10449585273410335, "train/image_loss_mean": 19.661637566306375, "train/image_loss_std": 21.47247889547637, "train/model_loss_mean": 25.452935507803254, "train/model_loss_std": 24.676740299571644, "train/model_opt_grad_norm": 121.1265453858809, "train/model_opt_grad_steps": 4566.0, "train/model_opt_loss": 8869.588741418087, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 352.7462121212121, "train/policy_entropy_mag": 2.517010880239082, "train/policy_entropy_max": 2.517010880239082, "train/policy_entropy_mean": 0.90148147037535, "train/policy_entropy_min": 0.07941264625300061, "train/policy_entropy_std": 0.6111788925799456, "train/policy_logprob_mag": 7.437704209125403, "train/policy_logprob_max": -0.009461439334589875, "train/policy_logprob_mean": -0.8990736337322177, "train/policy_logprob_min": -7.437704209125403, "train/policy_logprob_std": 1.2405151724815369, "train/policy_randomness_mag": 0.8883943887371005, "train/policy_randomness_max": 0.8883943887371005, "train/policy_randomness_mean": 0.3181833970275792, "train/policy_randomness_min": 0.02802917928519574, "train/policy_randomness_std": 0.21571932676615138, "train/post_ent_mag": 45.71660845207445, "train/post_ent_max": 45.71660845207445, "train/post_ent_mean": 32.43625406785445, "train/post_ent_min": 15.318972833228834, "train/post_ent_std": 5.153638073892305, "train/prior_ent_mag": 58.83754686875777, "train/prior_ent_max": 58.83754686875777, "train/prior_ent_mean": 42.229678992069125, "train/prior_ent_min": 17.540465080376826, "train/prior_ent_std": 7.755895137786865, "train/rep_loss_mean": 9.5556060220256, "train/rep_loss_std": 7.672839460950909, "train/reward_avg": 0.01435102964663229, "train/reward_loss_mean": 0.05709600696961085, "train/reward_loss_std": 0.30126184879830387, "train/reward_max_data": 1.0053030315673712, "train/reward_max_pred": 1.0007567604382832, "train/reward_neg_acc": 0.9942496215755289, "train/reward_neg_loss": 0.03588522324394999, "train/reward_pos_acc": 0.9123565220471584, "train/reward_pos_loss": 1.1326053255435191, "train/reward_pred": 0.013214945348656991, "train/reward_rate": 0.01946466619318182, "eval_stats/sum_log_reward": 3.7874999418854713, "eval_stats/max_log_achievement_collect_drink": 7.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_wood": 1.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 0.5, "eval_stats/max_log_achievement_wake_up": 2.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 0.00019658039673231542, "report/cont_loss_std": 0.006078903563320637, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0015411095228046179, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00019262977002654225, "report/cont_pred": 0.9969001412391663, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 9.779934883117676, "report/dyn_loss_std": 7.729860305786133, "report/image_loss_mean": 14.486656188964844, "report/image_loss_std": 14.62765121459961, "report/model_loss_mean": 20.386699676513672, "report/model_loss_std": 18.046030044555664, "report/post_ent_mag": 43.876670837402344, "report/post_ent_max": 43.876670837402344, "report/post_ent_mean": 32.76177215576172, "report/post_ent_min": 18.584558486938477, "report/post_ent_std": 4.63222074508667, "report/prior_ent_mag": 60.00330352783203, "report/prior_ent_max": 60.00330352783203, "report/prior_ent_mean": 43.132774353027344, "report/prior_ent_min": 20.938507080078125, "report/prior_ent_std": 7.580787658691406, "report/rep_loss_mean": 9.779934883117676, "report/rep_loss_std": 7.729860305786133, "report/reward_avg": 0.00478515587747097, "report/reward_loss_mean": 0.03188595175743103, "report/reward_loss_std": 0.27043694257736206, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9975515604019165, "report/reward_neg_acc": 0.9950787425041199, "report/reward_neg_loss": 0.01975577510893345, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.572418212890625, "report/reward_pred": 0.003808405715972185, "report/reward_rate": 0.0078125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 2.337833575438708e-05, "eval/cont_loss_std": 0.00038551658508367836, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00022713543148711324, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2979595087235793e-05, "eval/cont_pred": 0.9980245232582092, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 13.801043510437012, "eval/dyn_loss_std": 8.425758361816406, "eval/image_loss_mean": 31.059123992919922, "eval/image_loss_std": 27.897563934326172, "eval/model_loss_mean": 39.45763397216797, "eval/model_loss_std": 31.16476821899414, "eval/post_ent_mag": 48.054115295410156, "eval/post_ent_max": 48.054115295410156, "eval/post_ent_mean": 30.512130737304688, "eval/post_ent_min": 16.362300872802734, "eval/post_ent_std": 5.460047245025635, "eval/prior_ent_mag": 58.05672836303711, "eval/prior_ent_max": 58.05672836303711, "eval/prior_ent_mean": 41.24699401855469, "eval/prior_ent_min": 19.417417526245117, "eval/prior_ent_std": 8.585837364196777, "eval/rep_loss_mean": 13.801043510437012, "eval/rep_loss_std": 8.425758361816406, "eval/reward_avg": 0.01337890513241291, "eval/reward_loss_mean": 0.11785957962274551, "eval/reward_loss_std": 0.7286691665649414, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9987244606018066, "eval/reward_neg_acc": 0.9950397610664368, "eval/reward_neg_loss": 0.05623741075396538, "eval/reward_pos_acc": 0.5625, "eval/reward_pos_loss": 4.000056266784668, "eval/reward_pred": 0.0014071653131395578, "eval/reward_rate": 0.015625, "replay/size": 84793.0, "replay/inserts": 21112.0, "replay/samples": 21104.0, "replay/insert_wait_avg": 1.4731088069498019e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.058005039397291e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 18152.0, "eval_replay/inserts": 4192.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3541856794866896e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1771917343139648e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0219960212708, "timer/env.step_count": 2639.0, "timer/env.step_total": 274.63989663124084, "timer/env.step_frac": 0.2746338557791075, "timer/env.step_avg": 0.1040696842103982, "timer/env.step_min": 0.02434372901916504, "timer/env.step_max": 3.5081734657287598, "timer/replay._sample_count": 21104.0, "timer/replay._sample_total": 11.839895963668823, "timer/replay._sample_frac": 0.011839635538793674, "timer/replay._sample_avg": 0.0005610261544573931, "timer/replay._sample_min": 0.00039458274841308594, "timer/replay._sample_max": 0.010553598403930664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3163.0, "timer/agent.policy_total": 56.92978119850159, "timer/agent.policy_frac": 0.05692852899736685, "timer/agent.policy_avg": 0.01799866620249813, "timer/agent.policy_min": 0.009723901748657227, "timer/agent.policy_max": 0.14399051666259766, "timer/dataset_train_count": 1319.0, "timer/dataset_train_total": 0.15776467323303223, "timer/dataset_train_frac": 0.00015776120311425282, "timer/dataset_train_avg": 0.00011960930495301912, "timer/dataset_train_min": 0.00010156631469726562, "timer/dataset_train_max": 0.00036597251892089844, "timer/agent.train_count": 1319.0, "timer/agent.train_total": 598.4252350330353, "timer/agent.train_frac": 0.5984120723483632, "timer/agent.train_avg": 0.4536961599947197, "timer/agent.train_min": 0.4366188049316406, "timer/agent.train_max": 1.616835355758667, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48291683197021484, "timer/agent.report_frac": 0.0004829062099549489, "timer/agent.report_avg": 0.24145841598510742, "timer/agent.report_min": 0.23031306266784668, "timer/agent.report_max": 0.25260376930236816, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 3.719248025325699e-08, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05, "fps": 21.111127852490004}
{"step": 85448, "time": 4352.608802556992, "episode/length": 33.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 85848, "time": 4367.7448117733, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 86064, "time": 4377.146984100342, "episode/length": 143.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 86416, "time": 4390.690610408783, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 86560, "time": 4397.157009601593, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 86712, "time": 4403.845733880997, "episode/length": 189.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 86800, "time": 4408.775348901749, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 86936, "time": 4414.820966720581, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9684684684684685, "episode/intrinsic_return": 0.0}
{"step": 87000, "time": 4418.522768497467, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 87280, "time": 4429.883399248123, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 87304, "time": 4432.278742313385, "episode/length": 264.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 87600, "time": 4444.087993383408, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 87888, "time": 4455.488183498383, "episode/length": 146.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 88152, "time": 4465.876326799393, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 88224, "time": 4470.08682346344, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 88320, "time": 4474.89243221283, "episode/length": 219.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 88496, "time": 4482.421850204468, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 89096, "time": 4504.2290024757385, "episode/length": 261.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9885496183206107, "episode/intrinsic_return": 0.0}
{"step": 89192, "time": 4509.196728944778, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 89264, "time": 4513.984159708023, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 89512, "time": 4523.967909812927, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 89992, "time": 4541.903043985367, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 90024, "time": 4544.7090582847595, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4563.057579755783, "eval_episode/length": 37.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 90064, "time": 4569.795932292938, "eval_episode/length": 154.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 90064, "time": 4571.938878059387, "eval_episode/length": 167.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 90064, "time": 4573.797816991806, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 90064, "time": 4575.608082532883, "eval_episode/length": 178.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 90064, "time": 4577.292932510376, "eval_episode/length": 180.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 90064, "time": 4579.402344942093, "eval_episode/length": 36.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.972972972972973}
{"step": 90064, "time": 4582.269924402237, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 90184, "time": 4587.5007202625275, "episode/length": 232.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 90240, "time": 4591.2180788517, "episode/length": 366.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.997275204359673, "episode/intrinsic_return": 0.0}
{"step": 90472, "time": 4600.405403375626, "episode/length": 171.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 90800, "time": 4613.484644651413, "episode/length": 191.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 90832, "time": 4616.179627895355, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 90896, "time": 4620.0307722091675, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 91368, "time": 4637.280616044998, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 91568, "time": 4646.1786143779755, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 91776, "time": 4654.994397878647, "episode/length": 191.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 91904, "time": 4661.519112825394, "episode/length": 214.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 91960, "time": 4664.800991296768, "episode/length": 48.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 92096, "time": 4671.255394935608, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 92152, "time": 4674.466444969177, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 92608, "time": 4691.943253993988, "episode/length": 266.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9812734082397003, "episode/intrinsic_return": 0.0}
{"step": 92672, "time": 4695.710818052292, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 92864, "time": 4703.927861452103, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 93216, "time": 4717.4149954319, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 93496, "time": 4728.246579885483, "episode/length": 214.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 93568, "time": 4732.595910549164, "episode/length": 176.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9887005649717514, "episode/intrinsic_return": 0.0}
{"step": 94144, "time": 4753.76443529129, "episode/length": 191.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 94288, "time": 4760.281981229782, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 94344, "time": 4763.763236522675, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 94800, "time": 4781.050538063049, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 95112, "time": 4793.2007648944855, "episode/length": 400.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 95224, "time": 4798.588848829269, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 95288, "time": 4802.421907663345, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 95544, "time": 4812.843042373657, "episode/length": 358.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9749303621169917, "episode/intrinsic_return": 0.0}
{"step": 95768, "time": 4822.17272400856, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 95800, "time": 4824.934782028198, "episode/length": 206.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 96040, "time": 4834.727191448212, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 96104, "time": 4838.486052274704, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 96352, "time": 4848.530120134354, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 96384, "time": 4851.316712617874, "episode/length": 136.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 96680, "time": 4862.616176366806, "episode/length": 181.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 96752, "time": 4867.4535892009735, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 96752, "time": 4867.46129989624, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 97120, "time": 4883.412166595459, "episode/length": 164.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 97552, "time": 4899.808564186096, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 97800, "time": 4909.502468585968, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 97808, "time": 4911.727308750153, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 98144, "time": 4924.872400760651, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 98280, "time": 4931.587220907211, "episode/length": 236.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 98312, "time": 4935.052428245544, "episode/length": 194.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 98368, "time": 4940.18944644928, "episode/length": 210.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 98392, "time": 4942.642703294754, "episode/length": 158.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 99000, "time": 4964.812178134918, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 99032, "time": 4967.564005374908, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 99520, "time": 4986.11240363121, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 99528, "time": 4987.632484436035, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 99592, "time": 4991.3427839279175, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 99664, "time": 4995.700166940689, "episode/length": 158.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 99880, "time": 5004.594954490662, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 99904, "time": 5007.251855134964, "episode/length": 191.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 5035.885112762451, "eval_episode/length": 140.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.950354609929078}
{"step": 100048, "time": 5038.30889415741, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 100048, "time": 5040.009101390839, "eval_episode/length": 161.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 100048, "time": 5042.247166395187, "eval_episode/length": 176.0, "eval_episode/score": 5.099999964237213, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 100048, "time": 5044.601402759552, "eval_episode/length": 193.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9690721649484536}
{"step": 100048, "time": 5046.862459182739, "eval_episode/length": 207.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 100048, "time": 5049.179447174072, "eval_episode/length": 223.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 100048, "time": 5056.888483762741, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9781420765027322}
{"step": 100048, "time": 5056.897171974182, "eval_episode/length": 197.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9797979797979798}
{"step": 100496, "time": 5072.165718317032, "episode/length": 186.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 100504, "time": 5073.753993272781, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 100712, "time": 5082.530922651291, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 100840, "time": 5088.487933397293, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 100968, "time": 5094.588020563126, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 101440, "time": 5112.164964199066, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 101576, "time": 5118.177106142044, "episode/length": 211.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 101904, "time": 5131.272737026215, "episode/length": 288.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9930795847750865, "episode/intrinsic_return": 0.0}
{"step": 101912, "time": 5132.9598736763, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 102088, "time": 5140.580482006073, "episode/length": 197.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 102256, "time": 5148.105870962143, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 102344, "time": 5152.57018828392, "episode/length": 187.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 102520, "time": 5160.211699008942, "episode/length": 193.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 102544, "time": 5162.791187286377, "episode/length": 228.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9694323144104804, "episode/intrinsic_return": 0.0}
{"step": 102824, "time": 5173.745203256607, "episode/length": 37.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.8947368421052632, "episode/intrinsic_return": 0.0}
{"step": 103152, "time": 5187.08071231842, "episode/length": 196.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 103416, "time": 5197.393810749054, "episode/length": 188.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 103736, "time": 5210.007214784622, "episode/length": 205.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 103872, "time": 5216.7377099990845, "episode/length": 303.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 103904, "time": 5219.534768342972, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 104280, "time": 5233.799946546555, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 104488, "time": 5242.667033910751, "episode/length": 278.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 104488, "time": 5242.675008058548, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 104544, "time": 5248.051398992538, "episode/length": 274.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 105080, "time": 5267.6150624752045, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 105328, "time": 5278.136147260666, "episode/length": 238.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 105400, "time": 5281.972146987915, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 105752, "time": 5295.605932474136, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 105784, "time": 5298.428278207779, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 105872, "time": 5303.424080848694, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 105928, "time": 5306.707819223404, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 106224, "time": 5318.572264909744, "episode/length": 142.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 106376, "time": 5325.228967428207, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 106905, "time": 5347.449356794357, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.328456398292824, "train/action_min": 0.0, "train/action_std": 3.1675765567355687, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05091566918072877, "train/actor_opt_grad_steps": 5910.0, "train/actor_opt_loss": 4.687606676529955, "train/adv_mag": 1.110737509197659, "train/adv_max": 1.106552442797908, "train/adv_mean": 0.006906899613447119, "train/adv_min": -0.5381596459282769, "train/adv_std": 0.09609552191363441, "train/cont_avg": 0.9943938078703703, "train/cont_loss_mean": 0.00044159861551709885, "train/cont_loss_std": 0.011723387662790527, "train/cont_neg_acc": 0.9851557925895408, "train/cont_neg_loss": 0.03127103350572169, "train/cont_pos_acc": 0.9999272253778245, "train/cont_pos_loss": 0.0002635730292416417, "train/cont_pred": 0.9943560516392743, "train/cont_rate": 0.9943938078703703, "train/dyn_loss_mean": 11.37133029655174, "train/dyn_loss_std": 8.261674548961498, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.2483999455416643, "train/extr_critic_critic_opt_grad_steps": 5910.0, "train/extr_critic_critic_opt_loss": 15122.737297453703, "train/extr_critic_mag": 2.8056107415093314, "train/extr_critic_max": 2.8056107415093314, "train/extr_critic_mean": 0.7724074440973776, "train/extr_critic_min": -0.23669701328984014, "train/extr_critic_std": 0.8096317158805, "train/extr_return_normed_mag": 2.0272072553634644, "train/extr_return_normed_max": 2.0272072553634644, "train/extr_return_normed_mean": 0.36924148290245623, "train/extr_return_normed_min": -0.18609703230085195, "train/extr_return_normed_std": 0.35283043881257375, "train/extr_return_rate": 0.49656541965625905, "train/extr_return_raw_mag": 4.827732361687554, "train/extr_return_raw_max": 4.827732361687554, "train/extr_return_raw_mean": 0.7889197168526826, "train/extr_return_raw_min": -0.5631340137234441, "train/extr_return_raw_std": 0.8620066499268567, "train/extr_reward_mag": 1.0029859843077482, "train/extr_reward_max": 1.0029859843077482, "train/extr_reward_mean": 0.016753736386696496, "train/extr_reward_min": -0.34045085465466535, "train/extr_reward_std": 0.11195053336796937, "train/image_loss_mean": 18.291774876912434, "train/image_loss_std": 20.10996167924669, "train/model_loss_mean": 25.170599280463325, "train/model_loss_std": 23.60406338020607, "train/model_opt_grad_norm": 102.19889269228335, "train/model_opt_grad_steps": 5900.6518518518515, "train/model_opt_loss": 16912.28654513889, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 671.2962962962963, "train/policy_entropy_mag": 2.506731390070032, "train/policy_entropy_max": 2.506731390070032, "train/policy_entropy_mean": 0.7434906769681859, "train/policy_entropy_min": 0.07938077107623771, "train/policy_entropy_std": 0.5966859464292174, "train/policy_logprob_mag": 7.438245130468298, "train/policy_logprob_max": -0.009457028305364979, "train/policy_logprob_mean": -0.7430805826628649, "train/policy_logprob_min": -7.438245130468298, "train/policy_logprob_std": 1.2049212729489363, "train/policy_randomness_mag": 0.8847661751287955, "train/policy_randomness_max": 0.8847661751287955, "train/policy_randomness_mean": 0.26241958064061627, "train/policy_randomness_min": 0.028017928603070754, "train/policy_randomness_std": 0.21060395384276354, "train/post_ent_mag": 47.22967809041341, "train/post_ent_max": 47.22967809041341, "train/post_ent_mean": 33.800477769639755, "train/post_ent_min": 16.758879809909395, "train/post_ent_std": 5.259787729051378, "train/prior_ent_mag": 59.98102806939019, "train/prior_ent_max": 59.98102806939019, "train/prior_ent_mean": 45.26490071614583, "train/prior_ent_min": 19.00612168488679, "train/prior_ent_std": 8.119971406018292, "train/rep_loss_mean": 11.37133029655174, "train/rep_loss_std": 8.261674548961498, "train/reward_avg": 0.016319444358210873, "train/reward_loss_mean": 0.05558463072887174, "train/reward_loss_std": 0.2828479931310371, "train/reward_max_data": 1.0044444455040826, "train/reward_max_pred": 1.0014974311546043, "train/reward_neg_acc": 0.9936908178859287, "train/reward_neg_loss": 0.03458522305720382, "train/reward_pos_acc": 0.9364408991954944, "train/reward_pos_loss": 1.0226528331085487, "train/reward_pred": 0.01548162274821489, "train/reward_rate": 0.021281828703703702, "train_stats/sum_log_reward": 4.044954068070158, "train_stats/max_log_achievement_collect_drink": 5.467889908256881, "train_stats/max_log_achievement_collect_sapling": 2.623853211009174, "train_stats/max_log_achievement_collect_wood": 1.8440366972477065, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.23853211009174313, "train_stats/max_log_achievement_eat_cow": 0.05504587155963303, "train_stats/max_log_achievement_make_wood_pickaxe": 0.03669724770642202, "train_stats/max_log_achievement_make_wood_sword": 0.08256880733944955, "train_stats/max_log_achievement_place_plant": 2.467889908256881, "train_stats/max_log_achievement_place_table": 0.6055045871559633, "train_stats/max_log_achievement_wake_up": 1.4587155963302751, "train_stats/mean_log_entropy": 0.7827008979036174, "eval_stats/sum_log_reward": 3.747058763223536, "eval_stats/max_log_achievement_collect_drink": 10.647058823529411, "eval_stats/max_log_achievement_collect_sapling": 2.4705882352941178, "eval_stats/max_log_achievement_collect_wood": 1.6470588235294117, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.17647058823529413, "eval_stats/max_log_achievement_eat_cow": 0.11764705882352941, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.058823529411764705, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.411764705882353, "eval_stats/max_log_achievement_place_table": 0.47058823529411764, "eval_stats/max_log_achievement_wake_up": 1.2352941176470589, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.00034765206510201097, "report/cont_loss_std": 0.007932276464998722, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.038218267261981964, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.9458238208899274e-05, "report/cont_pred": 0.9924102425575256, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 13.229506492614746, "report/dyn_loss_std": 7.814004421234131, "report/image_loss_mean": 16.13178253173828, "report/image_loss_std": 14.522966384887695, "report/model_loss_mean": 24.134220123291016, "report/model_loss_std": 17.705081939697266, "report/post_ent_mag": 49.78215789794922, "report/post_ent_max": 49.78215789794922, "report/post_ent_mean": 34.838661193847656, "report/post_ent_min": 17.67772102355957, "report/post_ent_std": 5.367073059082031, "report/prior_ent_mag": 60.35234832763672, "report/prior_ent_max": 60.35234832763672, "report/prior_ent_mean": 48.060264587402344, "report/prior_ent_min": 17.656064987182617, "report/prior_ent_std": 7.280397891998291, "report/rep_loss_mean": 13.229506492614746, "report/rep_loss_std": 7.814004421234131, "report/reward_avg": 0.01640624925494194, "report/reward_loss_mean": 0.06438860297203064, "report/reward_loss_std": 0.3230968415737152, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001673936843872, "report/reward_neg_acc": 0.9960000514984131, "report/reward_neg_loss": 0.04365495964884758, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.9282907843589783, "report/reward_pred": 0.017244696617126465, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 0.0001222368737217039, "eval/cont_loss_std": 0.003906783182173967, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.1250782310962677, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 9.024812186453346e-08, "eval/cont_pred": 0.9991382360458374, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.302738189697266, "eval/dyn_loss_std": 9.420886039733887, "eval/image_loss_mean": 29.196216583251953, "eval/image_loss_std": 24.708023071289062, "eval/model_loss_mean": 39.13490295410156, "eval/model_loss_std": 28.513572692871094, "eval/post_ent_mag": 46.392398834228516, "eval/post_ent_max": 46.392398834228516, "eval/post_ent_mean": 32.647193908691406, "eval/post_ent_min": 18.658288955688477, "eval/post_ent_std": 5.155694484710693, "eval/prior_ent_mag": 59.787681579589844, "eval/prior_ent_max": 59.787681579589844, "eval/prior_ent_mean": 44.07251739501953, "eval/prior_ent_min": 20.218524932861328, "eval/prior_ent_std": 8.08598518371582, "eval/rep_loss_mean": 16.302738189697266, "eval/rep_loss_std": 9.420886039733887, "eval/reward_avg": 0.00859374925494194, "eval/reward_loss_mean": 0.15692099928855896, "eval/reward_loss_std": 0.8489993214607239, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9966998100280762, "eval/reward_neg_acc": 0.9980237483978271, "eval/reward_neg_loss": 0.10545893758535385, "eval/reward_pos_acc": 0.4166666865348816, "eval/reward_pos_loss": 4.496888160705566, "eval/reward_pred": 0.002027556300163269, "eval/reward_rate": 0.01171875, "replay/size": 106401.0, "replay/inserts": 21608.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.4966922704928983e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0469306582966882e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 22720.0, "eval_replay/inserts": 4568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3176175633579127e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0247497558594, "timer/env.step_count": 2701.0, "timer/env.step_total": 257.4850296974182, "timer/env.step_frac": 0.2574786571635144, "timer/env.step_avg": 0.09532951858475314, "timer/env.step_min": 0.0244443416595459, "timer/env.step_max": 3.404542922973633, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.846328496932983, "timer/replay._sample_frac": 0.011846035310451149, "timer/replay._sample_avg": 0.0005480351821305045, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.008104324340820312, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3272.0, "timer/agent.policy_total": 57.192543745040894, "timer/agent.policy_frac": 0.057191128278578675, "timer/agent.policy_avg": 0.017479383785159196, "timer/agent.policy_min": 0.009651660919189453, "timer/agent.policy_max": 0.11521530151367188, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.16029644012451172, "timer/dataset_train_frac": 0.00016029247292494072, "timer/dataset_train_avg": 0.00011865021474797314, "timer/dataset_train_min": 0.00010013580322265625, "timer/dataset_train_max": 0.0005395412445068359, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 612.1111724376678, "timer/agent.train_frac": 0.6120960232105309, "timer/agent.train_avg": 0.4530800684216638, "timer/agent.train_min": 0.43971848487854004, "timer/agent.train_max": 1.5217509269714355, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4694178104400635, "timer/agent.report_frac": 0.000469406192751394, "timer/agent.report_avg": 0.23470890522003174, "timer/agent.report_min": 0.2231457233428955, "timer/agent.report_max": 0.24627208709716797, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.029273986816406e-05, "timer/dataset_eval_frac": 4.0291742657370145e-08, "timer/dataset_eval_avg": 4.029273986816406e-05, "timer/dataset_eval_min": 4.029273986816406e-05, "timer/dataset_eval_max": 4.029273986816406e-05, "fps": 21.6071530032949}
{"step": 107024, "time": 5351.6591765880585, "episode/length": 211.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 107056, "time": 5354.481677770615, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 107112, "time": 5357.896120786667, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 107144, "time": 5360.64195895195, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 107208, "time": 5364.71306347847, "episode/length": 225.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 107264, "time": 5368.533993005753, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 107656, "time": 5383.263246536255, "episode/length": 159.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 107712, "time": 5386.931835174561, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 108312, "time": 5409.0429656505585, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 108440, "time": 5415.09525513649, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 108496, "time": 5418.77770280838, "episode/length": 153.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 108560, "time": 5422.647773981094, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 108664, "time": 5427.74968791008, "episode/length": 181.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 108688, "time": 5430.47580575943, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 108936, "time": 5440.360406398773, "episode/length": 61.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 109032, "time": 5445.197690010071, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 109056, "time": 5447.87492275238, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 109720, "time": 5471.9218463897705, "episode/length": 144.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 109872, "time": 5478.997674226761, "episode/length": 147.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 109944, "time": 5483.194446325302, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5502.65452170372, "eval_episode/length": 37.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 110032, "time": 5508.7898943424225, "eval_episode/length": 135.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9926470588235294}
{"step": 110032, "time": 5511.950017929077, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 110032, "time": 5513.759296655655, "eval_episode/length": 167.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 110032, "time": 5517.760162115097, "eval_episode/length": 183.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 110032, "time": 5519.453324794769, "eval_episode/length": 186.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 110032, "time": 5521.683098554611, "eval_episode/length": 162.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 110032, "time": 5524.057546138763, "eval_episode/length": 216.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 110352, "time": 5534.999150276184, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 110416, "time": 5538.728471517563, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 110600, "time": 5547.154030323029, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9825174825174825, "episode/intrinsic_return": 0.0}
{"step": 110632, "time": 5549.875193834305, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 110736, "time": 5555.313976287842, "episode/length": 209.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 111048, "time": 5567.472459554672, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 111160, "time": 5573.079641342163, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 111336, "time": 5580.6725153923035, "episode/length": 182.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 111480, "time": 5587.04630279541, "episode/length": 39.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 111904, "time": 5603.386139392853, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 112056, "time": 5609.975565671921, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 112144, "time": 5614.813727140427, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 112352, "time": 5623.48823428154, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793388429752066, "episode/intrinsic_return": 0.0}
{"step": 112392, "time": 5626.256400823593, "episode/length": 219.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 112680, "time": 5637.794293642044, "episode/length": 35.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 112784, "time": 5643.288859844208, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 5647.071969985962, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 112944, "time": 5651.95224571228, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 113136, "time": 5660.070369958878, "episode/length": 153.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 113928, "time": 5688.669394254684, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 113968, "time": 5691.943904399872, "episode/length": 238.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790794979079498, "episode/intrinsic_return": 0.0}
{"step": 114024, "time": 5695.215974569321, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 114160, "time": 5701.647563457489, "episode/length": 251.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 114224, "time": 5705.670745372772, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 114304, "time": 5710.109605789185, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 114320, "time": 5712.225655078888, "episode/length": 36.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 114528, "time": 5721.096853017807, "episode/length": 208.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 114656, "time": 5727.180641889572, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 114856, "time": 5736.650046348572, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 115240, "time": 5751.485811948776, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 115280, "time": 5754.6509737968445, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 115528, "time": 5764.571745157242, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 115672, "time": 5771.130662441254, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 115808, "time": 5777.779846429825, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 115808, "time": 5777.788639307022, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 115896, "time": 5784.797158479691, "episode/length": 154.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 115984, "time": 5789.6359832286835, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 116400, "time": 5805.336400270462, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 116560, "time": 5812.423492670059, "episode/length": 159.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 116952, "time": 5827.103782892227, "episode/length": 213.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 117112, "time": 5834.344087362289, "episode/length": 197.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 117240, "time": 5840.3888964653015, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 117368, "time": 5846.437296390533, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 117544, "time": 5854.375678062439, "episode/length": 142.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 117584, "time": 5857.701083421707, "episode/length": 210.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.985781990521327, "episode/intrinsic_return": 0.0}
{"step": 117728, "time": 5864.6274330616, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 117840, "time": 5870.121082782745, "episode/length": 110.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.954954954954955, "episode/intrinsic_return": 0.0}
{"step": 118160, "time": 5883.236436843872, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 118560, "time": 5898.378486633301, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 118824, "time": 5908.730744123459, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 118848, "time": 5911.451231002808, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 119008, "time": 5918.497284173965, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 119040, "time": 5921.199437379837, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.989010989010989, "episode/intrinsic_return": 0.0}
{"step": 119240, "time": 5929.298109769821, "episode/length": 265.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9887218045112782, "episode/intrinsic_return": 0.0}
{"step": 119488, "time": 5939.709589958191, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 119832, "time": 5952.749137639999, "episode/length": 262.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 119880, "time": 5956.039495229721, "episode/length": 131.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5981.769950628281, "eval_episode/length": 136.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 120016, "time": 5983.508515119553, "eval_episode/length": 137.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 120016, "time": 5985.1412444114685, "eval_episode/length": 139.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9928571428571429}
{"step": 120016, "time": 5987.092848539352, "eval_episode/length": 148.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 120016, "time": 5988.6569838523865, "eval_episode/length": 149.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 120016, "time": 5988.667079925537, "eval_episode/length": 149.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 120016, "time": 5992.752366542816, "eval_episode/length": 161.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9938271604938271}
{"step": 120016, "time": 5996.55813908577, "eval_episode/length": 211.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 120144, "time": 6000.865795373917, "episode/length": 161.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 120216, "time": 6004.724810123444, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 120424, "time": 6013.273901462555, "episode/length": 172.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9826589595375722, "episode/intrinsic_return": 0.0}
{"step": 120728, "time": 6025.393132448196, "episode/length": 270.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 120776, "time": 6028.6329119205475, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 121072, "time": 6040.426052331924, "episode/length": 148.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 121248, "time": 6047.959928035736, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 121440, "time": 6056.11839389801, "episode/length": 152.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 121672, "time": 6065.42215180397, "episode/length": 272.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 121768, "time": 6070.412804603577, "episode/length": 167.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 121936, "time": 6078.441219806671, "episode/length": 150.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 122040, "time": 6083.544682741165, "episode/length": 236.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704641350210971, "episode/intrinsic_return": 0.0}
{"step": 122456, "time": 6099.230994462967, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 122616, "time": 6106.39381313324, "episode/length": 192.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 122704, "time": 6111.338429927826, "episode/length": 116.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 122752, "time": 6114.477027893066, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 123016, "time": 6126.208433151245, "episode/length": 220.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 123400, "time": 6140.9269852638245, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 123504, "time": 6146.4145402908325, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 123696, "time": 6154.570290803909, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 123776, "time": 6158.959071159363, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 124016, "time": 6168.72891497612, "episode/length": 174.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 124024, "time": 6170.403213739395, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 124192, "time": 6178.009300470352, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 124784, "time": 6199.609922170639, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 124840, "time": 6203.021036624908, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 124872, "time": 6205.6136610507965, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 125064, "time": 6213.845658302307, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 125120, "time": 6217.586477279663, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 125184, "time": 6221.466333627701, "episode/length": 145.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 125344, "time": 6228.5009224414825, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 125376, "time": 6231.248472213745, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 125552, "time": 6238.775758266449, "episode/length": 53.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 126120, "time": 6259.418985843658, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 126464, "time": 6273.208088636398, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 126600, "time": 6279.2503926754, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 126688, "time": 6284.056422948837, "episode/length": 230.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 126760, "time": 6288.033734083176, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 126768, "time": 6290.23362493515, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 127272, "time": 6308.911725282669, "episode/length": 240.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979253112033195, "episode/intrinsic_return": 0.0}
{"step": 127288, "time": 6311.010325193405, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 127928, "time": 6334.466032266617, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 127984, "time": 6338.278993844986, "episode/length": 172.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 128024, "time": 6340.995075702667, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 128072, "time": 6344.212663888931, "episode/length": 162.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 128089, "time": 6347.487808704376, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.463212446732954, "train/action_min": 0.0, "train/action_std": 3.572417578913949, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.049779954281720246, "train/actor_opt_grad_steps": 7245.0, "train/actor_opt_loss": 9.85075236998047, "train/adv_mag": 0.9959487892461546, "train/adv_max": 0.9862509496284254, "train/adv_mean": 0.006209914205476597, "train/adv_min": -0.5495994994134614, "train/adv_std": 0.0897648400542411, "train/cont_avg": 0.9940962357954546, "train/cont_loss_mean": 0.0004891463871112564, "train/cont_loss_std": 0.013140158406720344, "train/cont_neg_acc": 0.9816164929758419, "train/cont_neg_loss": 0.04843894561583044, "train/cont_pos_acc": 0.9999478757381439, "train/cont_pos_loss": 0.00018644812603018192, "train/cont_pred": 0.9941158434658339, "train/cont_rate": 0.9940962357954546, "train/dyn_loss_mean": 12.696272199804133, "train/dyn_loss_std": 8.632597666798215, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1178505420684814, "train/extr_critic_critic_opt_grad_steps": 7245.0, "train/extr_critic_critic_opt_loss": 15340.433800899622, "train/extr_critic_mag": 3.1837749896627483, "train/extr_critic_max": 3.1837749896627483, "train/extr_critic_mean": 0.7498479361335436, "train/extr_critic_min": -0.28009140401175525, "train/extr_critic_std": 0.8929391422054984, "train/extr_return_normed_mag": 1.955844114224116, "train/extr_return_normed_max": 1.955844114224116, "train/extr_return_normed_mean": 0.3503392007992123, "train/extr_return_normed_min": -0.18843225931579416, "train/extr_return_normed_std": 0.36061328039927915, "train/extr_return_rate": 0.44537614872961334, "train/extr_return_raw_mag": 4.9383419553438825, "train/extr_return_raw_max": 4.9383419553438825, "train/extr_return_raw_mean": 0.766057793163892, "train/extr_return_raw_min": -0.63379679665421, "train/extr_return_raw_std": 0.9370558419913957, "train/extr_reward_mag": 1.003892477714654, "train/extr_reward_max": 1.003892477714654, "train/extr_reward_mean": 0.01752798239502943, "train/extr_reward_min": -0.36349312193465955, "train/extr_reward_std": 0.11697755037157824, "train/image_loss_mean": 15.603291814977473, "train/image_loss_std": 17.67480239723668, "train/model_loss_mean": 23.27654400738803, "train/model_loss_std": 21.36496712222244, "train/model_opt_grad_norm": 95.51466791557543, "train/model_opt_grad_steps": 7234.431818181818, "train/model_opt_loss": 14984.868630149147, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 643.939393939394, "train/policy_entropy_mag": 2.5277866432161042, "train/policy_entropy_max": 2.5277866432161042, "train/policy_entropy_mean": 0.757628831447977, "train/policy_entropy_min": 0.0793773400399721, "train/policy_entropy_std": 0.6283010750105886, "train/policy_logprob_mag": 7.438339110576745, "train/policy_logprob_max": -0.00945636878410975, "train/policy_logprob_mean": -0.7569101592808058, "train/policy_logprob_min": -7.438339110576745, "train/policy_logprob_std": 1.207718090577559, "train/policy_randomness_mag": 0.8921977543469631, "train/policy_randomness_max": 0.8921977543469631, "train/policy_randomness_mean": 0.26740973171862686, "train/policy_randomness_min": 0.028016717667042307, "train/policy_randomness_std": 0.2217627079649405, "train/post_ent_mag": 49.407440561236754, "train/post_ent_max": 49.407440561236754, "train/post_ent_mean": 35.138068314754605, "train/post_ent_min": 17.82462731997172, "train/post_ent_std": 5.586809989177819, "train/prior_ent_mag": 61.29685760266853, "train/prior_ent_max": 61.29685760266853, "train/prior_ent_mean": 48.010589888601594, "train/prior_ent_min": 20.74618248506026, "train/prior_ent_std": 7.859120972228773, "train/rep_loss_mean": 12.696272199804133, "train/rep_loss_std": 8.632597666798215, "train/reward_avg": 0.01680501291852896, "train/reward_loss_mean": 0.054999874481423336, "train/reward_loss_std": 0.27877876501191745, "train/reward_max_data": 1.006818183443763, "train/reward_max_pred": 1.002261693730499, "train/reward_neg_acc": 0.9932926107536663, "train/reward_neg_loss": 0.03377049242738973, "train/reward_pos_acc": 0.9417348138310693, "train/reward_pos_loss": 1.000870648658637, "train/reward_pred": 0.016186344065124904, "train/reward_rate": 0.02200964725378788, "train_stats/sum_log_reward": 4.526229442143049, "train_stats/max_log_achievement_collect_drink": 5.0, "train_stats/max_log_achievement_collect_sapling": 2.5163934426229506, "train_stats/max_log_achievement_collect_wood": 2.5901639344262297, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.18032786885245902, "train_stats/max_log_achievement_eat_cow": 0.09016393442622951, "train_stats/max_log_achievement_make_wood_pickaxe": 0.05737704918032787, "train_stats/max_log_achievement_make_wood_sword": 0.16393442622950818, "train_stats/max_log_achievement_place_plant": 2.3934426229508197, "train_stats/max_log_achievement_place_table": 0.819672131147541, "train_stats/max_log_achievement_wake_up": 1.8032786885245902, "train_stats/mean_log_entropy": 0.7464223276884829, "train_stats/max_log_achievement_collect_stone": 0.00847457627118644, "eval_stats/sum_log_reward": 4.162499904632568, "eval_stats/max_log_achievement_collect_drink": 2.6875, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_table": 0.8125, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.147251820540987e-05, "report/cont_loss_std": 0.0009549710084684193, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.4196320737246424e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.152328256168403e-05, "report/cont_pred": 0.9970294237136841, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 14.336896896362305, "report/dyn_loss_std": 8.877510070800781, "report/image_loss_mean": 14.358041763305664, "report/image_loss_std": 15.822230339050293, "report/model_loss_mean": 23.00436019897461, "report/model_loss_std": 19.67182731628418, "report/post_ent_mag": 48.70545959472656, "report/post_ent_max": 48.70545959472656, "report/post_ent_mean": 34.800819396972656, "report/post_ent_min": 20.75302505493164, "report/post_ent_std": 5.42389440536499, "report/prior_ent_mag": 62.016273498535156, "report/prior_ent_max": 62.016273498535156, "report/prior_ent_mean": 49.14300537109375, "report/prior_ent_min": 21.44464874267578, "report/prior_ent_std": 8.556160926818848, "report/rep_loss_mean": 14.336896896362305, "report/rep_loss_std": 8.877510070800781, "report/reward_avg": 0.02041015587747097, "report/reward_loss_mean": 0.04413864016532898, "report/reward_loss_std": 0.231297105550766, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.000286340713501, "report/reward_neg_acc": 0.9950000643730164, "report/reward_neg_loss": 0.024765536189079285, "report/reward_pos_acc": 0.9583333730697632, "report/reward_pos_loss": 0.8513513803482056, "report/reward_pred": 0.018854938447475433, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 5.924388915445888e-06, "eval/cont_loss_std": 0.0001466401299694553, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000899191596545279, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.595524268959707e-07, "eval/cont_pred": 0.9941452741622925, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 16.363304138183594, "eval/dyn_loss_std": 8.714280128479004, "eval/image_loss_mean": 19.839111328125, "eval/image_loss_std": 20.545795440673828, "eval/model_loss_mean": 29.822654724121094, "eval/model_loss_std": 23.797876358032227, "eval/post_ent_mag": 50.456783294677734, "eval/post_ent_max": 50.456783294677734, "eval/post_ent_mean": 34.189476013183594, "eval/post_ent_min": 18.643930435180664, "eval/post_ent_std": 5.633788108825684, "eval/prior_ent_mag": 62.016273498535156, "eval/prior_ent_max": 62.016273498535156, "eval/prior_ent_mean": 47.1870002746582, "eval/prior_ent_min": 22.613513946533203, "eval/prior_ent_std": 8.611376762390137, "eval/rep_loss_mean": 16.363304138183594, "eval/rep_loss_std": 8.714280128479004, "eval/reward_avg": 0.013281249441206455, "eval/reward_loss_mean": 0.16555418074131012, "eval/reward_loss_std": 0.990654706954956, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000038146972656, "eval/reward_neg_acc": 0.9980120062828064, "eval/reward_neg_loss": 0.07058003544807434, "eval/reward_pos_acc": 0.3333333432674408, "eval/reward_pos_loss": 5.4735541343688965, "eval/reward_pred": -0.0007953002350404859, "eval/reward_rate": 0.017578125, "replay/size": 127585.0, "replay/inserts": 21184.0, "replay/samples": 21184.0, "replay/insert_wait_avg": 1.4860982080960922e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 1.0428449358464729e-06, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26152.0, "eval_replay/inserts": 3432.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3813272222772344e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.043081283569336e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0213465690613, "timer/env.step_count": 2648.0, "timer/env.step_total": 276.4461600780487, "timer/env.step_frac": 0.27644025902696806, "timer/env.step_avg": 0.10439809670621175, "timer/env.step_min": 0.0242767333984375, "timer/env.step_max": 4.250763654708862, "timer/replay._sample_count": 21184.0, "timer/replay._sample_total": 12.041046142578125, "timer/replay._sample_frac": 0.012040789113041772, "timer/replay._sample_avg": 0.000568402857938922, "timer/replay._sample_min": 0.0004284381866455078, "timer/replay._sample_max": 0.012533903121948242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3077.0, "timer/agent.policy_total": 56.25517010688782, "timer/agent.policy_frac": 0.05625396927764766, "timer/agent.policy_avg": 0.018282473222907967, "timer/agent.policy_min": 0.009917497634887695, "timer/agent.policy_max": 0.1337735652923584, "timer/dataset_train_count": 1324.0, "timer/dataset_train_total": 0.16752958297729492, "timer/dataset_train_frac": 0.00016752600687181966, "timer/dataset_train_avg": 0.00012653291765656716, "timer/dataset_train_min": 0.00010585784912109375, "timer/dataset_train_max": 0.0004374980926513672, "timer/agent.train_count": 1324.0, "timer/agent.train_total": 600.3545582294464, "timer/agent.train_frac": 0.6003417429929693, "timer/agent.train_avg": 0.4534399986627239, "timer/agent.train_min": 0.43917298316955566, "timer/agent.train_max": 1.4169044494628906, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4765911102294922, "timer/agent.report_frac": 0.0004765809368616102, "timer/agent.report_avg": 0.2382955551147461, "timer/agent.report_min": 0.23148703575134277, "timer/agent.report_max": 0.24510407447814941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.266334533691406e-05, "timer/dataset_eval_frac": 3.266264810144064e-08, "timer/dataset_eval_avg": 3.266334533691406e-05, "timer/dataset_eval_min": 3.266334533691406e-05, "timer/dataset_eval_max": 3.266334533691406e-05, "fps": 21.18325750336603}
{"step": 128216, "time": 6351.836254835129, "episode/length": 417.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9784688995215312, "episode/intrinsic_return": 0.0}
{"step": 128456, "time": 6361.526054143906, "episode/length": 145.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 128568, "time": 6366.859976530075, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 128944, "time": 6381.853718042374, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 129160, "time": 6391.262075424194, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 129424, "time": 6402.027999639511, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 129680, "time": 6412.388243436813, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 129704, "time": 6414.644984722137, "episode/length": 221.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6441.543983459473, "eval_episode/length": 36.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.972972972972973}
{"step": 130000, "time": 6448.180097103119, "eval_episode/length": 145.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 130000, "time": 6450.484625339508, "eval_episode/length": 159.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.99375}
{"step": 130000, "time": 6452.950698852539, "eval_episode/length": 179.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 130000, "time": 6454.533310890198, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 130000, "time": 6456.449664592743, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 130000, "time": 6458.516863584518, "eval_episode/length": 38.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 130000, "time": 6460.635000228882, "eval_episode/length": 208.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 130136, "time": 6465.04709148407, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 130136, "time": 6465.0647752285, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9325842696629213, "episode/intrinsic_return": 0.0}
{"step": 130152, "time": 6468.931868553162, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 130200, "time": 6472.383582115173, "episode/length": 265.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9849624060150376, "episode/intrinsic_return": 0.0}
{"step": 130824, "time": 6495.098964214325, "episode/length": 234.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 130904, "time": 6499.343852519989, "episode/length": 217.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 131016, "time": 6504.908061504364, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 131112, "time": 6511.158169269562, "episode/length": 178.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 131280, "time": 6518.666636228561, "episode/length": 142.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 131472, "time": 6526.839621067047, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 131680, "time": 6535.677556991577, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 132104, "time": 6551.399529695511, "episode/length": 159.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 132200, "time": 6556.231304883957, "episode/length": 147.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 132344, "time": 6562.895440340042, "episode/length": 179.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 132384, "time": 6566.083011865616, "episode/length": 272.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 132408, "time": 6568.3799731731415, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 132672, "time": 6579.117800235748, "episode/length": 149.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 132824, "time": 6585.65682554245, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 133344, "time": 6605.1479575634, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 133504, "time": 6612.114345550537, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 133672, "time": 6619.3007600307465, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 133848, "time": 6626.945925951004, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 133984, "time": 6634.152072668076, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 134104, "time": 6639.80002450943, "episode/length": 219.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 134208, "time": 6645.661735057831, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 134416, "time": 6654.49655008316, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 134776, "time": 6668.120928287506, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 134872, "time": 6672.939475536346, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 135400, "time": 6692.601007699966, "episode/length": 176.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 135408, "time": 6694.763857603073, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 135448, "time": 6697.464656829834, "episode/length": 167.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 135464, "time": 6699.626139163971, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 135736, "time": 6710.4841322898865, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 136304, "time": 6731.72723531723, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 136328, "time": 6733.942743778229, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 136784, "time": 6751.589496612549, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 136920, "time": 6757.653603792191, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 137072, "time": 6764.622803926468, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 137184, "time": 6770.0629823207855, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 137400, "time": 6778.979731082916, "episode/length": 327.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9969512195121951, "episode/intrinsic_return": 0.0}
{"step": 137520, "time": 6784.98846745491, "episode/length": 258.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 137712, "time": 6793.199691295624, "episode/length": 38.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 137800, "time": 6797.565937995911, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 137952, "time": 6804.874955654144, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 138136, "time": 6812.436668872833, "episode/length": 228.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 138584, "time": 6829.120446920395, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 138616, "time": 6832.023583650589, "episode/length": 211.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 138656, "time": 6835.146482229233, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 139008, "time": 6848.748864889145, "episode/length": 161.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 139208, "time": 6856.942851781845, "episode/length": 156.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 139616, "time": 6874.108983516693, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 139800, "time": 6881.7241196632385, "episode/length": 249.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 140080, "time": 6893.147761821747, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6913.824130296707, "eval_episode/length": 136.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9635036496350365}
{"step": 140088, "time": 6915.745176553726, "eval_episode/length": 144.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.993103448275862}
{"step": 140088, "time": 6917.435304403305, "eval_episode/length": 147.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 140088, "time": 6919.578649759293, "eval_episode/length": 158.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9559748427672956}
{"step": 140088, "time": 6921.465471982956, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 140088, "time": 6923.6019032001495, "eval_episode/length": 172.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.976878612716763}
{"step": 140088, "time": 6926.00682759285, "eval_episode/length": 191.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 140088, "time": 6928.749675035477, "eval_episode/length": 217.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 140232, "time": 6933.594411373138, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 140280, "time": 6936.735900878906, "episode/length": 436.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 140424, "time": 6943.157538175583, "episode/length": 225.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 140432, "time": 6945.256177186966, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 140448, "time": 6947.3183035850525, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 141248, "time": 6976.034864187241, "episode/length": 99.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 141304, "time": 6979.2966339588165, "episode/length": 187.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 141504, "time": 6988.125262498856, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 141608, "time": 6993.100166797638, "episode/length": 44.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 141912, "time": 7004.973159790039, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 141920, "time": 7006.9039788246155, "episode/length": 204.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 141976, "time": 7010.190641403198, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 142376, "time": 7025.317440509796, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754098360655737, "episode/intrinsic_return": 0.0}
{"step": 142952, "time": 7046.4626479148865, "episode/length": 180.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 142952, "time": 7046.474425315857, "episode/length": 416.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9808153477218226, "episode/intrinsic_return": 0.0}
{"step": 142968, "time": 7050.327794551849, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 143160, "time": 7058.3458795547485, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 143160, "time": 7058.355424165726, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 143832, "time": 7084.646632194519, "episode/length": 231.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 143936, "time": 7089.943599462509, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9828178694158075, "episode/intrinsic_return": 0.0}
{"step": 144256, "time": 7102.497684955597, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 144272, "time": 7104.703470468521, "episode/length": 236.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 144312, "time": 7107.382863521576, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 144672, "time": 7121.367319583893, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 144744, "time": 7125.122458457947, "episode/length": 221.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 144928, "time": 7133.292285919189, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 145112, "time": 7140.87871837616, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 145232, "time": 7146.719606399536, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 145376, "time": 7153.203476905823, "episode/length": 137.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 145544, "time": 7160.241358757019, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 145816, "time": 7171.217981100082, "episode/length": 54.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 146064, "time": 7181.452131032944, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 146120, "time": 7184.697259426117, "episode/length": 232.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 146336, "time": 7194.251914024353, "episode/length": 207.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 146608, "time": 7205.124525785446, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 147024, "time": 7221.2201998233795, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 147200, "time": 7228.960226774216, "episode/length": 245.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 147224, "time": 7231.157666683197, "episode/length": 286.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9860627177700348, "episode/intrinsic_return": 0.0}
{"step": 147376, "time": 7238.422840118408, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 147704, "time": 7252.640115737915, "episode/length": 269.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 147776, "time": 7256.911272764206, "episode/length": 213.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 148104, "time": 7269.402720451355, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 148160, "time": 7273.141527175903, "episode/length": 141.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 148168, "time": 7274.774156093597, "episode/length": 194.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 148192, "time": 7277.5015614032745, "episode/length": 120.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9586776859504132, "episode/intrinsic_return": 0.0}
{"step": 148504, "time": 7289.675779104233, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 148888, "time": 7304.1091837883, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 149072, "time": 7312.46040725708, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 149200, "time": 7318.44385933876, "episode/length": 86.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 149432, "time": 7327.778946399689, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 149456, "time": 7330.4383289813995, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 149512, "time": 7333.783232212067, "episode/length": 164.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 149592, "time": 7338.194086790085, "episode/length": 235.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 149592, "time": 7338.203619480133, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 149705, "time": 7347.766991138458, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.574044171501608, "train/action_min": 0.0, "train/action_std": 3.8569771103999195, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04783637683345553, "train/actor_opt_grad_steps": 8585.0, "train/actor_opt_loss": 11.943093298112645, "train/adv_mag": 0.8605394525563016, "train/adv_max": 0.8504993937471333, "train/adv_mean": 0.007165474105042502, "train/adv_min": -0.5162597305196173, "train/adv_std": 0.08455889891175662, "train/cont_avg": 0.9947509765625, "train/cont_loss_mean": 0.0005128068514191309, "train/cont_loss_std": 0.01419439640774305, "train/cont_neg_acc": 0.9896501789198202, "train/cont_neg_loss": 0.04505448975754606, "train/cont_pos_acc": 0.999913336161305, "train/cont_pos_loss": 0.0002953538149674806, "train/cont_pred": 0.9946850809980842, "train/cont_rate": 0.9947509765625, "train/dyn_loss_mean": 13.476690285346088, "train/dyn_loss_std": 8.89815885179183, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1137030685649199, "train/extr_critic_critic_opt_grad_steps": 8585.0, "train/extr_critic_critic_opt_loss": 15466.149737189799, "train/extr_critic_mag": 3.3855612137738396, "train/extr_critic_max": 3.3855612137738396, "train/extr_critic_mean": 0.8016359240693205, "train/extr_critic_min": -0.24192112771903768, "train/extr_critic_std": 0.9277913535342497, "train/extr_return_normed_mag": 1.8361705629264606, "train/extr_return_normed_max": 1.8361705629264606, "train/extr_return_normed_mean": 0.3343246500281727, "train/extr_return_normed_min": -0.17567068639704408, "train/extr_return_normed_std": 0.3517185599707505, "train/extr_return_rate": 0.44650354652720337, "train/extr_return_raw_mag": 4.962312154910144, "train/extr_return_raw_max": 4.962312154910144, "train/extr_return_raw_mean": 0.8214827747467686, "train/extr_return_raw_min": -0.5855961685233256, "train/extr_return_raw_std": 0.9700419587247512, "train/extr_reward_mag": 1.004220698686207, "train/extr_reward_max": 1.004220698686207, "train/extr_reward_mean": 0.018411373808596504, "train/extr_reward_min": -0.37459736974800334, "train/extr_reward_std": 0.12060959571424652, "train/image_loss_mean": 13.36085844741148, "train/image_loss_std": 15.324933465789346, "train/model_loss_mean": 21.500880017000085, "train/model_loss_std": 19.09074494417976, "train/model_opt_grad_norm": 96.82107327966129, "train/model_opt_grad_steps": 8573.22794117647, "train/model_opt_loss": 14495.001565372242, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 675.5514705882352, "train/policy_entropy_mag": 2.4481058734304764, "train/policy_entropy_max": 2.4481058734304764, "train/policy_entropy_mean": 0.712532286915709, "train/policy_entropy_min": 0.07937654162592747, "train/policy_entropy_std": 0.6133217303191915, "train/policy_logprob_mag": 7.438366307931788, "train/policy_logprob_max": -0.009456081309027094, "train/policy_logprob_mean": -0.7117941497879869, "train/policy_logprob_min": -7.438366307931788, "train/policy_logprob_std": 1.1847517393967684, "train/policy_randomness_mag": 0.8640739383066401, "train/policy_randomness_max": 0.8640739383066401, "train/policy_randomness_mean": 0.25149262543110285, "train/policy_randomness_min": 0.028016435804174226, "train/policy_randomness_std": 0.21647565636564703, "train/post_ent_mag": 51.07533673679127, "train/post_ent_max": 51.07533673679127, "train/post_ent_mean": 36.00858733233284, "train/post_ent_min": 19.38698008481194, "train/post_ent_std": 5.698533170363483, "train/prior_ent_mag": 62.29529908124138, "train/prior_ent_max": 62.29529908124138, "train/prior_ent_mean": 49.62483700583963, "train/prior_ent_min": 22.880951965556424, "train/prior_ent_std": 7.539944329682519, "train/rep_loss_mean": 13.476690285346088, "train/rep_loss_std": 8.89815885179183, "train/reward_avg": 0.01849365234888597, "train/reward_loss_mean": 0.053494641146458244, "train/reward_loss_std": 0.26934091100359664, "train/reward_max_data": 1.0058823543436386, "train/reward_max_pred": 1.0020261012455995, "train/reward_neg_acc": 0.9938589610597667, "train/reward_neg_loss": 0.03133017508833505, "train/reward_pos_acc": 0.9448743813178119, "train/reward_pos_loss": 0.9864834012354121, "train/reward_pred": 0.017473868310095415, "train/reward_rate": 0.02339441636029412, "train_stats/sum_log_reward": 4.778260791820029, "train_stats/max_log_achievement_collect_drink": 4.886956521739131, "train_stats/max_log_achievement_collect_sapling": 2.9391304347826086, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 2.878260869565217, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3217391304347826, "train_stats/max_log_achievement_eat_cow": 0.06956521739130435, "train_stats/max_log_achievement_make_wood_pickaxe": 0.02608695652173913, "train_stats/max_log_achievement_make_wood_sword": 0.19130434782608696, "train_stats/max_log_achievement_place_plant": 2.747826086956522, "train_stats/max_log_achievement_place_table": 0.991304347826087, "train_stats/max_log_achievement_wake_up": 2.2956521739130435, "train_stats/mean_log_entropy": 0.690440815039303, "eval_stats/sum_log_reward": 4.162499934434891, "eval_stats/max_log_achievement_collect_drink": 3.4375, "eval_stats/max_log_achievement_collect_sapling": 2.1875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.0625, "eval_stats/max_log_achievement_place_table": 0.875, "eval_stats/max_log_achievement_wake_up": 2.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00016237016825471073, "report/cont_loss_std": 0.0022689744364470243, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.017198866233229637, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.877598545746878e-05, "report/cont_pred": 0.9951203465461731, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.762154579162598, "report/dyn_loss_std": 8.508056640625, "report/image_loss_mean": 12.948213577270508, "report/image_loss_std": 16.89273452758789, "report/model_loss_mean": 21.265594482421875, "report/model_loss_std": 20.253732681274414, "report/post_ent_mag": 49.58103942871094, "report/post_ent_max": 49.58103942871094, "report/post_ent_mean": 35.8983039855957, "report/post_ent_min": 21.130752563476562, "report/post_ent_std": 5.201289653778076, "report/prior_ent_mag": 63.19122314453125, "report/prior_ent_max": 63.19122314453125, "report/prior_ent_mean": 50.337318420410156, "report/prior_ent_min": 26.161659240722656, "report/prior_ent_std": 6.87497091293335, "report/rep_loss_mean": 13.762154579162598, "report/rep_loss_std": 8.508056640625, "report/reward_avg": 0.0205078125, "report/reward_loss_mean": 0.059926293790340424, "report/reward_loss_std": 0.2526043653488159, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.004732370376587, "report/reward_neg_acc": 0.9909819960594177, "report/reward_neg_loss": 0.03535204753279686, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 1.0031993389129639, "report/reward_pred": 0.01666555181145668, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.00022382356110028923, "eval/cont_loss_std": 0.005668333265930414, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 4.192200140096247e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0002243580383947119, "eval/cont_pred": 0.9968618750572205, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 11.556777000427246, "eval/dyn_loss_std": 8.620323181152344, "eval/image_loss_mean": 8.713897705078125, "eval/image_loss_std": 9.915593147277832, "eval/model_loss_mean": 15.702261924743652, "eval/model_loss_std": 12.879721641540527, "eval/post_ent_mag": 49.03855514526367, "eval/post_ent_max": 49.03855514526367, "eval/post_ent_mean": 36.62864303588867, "eval/post_ent_min": 18.961204528808594, "eval/post_ent_std": 6.005804061889648, "eval/prior_ent_mag": 63.19122314453125, "eval/prior_ent_max": 63.19122314453125, "eval/prior_ent_mean": 46.790985107421875, "eval/prior_ent_min": 19.891464233398438, "eval/prior_ent_std": 6.798834800720215, "eval/rep_loss_mean": 11.556777000427246, "eval/rep_loss_std": 8.620323181152344, "eval/reward_avg": 0.00546875037252903, "eval/reward_loss_mean": 0.054073676466941833, "eval/reward_loss_std": 0.4539373815059662, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0020780563354492, "eval/reward_neg_acc": 0.9960552453994751, "eval/reward_neg_loss": 0.0312747023999691, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 2.365889549255371, "eval/reward_pred": 0.003236335702240467, "eval/reward_rate": 0.009765625, "replay/size": 149201.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.4983773849171061e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.368208935311951e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 29568.0, "eval_replay/inserts": 3416.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3180722676618874e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2632632255554, "timer/env.step_count": 2702.0, "timer/env.step_total": 264.5612635612488, "timer/env.step_frac": 0.2644916326409073, "timer/env.step_avg": 0.09791312493014388, "timer/env.step_min": 0.02416706085205078, "timer/env.step_max": 4.588179111480713, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.797746419906616, "timer/replay._sample_frac": 0.011794641324587235, "timer/replay._sample_avg": 0.0005457876767166273, "timer/replay._sample_min": 0.0003790855407714844, "timer/replay._sample_max": 0.01085352897644043, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3129.0, "timer/agent.policy_total": 55.46258330345154, "timer/agent.policy_frac": 0.05544798588783616, "timer/agent.policy_avg": 0.017725338224177545, "timer/agent.policy_min": 0.009811639785766602, "timer/agent.policy_max": 0.21849370002746582, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.1573929786682129, "timer/dataset_train_frac": 0.00015735155379061581, "timer/dataset_train_avg": 0.00011650109449904729, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.00043582916259765625, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 613.785413980484, "timer/agent.train_frac": 0.6136238693813528, "timer/agent.train_avg": 0.4543193293711947, "timer/agent.train_min": 0.4399147033691406, "timer/agent.train_max": 1.5832202434539795, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4674406051635742, "timer/agent.report_frac": 0.00046731757763072843, "timer/agent.report_avg": 0.2337203025817871, "timer/agent.report_min": 0.22250723838806152, "timer/agent.report_max": 0.2449333667755127, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.314018249511719e-05, "timer/dataset_eval_frac": 3.3131460200037566e-08, "timer/dataset_eval_avg": 3.314018249511719e-05, "timer/dataset_eval_min": 3.314018249511719e-05, "timer/dataset_eval_max": 3.314018249511719e-05, "fps": 21.609974664828435}
{"step": 149864, "time": 7353.012033700943, "episode/length": 219.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7382.180491685867, "eval_episode/length": 160.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9627329192546584}
{"step": 150072, "time": 7383.818077802658, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 150072, "time": 7385.608551740646, "eval_episode/length": 168.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9644970414201184}
{"step": 150072, "time": 7387.297882795334, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 150072, "time": 7389.179255962372, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 150072, "time": 7392.358320474625, "eval_episode/length": 212.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 150072, "time": 7394.108623504639, "eval_episode/length": 216.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9769585253456221}
{"step": 150072, "time": 7397.459132194519, "eval_episode/length": 78.0, "eval_episode/score": 1.1000000312924385, "eval_episode/reward_rate": 0.9873417721518988}
{"step": 150424, "time": 7409.511188030243, "episode/length": 191.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 150544, "time": 7415.465337514877, "episode/length": 135.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 150632, "time": 7419.865404367447, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 150648, "time": 7422.016409397125, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 150672, "time": 7424.621756076813, "episode/length": 154.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 150800, "time": 7430.501125335693, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 150880, "time": 7435.079966545105, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 150968, "time": 7439.51357293129, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 151088, "time": 7445.499783754349, "episode/length": 56.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 151336, "time": 7455.304269790649, "episode/length": 85.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 151784, "time": 7472.149282455444, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 151848, "time": 7475.901999473572, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 152040, "time": 7484.09651350975, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 152256, "time": 7493.3752772808075, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 152416, "time": 7500.4073033332825, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 152416, "time": 7500.416648387909, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 152600, "time": 7509.767351388931, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 153032, "time": 7525.943137407303, "episode/length": 268.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 153096, "time": 7529.704848527908, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 153272, "time": 7537.338585138321, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 153736, "time": 7554.850748062134, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 153832, "time": 7559.791605949402, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 154008, "time": 7567.311168909073, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 154040, "time": 7570.06405043602, "episode/length": 249.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 154184, "time": 7576.469088077545, "episode/length": 197.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 154496, "time": 7588.944966316223, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 154816, "time": 7601.428064107895, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 155096, "time": 7612.374515295029, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 155472, "time": 7627.057042121887, "episode/length": 296.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 155536, "time": 7630.824240684509, "episode/length": 212.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 155856, "time": 7644.792003154755, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617224880382775, "episode/intrinsic_return": 0.0}
{"step": 156056, "time": 7652.871211051941, "episode/length": 255.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 156176, "time": 7658.708794116974, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 156312, "time": 7664.615914821625, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 156560, "time": 7675.035361766815, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 156560, "time": 7675.0454823970795, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 156744, "time": 7684.316030263901, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 156952, "time": 7693.075443267822, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 157112, "time": 7700.19880771637, "episode/length": 196.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 157168, "time": 7704.0270228385925, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 157288, "time": 7709.482510566711, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 157480, "time": 7717.519140005112, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 158136, "time": 7741.40060377121, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 158272, "time": 7747.884301662445, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 158392, "time": 7753.3698925971985, "episode/length": 228.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 158432, "time": 7756.540025472641, "episode/length": 184.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 158488, "time": 7759.882515907288, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 158776, "time": 7771.4130980968475, "episode/length": 253.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 158840, "time": 7775.293010473251, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 158848, "time": 7777.353894233704, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 159328, "time": 7795.318123340607, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 159432, "time": 7800.142082691193, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 159880, "time": 7816.833066940308, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9613259668508287, "episode/intrinsic_return": 0.0}
{"step": 159896, "time": 7819.048979759216, "episode/length": 175.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 159944, "time": 7822.386066913605, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7848.79465508461, "eval_episode/length": 142.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.972027972027972}
{"step": 160056, "time": 7851.949559688568, "eval_episode/length": 165.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.963855421686747}
{"step": 160056, "time": 7853.709343910217, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 160056, "time": 7855.258785009384, "eval_episode/length": 170.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 160056, "time": 7856.924966812134, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 160056, "time": 7859.729617118835, "eval_episode/length": 199.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 160056, "time": 7861.9648332595825, "eval_episode/length": 69.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9285714285714286}
{"step": 160056, "time": 7864.3883311748505, "eval_episode/length": 230.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9826839826839827}
{"step": 160104, "time": 7866.004870891571, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 160136, "time": 7868.714529275894, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 160216, "time": 7872.887189626694, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 160592, "time": 7887.487739562988, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 161208, "time": 7909.656258106232, "episode/length": 157.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 161392, "time": 7917.94776558876, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 161392, "time": 7917.956348419189, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 161488, "time": 7924.711010932922, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 161552, "time": 7928.507656097412, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 161760, "time": 7937.0741930007935, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 161864, "time": 7942.304238319397, "episode/length": 245.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715447154471545, "episode/intrinsic_return": 0.0}
{"step": 161904, "time": 7945.540143489838, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 162480, "time": 7966.582252979279, "episode/length": 158.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 162600, "time": 7972.129554271698, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 162728, "time": 7978.271674871445, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 163000, "time": 7988.992593288422, "episode/length": 141.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 163136, "time": 7995.49994635582, "episode/length": 217.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 163288, "time": 8002.096205949783, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 163520, "time": 8011.816455125809, "episode/length": 245.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 163536, "time": 8013.934967756271, "episode/length": 131.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 163680, "time": 8020.47642660141, "episode/length": 221.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 163864, "time": 8029.431191921234, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 164480, "time": 8052.271477222443, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 164568, "time": 8056.6720452308655, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 164704, "time": 8063.232398033142, "episode/length": 246.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 164768, "time": 8067.020224094391, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 164872, "time": 8072.505469560623, "episode/length": 168.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 165104, "time": 8082.1630210876465, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 165536, "time": 8098.394460201263, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 165544, "time": 8100.019275665283, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 165592, "time": 8103.221977233887, "episode/length": 102.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 165608, "time": 8105.342999696732, "episode/length": 140.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 166184, "time": 8126.776539564133, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 166216, "time": 8129.6565482616425, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 166376, "time": 8136.626456260681, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 166488, "time": 8142.002786159515, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 166920, "time": 8158.366232872009, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 166968, "time": 8161.637768268585, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 167216, "time": 8171.933658361435, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 167400, "time": 8179.557292699814, "episode/length": 225.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 167840, "time": 8196.571342229843, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 167960, "time": 8201.948846817017, "episode/length": 197.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 168000, "time": 8205.016907453537, "episode/length": 226.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 168384, "time": 8219.810429811478, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 168472, "time": 8224.125336647034, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 168592, "time": 8229.948081493378, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9530201342281879, "episode/intrinsic_return": 0.0}
{"step": 168696, "time": 8234.964922904968, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 168792, "time": 8239.739953517914, "episode/length": 39.0, "episode/score": 1.1000000312924385, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 168856, "time": 8243.771269798279, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9864864864864865, "episode/intrinsic_return": 0.0}
{"step": 169240, "time": 8258.449548482895, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 169384, "time": 8264.898773908615, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 169512, "time": 8270.7513525486, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 169696, "time": 8278.917762517929, "episode/length": 163.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 169792, "time": 8283.820077180862, "episode/length": 136.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 169928, "time": 8289.920450210571, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8315.393008947372, "eval_episode/length": 153.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 170040, "time": 8318.24694609642, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 170040, "time": 8320.260826349258, "eval_episode/length": 189.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968421052631579}
{"step": 170040, "time": 8322.28345155716, "eval_episode/length": 45.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 170040, "time": 8324.096909999847, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 170040, "time": 8326.036661863327, "eval_episode/length": 211.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 170040, "time": 8327.743888378143, "eval_episode/length": 213.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 170040, "time": 8329.437448263168, "eval_episode/length": 37.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 170240, "time": 8336.487753868103, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 170288, "time": 8339.729631900787, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 170465, "time": 8347.795110225677, "train_stats/sum_log_reward": 4.914159219876855, "train_stats/max_log_achievement_collect_drink": 2.920353982300885, "train_stats/max_log_achievement_collect_sapling": 3.106194690265487, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.353982300884956, "train_stats/max_log_achievement_defeat_skeleton": 0.008849557522123894, "train_stats/max_log_achievement_defeat_zombie": 0.30973451327433627, "train_stats/max_log_achievement_eat_cow": 0.061946902654867256, "train_stats/max_log_achievement_make_wood_pickaxe": 0.035398230088495575, "train_stats/max_log_achievement_make_wood_sword": 0.2920353982300885, "train_stats/max_log_achievement_place_plant": 2.8672566371681416, "train_stats/max_log_achievement_place_table": 1.1061946902654867, "train_stats/max_log_achievement_wake_up": 2.1769911504424777, "train_stats/mean_log_entropy": 0.6265594795741866, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.738963992096657, "train/action_min": 0.0, "train/action_std": 3.8554597085760545, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04664223941490632, "train/actor_opt_grad_steps": 9910.0, "train/actor_opt_loss": 13.077526667321376, "train/adv_mag": 0.8175334369027337, "train/adv_max": 0.8079846203327179, "train/adv_mean": 0.006493297404187277, "train/adv_min": -0.5004317291485246, "train/adv_std": 0.08135493189211963, "train/cont_avg": 0.9941103439922481, "train/cont_loss_mean": 0.0004981098105134137, "train/cont_loss_std": 0.013647073224346122, "train/cont_neg_acc": 0.9846160961676014, "train/cont_neg_loss": 0.062084207507976406, "train/cont_pos_acc": 0.9999390461648158, "train/cont_pos_loss": 0.00016295235896555195, "train/cont_pred": 0.9941128201262895, "train/cont_rate": 0.9941103439922481, "train/dyn_loss_mean": 13.902243614196777, "train/dyn_loss_std": 9.147025019623513, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1471506223198056, "train/extr_critic_critic_opt_grad_steps": 9910.0, "train/extr_critic_critic_opt_loss": 15603.442980862403, "train/extr_critic_mag": 3.805487484894982, "train/extr_critic_max": 3.805487484894982, "train/extr_critic_mean": 1.0073980605879496, "train/extr_critic_min": -0.2063055066175239, "train/extr_critic_std": 1.0155535848565804, "train/extr_return_normed_mag": 1.801976438640624, "train/extr_return_normed_max": 1.801976438640624, "train/extr_return_normed_mean": 0.34889852677204813, "train/extr_return_normed_min": -0.1758470675048902, "train/extr_return_normed_std": 0.34751913228700326, "train/extr_return_rate": 0.5399623781211617, "train/extr_return_raw_mag": 5.4472147956375006, "train/extr_return_raw_max": 5.4472147956375006, "train/extr_return_raw_mean": 1.0271652872248214, "train/extr_return_raw_min": -0.5692966876103897, "train/extr_return_raw_std": 1.0573490622431734, "train/extr_reward_mag": 1.0046694888625034, "train/extr_reward_max": 1.0046694888625034, "train/extr_reward_mean": 0.02080289575148576, "train/extr_reward_min": -0.38593452475791756, "train/extr_reward_std": 0.1292493353171866, "train/image_loss_mean": 12.052587339120318, "train/image_loss_std": 14.728722276613693, "train/model_loss_mean": 20.447660697523013, "train/model_loss_std": 18.564439049062802, "train/model_opt_grad_norm": 89.32042545080185, "train/model_opt_grad_steps": 9897.031007751939, "train/model_opt_loss": 14508.471853803294, "train/model_opt_model_opt_grad_overflow": 0.007751937984496124, "train/model_opt_model_opt_grad_scale": 702.5193798449612, "train/policy_entropy_mag": 2.399245304654735, "train/policy_entropy_max": 2.399245304654735, "train/policy_entropy_mean": 0.6686405206835547, "train/policy_entropy_min": 0.07937612569378327, "train/policy_entropy_std": 0.5834173109642294, "train/policy_logprob_mag": 7.438375280809033, "train/policy_logprob_max": -0.009456003611806289, "train/policy_logprob_mean": -0.6693108851133391, "train/policy_logprob_min": -7.438375280809033, "train/policy_logprob_std": 1.1566350145857462, "train/policy_randomness_mag": 0.8468283059061036, "train/policy_randomness_max": 0.8468283059061036, "train/policy_randomness_mean": 0.23600076127421948, "train/policy_randomness_min": 0.028016289031898328, "train/policy_randomness_std": 0.20592071000457735, "train/post_ent_mag": 52.30158387413321, "train/post_ent_max": 52.30158387413321, "train/post_ent_mean": 36.38740607564763, "train/post_ent_min": 20.24189489201982, "train/post_ent_std": 5.892696595007135, "train/prior_ent_mag": 63.03190583221672, "train/prior_ent_max": 63.03190583221672, "train/prior_ent_mean": 50.43564987182617, "train/prior_ent_min": 24.665665471276572, "train/prior_ent_std": 7.362529222355333, "train/rep_loss_mean": 13.902243614196777, "train/rep_loss_std": 9.147025019623513, "train/reward_avg": 0.01924055222152956, "train/reward_loss_mean": 0.05322911877676036, "train/reward_loss_std": 0.2618725637132807, "train/reward_max_data": 1.0046511638996214, "train/reward_max_pred": 1.001940935157066, "train/reward_neg_acc": 0.9937520798786666, "train/reward_neg_loss": 0.031451887963700666, "train/reward_pos_acc": 0.9546985348989797, "train/reward_pos_loss": 0.9276057283083597, "train/reward_pred": 0.018614003411313706, "train/reward_rate": 0.024323219476744186, "eval_stats/sum_log_reward": 4.724999929467837, "eval_stats/max_log_achievement_collect_drink": 2.2916666666666665, "eval_stats/max_log_achievement_collect_sapling": 3.5416666666666665, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.2916666666666665, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.2916666666666667, "eval_stats/max_log_achievement_place_plant": 3.375, "eval_stats/max_log_achievement_place_table": 1.1666666666666667, "eval_stats/max_log_achievement_wake_up": 1.8333333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 6.206509715411812e-05, "report/cont_loss_std": 0.0010526461992412806, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002123426180332899, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 4.787676880368963e-05, "report/cont_pred": 0.9931313991546631, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 12.24217700958252, "report/dyn_loss_std": 8.786707878112793, "report/image_loss_mean": 8.561275482177734, "report/image_loss_std": 11.562235832214355, "report/model_loss_mean": 15.962101936340332, "report/model_loss_std": 15.1962890625, "report/post_ent_mag": 51.336151123046875, "report/post_ent_max": 51.336151123046875, "report/post_ent_mean": 37.3905029296875, "report/post_ent_min": 22.083297729492188, "report/post_ent_std": 5.847919940948486, "report/prior_ent_mag": 64.18472290039062, "report/prior_ent_max": 64.18472290039062, "report/prior_ent_mean": 49.54652404785156, "report/prior_ent_min": 25.415796279907227, "report/prior_ent_std": 6.692694664001465, "report/rep_loss_mean": 12.24217700958252, "report/rep_loss_std": 8.786707878112793, "report/reward_avg": 0.01523437537252903, "report/reward_loss_mean": 0.05545821040868759, "report/reward_loss_std": 0.28741806745529175, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0003547668457031, "report/reward_neg_acc": 0.9950149655342102, "report/reward_neg_loss": 0.036629438400268555, "report/reward_pos_acc": 0.9047619104385376, "report/reward_pos_loss": 0.9547560811042786, "report/reward_pred": 0.013562314212322235, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0022007618099451065, "eval/cont_loss_std": 0.06416255235671997, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001507712877355516, "eval/cont_pos_acc": 0.9990177154541016, "eval/cont_pos_loss": 0.0022048463579267263, "eval/cont_pred": 0.9931190013885498, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 14.151192665100098, "eval/dyn_loss_std": 8.775379180908203, "eval/image_loss_mean": 17.609785079956055, "eval/image_loss_std": 18.590749740600586, "eval/model_loss_mean": 26.183786392211914, "eval/model_loss_std": 21.22507095336914, "eval/post_ent_mag": 50.06386947631836, "eval/post_ent_max": 50.06386947631836, "eval/post_ent_mean": 38.84599685668945, "eval/post_ent_min": 20.721132278442383, "eval/post_ent_std": 5.626608371734619, "eval/prior_ent_mag": 64.18472290039062, "eval/prior_ent_max": 64.18472290039062, "eval/prior_ent_mean": 50.635623931884766, "eval/prior_ent_min": 23.62689208984375, "eval/prior_ent_std": 5.711393356323242, "eval/rep_loss_mean": 14.151192665100098, "eval/rep_loss_std": 8.775379180908203, "eval/reward_avg": 0.014062500558793545, "eval/reward_loss_mean": 0.08108525723218918, "eval/reward_loss_std": 0.5690905451774597, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.004321575164795, "eval/reward_neg_acc": 0.9960199594497681, "eval/reward_neg_loss": 0.04943980276584625, "eval/reward_pos_acc": 0.8421052694320679, "eval/reward_pos_loss": 1.7549631595611572, "eval/reward_pred": 0.010061973705887794, "eval/reward_rate": 0.0185546875, "replay/size": 169961.0, "replay/inserts": 20760.0, "replay/samples": 20752.0, "replay/insert_wait_avg": 1.4027533963006815e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.832470857830533e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 35216.0, "eval_replay/inserts": 5648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2828084632289984e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.98377799987793e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.019035577774, "timer/env.step_count": 2595.0, "timer/env.step_total": 255.91924929618835, "timer/env.step_frac": 0.2559143778181459, "timer/env.step_avg": 0.09862013460354078, "timer/env.step_min": 0.02443552017211914, "timer/env.step_max": 3.53642201423645, "timer/replay._sample_count": 20752.0, "timer/replay._sample_total": 11.475012302398682, "timer/replay._sample_frac": 0.01147479387306747, "timer/replay._sample_avg": 0.0005529593437933058, "timer/replay._sample_min": 0.0003647804260253906, "timer/replay._sample_max": 0.011687994003295898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3301.0, "timer/agent.policy_total": 58.589106798172, "timer/agent.policy_frac": 0.058587991541902376, "timer/agent.policy_avg": 0.017748896333890336, "timer/agent.policy_min": 0.009637594223022461, "timer/agent.policy_max": 0.12359094619750977, "timer/dataset_train_count": 1297.0, "timer/dataset_train_total": 0.15635061264038086, "timer/dataset_train_frac": 0.000156347636472787, "timer/dataset_train_avg": 0.00012054788946829673, "timer/dataset_train_min": 0.000102996826171875, "timer/dataset_train_max": 0.000446319580078125, "timer/agent.train_count": 1297.0, "timer/agent.train_total": 586.6610333919525, "timer/agent.train_frac": 0.5866498661727988, "timer/agent.train_avg": 0.4523215369251754, "timer/agent.train_min": 0.4388148784637451, "timer/agent.train_max": 1.4125144481658936, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47894763946533203, "timer/agent.report_frac": 0.0004789385225938362, "timer/agent.report_avg": 0.23947381973266602, "timer/agent.report_min": 0.2303917407989502, "timer/agent.report_max": 0.24855589866638184, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.838539123535156e-05, "timer/dataset_eval_frac": 3.838466056116012e-08, "timer/dataset_eval_avg": 3.838539123535156e-05, "timer/dataset_eval_min": 3.838539123535156e-05, "timer/dataset_eval_max": 3.838539123535156e-05, "fps": 20.759353150991913}
{"step": 170512, "time": 8349.69949221611, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 170968, "time": 8366.588245391846, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 170984, "time": 8368.862723827362, "episode/length": 183.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 171296, "time": 8381.237686634064, "episode/length": 38.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 171352, "time": 8384.551078796387, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 171432, "time": 8388.87050485611, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 171456, "time": 8391.58577632904, "episode/length": 207.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 171504, "time": 8394.876360177994, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 171608, "time": 8399.679783344269, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 172264, "time": 8425.230531215668, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 172760, "time": 8443.619016647339, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 172832, "time": 8447.883457422256, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 173000, "time": 8455.08463191986, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 173008, "time": 8457.23296046257, "episode/length": 254.0, "episode/score": 5.10000005364418, "episode/reward_rate": 0.9921568627450981, "episode/intrinsic_return": 0.0}
{"step": 173120, "time": 8462.630542516708, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 173592, "time": 8480.561315536499, "episode/length": 269.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 173648, "time": 8484.474091291428, "episode/length": 65.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 173696, "time": 8487.73266029358, "episode/length": 299.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 173992, "time": 8499.07664346695, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 173992, "time": 8499.085379362106, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 174080, "time": 8505.735280513763, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 174256, "time": 8513.480285167694, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 174792, "time": 8532.942191839218, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 174832, "time": 8536.149265527725, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 174968, "time": 8542.362343549728, "episode/length": 244.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 175112, "time": 8548.917804002762, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 175152, "time": 8552.161952972412, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 175200, "time": 8555.590947151184, "episode/length": 150.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 175392, "time": 8563.610993385315, "episode/length": 163.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 175512, "time": 8569.032938480377, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 176168, "time": 8592.755360364914, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 176192, "time": 8595.416135549545, "episode/length": 152.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 176328, "time": 8601.567111492157, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 176624, "time": 8613.370129108429, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 176952, "time": 8625.855249404907, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 177248, "time": 8637.886980295181, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 177504, "time": 8648.03780078888, "episode/length": 293.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 177536, "time": 8650.684859752655, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 177544, "time": 8652.382135629654, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 177624, "time": 8656.733659267426, "episode/length": 278.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.992831541218638, "episode/intrinsic_return": 0.0}
{"step": 177672, "time": 8659.947800159454, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 177672, "time": 8659.958537101746, "episode/length": 319.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.990625, "episode/intrinsic_return": 0.0}
{"step": 177952, "time": 8673.030560731888, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 178616, "time": 8696.74939608574, "episode/length": 170.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 178848, "time": 8706.399843215942, "episode/length": 167.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 178960, "time": 8711.796858787537, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 179064, "time": 8716.750097036362, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 179144, "time": 8721.102075338364, "episode/length": 183.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 179336, "time": 8729.395565271378, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 179432, "time": 8734.16872882843, "episode/length": 225.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 179848, "time": 8749.82708644867, "episode/length": 236.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 179920, "time": 8754.35091495514, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8773.915278196335, "eval_episode/length": 30.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8387096774193549}
{"step": 180024, "time": 8781.631177425385, "eval_episode/length": 148.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9530201342281879}
{"step": 180024, "time": 8784.067406654358, "eval_episode/length": 164.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939393939393939}
{"step": 180024, "time": 8785.918738603592, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 180024, "time": 8787.465478658676, "eval_episode/length": 171.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9825581395348837}
{"step": 180024, "time": 8789.813510894775, "eval_episode/length": 189.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 180024, "time": 8791.560782909393, "eval_episode/length": 191.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 180024, "time": 8793.169405221939, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 180416, "time": 8807.927181005478, "episode/length": 168.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 180416, "time": 8807.936930418015, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 180496, "time": 8814.206507444382, "episode/length": 168.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 180648, "time": 8820.867757558823, "episode/length": 28.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 180760, "time": 8826.781526088715, "episode/length": 238.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 180936, "time": 8834.414111375809, "episode/length": 187.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 181208, "time": 8845.334633111954, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 181232, "time": 8847.930889368057, "episode/length": 236.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 181720, "time": 8865.762595415115, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 181824, "time": 8871.224500894547, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 181832, "time": 8872.901983737946, "episode/length": 147.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 181928, "time": 8877.73185300827, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 182072, "time": 8884.203303098679, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 182152, "time": 8888.477570295334, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 182400, "time": 8898.750007867813, "episode/length": 148.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 182544, "time": 8905.336150884628, "episode/length": 88.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 183128, "time": 8926.657225370407, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 183264, "time": 8933.72984457016, "episode/length": 166.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 183360, "time": 8938.715690135956, "episode/length": 265.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 183584, "time": 8947.807568073273, "episode/length": 232.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 183744, "time": 8954.821228265762, "episode/length": 198.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 183896, "time": 8961.513196468353, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 184024, "time": 8967.35626077652, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 184144, "time": 8973.264097929, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 184408, "time": 8983.672469854355, "episode/length": 142.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 184448, "time": 8986.877992868423, "episode/length": 37.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 184512, "time": 8990.702266454697, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 184784, "time": 9001.795662403107, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 185360, "time": 9023.18610215187, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 185512, "time": 9029.777808189392, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 185656, "time": 9036.263373613358, "episode/length": 258.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9922779922779923, "episode/intrinsic_return": 0.0}
{"step": 185688, "time": 9038.84929394722, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 185736, "time": 9042.05754518509, "episode/length": 152.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 185920, "time": 9050.047662973404, "episode/length": 271.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 186248, "time": 9062.660188674927, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 186736, "time": 9081.24292755127, "episode/length": 171.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 186768, "time": 9083.816463947296, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 186960, "time": 9091.890296697617, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 187200, "time": 9101.583515167236, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 187392, "time": 9109.567662239075, "episode/length": 212.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 187480, "time": 9114.101069927216, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 187608, "time": 9120.132628440857, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 187696, "time": 9124.944367170334, "episode/length": 37.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 187984, "time": 9136.237832307816, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 188224, "time": 9146.175775527954, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 188272, "time": 9149.442898750305, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 188480, "time": 9159.481375932693, "episode/length": 159.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 188696, "time": 9168.08549618721, "episode/length": 135.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 188776, "time": 9172.582684755325, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 189304, "time": 9191.96985077858, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 189320, "time": 9194.128193616867, "episode/length": 166.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 189416, "time": 9199.006653785706, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 189904, "time": 9217.541781187057, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9237.365449905396, "eval_episode/length": 34.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 190008, "time": 9242.967246055603, "eval_episode/length": 89.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9444444444444444}
{"step": 190008, "time": 9246.144478321075, "eval_episode/length": 161.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 190008, "time": 9248.068470716476, "eval_episode/length": 169.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 190008, "time": 9248.077292919159, "eval_episode/length": 169.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9588235294117647}
{"step": 190008, "time": 9251.685188770294, "eval_episode/length": 172.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9595375722543352}
{"step": 190008, "time": 9254.777653694153, "eval_episode/length": 205.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 190008, "time": 9256.586674690247, "eval_episode/length": 209.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9809523809523809}
{"step": 190056, "time": 9258.232810974121, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 190080, "time": 9260.831619977951, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 190400, "time": 9273.479622602463, "episode/length": 743.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 190464, "time": 9277.380537986755, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 190624, "time": 9284.52698969841, "episode/length": 164.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 190688, "time": 9288.433243274689, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 190968, "time": 9299.483685016632, "episode/length": 62.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 191016, "time": 9302.737334489822, "episode/length": 138.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 191288, "time": 9314.786998271942, "episode/length": 233.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 191288, "time": 9314.799464941025, "episode/length": 153.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.961038961038961, "episode/intrinsic_return": 0.0}
{"step": 191544, "time": 9326.913511753082, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 191816, "time": 9338.069270133972, "episode/length": 176.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 191936, "time": 9343.87919998169, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 191993, "time": 9348.221752643585, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.554755316840278, "train/action_min": 0.0, "train/action_std": 3.6774317882679126, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04335546643921623, "train/actor_opt_grad_steps": 11230.0, "train/actor_opt_loss": 2.906959992840334, "train/adv_mag": 0.7302599441122126, "train/adv_max": 0.7036664329193256, "train/adv_mean": 0.005569325268899977, "train/adv_min": -0.49335704997733787, "train/adv_std": 0.07360580152383557, "train/cont_avg": 0.9945095486111111, "train/cont_loss_mean": 0.0003458894379457854, "train/cont_loss_std": 0.009271559010098658, "train/cont_neg_acc": 0.9914801000659146, "train/cont_neg_loss": 0.0302418808205377, "train/cont_pos_acc": 0.999927239506333, "train/cont_pos_loss": 0.00019316092244749868, "train/cont_pred": 0.9944718268182543, "train/cont_rate": 0.9945095486111111, "train/dyn_loss_mean": 14.246178867198802, "train/dyn_loss_std": 9.24375412552445, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0846632105332834, "train/extr_critic_critic_opt_grad_steps": 11230.0, "train/extr_critic_critic_opt_loss": 15503.573321759259, "train/extr_critic_mag": 4.207258542378743, "train/extr_critic_max": 4.207258542378743, "train/extr_critic_mean": 1.143103708602764, "train/extr_critic_min": -0.18920182916853162, "train/extr_critic_std": 1.1268330507808262, "train/extr_return_normed_mag": 1.7051832278569539, "train/extr_return_normed_max": 1.7051832278569539, "train/extr_return_normed_mean": 0.34557617659922, "train/extr_return_normed_min": -0.15249515231008884, "train/extr_return_normed_std": 0.3444489971355156, "train/extr_return_rate": 0.5737297791021841, "train/extr_return_raw_mag": 5.782530738689282, "train/extr_return_raw_max": 5.782530738689282, "train/extr_return_raw_mean": 1.161900931375998, "train/extr_return_raw_min": -0.5316235661506653, "train/extr_return_raw_std": 1.171584231323666, "train/extr_reward_mag": 1.0058254815914012, "train/extr_reward_max": 1.0058254815914012, "train/extr_reward_mean": 0.02130063435545674, "train/extr_reward_min": -0.41443499635767056, "train/extr_reward_std": 0.13218402520374015, "train/image_loss_mean": 11.017354343555592, "train/image_loss_std": 13.573493646692347, "train/model_loss_mean": 19.619018597073026, "train/model_loss_std": 17.457643233405218, "train/model_opt_grad_norm": 86.51203220508717, "train/model_opt_grad_steps": 11215.666666666666, "train/model_opt_loss": 12435.541695601853, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 634.2592592592592, "train/policy_entropy_mag": 2.3782236946953668, "train/policy_entropy_max": 2.3782236946953668, "train/policy_entropy_mean": 0.634077243230961, "train/policy_entropy_min": 0.0793756322728263, "train/policy_entropy_std": 0.5738646928910855, "train/policy_logprob_mag": 7.438377758308693, "train/policy_logprob_max": -0.009455894064848069, "train/policy_logprob_mean": -0.634324746440958, "train/policy_logprob_min": -7.438377758308693, "train/policy_logprob_std": 1.140516667012815, "train/policy_randomness_mag": 0.8394085967982257, "train/policy_randomness_max": 0.8394085967982257, "train/policy_randomness_mean": 0.22380143955901818, "train/policy_randomness_min": 0.028016114773021805, "train/policy_randomness_std": 0.20254905477718071, "train/post_ent_mag": 53.14741185506185, "train/post_ent_max": 53.14741185506185, "train/post_ent_mean": 36.83707512749566, "train/post_ent_min": 20.574744330512154, "train/post_ent_std": 6.0537714534335665, "train/prior_ent_mag": 63.542808363172746, "train/prior_ent_max": 63.542808363172746, "train/prior_ent_mean": 51.231703751175495, "train/prior_ent_min": 26.36253125226056, "train/prior_ent_std": 7.045436212751601, "train/rep_loss_mean": 14.246178867198802, "train/rep_loss_std": 9.24375412552445, "train/reward_avg": 0.020565682672033157, "train/reward_loss_mean": 0.05361117168709084, "train/reward_loss_std": 0.2639366532917376, "train/reward_max_data": 1.008148150090818, "train/reward_max_pred": 1.0032268630133734, "train/reward_neg_acc": 0.9938284525164851, "train/reward_neg_loss": 0.030677503857899597, "train/reward_pos_acc": 0.9519704977671305, "train/reward_pos_loss": 0.931486373035996, "train/reward_pred": 0.019634168519190063, "train/reward_rate": 0.025557002314814815, "train_stats/sum_log_reward": 5.057627043481601, "train_stats/max_log_achievement_collect_drink": 4.38135593220339, "train_stats/max_log_achievement_collect_sapling": 2.3728813559322033, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 4.703389830508475, "train_stats/max_log_achievement_defeat_skeleton": 0.00847457627118644, "train_stats/max_log_achievement_defeat_zombie": 0.2542372881355932, "train_stats/max_log_achievement_eat_cow": 0.11016949152542373, "train_stats/max_log_achievement_make_wood_pickaxe": 0.01694915254237288, "train_stats/max_log_achievement_make_wood_sword": 0.4576271186440678, "train_stats/max_log_achievement_place_plant": 2.2542372881355934, "train_stats/max_log_achievement_place_table": 1.6864406779661016, "train_stats/max_log_achievement_wake_up": 2.26271186440678, "train_stats/mean_log_entropy": 0.5529472411183988, "eval_stats/sum_log_reward": 4.537499964237213, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.75, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_plant": 1.625, "eval_stats/max_log_achievement_place_table": 1.0625, "eval_stats/max_log_achievement_wake_up": 1.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 2.783971285680309e-05, "report/cont_loss_std": 0.00040352862561121583, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.003597578499466181, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0323821697966196e-05, "report/cont_pred": 0.9951244592666626, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 16.488445281982422, "report/dyn_loss_std": 8.796717643737793, "report/image_loss_mean": 11.69000244140625, "report/image_loss_std": 14.384926795959473, "report/model_loss_mean": 21.660564422607422, "report/model_loss_std": 18.065284729003906, "report/post_ent_mag": 52.12839889526367, "report/post_ent_max": 52.12839889526367, "report/post_ent_mean": 37.057334899902344, "report/post_ent_min": 19.03907012939453, "report/post_ent_std": 5.834951400756836, "report/prior_ent_mag": 64.18269348144531, "report/prior_ent_max": 64.18269348144531, "report/prior_ent_mean": 53.338565826416016, "report/prior_ent_min": 33.767093658447266, "report/prior_ent_std": 5.723124027252197, "report/rep_loss_mean": 16.488445281982422, "report/rep_loss_std": 8.796717643737793, "report/reward_avg": 0.03281249850988388, "report/reward_loss_mean": 0.07746576517820358, "report/reward_loss_std": 0.35629549622535706, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0026366710662842, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 0.032608382403850555, "report/reward_pos_acc": 0.8717948794364929, "report/reward_pos_loss": 1.2104021310806274, "report/reward_pred": 0.024923257529735565, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.30636269407114e-05, "eval/cont_loss_std": 0.00043314971844665706, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012581332121044397, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 1.8220218407805078e-05, "eval/cont_pred": 0.9960806369781494, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 13.817082405090332, "eval/dyn_loss_std": 9.75178050994873, "eval/image_loss_mean": 13.52369499206543, "eval/image_loss_std": 18.88285255432129, "eval/model_loss_mean": 21.874483108520508, "eval/model_loss_std": 23.206283569335938, "eval/post_ent_mag": 51.938880920410156, "eval/post_ent_max": 51.938880920410156, "eval/post_ent_mean": 38.73338317871094, "eval/post_ent_min": 19.214393615722656, "eval/post_ent_std": 6.571407318115234, "eval/prior_ent_mag": 64.18269348144531, "eval/prior_ent_max": 64.18269348144531, "eval/prior_ent_mean": 50.66925048828125, "eval/prior_ent_min": 24.2121639251709, "eval/prior_ent_std": 7.66764497756958, "eval/rep_loss_mean": 13.817082405090332, "eval/rep_loss_std": 9.75178050994873, "eval/reward_avg": 0.01123046875, "eval/reward_loss_mean": 0.060514725744724274, "eval/reward_loss_std": 0.46875664591789246, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.001511573791504, "eval/reward_neg_acc": 1.0, "eval/reward_neg_loss": 0.02723807282745838, "eval/reward_pos_acc": 0.6875, "eval/reward_pos_loss": 2.1569437980651855, "eval/reward_pred": 0.006346902810037136, "eval/reward_rate": 0.015625, "replay/size": 191489.0, "replay/inserts": 21528.0, "replay/samples": 21536.0, "replay/insert_wait_avg": 1.3995684464595344e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.95697064420975e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 38456.0, "eval_replay/inserts": 3240.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2763488439866053e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1026859283447266e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4082832336426, "timer/env.step_count": 2691.0, "timer/env.step_total": 268.8931107521057, "timer/env.step_frac": 0.2687833710082411, "timer/env.step_avg": 0.09992311807956362, "timer/env.step_min": 0.02442312240600586, "timer/env.step_max": 3.5709776878356934, "timer/replay._sample_count": 21536.0, "timer/replay._sample_total": 11.955179214477539, "timer/replay._sample_frac": 0.011950300107306728, "timer/replay._sample_avg": 0.0005551253349961711, "timer/replay._sample_min": 0.0003972053527832031, "timer/replay._sample_max": 0.008078336715698242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3096.0, "timer/agent.policy_total": 54.51754832267761, "timer/agent.policy_frac": 0.05449529880586284, "timer/agent.policy_avg": 0.01760902723600698, "timer/agent.policy_min": 0.00991511344909668, "timer/agent.policy_max": 0.1429738998413086, "timer/dataset_train_count": 1346.0, "timer/dataset_train_total": 0.1642148494720459, "timer/dataset_train_frac": 0.0001641478306649466, "timer/dataset_train_avg": 0.00012200211699260468, "timer/dataset_train_min": 0.0001049041748046875, "timer/dataset_train_max": 0.00021576881408691406, "timer/agent.train_count": 1346.0, "timer/agent.train_total": 610.3202874660492, "timer/agent.train_frac": 0.6100712056214659, "timer/agent.train_avg": 0.45343260584401873, "timer/agent.train_min": 0.4387357234954834, "timer/agent.train_max": 1.5267317295074463, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763157367706299, "timer/agent.report_frac": 0.00047612134440852853, "timer/agent.report_avg": 0.23815786838531494, "timer/agent.report_min": 0.23080897331237793, "timer/agent.report_max": 0.24550676345825195, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.2901763916015625e-05, "timer/dataset_eval_frac": 3.2888336159779184e-08, "timer/dataset_eval_avg": 3.2901763916015625e-05, "timer/dataset_eval_min": 3.2901763916015625e-05, "timer/dataset_eval_max": 3.2901763916015625e-05, "fps": 21.518913514938358}
{"step": 192288, "time": 9358.467423677444, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 192448, "time": 9365.551662683487, "episode/length": 227.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 192464, "time": 9367.737182378769, "episode/length": 146.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 192816, "time": 9381.33584189415, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 192848, "time": 9384.077823877335, "episode/length": 234.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 193120, "time": 9395.008568763733, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 193200, "time": 9399.624868869781, "episode/length": 238.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9623430962343096, "episode/intrinsic_return": 0.0}
{"step": 193336, "time": 9405.558857440948, "episode/length": 189.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 193616, "time": 9417.366874694824, "episode/length": 209.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 193672, "time": 9420.715133190155, "episode/length": 150.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 194008, "time": 9433.597801208496, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 194056, "time": 9436.777831077576, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 194112, "time": 9440.50646686554, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 194472, "time": 9454.340348482132, "episode/length": 202.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 194752, "time": 9465.773716449738, "episode/length": 141.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 194816, "time": 9469.575017690659, "episode/length": 201.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 195024, "time": 9479.22810792923, "episode/length": 237.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 195056, "time": 9482.277264595032, "episode/length": 37.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 195112, "time": 9485.578958272934, "episode/length": 36.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 195272, "time": 9492.734635591507, "episode/length": 144.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 195344, "time": 9497.101300477982, "episode/length": 250.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 195688, "time": 9510.337462425232, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 195744, "time": 9514.05407834053, "episode/length": 158.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 196016, "time": 9524.845731973648, "episode/length": 250.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 196496, "time": 9542.942116737366, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 196504, "time": 9544.623085260391, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 196528, "time": 9547.310594081879, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 196616, "time": 9552.090873718262, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 196976, "time": 9567.727636575699, "episode/length": 160.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 197320, "time": 9581.022762060165, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 197440, "time": 9586.865958213806, "episode/length": 270.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 197656, "time": 9595.669378519058, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 197656, "time": 9595.679614543915, "episode/length": 41.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 197680, "time": 9600.06678056717, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 198016, "time": 9613.380271673203, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 198184, "time": 9620.483150482178, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 198888, "time": 9646.18479013443, "episode/length": 153.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 199136, "time": 9656.575373649597, "episode/length": 328.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 199256, "time": 9661.904736757278, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 199600, "time": 9675.464064836502, "episode/length": 242.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 199624, "time": 9677.598330259323, "episode/length": 272.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 199728, "time": 9683.13712143898, "episode/length": 255.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9716.572029590607, "eval_episode/length": 137.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9927536231884058}
{"step": 200096, "time": 9718.247997283936, "eval_episode/length": 138.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 200096, "time": 9721.043211460114, "eval_episode/length": 165.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 200096, "time": 9723.062885761261, "eval_episode/length": 172.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 200096, "time": 9724.946967840195, "eval_episode/length": 179.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 200096, "time": 9727.522579431534, "eval_episode/length": 199.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.995}
{"step": 200096, "time": 9729.454908370972, "eval_episode/length": 205.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 200096, "time": 9732.497122764587, "eval_episode/length": 235.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 200160, "time": 9734.680721759796, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 200168, "time": 9736.35847902298, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 200504, "time": 9749.425091981888, "episode/length": 500.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9900199600798403, "episode/intrinsic_return": 0.0}
{"step": 200920, "time": 9765.04678940773, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 201032, "time": 9770.496453523636, "episode/length": 221.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 201208, "time": 9778.259730100632, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 201560, "time": 9791.837406396866, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 201608, "time": 9794.963495492935, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 201760, "time": 9802.088274478912, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 201904, "time": 9808.57290816307, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 201976, "time": 9812.322713851929, "episode/length": 293.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 202192, "time": 9821.520626306534, "episode/length": 158.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 202272, "time": 9825.799441576004, "episode/length": 154.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 202584, "time": 9837.85376238823, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 202768, "time": 9845.944205760956, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 203008, "time": 9855.754938364029, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 203016, "time": 9857.38160943985, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 203312, "time": 9869.385718345642, "episode/length": 139.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 203328, "time": 9871.545818805695, "episode/length": 168.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 203416, "time": 9875.95506811142, "episode/length": 188.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 203880, "time": 9893.458544254303, "episode/length": 200.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 204176, "time": 9905.237072706223, "episode/length": 36.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 204336, "time": 9912.289989471436, "episode/length": 218.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 204424, "time": 9916.770555973053, "episode/length": 206.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 204448, "time": 9919.463614463806, "episode/length": 179.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 204640, "time": 9927.698503017426, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 204664, "time": 9929.969051122665, "episode/length": 166.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 204680, "time": 9932.168461084366, "episode/length": 170.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 204896, "time": 9942.859143733978, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 205584, "time": 9968.50663280487, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 205680, "time": 9973.425632953644, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 205848, "time": 9980.47601366043, "episode/length": 145.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 206264, "time": 9996.582583904266, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 206328, "time": 10000.439975976944, "episode/length": 207.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 206352, "time": 10003.192700862885, "episode/length": 213.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 206512, "time": 10010.261924982071, "episode/length": 271.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 206688, "time": 10017.975852489471, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 206728, "time": 10020.706882476807, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 207016, "time": 10032.186803817749, "episode/length": 35.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 207144, "time": 10038.06036400795, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 207280, "time": 10044.888911008835, "episode/length": 32.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 207520, "time": 10054.699491977692, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 207800, "time": 10065.653276443481, "episode/length": 183.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 207864, "time": 10069.444739818573, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 208056, "time": 10077.706556797028, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 208152, "time": 10082.918093919754, "episode/length": 235.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 208440, "time": 10094.511669397354, "episode/length": 161.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 208640, "time": 10103.257940530777, "episode/length": 169.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 208696, "time": 10106.573529720306, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 208936, "time": 10116.415652275085, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 209000, "time": 10120.260174512863, "episode/length": 37.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 209072, "time": 10124.544394493103, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 209128, "time": 10127.79809141159, "episode/length": 200.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 209624, "time": 10146.36505150795, "episode/length": 195.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 209840, "time": 10155.556569576263, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 209992, "time": 10162.159745693207, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10188.938215970993, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9741935483870968}
{"step": 210080, "time": 10191.34060049057, "eval_episode/length": 166.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 210080, "time": 10193.315935373306, "eval_episode/length": 172.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 210080, "time": 10195.2107462883, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 210080, "time": 10195.220217704773, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 210080, "time": 10198.752525806427, "eval_episode/length": 184.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 210080, "time": 10201.085352659225, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 210080, "time": 10204.20620393753, "eval_episode/length": 233.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9786324786324786}
{"step": 210304, "time": 10211.808961391449, "episode/length": 38.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 210344, "time": 10214.497614383698, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 210848, "time": 10233.642077684402, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 210984, "time": 10239.708341360092, "episode/length": 238.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 211008, "time": 10242.342868566513, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 211168, "time": 10249.52506017685, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 211336, "time": 10256.773543596268, "episode/length": 40.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 211368, "time": 10259.51469707489, "episode/length": 401.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 211736, "time": 10273.736410856247, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 211872, "time": 10280.174738168716, "episode/length": 87.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9318181818181818, "episode/intrinsic_return": 0.0}
{"step": 212400, "time": 10300.015147209167, "episode/length": 346.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 212752, "time": 10314.446100711823, "episode/length": 237.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9873949579831933, "episode/intrinsic_return": 0.0}
{"step": 212824, "time": 10318.802824258804, "episode/length": 181.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 212848, "time": 10321.499639511108, "episode/length": 232.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 212848, "time": 10321.508686065674, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 212920, "time": 10327.009750127792, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
