{"step": 1288, "time": 112.73966956138611, "episode/length": 160.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 1312, "time": 114.32493805885315, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 1320, "time": 115.70256328582764, "episode/length": 164.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 1336, "time": 117.07218742370605, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 1488, "time": 119.00763082504272, "episode/length": 185.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 1512, "time": 120.44428181648254, "episode/length": 188.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 1560, "time": 134.26391768455505, "eval_episode/length": 61.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 1560, "time": 137.45957446098328, "eval_episode/length": 143.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 1560, "time": 139.04278922080994, "eval_episode/length": 152.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9607843137254902}
{"step": 1560, "time": 139.05037641525269, "eval_episode/length": 152.0, "eval_episode/score": 0.10000002384185791, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 1560, "time": 141.95268774032593, "eval_episode/length": 156.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 1560, "time": 143.76880741119385, "eval_episode/length": 172.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 1560, "time": 145.6700189113617, "train_stats/sum_log_reward": 1.5999999543031056, "train_stats/max_log_achievement_collect_sapling": 0.8333333333333334, "train_stats/max_log_achievement_place_plant": 0.8333333333333334, "train_stats/max_log_achievement_collect_wood": 0.8, "train_stats/max_log_achievement_wake_up": 2.0, "train_stats/max_log_achievement_place_table": 0.3333333333333333, "eval_stats/sum_log_reward": 1.0999999543031056, "eval_stats/max_log_achievement_collect_sapling": 0.8333333333333334, "eval_stats/max_log_achievement_collect_wood": 0.3333333333333333, "eval_stats/max_log_achievement_place_plant": 0.8333333333333334, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.5}
{"step": 1560, "time": 179.2713906764984, "eval_episode/length": 84.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9411764705882353}
{"step": 1560, "time": 182.32617568969727, "eval_episode/length": 116.0, "eval_episode/score": 2.0999999791383743, "eval_episode/reward_rate": 0.9914529914529915}
{"step": 1560, "time": 184.95671844482422, "eval_episode/length": 140.0, "eval_episode/score": 0.09999999403953552, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 1560, "time": 186.9064381122589, "eval_episode/length": 143.0, "eval_episode/score": 0.10000000894069672, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 1560, "time": 189.32117176055908, "eval_episode/length": 155.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 1560, "time": 193.2008068561554, "eval_episode/length": 204.0, "eval_episode/score": 1.0999999940395355, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 1560, "time": 194.97179174423218, "eval_episode/length": 206.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 1560, "time": 197.6623170375824, "eval_episode/length": 231.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 1561, "time": 317.7981834411621, "eval_stats/sum_log_reward": 0.9749999921768904, "eval_stats/max_log_achievement_collect_sapling": 0.375, "eval_stats/max_log_achievement_collect_wood": 0.25, "eval_stats/max_log_achievement_place_plant": 0.375, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 1.75, "eval_stats/max_log_achievement_collect_drink": 0.6666666666666666, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 8.331298828125, "train/action_min": 0.0, "train/action_std": 4.344633102416992, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0003579063049983233, "train/actor_opt_grad_steps": 1.0, "train/actor_opt_loss": -0.9065110683441162, "train/adv_mag": 0.0, "train/adv_max": 0.0, "train/adv_mean": 0.0, "train/adv_min": 0.0, "train/adv_std": 0.0, "train/cont_avg": 0.99609375, "train/cont_loss_mean": 0.8747686743736267, "train/cont_loss_std": 0.3383483290672302, "train/cont_neg_acc": 0.75, "train/cont_neg_loss": 0.4932098388671875, "train/cont_pos_acc": 0.3284313678741455, "train/cont_pos_loss": 0.8762649297714233, "train/cont_pred": 0.438968300819397, "train/cont_rate": 0.99609375, "train/dyn_loss_mean": 11.078014373779297, "train/dyn_loss_std": 0.43146100640296936, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 3.4899137020111084, "train/extr_critic_critic_opt_grad_steps": 1.0, "train/extr_critic_critic_opt_loss": 13693.87109375, "train/extr_critic_mag": 0.0, "train/extr_critic_max": 0.0, "train/extr_critic_mean": 0.0, "train/extr_critic_min": 0.0, "train/extr_critic_std": 0.0, "train/extr_return_normed_mag": 0.0, "train/extr_return_normed_max": 0.0, "train/extr_return_normed_mean": 0.0, "train/extr_return_normed_min": 0.0, "train/extr_return_normed_std": 0.0, "train/extr_return_rate": 0.0, "train/extr_return_raw_mag": 0.0, "train/extr_return_raw_max": 0.0, "train/extr_return_raw_mean": 0.0, "train/extr_return_raw_min": 0.0, "train/extr_return_raw_std": 0.0, "train/extr_reward_mag": 0.0, "train/extr_reward_max": 0.0, "train/extr_reward_mean": 0.0, "train/extr_reward_min": 0.0, "train/extr_reward_std": 0.0, "train/image_loss_mean": 3679.66845703125, "train/image_loss_std": 142.33187866210938, "train/model_loss_mean": 3692.731201171875, "train/model_loss_std": 142.38565063476562, "train/model_opt_grad_norm": NaN, "train/model_opt_grad_steps": 0.0, "train/model_opt_loss": 36927312.0, "train/model_opt_model_opt_grad_overflow": 1.0, "train/model_opt_model_opt_grad_scale": 5000.0, "train/policy_entropy_mag": 2.7472267150878906, "train/policy_entropy_max": 2.7472267150878906, "train/policy_entropy_mean": 2.4564194679260254, "train/policy_entropy_min": 1.379050850868225, "train/policy_entropy_std": 0.14821968972682953, "train/policy_logprob_mag": 5.8311004638671875, "train/policy_logprob_max": -0.3725389838218689, "train/policy_logprob_mean": -2.4777066707611084, "train/policy_logprob_min": -5.8311004638671875, "train/policy_logprob_std": 0.8596143126487732, "train/policy_randomness_mag": 0.9696504473686218, "train/policy_randomness_max": 0.9696504473686218, "train/policy_randomness_mean": 0.8670082688331604, "train/policy_randomness_min": 0.4867444336414337, "train/policy_randomness_std": 0.05231504514813423, "train/post_ent_mag": 105.98307037353516, "train/post_ent_max": 105.98307037353516, "train/post_ent_mean": 105.3606948852539, "train/post_ent_min": 104.75868225097656, "train/post_ent_std": 0.16462239623069763, "train/prior_ent_mag": 106.33232879638672, "train/prior_ent_max": 106.33232879638672, "train/prior_ent_mean": 105.6189193725586, "train/prior_ent_min": 104.78894805908203, "train/prior_ent_std": 0.2713398039340973, "train/rep_loss_mean": 11.078014373779297, "train/rep_loss_std": 0.43146100640296936, "train/reward_avg": 0.004296875558793545, "train/reward_loss_mean": 5.541262626647949, "train/reward_loss_std": 9.542561656417092e-07, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.0, "train/reward_neg_acc": 1.0, "train/reward_neg_loss": 5.541263103485107, "train/reward_pos_acc": 0.0, "train/reward_pos_loss": 5.541263580322266, "train/reward_pred": 0.0, "train/reward_rate": 0.0087890625, "train/params_agent/wm/model_opt": 181569923.0, "train/params_agent/task_behavior/critic/critic_opt": 9708799.0, "train/params_agent/task_behavior/ac/actor_opt": 9464849.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.8993335962295532, "report/cont_loss_std": 0.36212536692619324, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.51523756980896, "report/cont_pos_acc": 0.3166666626930237, "report/cont_pos_loss": 0.9008398056030273, "report/cont_pred": 0.43188971281051636, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 11.071653366088867, "report/dyn_loss_std": 0.4400407373905182, "report/image_loss_mean": 3678.300537109375, "report/image_loss_std": 141.47918701171875, "report/model_loss_mean": 3691.38427734375, "report/model_loss_std": 141.4636688232422, "report/post_ent_mag": 105.958740234375, "report/post_ent_max": 105.958740234375, "report/post_ent_mean": 105.3717269897461, "report/post_ent_min": 104.75088500976562, "report/post_ent_std": 0.15343821048736572, "report/prior_ent_mag": 106.5310287475586, "report/prior_ent_max": 106.5310287475586, "report/prior_ent_mean": 105.60061645507812, "report/prior_ent_min": 104.77005004882812, "report/prior_ent_std": 0.27257028222084045, "report/rep_loss_mean": 11.071653366088867, "report/rep_loss_std": 0.4400407373905182, "report/reward_avg": 0.004296875558793545, "report/reward_loss_mean": 5.541262626647949, "report/reward_loss_std": 9.542561656417092e-07, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.0, "report/reward_neg_acc": 1.0, "report/reward_neg_loss": 5.541263103485107, "report/reward_pos_acc": 0.0, "report/reward_pos_loss": 5.541263580322266, "report/reward_pred": 0.0, "report/reward_rate": 0.0087890625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.9154824018478394, "eval/cont_loss_std": 0.3666554391384125, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.37344738841056824, "eval/cont_pos_acc": 0.2993130385875702, "eval/cont_pos_loss": 0.9181420803070068, "eval/cont_pred": 0.42444944381713867, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 11.046936988830566, "eval/dyn_loss_std": 0.43800443410873413, "eval/image_loss_mean": 3695.94677734375, "eval/image_loss_std": 130.6641845703125, "eval/model_loss_mean": 3709.031494140625, "eval/model_loss_std": 130.70252990722656, "eval/post_ent_mag": 105.80159759521484, "eval/post_ent_max": 105.80159759521484, "eval/post_ent_mean": 105.36215209960938, "eval/post_ent_min": 104.94709014892578, "eval/post_ent_std": 0.15574267506599426, "eval/prior_ent_mag": 106.4454345703125, "eval/prior_ent_max": 106.4454345703125, "eval/prior_ent_mean": 105.65397644042969, "eval/prior_ent_min": 104.47318267822266, "eval/prior_ent_std": 0.27841615676879883, "eval/rep_loss_mean": 11.046936988830566, "eval/rep_loss_std": 0.43800443410873413, "eval/reward_avg": 0.00966796837747097, "eval/reward_loss_mean": 5.541262626647949, "eval/reward_loss_std": 9.542561656417092e-07, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.0, "eval/reward_neg_acc": 0.9999999403953552, "eval/reward_neg_loss": 5.541262626647949, "eval/reward_pos_acc": 0.0, "eval/reward_pos_loss": 5.541263580322266, "eval/reward_pred": 0.0, "eval/reward_rate": 0.0126953125, "replay/size": 1057.0, "replay/inserts": 1057.0, "replay/samples": 112.0, "replay/insert_wait_avg": 1.418556711418852e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.918902805873326e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 2912.0, "eval_replay/inserts": 2912.0, "eval_replay/samples": 112.0, "eval_replay/insert_wait_avg": 2.44248044359815e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0728836059570312e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 220.06696462631226, "timer/env.step_count": 196.0, "timer/env.step_total": 24.035701513290405, "timer/env.step_frac": 0.10921994382075728, "timer/env.step_avg": 0.122631130169849, "timer/env.step_min": 0.02044200897216797, "timer/env.step_max": 11.222548961639404, "timer/replay._sample_count": 112.0, "timer/replay._sample_total": 0.14577770233154297, "timer/replay._sample_frac": 0.0006624242878938364, "timer/replay._sample_avg": 0.001301586627960205, "timer/replay._sample_min": 0.0003561973571777344, "timer/replay._sample_max": 0.010295391082763672, "timer/agent.save_count": 1.0, "timer/agent.save_total": 9.22296690940857, "timer/agent.save_frac": 0.04190982015437781, "timer/agent.save_avg": 9.22296690940857, "timer/agent.save_min": 9.22296690940857, "timer/agent.save_max": 9.22296690940857, "timer/agent.policy_count": 233.0, "timer/agent.policy_total": 19.188892602920532, "timer/agent.policy_frac": 0.08719569807083265, "timer/agent.policy_avg": 0.08235576224429413, "timer/agent.policy_min": 0.009932756423950195, "timer/agent.policy_max": 13.133541107177734, "timer/dataset_train_count": 1.0, "timer/dataset_train_total": 3.337860107421875e-05, "timer/dataset_train_frac": 1.516747465068087e-07, "timer/dataset_train_avg": 3.337860107421875e-05, "timer/dataset_train_min": 3.337860107421875e-05, "timer/dataset_train_max": 3.337860107421875e-05, "timer/agent.train_count": 1.0, "timer/agent.train_total": 93.9830379486084, "timer/agent.train_frac": 0.42706563480892096, "timer/agent.train_avg": 93.9830379486084, "timer/agent.train_min": 93.9830379486084, "timer/agent.train_max": 93.9830379486084, "timer/agent.report_count": 2.0, "timer/agent.report_total": 23.871850967407227, "timer/agent.report_frac": 0.10847539524136733, "timer/agent.report_avg": 11.935925483703613, "timer/agent.report_min": 0.24707603454589844, "timer/agent.report_max": 23.624774932861328, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.719329833984375e-05, "timer/dataset_eval_frac": 1.69009003250444e-07, "timer/dataset_eval_avg": 3.719329833984375e-05, "timer/dataset_eval_min": 3.719329833984375e-05, "timer/dataset_eval_max": 3.719329833984375e-05}
{"step": 1592, "time": 318.6044569015503, "episode/length": 198.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 1808, "time": 327.7810626029968, "episode/length": 225.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 2520, "time": 353.4328365325928, "episode/length": 149.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 2536, "time": 355.56348180770874, "episode/length": 127.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9609375, "episode/intrinsic_return": 0.0}
{"step": 2760, "time": 364.645925283432, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 2880, "time": 370.6323390007019, "episode/length": 198.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 3040, "time": 377.63846492767334, "episode/length": 153.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 3120, "time": 381.8605360984802, "episode/length": 203.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 3224, "time": 386.6814546585083, "episode/length": 203.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 3264, "time": 389.89295530319214, "episode/length": 240.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 3688, "time": 405.9847311973572, "episode/length": 145.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 3992, "time": 417.7086796760559, "episode/length": 95.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 4104, "time": 423.02807116508484, "episode/length": 104.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9428571428571428, "episode/intrinsic_return": 0.0}
{"step": 4112, "time": 425.1371989250183, "episode/length": 52.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9056603773584906, "episode/intrinsic_return": 0.0}
{"step": 4136, "time": 427.21749329566956, "episode/length": 136.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 4136, "time": 427.22610306739807, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 4288, "time": 436.2334563732147, "episode/length": 218.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 4328, "time": 438.8951675891876, "episode/length": 180.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 4416, "time": 443.6566638946533, "episode/length": 161.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 5272, "time": 473.91578555107117, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 5280, "time": 476.03889298439026, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 5664, "time": 490.6847131252289, "episode/length": 155.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 5688, "time": 492.7940106391907, "episode/length": 169.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 5712, "time": 495.4327871799469, "episode/length": 196.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9847715736040609, "episode/intrinsic_return": 0.0}
{"step": 5792, "time": 499.72823667526245, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 5936, "time": 506.07937502861023, "episode/length": 228.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 6664, "time": 531.8869745731354, "episode/length": 318.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9905956112852664, "episode/intrinsic_return": 0.0}
{"step": 6776, "time": 537.2823112010956, "episode/length": 138.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9640287769784173, "episode/intrinsic_return": 0.0}
{"step": 6928, "time": 544.3093838691711, "episode/length": 205.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 7000, "time": 548.6298995018005, "episode/length": 163.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 7032, "time": 551.9641542434692, "episode/length": 219.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 7056, "time": 555.005453824997, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 7512, "time": 572.2667632102966, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9688888888888889, "episode/intrinsic_return": 0.0}
{"step": 7584, "time": 576.4874999523163, "episode/length": 81.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 7744, "time": 583.5538356304169, "episode/length": 225.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 8080, "time": 596.4110510349274, "episode/length": 162.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 8160, "time": 600.6928112506866, "episode/length": 51.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 8280, "time": 607.2546470165253, "episode/length": 86.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 8296, "time": 609.3780431747437, "episode/length": 203.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 8392, "time": 614.4248173236847, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 8672, "time": 625.5383534431458, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 8736, "time": 629.3769040107727, "episode/length": 216.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 8784, "time": 632.599169254303, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 9160, "time": 646.6582896709442, "episode/length": 46.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 9584, "time": 662.6717863082886, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 9720, "time": 668.6688163280487, "episode/length": 204.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 9768, "time": 672.0733909606934, "episode/length": 128.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 9784, "time": 674.2647762298584, "episode/length": 173.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 9800, "time": 676.4520189762115, "episode/length": 189.0, "episode/score": 0.09999997913837433, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 10088, "time": 705.0992879867554, "eval_episode/length": 87.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9431818181818182}
{"step": 10088, "time": 710.3651497364044, "eval_episode/length": 168.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 10088, "time": 712.5627117156982, "eval_episode/length": 179.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 10088, "time": 714.2320680618286, "eval_episode/length": 181.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 10088, "time": 716.0097763538361, "eval_episode/length": 184.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.972972972972973}
{"step": 10088, "time": 718.6955041885376, "eval_episode/length": 192.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.9740932642487047}
{"step": 10088, "time": 720.6111824512482, "eval_episode/length": 197.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 10088, "time": 722.7456107139587, "eval_episode/length": 213.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9813084112149533}
{"step": 10240, "time": 728.0635852813721, "episode/length": 195.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 10352, "time": 733.5375413894653, "episode/length": 70.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 10440, "time": 737.8769693374634, "episode/length": 284.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9929824561403509, "episode/intrinsic_return": 0.0}
{"step": 10568, "time": 743.7788248062134, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 11072, "time": 762.7808327674866, "episode/length": 185.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 11072, "time": 762.7895777225494, "episode/length": 158.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 11080, "time": 765.9303333759308, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 11624, "time": 785.6119606494904, "episode/length": 147.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9594594594594594, "episode/intrinsic_return": 0.0}
{"step": 11728, "time": 791.0081350803375, "episode/length": 144.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 11736, "time": 792.7661969661713, "episode/length": 251.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 11816, "time": 797.036416053772, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 12064, "time": 807.1221187114716, "episode/length": 213.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 12640, "time": 828.0332789421082, "episode/length": 194.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 12776, "time": 833.973025560379, "episode/length": 212.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 13112, "time": 846.8810708522797, "episode/length": 254.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9882352941176471, "episode/intrinsic_return": 0.0}
{"step": 13128, "time": 849.1008977890015, "episode/length": 173.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 13296, "time": 856.6230418682098, "episode/length": 153.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 13416, "time": 862.0455212593079, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 14072, "time": 885.9639525413513, "episode/length": 178.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 14120, "time": 889.2359986305237, "episode/length": 102.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9514563106796117, "episode/intrinsic_return": 0.0}
{"step": 14208, "time": 894.0260689258575, "episode/length": 322.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 14248, "time": 896.7656726837158, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 14400, "time": 903.7941491603851, "episode/length": 160.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 14528, "time": 910.3773505687714, "episode/length": 338.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 14672, "time": 917.5580894947052, "episode/length": 192.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 15392, "time": 944.5364944934845, "episode/length": 158.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 15488, "time": 949.4822700023651, "episode/length": 159.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 15592, "time": 954.3955342769623, "episode/length": 271.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 15720, "time": 960.9162397384644, "episode/length": 183.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 15872, "time": 968.4013483524323, "episode/length": 183.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 15960, "time": 972.8642148971558, "episode/length": 178.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 16024, "time": 976.641813993454, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 16136, "time": 982.0375130176544, "episode/length": 257.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 16688, "time": 1003.7338786125183, "episode/length": 101.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 16728, "time": 1006.4756314754486, "episode/length": 154.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 16768, "time": 1009.7173736095428, "episode/length": 171.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 16880, "time": 1015.1152911186218, "episode/length": 144.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 17000, "time": 1020.5576283931732, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 17000, "time": 1020.5653791427612, "episode/length": 121.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 17000, "time": 1020.5739922523499, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 17256, "time": 1034.6114258766174, "episode/length": 161.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 18128, "time": 1065.8402225971222, "episode/length": 248.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9919678714859438, "episode/intrinsic_return": 0.0}
{"step": 18184, "time": 1069.127763748169, "episode/length": 162.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 18232, "time": 1072.271623134613, "episode/length": 153.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 18368, "time": 1078.5940525531769, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 18392, "time": 1080.7974307537079, "episode/length": 173.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 18456, "time": 1084.6091210842133, "episode/length": 210.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 18720, "time": 1095.4097588062286, "episode/length": 182.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 19096, "time": 1109.443503856659, "episode/length": 295.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 19440, "time": 1122.935958147049, "episode/length": 89.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 19496, "time": 1126.1761584281921, "episode/length": 140.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 19552, "time": 1129.7952237129211, "episode/length": 170.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 19584, "time": 1132.366069316864, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 19592, "time": 1134.1005320549011, "episode/length": 169.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 19624, "time": 1136.749128818512, "episode/length": 65.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 19704, "time": 1140.9923341274261, "episode/length": 163.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 20072, "time": 1170.2520685195923, "eval_episode/length": 50.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9215686274509803}
{"step": 20072, "time": 1176.2924647331238, "eval_episode/length": 151.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 20072, "time": 1178.035890340805, "eval_episode/length": 156.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9745222929936306}
{"step": 20072, "time": 1180.0317182540894, "eval_episode/length": 162.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 20072, "time": 1182.0293140411377, "eval_episode/length": 170.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 20072, "time": 1184.7367632389069, "eval_episode/length": 195.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 20072, "time": 1186.4889919757843, "eval_episode/length": 199.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.98}
{"step": 20072, "time": 1188.8390946388245, "eval_episode/length": 217.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.981651376146789}
{"step": 20248, "time": 1194.73566198349, "episode/length": 223.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 20448, "time": 1203.2311816215515, "episode/length": 92.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.946236559139785, "episode/intrinsic_return": 0.0}
{"step": 20904, "time": 1220.0023262500763, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 20920, "time": 1222.1679558753967, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 21016, "time": 1227.1357333660126, "episode/length": 182.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 21080, "time": 1230.8555920124054, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 21128, "time": 1234.0142509937286, "episode/length": 191.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 21184, "time": 1237.678730249405, "episode/length": 210.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 21504, "time": 1250.1502134799957, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 22168, "time": 1273.8515129089355, "episode/length": 155.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 22184, "time": 1276.0658521652222, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 22272, "time": 1280.9096279144287, "episode/length": 227.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 22608, "time": 1293.8514306545258, "episode/length": 54.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 22609, "time": 1295.9914565086365, "train_stats/sum_log_reward": 1.4389830164106217, "train_stats/max_log_achievement_collect_drink": 1.11864406779661, "train_stats/max_log_achievement_collect_sapling": 7.1440677966101696, "train_stats/max_log_achievement_collect_wood": 0.2796610169491525, "train_stats/max_log_achievement_place_plant": 1.1694915254237288, "train_stats/max_log_achievement_place_table": 0.01694915254237288, "train_stats/max_log_achievement_wake_up": 0.7711864406779662, "train_stats/mean_log_entropy": 0.9385165858824375, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 6.240710076484971, "train/action_min": 0.0, "train/action_std": 2.3908392200033175, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.025239430598999937, "train/actor_opt_grad_steps": 660.0, "train/actor_opt_loss": 265.90689693652945, "train/adv_mag": 2.0332863915228208, "train/adv_max": 2.0325447855844296, "train/adv_mean": 0.03436521280883447, "train/adv_min": -0.40417993080945325, "train/adv_std": 0.1514318032407748, "train/cont_avg": 0.9945357228053435, "train/cont_loss_mean": 0.030123179494083382, "train/cont_loss_std": 0.2685795636804959, "train/cont_neg_acc": 0.04832485261309238, "train/cont_neg_loss": 3.463679765471975, "train/cont_pos_acc": 0.9951023204636028, "train/cont_pos_loss": 0.011433295398605775, "train/cont_pred": 0.9905199988652732, "train/cont_rate": 0.9945357228053435, "train/dyn_loss_mean": 5.183352603257157, "train/dyn_loss_std": 7.47173000735636, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 6.1947855521704405, "train/extr_critic_critic_opt_grad_steps": 660.0, "train/extr_critic_critic_opt_loss": 21428.463300632156, "train/extr_critic_mag": 0.32189673139848785, "train/extr_critic_max": 0.3218967295784987, "train/extr_critic_mean": 0.12698073494959022, "train/extr_critic_min": -0.020921926462013303, "train/extr_critic_std": 0.10615226403507802, "train/extr_return_normed_mag": 2.3237342438501387, "train/extr_return_normed_max": 2.32373424204941, "train/extr_return_normed_mean": 0.19741406889530086, "train/extr_return_normed_min": -0.2979282044934339, "train/extr_return_normed_std": 0.2086909966746947, "train/extr_return_rate": 0.07024640561248538, "train/extr_return_raw_mag": 2.46473752146481, "train/extr_return_raw_max": 2.4647375196502863, "train/extr_return_raw_mean": 0.16424215900580874, "train/extr_return_raw_min": -0.37625869833993114, "train/extr_return_raw_std": 0.23450291117144412, "train/extr_reward_mag": 0.5851029385137194, "train/extr_reward_max": 0.5851029385137194, "train/extr_reward_mean": 0.008722515536369116, "train/extr_reward_min": -0.09069421364150884, "train/extr_reward_std": 0.04128725407008373, "train/image_loss_mean": 92.06935039549383, "train/image_loss_std": 49.98485332226935, "train/model_loss_mean": 95.54829162131739, "train/model_loss_std": 51.38716924099522, "train/model_opt_grad_norm": 294.6360975999099, "train/model_opt_grad_steps": 650.0, "train/model_opt_loss": 1280.2093303185384, "train/model_opt_model_opt_grad_overflow": 0.007633587786259542, "train/model_opt_model_opt_grad_scale": 12.002027671755725, "train/policy_entropy_mag": 1.418809956380429, "train/policy_entropy_max": 1.418809956380429, "train/policy_entropy_mean": 0.8844751078095144, "train/policy_entropy_min": 0.7441631852442981, "train/policy_entropy_std": 0.10917664976712345, "train/policy_logprob_mag": 6.73909050817708, "train/policy_logprob_max": -0.3585523961268309, "train/policy_logprob_mean": -0.8861465295990005, "train/policy_logprob_min": -6.73909050817708, "train/policy_logprob_std": 0.8121735235206954, "train/policy_randomness_mag": 0.5007776529563748, "train/policy_randomness_max": 0.5007776529563748, "train/policy_randomness_mean": 0.3121808945905161, "train/policy_randomness_min": 0.2626569467020854, "train/policy_randomness_std": 0.03853456604912991, "train/post_ent_mag": 50.47670125597306, "train/post_ent_max": 50.47670125597306, "train/post_ent_mean": 31.78936059966342, "train/post_ent_min": 16.40635199219216, "train/post_ent_std": 6.762924033835644, "train/prior_ent_mag": 55.53710296863818, "train/prior_ent_max": 55.53710296863818, "train/prior_ent_mean": 37.647715648622004, "train/prior_ent_min": 21.45264718732761, "train/prior_ent_std": 6.259709091330985, "train/rep_loss_mean": 5.183352603257157, "train/rep_loss_std": 7.47173000735636, "train/reward_avg": 0.00937947273016232, "train/reward_loss_mean": 0.3388071656227112, "train/reward_loss_std": 0.6893529997843449, "train/reward_max_data": 1.0, "train/reward_max_pred": 0.6892968680112417, "train/reward_neg_acc": 0.9970203624426863, "train/reward_neg_loss": 0.2959210292528604, "train/reward_pos_acc": 0.43550829265181346, "train/reward_pos_loss": 3.196462882839086, "train/reward_pred": 0.006324348638886372, "train/reward_rate": 0.01440243320610687, "train_stats/max_log_achievement_defeat_zombie": 0.3150684931506849, "train_stats/max_log_achievement_eat_cow": 0.22535211267605634, "eval_stats/sum_log_reward": 1.1624999567866325, "eval_stats/max_log_achievement_collect_drink": 0.0, "eval_stats/max_log_achievement_collect_sapling": 9.75, "eval_stats/max_log_achievement_collect_wood": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3125, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_table": 0.0, "eval_stats/max_log_achievement_wake_up": 0.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 0.006495530717074871, "report/cont_loss_std": 0.10318472981452942, "report/cont_neg_acc": 0.25, "report/cont_neg_loss": 1.469348430633545, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.0007588528678752482, "report/cont_pred": 0.9980731010437012, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 6.079857349395752, "report/dyn_loss_std": 5.052931785583496, "report/image_loss_mean": 18.23486328125, "report/image_loss_std": 14.10184097290039, "report/model_loss_mean": 21.99357032775879, "report/model_loss_std": 15.675589561462402, "report/post_ent_mag": 42.3740234375, "report/post_ent_max": 42.3740234375, "report/post_ent_mean": 31.73076629638672, "report/post_ent_min": 14.90773868560791, "report/post_ent_std": 4.077402591705322, "report/prior_ent_mag": 48.70484924316406, "report/prior_ent_max": 48.70484924316406, "report/prior_ent_mean": 36.12310791015625, "report/prior_ent_min": 19.801454544067383, "report/prior_ent_std": 3.9275875091552734, "report/rep_loss_mean": 6.079857349395752, "report/rep_loss_std": 5.052931785583496, "report/reward_avg": 0.0008789061103016138, "report/reward_loss_mean": 0.104297935962677, "report/reward_loss_std": 0.40808573365211487, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9898173809051514, "report/reward_neg_acc": 0.9852796792984009, "report/reward_neg_loss": 0.09483271092176437, "report/reward_pos_acc": 0.6000000238418579, "report/reward_pos_loss": 2.0333104133605957, "report/reward_pred": 0.005357545800507069, "report/reward_rate": 0.0048828125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.03661365061998367, "eval/cont_loss_std": 0.6753374934196472, "eval/cont_neg_acc": 0.0, "eval/cont_neg_loss": 12.494795799255371, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.827245099178981e-06, "eval/cont_pred": 0.9999922513961792, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 8.580851554870605, "eval/dyn_loss_std": 7.390114784240723, "eval/image_loss_mean": 54.172157287597656, "eval/image_loss_std": 58.18271255493164, "eval/model_loss_mean": 59.44839859008789, "eval/model_loss_std": 60.40367126464844, "eval/post_ent_mag": 56.06074142456055, "eval/post_ent_max": 56.06074142456055, "eval/post_ent_mean": 29.44232940673828, "eval/post_ent_min": 14.849530220031738, "eval/post_ent_std": 6.32832145690918, "eval/prior_ent_mag": 54.329444885253906, "eval/prior_ent_max": 54.329444885253906, "eval/prior_ent_mean": 34.846702575683594, "eval/prior_ent_min": 19.214853286743164, "eval/prior_ent_std": 6.269819736480713, "eval/rep_loss_mean": 8.580851554870605, "eval/rep_loss_std": 7.390114784240723, "eval/reward_avg": 0.01835937425494194, "eval/reward_loss_mean": 0.09112223982810974, "eval/reward_loss_std": 0.6396687030792236, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9896999597549438, "eval/reward_neg_acc": 0.9930139780044556, "eval/reward_neg_loss": 0.044924069195985794, "eval/reward_pos_acc": 0.6818181872367859, "eval/reward_pos_loss": 2.1952390670776367, "eval/reward_pred": 0.014592594467103481, "eval/reward_rate": 0.021484375, "replay/size": 22105.0, "replay/inserts": 21048.0, "replay/samples": 21040.0, "replay/insert_wait_avg": 1.463813955726754e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.046987888930868e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 6368.0, "eval_replay/inserts": 3456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.3015060513107865e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.834766387939453e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 978.1818280220032, "timer/env.step_count": 2631.0, "timer/env.step_total": 263.64712476730347, "timer/env.step_frac": 0.2695277270693409, "timer/env.step_avg": 0.10020795316127079, "timer/env.step_min": 0.022791385650634766, "timer/env.step_max": 5.27807092666626, "timer/replay._sample_count": 21040.0, "timer/replay._sample_total": 11.56352972984314, "timer/replay._sample_frac": 0.011821452207127927, "timer/replay._sample_avg": 0.0005495974206199211, "timer/replay._sample_min": 0.0003476142883300781, "timer/replay._sample_max": 0.009447574615478516, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3063.0, "timer/agent.policy_total": 52.50981950759888, "timer/agent.policy_frac": 0.053681041707531824, "timer/agent.policy_avg": 0.017143264612340475, "timer/agent.policy_min": 0.009823322296142578, "timer/agent.policy_max": 0.10998201370239258, "timer/dataset_train_count": 1315.0, "timer/dataset_train_total": 0.1512162685394287, "timer/dataset_train_frac": 0.00015458912055768353, "timer/dataset_train_avg": 0.00011499336010602944, "timer/dataset_train_min": 8.225440979003906e-05, "timer/dataset_train_max": 0.000499725341796875, "timer/agent.train_count": 1315.0, "timer/agent.train_total": 595.0909626483917, "timer/agent.train_frac": 0.6083643608997874, "timer/agent.train_avg": 0.45254065600638155, "timer/agent.train_min": 0.4375011920928955, "timer/agent.train_max": 1.3300261497497559, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48111701011657715, "timer/agent.report_frac": 0.0004918482395951389, "timer/agent.report_avg": 0.24055850505828857, "timer/agent.report_min": 0.23470377922058105, "timer/agent.report_max": 0.2464132308959961, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.314815899144176e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 21.517218040995683}
{"step": 22640, "time": 1297.32639336586, "episode/length": 181.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 22688, "time": 1300.590074300766, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 22688, "time": 1300.6000709533691, "episode/length": 208.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 22984, "time": 1313.7465744018555, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 22992, "time": 1315.7714641094208, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 23584, "time": 1337.2919313907623, "episode/length": 174.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 23680, "time": 1342.2024240493774, "episode/length": 133.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 23752, "time": 1345.9707839488983, "episode/length": 184.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 23808, "time": 1349.637176990509, "episode/length": 139.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 23824, "time": 1351.685753107071, "episode/length": 147.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 24168, "time": 1364.6084365844727, "episode/length": 184.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 24328, "time": 1371.4934940338135, "episode/length": 167.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 24416, "time": 1376.3200738430023, "episode/length": 177.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 24856, "time": 1393.4845747947693, "episode/length": 158.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 24864, "time": 1395.5190563201904, "episode/length": 131.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 24904, "time": 1398.14253282547, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 25032, "time": 1404.2879946231842, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 25144, "time": 1410.3369283676147, "episode/length": 164.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 25160, "time": 1412.6424162387848, "episode/length": 31.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 25352, "time": 1420.8362131118774, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 25632, "time": 1432.1674904823303, "episode/length": 151.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 25656, "time": 1434.3910598754883, "episode/length": 37.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 25912, "time": 1444.5036907196045, "episode/length": 217.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 26128, "time": 1453.6589632034302, "episode/length": 158.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 26256, "time": 1459.5845403671265, "episode/length": 136.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9635036496350365, "episode/intrinsic_return": 0.0}
{"step": 26256, "time": 1459.5927684307098, "episode/length": 138.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 26416, "time": 1468.2481362819672, "episode/length": 193.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 26696, "time": 1479.1031293869019, "episode/length": 295.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 26768, "time": 1483.43004322052, "episode/length": 138.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 27000, "time": 1492.820874929428, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 27080, "time": 1497.7955782413483, "episode/length": 38.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 27192, "time": 1503.5715849399567, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 27424, "time": 1513.1594026088715, "episode/length": 42.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 27496, "time": 1516.8893389701843, "episode/length": 170.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 27536, "time": 1520.0756340026855, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 27552, "time": 1522.2172186374664, "episode/length": 141.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 27928, "time": 1536.2928898334503, "episode/length": 208.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 28528, "time": 1558.3875348567963, "episode/length": 190.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 28872, "time": 1571.3146197795868, "episode/length": 180.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.988950276243094, "episode/intrinsic_return": 0.0}
{"step": 28872, "time": 1571.3234314918518, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 29136, "time": 1583.7930295467377, "episode/length": 150.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 29176, "time": 1586.5390236377716, "episode/length": 202.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 29224, "time": 1589.7417578697205, "episode/length": 210.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 29608, "time": 1604.2882905006409, "episode/length": 47.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 29672, "time": 1608.0892524719238, "episode/length": 371.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9758064516129032, "episode/intrinsic_return": 0.0}
{"step": 30056, "time": 1637.6183393001556, "eval_episode/length": 39.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.975}
{"step": 30056, "time": 1642.1872417926788, "eval_episode/length": 111.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9553571428571429}
{"step": 30056, "time": 1646.303522825241, "eval_episode/length": 164.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 30056, "time": 1649.2342960834503, "eval_episode/length": 167.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9940476190476191}
{"step": 30056, "time": 1651.6848554611206, "eval_episode/length": 188.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 30056, "time": 1654.049433708191, "eval_episode/length": 203.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 30056, "time": 1656.5380041599274, "eval_episode/length": 183.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9891304347826086}
{"step": 30056, "time": 1658.4496593475342, "eval_episode/length": 229.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9826086956521739}
{"step": 30128, "time": 1661.265881538391, "episode/length": 199.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 30144, "time": 1663.4567096233368, "episode/length": 368.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 30280, "time": 1669.3916275501251, "episode/length": 175.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 30280, "time": 1669.4002349376678, "episode/length": 175.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 30576, "time": 1683.083783864975, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 30584, "time": 1684.6770741939545, "episode/length": 121.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 30896, "time": 1697.1567962169647, "episode/length": 219.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 31448, "time": 1717.4826855659485, "episode/length": 221.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 31696, "time": 1727.7776937484741, "episode/length": 193.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 31752, "time": 1731.0905182361603, "episode/length": 183.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 31912, "time": 1738.0268008708954, "episode/length": 166.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 31976, "time": 1741.7186913490295, "episode/length": 230.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 32016, "time": 1744.8976306915283, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 32208, "time": 1752.8832364082336, "episode/length": 240.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 32344, "time": 1759.6477553844452, "episode/length": 180.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 32832, "time": 1780.2545385360718, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 33120, "time": 1791.7033426761627, "episode/length": 96.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9484536082474226, "episode/intrinsic_return": 0.0}
{"step": 33152, "time": 1794.8907911777496, "episode/length": 181.0, "episode/score": 1.0999999716877937, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 33240, "time": 1799.8538920879364, "episode/length": 128.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9457364341085271, "episode/intrinsic_return": 0.0}
{"step": 33512, "time": 1810.7692630290985, "episode/length": 186.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 33800, "time": 1822.009673833847, "episode/length": 235.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 33824, "time": 1824.563173532486, "episode/length": 230.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 34504, "time": 1849.1280348300934, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 34792, "time": 1861.2041273117065, "episode/length": 204.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 34864, "time": 1866.0296630859375, "episode/length": 253.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.984251968503937, "episode/intrinsic_return": 0.0}
{"step": 34888, "time": 1868.809681892395, "episode/length": 391.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9770408163265306, "episode/intrinsic_return": 0.0}
{"step": 35120, "time": 1879.2548389434814, "episode/length": 200.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 35856, "time": 1906.9238028526306, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 35904, "time": 1910.658212184906, "episode/length": 259.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 36128, "time": 1920.5722072124481, "episode/length": 157.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 36224, "time": 1926.006742477417, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 36304, "time": 1931.044605255127, "episode/length": 188.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 36408, "time": 1936.4821722507477, "episode/length": 325.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9969325153374233, "episode/intrinsic_return": 0.0}
{"step": 36528, "time": 1942.6766288280487, "episode/length": 175.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 36600, "time": 1946.4334034919739, "episode/length": 434.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 37224, "time": 1968.879402399063, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 37608, "time": 1983.2400343418121, "episode/length": 218.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 37648, "time": 1986.3177044391632, "episode/length": 177.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 37704, "time": 1989.6223232746124, "episode/length": 174.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 37760, "time": 1993.4012644290924, "episode/length": 168.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 37848, "time": 1997.7127478122711, "episode/length": 164.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 38032, "time": 2005.781884431839, "episode/length": 237.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 38080, "time": 2008.9793393611908, "episode/length": 184.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 38368, "time": 2020.3826203346252, "episode/length": 35.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 38464, "time": 2025.1331260204315, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 38584, "time": 2030.5268132686615, "episode/length": 102.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 38864, "time": 2041.6149010658264, "episode/length": 156.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 38888, "time": 2043.8304424285889, "episode/length": 154.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 38888, "time": 2043.8381910324097, "episode/length": 106.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9439252336448598, "episode/intrinsic_return": 0.0}
{"step": 39136, "time": 2055.947035551071, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 39576, "time": 2072.169183254242, "episode/length": 215.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 39912, "time": 2085.1002910137177, "episode/length": 180.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 39960, "time": 2088.2174088954926, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 40008, "time": 2091.390661716461, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 40040, "time": 2108.9730381965637, "eval_episode/length": 52.0, "eval_episode/score": 2.1000000312924385, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 40040, "time": 2112.7833638191223, "eval_episode/length": 104.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 40040, "time": 2115.3902175426483, "eval_episode/length": 77.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9358974358974359}
{"step": 40040, "time": 2118.0979809761047, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 40040, "time": 2118.106736421585, "eval_episode/length": 154.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 40040, "time": 2122.059915781021, "eval_episode/length": 167.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 40040, "time": 2124.2341632843018, "eval_episode/length": 181.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 40040, "time": 2126.4743382930756, "eval_episode/length": 199.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.995}
{"step": 40304, "time": 2135.64847946167, "episode/length": 176.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 40344, "time": 2138.4189965724945, "episode/length": 47.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 40432, "time": 2143.404103755951, "episode/length": 161.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 40648, "time": 2151.9830417633057, "episode/length": 222.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 41056, "time": 2168.948053598404, "episode/length": 270.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.988929889298893, "episode/intrinsic_return": 0.0}
{"step": 41392, "time": 2182.10351896286, "episode/length": 172.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 41432, "time": 2184.7715718746185, "episode/length": 231.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 41528, "time": 2189.4500257968903, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 41896, "time": 2203.5064175128937, "episode/length": 198.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 41920, "time": 2206.135805130005, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 42128, "time": 2214.620341539383, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 42592, "time": 2231.8574879169464, "episode/length": 242.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 42704, "time": 2237.2041323184967, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 42992, "time": 2248.4641115665436, "episode/length": 194.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 43032, "time": 2251.150500059128, "episode/length": 246.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 43208, "time": 2258.729971885681, "episode/length": 163.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 43664, "time": 2275.9452447891235, "episode/length": 217.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.981651376146789, "episode/intrinsic_return": 0.0}
{"step": 43736, "time": 2279.7502608299255, "episode/length": 200.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 43992, "time": 2289.9465618133545, "episode/length": 174.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 44105, "time": 2296.2324216365814, "train_stats/sum_log_reward": 2.4135592528066394, "train_stats/max_log_achievement_collect_drink": 9.686440677966102, "train_stats/max_log_achievement_collect_sapling": 1.771186440677966, "train_stats/max_log_achievement_collect_wood": 0.8305084745762712, "train_stats/max_log_achievement_defeat_zombie": 0.07627118644067797, "train_stats/max_log_achievement_eat_cow": 0.09322033898305085, "train_stats/max_log_achievement_place_plant": 1.423728813559322, "train_stats/max_log_achievement_place_table": 0.025423728813559324, "train_stats/max_log_achievement_wake_up": 1.9915254237288136, "train_stats/mean_log_entropy": 0.4323994476916426, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.667036946614584, "train/action_min": 0.0, "train/action_std": 2.905231572963573, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03919939427740044, "train/actor_opt_grad_steps": 1990.0, "train/actor_opt_loss": 17.41680316792594, "train/adv_mag": 1.589295581093541, "train/adv_max": 1.5880276185494882, "train/adv_mean": 0.011673975245125971, "train/adv_min": -0.5666525001879091, "train/adv_std": 0.12183673961295022, "train/cont_avg": 0.9944878472222223, "train/cont_loss_mean": 0.0046227260966555115, "train/cont_loss_std": 0.06862444446707269, "train/cont_neg_acc": 0.7991975375899563, "train/cont_neg_loss": 0.530032014730117, "train/cont_pos_acc": 0.9997234883131805, "train/cont_pos_loss": 0.001488475117440868, "train/cont_pred": 0.99449174757357, "train/cont_rate": 0.9944878472222223, "train/dyn_loss_mean": 6.835743618011475, "train/dyn_loss_std": 6.098752876564308, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.4357401962633487, "train/extr_critic_critic_opt_grad_steps": 1990.0, "train/extr_critic_critic_opt_loss": 16614.9583984375, "train/extr_critic_mag": 1.5602942908251727, "train/extr_critic_max": 1.5602942908251727, "train/extr_critic_mean": 0.3053649186881052, "train/extr_critic_min": -0.41039081767753316, "train/extr_critic_std": 0.6550227103409944, "train/extr_return_normed_mag": 2.3949698059647173, "train/extr_return_normed_max": 2.3949698059647173, "train/extr_return_normed_mean": 0.36903187036514284, "train/extr_return_normed_min": -0.26490459546998696, "train/extr_return_normed_std": 0.3665885279575984, "train/extr_return_rate": 0.3259418567021688, "train/extr_return_raw_mag": 4.424805808950354, "train/extr_return_raw_max": 4.4230705331873015, "train/extr_return_raw_mean": 0.3289826676318491, "train/extr_return_raw_min": -0.9516804968869245, "train/extr_return_raw_std": 0.7425117077650847, "train/extr_reward_mag": 0.9935896352485374, "train/extr_reward_max": 0.9935896352485374, "train/extr_reward_mean": 0.011947938245807395, "train/extr_reward_min": -0.32315023298616763, "train/extr_reward_std": 0.08971003465078495, "train/image_loss_mean": 22.662476172270598, "train/image_loss_std": 23.703248751605, "train/model_loss_mean": 26.85336351747866, "train/model_loss_std": 25.512119787710684, "train/model_opt_grad_norm": 170.88971068770798, "train/model_opt_grad_steps": 1980.0, "train/model_opt_loss": 804.8538632993345, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 28.935185185185187, "train/policy_entropy_mag": 2.042204079804597, "train/policy_entropy_max": 2.042204079804597, "train/policy_entropy_mean": 0.4302596874811031, "train/policy_entropy_min": 0.07975307316691788, "train/policy_entropy_std": 0.38274412309681927, "train/policy_logprob_mag": 7.436711802305998, "train/policy_logprob_max": -0.009507749153784028, "train/policy_logprob_mean": -0.4302664683924781, "train/policy_logprob_min": -7.436711802305998, "train/policy_logprob_std": 1.0381069854453757, "train/policy_randomness_mag": 0.7208084181503013, "train/policy_randomness_max": 0.7208084181503013, "train/policy_randomness_mean": 0.15186278803480996, "train/policy_randomness_min": 0.02814933496216933, "train/policy_randomness_std": 0.1350918780874323, "train/post_ent_mag": 42.06188456217448, "train/post_ent_max": 42.06188456217448, "train/post_ent_mean": 29.94062025282118, "train/post_ent_min": 14.399713523299607, "train/post_ent_std": 4.5289667235480415, "train/prior_ent_mag": 52.078749084472655, "train/prior_ent_max": 52.078749084472655, "train/prior_ent_mean": 36.918494923909506, "train/prior_ent_min": 17.61880455723515, "train/prior_ent_std": 5.618816711284496, "train/rep_loss_mean": 6.835743618011475, "train/rep_loss_std": 6.098752876564308, "train/reward_avg": 0.010137442066506654, "train/reward_loss_mean": 0.08481836381057899, "train/reward_loss_std": 0.3988270946122982, "train/reward_max_data": 1.0029629636693884, "train/reward_max_pred": 0.9916296976583975, "train/reward_neg_acc": 0.9952345799516749, "train/reward_neg_loss": 0.06403855693837007, "train/reward_pos_acc": 0.8488451061425386, "train/reward_pos_loss": 1.4429994172520109, "train/reward_pred": 0.008928489322877592, "train/reward_rate": 0.015104166666666667, "eval_stats/sum_log_reward": 2.849999949336052, "eval_stats/max_log_achievement_collect_drink": 7.75, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_wood": 0.875, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_table": 0.0625, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.1, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_defeat_skeleton": 0.037037037037037035, "train_stats/max_log_achievement_make_wood_pickaxe": 0.023255813953488372, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "report/cont_avg": 0.9921875, "report/cont_loss_mean": 0.0053711095824837685, "report/cont_loss_std": 0.16779319941997528, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.651810640003532e-05, "report/cont_pos_acc": 0.999015748500824, "report/cont_pos_loss": 0.005412720143795013, "report/cont_pred": 0.9910931587219238, "report/cont_rate": 0.9921875, "report/dyn_loss_mean": 7.598102569580078, "report/dyn_loss_std": 6.7514328956604, "report/image_loss_mean": 19.42552947998047, "report/image_loss_std": 18.234535217285156, "report/model_loss_mean": 24.072681427001953, "report/model_loss_std": 20.870872497558594, "report/post_ent_mag": 42.482147216796875, "report/post_ent_max": 42.482147216796875, "report/post_ent_mean": 29.8214111328125, "report/post_ent_min": 13.233799934387207, "report/post_ent_std": 5.519845008850098, "report/prior_ent_mag": 51.114707946777344, "report/prior_ent_max": 51.114707946777344, "report/prior_ent_mean": 37.683555603027344, "report/prior_ent_min": 15.049686431884766, "report/prior_ent_std": 7.044907569885254, "report/rep_loss_mean": 7.598102569580078, "report/rep_loss_std": 6.7514328956604, "report/reward_avg": 0.01923828199505806, "report/reward_loss_mean": 0.08292096108198166, "report/reward_loss_std": 0.3752875030040741, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9946327209472656, "report/reward_neg_acc": 0.9909819960594177, "report/reward_neg_loss": 0.05344988405704498, "report/reward_pos_acc": 0.884615421295166, "report/reward_pos_loss": 1.214156985282898, "report/reward_pred": 0.01750900223851204, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.0064292955212295055, "eval/cont_loss_std": 0.18011760711669922, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 1.0929585695266724, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.5390032533323392e-05, "eval/cont_pred": 0.9957109689712524, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 11.224071502685547, "eval/dyn_loss_std": 8.261640548706055, "eval/image_loss_mean": 41.45595169067383, "eval/image_loss_std": 39.4879035949707, "eval/model_loss_mean": 48.306304931640625, "eval/model_loss_std": 41.955894470214844, "eval/post_ent_mag": 43.2149658203125, "eval/post_ent_max": 43.2149658203125, "eval/post_ent_mean": 30.11838150024414, "eval/post_ent_min": 12.006678581237793, "eval/post_ent_std": 6.119874477386475, "eval/prior_ent_mag": 55.20597457885742, "eval/prior_ent_max": 55.20597457885742, "eval/prior_ent_mean": 39.239219665527344, "eval/prior_ent_min": 15.973136901855469, "eval/prior_ent_std": 7.862945079803467, "eval/rep_loss_mean": 11.224071502685547, "eval/rep_loss_std": 8.261640548706055, "eval/reward_avg": 0.014160155318677425, "eval/reward_loss_mean": 0.10948104411363602, "eval/reward_loss_std": 0.689601719379425, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9949270486831665, "eval/reward_neg_acc": 0.993027925491333, "eval/reward_neg_loss": 0.06191789731383324, "eval/reward_pos_acc": 0.75, "eval/reward_pos_loss": 2.4971511363983154, "eval/reward_pred": 0.011038722470402718, "eval/reward_rate": 0.01953125, "replay/size": 43601.0, "replay/inserts": 21496.0, "replay/samples": 21504.0, "replay/insert_wait_avg": 1.4449190729650192e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.17341648822739e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 9808.0, "eval_replay/inserts": 3440.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2697868568952694e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2246487140656, "timer/env.step_count": 2687.0, "timer/env.step_total": 270.1771969795227, "timer/env.step_frac": 0.2701165156516337, "timer/env.step_avg": 0.10054975697042155, "timer/env.step_min": 0.022551774978637695, "timer/env.step_max": 3.54435658454895, "timer/replay._sample_count": 21504.0, "timer/replay._sample_total": 11.93951940536499, "timer/replay._sample_frac": 0.011936837810100942, "timer/replay._sample_avg": 0.0005552231866334166, "timer/replay._sample_min": 0.0004036426544189453, "timer/replay._sample_max": 0.011446237564086914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3117.0, "timer/agent.policy_total": 53.11471939086914, "timer/agent.policy_frac": 0.0531027899174009, "timer/agent.policy_avg": 0.01704033345873248, "timer/agent.policy_min": 0.009718179702758789, "timer/agent.policy_max": 0.10310983657836914, "timer/dataset_train_count": 1344.0, "timer/dataset_train_total": 0.1563112735748291, "timer/dataset_train_frac": 0.00015627616633502286, "timer/dataset_train_avg": 0.0001163030309336526, "timer/dataset_train_min": 0.00010085105895996094, "timer/dataset_train_max": 0.0010843276977539062, "timer/agent.train_count": 1344.0, "timer/agent.train_total": 610.0481746196747, "timer/agent.train_frac": 0.6099111588621421, "timer/agent.train_avg": 0.45390489183011506, "timer/agent.train_min": 0.4378664493560791, "timer/agent.train_max": 1.509425401687622, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.46968722343444824, "timer/agent.report_frac": 0.00046958173250209295, "timer/agent.report_avg": 0.23484361171722412, "timer/agent.report_min": 0.2246260643005371, "timer/agent.report_max": 0.24506115913391113, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.409385681152344e-05, "timer/dataset_eval_frac": 3.408619939066294e-08, "timer/dataset_eval_avg": 3.409385681152344e-05, "timer/dataset_eval_min": 3.409385681152344e-05, "timer/dataset_eval_max": 3.409385681152344e-05, "fps": 21.4909091859419}
{"step": 44296, "time": 2302.501108646393, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 44472, "time": 2310.093639612198, "episode/length": 157.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 44480, "time": 2312.1361603736877, "episode/length": 185.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 44528, "time": 2315.2868077754974, "episode/length": 374.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 44600, "time": 2319.1025092601776, "episode/length": 195.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 44888, "time": 2330.4912493228912, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 45520, "time": 2354.2518236637115, "episode/length": 190.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 45616, "time": 2359.0063841342926, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 45936, "time": 2371.312378168106, "episode/length": 274.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 45960, "time": 2373.5570685863495, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 46016, "time": 2377.135593891144, "episode/length": 185.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 46304, "time": 2388.535902261734, "episode/length": 176.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 46328, "time": 2390.7266476154327, "episode/length": 215.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 46344, "time": 2392.850894212723, "episode/length": 233.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 46384, "time": 2396.043521642685, "episode/length": 45.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 47240, "time": 2427.0506188869476, "episode/length": 116.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 47264, "time": 2429.605707883835, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 47496, "time": 2438.7329342365265, "episode/length": 143.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 47640, "time": 2445.3499417304993, "episode/length": 252.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9802371541501976, "episode/intrinsic_return": 0.0}
{"step": 47672, "time": 2448.012490749359, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 47720, "time": 2451.289632797241, "episode/length": 274.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 47840, "time": 2457.76225566864, "episode/length": 188.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 48384, "time": 2478.626969575882, "episode/length": 305.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 48776, "time": 2493.11599445343, "episode/length": 159.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 48936, "time": 2500.2251057624817, "episode/length": 136.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 49568, "time": 2525.032397031784, "episode/length": 287.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 49640, "time": 2528.8784589767456, "episode/length": 156.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 49768, "time": 2535.501046180725, "episode/length": 255.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 50024, "time": 2571.2912907600403, "eval_episode/length": 162.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 50024, "time": 2573.7649676799774, "eval_episode/length": 168.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 50024, "time": 2576.237680196762, "eval_episode/length": 176.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9717514124293786}
{"step": 50024, "time": 2578.329529285431, "eval_episode/length": 177.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9943820224719101}
{"step": 50024, "time": 2581.557636976242, "eval_episode/length": 201.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9801980198019802}
{"step": 50024, "time": 2584.518597126007, "eval_episode/length": 42.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.8837209302325582}
{"step": 50024, "time": 2588.4980289936066, "eval_episode/length": 260.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9808429118773946}
{"step": 50024, "time": 2590.6845557689667, "eval_episode/length": 261.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9961832061068703}
{"step": 50120, "time": 2593.988659143448, "episode/length": 305.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 50232, "time": 2599.258805990219, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 50456, "time": 2608.3550560474396, "episode/length": 189.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 50616, "time": 2615.2524650096893, "episode/length": 47.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 50784, "time": 2622.7912216186523, "episode/length": 442.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 51104, "time": 2635.2848238945007, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 51120, "time": 2637.4211461544037, "episode/length": 193.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 51128, "time": 2639.0096085071564, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 51240, "time": 2644.3630080223083, "episode/length": 449.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 51432, "time": 2652.4095001220703, "episode/length": 38.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 51464, "time": 2655.0673718452454, "episode/length": 41.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 51520, "time": 2658.6901667118073, "episode/length": 174.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 51752, "time": 2667.896529197693, "episode/length": 28.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8275862068965517, "episode/intrinsic_return": 0.0}
{"step": 52128, "time": 2682.4008016586304, "episode/length": 188.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 52696, "time": 2703.0294477939606, "episode/length": 279.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 52888, "time": 2711.8947706222534, "episode/length": 222.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 52928, "time": 2715.463248729706, "episode/length": 267.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9888059701492538, "episode/intrinsic_return": 0.0}
{"step": 53000, "time": 2719.832426548004, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 53024, "time": 2723.015822172165, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 53416, "time": 2737.863753557205, "episode/length": 271.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 53456, "time": 2741.553957462311, "episode/length": 53.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 53696, "time": 2751.8005397319794, "episode/length": 278.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 53768, "time": 2755.5277001857758, "episode/length": 204.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 53976, "time": 2764.0583362579346, "episode/length": 130.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 54112, "time": 2770.5282187461853, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 54408, "time": 2781.878535270691, "episode/length": 175.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 54504, "time": 2786.6327607631683, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 54696, "time": 2794.665316104889, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 54800, "time": 2800.162729740143, "episode/length": 167.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 54864, "time": 2803.9147222042084, "episode/length": 145.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 55512, "time": 2827.211167573929, "episode/length": 217.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 55624, "time": 2832.922609567642, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 55736, "time": 2838.268235206604, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 55992, "time": 2848.476346731186, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 56064, "time": 2852.7315328121185, "episode/length": 40.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 56328, "time": 2863.1247720718384, "episode/length": 190.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 56400, "time": 2867.3233671188354, "episode/length": 285.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9895104895104895, "episode/intrinsic_return": 0.0}
{"step": 56512, "time": 2872.707163333893, "episode/length": 205.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 56848, "time": 2885.609777212143, "episode/length": 292.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 57072, "time": 2894.832043647766, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 57272, "time": 2903.0263245105743, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 57504, "time": 2914.9425945281982, "episode/length": 179.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9611111111111111, "episode/intrinsic_return": 0.0}
{"step": 57984, "time": 2933.878251552582, "episode/length": 183.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 58208, "time": 2943.763739824295, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9577464788732394, "episode/intrinsic_return": 0.0}
{"step": 58408, "time": 2952.336400985718, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 58424, "time": 2954.450393676758, "episode/length": 196.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 58432, "time": 2956.511006832123, "episode/length": 144.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 58512, "time": 2960.723739385605, "episode/length": 272.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 58896, "time": 2975.0559599399567, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 59032, "time": 2981.0441579818726, "episode/length": 130.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 59264, "time": 2990.5552151203156, "episode/length": 131.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.946969696969697, "episode/intrinsic_return": 0.0}
{"step": 59280, "time": 2993.213682413101, "episode/length": 221.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 59680, "time": 3008.844412088394, "episode/length": 49.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 59720, "time": 3011.672213792801, "episode/length": 163.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 59944, "time": 3020.82630777359, "episode/length": 188.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 59952, "time": 3022.8268043994904, "episode/length": 179.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 59968, "time": 3024.9691376686096, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 60008, "time": 3044.1631944179535, "eval_episode/length": 71.0, "eval_episode/score": 4.100000023841858, "eval_episode/reward_rate": 0.9861111111111112}
{"step": 60008, "time": 3047.232558965683, "eval_episode/length": 34.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8571428571428571}
{"step": 60008, "time": 3049.9059734344482, "eval_episode/length": 134.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9925925925925926}
{"step": 60008, "time": 3051.8708176612854, "eval_episode/length": 144.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.993103448275862}
{"step": 60008, "time": 3054.4627633094788, "eval_episode/length": 168.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 60008, "time": 3057.6714990139008, "eval_episode/length": 175.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 60008, "time": 3060.5724182128906, "eval_episode/length": 207.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 60008, "time": 3062.813782453537, "eval_episode/length": 221.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 60608, "time": 3083.417033433914, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 60816, "time": 3092.6029345989227, "episode/length": 193.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 61176, "time": 3106.726459503174, "episode/length": 181.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 61264, "time": 3111.6195106506348, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 61280, "time": 3113.706375837326, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 61304, "time": 3115.8565425872803, "episode/length": 169.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 61400, "time": 3120.670832633972, "episode/length": 180.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 61952, "time": 3141.61998295784, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 62088, "time": 3147.955302000046, "episode/length": 100.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 62216, "time": 3153.718652486801, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 62376, "time": 3160.7581667900085, "episode/length": 434.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 62504, "time": 3166.625029563904, "episode/length": 165.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9578313253012049, "episode/intrinsic_return": 0.0}
{"step": 62864, "time": 3180.493335723877, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 62928, "time": 3184.2318625450134, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 63120, "time": 3192.325377702713, "episode/length": 31.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 63192, "time": 3196.108563184738, "episode/length": 240.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.983402489626556, "episode/intrinsic_return": 0.0}
{"step": 63456, "time": 3206.9919769763947, "episode/length": 32.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8787878787878788, "episode/intrinsic_return": 0.0}
{"step": 63536, "time": 3211.8793342113495, "episode/length": 197.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 63592, "time": 3215.130602836609, "episode/length": 151.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 63704, "time": 3220.5633778572083, "episode/length": 185.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 63856, "time": 3227.516860961914, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 64352, "time": 3245.848359107971, "episode/length": 177.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 64656, "time": 3257.6592099666595, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 64704, "time": 3260.747309923172, "episode/length": 197.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 64816, "time": 3266.1202187538147, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 65024, "time": 3274.6051528453827, "episode/length": 178.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 65488, "time": 3291.844126224518, "episode/length": 222.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 65545, "time": 3297.3954331874847, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.2723753060867535, "train/action_min": 0.0, "train/action_std": 2.841014290923503, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.047232727923277595, "train/actor_opt_grad_steps": 3335.0, "train/actor_opt_loss": 17.769225672554615, "train/adv_mag": 1.3008488007445833, "train/adv_max": 1.3008488007445833, "train/adv_mean": 0.006472738907123401, "train/adv_min": -0.5341799982003311, "train/adv_std": 0.09974836577564034, "train/cont_avg": 0.9944685750932836, "train/cont_loss_mean": 0.0005502141490534262, "train/cont_loss_std": 0.014471454311314486, "train/cont_neg_acc": 0.9843727817286306, "train/cont_neg_loss": 0.06462203888020043, "train/cont_pos_acc": 0.9999633137859515, "train/cont_pos_loss": 0.00019988368046300372, "train/cont_pred": 0.9944593737374491, "train/cont_rate": 0.9944685750932836, "train/dyn_loss_mean": 8.315708590977227, "train/dyn_loss_std": 6.996750860071894, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0913311981443148, "train/extr_critic_critic_opt_grad_steps": 3335.0, "train/extr_critic_critic_opt_loss": 14450.23927238806, "train/extr_critic_mag": 1.9551680301552388, "train/extr_critic_max": 1.9551680301552388, "train/extr_critic_mean": 0.3080407795148776, "train/extr_critic_min": -0.30155845364527917, "train/extr_critic_std": 0.6327389999112086, "train/extr_return_normed_mag": 2.2455730838562125, "train/extr_return_normed_max": 2.2455730838562125, "train/extr_return_normed_mean": 0.306765648077673, "train/extr_return_normed_min": -0.22399172606641676, "train/extr_return_normed_std": 0.3548272932643321, "train/extr_return_rate": 0.2711991940194102, "train/extr_return_raw_mag": 4.007099124922681, "train/extr_return_raw_max": 4.007099124922681, "train/extr_return_raw_mean": 0.32030277610269947, "train/extr_return_raw_min": -0.6898338610111777, "train/extr_return_raw_std": 0.6753030601722091, "train/extr_reward_mag": 1.0015456694275586, "train/extr_reward_max": 1.0015456694275586, "train/extr_reward_mean": 0.011022216504884523, "train/extr_reward_min": -0.39000775653924513, "train/extr_reward_std": 0.08584694280775625, "train/image_loss_mean": 23.13423099802501, "train/image_loss_std": 25.22353123906833, "train/model_loss_mean": 28.180583626476686, "train/model_loss_std": 27.895697024331163, "train/model_opt_grad_norm": 144.36891584254022, "train/model_opt_grad_steps": 3325.0, "train/model_opt_loss": 1905.1167894050257, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 67.92210820895522, "train/policy_entropy_mag": 2.412869977417277, "train/policy_entropy_max": 2.412869977417277, "train/policy_entropy_mean": 0.8251300458587817, "train/policy_entropy_min": 0.07944132888050222, "train/policy_entropy_std": 0.5168788786699523, "train/policy_logprob_mag": 7.437001146487336, "train/policy_logprob_max": -0.009465284200746622, "train/policy_logprob_mean": -0.8239847032436683, "train/policy_logprob_min": -7.437001146487336, "train/policy_logprob_std": 1.2203051456764562, "train/policy_randomness_mag": 0.8516372166462799, "train/policy_randomness_max": 0.8516372166462799, "train/policy_randomness_mean": 0.29123469597812907, "train/policy_randomness_min": 0.02803930281591949, "train/policy_randomness_std": 0.18243556302874836, "train/post_ent_mag": 45.04494393761478, "train/post_ent_max": 45.04494393761478, "train/post_ent_mean": 31.58851595067266, "train/post_ent_min": 15.09014560927206, "train/post_ent_std": 5.020963544276223, "train/prior_ent_mag": 56.33141685599711, "train/prior_ent_max": 56.33141685599711, "train/prior_ent_mean": 40.129308928304646, "train/prior_ent_min": 18.32575523319529, "train/prior_ent_std": 6.9039363007047285, "train/rep_loss_mean": 8.315708590977227, "train/rep_loss_std": 6.996750860071894, "train/reward_avg": 0.011564977786767839, "train/reward_loss_mean": 0.05637714033251378, "train/reward_loss_std": 0.29685487486978074, "train/reward_max_data": 1.0044776130078443, "train/reward_max_pred": 0.9992493737989397, "train/reward_neg_acc": 0.9946090365523723, "train/reward_neg_loss": 0.03791841535147891, "train/reward_pos_acc": 0.9103085843484793, "train/reward_pos_loss": 1.1534785259125837, "train/reward_pred": 0.010607018253640898, "train/reward_rate": 0.016455806902985076, "train_stats/sum_log_reward": 3.198214220548315, "train_stats/max_log_achievement_collect_drink": 19.473214285714285, "train_stats/max_log_achievement_collect_sapling": 2.2410714285714284, "train_stats/max_log_achievement_collect_wood": 1.5625, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.15178571428571427, "train_stats/max_log_achievement_eat_cow": 0.14285714285714285, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.008928571428571428, "train_stats/max_log_achievement_place_plant": 1.875, "train_stats/max_log_achievement_place_table": 0.03571428571428571, "train_stats/max_log_achievement_wake_up": 2.0625, "train_stats/mean_log_entropy": 0.8204032632389239, "eval_stats/sum_log_reward": 2.9749999111518264, "eval_stats/max_log_achievement_collect_drink": 18.3125, "eval_stats/max_log_achievement_collect_sapling": 1.9375, "eval_stats/max_log_achievement_collect_wood": 1.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_table": 0.125, "eval_stats/max_log_achievement_wake_up": 1.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00013394320558290929, "report/cont_loss_std": 0.003696703352034092, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.017756616696715355, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.2646533832594287e-05, "report/cont_pred": 0.9932663440704346, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 8.724653244018555, "report/dyn_loss_std": 7.04127836227417, "report/image_loss_mean": 19.119504928588867, "report/image_loss_std": 20.083106994628906, "report/model_loss_mean": 24.42934799194336, "report/model_loss_std": 22.843955993652344, "report/post_ent_mag": 44.33704376220703, "report/post_ent_max": 44.33704376220703, "report/post_ent_mean": 32.308807373046875, "report/post_ent_min": 14.387310981750488, "report/post_ent_std": 4.815167427062988, "report/prior_ent_mag": 58.903953552246094, "report/prior_ent_max": 58.903953552246094, "report/prior_ent_mean": 41.637420654296875, "report/prior_ent_min": 17.748388290405273, "report/prior_ent_std": 6.615240097045898, "report/rep_loss_mean": 8.724653244018555, "report/rep_loss_std": 7.04127836227417, "report/reward_avg": 0.01748046837747097, "report/reward_loss_mean": 0.07491624355316162, "report/reward_loss_std": 0.31049853563308716, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0017755031585693, "report/reward_neg_acc": 0.9920000433921814, "report/reward_neg_loss": 0.04797646775841713, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.1974072456359863, "report/reward_pred": 0.015405725687742233, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 0.005509464535862207, "eval/cont_loss_std": 0.17507855594158173, "eval/cont_neg_acc": 0.8333333730697632, "eval/cont_neg_loss": 0.9344278573989868, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.4504453651607037e-05, "eval/cont_pred": 0.9950807690620422, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 11.572296142578125, "eval/dyn_loss_std": 7.924359321594238, "eval/image_loss_mean": 27.91563606262207, "eval/image_loss_std": 31.81106185913086, "eval/model_loss_mean": 34.92469787597656, "eval/model_loss_std": 34.339820861816406, "eval/post_ent_mag": 44.56418991088867, "eval/post_ent_max": 44.56418991088867, "eval/post_ent_mean": 29.949180603027344, "eval/post_ent_min": 15.481517791748047, "eval/post_ent_std": 4.683652877807617, "eval/prior_ent_mag": 56.30929946899414, "eval/prior_ent_max": 56.30929946899414, "eval/prior_ent_mean": 39.27547073364258, "eval/prior_ent_min": 18.881855010986328, "eval/prior_ent_std": 7.497888565063477, "eval/rep_loss_mean": 11.572296142578125, "eval/rep_loss_std": 7.924359321594238, "eval/reward_avg": 0.008496093563735485, "eval/reward_loss_mean": 0.06017179414629936, "eval/reward_loss_std": 0.43903833627700806, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0004794597625732, "eval/reward_neg_acc": 0.9930761456489563, "eval/reward_neg_loss": 0.0393536351621151, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.6791841983795166, "eval/reward_pred": 0.005974387284368277, "eval/reward_rate": 0.0126953125, "replay/size": 65041.0, "replay/inserts": 21440.0, "replay/samples": 21440.0, "replay/insert_wait_avg": 1.436660983669224e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.242612034527223e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 13680.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2641972746730837e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.2665987014770508e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.149516582489, "timer/env.step_count": 2680.0, "timer/env.step_total": 259.8375256061554, "timer/env.step_frac": 0.25953918101377443, "timer/env.step_avg": 0.09695430059931172, "timer/env.step_min": 0.022180795669555664, "timer/env.step_max": 2.186249017715454, "timer/replay._sample_count": 21440.0, "timer/replay._sample_total": 12.174056053161621, "timer/replay._sample_frac": 0.01216007784203784, "timer/replay._sample_avg": 0.0005678197785989563, "timer/replay._sample_min": 0.00040650367736816406, "timer/replay._sample_max": 0.034235477447509766, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3164.0, "timer/agent.policy_total": 54.41723155975342, "timer/agent.policy_frac": 0.05435474987343686, "timer/agent.policy_avg": 0.01719887217438477, "timer/agent.policy_min": 0.009774923324584961, "timer/agent.policy_max": 0.09381222724914551, "timer/dataset_train_count": 1340.0, "timer/dataset_train_total": 0.15834593772888184, "timer/dataset_train_frac": 0.00015816412544392917, "timer/dataset_train_avg": 0.0001181686102454342, "timer/dataset_train_min": 0.00010371208190917969, "timer/dataset_train_max": 0.00044608116149902344, "timer/agent.train_count": 1340.0, "timer/agent.train_total": 610.3194246292114, "timer/agent.train_frac": 0.6096186578729917, "timer/agent.train_avg": 0.45546225718597866, "timer/agent.train_min": 0.4385349750518799, "timer/agent.train_max": 1.5089020729064941, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4754505157470703, "timer/agent.report_frac": 0.00047490460502848966, "timer/agent.report_avg": 0.23772525787353516, "timer/agent.report_min": 0.23316454887390137, "timer/agent.report_max": 0.24228596687316895, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.3855438232421875e-05, "timer/dataset_eval_frac": 3.3816565529582794e-08, "timer/dataset_eval_avg": 3.3855438232421875e-05, "timer/dataset_eval_min": 3.3855438232421875e-05, "timer/dataset_eval_max": 3.3855438232421875e-05, "fps": 21.415075343172216}
{"step": 65552, "time": 3297.4229879379272, "episode/length": 211.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9905660377358491, "episode/intrinsic_return": 0.0}
{"step": 65752, "time": 3306.921498298645, "episode/length": 130.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 65760, "time": 3309.0560507774353, "episode/length": 458.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956427015250545, "episode/intrinsic_return": 0.0}
{"step": 65784, "time": 3311.3425533771515, "episode/length": 178.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 66144, "time": 3325.2700328826904, "episode/length": 165.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 66544, "time": 3341.0413184165955, "episode/length": 235.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 66848, "time": 3352.9000475406647, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 66944, "time": 3357.706973552704, "episode/length": 173.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 67032, "time": 3362.0342133045197, "episode/length": 192.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 67104, "time": 3366.2700645923615, "episode/length": 167.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 67416, "time": 3378.5565745830536, "episode/length": 158.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 67688, "time": 3389.300595998764, "episode/length": 241.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 67704, "time": 3391.3791325092316, "episode/length": 239.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 67912, "time": 3399.953778743744, "episode/length": 27.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8214285714285714, "episode/intrinsic_return": 0.0}
{"step": 68312, "time": 3414.9587082862854, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 68520, "time": 3423.7351744174957, "episode/length": 208.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9856459330143541, "episode/intrinsic_return": 0.0}
{"step": 68736, "time": 3432.9227476119995, "episode/length": 273.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 68768, "time": 3435.6799986362457, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9526627218934911, "episode/intrinsic_return": 0.0}
{"step": 68912, "time": 3442.22771191597, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 69016, "time": 3447.0265893936157, "episode/length": 247.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 69240, "time": 3456.1933476924896, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 69680, "time": 3472.8031594753265, "episode/length": 117.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9576271186440678, "episode/intrinsic_return": 0.0}
{"step": 69688, "time": 3474.357202768326, "episode/length": 247.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 69808, "time": 3480.178750514984, "episode/length": 98.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 70080, "time": 3491.156384706497, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 70096, "time": 3513.982613325119, "eval_episode/length": 97.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9387755102040817}
{"step": 70096, "time": 3515.604810476303, "eval_episode/length": 99.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.95}
{"step": 70096, "time": 3519.8184030056, "eval_episode/length": 159.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 70096, "time": 3521.619498729706, "eval_episode/length": 165.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9819277108433735}
{"step": 70096, "time": 3523.635972261429, "eval_episode/length": 174.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 70096, "time": 3525.525945186615, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 70096, "time": 3527.229880332947, "eval_episode/length": 184.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 70096, "time": 3529.5512249469757, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 70120, "time": 3530.148771762848, "episode/length": 150.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 70208, "time": 3534.9455819129944, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 70216, "time": 3536.6128792762756, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 70720, "time": 3555.2953157424927, "episode/length": 129.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 71024, "time": 3567.1887271404266, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 71152, "time": 3573.079009771347, "episode/length": 238.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 71288, "time": 3578.9442760944366, "episode/length": 145.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 71424, "time": 3585.330069065094, "episode/length": 167.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 71520, "time": 3590.137258052826, "episode/length": 213.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 71600, "time": 3594.3984427452087, "episode/length": 172.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 71976, "time": 3608.38805437088, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9554140127388535, "episode/intrinsic_return": 0.0}
{"step": 72024, "time": 3611.7255551815033, "episode/length": 226.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 72216, "time": 3619.701709985733, "episode/length": 29.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.8333333333333334, "episode/intrinsic_return": 0.0}
{"step": 72224, "time": 3621.791347503662, "episode/length": 133.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 72584, "time": 3635.493277311325, "episode/length": 194.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 72664, "time": 3640.3989527225494, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 72768, "time": 3646.3981182575226, "episode/length": 145.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.958904109589041, "episode/intrinsic_return": 0.0}
{"step": 72816, "time": 3650.037071943283, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 72984, "time": 3657.1196477413177, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 73200, "time": 3666.1476607322693, "episode/length": 121.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 73240, "time": 3668.895578145981, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 73416, "time": 3676.543600797653, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 73672, "time": 3686.724722146988, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 73736, "time": 3690.7262909412384, "episode/length": 143.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 73928, "time": 3700.0269424915314, "episode/length": 63.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 74040, "time": 3705.3251338005066, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 74368, "time": 3718.244009256363, "episode/length": 172.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 74472, "time": 3723.1363849639893, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9906103286384976, "episode/intrinsic_return": 0.0}
{"step": 74512, "time": 3726.300437927246, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 74712, "time": 3734.5246255397797, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 75336, "time": 3757.159899711609, "episode/length": 207.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 75416, "time": 3761.403242111206, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 75768, "time": 3774.956278562546, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 75800, "time": 3777.6275362968445, "episode/length": 165.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 75856, "time": 3781.332041501999, "episode/length": 264.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9849056603773585, "episode/intrinsic_return": 0.0}
{"step": 75856, "time": 3781.3414223194122, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 76080, "time": 3792.3570647239685, "episode/length": 170.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 76312, "time": 3801.712169408798, "episode/length": 224.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9644444444444444, "episode/intrinsic_return": 0.0}
{"step": 76752, "time": 3818.633467912674, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 76928, "time": 3826.805789709091, "episode/length": 133.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 77152, "time": 3836.4000318050385, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 77240, "time": 3840.7813942432404, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 77472, "time": 3850.4405188560486, "episode/length": 266.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 77568, "time": 3855.29350566864, "episode/length": 220.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 77704, "time": 3861.195616722107, "episode/length": 202.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 78048, "time": 3874.552983045578, "episode/length": 216.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 78584, "time": 3894.682064294815, "episode/length": 228.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 78728, "time": 3901.0194330215454, "episode/length": 144.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 78736, "time": 3903.0064771175385, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 78848, "time": 3908.306835412979, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 79168, "time": 3920.980040550232, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 79392, "time": 3930.833374261856, "episode/length": 307.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9902597402597403, "episode/intrinsic_return": 0.0}
{"step": 79712, "time": 3944.125176668167, "episode/length": 207.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 80024, "time": 3956.482936143875, "episode/length": 347.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9971264367816092, "episode/intrinsic_return": 0.0}
{"step": 80056, "time": 3959.154388189316, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 3961.7954065799713, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 80080, "time": 3982.682208299637, "eval_episode/length": 149.0, "eval_episode/score": 1.0999999716877937, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 80080, "time": 3984.9884934425354, "eval_episode/length": 164.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9575757575757575}
{"step": 80080, "time": 3987.270917892456, "eval_episode/length": 178.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 80080, "time": 3990.0697741508484, "eval_episode/length": 204.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 80080, "time": 3991.6743683815002, "eval_episode/length": 205.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 80080, "time": 3993.4601266384125, "eval_episode/length": 208.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9952153110047847}
{"step": 80080, "time": 3997.2045521736145, "eval_episode/length": 259.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 80080, "time": 3999.2069902420044, "eval_episode/length": 269.0, "eval_episode/score": 4.099999964237213, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 80152, "time": 4003.2373955249786, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 80224, "time": 4007.617434978485, "episode/length": 131.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 80296, "time": 4011.4212262630463, "episode/length": 180.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 80984, "time": 4036.0691027641296, "episode/length": 198.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 81072, "time": 4040.9025235176086, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 81296, "time": 4049.9447145462036, "episode/length": 133.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 81432, "time": 4055.9270238876343, "episode/length": 175.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 81448, "time": 4058.0769641399384, "episode/length": 161.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 81600, "time": 4065.147681236267, "episode/length": 20.0, "episode/score": -0.9000000134110451, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 81632, "time": 4067.7424454689026, "episode/length": 196.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 81680, "time": 4070.8921914100647, "episode/length": 199.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 81712, "time": 4073.5045585632324, "episode/length": 51.0, "episode/score": 0.10000000149011612, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 81912, "time": 4081.457442998886, "episode/length": 201.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 82072, "time": 4089.735941886902, "episode/length": 54.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 82528, "time": 4106.7983384132385, "episode/length": 192.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 82600, "time": 4110.46594619751, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 82960, "time": 4124.22767996788, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 82992, "time": 4126.8437666893005, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 83368, "time": 4140.709457397461, "episode/length": 206.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 83416, "time": 4143.959701061249, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 83560, "time": 4150.522442579269, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 83848, "time": 4161.810419797897, "episode/length": 59.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9166666666666666, "episode/intrinsic_return": 0.0}
{"step": 83896, "time": 4165.078450918198, "episode/length": 305.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 84000, "time": 4170.441551685333, "episode/length": 174.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 84248, "time": 4180.227997303009, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 84696, "time": 4197.043579339981, "episode/length": 216.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 84744, "time": 4200.775223970413, "episode/length": 276.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 84808, "time": 4205.166975021362, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 84904, "time": 4210.6475121974945, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 85080, "time": 4218.903378486633, "episode/length": 147.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 85288, "time": 4227.987661123276, "episode/length": 160.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 85496, "time": 4236.489835739136, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 85520, "time": 4239.139963150024, "episode/length": 208.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 85848, "time": 4251.476805925369, "episode/length": 137.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 85968, "time": 4257.334667205811, "episode/length": 55.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 86304, "time": 4270.238861083984, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 86352, "time": 4273.352900981903, "episode/length": 192.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 86512, "time": 4280.261999130249, "episode/length": 200.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 86816, "time": 4292.002193927765, "episode/length": 190.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 86848, "time": 4294.745473623276, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 86857, "time": 4297.451620340347, "train_stats/sum_log_reward": 3.4140495255220036, "train_stats/max_log_achievement_collect_drink": 9.338842975206612, "train_stats/max_log_achievement_collect_sapling": 2.628099173553719, "train_stats/max_log_achievement_collect_wood": 1.6859504132231404, "train_stats/max_log_achievement_defeat_skeleton": 0.008264462809917356, "train_stats/max_log_achievement_defeat_zombie": 0.2066115702479339, "train_stats/max_log_achievement_eat_cow": 0.05785123966942149, "train_stats/max_log_achievement_make_wood_pickaxe": 0.0, "train_stats/max_log_achievement_make_wood_sword": 0.024793388429752067, "train_stats/max_log_achievement_place_plant": 2.3801652892561984, "train_stats/max_log_achievement_place_table": 0.2975206611570248, "train_stats/max_log_achievement_wake_up": 1.512396694214876, "train_stats/mean_log_entropy": 0.8229024503841873, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.4768571208294174, "train/action_min": 0.0, "train/action_std": 3.7379053589096642, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05319736843326486, "train/actor_opt_grad_steps": 4670.0, "train/actor_opt_loss": 19.84135359839389, "train/adv_mag": 1.3206216661553634, "train/adv_max": 1.3206140640983008, "train/adv_mean": 0.008222097569474377, "train/adv_min": -0.5629468564700363, "train/adv_std": 0.10456822750935878, "train/cont_avg": 0.9944783834586466, "train/cont_loss_mean": 0.0006023493877055239, "train/cont_loss_std": 0.01622965185249216, "train/cont_neg_acc": 0.9843073618231397, "train/cont_neg_loss": 0.053529261305150365, "train/cont_pos_acc": 0.9998891891393447, "train/cont_pos_loss": 0.0003155064428359939, "train/cont_pred": 0.994442988159065, "train/cont_rate": 0.9944783834586466, "train/dyn_loss_mean": 10.285135853559451, "train/dyn_loss_std": 7.681491098905864, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1444419116005862, "train/extr_critic_critic_opt_grad_steps": 4670.0, "train/extr_critic_critic_opt_loss": 14350.815921640038, "train/extr_critic_mag": 2.1947170809695593, "train/extr_critic_max": 2.1947170809695593, "train/extr_critic_mean": 0.41048632170024674, "train/extr_critic_min": -0.22796555121142165, "train/extr_critic_std": 0.6551557313230701, "train/extr_return_normed_mag": 2.2854561940171663, "train/extr_return_normed_max": 2.2854561940171663, "train/extr_return_normed_mean": 0.3201843708529508, "train/extr_return_normed_min": -0.21446627412075386, "train/extr_return_normed_std": 0.36985104514243905, "train/extr_return_rate": 0.30476779485107364, "train/extr_return_raw_mag": 4.148984122097044, "train/extr_return_raw_max": 4.148984122097044, "train/extr_return_raw_mean": 0.42606901685546217, "train/extr_return_raw_min": -0.5873884811885375, "train/extr_return_raw_std": 0.7007469516947753, "train/extr_reward_mag": 1.0060013425081296, "train/extr_reward_max": 1.0060013425081296, "train/extr_reward_mean": 0.013177731820151098, "train/extr_reward_min": -0.31571449910787713, "train/extr_reward_std": 0.09626630452790655, "train/image_loss_mean": 20.614155138345588, "train/image_loss_std": 20.873586188581655, "train/model_loss_mean": 26.841914614340418, "train/model_loss_std": 24.128405649859207, "train/model_opt_grad_norm": 119.00423491628547, "train/model_opt_grad_steps": 4660.0, "train/model_opt_loss": 5166.860597538769, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 193.2565789473684, "train/policy_entropy_mag": 2.505479199545724, "train/policy_entropy_max": 2.505479199545724, "train/policy_entropy_mean": 0.8025945877670345, "train/policy_entropy_min": 0.0793988919795904, "train/policy_entropy_std": 0.5500030822323677, "train/policy_logprob_mag": 7.438047419813342, "train/policy_logprob_max": -0.009459552649212511, "train/policy_logprob_mean": -0.8025497251883486, "train/policy_logprob_min": -7.438047419813342, "train/policy_logprob_std": 1.2362477555310816, "train/policy_randomness_mag": 0.8843242073417606, "train/policy_randomness_max": 0.8843242073417606, "train/policy_randomness_mean": 0.2832806666094558, "train/policy_randomness_min": 0.028024324503048023, "train/policy_randomness_std": 0.19412695319580853, "train/post_ent_mag": 46.466103374509885, "train/post_ent_max": 46.466103374509885, "train/post_ent_mean": 33.0120081793993, "train/post_ent_min": 16.8433967604673, "train/post_ent_std": 4.900399539703713, "train/prior_ent_mag": 58.098144101020985, "train/prior_ent_max": 58.098144101020985, "train/prior_ent_mean": 43.528124931163354, "train/prior_ent_min": 20.85767688607811, "train/prior_ent_std": 7.194584029061454, "train/rep_loss_mean": 10.285135853559451, "train/rep_loss_std": 7.681491098905864, "train/reward_avg": 0.014427425879004755, "train/reward_loss_mean": 0.05607556166561475, "train/reward_loss_std": 0.289663348879133, "train/reward_max_data": 1.0165413573272246, "train/reward_max_pred": 1.0022431226601278, "train/reward_neg_acc": 0.994042882793828, "train/reward_neg_loss": 0.036233276864023584, "train/reward_pos_acc": 0.9318741205939673, "train/reward_pos_loss": 1.0724217031235086, "train/reward_pred": 0.013519789011714826, "train/reward_rate": 0.019281602443609023, "train_stats/max_log_achievement_eat_plant": 0.008403361344537815, "eval_stats/sum_log_reward": 3.5999999195337296, "eval_stats/max_log_achievement_collect_drink": 8.625, "eval_stats/max_log_achievement_collect_sapling": 2.3125, "eval_stats/max_log_achievement_collect_wood": 2.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 2.0, "eval_stats/max_log_achievement_place_table": 0.4375, "eval_stats/max_log_achievement_wake_up": 1.5625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 8.663148946652655e-06, "report/cont_loss_std": 0.00014292963896878064, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00014265443314798176, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 8.26944233267568e-06, "report/cont_pred": 0.9970625042915344, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.702462196350098, "report/dyn_loss_std": 7.800958156585693, "report/image_loss_mean": 19.881319046020508, "report/image_loss_std": 16.870723724365234, "report/model_loss_mean": 26.944673538208008, "report/model_loss_std": 20.207157135009766, "report/post_ent_mag": 46.38581085205078, "report/post_ent_max": 46.38581085205078, "report/post_ent_mean": 33.417545318603516, "report/post_ent_min": 17.324810028076172, "report/post_ent_std": 4.55798864364624, "report/prior_ent_mag": 59.55167007446289, "report/prior_ent_max": 59.55167007446289, "report/prior_ent_mean": 45.1387939453125, "report/prior_ent_min": 18.466876983642578, "report/prior_ent_std": 7.6623311042785645, "report/rep_loss_mean": 11.702462196350098, "report/rep_loss_std": 7.800958156585693, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.041870057582855225, "report/reward_loss_std": 0.25064289569854736, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020387172698975, "report/reward_neg_acc": 0.9949899911880493, "report/reward_neg_loss": 0.01728012040257454, "report/reward_pos_acc": 0.9230769872665405, "report/reward_pos_loss": 0.985745370388031, "report/reward_pred": 0.022127345204353333, "report/reward_rate": 0.025390625, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 4.4604325921682175e-06, "eval/cont_loss_std": 6.201247015269473e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00026417532353661954, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.9296966204128694e-06, "eval/cont_pred": 0.9941393136978149, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 13.5404634475708, "eval/dyn_loss_std": 8.815767288208008, "eval/image_loss_mean": 23.33555793762207, "eval/image_loss_std": 22.723756790161133, "eval/model_loss_mean": 31.557418823242188, "eval/model_loss_std": 25.863872528076172, "eval/post_ent_mag": 45.66674041748047, "eval/post_ent_max": 45.66674041748047, "eval/post_ent_mean": 31.456769943237305, "eval/post_ent_min": 18.19452667236328, "eval/post_ent_std": 4.226040363311768, "eval/prior_ent_mag": 59.55167007446289, "eval/prior_ent_max": 59.55167007446289, "eval/prior_ent_mean": 42.472869873046875, "eval/prior_ent_min": 21.088619232177734, "eval/prior_ent_std": 7.422183036804199, "eval/rep_loss_mean": 13.5404634475708, "eval/rep_loss_std": 8.815767288208008, "eval/reward_avg": 0.013574219308793545, "eval/reward_loss_mean": 0.09757974743843079, "eval/reward_loss_std": 0.6422536373138428, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0052917003631592, "eval/reward_neg_acc": 0.9980080127716064, "eval/reward_neg_loss": 0.04787267744541168, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 2.5928752422332764, "eval/reward_pred": 0.0077829742804169655, "eval/reward_rate": 0.01953125, "replay/size": 86353.0, "replay/inserts": 21312.0, "replay/samples": 21312.0, "replay/insert_wait_avg": 1.4368769105848248e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.175624933328715e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 17464.0, "eval_replay/inserts": 3784.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2393481635644118e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0451066493988, "timer/env.step_count": 2664.0, "timer/env.step_total": 271.9502463340759, "timer/env.step_frac": 0.2719379801229483, "timer/env.step_avg": 0.10208342580107956, "timer/env.step_min": 0.022688865661621094, "timer/env.step_max": 3.409019947052002, "timer/replay._sample_count": 21312.0, "timer/replay._sample_total": 11.994754791259766, "timer/replay._sample_frac": 0.011994213772464317, "timer/replay._sample_avg": 0.0005628169477880896, "timer/replay._sample_min": 0.00041866302490234375, "timer/replay._sample_max": 0.008757352828979492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3137.0, "timer/agent.policy_total": 54.191678047180176, "timer/agent.policy_frac": 0.054189233752412115, "timer/agent.policy_avg": 0.017275000971367603, "timer/agent.policy_min": 0.00967717170715332, "timer/agent.policy_max": 0.12464118003845215, "timer/dataset_train_count": 1332.0, "timer/dataset_train_total": 0.15551018714904785, "timer/dataset_train_frac": 0.00015550317292194646, "timer/dataset_train_avg": 0.00011674938975153743, "timer/dataset_train_min": 0.00010132789611816406, "timer/dataset_train_max": 0.0005285739898681641, "timer/agent.train_count": 1332.0, "timer/agent.train_total": 603.9003024101257, "timer/agent.train_frac": 0.6038730637195592, "timer/agent.train_avg": 0.4533786054130073, "timer/agent.train_min": 0.4381687641143799, "timer/agent.train_max": 1.4140243530273438, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4809896945953369, "timer/agent.report_frac": 0.0004809679997404006, "timer/agent.report_avg": 0.24049484729766846, "timer/agent.report_min": 0.2335197925567627, "timer/agent.report_max": 0.24746990203857422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.075460946671495e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 21.310764507281444}
{"step": 87112, "time": 4305.924023866653, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 87160, "time": 4309.119810581207, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 87456, "time": 4320.7808957099915, "episode/length": 296.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 87520, "time": 4324.580668449402, "episode/length": 151.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 87568, "time": 4328.2538850307465, "episode/length": 151.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 87800, "time": 4338.162746191025, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 88080, "time": 4349.411530256271, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 88552, "time": 4366.929751157761, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 88808, "time": 4377.88956952095, "episode/length": 205.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 88896, "time": 4382.629328489304, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 89520, "time": 4405.734699010849, "episode/length": 243.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 89912, "time": 4420.30579328537, "episode/length": 169.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 89960, "time": 4423.458467960358, "episode/length": 312.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 90048, "time": 4428.380566835403, "episode/length": 280.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 90064, "time": 4450.071619272232, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 90064, "time": 4450.0812294483185, "eval_episode/length": 154.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 90064, "time": 4453.878380537033, "eval_episode/length": 165.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 90064, "time": 4455.820287227631, "eval_episode/length": 175.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 90064, "time": 4457.4974756240845, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9775280898876404}
{"step": 90064, "time": 4459.24716091156, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 90064, "time": 4461.120674610138, "eval_episode/length": 36.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.972972972972973}
{"step": 90064, "time": 4462.970879077911, "eval_episode/length": 198.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9698492462311558}
{"step": 90152, "time": 4467.071661949158, "episode/length": 412.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 90232, "time": 4471.318474292755, "episode/length": 177.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 90272, "time": 4474.467396259308, "episode/length": 171.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 90288, "time": 4476.713868379593, "episode/length": 29.0, "episode/score": 2.100000023841858, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 90520, "time": 4486.0861921310425, "episode/length": 304.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 90880, "time": 4500.047291517258, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 91288, "time": 4515.682737588882, "episode/length": 141.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 91424, "time": 4522.00913143158, "episode/length": 182.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 91488, "time": 4525.762898206711, "episode/length": 196.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 91672, "time": 4533.382027864456, "episode/length": 174.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 91672, "time": 4533.39157128334, "episode/length": 179.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 91744, "time": 4539.393155097961, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.875, "episode/intrinsic_return": 0.0}
{"step": 92040, "time": 4550.937209367752, "episode/length": 218.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 92200, "time": 4557.823922872543, "episode/length": 65.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 92680, "time": 4575.64102435112, "episode/length": 79.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 92680, "time": 4575.651312351227, "episode/length": 224.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 92864, "time": 4585.4113693237305, "episode/length": 82.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 92976, "time": 4590.827856302261, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 93192, "time": 4599.694438457489, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 93192, "time": 4599.722448348999, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 93392, "time": 4610.197504520416, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 93920, "time": 4630.738178253174, "episode/length": 154.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 94088, "time": 4637.851378440857, "episode/length": 445.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 94160, "time": 4642.27793264389, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 94448, "time": 4653.619558334351, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 94464, "time": 4655.711320877075, "episode/length": 222.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 94584, "time": 4661.283127069473, "episode/length": 173.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 94992, "time": 4676.837442159653, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 95040, "time": 4680.539659976959, "episode/length": 257.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 95296, "time": 4691.51552438736, "episode/length": 150.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 95488, "time": 4699.605856180191, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 95592, "time": 4704.397422075272, "episode/length": 208.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 95704, "time": 4709.736663341522, "episode/length": 156.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 95720, "time": 4711.866495132446, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 96128, "time": 4727.454679727554, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 96216, "time": 4731.708219051361, "episode/length": 146.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 96280, "time": 4735.538054704666, "episode/length": 211.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 96640, "time": 4749.426743745804, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 96920, "time": 4760.1076719760895, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 96936, "time": 4762.156495332718, "episode/length": 151.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 96960, "time": 4764.779275894165, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 97472, "time": 4783.987258195877, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 97928, "time": 4800.669057607651, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 97976, "time": 4803.796271085739, "episode/length": 166.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 98216, "time": 4813.492579936981, "episode/length": 241.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 98368, "time": 4821.814565420151, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 98456, "time": 4826.112936973572, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 98536, "time": 4830.442938089371, "episode/length": 199.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 99248, "time": 4855.987849235535, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 99248, "time": 4855.995480537415, "episode/length": 98.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 99272, "time": 4859.908552646637, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 99496, "time": 4868.89372754097, "episode/length": 252.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 99520, "time": 4871.7295794487, "episode/length": 143.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 99672, "time": 4878.2074110507965, "episode/length": 431.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 100048, "time": 4907.08918762207, "eval_episode/length": 34.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9714285714285714}
{"step": 100048, "time": 4908.747419595718, "eval_episode/length": 37.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 100048, "time": 4916.318346261978, "eval_episode/length": 182.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.994535519125683}
{"step": 100048, "time": 4918.69703412056, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 100048, "time": 4920.8675446510315, "eval_episode/length": 191.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 100048, "time": 4923.441887617111, "eval_episode/length": 200.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 100048, "time": 4925.756652593613, "eval_episode/length": 204.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 100048, "time": 4928.248060703278, "eval_episode/length": 186.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 100304, "time": 4936.878198385239, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 100592, "time": 4948.205773115158, "episode/length": 296.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9932659932659933, "episode/intrinsic_return": 0.0}
{"step": 100704, "time": 4953.54167675972, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 100824, "time": 4958.979725599289, "episode/length": 28.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8620689655172413, "episode/intrinsic_return": 0.0}
{"step": 100840, "time": 4961.334973812103, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 101096, "time": 4971.575973987579, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 101184, "time": 4976.3895037174225, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 101344, "time": 4983.260429620743, "episode/length": 261.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 101368, "time": 4985.334762096405, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 101384, "time": 4987.400341749191, "episode/length": 84.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9411764705882353, "episode/intrinsic_return": 0.0}
{"step": 101736, "time": 5001.251312255859, "episode/length": 48.0, "episode/score": 2.100000001490116, "episode/reward_rate": 0.9183673469387755, "episode/intrinsic_return": 0.0}
{"step": 102176, "time": 5018.521863937378, "episode/length": 168.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9644970414201184, "episode/intrinsic_return": 0.0}
{"step": 102200, "time": 5021.329813241959, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 102208, "time": 5023.7725422382355, "episode/length": 237.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 102600, "time": 5038.367566347122, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 102800, "time": 5046.938926935196, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 102856, "time": 5050.255105495453, "episode/length": 208.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 102968, "time": 5055.540339231491, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 103176, "time": 5064.106537818909, "episode/length": 223.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 103584, "time": 5079.533895254135, "episode/length": 172.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 103776, "time": 5087.695841550827, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 103856, "time": 5091.93182516098, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 103968, "time": 5097.372869491577, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732142857142857, "episode/intrinsic_return": 0.0}
{"step": 104320, "time": 5110.82048869133, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 104376, "time": 5114.138148069382, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 104432, "time": 5117.897280216217, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 104760, "time": 5130.2322380542755, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 104856, "time": 5134.990988731384, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 105200, "time": 5148.410765886307, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 105360, "time": 5155.297335147858, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 105560, "time": 5163.338305711746, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 105600, "time": 5166.384110450745, "episode/length": 203.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 105784, "time": 5174.315259218216, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 105816, "time": 5177.449463844299, "episode/length": 31.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.84375, "episode/intrinsic_return": 0.0}
{"step": 106136, "time": 5190.159162282944, "episode/length": 39.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 106192, "time": 5194.393634080887, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 106480, "time": 5206.4314432144165, "episode/length": 202.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 106640, "time": 5215.339964151382, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 106720, "time": 5219.625167131424, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 107048, "time": 5232.056437730789, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 107304, "time": 5242.118545532227, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 107600, "time": 5253.8089826107025, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 107624, "time": 5255.944838523865, "episode/length": 405.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 108024, "time": 5271.174067258835, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 108176, "time": 5278.076412200928, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 108200, "time": 5280.088480949402, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 108264, "time": 5283.666573047638, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 108601, "time": 5297.610201120377, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 5.344559164608226, "train/action_min": 0.0, "train/action_std": 3.532019893912708, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05169481971739408, "train/actor_opt_grad_steps": 6015.0, "train/actor_opt_loss": 15.251484045211006, "train/adv_mag": 1.1288770950015854, "train/adv_max": 1.1269893392043955, "train/adv_mean": 0.007248045449407126, "train/adv_min": -0.5636940909659162, "train/adv_std": 0.09592706614228733, "train/cont_avg": 0.9946073644301471, "train/cont_loss_mean": 0.000480776735115034, "train/cont_loss_std": 0.01228968988749557, "train/cont_neg_acc": 0.9785276633851668, "train/cont_neg_loss": 0.04742220595472906, "train/cont_pos_acc": 0.9999205487615922, "train/cont_pos_loss": 0.0002347524345538813, "train/cont_pred": 0.994615450501442, "train/cont_rate": 0.9946073644301471, "train/dyn_loss_mean": 11.613111096269945, "train/dyn_loss_std": 7.993933604044073, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0880083886577803, "train/extr_critic_critic_opt_grad_steps": 6015.0, "train/extr_critic_critic_opt_loss": 14668.603278664981, "train/extr_critic_mag": 2.616622319992851, "train/extr_critic_max": 2.616622319992851, "train/extr_critic_mean": 0.5066101263989421, "train/extr_critic_min": -0.2409924873534371, "train/extr_critic_std": 0.7483341501039618, "train/extr_return_normed_mag": 2.1677617307971504, "train/extr_return_normed_max": 2.1677617307971504, "train/extr_return_normed_mean": 0.32059451937675476, "train/extr_return_normed_min": -0.21476031664539785, "train/extr_return_normed_std": 0.3661234527826309, "train/extr_return_rate": 0.322294364518979, "train/extr_return_raw_mag": 4.509970964754329, "train/extr_return_raw_max": 4.509970964754329, "train/extr_return_raw_mean": 0.5222801176064155, "train/extr_return_raw_min": -0.6341394289013218, "train/extr_return_raw_std": 0.7907721584334093, "train/extr_reward_mag": 1.0066384787068647, "train/extr_reward_max": 1.0066384787068647, "train/extr_reward_mean": 0.013731331980499603, "train/extr_reward_min": -0.36008008437998157, "train/extr_reward_std": 0.1010722715736312, "train/image_loss_mean": 18.581004773869235, "train/image_loss_std": 19.022072174969843, "train/model_loss_mean": 25.60526962140027, "train/model_loss_std": 22.465846503482144, "train/model_opt_grad_norm": 103.74207081514247, "train/model_opt_grad_steps": 6005.0, "train/model_opt_loss": 12006.181913488052, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 468.75, "train/policy_entropy_mag": 2.499747633934021, "train/policy_entropy_max": 2.499747633934021, "train/policy_entropy_mean": 0.7847643915344688, "train/policy_entropy_min": 0.07938383733305861, "train/policy_entropy_std": 0.5852159610127702, "train/policy_logprob_mag": 7.438252168543198, "train/policy_logprob_max": -0.0094573611722273, "train/policy_logprob_mean": -0.7848614782971495, "train/policy_logprob_min": -7.438252168543198, "train/policy_logprob_std": 1.2067776445080252, "train/policy_randomness_mag": 0.8823012144250029, "train/policy_randomness_max": 0.8823012144250029, "train/policy_randomness_mean": 0.27698739355101304, "train/policy_randomness_min": 0.02801901082891752, "train/policy_randomness_std": 0.20655555431457126, "train/post_ent_mag": 48.32840235093061, "train/post_ent_max": 48.32840235093061, "train/post_ent_mean": 34.34624716814827, "train/post_ent_min": 18.375600870917825, "train/post_ent_std": 5.11855170656653, "train/prior_ent_mag": 59.773573454688574, "train/prior_ent_max": 59.773573454688574, "train/prior_ent_mean": 46.16103898777681, "train/prior_ent_min": 22.151054242077997, "train/prior_ent_std": 7.088800531976363, "train/rep_loss_mean": 11.613111096269945, "train/rep_loss_std": 7.993933604044073, "train/reward_avg": 0.015515136669444688, "train/reward_loss_mean": 0.055917559109409064, "train/reward_loss_std": 0.2862364389002323, "train/reward_max_data": 1.0125000029802322, "train/reward_max_pred": 1.0027081861215479, "train/reward_neg_acc": 0.993803075131248, "train/reward_neg_loss": 0.03500603945405387, "train/reward_pos_acc": 0.9306482203743037, "train/reward_pos_loss": 1.05738867994617, "train/reward_pred": 0.014423143383978373, "train/reward_rate": 0.020493451286764705, "train_stats/sum_log_reward": 4.160869503150815, "train_stats/max_log_achievement_collect_drink": 11.626086956521739, "train_stats/max_log_achievement_collect_sapling": 2.5739130434782607, "train_stats/max_log_achievement_collect_wood": 2.5652173913043477, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.17391304347826086, "train_stats/max_log_achievement_eat_cow": 0.0782608695652174, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008695652173913044, "train_stats/max_log_achievement_make_wood_sword": 0.008695652173913044, "train_stats/max_log_achievement_place_plant": 2.417391304347826, "train_stats/max_log_achievement_place_table": 0.8956521739130435, "train_stats/max_log_achievement_wake_up": 1.5478260869565217, "train_stats/mean_log_entropy": 0.7279665089171866, "eval_stats/sum_log_reward": 3.6624999176710844, "eval_stats/max_log_achievement_collect_drink": 15.4375, "eval_stats/max_log_achievement_collect_sapling": 1.4375, "eval_stats/max_log_achievement_collect_wood": 2.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_table": 0.75, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 5.914766461501131e-06, "report/cont_loss_std": 9.24565174500458e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0012099056039005518, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.1932330608033226e-06, "report/cont_pred": 0.9960973262786865, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.775872230529785, "report/dyn_loss_std": 8.64155387878418, "report/image_loss_mean": 21.118677139282227, "report/image_loss_std": 20.428565979003906, "report/model_loss_mean": 29.444744110107422, "report/model_loss_std": 24.364587783813477, "report/post_ent_mag": 49.37909698486328, "report/post_ent_max": 49.37909698486328, "report/post_ent_mean": 34.100765228271484, "report/post_ent_min": 19.60324478149414, "report/post_ent_std": 5.225825309753418, "report/prior_ent_mag": 61.32075500488281, "report/prior_ent_max": 61.32075500488281, "report/prior_ent_mean": 48.34501647949219, "report/prior_ent_min": 20.954790115356445, "report/prior_ent_std": 7.438779830932617, "report/rep_loss_mean": 13.775872230529785, "report/rep_loss_std": 8.64155387878418, "report/reward_avg": 0.01621093787252903, "report/reward_loss_mean": 0.06053895875811577, "report/reward_loss_std": 0.2714988589286804, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035030841827393, "report/reward_neg_acc": 0.9860419034957886, "report/reward_neg_loss": 0.04090171307325363, "report/reward_pos_acc": 0.9047619104385376, "report/reward_pos_loss": 0.9984514117240906, "report/reward_pred": 0.01814403012394905, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0007786554051563144, "eval/cont_loss_std": 0.02328927256166935, "eval/cont_neg_acc": 0.800000011920929, "eval/cont_neg_loss": 0.15837572515010834, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.362645424611401e-06, "eval/cont_pred": 0.9956700801849365, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.022967338562012, "eval/dyn_loss_std": 9.067656517028809, "eval/image_loss_mean": 26.469764709472656, "eval/image_loss_std": 28.043548583984375, "eval/model_loss_mean": 35.57855987548828, "eval/model_loss_std": 31.218860626220703, "eval/post_ent_mag": 43.190818786621094, "eval/post_ent_max": 43.190818786621094, "eval/post_ent_mean": 32.65808868408203, "eval/post_ent_min": 18.90024185180664, "eval/post_ent_std": 4.250361919403076, "eval/prior_ent_mag": 61.32075500488281, "eval/prior_ent_max": 61.32075500488281, "eval/prior_ent_mean": 45.14751434326172, "eval/prior_ent_min": 17.097915649414062, "eval/prior_ent_std": 7.742403984069824, "eval/rep_loss_mean": 15.022967338562012, "eval/rep_loss_std": 9.067656517028809, "eval/reward_avg": 0.010546875186264515, "eval/reward_loss_mean": 0.09423431009054184, "eval/reward_loss_std": 0.6197248101234436, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026392936706543, "eval/reward_neg_acc": 0.9890873432159424, "eval/reward_neg_loss": 0.06458423286676407, "eval/reward_pos_acc": 0.8125, "eval/reward_pos_loss": 1.9621890783309937, "eval/reward_pred": 0.011843263171613216, "eval/reward_rate": 0.015625, "replay/size": 108097.0, "replay/inserts": 21744.0, "replay/samples": 21744.0, "replay/insert_wait_avg": 1.4117287747381013e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.163830366267975e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 20856.0, "eval_replay/inserts": 3392.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.2069940567016602e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1379280090332, "timer/env.step_count": 2718.0, "timer/env.step_total": 263.44277477264404, "timer/env.step_frac": 0.2634064436463054, "timer/env.step_avg": 0.09692522986484328, "timer/env.step_min": 0.022207021713256836, "timer/env.step_max": 3.4735913276672363, "timer/replay._sample_count": 21744.0, "timer/replay._sample_total": 12.19260859489441, "timer/replay._sample_frac": 0.012190927124587846, "timer/replay._sample_avg": 0.0005607343908615899, "timer/replay._sample_min": 0.00041294097900390625, "timer/replay._sample_max": 0.010483980178833008, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3142.0, "timer/agent.policy_total": 53.25483798980713, "timer/agent.policy_frac": 0.053247493669019354, "timer/agent.policy_avg": 0.01694934372686414, "timer/agent.policy_min": 0.009591341018676758, "timer/agent.policy_max": 0.11604142189025879, "timer/dataset_train_count": 1359.0, "timer/dataset_train_total": 0.15873932838439941, "timer/dataset_train_frac": 0.00015871743680434213, "timer/dataset_train_avg": 0.00011680598115114011, "timer/dataset_train_min": 0.00010228157043457031, "timer/dataset_train_max": 0.00030159950256347656, "timer/agent.train_count": 1359.0, "timer/agent.train_total": 616.7900738716125, "timer/agent.train_frac": 0.6167050129770119, "timer/agent.train_avg": 0.4538558306634382, "timer/agent.train_min": 0.4380953311920166, "timer/agent.train_max": 1.4518725872039795, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47324109077453613, "timer/agent.report_frac": 0.000473175826574854, "timer/agent.report_avg": 0.23662054538726807, "timer/agent.report_min": 0.22491812705993652, "timer/agent.report_max": 0.2483229637145996, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 4.00543212890625e-05, "timer/dataset_eval_frac": 4.004879743816768e-08, "timer/dataset_eval_avg": 4.00543212890625e-05, "timer/dataset_eval_min": 4.00543212890625e-05, "timer/dataset_eval_max": 4.00543212890625e-05, "fps": 21.740558745943492}
{"step": 108648, "time": 5299.02799654007, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 108952, "time": 5310.769825220108, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 109136, "time": 5319.408018350601, "episode/length": 260.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 109344, "time": 5328.814660787582, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 109720, "time": 5343.283680200577, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 109728, "time": 5345.36554312706, "episode/length": 265.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 109744, "time": 5347.514600753784, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 109904, "time": 5354.492067575455, "episode/length": 215.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 110032, "time": 5379.843547821045, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 110032, "time": 5381.762442111969, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 110032, "time": 5383.759032964706, "eval_episode/length": 173.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 110032, "time": 5385.655568122864, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 110032, "time": 5387.493463516235, "eval_episode/length": 187.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 110032, "time": 5389.497354984283, "eval_episode/length": 198.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 110032, "time": 5391.748873949051, "eval_episode/length": 211.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 110032, "time": 5394.189609050751, "eval_episode/length": 235.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9788135593220338}
{"step": 110128, "time": 5397.345815896988, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 110544, "time": 5412.81298995018, "episode/length": 51.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 110688, "time": 5419.131624221802, "episode/length": 216.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 110824, "time": 5424.905212402344, "episode/length": 210.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 110880, "time": 5428.5623643398285, "episode/length": 143.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 111224, "time": 5441.550954341888, "episode/length": 184.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 111400, "time": 5449.150787830353, "episode/length": 209.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 111776, "time": 5463.484127521515, "episode/length": 303.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 111984, "time": 5472.103637456894, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 112208, "time": 5481.187404155731, "episode/length": 287.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 112360, "time": 5487.549797296524, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 112456, "time": 5492.4205894470215, "episode/length": 153.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 112584, "time": 5498.3253610134125, "episode/length": 236.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 112592, "time": 5500.519669532776, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 112856, "time": 5510.5988800525665, "episode/length": 61.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 112968, "time": 5515.95548415184, "episode/length": 148.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 113040, "time": 5520.084046840668, "episode/length": 131.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9621212121212122, "episode/intrinsic_return": 0.0}
{"step": 113320, "time": 5530.706932067871, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 113368, "time": 5533.880806922913, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 114048, "time": 5558.33295416832, "episode/length": 198.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 114136, "time": 5562.719108343124, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 114320, "time": 5570.73325753212, "episode/length": 216.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 114368, "time": 5573.961666584015, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 114432, "time": 5577.6343541145325, "episode/length": 173.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 114568, "time": 5583.561553001404, "episode/length": 213.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 114760, "time": 5593.0094656944275, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 115000, "time": 5602.610974550247, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 115408, "time": 5618.160151481628, "episode/length": 169.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 115560, "time": 5624.802218437195, "episode/length": 140.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 115680, "time": 5630.520582914352, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 115816, "time": 5636.347548723221, "episode/length": 186.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 115912, "time": 5641.190279006958, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 116120, "time": 5649.705973863602, "episode/length": 54.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 116392, "time": 5660.236763477325, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 116432, "time": 5663.432821512222, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9608938547486033, "episode/intrinsic_return": 0.0}
{"step": 116680, "time": 5673.041753768921, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 116800, "time": 5679.4037029743195, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 116936, "time": 5685.985884666443, "episode/length": 295.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 117208, "time": 5696.610325098038, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 117584, "time": 5710.982399463654, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 117592, "time": 5712.582696199417, "episode/length": 209.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 117864, "time": 5723.2004244327545, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 118032, "time": 5730.604358911514, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 118080, "time": 5733.852518558502, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 118096, "time": 5735.977660655975, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 118312, "time": 5744.549505472183, "episode/length": 34.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8857142857142857, "episode/intrinsic_return": 0.0}
{"step": 118352, "time": 5747.776854991913, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 118736, "time": 5762.0276391506195, "episode/length": 143.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 118984, "time": 5771.6716096401215, "episode/length": 173.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 119008, "time": 5774.343823432922, "episode/length": 224.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 119416, "time": 5789.153521776199, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 119648, "time": 5798.975337505341, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 119688, "time": 5802.176676034927, "episode/length": 200.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 119824, "time": 5809.083555459976, "episode/length": 215.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 119912, "time": 5813.897709131241, "episode/length": 146.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 120016, "time": 5834.266297340393, "eval_episode/length": 39.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.875}
{"step": 120016, "time": 5837.778064489365, "eval_episode/length": 87.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 120016, "time": 5842.114780664444, "eval_episode/length": 154.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 120016, "time": 5847.044655799866, "eval_episode/length": 193.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9742268041237113}
{"step": 120016, "time": 5848.766404628754, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 120016, "time": 5851.406893730164, "eval_episode/length": 215.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 120016, "time": 5853.090020895004, "eval_episode/length": 216.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9815668202764977}
{"step": 120016, "time": 5857.913336992264, "eval_episode/length": 242.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 120200, "time": 5864.284367799759, "episode/length": 148.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 120328, "time": 5870.3931658267975, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 120704, "time": 5885.445620536804, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 120792, "time": 5889.944121837616, "episode/length": 309.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709677419354839, "episode/intrinsic_return": 0.0}
{"step": 121120, "time": 5902.677803516388, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 121128, "time": 5904.245979309082, "episode/length": 162.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 121176, "time": 5907.415699720383, "episode/length": 190.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 121496, "time": 5919.621946334839, "episode/length": 197.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 121752, "time": 5929.747700929642, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 121776, "time": 5932.301014184952, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 121944, "time": 5939.187591552734, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 122440, "time": 5958.261875152588, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 122664, "time": 5967.958855628967, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 122720, "time": 5971.620861053467, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 122736, "time": 5973.838819742203, "episode/length": 242.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9794238683127572, "episode/intrinsic_return": 0.0}
{"step": 122904, "time": 5982.147547483444, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 123264, "time": 5995.745530366898, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 123448, "time": 6003.1811282634735, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9617224880382775, "episode/intrinsic_return": 0.0}
{"step": 123688, "time": 6013.392755508423, "episode/length": 273.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 123856, "time": 6020.787119150162, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 123904, "time": 6023.865343093872, "episode/length": 154.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 124256, "time": 6037.420097827911, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 124288, "time": 6040.654203176498, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 124552, "time": 6050.769674777985, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 124576, "time": 6053.39436173439, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 124664, "time": 6057.723224163055, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 124840, "time": 6065.044771432877, "episode/length": 143.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 125376, "time": 6085.140475511551, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 125616, "time": 6095.42139339447, "episode/length": 169.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 125784, "time": 6103.031650543213, "episode/length": 234.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 125960, "time": 6110.8457000255585, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 126008, "time": 6114.049539089203, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 126136, "time": 6119.738368272781, "episode/length": 161.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 126152, "time": 6121.838362932205, "episode/length": 232.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 126336, "time": 6129.677254915237, "episode/length": 222.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 127000, "time": 6153.066930532455, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 127152, "time": 6159.940297842026, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 127224, "time": 6163.688231229782, "episode/length": 157.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 127256, "time": 6166.373728275299, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 127648, "time": 6181.006824731827, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 127696, "time": 6184.232043027878, "episode/length": 259.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769230769230769, "episode/intrinsic_return": 0.0}
{"step": 128024, "time": 6196.513275384903, "episode/length": 235.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 128472, "time": 6213.011595487595, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 128480, "time": 6215.05530834198, "episode/length": 290.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.993127147766323, "episode/intrinsic_return": 0.0}
{"step": 128776, "time": 6226.374147415161, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 128824, "time": 6229.585314273834, "episode/length": 199.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 129144, "time": 6242.337397813797, "episode/length": 180.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 129248, "time": 6247.624700784683, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 129432, "time": 6255.843508243561, "episode/length": 271.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 129840, "time": 6271.57142496109, "episode/length": 169.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9529411764705882, "episode/intrinsic_return": 0.0}
{"step": 129952, "time": 6277.518059253693, "episode/length": 146.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 129992, "time": 6280.245153665543, "episode/length": 292.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795221843003413, "episode/intrinsic_return": 0.0}
{"step": 130000, "time": 6300.648903369904, "eval_episode/length": 138.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9568345323741008}
{"step": 130000, "time": 6302.907513856888, "eval_episode/length": 152.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9738562091503268}
{"step": 130000, "time": 6304.49568772316, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 130000, "time": 6306.0392825603485, "eval_episode/length": 155.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 130000, "time": 6308.274445295334, "eval_episode/length": 171.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 130000, "time": 6311.3937895298, "eval_episode/length": 206.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 130000, "time": 6313.006336212158, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 130000, "time": 6315.125068187714, "eval_episode/length": 222.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 130001, "time": 6315.698310852051, "train_stats/sum_log_reward": 4.699999922254811, "train_stats/max_log_achievement_collect_drink": 8.0, "train_stats/max_log_achievement_collect_sapling": 3.4695652173913043, "train_stats/max_log_achievement_collect_wood": 2.991304347826087, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2782608695652174, "train_stats/max_log_achievement_eat_cow": 0.08695652173913043, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.017391304347826087, "train_stats/max_log_achievement_make_wood_sword": 0.0, "train_stats/max_log_achievement_place_plant": 3.1043478260869564, "train_stats/max_log_achievement_place_table": 1.1043478260869566, "train_stats/max_log_achievement_wake_up": 1.7130434782608697, "train_stats/mean_log_entropy": 0.6943303953046384, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.792856316817434, "train/action_min": 0.0, "train/action_std": 3.1482211575472263, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05276640294525856, "train/actor_opt_grad_steps": 7360.0, "train/actor_opt_loss": 6.830290347113645, "train/adv_mag": 1.059674308712321, "train/adv_max": 1.0554432635916804, "train/adv_mean": 0.005818702584689245, "train/adv_min": -0.5605632245988774, "train/adv_std": 0.09408056912453551, "train/cont_avg": 0.9945224389097744, "train/cont_loss_mean": 0.0004767197761518981, "train/cont_loss_std": 0.013746351419713324, "train/cont_neg_acc": 0.9849114158099755, "train/cont_neg_loss": 0.047549534867400316, "train/cont_pos_acc": 0.9999704665707466, "train/cont_pos_loss": 0.00017920357794979283, "train/cont_pred": 0.9945557964475531, "train/cont_rate": 0.9945224389097744, "train/dyn_loss_mean": 12.79185424173685, "train/dyn_loss_std": 8.34950087482768, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.1363932306605173, "train/extr_critic_critic_opt_grad_steps": 7360.0, "train/extr_critic_critic_opt_loss": 14963.006762511748, "train/extr_critic_mag": 2.9336933193350196, "train/extr_critic_max": 2.9336933193350196, "train/extr_critic_mean": 0.5979738963725871, "train/extr_critic_min": -0.23377693506111777, "train/extr_critic_std": 0.825008297325077, "train/extr_return_normed_mag": 2.105102147374834, "train/extr_return_normed_max": 2.105102147374834, "train/extr_return_normed_mean": 0.31729367487412646, "train/extr_return_normed_min": -0.19291602245959125, "train/extr_return_normed_std": 0.3648200803681424, "train/extr_return_rate": 0.34901660131780726, "train/extr_return_raw_mag": 4.876889305903499, "train/extr_return_raw_max": 4.876889305903499, "train/extr_return_raw_mean": 0.6118830420020828, "train/extr_return_raw_min": -0.607264663043775, "train/extr_return_raw_std": 0.8716184788180473, "train/extr_reward_mag": 1.0064943150470131, "train/extr_reward_max": 1.0064943150470131, "train/extr_reward_mean": 0.015700844697710267, "train/extr_reward_min": -0.35815811784643875, "train/extr_reward_std": 0.11005611628069914, "train/image_loss_mean": 16.145397580655892, "train/image_loss_std": 17.449138713062258, "train/model_loss_mean": 23.87415213333933, "train/model_loss_std": 21.06071042656002, "train/model_opt_grad_norm": 92.68660710270244, "train/model_opt_grad_steps": 7349.278195488721, "train/model_opt_loss": 15508.851143973214, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 648.4962406015038, "train/policy_entropy_mag": 2.477722098056535, "train/policy_entropy_max": 2.477722098056535, "train/policy_entropy_mean": 0.730892218593368, "train/policy_entropy_min": 0.07938145711681896, "train/policy_entropy_std": 0.5643293629015299, "train/policy_logprob_mag": 7.438325412291333, "train/policy_logprob_max": -0.00945691568987038, "train/policy_logprob_mean": -0.7312297238443131, "train/policy_logprob_min": -7.438325412291333, "train/policy_logprob_std": 1.1711276438003195, "train/policy_randomness_mag": 0.8745271693494984, "train/policy_randomness_max": 0.8745271693494984, "train/policy_randomness_mean": 0.25797287615618314, "train/policy_randomness_min": 0.02801817082764959, "train/policy_randomness_std": 0.19918349956659445, "train/post_ent_mag": 49.86617947341804, "train/post_ent_max": 49.86617947341804, "train/post_ent_mean": 35.28070174482532, "train/post_ent_min": 19.08003992783396, "train/post_ent_std": 5.3264037433423495, "train/prior_ent_mag": 61.201983401649876, "train/prior_ent_max": 61.201983401649876, "train/prior_ent_mean": 48.22097568942192, "train/prior_ent_min": 23.316132179776528, "train/prior_ent_std": 6.814571481002004, "train/rep_loss_mean": 12.79185424173685, "train/rep_loss_std": 8.34950087482768, "train/reward_avg": 0.016912887489101046, "train/reward_loss_mean": 0.05316523910689175, "train/reward_loss_std": 0.268452109362846, "train/reward_max_data": 1.011278198177653, "train/reward_max_pred": 1.0032253812130232, "train/reward_neg_acc": 0.9939311899636921, "train/reward_neg_loss": 0.03192260396435745, "train/reward_pos_acc": 0.9401800444251612, "train/reward_pos_loss": 1.0083905377782376, "train/reward_pred": 0.015935400245305067, "train/reward_rate": 0.021770735432330827, "eval_stats/sum_log_reward": 4.516666596134503, "eval_stats/max_log_achievement_collect_drink": 7.5, "eval_stats/max_log_achievement_collect_sapling": 3.0, "eval_stats/max_log_achievement_collect_wood": 3.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.16666666666666666, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.041666666666666664, "eval_stats/max_log_achievement_make_wood_sword": 0.08333333333333333, "eval_stats/max_log_achievement_place_plant": 2.7916666666666665, "eval_stats/max_log_achievement_place_table": 1.3333333333333333, "eval_stats/max_log_achievement_wake_up": 1.9166666666666667, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 3.930210823455127e-06, "report/cont_loss_std": 9.331960609415546e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.948517981683835e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.555485363904154e-06, "report/cont_pred": 0.9960906505584717, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.191438674926758, "report/dyn_loss_std": 8.386935234069824, "report/image_loss_mean": 12.522443771362305, "report/image_loss_std": 11.97928237915039, "report/model_loss_mean": 19.878896713256836, "report/model_loss_std": 15.838410377502441, "report/post_ent_mag": 52.218345642089844, "report/post_ent_max": 52.218345642089844, "report/post_ent_mean": 34.758872985839844, "report/post_ent_min": 20.930694580078125, "report/post_ent_std": 5.006595611572266, "report/prior_ent_mag": 60.48712158203125, "report/prior_ent_max": 60.48712158203125, "report/prior_ent_mean": 47.51688003540039, "report/prior_ent_min": 27.685680389404297, "report/prior_ent_std": 6.1224775314331055, "report/rep_loss_mean": 12.191438674926758, "report/rep_loss_std": 8.386935234069824, "report/reward_avg": 0.01943359337747097, "report/reward_loss_mean": 0.0415862612426281, "report/reward_loss_std": 0.18108858168125153, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0050222873687744, "report/reward_neg_acc": 0.9950049519538879, "report/reward_neg_loss": 0.026408465579152107, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7021501660346985, "report/reward_pred": 0.019045285880565643, "report/reward_rate": 0.0224609375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.001229714835062623, "eval/cont_loss_std": 0.039210718125104904, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0005507857422344387, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0012330461759120226, "eval/cont_pred": 0.9944205284118652, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 14.382816314697266, "eval/dyn_loss_std": 8.329346656799316, "eval/image_loss_mean": 18.343259811401367, "eval/image_loss_std": 24.70517349243164, "eval/model_loss_mean": 27.032474517822266, "eval/model_loss_std": 28.110891342163086, "eval/post_ent_mag": 44.721519470214844, "eval/post_ent_max": 44.721519470214844, "eval/post_ent_mean": 33.66405487060547, "eval/post_ent_min": 22.961719512939453, "eval/post_ent_std": 4.205069541931152, "eval/prior_ent_mag": 60.48712158203125, "eval/prior_ent_max": 60.48712158203125, "eval/prior_ent_mean": 46.45684814453125, "eval/prior_ent_min": 23.083703994750977, "eval/prior_ent_std": 6.993957996368408, "eval/rep_loss_mean": 14.382816314697266, "eval/rep_loss_std": 8.329346656799316, "eval/reward_avg": 0.0027343749534338713, "eval/reward_loss_mean": 0.058294784277677536, "eval/reward_loss_std": 0.5265629887580872, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9992156028747559, "eval/reward_neg_acc": 0.9970500469207764, "eval/reward_neg_loss": 0.04505980759859085, "eval/reward_pos_acc": 0.8571429252624512, "eval/reward_pos_loss": 1.9811475276947021, "eval/reward_pred": 0.0018714776961132884, "eval/reward_rate": 0.0068359375, "replay/size": 129497.0, "replay/inserts": 21400.0, "replay/samples": 21392.0, "replay/insert_wait_avg": 1.3949603677910065e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 9.074885183603975e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 26792.0, "eval_replay/inserts": 5936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.219766480582101e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.1175870895385742e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1018.0758752822876, "timer/env.step_count": 2675.0, "timer/env.step_total": 262.2167935371399, "timer/env.step_frac": 0.2575611503066346, "timer/env.step_avg": 0.09802496954659436, "timer/env.step_min": 0.023008346557617188, "timer/env.step_max": 2.218043327331543, "timer/replay._sample_count": 21392.0, "timer/replay._sample_total": 11.734494924545288, "timer/replay._sample_frac": 0.011526149680436734, "timer/replay._sample_avg": 0.0005485459482304267, "timer/replay._sample_min": 0.0004115104675292969, "timer/replay._sample_max": 0.02414679527282715, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3417.0, "timer/agent.policy_total": 58.06804919242859, "timer/agent.policy_frac": 0.05703705450866099, "timer/agent.policy_avg": 0.016993868654500612, "timer/agent.policy_min": 0.009319543838500977, "timer/agent.policy_max": 0.1144711971282959, "timer/dataset_train_count": 1337.0, "timer/dataset_train_total": 0.15525102615356445, "timer/dataset_train_frac": 0.00015249455362108166, "timer/dataset_train_avg": 0.00011611894252323444, "timer/dataset_train_min": 9.775161743164062e-05, "timer/dataset_train_max": 0.0004990100860595703, "timer/agent.train_count": 1337.0, "timer/agent.train_total": 600.1713256835938, "timer/agent.train_frac": 0.589515320277264, "timer/agent.train_avg": 0.4488940356646176, "timer/agent.train_min": 0.4335610866546631, "timer/agent.train_max": 1.4427173137664795, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47281765937805176, "timer/agent.report_frac": 0.00046442281057583354, "timer/agent.report_avg": 0.23640882968902588, "timer/agent.report_min": 0.2289435863494873, "timer/agent.report_max": 0.24387407302856445, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.1948089599609375e-05, "timer/dataset_eval_frac": 3.138085321072061e-08, "timer/dataset_eval_avg": 3.1948089599609375e-05, "timer/dataset_eval_min": 3.1948089599609375e-05, "timer/dataset_eval_max": 3.1948089599609375e-05, "fps": 21.01978358894371}
{"step": 130088, "time": 6318.612576007843, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9851485148514851, "episode/intrinsic_return": 0.0}
{"step": 130216, "time": 6324.351425886154, "episode/length": 46.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8936170212765957, "episode/intrinsic_return": 0.0}
{"step": 130512, "time": 6336.288657426834, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9532163742690059, "episode/intrinsic_return": 0.0}
{"step": 130800, "time": 6347.54939699173, "episode/length": 88.0, "episode/score": 1.1000000014901161, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 130912, "time": 6352.830848932266, "episode/length": 49.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 131112, "time": 6362.144628286362, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 131160, "time": 6365.324575424194, "episode/length": 238.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 131272, "time": 6370.711184263229, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 131344, "time": 6374.893678188324, "episode/length": 168.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 131456, "time": 6380.077454566956, "episode/length": 328.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 131488, "time": 6382.870232343674, "episode/length": 158.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 131512, "time": 6385.051258563995, "episode/length": 49.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 132352, "time": 6414.6447241306305, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 132608, "time": 6424.6651158332825, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 132776, "time": 6431.77218747139, "episode/length": 201.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 132784, "time": 6433.929053544998, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 132968, "time": 6441.438180923462, "episode/length": 211.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 133168, "time": 6449.735096693039, "episode/length": 48.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 133328, "time": 6456.615369558334, "episode/length": 301.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9900662251655629, "episode/intrinsic_return": 0.0}
{"step": 133448, "time": 6462.1053376197815, "episode/length": 248.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 133528, "time": 6466.30824637413, "episode/length": 251.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 133704, "time": 6473.670714855194, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 134048, "time": 6486.798157215118, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 134104, "time": 6490.150933265686, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 134256, "time": 6497.007126092911, "episode/length": 160.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 134448, "time": 6504.935797452927, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 134576, "time": 6510.901063919067, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 134600, "time": 6513.07231760025, "episode/length": 178.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 134656, "time": 6516.738557815552, "episode/length": 49.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 135168, "time": 6535.436709880829, "episode/length": 204.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 135392, "time": 6544.366624593735, "episode/length": 210.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 135584, "time": 6552.423131942749, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 135640, "time": 6555.586375713348, "episode/length": 58.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 135776, "time": 6561.91170835495, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 135880, "time": 6566.777312994003, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 135984, "time": 6571.999024391174, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9829545454545454, "episode/intrinsic_return": 0.0}
{"step": 136000, "time": 6574.179059743881, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 136016, "time": 6576.259298801422, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 136208, "time": 6584.179228067398, "episode/length": 70.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 136304, "time": 6588.86817574501, "episode/length": 113.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 136808, "time": 6606.7904896736145, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 137088, "time": 6617.966797113419, "episode/length": 150.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 137248, "time": 6624.812883377075, "episode/length": 183.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 137296, "time": 6628.002893686295, "episode/length": 60.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 137392, "time": 6632.724197149277, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 137424, "time": 6635.4672820568085, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 137488, "time": 6639.260754823685, "episode/length": 159.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 137552, "time": 6643.131606578827, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 137936, "time": 6657.363489627838, "episode/length": 203.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 137976, "time": 6660.006156206131, "episode/length": 72.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9315068493150684, "episode/intrinsic_return": 0.0}
{"step": 138552, "time": 6680.793157339096, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 138600, "time": 6684.607053279877, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 138752, "time": 6692.033615112305, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 138816, "time": 6695.734012842178, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 138992, "time": 6703.2253677845, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 139136, "time": 6709.591009140015, "episode/length": 205.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 139632, "time": 6729.339624881744, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 139728, "time": 6734.260825395584, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 139872, "time": 6740.630339860916, "episode/length": 139.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 139928, "time": 6744.265586137772, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 139984, "time": 6748.349871873856, "episode/length": 178.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 140088, "time": 6767.543674707413, "eval_episode/length": 31.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.84375}
{"step": 140088, "time": 6774.181900024414, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 140088, "time": 6774.189849615097, "eval_episode/length": 156.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 140088, "time": 6777.687964439392, "eval_episode/length": 160.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 140088, "time": 6779.933524847031, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 140088, "time": 6782.9895169734955, "eval_episode/length": 192.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 140088, "time": 6786.880761384964, "eval_episode/length": 71.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 140088, "time": 6790.922067165375, "eval_episode/length": 278.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.982078853046595}
{"step": 140544, "time": 6806.26767206192, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 140552, "time": 6807.784281015396, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 140992, "time": 6824.21359205246, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 141000, "time": 6825.866057634354, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 141168, "time": 6833.184579372406, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 141304, "time": 6838.997233629227, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 141416, "time": 6844.307959318161, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 141576, "time": 6851.175597190857, "episode/length": 128.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 141696, "time": 6856.851589679718, "episode/length": 220.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 141864, "time": 6863.737449169159, "episode/length": 163.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 142336, "time": 6881.214472770691, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 142536, "time": 6889.21484208107, "episode/length": 192.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 142704, "time": 6897.020618915558, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 142744, "time": 6899.7373995780945, "episode/length": 165.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 142760, "time": 6901.806457519531, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 142976, "time": 6910.827867269516, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 143952, "time": 6945.013449668884, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 143960, "time": 6946.63937830925, "episode/length": 261.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 144016, "time": 6950.390923500061, "episode/length": 304.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 144024, "time": 6952.085658788681, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 144136, "time": 6957.410130262375, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 144152, "time": 6959.485514163971, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 144248, "time": 6964.166376113892, "episode/length": 158.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 144560, "time": 6976.445612668991, "episode/length": 231.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 145224, "time": 6999.766877174377, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 145512, "time": 7010.933476686478, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 145656, "time": 7017.374374389648, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 145656, "time": 7017.384993553162, "episode/length": 212.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 145672, "time": 7021.187113523483, "episode/length": 213.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 145736, "time": 7024.7902574539185, "episode/length": 199.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 145752, "time": 7026.873534202576, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 145952, "time": 7035.552464008331, "episode/length": 34.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 146136, "time": 7043.676754236221, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 146696, "time": 7063.944730043411, "episode/length": 129.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 146856, "time": 7070.777047157288, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 146896, "time": 7074.0268495082855, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 147008, "time": 7079.242321014404, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 147264, "time": 7089.477894306183, "episode/length": 188.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 147472, "time": 7100.018617630005, "episode/length": 226.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 147680, "time": 7108.606766700745, "episode/length": 215.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 147784, "time": 7113.44557261467, "episode/length": 205.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 148112, "time": 7126.3031713962555, "episode/length": 156.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 148280, "time": 7133.25846529007, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 148552, "time": 7144.504890680313, "episode/length": 160.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 148624, "time": 7149.25613117218, "episode/length": 215.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 148776, "time": 7156.324298858643, "episode/length": 162.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 149008, "time": 7166.322088241577, "episode/length": 288.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.986159169550173, "episode/intrinsic_return": 0.0}
{"step": 149320, "time": 7177.946453809738, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 149784, "time": 7194.9132244586945, "episode/length": 187.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 149896, "time": 7200.078943014145, "episode/length": 276.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 149904, "time": 7202.120505571365, "episode/length": 140.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9574468085106383, "episode/intrinsic_return": 0.0}
{"step": 149952, "time": 7205.3266813755035, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 150000, "time": 7208.511199712753, "episode/length": 235.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 150072, "time": 7227.189620256424, "eval_episode/length": 52.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9811320754716981}
{"step": 150072, "time": 7232.956390619278, "eval_episode/length": 154.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 150072, "time": 7234.70624089241, "eval_episode/length": 160.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 150072, "time": 7237.043785572052, "eval_episode/length": 180.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 150072, "time": 7238.715918302536, "eval_episode/length": 181.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 150072, "time": 7240.973825216293, "eval_episode/length": 196.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9746192893401016}
{"step": 150072, "time": 7243.240278244019, "eval_episode/length": 214.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 150072, "time": 7246.911660671234, "eval_episode/length": 210.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 150352, "time": 7256.3342208862305, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 150408, "time": 7259.512620210648, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 150800, "time": 7274.20285654068, "episode/length": 112.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9469026548672567, "episode/intrinsic_return": 0.0}
{"step": 151160, "time": 7287.569833517075, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 151224, "time": 7291.569893836975, "episode/length": 237.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 151384, "time": 7298.956027746201, "episode/length": 178.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 151464, "time": 7303.279185533524, "episode/length": 209.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 151760, "time": 7314.916839122772, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 151761, "time": 7317.140424489975, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.69809274112477, "train/action_min": 0.0, "train/action_std": 3.2464109396233276, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05147951890659683, "train/actor_opt_grad_steps": 8705.0, "train/actor_opt_loss": 2.850342256400515, "train/adv_mag": 0.9432808349237722, "train/adv_max": 0.938605905893971, "train/adv_mean": 0.004747847067044538, "train/adv_min": -0.5492912467349979, "train/adv_std": 0.0861685468322214, "train/cont_avg": 0.9944565716911765, "train/cont_loss_mean": 0.0006268876496215078, "train/cont_loss_std": 0.01582978741343515, "train/cont_neg_acc": 0.9853699829648522, "train/cont_neg_loss": 0.06009635931778736, "train/cont_pos_acc": 0.9998844055568471, "train/cont_pos_loss": 0.000273295522364926, "train/cont_pred": 0.99443129274775, "train/cont_rate": 0.9944565716911765, "train/dyn_loss_mean": 13.866130709648132, "train/dyn_loss_std": 8.55799232861575, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0535697218249827, "train/extr_critic_critic_opt_grad_steps": 8705.0, "train/extr_critic_critic_opt_loss": 15288.831823012408, "train/extr_critic_mag": 3.3126441590926228, "train/extr_critic_max": 3.3126441590926228, "train/extr_critic_mean": 0.6623089459231671, "train/extr_critic_min": -0.26356103052111235, "train/extr_critic_std": 0.9085868154378498, "train/extr_return_normed_mag": 2.0204663618522534, "train/extr_return_normed_max": 2.0204663618522534, "train/extr_return_normed_mean": 0.30855486169457436, "train/extr_return_normed_min": -0.1893094308564768, "train/extr_return_normed_std": 0.3550344571909484, "train/extr_return_rate": 0.3697481248527765, "train/extr_return_raw_mag": 5.254615301595015, "train/extr_return_raw_max": 5.254615301595015, "train/extr_return_raw_mean": 0.6749950397540542, "train/extr_return_raw_min": -0.6570052846389658, "train/extr_return_raw_std": 0.9495103227741578, "train/extr_reward_mag": 1.0066973453058916, "train/extr_reward_max": 1.0066973453058916, "train/extr_reward_mean": 0.016654060129761037, "train/extr_reward_min": -0.376038282233126, "train/extr_reward_std": 0.11515474045539603, "train/image_loss_mean": 14.475267908152412, "train/image_loss_std": 15.911882835275987, "train/model_loss_mean": 22.85022191440358, "train/model_loss_std": 19.579366466578314, "train/model_opt_grad_norm": 100.13629551494823, "train/model_opt_grad_steps": 8692.213235294117, "train/model_opt_loss": 9602.22791963465, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 418.1985294117647, "train/policy_entropy_mag": 2.5178259558537426, "train/policy_entropy_max": 2.5178259558537426, "train/policy_entropy_mean": 0.719458760584102, "train/policy_entropy_min": 0.07937971579239649, "train/policy_entropy_std": 0.5929923710577628, "train/policy_logprob_mag": 7.438345905612497, "train/policy_logprob_max": -0.00945660745149807, "train/policy_logprob_mean": -0.7190390145953964, "train/policy_logprob_min": -7.438345905612497, "train/policy_logprob_std": 1.1627213998752481, "train/policy_randomness_mag": 0.8886820713386816, "train/policy_randomness_max": 0.8886820713386816, "train/policy_randomness_mean": 0.2539373703081818, "train/policy_randomness_min": 0.02801755621262333, "train/policy_randomness_std": 0.20930028619135127, "train/post_ent_mag": 51.63230584649479, "train/post_ent_max": 51.63230584649479, "train/post_ent_mean": 35.95420102512135, "train/post_ent_min": 19.834457032820758, "train/post_ent_std": 5.561257053824032, "train/prior_ent_mag": 62.22591248680563, "train/prior_ent_max": 62.22591248680563, "train/prior_ent_mean": 49.960546745973474, "train/prior_ent_min": 25.881726054584277, "train/prior_ent_std": 6.51193313738879, "train/rep_loss_mean": 13.866130709648132, "train/rep_loss_std": 8.55799232861575, "train/reward_avg": 0.017817239088745898, "train/reward_loss_mean": 0.054648627664017325, "train/reward_loss_std": 0.27639629067305255, "train/reward_max_data": 1.0073529429295485, "train/reward_max_pred": 1.00301313049653, "train/reward_neg_acc": 0.9938853532075882, "train/reward_neg_loss": 0.0321256488780765, "train/reward_pos_acc": 0.9356431281741928, "train/reward_pos_loss": 1.0258819969261395, "train/reward_pred": 0.016664733278209016, "train/reward_rate": 0.02292049632352941, "train_stats/sum_log_reward": 4.559016316518432, "train_stats/max_log_achievement_collect_drink": 6.991803278688525, "train_stats/max_log_achievement_collect_sapling": 3.1311475409836067, "train_stats/max_log_achievement_collect_wood": 3.19672131147541, "train_stats/max_log_achievement_defeat_skeleton": 0.01639344262295082, "train_stats/max_log_achievement_defeat_zombie": 0.2540983606557377, "train_stats/max_log_achievement_eat_cow": 0.07377049180327869, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.04918032786885246, "train_stats/max_log_achievement_make_wood_sword": 0.02459016393442623, "train_stats/max_log_achievement_place_plant": 2.9508196721311477, "train_stats/max_log_achievement_place_table": 1.1967213114754098, "train_stats/max_log_achievement_wake_up": 1.5491803278688525, "train_stats/mean_log_entropy": 0.6529977524378261, "train_stats/max_log_achievement_collect_stone": 0.017699115044247787, "eval_stats/sum_log_reward": 4.412499941885471, "eval_stats/max_log_achievement_collect_drink": 6.875, "eval_stats/max_log_achievement_collect_sapling": 2.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 2.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.5625, "eval_stats/max_log_achievement_place_table": 0.9375, "eval_stats/max_log_achievement_wake_up": 1.625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.1397731213946827e-05, "report/cont_loss_std": 0.00015969968808349222, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0010753239039331675, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 7.225471563288011e-06, "report/cont_pred": 0.9960907697677612, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.011163711547852, "report/dyn_loss_std": 9.09842586517334, "report/image_loss_mean": 14.81614875793457, "report/image_loss_std": 19.624906539916992, "report/model_loss_mean": 23.877161026000977, "report/model_loss_std": 23.519044876098633, "report/post_ent_mag": 53.25340270996094, "report/post_ent_max": 53.25340270996094, "report/post_ent_mean": 36.580535888671875, "report/post_ent_min": 19.387216567993164, "report/post_ent_std": 5.506653785705566, "report/prior_ent_mag": 62.86859130859375, "report/prior_ent_max": 62.86859130859375, "report/prior_ent_mean": 51.83251190185547, "report/prior_ent_min": 29.41838836669922, "report/prior_ent_std": 6.2772746086120605, "report/rep_loss_mean": 15.011163711547852, "report/rep_loss_std": 9.09842586517334, "report/reward_avg": 0.01611328125, "report/reward_loss_mean": 0.05430152639746666, "report/reward_loss_std": 0.26073646545410156, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0120582580566406, "report/reward_neg_acc": 0.9950099587440491, "report/reward_neg_loss": 0.03363700211048126, "report/reward_pos_acc": 0.9545454978942871, "report/reward_pos_loss": 0.9954766631126404, "report/reward_pred": 0.013871266506612301, "report/reward_rate": 0.021484375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 1.045188128045993e-06, "eval/cont_loss_std": 2.0928142475895584e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00022549406276084483, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.059535735403188e-07, "eval/cont_pred": 0.9980467557907104, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 13.650367736816406, "eval/dyn_loss_std": 7.531538486480713, "eval/image_loss_mean": 10.48420524597168, "eval/image_loss_std": 15.550687789916992, "eval/model_loss_mean": 18.71855354309082, "eval/model_loss_std": 18.40890884399414, "eval/post_ent_mag": 51.944915771484375, "eval/post_ent_max": 51.944915771484375, "eval/post_ent_mean": 37.573509216308594, "eval/post_ent_min": 20.987648010253906, "eval/post_ent_std": 5.02540922164917, "eval/prior_ent_mag": 62.86859130859375, "eval/prior_ent_max": 62.86859130859375, "eval/prior_ent_mean": 49.07757568359375, "eval/prior_ent_min": 28.225902557373047, "eval/prior_ent_std": 4.708603858947754, "eval/rep_loss_mean": 13.650367736816406, "eval/rep_loss_std": 7.531538486480713, "eval/reward_avg": 0.007519531529396772, "eval/reward_loss_mean": 0.04412747174501419, "eval/reward_loss_std": 0.3848227560520172, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000529289245605, "eval/reward_neg_acc": 0.9980257153511047, "eval/reward_neg_loss": 0.01690935716032982, "eval/reward_pos_acc": 0.5454545617103577, "eval/reward_pos_loss": 2.550668478012085, "eval/reward_pred": 0.0035664821043610573, "eval/reward_rate": 0.0107421875, "replay/size": 151257.0, "replay/inserts": 21760.0, "replay/samples": 21760.0, "replay/insert_wait_avg": 1.37718503966051e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.627443629152635e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 31136.0, "eval_replay/inserts": 4344.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1732674874433935e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.791685104370117e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.4303686618805, "timer/env.step_count": 2720.0, "timer/env.step_total": 271.2243630886078, "timer/env.step_frac": 0.2708369663794199, "timer/env.step_avg": 0.09971483937081169, "timer/env.step_min": 0.022238969802856445, "timer/env.step_max": 3.2992188930511475, "timer/replay._sample_count": 21760.0, "timer/replay._sample_total": 11.322200059890747, "timer/replay._sample_frac": 0.011306028271361058, "timer/replay._sample_avg": 0.0005203216939288027, "timer/replay._sample_min": 0.00039386749267578125, "timer/replay._sample_max": 0.010196685791015625, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3263.0, "timer/agent.policy_total": 53.88444757461548, "timer/agent.policy_frac": 0.05380748303710454, "timer/agent.policy_avg": 0.016513774923265546, "timer/agent.policy_min": 0.00916290283203125, "timer/agent.policy_max": 0.11767196655273438, "timer/dataset_train_count": 1360.0, "timer/dataset_train_total": 0.1538393497467041, "timer/dataset_train_frac": 0.00015361961706061053, "timer/dataset_train_avg": 0.00011311716893140007, "timer/dataset_train_min": 9.870529174804688e-05, "timer/dataset_train_max": 0.0008797645568847656, "timer/agent.train_count": 1360.0, "timer/agent.train_total": 607.6352667808533, "timer/agent.train_frac": 0.6067673657558244, "timer/agent.train_avg": 0.4467906373388627, "timer/agent.train_min": 0.43209028244018555, "timer/agent.train_max": 1.4333305358886719, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778707027435303, "timer/agent.report_frac": 0.00047718814777113764, "timer/agent.report_avg": 0.23893535137176514, "timer/agent.report_min": 0.23349905014038086, "timer/agent.report_max": 0.24437165260314941, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 2.999783300654e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 21.72864769922281}
{"step": 151832, "time": 7319.545654296875, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 151928, "time": 7324.203283786774, "episode/length": 140.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.950354609929078, "episode/intrinsic_return": 0.0}
{"step": 151968, "time": 7327.430788516998, "episode/length": 245.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 152576, "time": 7349.296785831451, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 152744, "time": 7356.368307590485, "episode/length": 169.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 152848, "time": 7361.738114833832, "episode/length": 202.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 153152, "time": 7373.539922714233, "episode/length": 173.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 153352, "time": 7381.65416097641, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 153560, "time": 7390.226669311523, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 153592, "time": 7392.903097867966, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 153632, "time": 7396.075087070465, "episode/length": 270.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 154088, "time": 7412.7418377399445, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 154184, "time": 7417.627937555313, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 154568, "time": 7432.192878961563, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 154992, "time": 7448.177715301514, "episode/length": 204.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 155144, "time": 7454.852553606033, "episode/length": 248.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 155232, "time": 7459.682954072952, "episode/length": 82.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 155312, "time": 7464.034038066864, "episode/length": 39.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 155432, "time": 7469.349493503571, "episode/length": 229.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 155488, "time": 7473.03436088562, "episode/length": 162.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 155496, "time": 7474.615156650543, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 155616, "time": 7480.421144485474, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 155696, "time": 7486.062127113342, "episode/length": 257.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9844961240310077, "episode/intrinsic_return": 0.0}
{"step": 156696, "time": 7520.781092166901, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 156792, "time": 7525.600545406342, "episode/length": 194.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 156976, "time": 7533.5981657505035, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 156976, "time": 7533.608003854752, "episode/length": 184.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 157016, "time": 7538.114704608917, "episode/length": 233.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 157088, "time": 7542.485489368439, "episode/length": 221.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 157296, "time": 7551.022534370422, "episode/length": 209.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 157416, "time": 7556.4514582157135, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9090909090909091, "episode/intrinsic_return": 0.0}
{"step": 157920, "time": 7575.195803165436, "episode/length": 103.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 157944, "time": 7577.37643289566, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 158056, "time": 7582.687729358673, "episode/length": 294.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9966101694915255, "episode/intrinsic_return": 0.0}
{"step": 158056, "time": 7582.696654558182, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 158240, "time": 7592.62106013298, "episode/length": 36.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 158472, "time": 7601.960195541382, "episode/length": 186.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 158800, "time": 7614.588109731674, "episode/length": 172.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 158880, "time": 7618.883644104004, "episode/length": 232.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 158928, "time": 7622.178704738617, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 159216, "time": 7633.412146806717, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 159496, "time": 7644.066511631012, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 159624, "time": 7649.9413278102875, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 159688, "time": 7653.816049575806, "episode/length": 220.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 159960, "time": 7664.854571819305, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 160008, "time": 7668.464495420456, "episode/length": 47.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 160056, "time": 7686.839143276215, "eval_episode/length": 48.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9183673469387755}
{"step": 160056, "time": 7694.067955970764, "eval_episode/length": 150.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9602649006622517}
{"step": 160056, "time": 7696.733404159546, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 160056, "time": 7698.987269878387, "eval_episode/length": 180.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.994475138121547}
{"step": 160056, "time": 7701.120249032974, "eval_episode/length": 192.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 160056, "time": 7702.824514627457, "eval_episode/length": 196.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 160056, "time": 7704.795351743698, "eval_episode/length": 54.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 160056, "time": 7707.601152420044, "eval_episode/length": 185.0, "eval_episode/score": 6.100000016391277, "eval_episode/reward_rate": 0.978494623655914}
{"step": 160120, "time": 7709.770151615143, "episode/length": 154.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 160288, "time": 7717.180233240128, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 160808, "time": 7735.991529464722, "episode/length": 198.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 160936, "time": 7741.764710664749, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9800796812749004, "episode/intrinsic_return": 0.0}
{"step": 161064, "time": 7747.517680883408, "episode/length": 195.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 161200, "time": 7753.844450473785, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 161208, "time": 7755.543738365173, "episode/length": 189.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 161496, "time": 7766.709657430649, "episode/length": 185.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 161496, "time": 7766.718393802643, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 162280, "time": 7797.157465696335, "episode/length": 167.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 162320, "time": 7800.70623922348, "episode/length": 188.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 162456, "time": 7807.22238278389, "episode/length": 270.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 162480, "time": 7809.990087509155, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 162520, "time": 7812.746174812317, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 162616, "time": 7817.441774368286, "episode/length": 139.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9571428571428572, "episode/intrinsic_return": 0.0}
{"step": 162872, "time": 7827.6500787734985, "episode/length": 43.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 162920, "time": 7830.772021770477, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 163232, "time": 7843.08758187294, "episode/length": 44.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 163376, "time": 7849.543731927872, "episode/length": 270.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 163800, "time": 7865.383670091629, "episode/length": 189.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 163896, "time": 7871.642175197601, "episode/length": 159.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 164144, "time": 7881.716517448425, "episode/length": 152.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 164520, "time": 7895.644048452377, "episode/length": 257.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 164728, "time": 7904.194092988968, "episode/length": 280.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 164760, "time": 7906.9155814647675, "episode/length": 304.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 164808, "time": 7910.089609861374, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 165096, "time": 7921.277605295181, "episode/length": 45.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 165304, "time": 7929.930167913437, "episode/length": 144.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 165368, "time": 7933.748065471649, "episode/length": 248.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 165872, "time": 7952.3560791015625, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 166112, "time": 7962.067945718765, "episode/length": 276.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 166344, "time": 7971.873861551285, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 166384, "time": 7974.9955859184265, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 166520, "time": 7980.966696500778, "episode/length": 249.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 166752, "time": 7990.576046705246, "episode/length": 206.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 166856, "time": 7995.38122844696, "episode/length": 193.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 167064, "time": 8003.910254001617, "episode/length": 211.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 167368, "time": 8015.610946178436, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 167416, "time": 8018.720552682877, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 167800, "time": 8033.306400060654, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 167824, "time": 8035.954934120178, "episode/length": 162.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 167848, "time": 8038.099857330322, "episode/length": 182.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 168000, "time": 8044.9054980278015, "episode/length": 116.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 168312, "time": 8056.678533315659, "episode/length": 194.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 168424, "time": 8064.417158603668, "episode/length": 195.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 168728, "time": 8076.092257261276, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 169184, "time": 8093.257350921631, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 169264, "time": 8097.466680049896, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 169408, "time": 8103.709358215332, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 169408, "time": 8103.719542503357, "episode/length": 248.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 169576, "time": 8112.7239310741425, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 169920, "time": 8126.08606338501, "episode/length": 186.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 169992, "time": 8129.803564310074, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 170040, "time": 8152.858431339264, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 170040, "time": 8154.690344810486, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.975609756097561}
{"step": 170040, "time": 8156.402407407761, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 170040, "time": 8158.201305150986, "eval_episode/length": 170.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 170040, "time": 8160.658555269241, "eval_episode/length": 191.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 170040, "time": 8162.449497938156, "eval_episode/length": 197.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 170040, "time": 8164.2566614151, "eval_episode/length": 204.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9951219512195122}
{"step": 170040, "time": 8166.0540318489075, "eval_episode/length": 210.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.995260663507109}
{"step": 170104, "time": 8168.181826353073, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 170664, "time": 8188.502051353455, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 170672, "time": 8190.563084602356, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 170688, "time": 8192.677293300629, "episode/length": 159.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 170808, "time": 8197.982646942139, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 171104, "time": 8209.76449894905, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 171336, "time": 8219.056606292725, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 171408, "time": 8223.813133239746, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 171760, "time": 8237.914311170578, "episode/length": 272.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 171816, "time": 8241.704670190811, "episode/length": 142.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 172064, "time": 8254.039144039154, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 172248, "time": 8262.22328543663, "episode/length": 194.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 172392, "time": 8269.206729650497, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 172480, "time": 8274.519896507263, "episode/length": 51.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 172544, "time": 8278.7359457016, "episode/length": 179.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 172904, "time": 8293.122951507568, "episode/length": 186.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 173104, "time": 8302.293260097504, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 173264, "time": 8310.009083271027, "episode/length": 180.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 173401, "time": 8317.558382749557, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.655513987821691, "train/action_min": 0.0, "train/action_std": 3.337968389777576, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.05080414629157852, "train/actor_opt_grad_steps": 10065.0, "train/actor_opt_loss": 4.837731992935433, "train/adv_mag": 0.9182085640290204, "train/adv_max": 0.9079794226323857, "train/adv_mean": 0.006121345738232348, "train/adv_min": -0.5432025562314426, "train/adv_std": 0.08667425970163416, "train/cont_avg": 0.99462890625, "train/cont_loss_mean": 0.0005306842922378256, "train/cont_loss_std": 0.014688464747985778, "train/cont_neg_acc": 0.9780987426638603, "train/cont_neg_loss": 0.05560546711800431, "train/cont_pos_acc": 0.9999349371475332, "train/cont_pos_loss": 0.00019599678431112805, "train/cont_pred": 0.9946450380718007, "train/cont_rate": 0.99462890625, "train/dyn_loss_mean": 14.42201926427729, "train/dyn_loss_std": 8.82285734134562, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0054489225149155, "train/extr_critic_critic_opt_grad_steps": 10065.0, "train/extr_critic_critic_opt_loss": 15080.85383157169, "train/extr_critic_mag": 3.703034849727855, "train/extr_critic_max": 3.703034849727855, "train/extr_critic_mean": 0.7103829109931693, "train/extr_critic_min": -0.23602892107823314, "train/extr_critic_std": 0.9315697410527397, "train/extr_return_normed_mag": 2.029834650895175, "train/extr_return_normed_max": 2.029834650895175, "train/extr_return_normed_mean": 0.2997195238576216, "train/extr_return_normed_min": -0.18782512865522327, "train/extr_return_normed_std": 0.35059220760184173, "train/extr_return_rate": 0.38370626660830837, "train/extr_return_raw_mag": 5.549727913211374, "train/extr_return_raw_max": 5.549727913211374, "train/extr_return_raw_mean": 0.727457878563334, "train/extr_return_raw_min": -0.6317362200249644, "train/extr_return_raw_std": 0.9772782961235327, "train/extr_reward_mag": 1.008617499295403, "train/extr_reward_max": 1.008617499295403, "train/extr_reward_mean": 0.018363482736544135, "train/extr_reward_min": -0.4124023686437046, "train/extr_reward_std": 0.12081798741265255, "train/image_loss_mean": 13.234568013864404, "train/image_loss_std": 15.649384807137881, "train/model_loss_mean": 21.94249902052038, "train/model_loss_std": 19.388563450644998, "train/model_opt_grad_norm": 86.24287692238303, "train/model_opt_grad_steps": 10051.720588235294, "train/model_opt_loss": 15201.303596047794, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 689.3382352941177, "train/policy_entropy_mag": 2.514250197831322, "train/policy_entropy_max": 2.514250197831322, "train/policy_entropy_mean": 0.694375633755151, "train/policy_entropy_min": 0.07937656584031441, "train/policy_entropy_std": 0.6247796534615404, "train/policy_logprob_mag": 7.438369912259719, "train/policy_logprob_max": -0.009456052718793644, "train/policy_logprob_mean": -0.6943685500060811, "train/policy_logprob_min": -7.438369912259719, "train/policy_logprob_std": 1.1616573929786682, "train/policy_randomness_mag": 0.8874199850594297, "train/policy_randomness_max": 0.8874199850594297, "train/policy_randomness_mean": 0.24508412927389145, "train/policy_randomness_min": 0.02801644430934068, "train/policy_randomness_std": 0.22051979984868975, "train/post_ent_mag": 52.33537533703972, "train/post_ent_max": 52.33537533703972, "train/post_ent_mean": 36.40934010112987, "train/post_ent_min": 20.06569328027613, "train/post_ent_std": 5.771939891226151, "train/prior_ent_mag": 63.13612304014318, "train/prior_ent_max": 63.13612304014318, "train/prior_ent_mean": 50.97124029608334, "train/prior_ent_min": 27.43782719443826, "train/prior_ent_std": 6.507128406973446, "train/rep_loss_mean": 14.42201926427729, "train/rep_loss_std": 8.82285734134562, "train/reward_avg": 0.018865607562474906, "train/reward_loss_mean": 0.05418876750285134, "train/reward_loss_std": 0.27180313855847893, "train/reward_max_data": 1.0066176486365936, "train/reward_max_pred": 1.0037424327696072, "train/reward_neg_acc": 0.9926139927085709, "train/reward_neg_loss": 0.032398916007129144, "train/reward_pos_acc": 0.9484983419670778, "train/reward_pos_loss": 0.9609551438513924, "train/reward_pred": 0.018522027958704924, "train/reward_rate": 0.02360983455882353, "train_stats/sum_log_reward": 4.86068367652404, "train_stats/max_log_achievement_collect_drink": 6.094017094017094, "train_stats/max_log_achievement_collect_sapling": 3.3076923076923075, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.5982905982905984, "train_stats/max_log_achievement_defeat_skeleton": 0.008547008547008548, "train_stats/max_log_achievement_defeat_zombie": 0.3162393162393162, "train_stats/max_log_achievement_eat_cow": 0.1452991452991453, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.008547008547008548, "train_stats/max_log_achievement_make_wood_sword": 0.05982905982905983, "train_stats/max_log_achievement_place_plant": 3.2051282051282053, "train_stats/max_log_achievement_place_table": 1.4188034188034189, "train_stats/max_log_achievement_wake_up": 1.7179487179487178, "train_stats/mean_log_entropy": 0.6137481698623071, "eval_stats/sum_log_reward": 4.599999941885471, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 3.375, "eval_stats/max_log_achievement_collect_stone": 0.0625, "eval_stats/max_log_achievement_collect_wood": 3.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.0625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_plant": 3.1875, "eval_stats/max_log_achievement_place_table": 1.4375, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 8.021150279091671e-05, "report/cont_loss_std": 0.0025015424471348524, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001820847683120519, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.971164450282231e-05, "report/cont_pred": 0.9950418472290039, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.856939315795898, "report/dyn_loss_std": 9.004678726196289, "report/image_loss_mean": 10.489045143127441, "report/image_loss_std": 13.436614990234375, "report/model_loss_mean": 18.867183685302734, "report/model_loss_std": 17.399608612060547, "report/post_ent_mag": 53.086639404296875, "report/post_ent_max": 53.086639404296875, "report/post_ent_mean": 38.00250244140625, "report/post_ent_min": 20.800785064697266, "report/post_ent_std": 5.960315704345703, "report/prior_ent_mag": 63.59947204589844, "report/prior_ent_max": 63.59947204589844, "report/prior_ent_mean": 52.21918869018555, "report/prior_ent_min": 28.510709762573242, "report/prior_ent_std": 5.283753395080566, "report/rep_loss_mean": 13.856939315795898, "report/rep_loss_std": 9.004678726196289, "report/reward_avg": 0.02656250074505806, "report/reward_loss_mean": 0.06389334797859192, "report/reward_loss_std": 0.3359389007091522, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.028045892715454, "report/reward_neg_acc": 0.9959717988967896, "report/reward_neg_loss": 0.032179027795791626, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 1.0797746181488037, "report/reward_pred": 0.020059701055288315, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 2.8366093829390593e-06, "eval/cont_loss_std": 5.0942431698786095e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 8.761205390328541e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.420635837552254e-06, "eval/cont_pred": 0.9951152205467224, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.14840316772461, "eval/dyn_loss_std": 8.82631778717041, "eval/image_loss_mean": 20.977222442626953, "eval/image_loss_std": 19.873836517333984, "eval/model_loss_mean": 31.354938507080078, "eval/model_loss_std": 22.50550079345703, "eval/post_ent_mag": 54.50432205200195, "eval/post_ent_max": 54.50432205200195, "eval/post_ent_mean": 37.75858688354492, "eval/post_ent_min": 20.40557861328125, "eval/post_ent_std": 6.143117904663086, "eval/prior_ent_mag": 63.59947204589844, "eval/prior_ent_max": 63.59947204589844, "eval/prior_ent_mean": 51.32780838012695, "eval/prior_ent_min": 28.594701766967773, "eval/prior_ent_std": 6.022784233093262, "eval/rep_loss_mean": 17.14840316772461, "eval/rep_loss_std": 8.82631778717041, "eval/reward_avg": 0.01572265475988388, "eval/reward_loss_mean": 0.08867253363132477, "eval/reward_loss_std": 0.6642516255378723, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.003997802734375, "eval/reward_neg_acc": 0.9980080127716064, "eval/reward_neg_loss": 0.030505159869790077, "eval/reward_pos_acc": 0.699999988079071, "eval/reward_pos_loss": 3.0086746215820312, "eval/reward_pred": 0.006536313332617283, "eval/reward_rate": 0.01953125, "replay/size": 172897.0, "replay/inserts": 21640.0, "replay/samples": 21648.0, "replay/insert_wait_avg": 2.489513037605779e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 8.238811274413611e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 34704.0, "eval_replay/inserts": 3568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1734497386778416e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4046695232391, "timer/env.step_count": 2705.0, "timer/env.step_total": 266.3664665222168, "timer/env.step_frac": 0.26625871973304416, "timer/env.step_avg": 0.09847189150544058, "timer/env.step_min": 0.022360801696777344, "timer/env.step_max": 3.576432704925537, "timer/replay._sample_count": 21648.0, "timer/replay._sample_total": 11.273428678512573, "timer/replay._sample_frac": 0.011268868510864838, "timer/replay._sample_avg": 0.0005207607482683192, "timer/replay._sample_min": 0.00037789344787597656, "timer/replay._sample_max": 0.011152267456054688, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3151.0, "timer/agent.policy_total": 53.79801797866821, "timer/agent.policy_frac": 0.05377625636664274, "timer/agent.policy_avg": 0.017073315766000702, "timer/agent.policy_min": 0.009495735168457031, "timer/agent.policy_max": 0.11669254302978516, "timer/dataset_train_count": 1353.0, "timer/dataset_train_total": 0.15632987022399902, "timer/dataset_train_frac": 0.0001562666338797687, "timer/dataset_train_avg": 0.00011554314133333261, "timer/dataset_train_min": 9.894371032714844e-05, "timer/dataset_train_max": 0.0010783672332763672, "timer/agent.train_count": 1353.0, "timer/agent.train_total": 611.6964130401611, "timer/agent.train_frac": 0.6114489782736381, "timer/agent.train_avg": 0.4521037790392913, "timer/agent.train_min": 0.43601226806640625, "timer/agent.train_max": 1.5627622604370117, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.483182430267334, "timer/agent.report_frac": 0.00048298698015634343, "timer/agent.report_avg": 0.241591215133667, "timer/agent.report_min": 0.234696626663208, "timer/agent.report_max": 0.24848580360412598, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0517578125e-05, "timer/dataset_eval_frac": 3.050523358666819e-08, "timer/dataset_eval_avg": 3.0517578125e-05, "timer/dataset_eval_min": 3.0517578125e-05, "timer/dataset_eval_max": 3.0517578125e-05, "fps": 21.630987344748743}
{"step": 173696, "time": 8327.969791412354, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 173728, "time": 8331.191612958908, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 173872, "time": 8338.014922142029, "episode/length": 165.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 173904, "time": 8340.666250228882, "episode/length": 320.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 174040, "time": 8346.65942311287, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 174352, "time": 8359.468008041382, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 174504, "time": 8366.339295864105, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 174600, "time": 8371.747172355652, "episode/length": 90.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9560439560439561, "episode/intrinsic_return": 0.0}
{"step": 174696, "time": 8377.374242067337, "episode/length": 98.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9595959595959596, "episode/intrinsic_return": 0.0}
{"step": 175032, "time": 8391.080060958862, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 175088, "time": 8394.81242966652, "episode/length": 247.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 175496, "time": 8409.938565731049, "episode/length": 181.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 175704, "time": 8418.398132801056, "episode/length": 137.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 175840, "time": 8424.649218320847, "episode/length": 185.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 175856, "time": 8426.881685733795, "episode/length": 44.0, "episode/score": 1.0999999940395355, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 176120, "time": 8437.133588790894, "episode/length": 201.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 176136, "time": 8439.199771404266, "episode/length": 36.0, "episode/score": 0.10000000894069672, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 176344, "time": 8447.832511663437, "episode/length": 205.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 176448, "time": 8453.049252986908, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 176496, "time": 8456.137838840485, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 177120, "time": 8478.546741962433, "episode/length": 427.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 177288, "time": 8485.580929517746, "episode/length": 197.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 177360, "time": 8489.779382705688, "episode/length": 152.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 177424, "time": 8493.572761058807, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 177624, "time": 8501.784061670303, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 177720, "time": 8506.508826494217, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 177768, "time": 8509.692783355713, "episode/length": 238.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 177816, "time": 8512.927975654602, "episode/length": 164.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 178240, "time": 8528.885333061218, "episode/length": 52.0, "episode/score": 3.0999999791383743, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 178536, "time": 8540.313295602798, "episode/length": 138.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 178848, "time": 8552.8285176754, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 178960, "time": 8558.153418302536, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 178976, "time": 8560.37069439888, "episode/length": 91.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 179184, "time": 8568.968882083893, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 179360, "time": 8576.530894517899, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 179440, "time": 8580.712703704834, "episode/length": 268.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 179448, "time": 8582.264191865921, "episode/length": 290.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9862542955326461, "episode/intrinsic_return": 0.0}
{"step": 180024, "time": 8624.94075512886, "eval_episode/length": 158.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 180024, "time": 8627.180319309235, "eval_episode/length": 172.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9942196531791907}
{"step": 180024, "time": 8628.774275064468, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 180024, "time": 8632.25104212761, "eval_episode/length": 215.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 180024, "time": 8634.558301210403, "eval_episode/length": 232.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9828326180257511}
{"step": 180024, "time": 8637.3539853096, "eval_episode/length": 261.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9656488549618321}
{"step": 180024, "time": 8640.598606586456, "eval_episode/length": 272.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 180024, "time": 8643.946208715439, "eval_episode/length": 160.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 180064, "time": 8645.498632192612, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 180192, "time": 8651.2756960392, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 180328, "time": 8658.648685216904, "episode/length": 170.0, "episode/score": 4.099999964237213, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 180512, "time": 8667.210369348526, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 180528, "time": 8669.975485801697, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 180600, "time": 8674.180124282837, "episode/length": 154.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 180704, "time": 8679.891671657562, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 180728, "time": 8682.000321626663, "episode/length": 160.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 181496, "time": 8709.003284931183, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 181616, "time": 8714.887996912003, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 182056, "time": 8730.98027086258, "episode/length": 192.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 182168, "time": 8736.338574886322, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 182192, "time": 8739.102821826935, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 182352, "time": 8746.242400169373, "episode/length": 252.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9920948616600791, "episode/intrinsic_return": 0.0}
{"step": 182432, "time": 8750.547732830048, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 182488, "time": 8754.255827188492, "episode/length": 53.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 182544, "time": 8758.453622341156, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 182768, "time": 8768.014761686325, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 182976, "time": 8776.5656478405, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 182992, "time": 8778.691095590591, "episode/length": 99.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.94, "episode/intrinsic_return": 0.0}
{"step": 183632, "time": 8801.719051361084, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 183632, "time": 8801.731135606766, "episode/length": 387.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9974226804123711, "episode/intrinsic_return": 0.0}
{"step": 183752, "time": 8809.046767234802, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 183888, "time": 8815.392780065536, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 183952, "time": 8819.167011022568, "episode/length": 182.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 184328, "time": 8833.162494421005, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 184400, "time": 8837.371660470963, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 185008, "time": 8859.164936542511, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 185224, "time": 8868.277174949646, "episode/length": 183.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 185464, "time": 8878.976494789124, "episode/length": 188.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 185640, "time": 8886.383733987808, "episode/length": 250.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 185680, "time": 8889.615539550781, "episode/length": 223.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 185776, "time": 8894.527589559555, "episode/length": 180.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 185832, "time": 8897.780842065811, "episode/length": 178.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 186024, "time": 8905.75124502182, "episode/length": 406.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 186448, "time": 8921.793359518051, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 186480, "time": 8924.345541000366, "episode/length": 156.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 187080, "time": 8945.662018060684, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 187176, "time": 8950.47939825058, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 187192, "time": 8952.53719997406, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 187288, "time": 8957.480379343033, "episode/length": 181.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 187640, "time": 8970.63401556015, "episode/length": 201.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 187672, "time": 8973.322876214981, "episode/length": 275.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 188008, "time": 8986.203833818436, "episode/length": 45.0, "episode/score": 0.09999997168779373, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 188024, "time": 8988.334886312485, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 188232, "time": 8996.784282684326, "episode/length": 129.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 188320, "time": 9001.421779870987, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 188600, "time": 9013.426127672195, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 188664, "time": 9017.10995054245, "episode/length": 123.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9596774193548387, "episode/intrinsic_return": 0.0}
{"step": 188824, "time": 9023.939471960068, "episode/length": 62.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9206349206349206, "episode/intrinsic_return": 0.0}
{"step": 189064, "time": 9034.003553390503, "episode/length": 235.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 189704, "time": 9057.585649967194, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 189744, "time": 9060.639986038208, "episode/length": 411.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 189808, "time": 9064.321322441101, "episode/length": 196.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 190008, "time": 9086.618419885635, "eval_episode/length": 50.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 190008, "time": 9091.196836948395, "eval_episode/length": 75.0, "eval_episode/score": 4.1000000312924385, "eval_episode/reward_rate": 0.9868421052631579}
{"step": 190008, "time": 9093.39848947525, "eval_episode/length": 142.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.958041958041958}
{"step": 190008, "time": 9094.959965467453, "eval_episode/length": 144.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.993103448275862}
{"step": 190008, "time": 9097.458420276642, "eval_episode/length": 167.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 190008, "time": 9100.058234453201, "eval_episode/length": 188.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 190008, "time": 9101.98137831688, "eval_episode/length": 198.0, "eval_episode/score": 5.099999979138374, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 190008, "time": 9107.647684335709, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9625}
{"step": 190152, "time": 9112.396956443787, "episode/length": 267.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 190160, "time": 9114.437941551208, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 190272, "time": 9119.782029628754, "episode/length": 180.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 190472, "time": 9127.733142375946, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 190800, "time": 9140.347529411316, "episode/length": 266.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 191016, "time": 9148.845232725143, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 191160, "time": 9155.218983650208, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 191168, "time": 9157.180091619492, "episode/length": 182.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 191744, "time": 9177.892392873764, "episode/length": 197.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 191968, "time": 9187.015634298325, "episode/length": 211.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 192224, "time": 9197.099491596222, "episode/length": 177.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 192416, "time": 9205.16589975357, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9717314487632509, "episode/intrinsic_return": 0.0}
{"step": 192456, "time": 9208.326501131058, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 192488, "time": 9211.404326677322, "episode/length": 251.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 192936, "time": 9227.791362762451, "episode/length": 148.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 192976, "time": 9231.020488739014, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 193408, "time": 9247.296576499939, "episode/length": 298.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 193680, "time": 9258.77879023552, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 193944, "time": 9269.60789179802, "episode/length": 246.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 194048, "time": 9274.767704248428, "episode/length": 198.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 194216, "time": 9281.899985074997, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 194512, "time": 9293.623699188232, "episode/length": 191.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 194600, "time": 9297.888537168503, "episode/length": 263.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 194664, "time": 9301.586256027222, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9893238434163701, "episode/intrinsic_return": 0.0}
{"step": 194800, "time": 9307.937371253967, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 195017, "time": 9317.572731494904, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.805975567853009, "train/action_min": 0.0, "train/action_std": 3.534681362575955, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04783431904183494, "train/actor_opt_grad_steps": 11420.0, "train/actor_opt_loss": -4.67625581164051, "train/adv_mag": 0.8225805830072473, "train/adv_max": 0.8126726362440321, "train/adv_mean": 0.003926018651421785, "train/adv_min": -0.5287096354696486, "train/adv_std": 0.08068877188143907, "train/cont_avg": 0.9945891203703704, "train/cont_loss_mean": 0.000566086035203002, "train/cont_loss_std": 0.016393523332970762, "train/cont_neg_acc": 0.9760023540920681, "train/cont_neg_loss": 0.07523868771065989, "train/cont_pos_acc": 0.9999344891972012, "train/cont_pos_loss": 0.00022213890050108, "train/cont_pred": 0.9946011658068057, "train/cont_rate": 0.9945891203703704, "train/dyn_loss_mean": 15.017456287807889, "train/dyn_loss_std": 8.839192559983996, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9883679593050921, "train/extr_critic_critic_opt_grad_steps": 11420.0, "train/extr_critic_critic_opt_loss": 15318.495421006945, "train/extr_critic_mag": 4.062983604713723, "train/extr_critic_max": 4.062983604713723, "train/extr_critic_mean": 0.7971515911596793, "train/extr_critic_min": -0.25128941006130645, "train/extr_critic_std": 1.0163451525900098, "train/extr_return_normed_mag": 1.956787935009709, "train/extr_return_normed_max": 1.956787935009709, "train/extr_return_normed_mean": 0.30068115481623897, "train/extr_return_normed_min": -0.17132819173512637, "train/extr_return_normed_std": 0.3434627830982208, "train/extr_return_rate": 0.4117510817669056, "train/extr_return_raw_mag": 5.920796493247703, "train/extr_return_raw_max": 5.920796493247703, "train/extr_return_raw_mean": 0.8092220370416288, "train/extr_return_raw_min": -0.6489623235331641, "train/extr_return_raw_std": 1.0604901945149456, "train/extr_reward_mag": 1.0092709717927155, "train/extr_reward_max": 1.0092709717927155, "train/extr_reward_mean": 0.019596903533157375, "train/extr_reward_min": -0.43293007921289517, "train/extr_reward_std": 0.126384895046552, "train/image_loss_mean": 12.54475540584988, "train/image_loss_std": 15.062387982121221, "train/model_loss_mean": 21.612364232098614, "train/model_loss_std": 18.786018194975675, "train/model_opt_grad_norm": 78.46469102082429, "train/model_opt_grad_steps": 11405.68888888889, "train/model_opt_loss": 16547.803645833334, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 768.5185185185185, "train/policy_entropy_mag": 2.529556597603692, "train/policy_entropy_max": 2.529556597603692, "train/policy_entropy_mean": 0.7393719205149898, "train/policy_entropy_min": 0.07937560705123124, "train/policy_entropy_std": 0.6746811751966123, "train/policy_logprob_mag": 7.438375250498454, "train/policy_logprob_max": -0.009455901080811466, "train/policy_logprob_mean": -0.73947614563836, "train/policy_logprob_min": -7.438375250498454, "train/policy_logprob_std": 1.1842431139062952, "train/policy_randomness_mag": 0.8928224740204987, "train/policy_randomness_max": 0.8928224740204987, "train/policy_randomness_mean": 0.26096584090480096, "train/policy_randomness_min": 0.028016105887514575, "train/policy_randomness_std": 0.23813284779036487, "train/post_ent_mag": 53.08163746021412, "train/post_ent_max": 53.08163746021412, "train/post_ent_mean": 36.779167570891204, "train/post_ent_min": 20.135494189792208, "train/post_ent_std": 5.900044621361626, "train/prior_ent_mag": 63.71077765005606, "train/prior_ent_max": 63.71077765005606, "train/prior_ent_mean": 51.92357838948568, "train/prior_ent_min": 29.733012277108653, "train/prior_ent_std": 6.177694363064236, "train/rep_loss_mean": 15.017456287807889, "train/rep_loss_std": 8.839192559983996, "train/reward_avg": 0.020285011393328507, "train/reward_loss_mean": 0.056568758203475566, "train/reward_loss_std": 0.27418912362169334, "train/reward_max_data": 1.0148148183469419, "train/reward_max_pred": 1.0056296057171292, "train/reward_neg_acc": 0.9925705702216537, "train/reward_neg_loss": 0.03355068971437437, "train/reward_pos_acc": 0.9538521077897814, "train/reward_pos_loss": 0.9489520253958525, "train/reward_pred": 0.01942753416520578, "train/reward_rate": 0.02520978009259259, "train_stats/sum_log_reward": 5.022413728822922, "train_stats/max_log_achievement_collect_drink": 5.706896551724138, "train_stats/max_log_achievement_collect_sapling": 3.5517241379310347, "train_stats/max_log_achievement_collect_stone": 0.0, "train_stats/max_log_achievement_collect_wood": 3.913793103448276, "train_stats/max_log_achievement_defeat_skeleton": 0.008620689655172414, "train_stats/max_log_achievement_defeat_zombie": 0.3620689655172414, "train_stats/max_log_achievement_eat_cow": 0.16379310344827586, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.07758620689655173, "train_stats/max_log_achievement_make_wood_sword": 0.02586206896551724, "train_stats/max_log_achievement_place_plant": 3.3620689655172415, "train_stats/max_log_achievement_place_table": 1.543103448275862, "train_stats/max_log_achievement_wake_up": 1.6982758620689655, "train_stats/mean_log_entropy": 0.638830705963332, "eval_stats/sum_log_reward": 4.7874999940395355, "eval_stats/max_log_achievement_collect_drink": 3.9375, "eval_stats/max_log_achievement_collect_sapling": 2.625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_plant": 2.4375, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 4.38716851931531e-05, "report/cont_loss_std": 0.0011185701005160809, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.001066124066710472, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.0868002542993054e-05, "report/cont_pred": 0.9970333576202393, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 12.980957984924316, "report/dyn_loss_std": 8.46714973449707, "report/image_loss_mean": 7.629794120788574, "report/image_loss_std": 9.636770248413086, "report/model_loss_mean": 15.449291229248047, "report/model_loss_std": 13.131723403930664, "report/post_ent_mag": 54.91693115234375, "report/post_ent_max": 54.91693115234375, "report/post_ent_mean": 37.781761169433594, "report/post_ent_min": 19.468605041503906, "report/post_ent_std": 6.475360870361328, "report/prior_ent_mag": 64.22669219970703, "report/prior_ent_max": 64.22669219970703, "report/prior_ent_mean": 51.661033630371094, "report/prior_ent_min": 31.498008728027344, "report/prior_ent_std": 5.454122543334961, "report/rep_loss_mean": 12.980957984924316, "report/rep_loss_std": 8.46714973449707, "report/reward_avg": 0.01005859486758709, "report/reward_loss_mean": 0.030878450721502304, "report/reward_loss_std": 0.1332072615623474, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0013608932495117, "report/reward_neg_acc": 0.997026801109314, "report/reward_neg_loss": 0.021155355498194695, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6849187612533569, "report/reward_pred": 0.01012282446026802, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0013931686989963055, "eval/cont_loss_std": 0.034705955535173416, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.041021279990673065, "eval/cont_pos_acc": 0.999018669128418, "eval/cont_pos_loss": 0.0011987225152552128, "eval/cont_pred": 0.9945255517959595, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.97912311553955, "eval/dyn_loss_std": 9.533811569213867, "eval/image_loss_mean": 14.124154090881348, "eval/image_loss_std": 18.340547561645508, "eval/model_loss_mean": 23.758695602416992, "eval/model_loss_std": 22.471874237060547, "eval/post_ent_mag": 53.492950439453125, "eval/post_ent_max": 53.492950439453125, "eval/post_ent_mean": 37.59614944458008, "eval/post_ent_min": 19.42720603942871, "eval/post_ent_std": 5.896817207336426, "eval/prior_ent_mag": 64.22669219970703, "eval/prior_ent_max": 64.22669219970703, "eval/prior_ent_mean": 51.80772399902344, "eval/prior_ent_min": 30.567527770996094, "eval/prior_ent_std": 4.851220607757568, "eval/rep_loss_mean": 15.97912311553955, "eval/rep_loss_std": 9.533811569213867, "eval/reward_avg": 0.013964843936264515, "eval/reward_loss_mean": 0.045674651861190796, "eval/reward_loss_std": 0.30117860436439514, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0000488758087158, "eval/reward_neg_acc": 0.9950249195098877, "eval/reward_neg_loss": 0.027316607534885406, "eval/reward_pos_acc": 0.9473684430122375, "eval/reward_pos_loss": 1.0167186260223389, "eval/reward_pred": 0.013175204396247864, "eval/reward_rate": 0.0185546875, "replay/size": 194513.0, "replay/inserts": 21616.0, "replay/samples": 21616.0, "replay/insert_wait_avg": 1.3245930061086208e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.300686606824354e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 39688.0, "eval_replay/inserts": 4984.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1064650350359432e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.301568984985352e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0025177001953, "timer/env.step_count": 2702.0, "timer/env.step_total": 266.16744208335876, "timer/env.step_frac": 0.26616677195522503, "timer/env.step_avg": 0.09850756553788259, "timer/env.step_min": 0.022574186325073242, "timer/env.step_max": 3.6018869876861572, "timer/replay._sample_count": 21616.0, "timer/replay._sample_total": 11.048381328582764, "timer/replay._sample_frac": 0.011048353512140969, "timer/replay._sample_avg": 0.0005111205277841767, "timer/replay._sample_min": 0.0003807544708251953, "timer/replay._sample_max": 0.028264522552490234, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3325.0, "timer/agent.policy_total": 54.24394464492798, "timer/agent.policy_frac": 0.05424380807528179, "timer/agent.policy_avg": 0.016313968314264054, "timer/agent.policy_min": 0.009399890899658203, "timer/agent.policy_max": 0.09604835510253906, "timer/dataset_train_count": 1351.0, "timer/dataset_train_total": 0.14976024627685547, "timer/dataset_train_frac": 0.00014975986922640346, "timer/dataset_train_avg": 0.0001108514036098116, "timer/dataset_train_min": 9.584426879882812e-05, "timer/dataset_train_max": 0.0010721683502197266, "timer/agent.train_count": 1351.0, "timer/agent.train_total": 607.954594373703, "timer/agent.train_frac": 0.6079530637301557, "timer/agent.train_avg": 0.4500034007207276, "timer/agent.train_min": 0.43544721603393555, "timer/agent.train_max": 1.4637157917022705, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.478163480758667, "timer/agent.report_frac": 0.0004781622768894091, "timer/agent.report_avg": 0.2390817403793335, "timer/agent.report_min": 0.23245525360107422, "timer/agent.report_max": 0.24570822715759277, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7656485545042192e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 21.6156834413158}
{"step": 195088, "time": 9319.993993282318, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 195432, "time": 9332.732412338257, "episode/length": 172.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 195736, "time": 9344.542722940445, "episode/length": 223.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 196064, "time": 9357.335205554962, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 196088, "time": 9359.502977609634, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 196288, "time": 9368.03420829773, "episode/length": 185.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 196368, "time": 9372.382080554962, "episode/length": 268.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 196552, "time": 9379.909774780273, "episode/length": 254.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 196656, "time": 9386.551589250565, "episode/length": 195.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 196952, "time": 9397.78060078621, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 197384, "time": 9413.689939498901, "episode/length": 126.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9606299212598425, "episode/intrinsic_return": 0.0}
{"step": 197456, "time": 9417.877082824707, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 197488, "time": 9420.581521749496, "episode/length": 149.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 197848, "time": 9433.963745355606, "episode/length": 148.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 198224, "time": 9448.173034191132, "episode/length": 266.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 198264, "time": 9450.83409357071, "episode/length": 315.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990506329113924, "episode/intrinsic_return": 0.0}
{"step": 198512, "time": 9460.898771047592, "episode/length": 194.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 198728, "time": 9469.366974592209, "episode/length": 271.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 198864, "time": 9475.63953924179, "episode/length": 171.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 198976, "time": 9480.926525354385, "episode/length": 189.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 199336, "time": 9494.221338033676, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 199560, "time": 9503.262562274933, "episode/length": 130.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 199656, "time": 9507.975274562836, "episode/length": 98.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 199720, "time": 9511.751701831818, "episode/length": 186.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 200096, "time": 9540.66867852211, "eval_episode/length": 40.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8780487804878049}
{"step": 200096, "time": 9548.632672071457, "eval_episode/length": 148.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9664429530201343}
{"step": 200096, "time": 9551.006144285202, "eval_episode/length": 154.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.967741935483871}
{"step": 200096, "time": 9553.358238697052, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 200096, "time": 9555.801560163498, "eval_episode/length": 172.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9710982658959537}
{"step": 200096, "time": 9558.088105916977, "eval_episode/length": 179.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 200096, "time": 9560.32787656784, "eval_episode/length": 184.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 200096, "time": 9563.86546087265, "eval_episode/length": 177.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 200232, "time": 9568.32667684555, "episode/length": 156.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 200424, "time": 9576.90527009964, "episode/length": 211.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 200456, "time": 9580.203136444092, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 200736, "time": 9591.880009412766, "episode/length": 418.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785202863961814, "episode/intrinsic_return": 0.0}
{"step": 200888, "time": 9598.838556528091, "episode/length": 193.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 200944, "time": 9602.559574365616, "episode/length": 152.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 200952, "time": 9604.218245744705, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 201240, "time": 9615.484369754791, "episode/length": 97.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9387755102040817, "episode/intrinsic_return": 0.0}
{"step": 201344, "time": 9620.665395498276, "episode/length": 222.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 201584, "time": 9630.236580133438, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9517241379310345, "episode/intrinsic_return": 0.0}
{"step": 201712, "time": 9636.061311721802, "episode/length": 184.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 202216, "time": 9654.213898658752, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 202264, "time": 9657.423705816269, "episode/length": 171.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9825581395348837, "episode/intrinsic_return": 0.0}
{"step": 202264, "time": 9657.446472883224, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 202352, "time": 9663.923339605331, "episode/length": 201.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 202712, "time": 9677.14885377884, "episode/length": 44.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 203048, "time": 9689.810980319977, "episode/length": 212.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 203096, "time": 9692.993372440338, "episode/length": 188.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 203512, "time": 9708.385334730148, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 203664, "time": 9715.22450017929, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 203728, "time": 9718.974487066269, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 203968, "time": 9728.486005783081, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 204432, "time": 9745.456593513489, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 204560, "time": 9751.157221794128, "episode/length": 230.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 204568, "time": 9752.882349014282, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 204624, "time": 9756.523522615433, "episode/length": 422.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 204976, "time": 9771.406153202057, "episode/length": 163.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 205040, "time": 9775.737144708633, "episode/length": 163.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 205352, "time": 9788.116589784622, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 205752, "time": 9803.906670331955, "episode/length": 279.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 205768, "time": 9806.006846666336, "episode/length": 149.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 206152, "time": 9820.462396144867, "episode/length": 146.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 206368, "time": 9829.68507552147, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 206840, "time": 9847.61162185669, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 207160, "time": 9859.739334106445, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 207296, "time": 9866.087566375732, "episode/length": 142.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 207400, "time": 9870.83676290512, "episode/length": 203.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 207456, "time": 9874.495698928833, "episode/length": 353.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 207840, "time": 9888.700303077698, "episode/length": 425.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9976525821596244, "episode/intrinsic_return": 0.0}
{"step": 207896, "time": 9891.86380648613, "episode/length": 416.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 208544, "time": 9915.098722696304, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 208584, "time": 9917.707135915756, "episode/length": 147.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 208800, "time": 9926.686597824097, "episode/length": 187.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 208936, "time": 9932.518337249756, "episode/length": 184.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 209160, "time": 9941.496423482895, "episode/length": 249.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 209280, "time": 9947.315583467484, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 209368, "time": 9951.52051281929, "episode/length": 374.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9893333333333333, "episode/intrinsic_return": 0.0}
{"step": 209560, "time": 9959.35313129425, "episode/length": 207.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 209944, "time": 9973.6720225811, "episode/length": 125.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 210008, "time": 9977.298283576965, "episode/length": 182.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 210064, "time": 9980.874534606934, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 210080, "time": 10001.178009986877, "eval_episode/length": 133.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9701492537313433}
{"step": 210080, "time": 10003.70681643486, "eval_episode/length": 156.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 210080, "time": 10006.932488441467, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 210080, "time": 10008.562539100647, "eval_episode/length": 198.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 210080, "time": 10011.969822883606, "eval_episode/length": 242.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9835390946502057}
{"step": 210080, "time": 10013.544182538986, "eval_episode/length": 244.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 210080, "time": 10015.390641450882, "eval_episode/length": 252.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9802371541501976}
{"step": 210080, "time": 10017.58653640747, "eval_episode/length": 266.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9962546816479401}
{"step": 210152, "time": 10019.73204612732, "episode/length": 108.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9541284403669725, "episode/intrinsic_return": 0.0}
{"step": 210760, "time": 10041.421736478806, "episode/length": 244.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 210896, "time": 10047.720705986023, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 211224, "time": 10060.0302298069, "episode/length": 231.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 211736, "time": 10078.552156448364, "episode/length": 208.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 211800, "time": 10082.330194950104, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 212056, "time": 10092.527481555939, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 212200, "time": 10098.7960460186, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 212320, "time": 10104.62870502472, "episode/length": 177.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 212648, "time": 10116.86308670044, "episode/length": 40.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 212760, "time": 10122.256729125977, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 212904, "time": 10128.6163687706, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 213368, "time": 10147.1777176857, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 213408, "time": 10151.029189109802, "episode/length": 432.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9930715935334873, "episode/intrinsic_return": 0.0}
{"step": 213528, "time": 10156.81998348236, "episode/length": 215.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 213592, "time": 10160.489786863327, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 213616, "time": 10163.146830558777, "episode/length": 506.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9842209072978304, "episode/intrinsic_return": 0.0}
{"step": 214080, "time": 10180.150399446487, "episode/length": 178.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 214208, "time": 10185.936620473862, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 214216, "time": 10187.537433624268, "episode/length": 181.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 214672, "time": 10204.37777876854, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 214944, "time": 10214.894829750061, "episode/length": 107.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 214992, "time": 10218.058861732483, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 214992, "time": 10218.06772184372, "episode/length": 182.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 215392, "time": 10234.621364831924, "episode/length": 224.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 215600, "time": 10243.257780313492, "episode/length": 273.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 215784, "time": 10250.728233575821, "episode/length": 195.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 215888, "time": 10255.938590049744, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 216080, "time": 10263.851091623306, "episode/length": 175.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 216272, "time": 10271.974086999893, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 216432, "time": 10278.84917640686, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 216528, "time": 10283.663701057434, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 217008, "time": 10301.367842674255, "episode/length": 175.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 217272, "time": 10311.695136547089, "episode/length": 172.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 217369, "time": 10318.061560869217, "train_stats/sum_log_reward": 5.136697198272845, "train_stats/max_log_achievement_collect_drink": 6.229357798165138, "train_stats/max_log_achievement_collect_sapling": 3.3486238532110093, "train_stats/max_log_achievement_collect_stone": 0.045871559633027525, "train_stats/max_log_achievement_collect_wood": 5.220183486238532, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.3119266055045872, "train_stats/max_log_achievement_eat_cow": 0.08256880733944955, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.11009174311926606, "train_stats/max_log_achievement_make_wood_sword": 0.07339449541284404, "train_stats/max_log_achievement_place_plant": 3.1926605504587156, "train_stats/max_log_achievement_place_table": 2.128440366972477, "train_stats/max_log_achievement_wake_up": 1.7064220183486238, "train_stats/mean_log_entropy": 0.6272649076006828, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.492710470295639, "train/action_min": 0.0, "train/action_std": 3.233405914238031, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04949568565800893, "train/actor_opt_grad_steps": 12790.0, "train/actor_opt_loss": 3.210622255321887, "train/adv_mag": 0.7802021906530257, "train/adv_max": 0.7675527724430715, "train/adv_mean": 0.005218618982299834, "train/adv_min": -0.5297897303704735, "train/adv_std": 0.07954396621036015, "train/cont_avg": 0.9946815984712231, "train/cont_loss_mean": 0.0004533697868294066, "train/cont_loss_std": 0.011965460232426816, "train/cont_neg_acc": 0.9862881152749919, "train/cont_neg_loss": 0.042592499105786934, "train/cont_pos_acc": 0.9999435042305816, "train/cont_pos_loss": 0.00021732862790399684, "train/cont_pred": 0.9946597124175202, "train/cont_rate": 0.9946815984712231, "train/dyn_loss_mean": 14.95814197183513, "train/dyn_loss_std": 8.933139413380795, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9569706440829545, "train/extr_critic_critic_opt_grad_steps": 12790.0, "train/extr_critic_critic_opt_loss": 15659.338565085432, "train/extr_critic_mag": 4.472057538066837, "train/extr_critic_max": 4.472057538066837, "train/extr_critic_mean": 0.84485222367074, "train/extr_critic_min": -0.2538108722769099, "train/extr_critic_std": 1.077874453376523, "train/extr_return_normed_mag": 1.9537778543911393, "train/extr_return_normed_max": 1.9537778543911393, "train/extr_return_normed_mean": 0.29527058136120116, "train/extr_return_normed_min": -0.16215387715710153, "train/extr_return_normed_std": 0.3442769728118567, "train/extr_return_rate": 0.41841419802295216, "train/extr_return_raw_mag": 6.259272987036396, "train/extr_return_raw_max": 6.259272987036396, "train/extr_return_raw_mean": 0.861839469817045, "train/extr_return_raw_min": -0.6270949094415569, "train/extr_return_raw_std": 1.1209410227459968, "train/extr_reward_mag": 1.0101428169140714, "train/extr_reward_max": 1.0101428169140714, "train/extr_reward_mean": 0.021963500799678213, "train/extr_reward_min": -0.4340016181520421, "train/extr_reward_std": 0.1345203203691853, "train/image_loss_mean": 11.375925139557543, "train/image_loss_std": 14.755431511419282, "train/model_loss_mean": 20.404699188342196, "train/model_loss_std": 18.46989036120957, "train/model_opt_grad_norm": 82.78099342014478, "train/model_opt_grad_steps": 12774.74820143885, "train/model_opt_loss": 17074.787769784172, "train/model_opt_model_opt_grad_overflow": 0.007194244604316547, "train/model_opt_model_opt_grad_scale": 831.8345323741007, "train/policy_entropy_mag": 2.5136900960112647, "train/policy_entropy_max": 2.5136900960112647, "train/policy_entropy_mean": 0.6848221612062385, "train/policy_entropy_min": 0.07937539197343717, "train/policy_entropy_std": 0.6442452754905755, "train/policy_logprob_mag": 7.438380248255009, "train/policy_logprob_max": -0.009455894120037556, "train/policy_logprob_mean": -0.6848128515181782, "train/policy_logprob_min": -7.438380248255009, "train/policy_logprob_std": 1.1618315650404787, "train/policy_randomness_mag": 0.8872222930407353, "train/policy_randomness_max": 0.8872222930407353, "train/policy_randomness_mean": 0.241712170646345, "train/policy_randomness_min": 0.028016030091604742, "train/policy_randomness_std": 0.22739030946072913, "train/post_ent_mag": 53.69071120666943, "train/post_ent_max": 53.69071120666943, "train/post_ent_mean": 37.21043107835509, "train/post_ent_min": 20.22252144573404, "train/post_ent_std": 6.09188219797697, "train/prior_ent_mag": 64.13780393531854, "train/prior_ent_max": 64.13780393531854, "train/prior_ent_mean": 52.34531119916079, "train/prior_ent_min": 31.123593529351325, "train/prior_ent_std": 5.9222941878888244, "train/rep_loss_mean": 14.95814197183513, "train/rep_loss_std": 8.933139413380795, "train/reward_avg": 0.020298448625764402, "train/reward_loss_mean": 0.053435529495100324, "train/reward_loss_std": 0.26825770757181183, "train/reward_max_data": 1.0129496433752045, "train/reward_max_pred": 1.0054917695710985, "train/reward_neg_acc": 0.993746875858993, "train/reward_neg_loss": 0.02989280935403683, "train/reward_pos_acc": 0.9428909095071203, "train/reward_pos_loss": 0.972811932615239, "train/reward_pred": 0.01921398813079158, "train/reward_rate": 0.025151753597122302, "eval_stats/sum_log_reward": 4.849999904632568, "eval_stats/max_log_achievement_collect_drink": 6.3125, "eval_stats/max_log_achievement_collect_sapling": 3.5625, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 3.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.1875, "eval_stats/max_log_achievement_place_plant": 3.4375, "eval_stats/max_log_achievement_place_table": 1.3125, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_place_furnace": 0.024390243902439025, "eval_stats/max_log_achievement_place_furnace": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.9597842765506357e-05, "report/cont_loss_std": 0.00025266833836212754, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002288688672706485, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.22402740191319e-06, "report/cont_pred": 0.9941478967666626, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.642123222351074, "report/dyn_loss_std": 9.19166374206543, "report/image_loss_mean": 11.550127029418945, "report/image_loss_std": 15.929197311401367, "report/model_loss_mean": 20.98448944091797, "report/model_loss_std": 19.729782104492188, "report/post_ent_mag": 55.27418518066406, "report/post_ent_max": 55.27418518066406, "report/post_ent_mean": 37.22650909423828, "report/post_ent_min": 20.0377197265625, "report/post_ent_std": 6.06443977355957, "report/prior_ent_mag": 64.35441589355469, "report/prior_ent_max": 64.35441589355469, "report/prior_ent_mean": 52.95289993286133, "report/prior_ent_min": 26.833892822265625, "report/prior_ent_std": 6.058302879333496, "report/rep_loss_mean": 15.642123222351074, "report/rep_loss_std": 9.19166374206543, "report/reward_avg": 0.0077148438431322575, "report/reward_loss_mean": 0.049070220440626144, "report/reward_loss_std": 0.23165152966976166, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.00062894821167, "report/reward_neg_acc": 0.9980178475379944, "report/reward_neg_loss": 0.034330837428569794, "report/reward_pos_acc": 0.9333333969116211, "report/reward_pos_loss": 1.0405397415161133, "report/reward_pred": 0.006912539713084698, "report/reward_rate": 0.0146484375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.749146228277823e-06, "eval/cont_loss_std": 8.260647155111656e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.001513933064416051, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.14718107574663e-07, "eval/cont_pred": 0.9970744848251343, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 20.746192932128906, "eval/dyn_loss_std": 9.635376930236816, "eval/image_loss_mean": 20.45711898803711, "eval/image_loss_std": 23.536144256591797, "eval/model_loss_mean": 32.978179931640625, "eval/model_loss_std": 27.448625564575195, "eval/post_ent_mag": 50.10093688964844, "eval/post_ent_max": 50.10093688964844, "eval/post_ent_mean": 35.37905502319336, "eval/post_ent_min": 20.81368637084961, "eval/post_ent_std": 5.333350658416748, "eval/prior_ent_mag": 64.35441589355469, "eval/prior_ent_max": 64.35441589355469, "eval/prior_ent_mean": 52.24616241455078, "eval/prior_ent_min": 33.28812026977539, "eval/prior_ent_std": 5.754980087280273, "eval/rep_loss_mean": 20.746192932128906, "eval/rep_loss_std": 9.635376930236816, "eval/reward_avg": 0.02363281324505806, "eval/reward_loss_mean": 0.07334554195404053, "eval/reward_loss_std": 0.5692508220672607, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026614665985107, "eval/reward_neg_acc": 0.9969940185546875, "eval/reward_neg_loss": 0.017832323908805847, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.2041993141174316, "eval/reward_pred": 0.01612854190170765, "eval/reward_rate": 0.025390625, "replay/size": 216865.0, "replay/inserts": 22352.0, "replay/samples": 22352.0, "replay/insert_wait_avg": 1.3103421961484677e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.389887964716961e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 43576.0, "eval_replay/inserts": 3888.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.142545001496994e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.0579824447631836e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4774193763733, "timer/env.step_count": 2794.0, "timer/env.step_total": 250.08131003379822, "timer/env.step_frac": 0.24996197334436712, "timer/env.step_avg": 0.08950655334065792, "timer/env.step_min": 0.02220439910888672, "timer/env.step_max": 3.376009941101074, "timer/replay._sample_count": 22352.0, "timer/replay._sample_total": 11.426851272583008, "timer/replay._sample_frac": 0.011421398475645455, "timer/replay._sample_avg": 0.0005112227663109793, "timer/replay._sample_min": 0.00037097930908203125, "timer/replay._sample_max": 0.01080942153930664, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3280.0, "timer/agent.policy_total": 54.44877529144287, "timer/agent.policy_frac": 0.05442279279564588, "timer/agent.policy_avg": 0.01660023636934234, "timer/agent.policy_min": 0.009176015853881836, "timer/agent.policy_max": 0.1355912685394287, "timer/dataset_train_count": 1397.0, "timer/dataset_train_total": 0.15000534057617188, "timer/dataset_train_frac": 0.00014993375929431228, "timer/dataset_train_avg": 0.0001073767649077823, "timer/dataset_train_min": 9.274482727050781e-05, "timer/dataset_train_max": 0.00031685829162597656, "timer/agent.train_count": 1397.0, "timer/agent.train_total": 627.777749300003, "timer/agent.train_frac": 0.6274781790590688, "timer/agent.train_avg": 0.44937562584109025, "timer/agent.train_min": 0.43529486656188965, "timer/agent.train_max": 1.530648946762085, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48116493225097656, "timer/agent.report_frac": 0.00048093532440832165, "timer/agent.report_avg": 0.24058246612548828, "timer/agent.report_min": 0.23392844200134277, "timer/agent.report_max": 0.2472364902496338, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.337860107421875e-05, "timer/dataset_eval_frac": 3.33626730876391e-08, "timer/dataset_eval_avg": 3.337860107421875e-05, "timer/dataset_eval_min": 3.337860107421875e-05, "timer/dataset_eval_max": 3.337860107421875e-05, "fps": 22.341067583208318}
{"step": 217520, "time": 10323.170140743256, "episode/length": 265.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9962406015037594, "episode/intrinsic_return": 0.0}
{"step": 217720, "time": 10331.307460784912, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 217728, "time": 10333.405111551285, "episode/length": 242.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 217728, "time": 10333.414870500565, "episode/length": 181.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 217888, "time": 10342.163152217865, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 218144, "time": 10352.465836763382, "episode/length": 201.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 218184, "time": 10355.187138080597, "episode/length": 146.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 218800, "time": 10377.62506890297, "episode/length": 190.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 219048, "time": 10387.174459218979, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 219248, "time": 10395.731939315796, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 219360, "time": 10401.102301120758, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 219568, "time": 10409.641139745712, "episode/length": 177.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 219632, "time": 10413.427661180496, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 219904, "time": 10424.119074106216, "episode/length": 271.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 220064, "time": 10445.662791252136, "eval_episode/length": 51.0, "eval_episode/score": 3.100000023841858, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 220064, "time": 10445.672947406769, "eval_episode/length": 51.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 220064, "time": 10450.771753549576, "eval_episode/length": 44.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9111111111111111}
{"step": 220064, "time": 10454.673653364182, "eval_episode/length": 155.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 220064, "time": 10456.508214235306, "eval_episode/length": 162.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 220064, "time": 10456.517364501953, "eval_episode/length": 162.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 220064, "time": 10459.882382392883, "eval_episode/length": 166.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9640718562874252}
{"step": 220064, "time": 10461.688596725464, "eval_episode/length": 171.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 220216, "time": 10466.463212966919, "episode/length": 310.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9935691318327974, "episode/intrinsic_return": 0.0}
{"step": 220776, "time": 10486.621644973755, "episode/length": 215.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 220896, "time": 10492.40129327774, "episode/length": 191.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 220976, "time": 10496.703981876373, "episode/length": 215.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 220992, "time": 10498.863090515137, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 221200, "time": 10508.993284702301, "episode/length": 195.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 221208, "time": 10510.60150194168, "episode/length": 300.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 221304, "time": 10515.430393695831, "episode/length": 65.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 221352, "time": 10518.822504997253, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 221608, "time": 10528.85979962349, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 222240, "time": 10551.470272302628, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 222392, "time": 10557.912195205688, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 222608, "time": 10566.937958717346, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 222728, "time": 10572.341455221176, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 223128, "time": 10587.105558395386, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 223176, "time": 10590.237739801407, "episode/length": 233.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 223488, "time": 10602.433034181595, "episode/length": 311.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9871794871794872, "episode/intrinsic_return": 0.0}
{"step": 223528, "time": 10605.173226118088, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 223608, "time": 10609.326846837997, "episode/length": 249.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 223816, "time": 10617.728340864182, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 224040, "time": 10627.456440925598, "episode/length": 107.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 224168, "time": 10633.351828575134, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 224320, "time": 10640.150276184082, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 224680, "time": 10653.327031850815, "episode/length": 193.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 224920, "time": 10662.84907579422, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 224984, "time": 10666.489862442017, "episode/length": 171.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 225136, "time": 10673.265169858932, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 225264, "time": 10679.667717933655, "episode/length": 216.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 225512, "time": 10689.810843229294, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 225536, "time": 10692.826181650162, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 225800, "time": 10703.604638814926, "episode/length": 184.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 225832, "time": 10706.760027647018, "episode/length": 143.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 226144, "time": 10719.52552819252, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 226496, "time": 10732.714844226837, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 226624, "time": 10738.486010313034, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 226688, "time": 10742.189158916473, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 226944, "time": 10752.381005048752, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 227032, "time": 10757.093539953232, "episode/length": 189.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 227136, "time": 10762.778515815735, "episode/length": 166.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 227160, "time": 10765.492370605469, "episode/length": 165.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 227712, "time": 10786.063570737839, "episode/length": 195.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 227944, "time": 10795.160341262817, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 228136, "time": 10803.782695531845, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 228304, "time": 10811.115247488022, "episode/length": 225.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 228360, "time": 10814.308748483658, "episode/length": 176.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 228488, "time": 10819.965292930603, "episode/length": 224.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 228536, "time": 10823.039137125015, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 228656, "time": 10828.812308311462, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 229096, "time": 10844.86623620987, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 229336, "time": 10854.32186794281, "episode/length": 173.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 229680, "time": 10868.760334014893, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 229944, "time": 10879.084517478943, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 229952, "time": 10881.141838788986, "episode/length": 176.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 230048, "time": 10900.959679365158, "eval_episode/length": 42.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 230048, "time": 10907.815472364426, "eval_episode/length": 176.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 230048, "time": 10909.58675289154, "eval_episode/length": 181.0, "eval_episode/score": 3.099999964237213, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 230048, "time": 10911.378880739212, "eval_episode/length": 186.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9946524064171123}
{"step": 230048, "time": 10912.920937299728, "eval_episode/length": 187.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 230048, "time": 10914.762817621231, "eval_episode/length": 194.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 230048, "time": 10916.369277238846, "eval_episode/length": 195.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 230048, "time": 10917.918148994446, "eval_episode/length": 196.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 230096, "time": 10919.510386705399, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 230192, "time": 10924.232315778732, "episode/length": 235.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 230344, "time": 10930.574050664902, "episode/length": 231.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 230616, "time": 10941.13152718544, "episode/length": 159.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 230680, "time": 10944.907241821289, "episode/length": 197.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 230824, "time": 10951.736399888992, "episode/length": 17.0, "episode/score": 1.100000023841858, "episode/reward_rate": 0.9444444444444444, "episode/intrinsic_return": 0.0}
{"step": 231184, "time": 10966.430213212967, "episode/length": 187.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 231272, "time": 10971.204889059067, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 231672, "time": 10986.628205537796, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 231704, "time": 10989.219108104706, "episode/length": 188.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 231840, "time": 10995.547766685486, "episode/length": 152.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 232320, "time": 11012.898338794708, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 232488, "time": 11019.920597791672, "episode/length": 162.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9570552147239264, "episode/intrinsic_return": 0.0}
{"step": 232576, "time": 11024.583224058151, "episode/length": 91.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9891304347826086, "episode/intrinsic_return": 0.0}
{"step": 232728, "time": 11030.891392469406, "episode/length": 297.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 232832, "time": 11036.090570688248, "episode/length": 144.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.993103448275862, "episode/intrinsic_return": 0.0}
{"step": 232848, "time": 11038.140061378479, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 233368, "time": 11056.475545167923, "episode/length": 426.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 233416, "time": 11059.543865203857, "episode/length": 213.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 233688, "time": 11070.028000831604, "episode/length": 170.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 233760, "time": 11074.178243160248, "episode/length": 42.0, "episode/score": -0.8999999910593033, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 233912, "time": 11080.721274375916, "episode/length": 132.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 233968, "time": 11084.336533546448, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 234136, "time": 11091.174864292145, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 234368, "time": 11100.61892580986, "episode/length": 75.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9605263157894737, "episode/intrinsic_return": 0.0}
{"step": 234408, "time": 11103.399642705917, "episode/length": 239.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 234640, "time": 11113.038277864456, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 234728, "time": 11117.32854938507, "episode/length": 236.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 235544, "time": 11146.023337841034, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9593908629441624, "episode/intrinsic_return": 0.0}
{"step": 235568, "time": 11148.576249837875, "episode/length": 234.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 235592, "time": 11150.7782599926, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9835164835164835, "episode/intrinsic_return": 0.0}
{"step": 235736, "time": 11157.118878364563, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 235784, "time": 11160.32792520523, "episode/length": 171.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 236000, "time": 11170.13960981369, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 236032, "time": 11172.853716611862, "episode/length": 57.0, "episode/score": 1.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 236232, "time": 11180.749608516693, "episode/length": 198.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.964824120603015, "episode/intrinsic_return": 0.0}
{"step": 236304, "time": 11184.842476844788, "episode/length": 70.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9295774647887324, "episode/intrinsic_return": 0.0}
{"step": 236536, "time": 11193.815207481384, "episode/length": 327.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 237032, "time": 11211.788593053818, "episode/length": 128.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 237080, "time": 11214.94457578659, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 237152, "time": 11219.084481716156, "episode/length": 170.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 237512, "time": 11232.613013267517, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 237688, "time": 11241.937890529633, "episode/length": 206.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 237776, "time": 11246.64232969284, "episode/length": 154.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 237904, "time": 11252.403252840042, "episode/length": 294.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9898305084745763, "episode/intrinsic_return": 0.0}
{"step": 238048, "time": 11258.740389585495, "episode/length": 226.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 238272, "time": 11267.685270309448, "episode/length": 154.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 238552, "time": 11278.229820013046, "episode/length": 183.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 238744, "time": 11286.200762748718, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 239128, "time": 11300.57206749916, "episode/length": 246.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 239248, "time": 11306.360703229904, "episode/length": 194.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 239344, "time": 11311.102539777756, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 239376, "time": 11313.726662874222, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 239449, "time": 11318.388225078583, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.765121238819067, "train/action_min": 0.0, "train/action_std": 3.4730178342349287, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04612356513414694, "train/actor_opt_grad_steps": 14175.0, "train/actor_opt_loss": -4.547075568333916, "train/adv_mag": 0.7485246105470519, "train/adv_max": 0.7387255991714589, "train/adv_mean": 0.004291364150602654, "train/adv_min": -0.49617403184158215, "train/adv_std": 0.07554718231161435, "train/cont_avg": 0.9945935235507246, "train/cont_loss_mean": 0.00046784142801637216, "train/cont_loss_std": 0.013538734332133321, "train/cont_neg_acc": 0.9871721911257592, "train/cont_neg_loss": 0.045552354448232836, "train/cont_pos_acc": 0.9999359198238539, "train/cont_pos_loss": 0.0001561809146603862, "train/cont_pred": 0.9945965465428173, "train/cont_rate": 0.9945935235507246, "train/dyn_loss_mean": 15.041579122128693, "train/dyn_loss_std": 8.93952427048614, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.905556074951006, "train/extr_critic_critic_opt_grad_steps": 14175.0, "train/extr_critic_critic_opt_loss": 15547.322435461956, "train/extr_critic_mag": 4.768816999767138, "train/extr_critic_max": 4.768816999767138, "train/extr_critic_mean": 0.9331249240515889, "train/extr_critic_min": -0.25833527679028717, "train/extr_critic_std": 1.1360926697219627, "train/extr_return_normed_mag": 1.8892283629680025, "train/extr_return_normed_max": 1.8892283629680025, "train/extr_return_normed_mean": 0.2937034552080044, "train/extr_return_normed_min": -0.17251801482685233, "train/extr_return_normed_std": 0.34207808064377826, "train/extr_return_rate": 0.43750144033760263, "train/extr_return_raw_mag": 6.448565548744755, "train/extr_return_raw_max": 6.448565548744755, "train/extr_return_raw_mean": 0.9478466962126718, "train/extr_return_raw_min": -0.6598483928735706, "train/extr_return_raw_std": 1.179541193920633, "train/extr_reward_mag": 1.0114569024763245, "train/extr_reward_max": 1.0114569024763245, "train/extr_reward_mean": 0.023339585529343374, "train/extr_reward_min": -0.4681419548781022, "train/extr_reward_std": 0.13912909040632454, "train/image_loss_mean": 10.828831451526586, "train/image_loss_std": 14.139395271522412, "train/model_loss_mean": 19.90881411234538, "train/model_loss_std": 17.828005106552787, "train/model_opt_grad_norm": 77.20646999193275, "train/model_opt_grad_steps": 14158.492753623188, "train/model_opt_loss": 12607.690259850544, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 634.0579710144928, "train/policy_entropy_mag": 2.5052407288896865, "train/policy_entropy_max": 2.5052407288896865, "train/policy_entropy_mean": 0.7587754752324976, "train/policy_entropy_min": 0.07937530870886816, "train/policy_entropy_std": 0.7097884317239126, "train/policy_logprob_mag": 7.438380894453629, "train/policy_logprob_max": -0.009455894120037556, "train/policy_logprob_mean": -0.7583680161531421, "train/policy_logprob_min": -7.438380894453629, "train/policy_logprob_std": 1.1981721770936165, "train/policy_randomness_mag": 0.8842400381530541, "train/policy_randomness_max": 0.8842400381530541, "train/policy_randomness_mean": 0.26781444543081784, "train/policy_randomness_min": 0.028016000743145527, "train/policy_randomness_std": 0.2505241669174554, "train/post_ent_mag": 54.51164566261181, "train/post_ent_max": 54.51164566261181, "train/post_ent_mean": 37.55419526583906, "train/post_ent_min": 20.52385529227879, "train/post_ent_std": 6.333328706630762, "train/prior_ent_mag": 64.28276302503502, "train/prior_ent_max": 64.28276302503502, "train/prior_ent_mean": 52.74174236905748, "train/prior_ent_min": 32.21891896621041, "train/prior_ent_std": 5.741423786550328, "train/rep_loss_mean": 15.041579122128693, "train/rep_loss_std": 8.93952427048614, "train/reward_avg": 0.02117088410085526, "train/reward_loss_mean": 0.054567324699483055, "train/reward_loss_std": 0.2698336077341135, "train/reward_max_data": 1.015942032786383, "train/reward_max_pred": 1.0085992182510486, "train/reward_neg_acc": 0.9934601170429285, "train/reward_neg_loss": 0.03134108016240424, "train/reward_pos_acc": 0.956542646539384, "train/reward_pos_loss": 0.9335912431495778, "train/reward_pred": 0.02032356078574515, "train/reward_rate": 0.025907212409420288, "train_stats/sum_log_reward": 5.083333292603493, "train_stats/max_log_achievement_collect_drink": 6.525, "train_stats/max_log_achievement_collect_sapling": 2.85, "train_stats/max_log_achievement_collect_stone": 0.058333333333333334, "train_stats/max_log_achievement_collect_wood": 5.616666666666666, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "train_stats/max_log_achievement_eat_cow": 0.041666666666666664, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.21666666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.058333333333333334, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.55, "train_stats/max_log_achievement_place_table": 2.2916666666666665, "train_stats/max_log_achievement_wake_up": 1.7333333333333334, "train_stats/mean_log_entropy": 0.6594737399369478, "eval_stats/sum_log_reward": 4.724999949336052, "eval_stats/max_log_achievement_collect_drink": 4.5625, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 4.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.4375, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_collect_coal": 0.2222222222222222, "train_stats/max_log_achievement_place_stone": 0.125, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.0117229723837227e-05, "report/cont_loss_std": 0.0002195408014813438, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006465039914473891, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.580581556481775e-05, "report/cont_pred": 0.9931528568267822, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 15.73630142211914, "report/dyn_loss_std": 8.875200271606445, "report/image_loss_mean": 9.162109375, "report/image_loss_std": 11.02542781829834, "report/model_loss_mean": 18.650327682495117, "report/model_loss_std": 14.568791389465332, "report/post_ent_mag": 56.15055465698242, "report/post_ent_max": 56.15055465698242, "report/post_ent_mean": 37.56593704223633, "report/post_ent_min": 21.36109161376953, "report/post_ent_std": 6.6758341789245605, "report/prior_ent_mag": 64.03326416015625, "report/prior_ent_max": 64.03326416015625, "report/prior_ent_mean": 53.45545959472656, "report/prior_ent_min": 33.47793960571289, "report/prior_ent_std": 5.365146636962891, "report/rep_loss_mean": 15.73630142211914, "report/rep_loss_std": 8.875200271606445, "report/reward_avg": 0.02304687350988388, "report/reward_loss_mean": 0.046417027711868286, "report/reward_loss_std": 0.18693365156650543, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0010123252868652, "report/reward_neg_acc": 0.9949697852134705, "report/reward_neg_loss": 0.023324714973568916, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8115424513816833, "report/reward_pred": 0.02063668891787529, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 0.00014785218809265643, "eval/cont_loss_std": 0.0024886284954845905, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0006058127619326115, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 0.00014470003952737898, "eval/cont_pred": 0.9930275678634644, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.379281997680664, "eval/dyn_loss_std": 9.07712459564209, "eval/image_loss_mean": 19.852264404296875, "eval/image_loss_std": 20.555316925048828, "eval/model_loss_mean": 31.55051612854004, "eval/model_loss_std": 24.226858139038086, "eval/post_ent_mag": 51.99889373779297, "eval/post_ent_max": 51.99889373779297, "eval/post_ent_mean": 37.74639129638672, "eval/post_ent_min": 19.992534637451172, "eval/post_ent_std": 5.4742536544799805, "eval/prior_ent_mag": 64.03326416015625, "eval/prior_ent_max": 64.03326416015625, "eval/prior_ent_mean": 54.167869567871094, "eval/prior_ent_min": 30.376995086669922, "eval/prior_ent_std": 5.470363616943359, "eval/rep_loss_mean": 19.379281997680664, "eval/rep_loss_std": 9.07712459564209, "eval/reward_avg": 0.00937500037252903, "eval/reward_loss_mean": 0.07053598761558533, "eval/reward_loss_std": 0.5470117926597595, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9987865686416626, "eval/reward_neg_acc": 0.9960356950759888, "eval/reward_neg_loss": 0.039764367043972015, "eval/reward_pos_acc": 0.8000000715255737, "eval/reward_pos_loss": 2.1404404640197754, "eval/reward_pred": 0.007262886967509985, "eval/reward_rate": 0.0146484375, "replay/size": 238945.0, "replay/inserts": 22080.0, "replay/samples": 22080.0, "replay/insert_wait_avg": 1.299877961476644e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.305888162142988e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 46528.0, "eval_replay/inserts": 2952.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1661672979835573e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3147876262665, "timer/env.step_count": 2760.0, "timer/env.step_total": 270.59214782714844, "timer/env.step_frac": 0.2705069955721238, "timer/env.step_avg": 0.09804063327070596, "timer/env.step_min": 0.022324800491333008, "timer/env.step_max": 3.4028639793395996, "timer/replay._sample_count": 22080.0, "timer/replay._sample_total": 11.446696758270264, "timer/replay._sample_frac": 0.01144309461367968, "timer/replay._sample_avg": 0.0005184192372405011, "timer/replay._sample_min": 0.0003762245178222656, "timer/replay._sample_max": 0.01091313362121582, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3129.0, "timer/agent.policy_total": 50.27280855178833, "timer/agent.policy_frac": 0.050256988273746334, "timer/agent.policy_avg": 0.01606673331792532, "timer/agent.policy_min": 0.009303569793701172, "timer/agent.policy_max": 0.09732842445373535, "timer/dataset_train_count": 1380.0, "timer/dataset_train_total": 0.15174245834350586, "timer/dataset_train_frac": 0.00015169470672685812, "timer/dataset_train_avg": 0.00010995830314746802, "timer/dataset_train_min": 9.5367431640625e-05, "timer/dataset_train_max": 0.0010728836059570312, "timer/agent.train_count": 1380.0, "timer/agent.train_total": 617.4496119022369, "timer/agent.train_frac": 0.6172553075691668, "timer/agent.train_avg": 0.44742725500162095, "timer/agent.train_min": 0.4348111152648926, "timer/agent.train_max": 1.5038506984710693, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4682767391204834, "timer/agent.report_frac": 0.0004681293777848649, "timer/agent.report_avg": 0.2341383695602417, "timer/agent.report_min": 0.2231295108795166, "timer/agent.report_max": 0.2451472282409668, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.489059448242188e-05, "timer/dataset_eval_frac": 9.486073349729837e-08, "timer/dataset_eval_avg": 9.489059448242188e-05, "timer/dataset_eval_min": 9.489059448242188e-05, "timer/dataset_eval_max": 9.489059448242188e-05, "fps": 22.072774247978113}
{"step": 239472, "time": 11319.112707853317, "episode/length": 149.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 239688, "time": 11328.083104372025, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 239936, "time": 11338.079156160355, "episode/length": 172.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 239968, "time": 11340.699650287628, "episode/length": 152.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 240032, "time": 11359.711119890213, "eval_episode/length": 57.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 240032, "time": 11364.88894867897, "eval_episode/length": 148.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9932885906040269}
{"step": 240032, "time": 11367.076615810394, "eval_episode/length": 163.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 240032, "time": 11369.082264184952, "eval_episode/length": 171.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 240032, "time": 11370.914850950241, "eval_episode/length": 178.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 240032, "time": 11373.123248577118, "eval_episode/length": 194.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 240032, "time": 11375.197122812271, "eval_episode/length": 147.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.972972972972973}
{"step": 240032, "time": 11376.849017858505, "eval_episode/length": 206.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.966183574879227}
{"step": 240336, "time": 11387.031774759293, "episode/length": 45.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 240352, "time": 11389.16593837738, "episode/length": 137.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 240488, "time": 11395.02718949318, "episode/length": 126.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.952755905511811, "episode/intrinsic_return": 0.0}
{"step": 240512, "time": 11397.74464583397, "episode/length": 141.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 240672, "time": 11404.591563224792, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 240896, "time": 11413.672929763794, "episode/length": 193.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 241200, "time": 11425.189361572266, "episode/length": 157.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 241736, "time": 11444.450042247772, "episode/length": 255.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 241776, "time": 11447.504464149475, "episode/length": 177.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 241792, "time": 11449.591709136963, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 241976, "time": 11457.055363178253, "episode/length": 182.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 242464, "time": 11475.176712989807, "episode/length": 195.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 242496, "time": 11477.878630161285, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 242560, "time": 11481.6128616333, "episode/length": 277.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9820143884892086, "episode/intrinsic_return": 0.0}
{"step": 242912, "time": 11494.852490663528, "episode/length": 279.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 243056, "time": 11501.265754461288, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 243200, "time": 11507.577104091644, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 243352, "time": 11513.946660518646, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 243600, "time": 11523.977739334106, "episode/length": 225.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 243896, "time": 11535.235497951508, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 243912, "time": 11537.411220788956, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 244264, "time": 11550.614093542099, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 244472, "time": 11559.244655370712, "episode/length": 246.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 244568, "time": 11564.01448726654, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 244624, "time": 11567.645496845245, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 244752, "time": 11573.479492664337, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 245000, "time": 11583.232857465744, "episode/length": 242.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 245104, "time": 11589.255163192749, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 245424, "time": 11601.587026119232, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 245448, "time": 11603.776883363724, "episode/length": 121.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 245792, "time": 11618.249898672104, "episode/length": 190.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 246024, "time": 11627.4898583889, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 246080, "time": 11631.111526966095, "episode/length": 165.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 246272, "time": 11638.94539141655, "episode/length": 212.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 246440, "time": 11645.829470396042, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 246520, "time": 11650.032687187195, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 247080, "time": 11670.035384654999, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 247120, "time": 11673.154327869415, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 247200, "time": 11677.28087568283, "episode/length": 139.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 247456, "time": 11687.55565237999, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 247520, "time": 11691.32752752304, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 247600, "time": 11695.657576799393, "episode/length": 165.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 248096, "time": 11713.872019767761, "episode/length": 206.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 248136, "time": 11716.489056110382, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 248576, "time": 11732.829819917679, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 248680, "time": 11737.638125419617, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 248712, "time": 11740.380580425262, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.959731543624161, "episode/intrinsic_return": 0.0}
{"step": 248792, "time": 11744.552897453308, "episode/length": 208.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 248872, "time": 11748.782010316849, "episode/length": 176.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 248920, "time": 11751.97335934639, "episode/length": 164.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 249576, "time": 11775.824726581573, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 250016, "time": 11817.701406478882, "eval_episode/length": 125.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 250016, "time": 11821.529866933823, "eval_episode/length": 165.0, "eval_episode/score": 2.100000023841858, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 250016, "time": 11824.489842176437, "eval_episode/length": 181.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 250016, "time": 11826.965268850327, "eval_episode/length": 185.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 250016, "time": 11829.533337593079, "eval_episode/length": 193.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 250016, "time": 11832.823464155197, "eval_episode/length": 218.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9817351598173516}
{"step": 250016, "time": 11835.502755403519, "eval_episode/length": 232.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9742489270386266}
{"step": 250016, "time": 11837.71247267723, "eval_episode/length": 236.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 250056, "time": 11838.894174337387, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 250400, "time": 11852.727727890015, "episode/length": 200.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 250488, "time": 11857.11099267006, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 250640, "time": 11863.969592571259, "episode/length": 132.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 251328, "time": 11888.682582855225, "episode/length": 85.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 251360, "time": 11891.47893333435, "episode/length": 310.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9807073954983923, "episode/intrinsic_return": 0.0}
{"step": 251496, "time": 11897.319989204407, "episode/length": 347.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 251544, "time": 11900.552227973938, "episode/length": 185.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 251832, "time": 11911.636654138565, "episode/length": 58.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9152542372881356, "episode/intrinsic_return": 0.0}
{"step": 251896, "time": 11915.35609126091, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 251944, "time": 11918.538414239883, "episode/length": 49.0, "episode/score": 2.0999999791383743, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 251976, "time": 11921.309206962585, "episode/length": 484.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9979381443298969, "episode/intrinsic_return": 0.0}
{"step": 252032, "time": 11924.911051511765, "episode/length": 431.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 252752, "time": 11950.407148838043, "episode/length": 282.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 253008, "time": 11960.65385723114, "episode/length": 209.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 253024, "time": 11963.116755247116, "episode/length": 190.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 253520, "time": 11982.048319101334, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 253600, "time": 11986.296043634415, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 253664, "time": 11989.853961706161, "episode/length": 220.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 253824, "time": 11996.730281829834, "episode/length": 230.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 253856, "time": 11999.395760774612, "episode/length": 137.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 253896, "time": 12001.918308734894, "episode/length": 46.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 253944, "time": 12005.100789308548, "episode/length": 249.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 254496, "time": 12026.88485789299, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 254728, "time": 12035.93918800354, "episode/length": 214.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 254760, "time": 12038.638312578201, "episode/length": 107.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9537037037037037, "episode/intrinsic_return": 0.0}
{"step": 254984, "time": 12047.899368524551, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 255040, "time": 12051.782197237015, "episode/length": 147.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 255168, "time": 12057.599999904633, "episode/length": 54.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 255288, "time": 12062.94215631485, "episode/length": 182.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 255536, "time": 12073.112632274628, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 255800, "time": 12083.207597732544, "episode/length": 129.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 256016, "time": 12092.117747068405, "episode/length": 189.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 256616, "time": 12113.510403633118, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 256792, "time": 12120.91785645485, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 256896, "time": 12126.096848964691, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 257048, "time": 12132.617237567902, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 257240, "time": 12140.641476154327, "episode/length": 55.0, "episode/score": 1.0999999791383743, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 257344, "time": 12145.858528375626, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 257536, "time": 12154.520631551743, "episode/length": 318.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 257648, "time": 12160.472575902939, "episode/length": 230.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 257832, "time": 12168.575938463211, "episode/length": 528.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9867674858223062, "episode/intrinsic_return": 0.0}
{"step": 258472, "time": 12192.216131687164, "episode/length": 196.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 258664, "time": 12200.287618637085, "episode/length": 201.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 258728, "time": 12204.014294147491, "episode/length": 185.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 258816, "time": 12208.726282119751, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 258928, "time": 12214.01498246193, "episode/length": 288.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 258936, "time": 12215.550672769547, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 259616, "time": 12240.082650661469, "episode/length": 85.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 259896, "time": 12250.78793501854, "episode/length": 280.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 259968, "time": 12254.98102092743, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 260000, "time": 12271.701606988907, "eval_episode/length": 29.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8333333333333334}
{"step": 260000, "time": 12278.140611171722, "eval_episode/length": 150.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9933774834437086}
{"step": 260000, "time": 12280.578120946884, "eval_episode/length": 169.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 260000, "time": 12282.498018980026, "eval_episode/length": 177.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 260000, "time": 12284.484850406647, "eval_episode/length": 185.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 260000, "time": 12286.358999729156, "eval_episode/length": 191.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 260000, "time": 12288.056862831116, "eval_episode/length": 193.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.979381443298969}
{"step": 260000, "time": 12290.878979921341, "eval_episode/length": 225.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.995575221238938}
{"step": 260160, "time": 12296.198848724365, "episode/length": 186.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 260224, "time": 12299.828810691833, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 260232, "time": 12301.479402065277, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 260416, "time": 12309.308997154236, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 260617, "time": 12318.449919939041, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.922610634251645, "train/action_min": 0.0, "train/action_std": 3.6336557829290403, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044533945129890194, "train/actor_opt_grad_steps": 15530.0, "train/actor_opt_loss": -5.407518634446581, "train/adv_mag": 0.7078045073308443, "train/adv_max": 0.6949371180139986, "train/adv_mean": 0.0036611355777372103, "train/adv_min": -0.4847828985605025, "train/adv_std": 0.07305144647458442, "train/cont_avg": 0.9945004111842105, "train/cont_loss_mean": 0.0005440911572770716, "train/cont_loss_std": 0.016505564255115825, "train/cont_neg_acc": 0.9812059931288984, "train/cont_neg_loss": 0.07057472933355116, "train/cont_pos_acc": 0.9999556873077736, "train/cont_pos_loss": 0.00017700303203230136, "train/cont_pred": 0.9945158774691417, "train/cont_rate": 0.9945004111842105, "train/dyn_loss_mean": 15.068386343188752, "train/dyn_loss_std": 8.956170723850565, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8774247604205196, "train/extr_critic_critic_opt_grad_steps": 15530.0, "train/extr_critic_critic_opt_loss": 15514.1943359375, "train/extr_critic_mag": 4.9878757663239215, "train/extr_critic_max": 4.9878757663239215, "train/extr_critic_mean": 0.9636716981579486, "train/extr_critic_min": -0.25704120872612285, "train/extr_critic_std": 1.1967580632159585, "train/extr_return_normed_mag": 1.86734682366364, "train/extr_return_normed_max": 1.86734682366364, "train/extr_return_normed_mean": 0.2925816220896585, "train/extr_return_normed_min": -0.1587415189671337, "train/extr_return_normed_std": 0.34397218370796145, "train/extr_return_rate": 0.4379503694467975, "train/extr_return_raw_mag": 6.637140005154717, "train/extr_return_raw_max": 6.637140005154717, "train/extr_return_raw_mean": 0.976814471689382, "train/extr_return_raw_min": -0.6456105520850733, "train/extr_return_raw_std": 1.2364962679102904, "train/extr_reward_mag": 1.0119115392068274, "train/extr_reward_max": 1.0119115392068274, "train/extr_reward_mean": 0.024118371482910517, "train/extr_reward_min": -0.43953531935699003, "train/extr_reward_std": 0.14219289127373158, "train/image_loss_mean": 10.219404826486917, "train/image_loss_std": 13.990492763375878, "train/model_loss_mean": 19.314965721359826, "train/model_loss_std": 17.653332315889518, "train/model_opt_grad_norm": 71.13952440204042, "train/model_opt_grad_steps": 15512.368421052632, "train/model_opt_loss": 13935.008950599155, "train/model_opt_model_opt_grad_overflow": 0.007518796992481203, "train/model_opt_model_opt_grad_scale": 714.2857142857143, "train/policy_entropy_mag": 2.5223400987180553, "train/policy_entropy_max": 2.5223400987180553, "train/policy_entropy_mean": 0.7562856636101142, "train/policy_entropy_min": 0.07937527139832203, "train/policy_entropy_std": 0.7128129973447412, "train/policy_logprob_mag": 7.438381962310102, "train/policy_logprob_max": -0.009455889673497444, "train/policy_logprob_mean": -0.7556065773605404, "train/policy_logprob_min": -7.438381962310102, "train/policy_logprob_std": 1.206229355102195, "train/policy_randomness_mag": 0.8902753663242311, "train/policy_randomness_max": 0.8902753663242311, "train/policy_randomness_mean": 0.2669356513516347, "train/policy_randomness_min": 0.028015987499427974, "train/policy_randomness_std": 0.25159170674650294, "train/post_ent_mag": 55.21517488293182, "train/post_ent_max": 55.21517488293182, "train/post_ent_mean": 37.90316901529642, "train/post_ent_min": 20.517986139856784, "train/post_ent_std": 6.535348096288237, "train/prior_ent_mag": 64.58843440579292, "train/prior_ent_max": 64.58843440579292, "train/prior_ent_mean": 53.08219069287293, "train/prior_ent_min": 32.77050809931934, "train/prior_ent_std": 5.576843297571168, "train/rep_loss_mean": 15.068386343188752, "train/rep_loss_std": 8.956170723850565, "train/reward_avg": 0.022140801120969587, "train/reward_loss_mean": 0.053984997976095156, "train/reward_loss_std": 0.25854729093555223, "train/reward_max_data": 1.0075187987851022, "train/reward_max_pred": 1.0050421971127503, "train/reward_neg_acc": 0.9933621309753647, "train/reward_neg_loss": 0.030233733075901978, "train/reward_pos_acc": 0.9525541909655234, "train/reward_pos_loss": 0.9132740981596753, "train/reward_pred": 0.02122964661680442, "train/reward_rate": 0.026976621240601503, "train_stats/sum_log_reward": 5.318181766163219, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.045454545454546, "train_stats/max_log_achievement_collect_sapling": 2.809090909090909, "train_stats/max_log_achievement_collect_stone": 0.14545454545454545, "train_stats/max_log_achievement_collect_wood": 5.654545454545454, "train_stats/max_log_achievement_defeat_skeleton": 0.00909090909090909, "train_stats/max_log_achievement_defeat_zombie": 0.2727272727272727, "train_stats/max_log_achievement_eat_cow": 0.11818181818181818, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.4090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.01818181818181818, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.7, "train_stats/max_log_achievement_place_stone": 0.00909090909090909, "train_stats/max_log_achievement_place_table": 2.090909090909091, "train_stats/max_log_achievement_wake_up": 1.5545454545454545, "train_stats/mean_log_entropy": 0.6672888904809952, "eval_stats/sum_log_reward": 5.224999904632568, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 6.75, "eval_stats/max_log_achievement_collect_sapling": 2.7083333333333335, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 5.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.3333333333333333, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.8333333333333333, "eval_stats/max_log_achievement_wake_up": 1.5833333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.016129032258064516, "train_stats/max_log_achievement_make_stone_sword": 0.016129032258064516, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.003206715453416109, "report/cont_loss_std": 0.08418715000152588, "report/cont_neg_acc": 0.8333333730697632, "report/cont_neg_loss": 0.5438581705093384, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.016491453105118e-05, "report/cont_pred": 0.995517373085022, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 14.245732307434082, "report/dyn_loss_std": 8.220476150512695, "report/image_loss_mean": 9.664794921875, "report/image_loss_std": 13.93159294128418, "report/model_loss_mean": 18.28717041015625, "report/model_loss_std": 17.40346908569336, "report/post_ent_mag": 55.330543518066406, "report/post_ent_max": 55.330543518066406, "report/post_ent_mean": 38.46791076660156, "report/post_ent_min": 22.91861915588379, "report/post_ent_std": 6.493528842926025, "report/prior_ent_mag": 64.2117919921875, "report/prior_ent_max": 64.2117919921875, "report/prior_ent_mean": 53.38566207885742, "report/prior_ent_min": 35.97074508666992, "report/prior_ent_std": 5.10724401473999, "report/rep_loss_mean": 14.245732307434082, "report/rep_loss_std": 8.220476150512695, "report/reward_avg": 0.03242187574505806, "report/reward_loss_mean": 0.07172907888889313, "report/reward_loss_std": 0.39348533749580383, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0016558170318604, "report/reward_neg_acc": 0.99493408203125, "report/reward_neg_loss": 0.03687487170100212, "report/reward_pos_acc": 0.9189188480377197, "report/reward_pos_loss": 1.001488447189331, "report/reward_pred": 0.0313996858894825, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0008070000330917537, "eval/cont_loss_std": 0.025752970948815346, "eval/cont_neg_acc": 0.75, "eval/cont_neg_loss": 0.20639503002166748, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 7.724810870968213e-07, "eval/cont_pred": 0.9966424703598022, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 20.02695083618164, "eval/dyn_loss_std": 9.461181640625, "eval/image_loss_mean": 22.43979263305664, "eval/image_loss_std": 23.557689666748047, "eval/model_loss_mean": 34.55625915527344, "eval/model_loss_std": 27.283008575439453, "eval/post_ent_mag": 53.14284896850586, "eval/post_ent_max": 53.14284896850586, "eval/post_ent_mean": 36.56325149536133, "eval/post_ent_min": 22.009963989257812, "eval/post_ent_std": 5.740157127380371, "eval/prior_ent_mag": 64.2117919921875, "eval/prior_ent_max": 64.2117919921875, "eval/prior_ent_mean": 53.203338623046875, "eval/prior_ent_min": 37.20061492919922, "eval/prior_ent_std": 4.395253658294678, "eval/rep_loss_mean": 20.02695083618164, "eval/rep_loss_std": 9.461181640625, "eval/reward_avg": 0.03339843451976776, "eval/reward_loss_mean": 0.0994885116815567, "eval/reward_loss_std": 0.590884268283844, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0029003620147705, "eval/reward_neg_acc": 0.991894543170929, "eval/reward_neg_loss": 0.027061061933636665, "eval/reward_pos_acc": 0.7027026414871216, "eval/reward_pos_loss": 2.0315394401550293, "eval/reward_pred": 0.02427893877029419, "eval/reward_rate": 0.0361328125, "replay/size": 260113.0, "replay/inserts": 21168.0, "replay/samples": 21168.0, "replay/insert_wait_avg": 1.302854814767297e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.4184805898169e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 51888.0, "eval_replay/inserts": 5360.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.167316934955654e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0452125072479, "timer/env.step_count": 2646.0, "timer/env.step_total": 247.01073098182678, "timer/env.step_frac": 0.24699956351227126, "timer/env.step_avg": 0.09335250603999501, "timer/env.step_min": 0.022191286087036133, "timer/env.step_max": 2.2537362575531006, "timer/replay._sample_count": 21168.0, "timer/replay._sample_total": 11.065293550491333, "timer/replay._sample_frac": 0.01106479328344481, "timer/replay._sample_avg": 0.0005227368457337175, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.010824918746948242, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3316.0, "timer/agent.policy_total": 55.45404124259949, "timer/agent.policy_frac": 0.05545153413971029, "timer/agent.policy_avg": 0.016723172871712752, "timer/agent.policy_min": 0.009275674819946289, "timer/agent.policy_max": 1.1069939136505127, "timer/dataset_train_count": 1323.0, "timer/dataset_train_total": 0.14198565483093262, "timer/dataset_train_frac": 0.00014197923559371427, "timer/dataset_train_avg": 0.00010732097870818792, "timer/dataset_train_min": 9.131431579589844e-05, "timer/dataset_train_max": 0.0004532337188720703, "timer/agent.train_count": 1323.0, "timer/agent.train_total": 594.869686126709, "timer/agent.train_frac": 0.5948427917926736, "timer/agent.train_avg": 0.44963695096501055, "timer/agent.train_min": 0.4357724189758301, "timer/agent.train_max": 1.532386302947998, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4808468818664551, "timer/agent.report_frac": 0.00048082514255621227, "timer/agent.report_avg": 0.24042344093322754, "timer/agent.report_min": 0.23415136337280273, "timer/agent.report_max": 0.24669551849365234, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7893712610199252e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 21.16676369624846}
{"step": 261064, "time": 12333.235201358795, "episode/length": 180.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 261432, "time": 12347.10401725769, "episode/length": 149.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 261472, "time": 12350.57804274559, "episode/length": 155.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 261488, "time": 12353.03160572052, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 261552, "time": 12357.253154754639, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 261776, "time": 12366.4543800354, "episode/length": 201.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 261896, "time": 12371.8162753582, "episode/length": 42.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 262008, "time": 12377.113151073456, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 262312, "time": 12390.101803302765, "episode/length": 109.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 262464, "time": 12396.916596412659, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 262768, "time": 12408.472486257553, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 262944, "time": 12415.890273571014, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 263112, "time": 12422.833323955536, "episode/length": 42.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 263208, "time": 12427.543129205704, "episode/length": 163.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 263536, "time": 12440.188731431961, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 263576, "time": 12442.771569013596, "episode/length": 195.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 263752, "time": 12450.126527309418, "episode/length": 246.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 263984, "time": 12459.587088823318, "episode/length": 768.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9960988296488946, "episode/intrinsic_return": 0.0}
{"step": 264504, "time": 12478.022766828537, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 264832, "time": 12490.7496175766, "episode/length": 295.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 264920, "time": 12495.098415136337, "episode/length": 246.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9757085020242915, "episode/intrinsic_return": 0.0}
{"step": 265032, "time": 12500.43077993393, "episode/length": 186.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 265272, "time": 12510.15516614914, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 265552, "time": 12522.162650346756, "episode/length": 246.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 265936, "time": 12536.852631568909, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 266080, "time": 12543.192374944687, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 266448, "time": 12557.32303929329, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 266712, "time": 12568.161965847015, "episode/length": 437.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 266832, "time": 12574.484876155853, "episode/length": 224.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 266904, "time": 12578.121307373047, "episode/length": 203.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 267152, "time": 12588.282411336899, "episode/length": 199.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 267416, "time": 12598.209310293198, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 267712, "time": 12609.946252346039, "episode/length": 494.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838383838383838, "episode/intrinsic_return": 0.0}
{"step": 267872, "time": 12616.744069337845, "episode/length": 241.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.0}
{"step": 268064, "time": 12624.74928021431, "episode/length": 201.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 268152, "time": 12629.15644478798, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 268312, "time": 12636.033680200577, "episode/length": 175.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 268560, "time": 12646.003635644913, "episode/length": 215.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 269112, "time": 12665.478069782257, "episode/length": 154.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9870967741935484, "episode/intrinsic_return": 0.0}
{"step": 269152, "time": 12668.484549045563, "episode/length": 179.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 269376, "time": 12677.63276219368, "episode/length": 244.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 269416, "time": 12680.382808446884, "episode/length": 282.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 269792, "time": 12694.602717161179, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 269952, "time": 12701.51006603241, "episode/length": 173.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 269992, "time": 12704.184276342392, "episode/length": 240.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 270088, "time": 12727.099799394608, "eval_episode/length": 118.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.957983193277311}
{"step": 270088, "time": 12731.749122619629, "eval_episode/length": 191.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 270088, "time": 12731.759016036987, "eval_episode/length": 191.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 270088, "time": 12736.74782538414, "eval_episode/length": 228.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 270088, "time": 12736.75820851326, "eval_episode/length": 228.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9737991266375546}
{"step": 270088, "time": 12740.272222280502, "eval_episode/length": 231.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.978448275862069}
{"step": 270088, "time": 12743.129490613937, "eval_episode/length": 264.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9773584905660377}
{"step": 270088, "time": 12746.17793059349, "eval_episode/length": 301.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9966887417218543}
{"step": 270272, "time": 12752.438134431839, "episode/length": 264.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 270568, "time": 12765.276649475098, "episode/length": 176.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 270664, "time": 12770.541172742844, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 270680, "time": 12772.769354581833, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 271256, "time": 12794.123361110687, "episode/length": 157.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 271480, "time": 12803.059618234634, "episode/length": 210.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 271744, "time": 12813.628605127335, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 271968, "time": 12822.777606725693, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 271976, "time": 12824.396625757217, "episode/length": 161.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 272032, "time": 12828.927614450455, "episode/length": 182.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 272600, "time": 12849.10201048851, "episode/length": 435.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 272632, "time": 12851.930463552475, "episode/length": 143.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 272744, "time": 12857.117191791534, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 273296, "time": 12877.160155296326, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 273968, "time": 12901.501877307892, "episode/length": 241.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.987603305785124, "episode/intrinsic_return": 0.0}
{"step": 274048, "time": 12905.772514343262, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 274144, "time": 12910.586098909378, "episode/length": 192.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 274216, "time": 12914.362295866013, "episode/length": 443.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.990990990990991, "episode/intrinsic_return": 0.0}
{"step": 274232, "time": 12916.433643341064, "episode/length": 185.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 274248, "time": 12918.566300153732, "episode/length": 283.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9683098591549296, "episode/intrinsic_return": 0.0}
{"step": 274440, "time": 12926.597888946533, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9851632047477745, "episode/intrinsic_return": 0.0}
{"step": 274704, "time": 12937.917785406113, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 275560, "time": 12967.763527870178, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 275576, "time": 12969.951782226562, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 275672, "time": 12974.723601341248, "episode/length": 179.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9944444444444445, "episode/intrinsic_return": 0.0}
{"step": 275872, "time": 12983.27208018303, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 276008, "time": 12989.290076494217, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 276168, "time": 12996.185002326965, "episode/length": 274.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 276968, "time": 13024.221301317215, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 277184, "time": 13033.317269086838, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 277240, "time": 13036.627266407013, "episode/length": 209.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 277488, "time": 13046.671061754227, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 277584, "time": 13051.619740247726, "episode/length": 416.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 277600, "time": 13053.601527929306, "episode/length": 361.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9917127071823204, "episode/intrinsic_return": 0.0}
{"step": 277744, "time": 13060.145082473755, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 277912, "time": 13067.012391090393, "episode/length": 254.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9686274509803922, "episode/intrinsic_return": 0.0}
{"step": 278048, "time": 13073.491344213486, "episode/length": 254.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 278224, "time": 13081.601848125458, "episode/length": 38.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 278408, "time": 13089.930719137192, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 278704, "time": 13103.794964551926, "episode/length": 151.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 278960, "time": 13113.918087482452, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 279600, "time": 13136.854090690613, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 279736, "time": 13144.703537940979, "episode/length": 248.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9799196787148594, "episode/intrinsic_return": 0.0}
{"step": 279744, "time": 13146.904714107513, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 279792, "time": 13150.220966815948, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9817518248175182, "episode/intrinsic_return": 0.0}
{"step": 279928, "time": 13156.044122457504, "episode/length": 335.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9880952380952381, "episode/intrinsic_return": 0.0}
{"step": 279984, "time": 13159.751710891724, "episode/length": 159.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 280072, "time": 13179.031737804413, "eval_episode/length": 50.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9019607843137255}
{"step": 280072, "time": 13181.89908671379, "eval_episode/length": 79.0, "eval_episode/score": 4.099999979138374, "eval_episode/reward_rate": 0.9875}
{"step": 280072, "time": 13186.853431224823, "eval_episode/length": 158.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9937106918238994}
{"step": 280072, "time": 13186.861752271652, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 280072, "time": 13190.934822320938, "eval_episode/length": 178.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994413407821229}
{"step": 280072, "time": 13192.707113742828, "eval_episode/length": 183.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9619565217391305}
{"step": 280072, "time": 13194.428619623184, "eval_episode/length": 187.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 280072, "time": 13196.635814666748, "eval_episode/length": 202.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 280136, "time": 13198.77631521225, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 280264, "time": 13204.570695877075, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 280936, "time": 13228.209618806839, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9640718562874252, "episode/intrinsic_return": 0.0}
{"step": 281208, "time": 13238.855794429779, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 281272, "time": 13243.272789001465, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 281400, "time": 13249.637196540833, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 281536, "time": 13256.66415309906, "episode/length": 174.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 281560, "time": 13258.955594539642, "episode/length": 220.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 281768, "time": 13267.448091506958, "episode/length": 187.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 282104, "time": 13280.216953992844, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 282208, "time": 13285.412341594696, "episode/length": 158.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 282736, "time": 13304.418672323227, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 282784, "time": 13307.659091472626, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 282952, "time": 13314.528053283691, "episode/length": 173.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 282952, "time": 13314.537047624588, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 282953, "time": 13318.743903160095, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.743774853164344, "train/action_min": 0.0, "train/action_std": 3.439375014613858, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04462128856199251, "train/actor_opt_grad_steps": 16890.0, "train/actor_opt_loss": -2.849250528345005, "train/adv_mag": 0.7295010102738579, "train/adv_max": 0.7186937447932127, "train/adv_mean": 0.004109920475951335, "train/adv_min": -0.48960925434990754, "train/adv_std": 0.0729809878863019, "train/cont_avg": 0.9946886241007195, "train/cont_loss_mean": 0.0004438384071756131, "train/cont_loss_std": 0.012677813280323979, "train/cont_neg_acc": 0.9856457714554218, "train/cont_neg_loss": 0.055757128419003064, "train/cont_pos_acc": 0.999922342008824, "train/cont_pos_loss": 0.00019549420724933789, "train/cont_pred": 0.9946651763195614, "train/cont_rate": 0.9946886241007195, "train/dyn_loss_mean": 15.079765820674758, "train/dyn_loss_std": 8.845260331956602, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.909265700432894, "train/extr_critic_critic_opt_grad_steps": 16890.0, "train/extr_critic_critic_opt_loss": 15733.280596616456, "train/extr_critic_mag": 5.1332187755502385, "train/extr_critic_max": 5.1332187755502385, "train/extr_critic_mean": 1.002740028950808, "train/extr_critic_min": -0.246027857279606, "train/extr_critic_std": 1.2023563556533923, "train/extr_return_normed_mag": 1.874339162016944, "train/extr_return_normed_max": 1.874339162016944, "train/extr_return_normed_mean": 0.2980401815055943, "train/extr_return_normed_min": -0.14989113376187763, "train/extr_return_normed_std": 0.3436029541621105, "train/extr_return_rate": 0.46225974757036714, "train/extr_return_raw_mag": 6.706823338707574, "train/extr_return_raw_max": 6.706823338707574, "train/extr_return_raw_mean": 1.0175676088538959, "train/extr_return_raw_min": -0.5994160991135261, "train/extr_return_raw_std": 1.2403901866871676, "train/extr_reward_mag": 1.0121049572237961, "train/extr_reward_max": 1.0121049572237961, "train/extr_reward_mean": 0.025107529289055644, "train/extr_reward_min": -0.43581839259579885, "train/extr_reward_std": 0.1448683101389048, "train/image_loss_mean": 9.757101690168861, "train/image_loss_std": 13.333692063530572, "train/model_loss_mean": 18.861355232677873, "train/model_loss_std": 16.968675942729703, "train/model_opt_grad_norm": 75.70746521984073, "train/model_opt_grad_steps": 16871.21582733813, "train/model_opt_loss": 13678.055558678057, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 723.9208633093525, "train/policy_entropy_mag": 2.5227087676096307, "train/policy_entropy_max": 2.5227087676096307, "train/policy_entropy_mean": 0.6987375419774502, "train/policy_entropy_min": 0.07937525448610457, "train/policy_entropy_std": 0.6876423607627264, "train/policy_logprob_mag": 7.438382550109204, "train/policy_logprob_max": -0.00945588731267255, "train/policy_logprob_mean": -0.6986409104127678, "train/policy_logprob_min": -7.438382550109204, "train/policy_logprob_std": 1.1802748321629257, "train/policy_randomness_mag": 0.8904054893864145, "train/policy_randomness_max": 0.8904054893864145, "train/policy_randomness_mean": 0.24662369039418885, "train/policy_randomness_min": 0.02801598135462339, "train/policy_randomness_std": 0.2427075779695305, "train/post_ent_mag": 54.993015399082104, "train/post_ent_max": 54.993015399082104, "train/post_ent_mean": 38.07520124037489, "train/post_ent_min": 20.353159746677754, "train/post_ent_std": 6.5107963959947766, "train/prior_ent_mag": 64.8403798384632, "train/prior_ent_max": 64.8403798384632, "train/prior_ent_mean": 53.245750948679536, "train/prior_ent_min": 34.15264346445207, "train/prior_ent_std": 5.315447073188617, "train/rep_loss_mean": 15.079765820674758, "train/rep_loss_std": 8.845260331956602, "train/reward_avg": 0.02336443319461114, "train/reward_loss_mean": 0.055950388071133936, "train/reward_loss_std": 0.2647807256137724, "train/reward_max_data": 1.0129496433752045, "train/reward_max_pred": 1.0068508755388876, "train/reward_neg_acc": 0.9930674939704456, "train/reward_neg_loss": 0.03140947804953769, "train/reward_pos_acc": 0.9602870589537587, "train/reward_pos_loss": 0.9068817693552524, "train/reward_pred": 0.02256602896444446, "train/reward_rate": 0.028151697392086332, "train_stats/sum_log_reward": 5.875700923884026, "train_stats/max_log_achievement_collect_coal": 0.009345794392523364, "train_stats/max_log_achievement_collect_drink": 7.327102803738318, "train_stats/max_log_achievement_collect_sapling": 3.2336448598130842, "train_stats/max_log_achievement_collect_stone": 0.17757009345794392, "train_stats/max_log_achievement_collect_wood": 7.261682242990654, "train_stats/max_log_achievement_defeat_skeleton": 0.009345794392523364, "train_stats/max_log_achievement_defeat_zombie": 0.4205607476635514, "train_stats/max_log_achievement_eat_cow": 0.18691588785046728, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.8411214953271028, "train_stats/max_log_achievement_make_wood_sword": 0.09345794392523364, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 3.0934579439252334, "train_stats/max_log_achievement_place_stone": 0.009345794392523364, "train_stats/max_log_achievement_place_table": 2.383177570093458, "train_stats/max_log_achievement_wake_up": 1.8598130841121496, "train_stats/mean_log_entropy": 0.6522404103078575, "eval_stats/sum_log_reward": 5.662499949336052, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.875, "eval_stats/max_log_achievement_collect_sapling": 2.6875, "eval_stats/max_log_achievement_collect_stone": 0.0, "eval_stats/max_log_achievement_collect_wood": 6.9375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.375, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 2.2158646970638074e-06, "report/cont_loss_std": 1.958136272151023e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.234526957385242e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.097709966619732e-06, "report/cont_pred": 0.9960918426513672, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.229086875915527, "report/dyn_loss_std": 8.713282585144043, "report/image_loss_mean": 8.60288143157959, "report/image_loss_std": 12.977657318115234, "report/model_loss_mean": 16.585119247436523, "report/model_loss_std": 16.563764572143555, "report/post_ent_mag": 55.408668518066406, "report/post_ent_max": 55.408668518066406, "report/post_ent_mean": 40.178863525390625, "report/post_ent_min": 21.54207992553711, "report/post_ent_std": 7.270468711853027, "report/prior_ent_mag": 65.2356948852539, "report/prior_ent_max": 65.2356948852539, "report/prior_ent_mean": 53.472816467285156, "report/prior_ent_min": 37.21437454223633, "report/prior_ent_std": 5.286547660827637, "report/rep_loss_mean": 13.229086875915527, "report/rep_loss_std": 8.713282585144043, "report/reward_avg": 0.01201171800494194, "report/reward_loss_mean": 0.044784002006053925, "report/reward_loss_std": 0.28457024693489075, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9993630647659302, "report/reward_neg_acc": 0.996023952960968, "report/reward_neg_loss": 0.024989290162920952, "report/reward_pos_acc": 0.8888888955116272, "report/reward_pos_loss": 1.1510884761810303, "report/reward_pred": 0.010084878653287888, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.9921875, "eval/cont_loss_mean": 0.0018600411713123322, "eval/cont_loss_std": 0.04411349445581436, "eval/cont_neg_acc": 0.875, "eval/cont_neg_loss": 0.15715931355953217, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.0006372122443281114, "eval/cont_pred": 0.9924198985099792, "eval/cont_rate": 0.9921875, "eval/dyn_loss_mean": 18.814809799194336, "eval/dyn_loss_std": 9.731364250183105, "eval/image_loss_mean": 18.281620025634766, "eval/image_loss_std": 20.48225975036621, "eval/model_loss_mean": 29.705352783203125, "eval/model_loss_std": 24.13292694091797, "eval/post_ent_mag": 56.07334899902344, "eval/post_ent_max": 56.07334899902344, "eval/post_ent_mean": 38.02036666870117, "eval/post_ent_min": 21.929298400878906, "eval/post_ent_std": 6.633730411529541, "eval/prior_ent_mag": 65.2356948852539, "eval/prior_ent_max": 65.2356948852539, "eval/prior_ent_mean": 53.86555480957031, "eval/prior_ent_min": 36.284969329833984, "eval/prior_ent_std": 5.538167953491211, "eval/rep_loss_mean": 18.814809799194336, "eval/rep_loss_std": 9.731364250183105, "eval/reward_avg": 0.017578125, "eval/reward_loss_mean": 0.13298465311527252, "eval/reward_loss_std": 0.7623760104179382, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999978542327881, "eval/reward_neg_acc": 0.9909819960594177, "eval/reward_neg_loss": 0.0774640217423439, "eval/reward_pos_acc": 0.7692307829856873, "eval/reward_pos_loss": 2.2641232013702393, "eval/reward_pred": 0.014400104060769081, "eval/reward_rate": 0.025390625, "replay/size": 282449.0, "replay/inserts": 22336.0, "replay/samples": 22336.0, "replay/insert_wait_avg": 1.3118465684546441e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.420159171850429e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 55928.0, "eval_replay/inserts": 4040.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1353209467217474e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.387731552124023e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2796397209167, "timer/env.step_count": 2792.0, "timer/env.step_total": 249.83460807800293, "timer/env.step_frac": 0.24976476392912295, "timer/env.step_avg": 0.08948230948352541, "timer/env.step_min": 0.02251911163330078, "timer/env.step_max": 3.215085506439209, "timer/replay._sample_count": 22336.0, "timer/replay._sample_total": 11.504223346710205, "timer/replay._sample_frac": 0.011501007208264224, "timer/replay._sample_avg": 0.000515052979347699, "timer/replay._sample_min": 0.00034928321838378906, "timer/replay._sample_max": 0.010488510131835938, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3297.0, "timer/agent.policy_total": 53.276198863983154, "timer/agent.policy_frac": 0.05326130488754874, "timer/agent.policy_avg": 0.01615899267940041, "timer/agent.policy_min": 0.00934457778930664, "timer/agent.policy_max": 0.11105513572692871, "timer/dataset_train_count": 1396.0, "timer/dataset_train_total": 0.1506953239440918, "timer/dataset_train_frac": 0.00015065319532659544, "timer/dataset_train_avg": 0.00010794793978803137, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.00046324729919433594, "timer/agent.train_count": 1396.0, "timer/agent.train_total": 627.1923398971558, "timer/agent.train_frac": 0.6270170010379754, "timer/agent.train_avg": 0.44927818044208867, "timer/agent.train_min": 0.4336245059967041, "timer/agent.train_max": 1.569455623626709, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47869372367858887, "timer/agent.report_frac": 0.00047855989932190057, "timer/agent.report_avg": 0.23934686183929443, "timer/agent.report_min": 0.2308211326599121, "timer/agent.report_max": 0.24787259101867676, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.5980359981455783e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 22.329450114069417}
{"step": 282968, "time": 13318.825371980667, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 283472, "time": 13338.071460723877, "episode/length": 170.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 284072, "time": 13359.373046636581, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 284152, "time": 13363.720860481262, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 284208, "time": 13367.407995462418, "episode/length": 527.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 284296, "time": 13371.67231798172, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 284352, "time": 13375.300627708435, "episode/length": 267.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 284464, "time": 13380.597778081894, "episode/length": 188.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 284608, "time": 13387.020568609238, "episode/length": 206.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 284816, "time": 13395.432220458984, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 284848, "time": 13398.079565763474, "episode/length": 47.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 285384, "time": 13417.174550533295, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 286008, "time": 13439.532769441605, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 286032, "time": 13442.129564523697, "episode/length": 227.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 286208, "time": 13449.532447576523, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 286264, "time": 13452.9262509346, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 286416, "time": 13459.744888067245, "episode/length": 199.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 286480, "time": 13463.371940851212, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 286736, "time": 13474.825776338577, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 286800, "time": 13478.475368022919, "episode/length": 47.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 287456, "time": 13501.860436916351, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 287600, "time": 13508.78790140152, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 287712, "time": 13514.329331159592, "episode/length": 153.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 287760, "time": 13517.495025157928, "episode/length": 186.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 288064, "time": 13529.098002433777, "episode/length": 253.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 288360, "time": 13540.331462860107, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 288408, "time": 13543.439534187317, "episode/length": 299.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 288728, "time": 13555.56819844246, "episode/length": 140.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 288832, "time": 13560.759345531464, "episode/length": 261.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 288952, "time": 13566.059450387955, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 289008, "time": 13569.73382472992, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9639175257731959, "episode/intrinsic_return": 0.0}
{"step": 289224, "time": 13578.233680725098, "episode/length": 33.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 289264, "time": 13581.332724809647, "episode/length": 53.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 289480, "time": 13589.838919639587, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 289544, "time": 13593.630266904831, "episode/length": 222.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 289696, "time": 13600.667078733444, "episode/length": 166.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 290056, "time": 13628.091089010239, "eval_episode/length": 33.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 290056, "time": 13635.793062448502, "eval_episode/length": 143.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9652777777777778}
{"step": 290056, "time": 13635.800895929337, "eval_episode/length": 143.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 290056, "time": 13639.25193476677, "eval_episode/length": 149.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9533333333333334}
{"step": 290056, "time": 13640.897808551788, "eval_episode/length": 152.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9934640522875817}
{"step": 290056, "time": 13642.727236270905, "eval_episode/length": 158.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 290056, "time": 13646.3101811409, "eval_episode/length": 206.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 290056, "time": 13649.167134284973, "eval_episode/length": 202.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9704433497536946}
{"step": 290424, "time": 13661.544011592865, "episode/length": 251.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 290520, "time": 13666.314237117767, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 290576, "time": 13669.970244407654, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 290712, "time": 13675.803787469864, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 290968, "time": 13685.728168964386, "episode/length": 158.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 290992, "time": 13688.410105705261, "episode/length": 34.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8571428571428571, "episode/intrinsic_return": 0.0}
{"step": 291032, "time": 13691.22596025467, "episode/length": 185.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 291168, "time": 13697.50203537941, "episode/length": 304.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 291992, "time": 13726.163052082062, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 292056, "time": 13729.822369813919, "episode/length": 321.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 292200, "time": 13736.158675909042, "episode/length": 221.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 292480, "time": 13747.200272083282, "episode/length": 188.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 292680, "time": 13755.21735239029, "episode/length": 262.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.973384030418251, "episode/intrinsic_return": 0.0}
{"step": 293472, "time": 13783.39610171318, "episode/length": 304.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 293552, "time": 13787.587649822235, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 293824, "time": 13798.393399000168, "episode/length": 228.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 294208, "time": 13813.754851341248, "episode/length": 379.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763157894736842, "episode/intrinsic_return": 0.0}
{"step": 294240, "time": 13816.870602846146, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681818181818181, "episode/intrinsic_return": 0.0}
{"step": 294440, "time": 13825.502512931824, "episode/length": 430.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9953596287703016, "episode/intrinsic_return": 0.0}
{"step": 294656, "time": 13834.480080127716, "episode/length": 306.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 294704, "time": 13837.781808137894, "episode/length": 252.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9762845849802372, "episode/intrinsic_return": 0.0}
{"step": 295016, "time": 13851.057203769684, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 295120, "time": 13856.232233285904, "episode/length": 195.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 295256, "time": 13862.03575015068, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 295992, "time": 13887.997735023499, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 296248, "time": 13898.09221816063, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 296280, "time": 13900.884869813919, "episode/length": 229.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 296488, "time": 13909.36618733406, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 296504, "time": 13911.473882436752, "episode/length": 282.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 296608, "time": 13916.698127746582, "episode/length": 237.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 296680, "time": 13920.438915491104, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 296896, "time": 13929.612415790558, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.963963963963964, "episode/intrinsic_return": 0.0}
{"step": 296984, "time": 13934.502897500992, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 297368, "time": 13949.575273036957, "episode/length": 171.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 297696, "time": 13962.288697004318, "episode/length": 176.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 297784, "time": 13966.69423365593, "episode/length": 191.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 297912, "time": 13972.465245008469, "episode/length": 177.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 298064, "time": 13979.39208483696, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 298120, "time": 13982.4991106987, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 298144, "time": 13985.101420879364, "episode/length": 144.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9586206896551724, "episode/intrinsic_return": 0.0}
{"step": 298304, "time": 13992.008207798004, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 299320, "time": 14027.030803442001, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 299320, "time": 14027.039954185486, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 299320, "time": 14027.04725432396, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9617834394904459, "episode/intrinsic_return": 0.0}
{"step": 299496, "time": 14038.011438131332, "episode/length": 197.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 299512, "time": 14040.107655286789, "episode/length": 173.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 299816, "time": 14051.988043308258, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 299920, "time": 14057.323557376862, "episode/length": 266.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 300040, "time": 14079.870703697205, "eval_episode/length": 27.0, "eval_episode/score": 3.100000001490116, "eval_episode/reward_rate": 0.8571428571428571}
{"step": 300040, "time": 14088.77951669693, "eval_episode/length": 175.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9829545454545454}
{"step": 300040, "time": 14091.120212554932, "eval_episode/length": 180.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.994475138121547}
{"step": 300040, "time": 14093.189821958542, "eval_episode/length": 181.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 300040, "time": 14097.126612663269, "eval_episode/length": 219.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9954545454545455}
{"step": 300040, "time": 14099.36991596222, "eval_episode/length": 222.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9820627802690582}
{"step": 300040, "time": 14101.072416305542, "eval_episode/length": 229.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 300040, "time": 14102.597362041473, "eval_episode/length": 48.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 300240, "time": 14109.41780090332, "episode/length": 39.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 300296, "time": 14112.760628938675, "episode/length": 365.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 300648, "time": 14125.98238492012, "episode/length": 165.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 300776, "time": 14131.79133105278, "episode/length": 181.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 300952, "time": 14139.213386774063, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9647887323943662, "episode/intrinsic_return": 0.0}
{"step": 301128, "time": 14146.80879688263, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 301280, "time": 14153.678764343262, "episode/length": 244.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 301624, "time": 14166.473189353943, "episode/length": 172.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 301680, "time": 14170.148865699768, "episode/length": 172.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 301912, "time": 14179.187745809555, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 302112, "time": 14187.67188334465, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 302224, "time": 14192.865140199661, "episode/length": 158.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 302304, "time": 14197.096142053604, "episode/length": 348.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9828080229226361, "episode/intrinsic_return": 0.0}
{"step": 302880, "time": 14217.948068380356, "episode/length": 199.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 302920, "time": 14220.60947728157, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 303136, "time": 14230.991474628448, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 303392, "time": 14241.028109312057, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 303408, "time": 14243.18944811821, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 303440, "time": 14245.709971666336, "episode/length": 37.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 303456, "time": 14247.796539068222, "episode/length": 221.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 303544, "time": 14252.055957317352, "episode/length": 164.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 304168, "time": 14274.431503295898, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 304504, "time": 14286.973110198975, "episode/length": 197.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 304504, "time": 14286.9796397686, "episode/length": 41.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 304656, "time": 14295.58273434639, "episode/length": 149.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 304688, "time": 14298.213445425034, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 304792, "time": 14303.67567563057, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 305161, "time": 14319.039915800095, "train_stats/sum_log_reward": 5.991891853444211, "train_stats/max_log_achievement_collect_coal": 0.04504504504504504, "train_stats/max_log_achievement_collect_drink": 6.495495495495495, "train_stats/max_log_achievement_collect_sapling": 2.7567567567567566, "train_stats/max_log_achievement_collect_stone": 0.46846846846846846, "train_stats/max_log_achievement_collect_wood": 7.666666666666667, "train_stats/max_log_achievement_defeat_skeleton": 0.009009009009009009, "train_stats/max_log_achievement_defeat_zombie": 0.42342342342342343, "train_stats/max_log_achievement_eat_cow": 0.0990990990990991, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.009009009009009009, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4054054054054055, "train_stats/max_log_achievement_make_wood_sword": 0.12612612612612611, "train_stats/max_log_achievement_place_furnace": 0.009009009009009009, "train_stats/max_log_achievement_place_plant": 2.4324324324324325, "train_stats/max_log_achievement_place_stone": 0.02702702702702703, "train_stats/max_log_achievement_place_table": 2.5045045045045047, "train_stats/max_log_achievement_wake_up": 1.5855855855855856, "train_stats/mean_log_entropy": 0.6251810233335238, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.818396259554856, "train/action_min": 0.0, "train/action_std": 3.471411578089213, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04409369902698685, "train/actor_opt_grad_steps": 18280.0, "train/actor_opt_loss": -1.9796565216865472, "train/adv_mag": 0.6758327606341822, "train/adv_max": 0.6673953766874272, "train/adv_mean": 0.0037145622922213836, "train/adv_min": -0.4768899893589157, "train/adv_std": 0.07167210574630353, "train/cont_avg": 0.9946394446942446, "train/cont_loss_mean": 0.00025318460217699435, "train/cont_loss_std": 0.007116246749937869, "train/cont_neg_acc": 0.9934061126432557, "train/cont_neg_loss": 0.016649316745233064, "train/cont_pos_acc": 0.9999434677816981, "train/cont_pos_loss": 0.00015483706921003818, "train/cont_pred": 0.9946012518388762, "train/cont_rate": 0.9946394446942446, "train/dyn_loss_mean": 14.919754501726988, "train/dyn_loss_std": 8.797713211114457, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8791585002871726, "train/extr_critic_critic_opt_grad_steps": 18280.0, "train/extr_critic_critic_opt_loss": 15787.907142254946, "train/extr_critic_mag": 5.412663284823191, "train/extr_critic_max": 5.412663284823191, "train/extr_critic_mean": 1.042017044566518, "train/extr_critic_min": -0.21274172745162634, "train/extr_critic_std": 1.2397200568116826, "train/extr_return_normed_mag": 1.8596061416667142, "train/extr_return_normed_max": 1.8596061416667142, "train/extr_return_normed_mean": 0.2921090623457655, "train/extr_return_normed_min": -0.1522073748943617, "train/extr_return_normed_std": 0.34291930593174996, "train/extr_return_rate": 0.4682188865949782, "train/extr_return_raw_mag": 6.888973246375434, "train/extr_return_raw_max": 6.888973246375434, "train/extr_return_raw_mean": 1.0558306446178354, "train/extr_return_raw_min": -0.597570769220805, "train/extr_return_raw_std": 1.2762427805996628, "train/extr_reward_mag": 1.012868982424839, "train/extr_reward_max": 1.012868982424839, "train/extr_reward_mean": 0.026402917757576746, "train/extr_reward_min": -0.4435501373071465, "train/extr_reward_std": 0.14892894914038748, "train/image_loss_mean": 9.240815515998456, "train/image_loss_std": 12.978193653573236, "train/model_loss_mean": 18.247576020604416, "train/model_loss_std": 16.546748442615538, "train/model_opt_grad_norm": 71.41079621349307, "train/model_opt_grad_steps": 18260.510791366905, "train/model_opt_loss": 17240.78965265288, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 944.2446043165468, "train/policy_entropy_mag": 2.532075180424203, "train/policy_entropy_max": 2.532075180424203, "train/policy_entropy_mean": 0.7047122901292155, "train/policy_entropy_min": 0.07937524339063562, "train/policy_entropy_std": 0.6916398324554772, "train/policy_logprob_mag": 7.438382906879452, "train/policy_logprob_max": -0.009455852424926895, "train/policy_logprob_mean": -0.7049405733458429, "train/policy_logprob_min": -7.438382906879452, "train/policy_logprob_std": 1.1874890936364373, "train/policy_randomness_mag": 0.8937114198430837, "train/policy_randomness_max": 0.8937114198430837, "train/policy_randomness_mean": 0.24873251419702022, "train/policy_randomness_min": 0.02801597726752432, "train/policy_randomness_std": 0.24411850535183502, "train/post_ent_mag": 55.47658121671608, "train/post_ent_max": 55.47658121671608, "train/post_ent_mean": 38.42705025432779, "train/post_ent_min": 20.353774365761296, "train/post_ent_std": 6.6135475241023, "train/prior_ent_mag": 64.98109633630986, "train/prior_ent_max": 64.98109633630986, "train/prior_ent_mean": 53.46211659822533, "train/prior_ent_min": 35.02482285259439, "train/prior_ent_std": 5.130984783172607, "train/rep_loss_mean": 14.919754501726988, "train/rep_loss_std": 8.797713211114457, "train/reward_avg": 0.022539624428416758, "train/reward_loss_mean": 0.054654822852328526, "train/reward_loss_std": 0.25814202953156806, "train/reward_max_data": 1.0129496433752045, "train/reward_max_pred": 1.006434558106841, "train/reward_neg_acc": 0.9930700934190544, "train/reward_neg_loss": 0.03063124278895289, "train/reward_pos_acc": 0.9551434482601907, "train/reward_pos_loss": 0.9174833542151417, "train/reward_pred": 0.02174502367944383, "train/reward_rate": 0.027378878147482015, "eval_stats/sum_log_reward": 5.349999971687794, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 3.6875, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 0.125, "eval_stats/max_log_achievement_collect_wood": 6.1875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0, "eval_stats/max_log_achievement_make_wood_sword": 0.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 9.770365977601614e-06, "report/cont_loss_std": 0.00014982023276388645, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.2549610952846706e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.577167475072201e-06, "report/cont_pred": 0.994131326675415, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 16.33867645263672, "report/dyn_loss_std": 8.777192115783691, "report/image_loss_mean": 10.286859512329102, "report/image_loss_std": 12.207185745239258, "report/model_loss_mean": 20.144092559814453, "report/model_loss_std": 15.872696876525879, "report/post_ent_mag": 56.01746368408203, "report/post_ent_max": 56.01746368408203, "report/post_ent_mean": 37.409645080566406, "report/post_ent_min": 22.278057098388672, "report/post_ent_std": 6.995250701904297, "report/prior_ent_mag": 65.30908203125, "report/prior_ent_max": 65.30908203125, "report/prior_ent_mean": 54.080780029296875, "report/prior_ent_min": 37.17414855957031, "report/prior_ent_std": 4.606725692749023, "report/rep_loss_mean": 16.33867645263672, "report/rep_loss_std": 8.777192115783691, "report/reward_avg": 0.01875000074505806, "report/reward_loss_mean": 0.054016340523958206, "report/reward_loss_std": 0.28393617272377014, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.003394603729248, "report/reward_neg_acc": 0.9960000514984131, "report/reward_neg_loss": 0.029245508834719658, "report/reward_pos_acc": 0.875, "report/reward_pos_loss": 1.086134433746338, "report/reward_pred": 0.01679838076233864, "report/reward_rate": 0.0234375, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 6.103659688960761e-05, "eval/cont_loss_std": 0.0018708755960687995, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.05988971143960953, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.553048261688673e-06, "eval/cont_pred": 0.999077558517456, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 19.41701316833496, "eval/dyn_loss_std": 9.621793746948242, "eval/image_loss_mean": 25.170001983642578, "eval/image_loss_std": 41.80475997924805, "eval/model_loss_mean": 36.88178253173828, "eval/model_loss_std": 45.23379135131836, "eval/post_ent_mag": 58.155357360839844, "eval/post_ent_max": 58.155357360839844, "eval/post_ent_mean": 38.21934127807617, "eval/post_ent_min": 22.871952056884766, "eval/post_ent_std": 6.410147190093994, "eval/prior_ent_mag": 64.88883209228516, "eval/prior_ent_max": 64.88883209228516, "eval/prior_ent_mean": 54.577392578125, "eval/prior_ent_min": 34.49806594848633, "eval/prior_ent_std": 4.752357006072998, "eval/rep_loss_mean": 19.41701316833496, "eval/rep_loss_std": 9.621793746948242, "eval/reward_avg": 0.01679687574505806, "eval/reward_loss_mean": 0.0615093819797039, "eval/reward_loss_std": 0.39711037278175354, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0026147365570068, "eval/reward_neg_acc": 0.9930348992347717, "eval/reward_neg_loss": 0.024921992793679237, "eval/reward_pos_acc": 0.6842105388641357, "eval/reward_pos_loss": 1.9967894554138184, "eval/reward_pred": 0.010841324925422668, "eval/reward_rate": 0.0185546875, "replay/size": 304657.0, "replay/inserts": 22208.0, "replay/samples": 22208.0, "replay/insert_wait_avg": 1.3195901507946532e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.319497615528382e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 59672.0, "eval_replay/inserts": 3744.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.203045885787051e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2832970619202, "timer/env.step_count": 2776.0, "timer/env.step_total": 252.9114067554474, "timer/env.step_frac": 0.2528397779892065, "timer/env.step_avg": 0.09110641453726491, "timer/env.step_min": 0.02267146110534668, "timer/env.step_max": 5.136409044265747, "timer/replay._sample_count": 22208.0, "timer/replay._sample_total": 11.21285104751587, "timer/replay._sample_frac": 0.011209675379415801, "timer/replay._sample_avg": 0.00050490143405601, "timer/replay._sample_min": 0.0003809928894042969, "timer/replay._sample_max": 0.01104426383972168, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3244.0, "timer/agent.policy_total": 53.373050689697266, "timer/agent.policy_frac": 0.05335793454361093, "timer/agent.policy_avg": 0.016452851630609514, "timer/agent.policy_min": 0.00900888442993164, "timer/agent.policy_max": 0.10084724426269531, "timer/dataset_train_count": 1388.0, "timer/dataset_train_total": 0.1530306339263916, "timer/dataset_train_frac": 0.00015298729307575213, "timer/dataset_train_avg": 0.00011025261810258761, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0054225921630859375, "timer/agent.train_count": 1388.0, "timer/agent.train_total": 622.434063911438, "timer/agent.train_frac": 0.6222577801105756, "timer/agent.train_avg": 0.4484395273137161, "timer/agent.train_min": 0.43448686599731445, "timer/agent.train_max": 1.6126298904418945, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4720878601074219, "timer/agent.report_frac": 0.00047195415688141635, "timer/agent.report_avg": 0.23604393005371094, "timer/agent.report_min": 0.22708892822265625, "timer/agent.report_max": 0.24499893188476562, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.075599670410156e-05, "timer/dataset_eval_frac": 3.074728608829073e-08, "timer/dataset_eval_avg": 3.075599670410156e-05, "timer/dataset_eval_min": 3.075599670410156e-05, "timer/dataset_eval_max": 3.075599670410156e-05, "fps": 22.201399833902336}
{"step": 305384, "time": 14326.464593172073, "episode/length": 242.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 305504, "time": 14332.178971767426, "episode/length": 244.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 305752, "time": 14341.845321178436, "episode/length": 430.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9930394431554525, "episode/intrinsic_return": 0.0}
{"step": 305776, "time": 14344.460005044937, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 305928, "time": 14350.88889837265, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 305944, "time": 14352.972622394562, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 306112, "time": 14360.279770851135, "episode/length": 177.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 306984, "time": 14391.002038002014, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 306984, "time": 14391.011994123459, "episode/length": 184.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 307024, "time": 14396.878820896149, "episode/length": 158.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 307096, "time": 14401.132616758347, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 307312, "time": 14410.815213680267, "episode/length": 149.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 307480, "time": 14418.402580499649, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 307720, "time": 14427.947413921356, "episode/length": 242.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9670781893004116, "episode/intrinsic_return": 0.0}
{"step": 308184, "time": 14445.00389289856, "episode/length": 281.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 308296, "time": 14450.239738225937, "episode/length": 163.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 308528, "time": 14459.863036632538, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 308576, "time": 14463.078236103058, "episode/length": 193.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 308704, "time": 14468.9065117836, "episode/length": 200.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 308752, "time": 14472.178427934647, "episode/length": 179.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 308776, "time": 14474.271453619003, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 308968, "time": 14482.224477529526, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 309152, "time": 14490.063439846039, "episode/length": 46.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 309504, "time": 14503.324123382568, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 309536, "time": 14505.933493852615, "episode/length": 119.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9916666666666667, "episode/intrinsic_return": 0.0}
{"step": 309600, "time": 14509.654875993729, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754601226993865, "episode/intrinsic_return": 0.0}
{"step": 310024, "time": 14539.747758865356, "eval_episode/length": 44.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 310024, "time": 14543.70158457756, "eval_episode/length": 51.0, "eval_episode/score": 1.1000000014901161, "eval_episode/reward_rate": 0.9807692307692307}
{"step": 310024, "time": 14548.68297457695, "eval_episode/length": 156.0, "eval_episode/score": 6.1000000312924385, "eval_episode/reward_rate": 0.9617834394904459}
{"step": 310024, "time": 14550.691614627838, "eval_episode/length": 157.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 310024, "time": 14552.965223789215, "eval_episode/length": 165.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 310024, "time": 14554.69702386856, "eval_episode/length": 166.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 310024, "time": 14556.533685207367, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 310024, "time": 14559.189113378525, "eval_episode/length": 33.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 310040, "time": 14559.82153248787, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 310272, "time": 14569.321465969086, "episode/length": 217.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 310480, "time": 14577.782713413239, "episode/length": 215.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 310680, "time": 14585.831670045853, "episode/length": 213.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 310808, "time": 14592.440380334854, "episode/length": 206.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 310960, "time": 14599.82777094841, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 311080, "time": 14605.863327980042, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 311360, "time": 14619.174721002579, "episode/length": 231.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 311656, "time": 14630.598632097244, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 311800, "time": 14636.875894784927, "episode/length": 219.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 311992, "time": 14645.04074883461, "episode/length": 147.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 312064, "time": 14649.907935857773, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 312072, "time": 14651.932859659195, "episode/length": 173.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 312512, "time": 14668.907098531723, "episode/length": 193.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 312600, "time": 14673.219998598099, "episode/length": 189.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 313280, "time": 14697.579874515533, "episode/length": 184.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 313312, "time": 14700.281373500824, "episode/length": 243.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9795081967213115, "episode/intrinsic_return": 0.0}
{"step": 313384, "time": 14704.033949136734, "episode/length": 164.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 313552, "time": 14711.546161174774, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 313696, "time": 14717.822099685669, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 313968, "time": 14728.53815293312, "episode/length": 288.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 314432, "time": 14746.546699762344, "episode/length": 239.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 314536, "time": 14751.86093211174, "episode/length": 104.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9904761904761905, "episode/intrinsic_return": 0.0}
{"step": 314776, "time": 14761.492551803589, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 314832, "time": 14765.149247646332, "episode/length": 278.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 314856, "time": 14767.256219625473, "episode/length": 183.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 314880, "time": 14769.973565101624, "episode/length": 165.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 315136, "time": 14780.27861070633, "episode/length": 145.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 315152, "time": 14782.931319236755, "episode/length": 229.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 315776, "time": 14805.743663549423, "episode/length": 154.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 316240, "time": 14822.755496263504, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 316328, "time": 14827.075117826462, "episode/length": 236.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 316336, "time": 14829.164372444153, "episode/length": 184.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 316352, "time": 14831.372252464294, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 316424, "time": 14835.073615550995, "episode/length": 192.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 316648, "time": 14844.084362268448, "episode/length": 27.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 316760, "time": 14849.501659870148, "episode/length": 50.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 316784, "time": 14851.965556144714, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 316816, "time": 14854.534728765488, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 317072, "time": 14864.682014226913, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 317336, "time": 14874.720953702927, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 317632, "time": 14886.198971748352, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 317680, "time": 14889.341949939728, "episode/length": 168.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 317832, "time": 14896.440946102142, "episode/length": 198.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 318584, "time": 14923.70510172844, "episode/length": 227.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 318824, "time": 14933.373842954636, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 318896, "time": 14938.1625790596, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 318928, "time": 14940.852659702301, "episode/length": 231.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 319024, "time": 14945.792000055313, "episode/length": 279.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 319088, "time": 14949.438000679016, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 319152, "time": 14953.241810560226, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 319344, "time": 14961.283163309097, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 319936, "time": 14984.443936109543, "episode/length": 129.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9923076923076923, "episode/intrinsic_return": 0.0}
{"step": 320008, "time": 15007.733091831207, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 320008, "time": 15010.532898426056, "eval_episode/length": 190.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 320008, "time": 15012.06997013092, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 320008, "time": 15013.987258195877, "eval_episode/length": 198.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9949748743718593}
{"step": 320008, "time": 15017.619861841202, "eval_episode/length": 244.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 320008, "time": 15020.085096120834, "eval_episode/length": 266.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9850187265917603}
{"step": 320008, "time": 15023.763738155365, "eval_episode/length": 316.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9905362776025236}
{"step": 320008, "time": 15026.29156780243, "eval_episode/length": 338.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9970501474926253}
{"step": 320272, "time": 15035.366850852966, "episode/length": 210.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.966824644549763, "episode/intrinsic_return": 0.0}
{"step": 320384, "time": 15040.852811336517, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 320400, "time": 15042.877329826355, "episode/length": 171.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 320712, "time": 15054.630061388016, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 320864, "time": 15061.517764806747, "episode/length": 213.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 321120, "time": 15071.689970254898, "episode/length": 286.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 321128, "time": 15073.37444806099, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 321680, "time": 15094.83856511116, "episode/length": 161.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 321680, "time": 15094.847786188126, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 321712, "time": 15099.350445985794, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 321776, "time": 15103.115258455276, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 322272, "time": 15121.762618780136, "episode/length": 194.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 322424, "time": 15128.179918527603, "episode/length": 162.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 322608, "time": 15136.139010429382, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 323048, "time": 15152.059784412384, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 323080, "time": 15154.77649974823, "episode/length": 174.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 323184, "time": 15160.146870136261, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 323336, "time": 15166.60125207901, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 323960, "time": 15189.299976110458, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 323984, "time": 15191.951182126999, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 324104, "time": 15197.135764598846, "episode/length": 290.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9965635738831615, "episode/intrinsic_return": 0.0}
{"step": 324392, "time": 15208.560300588608, "episode/length": 167.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 324768, "time": 15223.250973463058, "episode/length": 178.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 324920, "time": 15229.773499965668, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 325168, "time": 15239.918148517609, "episode/length": 260.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 325200, "time": 15242.56209731102, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 325288, "time": 15246.964325904846, "episode/length": 376.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9973474801061007, "episode/intrinsic_return": 0.0}
{"step": 325304, "time": 15248.991348028183, "episode/length": 167.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 325528, "time": 15258.092025279999, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 326128, "time": 15279.907984972, "episode/length": 216.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 326160, "time": 15282.529238939285, "episode/length": 173.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9597701149425287, "episode/intrinsic_return": 0.0}
{"step": 326544, "time": 15297.105287790298, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 326752, "time": 15306.110036849976, "episode/length": 182.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 326880, "time": 15312.106451272964, "episode/length": 213.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 327033, "time": 15319.482735872269, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.672512973312044, "train/action_min": 0.0, "train/action_std": 3.4318136629396983, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04471734359207814, "train/actor_opt_grad_steps": 19660.0, "train/actor_opt_loss": 1.3663308244116985, "train/adv_mag": 0.6942042231994824, "train/adv_max": 0.6779138458906299, "train/adv_mean": 0.004576537698098581, "train/adv_min": -0.4930335681368835, "train/adv_std": 0.07292551248177995, "train/cont_avg": 0.9946609831204379, "train/cont_loss_mean": 0.0003726240446850754, "train/cont_loss_std": 0.010632210799075684, "train/cont_neg_acc": 0.9861140098885028, "train/cont_neg_loss": 0.031126700642651314, "train/cont_pos_acc": 0.9999497685119183, "train/cont_pos_loss": 0.00020541538864385752, "train/cont_pred": 0.9946720974288717, "train/cont_rate": 0.9946609831204379, "train/dyn_loss_mean": 14.794370908806794, "train/dyn_loss_std": 8.871915535335123, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8998841282225003, "train/extr_critic_critic_opt_grad_steps": 19660.0, "train/extr_critic_critic_opt_loss": 15990.53856352646, "train/extr_critic_mag": 5.470690093771385, "train/extr_critic_max": 5.470690093771385, "train/extr_critic_mean": 1.0802534527152123, "train/extr_critic_min": -0.20217790481817982, "train/extr_critic_std": 1.2150418310269822, "train/extr_return_normed_mag": 1.864959260843096, "train/extr_return_normed_max": 1.864959260843096, "train/extr_return_normed_mean": 0.30290840848954054, "train/extr_return_normed_min": -0.15577351277435783, "train/extr_return_normed_std": 0.338915029798981, "train/extr_return_rate": 0.5076495274140017, "train/extr_return_raw_mag": 6.878725935942935, "train/extr_return_raw_max": 6.878725935942935, "train/extr_return_raw_mean": 1.0972063019327873, "train/extr_return_raw_min": -0.6005007150399424, "train/extr_return_raw_std": 1.2543693985382136, "train/extr_reward_mag": 1.0129209452301917, "train/extr_reward_max": 1.0129209452301917, "train/extr_reward_mean": 0.02722884977005259, "train/extr_reward_min": -0.4745429954389586, "train/extr_reward_std": 0.1516633939242711, "train/image_loss_mean": 9.057132929781057, "train/image_loss_std": 13.1342742321265, "train/model_loss_mean": 17.988602123121275, "train/model_loss_std": 16.764645840999854, "train/model_opt_grad_norm": 68.98767643949411, "train/model_opt_grad_steps": 19639.284671532845, "train/model_opt_loss": 11849.140682025547, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 656.9343065693431, "train/policy_entropy_mag": 2.5282979707648283, "train/policy_entropy_max": 2.5282979707648283, "train/policy_entropy_mean": 0.6565888628472377, "train/policy_entropy_min": 0.07937524076143321, "train/policy_entropy_std": 0.6556505223695379, "train/policy_logprob_mag": 7.438382973636154, "train/policy_logprob_max": -0.009455833686039831, "train/policy_logprob_mean": -0.6569782839204273, "train/policy_logprob_min": -7.438382973636154, "train/policy_logprob_std": 1.1586154220748122, "train/policy_randomness_mag": 0.8923782327749433, "train/policy_randomness_max": 0.8923782327749433, "train/policy_randomness_mean": 0.23174705524949263, "train/policy_randomness_min": 0.028015976336641903, "train/policy_randomness_std": 0.23141586019174895, "train/post_ent_mag": 55.9016791016516, "train/post_ent_max": 55.9016791016516, "train/post_ent_mean": 38.81658183745224, "train/post_ent_min": 20.24341258863463, "train/post_ent_std": 6.786241419994048, "train/prior_ent_mag": 65.12761376373959, "train/prior_ent_max": 65.12761376373959, "train/prior_ent_mean": 53.66490925141495, "train/prior_ent_min": 36.04540386339173, "train/prior_ent_std": 4.972423765781152, "train/rep_loss_mean": 14.794370908806794, "train/rep_loss_std": 8.871915535335123, "train/reward_avg": 0.02424441149159178, "train/reward_loss_mean": 0.05447431044639462, "train/reward_loss_std": 0.25356344922180596, "train/reward_max_data": 1.0116788349012389, "train/reward_max_pred": 1.0043339015793626, "train/reward_neg_acc": 0.9927572046753264, "train/reward_neg_loss": 0.030021980697166745, "train/reward_pos_acc": 0.962054666376462, "train/reward_pos_loss": 0.8750451851065142, "train/reward_pred": 0.023831828116663616, "train/reward_rate": 0.02904026003649635, "train_stats/sum_log_reward": 6.436283198078121, "train_stats/max_log_achievement_collect_coal": 0.061946902654867256, "train_stats/max_log_achievement_collect_drink": 6.9734513274336285, "train_stats/max_log_achievement_collect_sapling": 2.424778761061947, "train_stats/max_log_achievement_collect_stone": 0.7964601769911505, "train_stats/max_log_achievement_collect_wood": 7.398230088495575, "train_stats/max_log_achievement_defeat_skeleton": 0.02654867256637168, "train_stats/max_log_achievement_defeat_zombie": 0.4247787610619469, "train_stats/max_log_achievement_eat_cow": 0.10619469026548672, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1415929203539823, "train_stats/max_log_achievement_make_wood_sword": 0.45132743362831856, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.230088495575221, "train_stats/max_log_achievement_place_stone": 0.035398230088495575, "train_stats/max_log_achievement_place_table": 2.309734513274336, "train_stats/max_log_achievement_wake_up": 1.3716814159292035, "train_stats/mean_log_entropy": 0.5895995268252043, "eval_stats/sum_log_reward": 5.474999949336052, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 5.375, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 1.3125, "eval_stats/max_log_achievement_collect_wood": 6.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.5625, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.990234375, "report/cont_loss_mean": 0.002740447875112295, "report/cont_loss_std": 0.05609847605228424, "report/cont_neg_acc": 0.9000000357627869, "report/cont_neg_loss": 0.13578687608242035, "report/cont_pos_acc": 0.9990138411521912, "report/cont_pos_loss": 0.0014283527852967381, "report/cont_pred": 0.9900354146957397, "report/cont_rate": 0.990234375, "report/dyn_loss_mean": 14.105640411376953, "report/dyn_loss_std": 8.671472549438477, "report/image_loss_mean": 7.95058536529541, "report/image_loss_std": 10.590901374816895, "report/model_loss_mean": 16.47771644592285, "report/model_loss_std": 14.323046684265137, "report/post_ent_mag": 54.12602996826172, "report/post_ent_max": 54.12602996826172, "report/post_ent_mean": 40.060604095458984, "report/post_ent_min": 22.31607437133789, "report/post_ent_std": 6.5070881843566895, "report/prior_ent_mag": 65.20166015625, "report/prior_ent_max": 65.20166015625, "report/prior_ent_mean": 54.009761810302734, "report/prior_ent_min": 38.03009033203125, "report/prior_ent_std": 4.789848327636719, "report/rep_loss_mean": 14.105640411376953, "report/rep_loss_std": 8.671472549438477, "report/reward_avg": 0.02509765513241291, "report/reward_loss_mean": 0.06100594252347946, "report/reward_loss_std": 0.24584649503231049, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.027055025100708, "report/reward_neg_acc": 0.9939393401145935, "report/reward_neg_loss": 0.03634347766637802, "report/reward_pos_acc": 0.9705882668495178, "report/reward_pos_loss": 0.7791189551353455, "report/reward_pred": 0.024357939139008522, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 5.986744872643612e-05, "eval/cont_loss_std": 0.0018884375458583236, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.010133720003068447, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.930809609504649e-07, "eval/cont_pred": 0.9941979050636292, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.729434967041016, "eval/dyn_loss_std": 9.27169418334961, "eval/image_loss_mean": 21.979116439819336, "eval/image_loss_std": 22.553287506103516, "eval/model_loss_mean": 33.285682678222656, "eval/model_loss_std": 26.11381721496582, "eval/post_ent_mag": 56.04690933227539, "eval/post_ent_max": 56.04690933227539, "eval/post_ent_mean": 39.28164291381836, "eval/post_ent_min": 22.868457794189453, "eval/post_ent_std": 6.702132701873779, "eval/prior_ent_mag": 65.20166015625, "eval/prior_ent_max": 65.20166015625, "eval/prior_ent_mean": 54.75849533081055, "eval/prior_ent_min": 35.06327819824219, "eval/prior_ent_std": 4.956309795379639, "eval/rep_loss_mean": 18.729434967041016, "eval/rep_loss_std": 9.27169418334961, "eval/reward_avg": 0.01435546949505806, "eval/reward_loss_mean": 0.0688461884856224, "eval/reward_loss_std": 0.4251594841480255, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0001661777496338, "eval/reward_neg_acc": 0.9980080127716064, "eval/reward_neg_loss": 0.036805830895900726, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 1.6772722005844116, "eval/reward_pred": 0.008622696623206139, "eval/reward_rate": 0.01953125, "replay/size": 326529.0, "replay/inserts": 21872.0, "replay/samples": 21872.0, "replay/insert_wait_avg": 1.3384556543591602e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.326858446557939e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 63984.0, "eval_replay/inserts": 4312.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.14476304770843e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4305353164673, "timer/env.step_count": 2734.0, "timer/env.step_total": 262.12401056289673, "timer/env.step_frac": 0.262011205485625, "timer/env.step_avg": 0.09587564395131555, "timer/env.step_min": 0.02268195152282715, "timer/env.step_max": 4.289994239807129, "timer/replay._sample_count": 21872.0, "timer/replay._sample_total": 11.142116069793701, "timer/replay._sample_frac": 0.011137321059746646, "timer/replay._sample_avg": 0.0005094237413036623, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.00997018814086914, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3273.0, "timer/agent.policy_total": 52.94466543197632, "timer/agent.policy_frac": 0.05292188069332397, "timer/agent.policy_avg": 0.016176188644050203, "timer/agent.policy_min": 0.009295225143432617, "timer/agent.policy_max": 0.13591575622558594, "timer/dataset_train_count": 1367.0, "timer/dataset_train_total": 0.14832448959350586, "timer/dataset_train_frac": 0.00014826065814413212, "timer/dataset_train_avg": 0.0001085036500318258, "timer/dataset_train_min": 9.393692016601562e-05, "timer/dataset_train_max": 0.0005509853363037109, "timer/agent.train_count": 1367.0, "timer/agent.train_total": 616.8438827991486, "timer/agent.train_frac": 0.6165784240122395, "timer/agent.train_avg": 0.45123912421298357, "timer/agent.train_min": 0.4360203742980957, "timer/agent.train_max": 1.54512619972229, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.48056721687316895, "timer/agent.report_frac": 0.0004803604047542897, "timer/agent.report_avg": 0.24028360843658447, "timer/agent.report_min": 0.23291969299316406, "timer/agent.report_max": 0.24764752388000488, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7168021224962245e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 21.86229338659297}
{"step": 327152, "time": 15323.602221250534, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 327160, "time": 15325.689080238342, "episode/length": 231.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9870689655172413, "episode/intrinsic_return": 0.0}
{"step": 327272, "time": 15331.6606695652, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972027972027972, "episode/intrinsic_return": 0.0}
{"step": 327352, "time": 15336.506366729736, "episode/length": 268.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 327456, "time": 15342.415541410446, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 327792, "time": 15357.579624891281, "episode/length": 64.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 327888, "time": 15362.831466197968, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 328024, "time": 15369.197148323059, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 328296, "time": 15379.92213344574, "episode/length": 176.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 328512, "time": 15388.849888086319, "episode/length": 168.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 328696, "time": 15396.469720125198, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 328752, "time": 15400.324676275253, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 328984, "time": 15409.305078029633, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 329104, "time": 15414.95290350914, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 329424, "time": 15427.043745279312, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 329736, "time": 15438.803700447083, "episode/length": 213.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 329752, "time": 15440.911805152893, "episode/length": 299.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 329896, "time": 15447.355322599411, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 329944, "time": 15450.621609687805, "episode/length": 205.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 330096, "time": 15478.828159332275, "eval_episode/length": 162.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 330096, "time": 15480.947668075562, "eval_episode/length": 174.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 330096, "time": 15483.219450235367, "eval_episode/length": 193.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948453608247423}
{"step": 330096, "time": 15485.401711463928, "eval_episode/length": 205.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 330096, "time": 15487.087952375412, "eval_episode/length": 207.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 330096, "time": 15490.597876787186, "eval_episode/length": 44.0, "eval_episode/score": 1.1000000089406967, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 330096, "time": 15493.239697694778, "eval_episode/length": 274.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 330096, "time": 15496.558438777924, "eval_episode/length": 119.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9583333333333334}
{"step": 330136, "time": 15497.666503667831, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 330160, "time": 15500.210866451263, "episode/length": 52.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 330256, "time": 15505.060404777527, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 330304, "time": 15508.154430627823, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 330984, "time": 15532.13549208641, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 331360, "time": 15546.43013548851, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 331440, "time": 15550.73248410225, "episode/length": 210.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 331520, "time": 15555.040330171585, "episode/length": 157.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 331592, "time": 15558.74752831459, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 331632, "time": 15561.88458275795, "episode/length": 210.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 331680, "time": 15565.031821250916, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 331736, "time": 15568.204485654831, "episode/length": 196.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 332312, "time": 15588.984086990356, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 332936, "time": 15611.268571853638, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 333032, "time": 15616.0450360775, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 333112, "time": 15620.25353193283, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 333112, "time": 15620.263570547104, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 333200, "time": 15626.60500407219, "episode/length": 200.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 333560, "time": 15640.026581525803, "episode/length": 227.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 333568, "time": 15642.23997926712, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 333912, "time": 15654.96304821968, "episode/length": 43.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 334032, "time": 15660.67904162407, "episode/length": 136.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 334248, "time": 15669.134038686752, "episode/length": 326.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 334504, "time": 15679.359223604202, "episode/length": 173.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 334584, "time": 15683.659381866455, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 334816, "time": 15693.365975141525, "episode/length": 212.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 334984, "time": 15700.905537128448, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 335464, "time": 15718.42139840126, "episode/length": 151.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 335488, "time": 15721.14361834526, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 335520, "time": 15723.77879524231, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9871382636655949, "episode/intrinsic_return": 0.0}
{"step": 335664, "time": 15730.134331941605, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 336064, "time": 15746.150012493134, "episode/length": 194.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 336296, "time": 15755.192150354385, "episode/length": 213.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 336480, "time": 15763.104057788849, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 336872, "time": 15777.403346776962, "episode/length": 175.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 336912, "time": 15780.499763250351, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 336912, "time": 15780.51085138321, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 337200, "time": 15793.420095682144, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 337336, "time": 15799.253244876862, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 337992, "time": 15822.980639457703, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 338000, "time": 15825.46682047844, "episode/length": 291.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 338024, "time": 15828.110342741013, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 338168, "time": 15835.122692346573, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 338352, "time": 15843.600366830826, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 338584, "time": 15852.624646186829, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 338608, "time": 15855.107720375061, "episode/length": 211.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 339248, "time": 15877.737037658691, "episode/length": 155.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 339384, "time": 15883.670128583908, "episode/length": 173.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 339504, "time": 15889.395322799683, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 339760, "time": 15899.445976734161, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 339768, "time": 15901.04758810997, "episode/length": 147.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 340080, "time": 15933.829433441162, "eval_episode/length": 158.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 340080, "time": 15936.679275989532, "eval_episode/length": 174.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 340080, "time": 15938.785897493362, "eval_episode/length": 178.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9832402234636871}
{"step": 340080, "time": 15941.114030361176, "eval_episode/length": 179.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 340080, "time": 15943.189488172531, "eval_episode/length": 181.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.967032967032967}
{"step": 340080, "time": 15945.835717916489, "eval_episode/length": 191.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 340080, "time": 15948.753656625748, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9672897196261683}
{"step": 340080, "time": 15950.507568597794, "eval_episode/length": 217.0, "eval_episode/score": 6.0999999940395355, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 340152, "time": 15952.688549995422, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 340768, "time": 15975.035363912582, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 340784, "time": 15977.623392820358, "episode/length": 430.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791183294663574, "episode/intrinsic_return": 0.0}
{"step": 340960, "time": 15985.527153015137, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 340984, "time": 15987.696062326431, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 341232, "time": 15997.701162815094, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 341600, "time": 16011.838856935501, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 341760, "time": 16018.933483839035, "episode/length": 200.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 341784, "time": 16021.055240869522, "episode/length": 451.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9800884955752213, "episode/intrinsic_return": 0.0}
{"step": 342040, "time": 16031.245828390121, "episode/length": 158.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 342200, "time": 16038.240889549255, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 342312, "time": 16043.470139741898, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 342432, "time": 16049.232780218124, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 343032, "time": 16070.631309509277, "episode/length": 255.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765625, "episode/intrinsic_return": 0.0}
{"step": 343304, "time": 16081.197650432587, "episode/length": 192.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 343464, "time": 16088.18741941452, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 343576, "time": 16093.673027276993, "episode/length": 246.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9838056680161943, "episode/intrinsic_return": 0.0}
{"step": 343720, "time": 16100.605284690857, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 343728, "time": 16103.306514024734, "episode/length": 161.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 343904, "time": 16111.559274196625, "episode/length": 232.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 344384, "time": 16131.223685503006, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 344816, "time": 16147.791248321533, "episode/length": 188.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 345008, "time": 16155.72693657875, "episode/length": 192.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 345104, "time": 16160.602470874786, "episode/length": 414.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9783132530120482, "episode/intrinsic_return": 0.0}
{"step": 345216, "time": 16166.41927075386, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 345240, "time": 16169.042233467102, "episode/length": 207.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 345448, "time": 16178.25195646286, "episode/length": 42.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 345512, "time": 16182.360511779785, "episode/length": 222.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 345800, "time": 16193.544095277786, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 346312, "time": 16212.082946300507, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 346584, "time": 16222.696587324142, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 346704, "time": 16228.481167078018, "episode/length": 211.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 346712, "time": 16230.107166051865, "episode/length": 350.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 346824, "time": 16235.376924991608, "episode/length": 197.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 347392, "time": 16256.18125963211, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 347536, "time": 16262.620264053345, "episode/length": 260.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 347552, "time": 16264.713705301285, "episode/length": 154.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 348144, "time": 16286.027782678604, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 348456, "time": 16297.963636398315, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9656862745098039, "episode/intrinsic_return": 0.0}
{"step": 348472, "time": 16300.693707942963, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 348480, "time": 16303.037631750107, "episode/length": 220.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 348552, "time": 16306.697090864182, "episode/length": 50.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 348873, "time": 16319.958544254303, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.522052091710708, "train/action_min": 0.0, "train/action_std": 3.550161056658801, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.044002372470191294, "train/actor_opt_grad_steps": 21025.0, "train/actor_opt_loss": 3.1881861332256127, "train/adv_mag": 0.6888056649442982, "train/adv_max": 0.6714611515841064, "train/adv_mean": 0.005244302680680716, "train/adv_min": -0.4721764941864154, "train/adv_std": 0.07200662917731439, "train/cont_avg": 0.9945211971507353, "train/cont_loss_mean": 0.00025357144577435354, "train/cont_loss_std": 0.00734218696647852, "train/cont_neg_acc": 0.9909751415252686, "train/cont_neg_loss": 0.029061827565375526, "train/cont_pos_acc": 0.9999710961299784, "train/cont_pos_loss": 9.85218103303797e-05, "train/cont_pred": 0.9945335077012286, "train/cont_rate": 0.9945211971507353, "train/dyn_loss_mean": 14.724301843082204, "train/dyn_loss_std": 8.900927901268005, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9272572946022538, "train/extr_critic_critic_opt_grad_steps": 21025.0, "train/extr_critic_critic_opt_loss": 15881.597268497242, "train/extr_critic_mag": 5.631825517205631, "train/extr_critic_max": 5.631825517205631, "train/extr_critic_mean": 1.2457478804623379, "train/extr_critic_min": -0.19793602122980006, "train/extr_critic_std": 1.2817327643142027, "train/extr_return_normed_mag": 1.8457426051883137, "train/extr_return_normed_max": 1.8457426051883137, "train/extr_return_normed_mean": 0.3242921018425156, "train/extr_return_normed_min": -0.15587550368817413, "train/extr_return_normed_std": 0.34173697824863825, "train/extr_return_rate": 0.5920037064043915, "train/extr_return_raw_mag": 7.155641131541309, "train/extr_return_raw_max": 7.155641131541309, "train/extr_return_raw_mean": 1.2660118096015032, "train/extr_return_raw_min": -0.5944682657718658, "train/extr_return_raw_std": 1.3232987843015616, "train/extr_reward_mag": 1.012399286031723, "train/extr_reward_max": 1.012399286031723, "train/extr_reward_mean": 0.02787215553004952, "train/extr_reward_min": -0.4453204186523662, "train/extr_reward_std": 0.1531207220738425, "train/image_loss_mean": 9.033121249255013, "train/image_loss_std": 13.293341836508583, "train/model_loss_mean": 17.923933590159695, "train/model_loss_std": 16.89996478136848, "train/model_opt_grad_norm": 69.11422275094425, "train/model_opt_grad_steps": 21003.29411764706, "train/model_opt_loss": 14323.033992991728, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 799.6323529411765, "train/policy_entropy_mag": 2.5250241212985096, "train/policy_entropy_max": 2.5250241212985096, "train/policy_entropy_mean": 0.5999317690730095, "train/policy_entropy_min": 0.07937522550277851, "train/policy_entropy_std": 0.6052485176307314, "train/policy_logprob_mag": 7.438383165527792, "train/policy_logprob_max": -0.009455793235889253, "train/policy_logprob_mean": -0.5996676247347804, "train/policy_logprob_min": -7.438383165527792, "train/policy_logprob_std": 1.1240184473640777, "train/policy_randomness_mag": 0.8912227048593409, "train/policy_randomness_max": 0.8912227048593409, "train/policy_randomness_mean": 0.2117495857836569, "train/policy_randomness_min": 0.028015971005729893, "train/policy_randomness_std": 0.21362616603865342, "train/post_ent_mag": 56.04462317859425, "train/post_ent_max": 56.04462317859425, "train/post_ent_mean": 39.05215235317455, "train/post_ent_min": 20.373352941344766, "train/post_ent_std": 6.854035857845755, "train/prior_ent_mag": 65.36607977923225, "train/prior_ent_max": 65.36607977923225, "train/prior_ent_mean": 53.828486498664404, "train/prior_ent_min": 35.73856543092167, "train/prior_ent_std": 4.9614490954314965, "train/rep_loss_mean": 14.724301843082204, "train/rep_loss_std": 8.900927901268005, "train/reward_avg": 0.0238022747079787, "train/reward_loss_mean": 0.055977849988266826, "train/reward_loss_std": 0.26514851126600714, "train/reward_max_data": 1.0147058858590967, "train/reward_max_pred": 1.0090092911439783, "train/reward_neg_acc": 0.9932524894966799, "train/reward_neg_loss": 0.030656841850620422, "train/reward_pos_acc": 0.9587227671461946, "train/reward_pos_loss": 0.9122472295866293, "train/reward_pred": 0.022995996377978695, "train/reward_rate": 0.028693704044117647, "train_stats/sum_log_reward": 6.171428516507149, "train_stats/max_log_achievement_collect_coal": 0.008928571428571428, "train_stats/max_log_achievement_collect_drink": 6.857142857142857, "train_stats/max_log_achievement_collect_sapling": 2.125, "train_stats/max_log_achievement_collect_stone": 0.30357142857142855, "train_stats/max_log_achievement_collect_wood": 8.133928571428571, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.4375, "train_stats/max_log_achievement_eat_cow": 0.10714285714285714, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.24107142857142858, "train_stats/max_log_achievement_make_wood_sword": 1.9285714285714286, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.9464285714285714, "train_stats/max_log_achievement_place_stone": 0.017857142857142856, "train_stats/max_log_achievement_place_table": 2.330357142857143, "train_stats/max_log_achievement_wake_up": 1.3214285714285714, "train_stats/mean_log_entropy": 0.5598079093864986, "eval_stats/sum_log_reward": 5.662499964237213, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.9375, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 0.25, "eval_stats/max_log_achievement_collect_wood": 6.4375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.25, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.00017929135356098413, "report/cont_loss_std": 0.00560423731803894, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 7.91364709584741e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 0.00018047093180939555, "report/cont_pred": 0.9929996728897095, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 16.02821159362793, "report/dyn_loss_std": 8.842692375183105, "report/image_loss_mean": 9.12101936340332, "report/image_loss_std": 18.19001579284668, "report/model_loss_mean": 18.788482666015625, "report/model_loss_std": 21.049646377563477, "report/post_ent_mag": 56.493343353271484, "report/post_ent_max": 56.493343353271484, "report/post_ent_mean": 39.04365158081055, "report/post_ent_min": 20.816370010375977, "report/post_ent_std": 7.280680179595947, "report/prior_ent_mag": 65.20136260986328, "report/prior_ent_max": 65.20136260986328, "report/prior_ent_mean": 55.287899017333984, "report/prior_ent_min": 37.69226837158203, "report/prior_ent_std": 4.608592987060547, "report/rep_loss_mean": 16.02821159362793, "report/rep_loss_std": 8.842692375183105, "report/reward_avg": 0.01064453087747097, "report/reward_loss_mean": 0.05035580322146416, "report/reward_loss_std": 0.19248558580875397, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0034689903259277, "report/reward_neg_acc": 0.9930418133735657, "report/reward_neg_loss": 0.037293341010808945, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7804026007652283, "report/reward_pred": 0.011232582852244377, "report/reward_rate": 0.017578125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.004226678982377052, "eval/cont_loss_std": 0.09722930192947388, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 3.108943928964436e-06, "eval/cont_pos_acc": 0.9980430603027344, "eval/cont_pos_loss": 0.004234944470226765, "eval/cont_pred": 0.9963359832763672, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 18.140178680419922, "eval/dyn_loss_std": 10.44408893585205, "eval/image_loss_mean": 14.989603042602539, "eval/image_loss_std": 20.544832229614258, "eval/model_loss_mean": 25.981754302978516, "eval/model_loss_std": 24.570310592651367, "eval/post_ent_mag": 54.84961700439453, "eval/post_ent_max": 54.84961700439453, "eval/post_ent_mean": 38.38374328613281, "eval/post_ent_min": 21.541996002197266, "eval/post_ent_std": 6.273738384246826, "eval/prior_ent_mag": 65.20136260986328, "eval/prior_ent_max": 65.20136260986328, "eval/prior_ent_mean": 54.067604064941406, "eval/prior_ent_min": 37.696929931640625, "eval/prior_ent_std": 4.84216833114624, "eval/rep_loss_mean": 18.140178680419922, "eval/rep_loss_std": 10.44408893585205, "eval/reward_avg": 0.03369140625, "eval/reward_loss_mean": 0.1038171574473381, "eval/reward_loss_std": 0.6371189951896667, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9998831748962402, "eval/reward_neg_acc": 0.9898682236671448, "eval/reward_neg_loss": 0.040933094918727875, "eval/reward_pos_acc": 0.8108108043670654, "eval/reward_pos_loss": 1.7812917232513428, "eval/reward_pred": 0.030891336500644684, "eval/reward_rate": 0.0361328125, "replay/size": 348369.0, "replay/inserts": 21840.0, "replay/samples": 21840.0, "replay/insert_wait_avg": 1.3099594430609064e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.354077838716053e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 68240.0, "eval_replay/inserts": 4256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1925410507316877e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4558320045471, "timer/env.step_count": 2730.0, "timer/env.step_total": 260.9785678386688, "timer/env.step_frac": 0.26085965965710184, "timer/env.step_avg": 0.09559654499584938, "timer/env.step_min": 0.022350072860717773, "timer/env.step_max": 3.3833491802215576, "timer/replay._sample_count": 21840.0, "timer/replay._sample_total": 11.073320865631104, "timer/replay._sample_frac": 0.011068275591381405, "timer/replay._sample_avg": 0.0005070201861552703, "timer/replay._sample_min": 0.000347137451171875, "timer/replay._sample_max": 0.011748075485229492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3262.0, "timer/agent.policy_total": 53.863173484802246, "timer/agent.policy_frac": 0.053838632113204006, "timer/agent.policy_avg": 0.016512315599264943, "timer/agent.policy_min": 0.009289979934692383, "timer/agent.policy_max": 0.11034917831420898, "timer/dataset_train_count": 1365.0, "timer/dataset_train_total": 0.14465808868408203, "timer/dataset_train_frac": 0.00014459217894131337, "timer/dataset_train_avg": 0.00010597662174658025, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.00036072731018066406, "timer/agent.train_count": 1365.0, "timer/agent.train_total": 614.4586071968079, "timer/agent.train_frac": 0.6141786449139467, "timer/agent.train_avg": 0.4501528257852072, "timer/agent.train_min": 0.4359009265899658, "timer/agent.train_max": 1.613558053970337, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4782137870788574, "timer/agent.report_frac": 0.00047799590124902576, "timer/agent.report_avg": 0.2391068935394287, "timer/agent.report_min": 0.23363065719604492, "timer/agent.report_max": 0.2445831298828125, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.78822641265347e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 21.829730189467348}
{"step": 348936, "time": 16321.933615922928, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 348968, "time": 16324.680767059326, "episode/length": 431.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 349088, "time": 16330.502747297287, "episode/length": 191.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 349736, "time": 16353.331626653671, "episode/length": 156.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 349800, "time": 16357.137175798416, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 350064, "time": 16387.460255146027, "eval_episode/length": 159.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 350064, "time": 16389.722497463226, "eval_episode/length": 171.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 350064, "time": 16391.363838911057, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9770114942528736}
{"step": 350064, "time": 16391.372805833817, "eval_episode/length": 173.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 350064, "time": 16391.37956380844, "eval_episode/length": 173.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 350064, "time": 16397.36762070656, "eval_episode/length": 188.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 350064, "time": 16399.10368847847, "eval_episode/length": 192.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 350064, "time": 16401.26629638672, "eval_episode/length": 205.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 350144, "time": 16403.92980504036, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 350296, "time": 16410.2849881649, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 350472, "time": 16417.72577738762, "episode/length": 191.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 350480, "time": 16419.923149347305, "episode/length": 188.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 350600, "time": 16425.240984916687, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 350896, "time": 16436.94422841072, "episode/length": 437.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 351168, "time": 16447.58601117134, "episode/length": 170.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 351240, "time": 16451.386684417725, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 351464, "time": 16460.25836467743, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 351488, "time": 16462.957205295563, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 351632, "time": 16469.37073135376, "episode/length": 143.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 351984, "time": 16482.752680301666, "episode/length": 172.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 352208, "time": 16491.77528166771, "episode/length": 216.0, "episode/score": 6.100000016391277, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 352352, "time": 16499.512437582016, "episode/length": 181.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 352560, "time": 16507.968980789185, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 352776, "time": 16516.596085071564, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 352864, "time": 16521.22645664215, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 353240, "time": 16534.976950883865, "episode/length": 258.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9922779922779923, "episode/intrinsic_return": 0.0}
{"step": 353280, "time": 16538.06490468979, "episode/length": 205.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 353520, "time": 16547.539679288864, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 353528, "time": 16549.11200237274, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 353784, "time": 16559.10605072975, "episode/length": 178.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 354144, "time": 16572.781707048416, "episode/length": 197.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 354200, "time": 16575.92212343216, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 354248, "time": 16579.01576757431, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 354712, "time": 16595.793614149094, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 354824, "time": 16601.236454725266, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 354904, "time": 16605.428355693817, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 355160, "time": 16615.42205309868, "episode/length": 204.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 355200, "time": 16618.497101306915, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 355424, "time": 16627.41786289215, "episode/length": 74.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 355632, "time": 16635.967230558395, "episode/length": 58.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 355760, "time": 16641.70652937889, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 356088, "time": 16653.97947382927, "episode/length": 235.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 356168, "time": 16658.115170240402, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 356208, "time": 16661.28767800331, "episode/length": 257.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 356376, "time": 16668.191182613373, "episode/length": 207.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 356920, "time": 16687.841698408127, "episode/length": 160.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 356928, "time": 16690.09240245819, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 356976, "time": 16693.20828104019, "episode/length": 221.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 357176, "time": 16701.105805158615, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9548022598870056, "episode/intrinsic_return": 0.0}
{"step": 357424, "time": 16711.13507580757, "episode/length": 30.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.8709677419354839, "episode/intrinsic_return": 0.0}
{"step": 357432, "time": 16712.809414863586, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 357656, "time": 16721.791763305664, "episode/length": 185.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 357936, "time": 16732.991285800934, "episode/length": 194.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 358200, "time": 16743.21426177025, "episode/length": 248.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 358224, "time": 16746.307767391205, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 358456, "time": 16755.80281829834, "episode/length": 191.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 358888, "time": 16771.745930671692, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 358984, "time": 16776.571178913116, "episode/length": 250.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 359152, "time": 16783.894830465317, "episode/length": 186.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 359736, "time": 16804.68623161316, "episode/length": 287.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 359816, "time": 16808.892634391785, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 359816, "time": 16808.900851726532, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 359824, "time": 16812.752563238144, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 360048, "time": 16836.47157549858, "eval_episode/length": 49.0, "eval_episode/score": 3.0999999791383743, "eval_episode/reward_rate": 0.98}
{"step": 360048, "time": 16836.47979736328, "eval_episode/length": 49.0, "eval_episode/score": 2.0999999940395355, "eval_episode/reward_rate": 0.98}
{"step": 360048, "time": 16840.19661450386, "eval_episode/length": 57.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 360048, "time": 16845.885315656662, "eval_episode/length": 164.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 360048, "time": 16847.842418193817, "eval_episode/length": 173.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 360048, "time": 16849.96135854721, "eval_episode/length": 188.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 360048, "time": 16852.264147043228, "eval_episode/length": 206.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 360048, "time": 16854.209721565247, "eval_episode/length": 165.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9759036144578314}
{"step": 360336, "time": 16863.680998325348, "episode/length": 266.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9887640449438202, "episode/intrinsic_return": 0.0}
{"step": 360640, "time": 16876.853727579117, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 360944, "time": 16888.362416505814, "episode/length": 150.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 360952, "time": 16889.963498353958, "episode/length": 224.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 361120, "time": 16897.49868798256, "episode/length": 278.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 361128, "time": 16899.69106245041, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 361200, "time": 16904.30251455307, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 361368, "time": 16911.238219499588, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 361792, "time": 16927.028702020645, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 362224, "time": 16942.899881124496, "episode/length": 159.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 362432, "time": 16951.4074113369, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 362576, "time": 16957.72034406662, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 362768, "time": 16965.68037891388, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 362832, "time": 16969.43247127533, "episode/length": 273.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 362848, "time": 16971.549080371857, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 363152, "time": 16983.07956790924, "episode/length": 243.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 363216, "time": 16986.87068462372, "episode/length": 45.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 363240, "time": 16989.04319882393, "episode/length": 50.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 363248, "time": 16991.187371730804, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 363536, "time": 17002.26228070259, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 363696, "time": 17009.08093380928, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 363840, "time": 17015.401317834854, "episode/length": 157.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 364032, "time": 17023.45841884613, "episode/length": 157.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9936708860759493, "episode/intrinsic_return": 0.0}
{"step": 364424, "time": 17037.734204769135, "episode/length": 150.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 364792, "time": 17051.6278924942, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 364808, "time": 17053.81402540207, "episode/length": 195.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 364904, "time": 17058.61475253105, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 365184, "time": 17069.659062623978, "episode/length": 241.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 365344, "time": 17076.603979587555, "episode/length": 187.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 365368, "time": 17078.72209262848, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 366096, "time": 17104.543978452682, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 366232, "time": 17110.447860479355, "episode/length": 177.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 366360, "time": 17116.293823242188, "episode/length": 181.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 366400, "time": 17119.478105545044, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 366640, "time": 17128.97678899765, "episode/length": 161.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 366640, "time": 17128.986608743668, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9783393501805054, "episode/intrinsic_return": 0.0}
{"step": 366888, "time": 17140.432750463486, "episode/length": 189.0, "episode/score": 7.100000016391277, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 367576, "time": 17164.60852265358, "episode/length": 504.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.998019801980198, "episode/intrinsic_return": 0.0}
{"step": 367832, "time": 17174.686569452286, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 367864, "time": 17177.257573843002, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 367888, "time": 17179.791385412216, "episode/length": 206.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 367888, "time": 17179.80287837982, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 368128, "time": 17191.225124120712, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 368512, "time": 17205.995124340057, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 368520, "time": 17207.584956407547, "episode/length": 234.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 368888, "time": 17222.808043718338, "episode/length": 45.0, "episode/score": 3.100000023841858, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 368920, "time": 17226.012102127075, "episode/length": 128.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9612403100775194, "episode/intrinsic_return": 0.0}
{"step": 369064, "time": 17233.05083489418, "episode/length": 185.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9623655913978495, "episode/intrinsic_return": 0.0}
{"step": 369152, "time": 17238.057612657547, "episode/length": 164.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 369368, "time": 17246.568578243256, "episode/length": 187.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 369400, "time": 17249.267456293106, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 369816, "time": 17264.63543534279, "episode/length": 210.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 370032, "time": 17287.946573019028, "eval_episode/length": 37.0, "eval_episode/score": 0.09999998658895493, "eval_episode/reward_rate": 0.868421052631579}
{"step": 370032, "time": 17294.167828798294, "eval_episode/length": 151.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 370032, "time": 17296.409975528717, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 370032, "time": 17298.0606341362, "eval_episode/length": 168.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 370032, "time": 17299.738495111465, "eval_episode/length": 172.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9826589595375722}
{"step": 370032, "time": 17301.708763599396, "eval_episode/length": 183.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 370032, "time": 17303.383047103882, "eval_episode/length": 188.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 370032, "time": 17307.61264896393, "eval_episode/length": 180.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9779005524861878}
{"step": 370168, "time": 17311.93705058098, "episode/length": 155.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 370184, "time": 17314.063292980194, "episode/length": 208.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 370297, "time": 17320.391654253006, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.574594070662314, "train/action_min": 0.0, "train/action_std": 3.6358558206415887, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04319583471697658, "train/actor_opt_grad_steps": 22375.0, "train/actor_opt_loss": 2.0763818632755706, "train/adv_mag": 0.6584785831953163, "train/adv_max": 0.6264486997874815, "train/adv_mean": 0.005087542076662023, "train/adv_min": -0.4920859098879259, "train/adv_std": 0.06924115885883125, "train/cont_avg": 0.9945414528917911, "train/cont_loss_mean": 0.0003063637268127619, "train/cont_loss_std": 0.008813628613725357, "train/cont_neg_acc": 0.986807038534933, "train/cont_neg_loss": 0.046254410934963415, "train/cont_pos_acc": 0.9999926517258829, "train/cont_pos_loss": 5.560018137024694e-05, "train/cont_pred": 0.994600756399667, "train/cont_rate": 0.9945414528917911, "train/dyn_loss_mean": 14.626963088761515, "train/dyn_loss_std": 8.913866263716969, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8869890099141136, "train/extr_critic_critic_opt_grad_steps": 22375.0, "train/extr_critic_critic_opt_loss": 15777.797727670242, "train/extr_critic_mag": 5.890998495158865, "train/extr_critic_max": 5.890998495158865, "train/extr_critic_mean": 1.3963184338897021, "train/extr_critic_min": -0.16792511940002441, "train/extr_critic_std": 1.3355986008893197, "train/extr_return_normed_mag": 1.7811359273853586, "train/extr_return_normed_max": 1.7811359273853586, "train/extr_return_normed_mean": 0.3306083968326227, "train/extr_return_normed_min": -0.14231020545781548, "train/extr_return_normed_std": 0.33399904719484386, "train/extr_return_rate": 0.6675587254228876, "train/extr_return_raw_mag": 7.387165222594987, "train/extr_return_raw_max": 7.387165222594987, "train/extr_return_raw_mean": 1.417230894761299, "train/extr_return_raw_min": -0.5289413278449827, "train/extr_return_raw_std": 1.374741182843251, "train/extr_reward_mag": 1.0130439391776698, "train/extr_reward_max": 1.0130439391776698, "train/extr_reward_mean": 0.028230811420605698, "train/extr_reward_min": -0.4267000769501302, "train/extr_reward_std": 0.1539989412942929, "train/image_loss_mean": 8.687020682576877, "train/image_loss_std": 12.981736635094258, "train/model_loss_mean": 17.51918321581029, "train/model_loss_std": 16.629335581366696, "train/model_opt_grad_norm": 69.62149440794063, "train/model_opt_grad_steps": 22352.082089552237, "train/model_opt_loss": 12740.731335995803, "train/model_opt_model_opt_grad_overflow": 0.007462686567164179, "train/model_opt_model_opt_grad_scale": 727.6119402985074, "train/policy_entropy_mag": 2.532464079002836, "train/policy_entropy_max": 2.532464079002836, "train/policy_entropy_mean": 0.5986312512141555, "train/policy_entropy_min": 0.0793752176548118, "train/policy_entropy_std": 0.6360368452855011, "train/policy_logprob_mag": 7.4383833301601125, "train/policy_logprob_max": -0.009455788199470114, "train/policy_logprob_mean": -0.5985995671197549, "train/policy_logprob_min": -7.4383833301601125, "train/policy_logprob_std": 1.1238401398729922, "train/policy_randomness_mag": 0.8938486878551654, "train/policy_randomness_max": 0.8938486878551654, "train/policy_randomness_mean": 0.21129056121875991, "train/policy_randomness_min": 0.028015968195204414, "train/policy_randomness_std": 0.22449309679109658, "train/post_ent_mag": 55.96439031344741, "train/post_ent_max": 55.96439031344741, "train/post_ent_mean": 39.288228590097, "train/post_ent_min": 20.440347557637228, "train/post_ent_std": 6.815137286684406, "train/prior_ent_mag": 65.50260338854434, "train/prior_ent_max": 65.50260338854434, "train/prior_ent_mean": 53.95006080171955, "train/prior_ent_min": 36.696599248629894, "train/prior_ent_std": 4.863440086592489, "train/rep_loss_mean": 14.626963088761515, "train/rep_loss_std": 8.913866263716969, "train/reward_avg": 0.0240489447579733, "train/reward_loss_mean": 0.05567860632523227, "train/reward_loss_std": 0.26457437005505635, "train/reward_max_data": 1.0149253766928146, "train/reward_max_pred": 1.0060164732719534, "train/reward_neg_acc": 0.9931149171359503, "train/reward_neg_loss": 0.030176735893169892, "train/reward_pos_acc": 0.9544876066606436, "train/reward_pos_loss": 0.9201851006764085, "train/reward_pred": 0.023119720421842675, "train/reward_rate": 0.0289033348880597, "train_stats/sum_log_reward": 6.126315757893679, "train_stats/max_log_achievement_collect_coal": 0.0, "train_stats/max_log_achievement_collect_drink": 6.245614035087719, "train_stats/max_log_achievement_collect_sapling": 2.3421052631578947, "train_stats/max_log_achievement_collect_stone": 0.2631578947368421, "train_stats/max_log_achievement_collect_wood": 9.280701754385966, "train_stats/max_log_achievement_defeat_skeleton": 0.03508771929824561, "train_stats/max_log_achievement_defeat_zombie": 0.43859649122807015, "train_stats/max_log_achievement_eat_cow": 0.14912280701754385, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.08771929824561403, "train_stats/max_log_achievement_make_wood_sword": 2.245614035087719, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 2.1052631578947367, "train_stats/max_log_achievement_place_stone": 0.0, "train_stats/max_log_achievement_place_table": 2.3333333333333335, "train_stats/max_log_achievement_wake_up": 1.2105263157894737, "train_stats/mean_log_entropy": 0.521503652527667, "eval_stats/sum_log_reward": 5.808333341653149, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 4.166666666666667, "eval_stats/max_log_achievement_collect_sapling": 2.5416666666666665, "eval_stats/max_log_achievement_collect_stone": 0.041666666666666664, "eval_stats/max_log_achievement_collect_wood": 9.958333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.125, "eval_stats/max_log_achievement_make_wood_sword": 2.3333333333333335, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.9583333333333333, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 1.9166666666666667, "eval_stats/max_log_achievement_wake_up": 0.9166666666666666, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.0006003014277666807, "report/cont_loss_std": 0.016263991594314575, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.10319206863641739, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 9.690704609965906e-05, "report/cont_pred": 0.9954168796539307, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.411755561828613, "report/dyn_loss_std": 8.623007774353027, "report/image_loss_mean": 7.4189252853393555, "report/image_loss_std": 13.226263999938965, "report/model_loss_mean": 16.120187759399414, "report/model_loss_std": 16.43152618408203, "report/post_ent_mag": 53.12701416015625, "report/post_ent_max": 53.12701416015625, "report/post_ent_mean": 38.58477783203125, "report/post_ent_min": 20.02602767944336, "report/post_ent_std": 6.370274543762207, "report/prior_ent_mag": 65.31671905517578, "report/prior_ent_max": 65.31671905517578, "report/prior_ent_mean": 53.533538818359375, "report/prior_ent_min": 37.20851135253906, "report/prior_ent_std": 4.310948371887207, "report/rep_loss_mean": 14.411755561828613, "report/rep_loss_std": 8.623007774353027, "report/reward_avg": 0.02851562388241291, "report/reward_loss_mean": 0.053609348833560944, "report/reward_loss_std": 0.2712957561016083, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 0.9993313550949097, "report/reward_neg_acc": 0.9959595203399658, "report/reward_neg_loss": 0.02072366140782833, "report/reward_pos_acc": 0.9117646813392639, "report/reward_pos_loss": 1.0111632347106934, "report/reward_pred": 0.026289360597729683, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.000713592569809407, "eval/cont_loss_std": 0.021386265754699707, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.18257524073123932, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 4.0964172853819036e-07, "eval/cont_pred": 0.9966219067573547, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 18.32857894897461, "eval/dyn_loss_std": 9.572606086730957, "eval/image_loss_mean": 16.505149841308594, "eval/image_loss_std": 19.24519920349121, "eval/model_loss_mean": 27.624958038330078, "eval/model_loss_std": 22.921459197998047, "eval/post_ent_mag": 53.162986755371094, "eval/post_ent_max": 53.162986755371094, "eval/post_ent_mean": 38.00202941894531, "eval/post_ent_min": 20.866031646728516, "eval/post_ent_std": 6.361655235290527, "eval/prior_ent_mag": 65.31671905517578, "eval/prior_ent_max": 65.31671905517578, "eval/prior_ent_mean": 54.54435729980469, "eval/prior_ent_min": 38.637664794921875, "eval/prior_ent_std": 4.1329803466796875, "eval/rep_loss_mean": 18.32857894897461, "eval/rep_loss_std": 9.572606086730957, "eval/reward_avg": 0.02822265401482582, "eval/reward_loss_mean": 0.12194894254207611, "eval/reward_loss_std": 0.7775216102600098, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0015945434570312, "eval/reward_neg_acc": 0.9868819117546082, "eval/reward_neg_loss": 0.044801220297813416, "eval/reward_pos_acc": 0.7575757503509521, "eval/reward_pos_loss": 2.438717842102051, "eval/reward_pred": 0.02288912981748581, "eval/reward_rate": 0.0322265625, "replay/size": 369793.0, "replay/inserts": 21424.0, "replay/samples": 21424.0, "replay/insert_wait_avg": 1.2830133487966366e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 6.956026748190004e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 73368.0, "eval_replay/inserts": 5128.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0963163212197432e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4253282546997, "timer/env.step_count": 2678.0, "timer/env.step_total": 253.33579087257385, "timer/env.step_frac": 0.25322808581279416, "timer/env.step_avg": 0.09459887635271615, "timer/env.step_min": 0.022393226623535156, "timer/env.step_max": 3.516925573348999, "timer/replay._sample_count": 21424.0, "timer/replay._sample_total": 10.484224796295166, "timer/replay._sample_frac": 0.010479767455093832, "timer/replay._sample_avg": 0.0004893682223812158, "timer/replay._sample_min": 0.00038504600524902344, "timer/replay._sample_max": 0.032668352127075195, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3319.0, "timer/agent.policy_total": 53.200522899627686, "timer/agent.policy_frac": 0.053177904834175976, "timer/agent.policy_avg": 0.016029081922153566, "timer/agent.policy_min": 0.009134769439697266, "timer/agent.policy_max": 0.10569524765014648, "timer/dataset_train_count": 1339.0, "timer/dataset_train_total": 0.13845610618591309, "timer/dataset_train_frac": 0.00013839724192854836, "timer/dataset_train_avg": 0.00010340261851076407, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.00030875205993652344, "timer/agent.train_count": 1339.0, "timer/agent.train_total": 600.1091086864471, "timer/agent.train_frac": 0.5998539738426779, "timer/agent.train_avg": 0.44817707892938546, "timer/agent.train_min": 0.4320707321166992, "timer/agent.train_max": 1.6125726699829102, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47322845458984375, "timer/agent.report_frac": 0.0004730272627297615, "timer/agent.report_avg": 0.23661422729492188, "timer/agent.report_min": 0.23113417625427246, "timer/agent.report_max": 0.2420942783355713, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7179718017578125e-05, "timer/dataset_eval_frac": 2.7168162630383146e-08, "timer/dataset_eval_avg": 2.7179718017578125e-05, "timer/dataset_eval_min": 2.7179718017578125e-05, "timer/dataset_eval_max": 2.7179718017578125e-05, "fps": 21.414653809106948}
{"step": 370480, "time": 17326.502838611603, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 370608, "time": 17332.467317819595, "episode/length": 181.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 370840, "time": 17341.542343378067, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 370928, "time": 17346.244343996048, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 371016, "time": 17350.637850522995, "episode/length": 149.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 371600, "time": 17371.73542904854, "episode/length": 338.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 371664, "time": 17375.330731391907, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 371936, "time": 17385.92736887932, "episode/length": 181.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 372016, "time": 17390.128786563873, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 372336, "time": 17402.231009960175, "episode/length": 186.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 372384, "time": 17405.302265167236, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 372616, "time": 17414.576093435287, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 372640, "time": 17417.58134651184, "episode/length": 308.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 372864, "time": 17426.919404745102, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 372880, "time": 17429.068383693695, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 373248, "time": 17442.757000684738, "episode/length": 163.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 373312, "time": 17446.32492518425, "episode/length": 161.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 373640, "time": 17458.52724504471, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 373872, "time": 17467.976456403732, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 374288, "time": 17483.40451478958, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 374632, "time": 17496.14809012413, "episode/length": 248.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 374712, "time": 17500.48303437233, "episode/length": 182.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 374904, "time": 17508.330315828323, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 374936, "time": 17510.948552131653, "episode/length": 161.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 374984, "time": 17514.20177412033, "episode/length": 262.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9809885931558935, "episode/intrinsic_return": 0.0}
{"step": 375024, "time": 17517.304508686066, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 375040, "time": 17519.468990325928, "episode/length": 302.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 375600, "time": 17539.51049900055, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 375960, "time": 17552.61780667305, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 376248, "time": 17563.597786188126, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 376288, "time": 17566.71563243866, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 376320, "time": 17569.316208839417, "episode/length": 166.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 376416, "time": 17573.944281339645, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 376488, "time": 17577.689841985703, "episode/length": 221.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 376944, "time": 17595.92838382721, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 377112, "time": 17602.868618249893, "episode/length": 258.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 377240, "time": 17608.634838819504, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 377408, "time": 17615.833091020584, "episode/length": 57.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 377640, "time": 17624.909134864807, "episode/length": 168.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 377752, "time": 17630.201013803482, "episode/length": 157.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 377896, "time": 17636.660413742065, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 377952, "time": 17640.89194917679, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 378344, "time": 17656.216826200485, "episode/length": 252.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9723320158102767, "episode/intrinsic_return": 0.0}
{"step": 378664, "time": 17669.334233522415, "episode/length": 193.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 378768, "time": 17675.129234552383, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 378984, "time": 17684.16305041313, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 379000, "time": 17686.20774102211, "episode/length": 219.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 379096, "time": 17690.887362718582, "episode/length": 53.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9074074074074074, "episode/intrinsic_return": 0.0}
{"step": 379152, "time": 17694.391330480576, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 379608, "time": 17710.75067973137, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.966183574879227, "episode/intrinsic_return": 0.0}
{"step": 379832, "time": 17719.8315346241, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 379904, "time": 17723.962245464325, "episode/length": 250.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 380016, "time": 17743.47739315033, "eval_episode/length": 30.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8387096774193549}
{"step": 380016, "time": 17749.43485379219, "eval_episode/length": 145.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9931506849315068}
{"step": 380016, "time": 17751.74523949623, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 380016, "time": 17753.441643476486, "eval_episode/length": 167.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 380016, "time": 17755.64255952835, "eval_episode/length": 182.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9726775956284153}
{"step": 380016, "time": 17759.590926408768, "eval_episode/length": 242.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9753086419753086}
{"step": 380016, "time": 17761.319752693176, "eval_episode/length": 247.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9959677419354839}
{"step": 380016, "time": 17763.88404226303, "eval_episode/length": 238.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9832635983263598}
{"step": 380224, "time": 17770.782888650894, "episode/length": 181.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 380232, "time": 17772.48930120468, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 380392, "time": 17779.38324046135, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 380760, "time": 17793.057228803635, "episode/length": 219.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 380832, "time": 17797.17763352394, "episode/length": 152.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 380848, "time": 17799.230610609055, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 381328, "time": 17816.83719062805, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 381896, "time": 17836.842779636383, "episode/length": 208.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 381928, "time": 17839.50381541252, "episode/length": 211.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 381976, "time": 17842.755886554718, "episode/length": 197.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9797979797979798, "episode/intrinsic_return": 0.0}
{"step": 382096, "time": 17848.454483032227, "episode/length": 155.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 382480, "time": 17863.056047677994, "episode/length": 330.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9969788519637462, "episode/intrinsic_return": 0.0}
{"step": 382536, "time": 17866.233261585236, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 382576, "time": 17869.250811100006, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 383040, "time": 17886.04815840721, "episode/length": 284.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 383136, "time": 17891.281421661377, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 383296, "time": 17898.69323539734, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 383424, "time": 17904.388555288315, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 383544, "time": 17909.7323718071, "episode/length": 205.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 383584, "time": 17912.895537376404, "episode/length": 55.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 383776, "time": 17920.930988550186, "episode/length": 161.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 384440, "time": 17944.230527877808, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 384568, "time": 17950.18124294281, "episode/length": 253.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 384856, "time": 17961.43875479698, "episode/length": 178.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 384928, "time": 17965.70315337181, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 385072, "time": 17973.488720417023, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 385080, "time": 17975.102430582047, "episode/length": 254.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 385280, "time": 17983.586303949356, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 385352, "time": 17987.212095737457, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 385416, "time": 17990.889167547226, "episode/length": 60.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 385896, "time": 18008.71852374077, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 386512, "time": 18031.49513053894, "episode/length": 153.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 386560, "time": 18035.269174814224, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 386560, "time": 18035.278955936432, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 386560, "time": 18035.286821365356, "episode/length": 150.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 386976, "time": 18054.67143344879, "episode/length": 316.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 387608, "time": 18076.87017059326, "episode/length": 273.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9890510948905109, "episode/intrinsic_return": 0.0}
{"step": 387728, "time": 18082.604927778244, "episode/length": 151.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 387752, "time": 18084.7737929821, "episode/length": 148.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9664429530201343, "episode/intrinsic_return": 0.0}
{"step": 387992, "time": 18094.28909611702, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 388064, "time": 18098.360509872437, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 388472, "time": 18113.652125120163, "episode/length": 423.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9929245283018868, "episode/intrinsic_return": 0.0}
{"step": 388688, "time": 18123.01522731781, "episode/length": 213.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 388896, "time": 18131.54262971878, "episode/length": 160.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 389256, "time": 18144.997037410736, "episode/length": 190.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 389392, "time": 18151.98281621933, "episode/length": 165.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 389488, "time": 18157.304646492004, "episode/length": 186.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 389792, "time": 18169.525417089462, "episode/length": 164.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 390000, "time": 18191.92052078247, "eval_episode/length": 30.0, "eval_episode/score": -0.9000000134110451, "eval_episode/reward_rate": 0.8387096774193549}
{"step": 390000, "time": 18198.342000722885, "eval_episode/length": 151.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 390000, "time": 18200.156850099564, "eval_episode/length": 158.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9748427672955975}
{"step": 390000, "time": 18202.3193192482, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 390000, "time": 18204.295072555542, "eval_episode/length": 178.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 390000, "time": 18205.968717336655, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 390000, "time": 18209.201131105423, "eval_episode/length": 188.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 390000, "time": 18210.915350198746, "eval_episode/length": 221.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9954954954954955}
{"step": 390040, "time": 18212.0515832901, "episode/length": 285.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 390152, "time": 18217.38313817978, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 390680, "time": 18236.69333434105, "episode/length": 248.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 390712, "time": 18239.232110500336, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 390768, "time": 18242.964248895645, "episode/length": 525.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9828897338403042, "episode/intrinsic_return": 0.0}
{"step": 390776, "time": 18244.635208129883, "episode/length": 172.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 390944, "time": 18252.013027668, "episode/length": 181.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 391072, "time": 18257.82028055191, "episode/length": 37.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 391088, "time": 18260.010625362396, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 391592, "time": 18277.97555208206, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 391960, "time": 18291.845868587494, "episode/length": 239.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 392064, "time": 18296.92422938347, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 392200, "time": 18302.689148187637, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 392208, "time": 18304.74946451187, "episode/length": 139.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 392432, "time": 18313.81347680092, "episode/length": 218.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 392440, "time": 18315.40184521675, "episode/length": 215.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 392521, "time": 18320.51610684395, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.220882278552159, "train/action_min": 0.0, "train/action_std": 3.1328063011169434, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.041754899050692004, "train/actor_opt_grad_steps": 23740.0, "train/actor_opt_loss": -5.121058833524049, "train/adv_mag": 0.6211355384305227, "train/adv_max": 0.5920104075678818, "train/adv_mean": 0.0033043835423832335, "train/adv_min": -0.47422440875348426, "train/adv_std": 0.06523355790715424, "train/cont_avg": 0.994716726618705, "train/cont_loss_mean": 0.000254811022961162, "train/cont_loss_std": 0.007645734863891454, "train/cont_neg_acc": 0.994835560699161, "train/cont_neg_loss": 0.023110257332944115, "train/cont_pos_acc": 0.999971767552465, "train/cont_pos_loss": 0.00011111070275777862, "train/cont_pred": 0.994701047166646, "train/cont_rate": 0.994716726618705, "train/dyn_loss_mean": 14.47865953376825, "train/dyn_loss_std": 8.93653387302975, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8477322446356574, "train/extr_critic_critic_opt_grad_steps": 23740.0, "train/extr_critic_critic_opt_loss": 15719.291865726169, "train/extr_critic_mag": 6.2678559118037604, "train/extr_critic_max": 6.2678559118037604, "train/extr_critic_mean": 1.5145635630587022, "train/extr_critic_min": -0.16487481182427716, "train/extr_critic_std": 1.4161893498125693, "train/extr_return_normed_mag": 1.73622702351577, "train/extr_return_normed_max": 1.73622702351577, "train/extr_return_normed_mean": 0.33014898034308454, "train/extr_return_normed_min": -0.14986393579261767, "train/extr_return_normed_std": 0.33377413076462503, "train/extr_return_rate": 0.6746759180971187, "train/extr_return_raw_mag": 7.649855730344924, "train/extr_return_raw_max": 7.649855730344924, "train/extr_return_raw_mean": 1.5289312348091344, "train/extr_return_raw_min": -0.5608479378463553, "train/extr_return_raw_std": 1.4532302806703308, "train/extr_reward_mag": 1.0109918846500863, "train/extr_reward_max": 1.0109918846500863, "train/extr_reward_mean": 0.027641144581139088, "train/extr_reward_min": -0.44628323410912385, "train/extr_reward_std": 0.15370454044221973, "train/image_loss_mean": 8.285173718020213, "train/image_loss_std": 12.629274838262324, "train/model_loss_mean": 17.027982924481947, "train/model_loss_std": 16.313753265271085, "train/model_opt_grad_norm": 72.86404763365822, "train/model_opt_grad_steps": 23715.798561151078, "train/model_opt_loss": 11956.486075202338, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 705.9352517985611, "train/policy_entropy_mag": 2.556773497903947, "train/policy_entropy_max": 2.556773497903947, "train/policy_entropy_mean": 0.5890187886979082, "train/policy_entropy_min": 0.07937520034879232, "train/policy_entropy_std": 0.6252293207233758, "train/policy_logprob_mag": 7.4383833562727455, "train/policy_logprob_max": -0.00945575967457869, "train/policy_logprob_mean": -0.5893341958951607, "train/policy_logprob_min": -7.4383833562727455, "train/policy_logprob_std": 1.1174101344973064, "train/policy_randomness_mag": 0.90242884442103, "train/policy_randomness_max": 0.90242884442103, "train/policy_randomness_mean": 0.2078977852202148, "train/policy_randomness_min": 0.02801596223235988, "train/policy_randomness_std": 0.2206785122482039, "train/post_ent_mag": 56.34102369898515, "train/post_ent_max": 56.34102369898515, "train/post_ent_mean": 39.50191484080802, "train/post_ent_min": 20.04310168122216, "train/post_ent_std": 6.914501238212311, "train/prior_ent_mag": 65.5233969379672, "train/prior_ent_max": 65.5233969379672, "train/prior_ent_mean": 54.045329388954656, "train/prior_ent_min": 36.72202181644577, "train/prior_ent_std": 4.808987075476337, "train/rep_loss_mean": 14.47865953376825, "train/rep_loss_std": 8.93653387302975, "train/reward_avg": 0.02387730431535261, "train/reward_loss_mean": 0.05535872781769835, "train/reward_loss_std": 0.257602769265072, "train/reward_max_data": 1.015827341903028, "train/reward_max_pred": 1.0084092882897358, "train/reward_neg_acc": 0.9926560628328392, "train/reward_neg_loss": 0.03071641737742604, "train/reward_pos_acc": 0.9601762449141029, "train/reward_pos_loss": 0.8842897595261499, "train/reward_pred": 0.023299613337722614, "train/reward_rate": 0.028678619604316547, "train_stats/sum_log_reward": 6.651724157662227, "train_stats/max_log_achievement_collect_coal": 0.1724137931034483, "train_stats/max_log_achievement_collect_drink": 6.560344827586207, "train_stats/max_log_achievement_collect_sapling": 2.1293103448275863, "train_stats/max_log_achievement_collect_stone": 1.1551724137931034, "train_stats/max_log_achievement_collect_wood": 10.698275862068966, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.41379310344827586, "train_stats/max_log_achievement_eat_cow": 0.1206896551724138, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.043103448275862, "train_stats/max_log_achievement_make_wood_sword": 1.5689655172413792, "train_stats/max_log_achievement_place_furnace": 0.017241379310344827, "train_stats/max_log_achievement_place_plant": 1.9396551724137931, "train_stats/max_log_achievement_place_stone": 0.06896551724137931, "train_stats/max_log_achievement_place_table": 2.3275862068965516, "train_stats/max_log_achievement_wake_up": 1.3103448275862069, "train_stats/mean_log_entropy": 0.5183183090953991, "eval_stats/sum_log_reward": 6.537500128149986, "eval_stats/max_log_achievement_collect_coal": 0.1875, "eval_stats/max_log_achievement_collect_drink": 5.4375, "eval_stats/max_log_achievement_collect_sapling": 2.25, "eval_stats/max_log_achievement_collect_stone": 1.5, "eval_stats/max_log_achievement_collect_wood": 9.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 2.1875, "eval_stats/max_log_achievement_place_stone": 0.1875, "eval_stats/max_log_achievement_place_table": 1.6875, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.1927771639602724e-06, "report/cont_loss_std": 0.00010741881851572543, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 2.951649912574794e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.0783331718994305e-06, "report/cont_pred": 0.995111346244812, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.4697904586792, "report/dyn_loss_std": 8.690225601196289, "report/image_loss_mean": 5.482937335968018, "report/image_loss_std": 8.6201810836792, "report/model_loss_mean": 13.615434646606445, "report/model_loss_std": 12.203560829162598, "report/post_ent_mag": 55.863616943359375, "report/post_ent_max": 55.863616943359375, "report/post_ent_mean": 39.36068344116211, "report/post_ent_min": 18.1697998046875, "report/post_ent_std": 6.565219402313232, "report/prior_ent_mag": 65.75236511230469, "report/prior_ent_max": 65.75236511230469, "report/prior_ent_mean": 52.96471405029297, "report/prior_ent_min": 30.234615325927734, "report/prior_ent_std": 5.230253219604492, "report/rep_loss_mean": 13.4697904586792, "report/rep_loss_std": 8.690225601196289, "report/reward_avg": 0.02988281287252903, "report/reward_loss_mean": 0.050616227090358734, "report/reward_loss_std": 0.20611350238323212, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0037939548492432, "report/reward_neg_acc": 0.996966540813446, "report/reward_neg_loss": 0.023637624457478523, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.8129544854164124, "report/reward_pred": 0.028677258640527725, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.01665828377008438, "eval/cont_loss_std": 0.3804382383823395, "eval/cont_neg_acc": 0.6000000238418579, "eval/cont_neg_loss": 3.410344362258911, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.240682523639407e-06, "eval/cont_pred": 0.9970636367797852, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.495323181152344, "eval/dyn_loss_std": 10.267313957214355, "eval/image_loss_mean": 16.521181106567383, "eval/image_loss_std": 24.235414505004883, "eval/model_loss_mean": 27.160219192504883, "eval/model_loss_std": 28.46398162841797, "eval/post_ent_mag": 59.513572692871094, "eval/post_ent_max": 59.513572692871094, "eval/post_ent_mean": 39.516624450683594, "eval/post_ent_min": 21.964168548583984, "eval/post_ent_std": 6.632999420166016, "eval/prior_ent_mag": 65.75236511230469, "eval/prior_ent_max": 65.75236511230469, "eval/prior_ent_mean": 54.710689544677734, "eval/prior_ent_min": 38.21711349487305, "eval/prior_ent_std": 4.441347599029541, "eval/rep_loss_mean": 17.495323181152344, "eval/rep_loss_std": 10.267313957214355, "eval/reward_avg": 0.02158203162252903, "eval/reward_loss_mean": 0.12518726289272308, "eval/reward_loss_std": 0.7378117442131042, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0022873878479004, "eval/reward_neg_acc": 0.9899699091911316, "eval/reward_neg_loss": 0.056498873978853226, "eval/reward_pos_acc": 0.6666666865348816, "eval/reward_pos_loss": 2.661569595336914, "eval/reward_pred": 0.015470809303224087, "eval/reward_rate": 0.0263671875, "replay/size": 392017.0, "replay/inserts": 22224.0, "replay/samples": 22224.0, "replay/insert_wait_avg": 1.2837956499246662e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.023285240299672e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 77304.0, "eval_replay/inserts": 3936.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.056892115895341e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1126329898834, "timer/env.step_count": 2778.0, "timer/env.step_total": 262.9327886104584, "timer/env.step_frac": 0.26290317703957855, "timer/env.step_avg": 0.09464823204120172, "timer/env.step_min": 0.02243208885192871, "timer/env.step_max": 5.602515697479248, "timer/replay._sample_count": 22224.0, "timer/replay._sample_total": 10.785189390182495, "timer/replay._sample_frac": 0.010783974758862577, "timer/replay._sample_avg": 0.0004852946989822937, "timer/replay._sample_min": 0.0003573894500732422, "timer/replay._sample_max": 0.008672475814819336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3270.0, "timer/agent.policy_total": 51.57176971435547, "timer/agent.policy_frac": 0.05156596168591457, "timer/agent.policy_avg": 0.015771183398885464, "timer/agent.policy_min": 0.009221315383911133, "timer/agent.policy_max": 0.08917117118835449, "timer/dataset_train_count": 1389.0, "timer/dataset_train_total": 0.14370965957641602, "timer/dataset_train_frac": 0.00014369347495070558, "timer/dataset_train_avg": 0.00010346267788078907, "timer/dataset_train_min": 8.916854858398438e-05, "timer/dataset_train_max": 0.0003616809844970703, "timer/agent.train_count": 1389.0, "timer/agent.train_total": 620.6322367191315, "timer/agent.train_frac": 0.6205623409272638, "timer/agent.train_avg": 0.4468194648805842, "timer/agent.train_min": 0.43268585205078125, "timer/agent.train_max": 1.477238655090332, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4778585433959961, "timer/agent.report_frac": 0.00047780472682103383, "timer/agent.report_avg": 0.23892927169799805, "timer/agent.report_min": 0.2306230068206787, "timer/agent.report_max": 0.24723553657531738, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.93221825843978e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 22.221224805149475}
{"step": 392536, "time": 18320.59912085533, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 392880, "time": 18334.490391016006, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 393552, "time": 18360.32593011856, "episode/length": 168.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 393568, "time": 18362.37777686119, "episode/length": 200.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 393720, "time": 18368.809554815292, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 393864, "time": 18375.177947044373, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 393888, "time": 18377.798514842987, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 394152, "time": 18387.76319718361, "episode/length": 201.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 394280, "time": 18393.644622325897, "episode/length": 258.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 394560, "time": 18405.31226348877, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 394888, "time": 18417.38836169243, "episode/length": 166.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 395224, "time": 18429.990832567215, "episode/length": 206.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 395280, "time": 18433.596355438232, "episode/length": 48.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 395328, "time": 18436.8088490963, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 395744, "time": 18452.144645690918, "episode/length": 231.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 395832, "time": 18456.455132246017, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 395864, "time": 18459.065931081772, "episode/length": 162.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 396056, "time": 18466.98627090454, "episode/length": 221.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 396528, "time": 18484.70249271393, "episode/length": 82.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9879518072289156, "episode/intrinsic_return": 0.0}
{"step": 396704, "time": 18492.098874092102, "episode/length": 177.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9662921348314607, "episode/intrinsic_return": 0.0}
{"step": 396816, "time": 18497.365250110626, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 396912, "time": 18502.09329009056, "episode/length": 145.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 397160, "time": 18511.933675050735, "episode/length": 429.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976744186046511, "episode/intrinsic_return": 0.0}
{"step": 397304, "time": 18519.011382818222, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 397304, "time": 18519.022152662277, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 397376, "time": 18526.158932209015, "episode/length": 83.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9404761904761905, "episode/intrinsic_return": 0.0}
{"step": 398168, "time": 18554.650617837906, "episode/length": 204.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 398272, "time": 18560.45153284073, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 398296, "time": 18562.664544582367, "episode/length": 141.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 398336, "time": 18565.802041053772, "episode/length": 189.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 398560, "time": 18574.851281166077, "episode/length": 312.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 399016, "time": 18591.257247924805, "episode/length": 89.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 399056, "time": 18594.326362609863, "episode/length": 218.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 399152, "time": 18598.998475313187, "episode/length": 109.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 399240, "time": 18603.24487400055, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 399600, "time": 18616.88450884819, "episode/length": 178.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 399648, "time": 18620.131400823593, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 400088, "time": 18653.023218870163, "eval_episode/length": 44.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8888888888888888}
{"step": 400088, "time": 18659.210938453674, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 400088, "time": 18661.190644025803, "eval_episode/length": 170.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 400088, "time": 18664.101238012314, "eval_episode/length": 201.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.995049504950495}
{"step": 400088, "time": 18664.11078929901, "eval_episode/length": 201.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.995049504950495}
{"step": 400088, "time": 18667.563249349594, "eval_episode/length": 209.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 400088, "time": 18669.683651208878, "eval_episode/length": 217.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 400088, "time": 18671.824120283127, "eval_episode/length": 232.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 400136, "time": 18673.436178684235, "episode/length": 344.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 400160, "time": 18675.989198446274, "episode/length": 199.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 400488, "time": 18688.135375261307, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 400608, "time": 18693.881086826324, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 400696, "time": 18698.25065922737, "episode/length": 181.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 400984, "time": 18709.669397115707, "episode/length": 166.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 401112, "time": 18715.477304697037, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 401392, "time": 18726.466106891632, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 401880, "time": 18745.59366416931, "episode/length": 147.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 401944, "time": 18749.197446107864, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 402032, "time": 18753.984142780304, "episode/length": 192.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 402240, "time": 18762.462742567062, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 402464, "time": 18772.5853972435, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 402512, "time": 18775.712874650955, "episode/length": 431.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9976851851851852, "episode/intrinsic_return": 0.0}
{"step": 402768, "time": 18785.698776483536, "episode/length": 37.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.868421052631579, "episode/intrinsic_return": 0.0}
{"step": 402784, "time": 18787.767478466034, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 403344, "time": 18808.25169324875, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 403520, "time": 18815.812732696533, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 403888, "time": 18829.74286055565, "episode/length": 242.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 403960, "time": 18833.295299768448, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 404040, "time": 18837.54730463028, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 404104, "time": 18841.20919251442, "episode/length": 198.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 404200, "time": 18846.00358605385, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 404832, "time": 18868.605834007263, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 405000, "time": 18875.58770298958, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 405248, "time": 18885.70271229744, "episode/length": 169.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 405328, "time": 18889.86165523529, "episode/length": 411.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 405336, "time": 18891.418931007385, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 405480, "time": 18897.640291690826, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 405752, "time": 18908.27868628502, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 405848, "time": 18913.132312059402, "episode/length": 63.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 406016, "time": 18920.413280010223, "episode/length": 226.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 406280, "time": 18930.640441656113, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 406664, "time": 18945.016598701477, "episode/length": 207.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 406712, "time": 18948.25662636757, "episode/length": 182.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9781420765027322, "episode/intrinsic_return": 0.0}
{"step": 406880, "time": 18955.514780282974, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 406880, "time": 18955.523812770844, "episode/length": 174.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 406912, "time": 18960.016374349594, "episode/length": 144.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 407136, "time": 18968.9728140831, "episode/length": 58.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 407176, "time": 18971.90527844429, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 407496, "time": 18983.909491539, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 407800, "time": 18995.591453313828, "episode/length": 189.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 407872, "time": 18999.73096728325, "episode/length": 86.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9425287356321839, "episode/intrinsic_return": 0.0}
{"step": 408096, "time": 19008.6902179718, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 408568, "time": 19025.6999437809, "episode/length": 206.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 408896, "time": 19038.526826143265, "episode/length": 219.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 409336, "time": 19054.57456755638, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869706840390879, "episode/intrinsic_return": 0.0}
{"step": 409408, "time": 19058.754333734512, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 409424, "time": 19061.00320792198, "episode/length": 317.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779874213836478, "episode/intrinsic_return": 0.0}
{"step": 409520, "time": 19065.70331788063, "episode/length": 177.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 409752, "time": 19076.236664533615, "episode/length": 243.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 409760, "time": 19078.290066480637, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9047619047619048, "episode/intrinsic_return": 0.0}
{"step": 409800, "time": 19081.012368440628, "episode/length": 287.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9965277777777778, "episode/intrinsic_return": 0.0}
{"step": 410072, "time": 19106.14913201332, "eval_episode/length": 34.0, "eval_episode/score": 2.100000001490116, "eval_episode/reward_rate": 0.8857142857142857}
{"step": 410072, "time": 19108.68258547783, "eval_episode/length": 59.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 410072, "time": 19115.50551366806, "eval_episode/length": 184.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 410072, "time": 19117.256849765778, "eval_episode/length": 187.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 410072, "time": 19119.97736477852, "eval_episode/length": 211.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 410072, "time": 19122.314146757126, "eval_episode/length": 228.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 410072, "time": 19124.74703478813, "eval_episode/length": 57.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 410072, "time": 19126.542583227158, "eval_episode/length": 190.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9581151832460733}
{"step": 410080, "time": 19127.031618118286, "episode/length": 188.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 410128, "time": 19130.23205637932, "episode/length": 98.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9494949494949495, "episode/intrinsic_return": 0.0}
{"step": 410816, "time": 19154.746842861176, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 410992, "time": 19162.28718852997, "episode/length": 107.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9907407407407407, "episode/intrinsic_return": 0.0}
{"step": 411032, "time": 19164.96872138977, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 411136, "time": 19170.19607782364, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 411216, "time": 19174.51734972, "episode/length": 225.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 411248, "time": 19177.13340330124, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9834254143646409, "episode/intrinsic_return": 0.0}
{"step": 411392, "time": 19183.516490459442, "episode/length": 163.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 412024, "time": 19205.656686306, "episode/length": 390.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769820971867008, "episode/intrinsic_return": 0.0}
{"step": 412704, "time": 19230.366190195084, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 412792, "time": 19234.68994140625, "episode/length": 224.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 413064, "time": 19245.303339242935, "episode/length": 208.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 413080, "time": 19247.505227327347, "episode/length": 232.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 413128, "time": 19250.60276246071, "episode/length": 234.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 413368, "time": 19260.120007753372, "episode/length": 318.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9811912225705329, "episode/intrinsic_return": 0.0}
{"step": 414296, "time": 19293.139329195023, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 414344, "time": 19296.408511161804, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 414544, "time": 19304.88195514679, "episode/length": 229.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 414792, "time": 19314.378059625626, "episode/length": 469.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 414905, "time": 19320.781378507614, "train_stats/sum_log_reward": 6.700000049851157, "train_stats/max_log_achievement_collect_coal": 0.16363636363636364, "train_stats/max_log_achievement_collect_drink": 5.445454545454545, "train_stats/max_log_achievement_collect_sapling": 1.8454545454545455, "train_stats/max_log_achievement_collect_stone": 2.1636363636363636, "train_stats/max_log_achievement_collect_wood": 10.927272727272728, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.24545454545454545, "train_stats/max_log_achievement_eat_cow": 0.07272727272727272, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 3.090909090909091, "train_stats/max_log_achievement_make_wood_sword": 0.18181818181818182, "train_stats/max_log_achievement_place_furnace": 0.05454545454545454, "train_stats/max_log_achievement_place_plant": 1.6818181818181819, "train_stats/max_log_achievement_place_stone": 0.13636363636363635, "train_stats/max_log_achievement_place_table": 2.6545454545454548, "train_stats/max_log_achievement_wake_up": 1.2545454545454546, "train_stats/mean_log_entropy": 0.5506809119473804, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.44384286063058, "train/action_min": 0.0, "train/action_std": 3.2385255677359446, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.04218491329146283, "train/actor_opt_grad_steps": 25135.0, "train/actor_opt_loss": -1.8619479547653879, "train/adv_mag": 0.593536117034299, "train/adv_max": 0.5667062403900283, "train/adv_mean": 0.004210117875993546, "train/adv_min": -0.449935619533062, "train/adv_std": 0.06575585066207817, "train/cont_avg": 0.9945940290178571, "train/cont_loss_mean": 0.00031350931736743144, "train/cont_loss_std": 0.00917229417956459, "train/cont_neg_acc": 0.9913690486124583, "train/cont_neg_loss": 0.01993050238017174, "train/cont_pos_acc": 0.999936826314245, "train/cont_pos_loss": 0.00020069895276405094, "train/cont_pred": 0.994558556165014, "train/cont_rate": 0.9945940290178571, "train/dyn_loss_mean": 14.351552663530622, "train/dyn_loss_std": 8.975268387794495, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9005618099655424, "train/extr_critic_critic_opt_grad_steps": 25135.0, "train/extr_critic_critic_opt_loss": 15858.009898158482, "train/extr_critic_mag": 6.430525146211896, "train/extr_critic_max": 6.430525146211896, "train/extr_critic_mean": 1.595673398886408, "train/extr_critic_min": -0.17226476584162032, "train/extr_critic_std": 1.4502181270292827, "train/extr_return_normed_mag": 1.7254088929721287, "train/extr_return_normed_max": 1.7254088929721287, "train/extr_return_normed_mean": 0.3413964191717761, "train/extr_return_normed_min": -0.13699957353195974, "train/extr_return_normed_std": 0.33587538195507866, "train/extr_return_rate": 0.6882975633655276, "train/extr_return_raw_mag": 7.751120206287929, "train/extr_return_raw_max": 7.751120206287929, "train/extr_return_raw_mean": 1.6143730116741999, "train/extr_return_raw_min": -0.5079329229891301, "train/extr_return_raw_std": 1.4896469793149403, "train/extr_reward_mag": 1.0175118378230503, "train/extr_reward_max": 1.0175118378230503, "train/extr_reward_mean": 0.029630524724988002, "train/extr_reward_min": -0.40904477834701536, "train/extr_reward_std": 0.15937537997961043, "train/image_loss_mean": 8.257161491257804, "train/image_loss_std": 12.921734302384513, "train/model_loss_mean": 16.923821599142894, "train/model_loss_std": 16.56372070993696, "train/model_opt_grad_norm": 68.30319553102765, "train/model_opt_grad_steps": 25110.0, "train/model_opt_loss": 15654.160365513393, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 928.5714285714286, "train/policy_entropy_mag": 2.551481294631958, "train/policy_entropy_max": 2.551481294631958, "train/policy_entropy_mean": 0.6251025553260531, "train/policy_entropy_min": 0.07937518895736763, "train/policy_entropy_std": 0.6790625751018524, "train/policy_logprob_mag": 7.438383351053511, "train/policy_logprob_max": -0.00945575641069029, "train/policy_logprob_mean": -0.6257311714547021, "train/policy_logprob_min": -7.438383351053511, "train/policy_logprob_std": 1.1427596126283919, "train/policy_randomness_mag": 0.900560929945537, "train/policy_randomness_max": 0.900560929945537, "train/policy_randomness_mean": 0.22063376946108681, "train/policy_randomness_min": 0.028015958344829932, "train/policy_randomness_std": 0.2396792873740196, "train/post_ent_mag": 56.58856898716518, "train/post_ent_max": 56.58856898716518, "train/post_ent_mean": 39.7727244240897, "train/post_ent_min": 20.338633728027343, "train/post_ent_std": 6.982691996438163, "train/prior_ent_mag": 65.55830029078892, "train/prior_ent_max": 65.55830029078892, "train/prior_ent_mean": 54.14936408996582, "train/prior_ent_min": 37.04068446840559, "train/prior_ent_std": 4.710794305801391, "train/rep_loss_mean": 14.351552663530622, "train/rep_loss_std": 8.975268387794495, "train/reward_avg": 0.025845423926200185, "train/reward_loss_mean": 0.05541501058531659, "train/reward_loss_std": 0.25820529663137026, "train/reward_max_data": 1.0171428612300328, "train/reward_max_pred": 1.008347567490169, "train/reward_neg_acc": 0.9934980601072312, "train/reward_neg_loss": 0.029822651982041343, "train/reward_pos_acc": 0.9625657882009234, "train/reward_pos_loss": 0.8703042315585273, "train/reward_pred": 0.025068426464817353, "train/reward_rate": 0.030615234375, "eval_stats/sum_log_reward": 5.850000023841858, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 2.0, "eval_stats/max_log_achievement_collect_stone": 1.125, "eval_stats/max_log_achievement_collect_wood": 8.5625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 0.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 1.4238689800549764e-06, "report/cont_loss_std": 8.268610145023558e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.3270257669501e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.0593519164103782e-06, "report/cont_pred": 0.9941400289535522, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.695039749145508, "report/dyn_loss_std": 8.855066299438477, "report/image_loss_mean": 6.586000442504883, "report/image_loss_std": 10.795784950256348, "report/model_loss_mean": 14.260980606079102, "report/model_loss_std": 14.676506042480469, "report/post_ent_mag": 54.19003677368164, "report/post_ent_max": 54.19003677368164, "report/post_ent_mean": 40.36548614501953, "report/post_ent_min": 19.876564025878906, "report/post_ent_std": 6.780287742614746, "report/prior_ent_mag": 65.80575561523438, "report/prior_ent_max": 65.80575561523438, "report/prior_ent_mean": 53.7166748046875, "report/prior_ent_min": 37.33012390136719, "report/prior_ent_std": 5.395392417907715, "report/rep_loss_mean": 12.695039749145508, "report/rep_loss_std": 8.855066299438477, "report/reward_avg": 0.02021484449505806, "report/reward_loss_mean": 0.05795485898852348, "report/reward_loss_std": 0.23189419507980347, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0023508071899414, "report/reward_neg_acc": 0.9989960789680481, "report/reward_neg_loss": 0.034928739070892334, "report/reward_pos_acc": 0.9642857313156128, "report/reward_pos_loss": 0.8770270347595215, "report/reward_pred": 0.01784082129597664, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.0030458292458206415, "eval/cont_loss_std": 0.0973755493760109, "eval/cont_neg_acc": 0.5, "eval/cont_neg_loss": 1.5588542222976685, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1948015981033677e-06, "eval/cont_pred": 0.9989792704582214, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.954357147216797, "eval/dyn_loss_std": 9.353034973144531, "eval/image_loss_mean": 13.420655250549316, "eval/image_loss_std": 17.203941345214844, "eval/model_loss_mean": 24.301456451416016, "eval/model_loss_std": 20.657155990600586, "eval/post_ent_mag": 55.50871276855469, "eval/post_ent_max": 55.50871276855469, "eval/post_ent_mean": 38.48919677734375, "eval/post_ent_min": 20.889427185058594, "eval/post_ent_std": 6.346116542816162, "eval/prior_ent_mag": 65.80575561523438, "eval/prior_ent_max": 65.80575561523438, "eval/prior_ent_mean": 54.85100555419922, "eval/prior_ent_min": 37.555477142333984, "eval/prior_ent_std": 4.269694805145264, "eval/rep_loss_mean": 17.954357147216797, "eval/rep_loss_std": 9.353034973144531, "eval/reward_avg": 0.03193359449505806, "eval/reward_loss_mean": 0.10514058917760849, "eval/reward_loss_std": 0.5734060406684875, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0005717277526855, "eval/reward_neg_acc": 0.9908907413482666, "eval/reward_neg_loss": 0.047452494502067566, "eval/reward_pos_acc": 0.8333333134651184, "eval/reward_pos_loss": 1.688358187675476, "eval/reward_pred": 0.025716513395309448, "eval/reward_rate": 0.03515625, "replay/size": 414401.0, "replay/inserts": 22384.0, "replay/samples": 22384.0, "replay/insert_wait_avg": 1.315786380099773e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.139349767699934e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 81176.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0992377257544147e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.642673492431641e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2543203830719, "timer/env.step_count": 2798.0, "timer/env.step_total": 252.34425735473633, "timer/env.step_frac": 0.2522800973837283, "timer/env.step_avg": 0.09018736860426602, "timer/env.step_min": 0.022228240966796875, "timer/env.step_max": 4.4962451457977295, "timer/replay._sample_count": 22384.0, "timer/replay._sample_total": 10.925642013549805, "timer/replay._sample_frac": 0.010922864106565981, "timer/replay._sample_avg": 0.0004881005188326396, "timer/replay._sample_min": 0.0003821849822998047, "timer/replay._sample_max": 0.009361982345581055, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3282.0, "timer/agent.policy_total": 52.536195516586304, "timer/agent.policy_frac": 0.05252283788833452, "timer/agent.policy_avg": 0.016007372186650305, "timer/agent.policy_min": 0.009301185607910156, "timer/agent.policy_max": 0.11143851280212402, "timer/dataset_train_count": 1399.0, "timer/dataset_train_total": 0.1466660499572754, "timer/dataset_train_frac": 0.0001466287592750472, "timer/dataset_train_avg": 0.00010483634736045417, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0002815723419189453, "timer/agent.train_count": 1399.0, "timer/agent.train_total": 627.40203166008, "timer/agent.train_frac": 0.6272425111043769, "timer/agent.train_avg": 0.44846464021449606, "timer/agent.train_min": 0.43359923362731934, "timer/agent.train_max": 1.6436147689819336, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47754573822021484, "timer/agent.report_frac": 0.00047742431948439575, "timer/agent.report_avg": 0.23877286911010742, "timer/agent.report_min": 0.2319164276123047, "timer/agent.report_max": 0.24562931060791016, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0279159545898438e-05, "timer/dataset_eval_frac": 3.0271460896367125e-08, "timer/dataset_eval_avg": 3.0279159545898438e-05, "timer/dataset_eval_min": 3.0279159545898438e-05, "timer/dataset_eval_max": 3.0279159545898438e-05, "fps": 22.378012821546072}
{"step": 415192, "time": 19330.582927703857, "episode/length": 263.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9810606060606061, "episode/intrinsic_return": 0.0}
{"step": 415504, "time": 19343.401505947113, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 415640, "time": 19349.285276174545, "episode/length": 313.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 415736, "time": 19354.097345352173, "episode/length": 333.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9970059880239521, "episode/intrinsic_return": 0.0}
{"step": 415976, "time": 19363.741339683533, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 416000, "time": 19366.401926755905, "episode/length": 328.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9878419452887538, "episode/intrinsic_return": 0.0}
{"step": 416200, "time": 19374.459183454514, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 416248, "time": 19378.143582582474, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 417112, "time": 19409.033485412598, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 417152, "time": 19412.24290060997, "episode/length": 176.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 417328, "time": 19419.61805319786, "episode/length": 134.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 417344, "time": 19421.707159757614, "episode/length": 212.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 417568, "time": 19430.823396205902, "episode/length": 198.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 417728, "time": 19437.75450205803, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 418168, "time": 19455.228254556656, "episode/length": 245.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 418488, "time": 19467.437710523605, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9781553398058253, "episode/intrinsic_return": 0.0}
{"step": 418576, "time": 19472.265251636505, "episode/length": 177.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 418592, "time": 19474.44121646881, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 418784, "time": 19482.554744243622, "episode/length": 208.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 418800, "time": 19484.66087961197, "episode/length": 183.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 419080, "time": 19495.371367931366, "episode/length": 188.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 419400, "time": 19507.445563554764, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 419952, "time": 19528.012242794037, "episode/length": 222.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 420056, "time": 19551.221360445023, "eval_episode/length": 47.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 420056, "time": 19557.526273727417, "eval_episode/length": 157.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 420056, "time": 19559.69614982605, "eval_episode/length": 171.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9709302325581395}
{"step": 420056, "time": 19561.659668445587, "eval_episode/length": 181.0, "eval_episode/score": 6.099999979138374, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 420056, "time": 19563.55636382103, "eval_episode/length": 188.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 420056, "time": 19565.340262651443, "eval_episode/length": 192.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9792746113989638}
{"step": 420056, "time": 19567.473073244095, "eval_episode/length": 158.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9685534591194969}
{"step": 420056, "time": 19569.83034825325, "eval_episode/length": 223.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 420128, "time": 19572.459624767303, "episode/length": 204.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 420152, "time": 19574.513436079025, "episode/length": 194.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 420272, "time": 19580.327733278275, "episode/length": 185.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 420376, "time": 19585.214859724045, "episode/length": 224.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 420584, "time": 19593.672425031662, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730941704035875, "episode/intrinsic_return": 0.0}
{"step": 420808, "time": 19602.71751332283, "episode/length": 175.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 421056, "time": 19612.776683807373, "episode/length": 246.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 421560, "time": 19631.794890880585, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 421832, "time": 19642.42411184311, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 421848, "time": 19644.543015003204, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 421864, "time": 19647.14660859108, "episode/length": 238.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 422136, "time": 19658.47207212448, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 422256, "time": 19664.431300401688, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 422384, "time": 19670.322791337967, "episode/length": 281.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 422392, "time": 19671.978364944458, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 422552, "time": 19678.791831970215, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 423192, "time": 19701.703861236572, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 423232, "time": 19704.9150724411, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 423232, "time": 19704.923585653305, "episode/length": 104.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 423280, "time": 19709.805583953857, "episode/length": 180.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 423808, "time": 19728.89479112625, "episode/length": 65.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 423880, "time": 19732.770330667496, "episode/length": 202.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 424360, "time": 19750.403091192245, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 424384, "time": 19753.112557649612, "episode/length": 316.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9779179810725552, "episode/intrinsic_return": 0.0}
{"step": 424384, "time": 19753.12190413475, "episode/length": 249.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 424720, "time": 19767.570484638214, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 424768, "time": 19770.69902586937, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 425640, "time": 19801.234307289124, "episode/length": 228.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 425680, "time": 19804.418024539948, "episode/length": 164.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 425736, "time": 19807.658950567245, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 425840, "time": 19812.976438999176, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 426112, "time": 19825.128641605377, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 426456, "time": 19837.81662082672, "episode/length": 407.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 426544, "time": 19842.62432742119, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 426896, "time": 19855.893465042114, "episode/length": 156.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 426960, "time": 19859.5773396492, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 427120, "time": 19866.34493780136, "episode/length": 293.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 427376, "time": 19876.505519151688, "episode/length": 191.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 427528, "time": 19882.904421567917, "episode/length": 223.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 427816, "time": 19894.165613889694, "episode/length": 158.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 427944, "time": 19900.108897447586, "episode/length": 228.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.982532751091703, "episode/intrinsic_return": 0.0}
{"step": 427960, "time": 19902.327738046646, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 428032, "time": 19906.548341989517, "episode/length": 113.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.956140350877193, "episode/intrinsic_return": 0.0}
{"step": 428136, "time": 19911.3083922863, "episode/length": 154.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 428448, "time": 19923.454177379608, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 429016, "time": 19943.624941825867, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 429272, "time": 19953.79230284691, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 429368, "time": 19958.61161661148, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9580838323353293, "episode/intrinsic_return": 0.0}
{"step": 429560, "time": 19966.744685173035, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 429600, "time": 19969.958216428757, "episode/length": 222.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9775784753363229, "episode/intrinsic_return": 0.0}
{"step": 430040, "time": 20004.671407222748, "eval_episode/length": 151.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.993421052631579}
{"step": 430040, "time": 20006.40530347824, "eval_episode/length": 155.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9935897435897436}
{"step": 430040, "time": 20009.23132777214, "eval_episode/length": 184.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 430040, "time": 20011.20126724243, "eval_episode/length": 195.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9948979591836735}
{"step": 430040, "time": 20013.26962018013, "eval_episode/length": 206.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9951690821256038}
{"step": 430040, "time": 20019.042674303055, "eval_episode/length": 309.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9967741935483871}
{"step": 430040, "time": 20021.67700767517, "eval_episode/length": 331.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9969879518072289}
{"step": 430040, "time": 20023.295632839203, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 430088, "time": 20024.90300798416, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 430344, "time": 20034.947592020035, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 430600, "time": 20044.86273741722, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 430728, "time": 20050.735397338867, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 430904, "time": 20058.105794906616, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 431008, "time": 20063.362859010696, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 431016, "time": 20065.04466700554, "episode/length": 383.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 431184, "time": 20072.350383520126, "episode/length": 226.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 431456, "time": 20083.053952932358, "episode/length": 170.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9649122807017544, "episode/intrinsic_return": 0.0}
{"step": 431728, "time": 20093.653244256973, "episode/length": 140.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 431968, "time": 20103.15846848488, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 432680, "time": 20128.75562930107, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 432800, "time": 20134.612166166306, "episode/length": 236.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9789029535864979, "episode/intrinsic_return": 0.0}
{"step": 432808, "time": 20136.258343696594, "episode/length": 202.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 432976, "time": 20143.855922937393, "episode/length": 155.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 433048, "time": 20147.76390147209, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 433216, "time": 20155.196988344193, "episode/length": 219.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 433320, "time": 20160.670855760574, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 433632, "time": 20173.50729894638, "episode/length": 362.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.977961432506887, "episode/intrinsic_return": 0.0}
{"step": 434264, "time": 20197.26858329773, "episode/length": 160.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 434352, "time": 20202.061724185944, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 434392, "time": 20204.778865098953, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 434400, "time": 20206.981980085373, "episode/length": 199.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 434720, "time": 20219.103096485138, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 434792, "time": 20222.838026046753, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 435192, "time": 20237.604084968567, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 435488, "time": 20249.242513895035, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 435520, "time": 20251.91107773781, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 435648, "time": 20257.749229192734, "episode/length": 155.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 435992, "time": 20270.800964593887, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 436008, "time": 20273.405451774597, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 436208, "time": 20282.198361873627, "episode/length": 176.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 436344, "time": 20287.960922718048, "episode/length": 202.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 436776, "time": 20304.02667927742, "episode/length": 160.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 437072, "time": 20315.744619607925, "episode/length": 234.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 437161, "time": 20321.115740537643, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.271526967878822, "train/action_min": 0.0, "train/action_std": 3.16334263540858, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03884202303539077, "train/actor_opt_grad_steps": 26530.0, "train/actor_opt_loss": -3.4121682135750064, "train/adv_mag": 0.537308883538349, "train/adv_max": 0.5093106333729175, "train/adv_mean": 0.0038295572257143018, "train/adv_min": -0.42780285880720015, "train/adv_std": 0.060815361361923836, "train/cont_avg": 0.9947869829136691, "train/cont_loss_mean": 0.0004418179222695779, "train/cont_loss_std": 0.012859735577317125, "train/cont_neg_acc": 0.9917694428841844, "train/cont_neg_loss": 0.041076339075555704, "train/cont_pos_acc": 0.999943399172035, "train/cont_pos_loss": 0.00022455498638719406, "train/cont_pred": 0.9947449028920784, "train/cont_rate": 0.9947869829136691, "train/dyn_loss_mean": 14.334293214537256, "train/dyn_loss_std": 8.955833188063806, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.887180450580103, "train/extr_critic_critic_opt_grad_steps": 26530.0, "train/extr_critic_critic_opt_loss": 15750.84611061151, "train/extr_critic_mag": 6.639118016194955, "train/extr_critic_max": 6.639118016194955, "train/extr_critic_mean": 1.6953961171692224, "train/extr_critic_min": -0.17571515059299606, "train/extr_critic_std": 1.5336186457023346, "train/extr_return_normed_mag": 1.6721863600847533, "train/extr_return_normed_max": 1.6721863600847533, "train/extr_return_normed_mean": 0.34801048908731064, "train/extr_return_normed_min": -0.13341623359768512, "train/extr_return_normed_std": 0.3334215819406852, "train/extr_return_rate": 0.7079305646659659, "train/extr_return_raw_mag": 7.937824036577623, "train/extr_return_raw_max": 7.937824036577623, "train/extr_return_raw_mean": 1.7134063827048103, "train/extr_return_raw_min": -0.5504410548819055, "train/extr_return_raw_std": 1.567575582926222, "train/extr_reward_mag": 1.0155738583571619, "train/extr_reward_max": 1.0155738583571619, "train/extr_reward_mean": 0.030180058629660726, "train/extr_reward_min": -0.44325845704661854, "train/extr_reward_std": 0.16061315851674662, "train/image_loss_mean": 8.172842801046029, "train/image_loss_std": 12.770864994405843, "train/model_loss_mean": 16.83005027633777, "train/model_loss_std": 16.39458289249338, "train/model_opt_grad_norm": 65.53819398399737, "train/model_opt_grad_steps": 26503.913669064747, "train/model_opt_loss": 18208.086569806655, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1083.63309352518, "train/policy_entropy_mag": 2.5575002440445713, "train/policy_entropy_max": 2.5575002440445713, "train/policy_entropy_mean": 0.5933154628431196, "train/policy_entropy_min": 0.07937518078431809, "train/policy_entropy_std": 0.6620273825933607, "train/policy_logprob_mag": 7.4383833837166105, "train/policy_logprob_max": -0.009455740954324925, "train/policy_logprob_mean": -0.5933532984994299, "train/policy_logprob_min": -7.4383833837166105, "train/policy_logprob_std": 1.1259743627026784, "train/policy_randomness_mag": 0.9026853527954156, "train/policy_randomness_max": 0.9026853527954156, "train/policy_randomness_mean": 0.20941432206321964, "train/policy_randomness_min": 0.028015955398194223, "train/policy_randomness_std": 0.23366661326919527, "train/post_ent_mag": 56.71210759663754, "train/post_ent_max": 56.71210759663754, "train/post_ent_mean": 40.01641851191898, "train/post_ent_min": 20.23613413803869, "train/post_ent_std": 7.0015001125472915, "train/prior_ent_mag": 65.71263956852097, "train/prior_ent_max": 65.71263956852097, "train/prior_ent_mean": 54.374139552493745, "train/prior_ent_min": 37.734964466781065, "train/prior_ent_std": 4.664347581726184, "train/rep_loss_mean": 14.334293214537256, "train/rep_loss_std": 8.955833188063806, "train/reward_avg": 0.025918249395950665, "train/reward_loss_mean": 0.056189806260865366, "train/reward_loss_std": 0.2563105101208035, "train/reward_max_data": 1.0064748216876023, "train/reward_max_pred": 1.009410157478113, "train/reward_neg_acc": 0.9922914363497453, "train/reward_neg_loss": 0.02971960511058569, "train/reward_pos_acc": 0.9547416169008762, "train/reward_pos_loss": 0.8989465841286474, "train/reward_pred": 0.02499283230428001, "train/reward_rate": 0.03063877023381295, "train_stats/sum_log_reward": 7.062963039786728, "train_stats/max_log_achievement_collect_coal": 0.1574074074074074, "train_stats/max_log_achievement_collect_drink": 6.87037037037037, "train_stats/max_log_achievement_collect_sapling": 2.1203703703703702, "train_stats/max_log_achievement_collect_stone": 3.0833333333333335, "train_stats/max_log_achievement_collect_wood": 12.157407407407407, "train_stats/max_log_achievement_defeat_skeleton": 0.0, "train_stats/max_log_achievement_defeat_zombie": 0.5185185185185185, "train_stats/max_log_achievement_eat_cow": 0.08333333333333333, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 2.9537037037037037, "train_stats/max_log_achievement_make_wood_sword": 0.1388888888888889, "train_stats/max_log_achievement_place_furnace": 0.027777777777777776, "train_stats/max_log_achievement_place_plant": 1.9351851851851851, "train_stats/max_log_achievement_place_stone": 0.19444444444444445, "train_stats/max_log_achievement_place_table": 3.0, "train_stats/max_log_achievement_wake_up": 1.2407407407407407, "train_stats/mean_log_entropy": 0.531855119323289, "eval_stats/sum_log_reward": 6.474999934434891, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 6.8125, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 2.375, "eval_stats/max_log_achievement_collect_wood": 12.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.125, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.8125, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 0.0, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 7.605701102875173e-05, "report/cont_loss_std": 0.001705192495137453, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004449762054719031, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.5335061410442e-05, "report/cont_pred": 0.9979740381240845, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 15.543664932250977, "report/dyn_loss_std": 9.929574966430664, "report/image_loss_mean": 10.987095832824707, "report/image_loss_std": 15.497345924377441, "report/model_loss_mean": 20.373088836669922, "report/model_loss_std": 19.397062301635742, "report/post_ent_mag": 58.311134338378906, "report/post_ent_max": 58.311134338378906, "report/post_ent_mean": 39.61915588378906, "report/post_ent_min": 21.2893009185791, "report/post_ent_std": 7.439957618713379, "report/prior_ent_mag": 65.34483337402344, "report/prior_ent_max": 65.34483337402344, "report/prior_ent_mean": 55.07978057861328, "report/prior_ent_min": 35.351806640625, "report/prior_ent_std": 4.7581048011779785, "report/rep_loss_mean": 15.543664932250977, "report/rep_loss_std": 9.929574966430664, "report/reward_avg": 0.01767578162252903, "report/reward_loss_mean": 0.059718213975429535, "report/reward_loss_std": 0.36749571561813354, "report/reward_max_data": 1.0, "report/reward_max_pred": 0.9987177848815918, "report/reward_neg_acc": 0.9930209517478943, "report/reward_neg_loss": 0.03344791755080223, "report/reward_pos_acc": 0.9047619104385376, "report/reward_pos_loss": 1.314437747001648, "report/reward_pred": 0.01727130450308323, "report/reward_rate": 0.0205078125, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 9.206181130139157e-05, "eval/cont_loss_std": 0.0029325089417397976, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01879153959453106, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.077373946780426e-07, "eval/cont_pred": 0.995204508304596, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.803619384765625, "eval/dyn_loss_std": 9.66679573059082, "eval/image_loss_mean": 15.844191551208496, "eval/image_loss_std": 18.225242614746094, "eval/model_loss_mean": 26.637680053710938, "eval/model_loss_std": 22.15009307861328, "eval/post_ent_mag": 52.74641418457031, "eval/post_ent_max": 52.74641418457031, "eval/post_ent_mean": 39.3995361328125, "eval/post_ent_min": 21.021697998046875, "eval/post_ent_std": 6.3658833503723145, "eval/prior_ent_mag": 65.34483337402344, "eval/prior_ent_max": 65.34483337402344, "eval/prior_ent_mean": 54.984493255615234, "eval/prior_ent_min": 40.9377555847168, "eval/prior_ent_std": 3.9956464767456055, "eval/rep_loss_mean": 17.803619384765625, "eval/rep_loss_std": 9.66679573059082, "eval/reward_avg": 0.02402343600988388, "eval/reward_loss_mean": 0.11122595518827438, "eval/reward_loss_std": 0.7130621075630188, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0002243518829346, "eval/reward_neg_acc": 0.9949748516082764, "eval/reward_neg_loss": 0.046239376068115234, "eval/reward_pos_acc": 0.7586206793785095, "eval/reward_pos_loss": 2.340938091278076, "eval/reward_pred": 0.021408699452877045, "eval/reward_rate": 0.0283203125, "replay/size": 436657.0, "replay/inserts": 22256.0, "replay/samples": 22256.0, "replay/insert_wait_avg": 1.2928765939346412e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.350953854218736e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 85640.0, "eval_replay/inserts": 4464.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.091042727125161e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.599592208862305e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3185527324677, "timer/env.step_count": 2782.0, "timer/env.step_total": 249.8229444026947, "timer/env.step_frac": 0.24974338796404302, "timer/env.step_avg": 0.08979976434316847, "timer/env.step_min": 0.022394895553588867, "timer/env.step_max": 3.3214352130889893, "timer/replay._sample_count": 22256.0, "timer/replay._sample_total": 10.931791305541992, "timer/replay._sample_frac": 0.010928310062510325, "timer/replay._sample_avg": 0.0004911840090556252, "timer/replay._sample_min": 0.00037741661071777344, "timer/replay._sample_max": 0.010519981384277344, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3340.0, "timer/agent.policy_total": 54.41210198402405, "timer/agent.policy_frac": 0.05439477438001333, "timer/agent.policy_avg": 0.016291048498210794, "timer/agent.policy_min": 0.00911712646484375, "timer/agent.policy_max": 0.12065625190734863, "timer/dataset_train_count": 1391.0, "timer/dataset_train_total": 0.14548683166503906, "timer/dataset_train_frac": 0.00014544050119597162, "timer/dataset_train_avg": 0.00010459153965854713, "timer/dataset_train_min": 8.845329284667969e-05, "timer/dataset_train_max": 0.0005834102630615234, "timer/agent.train_count": 1391.0, "timer/agent.train_total": 627.1363446712494, "timer/agent.train_frac": 0.6269366322939481, "timer/agent.train_avg": 0.45085287179816635, "timer/agent.train_min": 0.4385337829589844, "timer/agent.train_max": 1.5471866130828857, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4783504009246826, "timer/agent.report_frac": 0.00047819806962294347, "timer/agent.report_avg": 0.2391752004623413, "timer/agent.report_min": 0.23543071746826172, "timer/agent.report_max": 0.2429196834564209, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.3603439331054688e-05, "timer/dataset_eval_frac": 2.359592278537631e-08, "timer/dataset_eval_avg": 2.3603439331054688e-05, "timer/dataset_eval_min": 2.3603439331054688e-05, "timer/dataset_eval_max": 2.3603439331054688e-05, "fps": 22.24863405574187}
{"step": 437168, "time": 20321.14186859131, "episode/length": 146.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9659863945578231, "episode/intrinsic_return": 0.0}
{"step": 437312, "time": 20328.04277253151, "episode/length": 207.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 437488, "time": 20335.630245923996, "episode/length": 245.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 437672, "time": 20343.573025226593, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 437888, "time": 20352.79570698738, "episode/length": 209.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 438104, "time": 20362.017791748047, "episode/length": 53.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 438240, "time": 20368.50303864479, "episode/length": 278.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 438480, "time": 20378.12184357643, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 438816, "time": 20391.04465007782, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 439216, "time": 20405.925788402557, "episode/length": 215.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 439344, "time": 20411.82485818863, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 439464, "time": 20417.212866306305, "episode/length": 286.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9825783972125436, "episode/intrinsic_return": 0.0}
{"step": 439736, "time": 20428.63183927536, "episode/length": 203.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 439824, "time": 20434.028031349182, "episode/length": 44.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9111111111111111, "episode/intrinsic_return": 0.0}
{"step": 440024, "time": 20462.135637283325, "eval_episode/length": 161.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 440024, "time": 20464.458922863007, "eval_episode/length": 179.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 440024, "time": 20466.673179864883, "eval_episode/length": 191.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 440024, "time": 20469.096711158752, "eval_episode/length": 213.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9766355140186916}
{"step": 440024, "time": 20471.5303170681, "eval_episode/length": 229.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 440024, "time": 20474.015513420105, "eval_episode/length": 250.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 440024, "time": 20477.18900513649, "eval_episode/length": 289.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 440024, "time": 20480.756647109985, "eval_episode/length": 174.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 440056, "time": 20481.825181007385, "episode/length": 154.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 440136, "time": 20486.048280000687, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 440200, "time": 20489.62842941284, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 440616, "time": 20504.96563386917, "episode/length": 174.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 440744, "time": 20510.761752843857, "episode/length": 428.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9976689976689976, "episode/intrinsic_return": 0.0}
{"step": 440744, "time": 20510.769149541855, "episode/length": 85.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9302325581395349, "episode/intrinsic_return": 0.0}
{"step": 441080, "time": 20525.203904867172, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9940476190476191, "episode/intrinsic_return": 0.0}
{"step": 441088, "time": 20527.20529270172, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 441672, "time": 20548.14872455597, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 441712, "time": 20551.35840201378, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 441888, "time": 20558.829860448837, "episode/length": 100.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9504950495049505, "episode/intrinsic_return": 0.0}
{"step": 442128, "time": 20568.412771701813, "episode/length": 347.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 442200, "time": 20572.230655431747, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 442496, "time": 20585.545112848282, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9817351598173516, "episode/intrinsic_return": 0.0}
{"step": 442864, "time": 20600.35803627968, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 443152, "time": 20611.591135263443, "episode/length": 184.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 443696, "time": 20631.26564669609, "episode/length": 384.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948051948051948, "episode/intrinsic_return": 0.0}
{"step": 443712, "time": 20633.358855247498, "episode/length": 227.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 443976, "time": 20643.37042117119, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 444456, "time": 20660.87636756897, "episode/length": 198.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 444576, "time": 20666.59449982643, "episode/length": 435.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 445064, "time": 20684.232996463776, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 445120, "time": 20687.91556286812, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 445208, "time": 20692.714590787888, "episode/length": 375.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 445464, "time": 20703.290152549744, "episode/length": 416.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 445480, "time": 20705.39534521103, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 445992, "time": 20724.038531541824, "episode/length": 176.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 446112, "time": 20730.59835243225, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 446576, "time": 20748.43147802353, "episode/length": 181.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 446584, "time": 20750.077262163162, "episode/length": 428.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 446776, "time": 20758.00333714485, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 446784, "time": 20760.056783676147, "episode/length": 196.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 446800, "time": 20762.19210577011, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 446936, "time": 20768.02774453163, "episode/length": 181.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 446976, "time": 20771.283185005188, "episode/length": 49.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.92, "episode/intrinsic_return": 0.0}
{"step": 447472, "time": 20790.07741856575, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 447880, "time": 20805.99555873871, "episode/length": 161.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 448216, "time": 20818.729046583176, "episode/length": 176.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96045197740113, "episode/intrinsic_return": 0.0}
{"step": 448248, "time": 20821.340328216553, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 448328, "time": 20825.643357992172, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 448440, "time": 20831.02817630768, "episode/length": 182.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 448952, "time": 20849.583245515823, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 449176, "time": 20858.611323833466, "episode/length": 397.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.992462311557789, "episode/intrinsic_return": 0.0}
{"step": 449616, "time": 20875.117515325546, "episode/length": 353.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 449872, "time": 20885.286169052124, "episode/length": 178.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 449984, "time": 20890.66685938835, "episode/length": 206.0, "episode/score": 8.1000000461936, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 449984, "time": 20890.676184415817, "episode/length": 216.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 450008, "time": 20915.08243894577, "eval_episode/length": 160.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.968944099378882}
{"step": 450008, "time": 20918.322585344315, "eval_episode/length": 164.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9696969696969697}
{"step": 450008, "time": 20920.733642101288, "eval_episode/length": 181.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 450008, "time": 20922.550757408142, "eval_episode/length": 185.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 450008, "time": 20924.163855314255, "eval_episode/length": 186.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 450008, "time": 20927.008299827576, "eval_episode/length": 214.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 450008, "time": 20929.81878876686, "eval_episode/length": 67.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9852941176470589}
{"step": 450008, "time": 20932.08007287979, "eval_episode/length": 231.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9741379310344828}
{"step": 450016, "time": 20932.58555650711, "episode/length": 224.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 450384, "time": 20948.160098552704, "episode/length": 178.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 450888, "time": 20967.759139060974, "episode/length": 213.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 451088, "time": 20976.239195346832, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9975062344139651, "episode/intrinsic_return": 0.0}
{"step": 451128, "time": 20978.94483590126, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 451352, "time": 20988.10488009453, "episode/length": 216.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 451392, "time": 20991.14450931549, "episode/length": 175.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 451624, "time": 21000.17892050743, "episode/length": 200.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 452240, "time": 21022.35916376114, "episode/length": 231.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 452464, "time": 21031.338653564453, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 452528, "time": 21035.033205747604, "episode/length": 204.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 452640, "time": 21040.426206827164, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 452976, "time": 21053.115387439728, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 453352, "time": 21066.803151845932, "episode/length": 420.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9928741092636579, "episode/intrinsic_return": 0.0}
{"step": 453632, "time": 21077.953310251236, "episode/length": 250.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 453776, "time": 21084.318103551865, "episode/length": 297.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 453888, "time": 21089.622326612473, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 454136, "time": 21099.18528676033, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 454240, "time": 21104.65381217003, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 454264, "time": 21106.81888461113, "episode/length": 202.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 454320, "time": 21110.609461545944, "episode/length": 223.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 454704, "time": 21124.772442102432, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 454832, "time": 21130.58369255066, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 455088, "time": 21140.672220230103, "episode/length": 163.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 455096, "time": 21142.28504729271, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 455216, "time": 21148.00473189354, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 455304, "time": 21152.24067044258, "episode/length": 129.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 455496, "time": 21160.452882051468, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 455584, "time": 21165.299016475677, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 456096, "time": 21183.97221016884, "episode/length": 221.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 456520, "time": 21200.241811037064, "episode/length": 226.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 456576, "time": 21203.796290636063, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 456784, "time": 21212.257814884186, "episode/length": 210.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 456944, "time": 21219.109511613846, "episode/length": 180.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 457360, "time": 21234.542707443237, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 457360, "time": 21234.54930615425, "episode/length": 51.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 457912, "time": 21256.099856615067, "episode/length": 166.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 457952, "time": 21259.15067911148, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 458008, "time": 21262.339437007904, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 458416, "time": 21278.06671142578, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 458496, "time": 21282.923568487167, "episode/length": 425.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 458560, "time": 21287.156703472137, "episode/length": 149.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9933333333333333, "episode/intrinsic_return": 0.0}
{"step": 458904, "time": 21302.053975343704, "episode/length": 192.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 459144, "time": 21311.66130709648, "episode/length": 294.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9864406779661017, "episode/intrinsic_return": 0.0}
{"step": 459353, "time": 21321.145089626312, "train_stats/sum_log_reward": 7.280952471778506, "train_stats/max_log_achievement_collect_coal": 0.23809523809523808, "train_stats/max_log_achievement_collect_drink": 6.942857142857143, "train_stats/max_log_achievement_collect_sapling": 2.0, "train_stats/max_log_achievement_collect_stone": 2.4952380952380953, "train_stats/max_log_achievement_collect_wood": 12.857142857142858, "train_stats/max_log_achievement_defeat_skeleton": 0.01904761904761905, "train_stats/max_log_achievement_defeat_zombie": 0.38095238095238093, "train_stats/max_log_achievement_eat_cow": 0.08571428571428572, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009523809523809525, "train_stats/max_log_achievement_make_stone_sword": 0.009523809523809525, "train_stats/max_log_achievement_make_wood_pickaxe": 2.380952380952381, "train_stats/max_log_achievement_make_wood_sword": 0.21904761904761905, "train_stats/max_log_achievement_place_furnace": 0.047619047619047616, "train_stats/max_log_achievement_place_plant": 1.9238095238095239, "train_stats/max_log_achievement_place_stone": 0.12380952380952381, "train_stats/max_log_achievement_place_table": 2.9523809523809526, "train_stats/max_log_achievement_wake_up": 1.4190476190476191, "train_stats/mean_log_entropy": 0.5565413653850555, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.569133950651978, "train/action_min": 0.0, "train/action_std": 3.43031656827858, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03846465438443551, "train/actor_opt_grad_steps": 27920.0, "train/actor_opt_loss": 0.7611031371751706, "train/adv_mag": 0.5330544564363767, "train/adv_max": 0.5108840478409966, "train/adv_mean": 0.004356565266527678, "train/adv_min": -0.4117924535660435, "train/adv_std": 0.05932329554887984, "train/cont_avg": 0.9946043165467626, "train/cont_loss_mean": 0.000252232775315356, "train/cont_loss_std": 0.0076406212667538215, "train/cont_neg_acc": 0.9928057562533043, "train/cont_neg_loss": 0.02589153486760486, "train/cont_pos_acc": 0.999957620239944, "train/cont_pos_loss": 0.00010596129938482881, "train/cont_pred": 0.9945957219000343, "train/cont_rate": 0.9946043165467626, "train/dyn_loss_mean": 14.390943431168152, "train/dyn_loss_std": 8.96681388333547, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8882307658950201, "train/extr_critic_critic_opt_grad_steps": 27920.0, "train/extr_critic_critic_opt_loss": 15620.77511662545, "train/extr_critic_mag": 6.792964232053688, "train/extr_critic_max": 6.792964232053688, "train/extr_critic_mean": 1.8675543421464, "train/extr_critic_min": -0.17737550529644644, "train/extr_critic_std": 1.6059753182980654, "train/extr_return_normed_mag": 1.651684984886389, "train/extr_return_normed_max": 1.651684984886389, "train/extr_return_normed_mean": 0.36864269315767634, "train/extr_return_normed_min": -0.12286712012166599, "train/extr_return_normed_std": 0.33518000161476275, "train/extr_return_rate": 0.741398325926966, "train/extr_return_raw_mag": 8.173210826709116, "train/extr_return_raw_max": 8.173210826709116, "train/extr_return_raw_mean": 1.888919614201827, "train/extr_return_raw_min": -0.5185536944823299, "train/extr_return_raw_std": 1.6420160060306248, "train/extr_reward_mag": 1.0151373070778607, "train/extr_reward_max": 1.0151373070778607, "train/extr_reward_mean": 0.032143163628769005, "train/extr_reward_min": -0.4178560243236075, "train/extr_reward_std": 0.16642830531588562, "train/image_loss_mean": 7.968989855951542, "train/image_loss_std": 12.60036451696492, "train/model_loss_mean": 16.660093959286915, "train/model_loss_std": 16.22715794268272, "train/model_opt_grad_norm": 68.7699036906949, "train/model_opt_grad_steps": 27892.64748201439, "train/model_opt_loss": 13493.438947279676, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 809.3525179856115, "train/policy_entropy_mag": 2.539455885509793, "train/policy_entropy_max": 2.539455885509793, "train/policy_entropy_mean": 0.5990700998323427, "train/policy_entropy_min": 0.07937516727679067, "train/policy_entropy_std": 0.6738578664313117, "train/policy_logprob_mag": 7.438383418021442, "train/policy_logprob_max": -0.009455731594198042, "train/policy_logprob_mean": -0.5988346938606647, "train/policy_logprob_min": -7.438383418021442, "train/policy_logprob_std": 1.123833418750077, "train/policy_randomness_mag": 0.8963164862968939, "train/policy_randomness_max": 0.8963164862968939, "train/policy_randomness_mean": 0.2114454554996902, "train/policy_randomness_min": 0.028015950681279888, "train/policy_randomness_std": 0.23784225600228892, "train/post_ent_mag": 56.450513496673366, "train/post_ent_max": 56.450513496673366, "train/post_ent_mean": 40.05413250271365, "train/post_ent_min": 20.430722874703168, "train/post_ent_std": 6.9122829059902715, "train/prior_ent_mag": 65.82846563325512, "train/prior_ent_max": 65.82846563325512, "train/prior_ent_mean": 54.452347926956286, "train/prior_ent_min": 38.02604409087476, "train/prior_ent_std": 4.544321809741233, "train/rep_loss_mean": 14.390943431168152, "train/rep_loss_std": 8.96681388333547, "train/reward_avg": 0.026842119848931863, "train/reward_loss_mean": 0.056285994636605115, "train/reward_loss_std": 0.25615986345483244, "train/reward_max_data": 1.0165467665349837, "train/reward_max_pred": 1.0106049604553113, "train/reward_neg_acc": 0.9930455809016879, "train/reward_neg_loss": 0.030248923495197467, "train/reward_pos_acc": 0.9670491424395884, "train/reward_pos_loss": 0.8611490807944923, "train/reward_pred": 0.026156682782411147, "train/reward_rate": 0.03164343525179856, "eval_stats/sum_log_reward": 6.787500083446503, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 6.375, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 2.125, "eval_stats/max_log_achievement_collect_wood": 10.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.0, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 0.0625, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.3125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 0.0019164944533258677, "report/cont_loss_std": 0.05980066582560539, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00374414911493659, "report/cont_pos_acc": 0.9990166425704956, "report/cont_pos_loss": 0.001903914613649249, "report/cont_pred": 0.9923355579376221, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.749669075012207, "report/dyn_loss_std": 8.180444717407227, "report/image_loss_mean": 6.804391384124756, "report/image_loss_std": 11.905320167541504, "report/model_loss_mean": 15.109941482543945, "report/model_loss_std": 15.061050415039062, "report/post_ent_mag": 58.41158676147461, "report/post_ent_max": 58.41158676147461, "report/post_ent_mean": 40.21295928955078, "report/post_ent_min": 16.98436737060547, "report/post_ent_std": 7.395513534545898, "report/prior_ent_mag": 66.16869354248047, "report/prior_ent_max": 66.16869354248047, "report/prior_ent_mean": 54.568214416503906, "report/prior_ent_min": 36.10261917114258, "report/prior_ent_std": 4.6746392250061035, "report/rep_loss_mean": 13.749669075012207, "report/rep_loss_std": 8.180444717407227, "report/reward_avg": 0.03330077975988388, "report/reward_loss_mean": 0.053832609206438065, "report/reward_loss_std": 0.20481957495212555, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0022392272949219, "report/reward_neg_acc": 0.992893397808075, "report/reward_neg_loss": 0.025446482002735138, "report/reward_pos_acc": 0.9743589758872986, "report/reward_pos_loss": 0.7707644104957581, "report/reward_pred": 0.032603710889816284, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00015442956646438688, "eval/cont_loss_std": 0.003517147619277239, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.002102244645357132, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.000150617808685638, "eval/cont_pred": 0.9979067444801331, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 19.22124481201172, "eval/dyn_loss_std": 10.005863189697266, "eval/image_loss_mean": 19.895797729492188, "eval/image_loss_std": 23.06045150756836, "eval/model_loss_mean": 31.518959045410156, "eval/model_loss_std": 27.124732971191406, "eval/post_ent_mag": 56.694095611572266, "eval/post_ent_max": 56.694095611572266, "eval/post_ent_mean": 37.2124137878418, "eval/post_ent_min": 19.825395584106445, "eval/post_ent_std": 5.961453914642334, "eval/prior_ent_mag": 66.16869354248047, "eval/prior_ent_max": 66.16869354248047, "eval/prior_ent_mean": 53.829124450683594, "eval/prior_ent_min": 35.86775207519531, "eval/prior_ent_std": 4.496882915496826, "eval/rep_loss_mean": 19.22124481201172, "eval/rep_loss_std": 10.005863189697266, "eval/reward_avg": 0.03876953199505806, "eval/reward_loss_mean": 0.09026074409484863, "eval/reward_loss_std": 0.5954188108444214, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0047860145568848, "eval/reward_neg_acc": 0.9928717613220215, "eval/reward_neg_loss": 0.03980576992034912, "eval/reward_pos_acc": 0.9285714626312256, "eval/reward_pos_loss": 1.2699459791183472, "eval/reward_pred": 0.03704589232802391, "eval/reward_rate": 0.041015625, "replay/size": 458849.0, "replay/inserts": 22192.0, "replay/samples": 22192.0, "replay/insert_wait_avg": 1.3158574066492148e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.324559961881411e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 90192.0, "eval_replay/inserts": 4552.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1446396370135209e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0187382698059, "timer/env.step_count": 2774.0, "timer/env.step_total": 247.86484599113464, "timer/env.step_frac": 0.24786020151980442, "timer/env.step_avg": 0.08935286445246382, "timer/env.step_min": 0.02220296859741211, "timer/env.step_max": 3.467947006225586, "timer/replay._sample_count": 22192.0, "timer/replay._sample_total": 10.989506006240845, "timer/replay._sample_frac": 0.01098930008577086, "timer/replay._sample_avg": 0.0004952012439726408, "timer/replay._sample_min": 0.0003795623779296875, "timer/replay._sample_max": 0.010888814926147461, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3343.0, "timer/agent.policy_total": 53.66269636154175, "timer/agent.policy_frac": 0.053661690834300654, "timer/agent.policy_avg": 0.0160522573621124, "timer/agent.policy_min": 0.00914144515991211, "timer/agent.policy_max": 0.12981367111206055, "timer/dataset_train_count": 1387.0, "timer/dataset_train_total": 0.14639592170715332, "timer/dataset_train_frac": 0.00014639317855227586, "timer/dataset_train_avg": 0.00010554860973839461, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0004317760467529297, "timer/agent.train_count": 1387.0, "timer/agent.train_total": 625.3236756324768, "timer/agent.train_frac": 0.625311958368288, "timer/agent.train_avg": 0.45084619728368913, "timer/agent.train_min": 0.4349353313446045, "timer/agent.train_max": 1.6391353607177734, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47669553756713867, "timer/agent.report_frac": 0.000476686605284916, "timer/agent.report_avg": 0.23834776878356934, "timer/agent.report_min": 0.23348021507263184, "timer/agent.report_max": 0.24321532249450684, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 7.033348083496094e-05, "timer/dataset_eval_frac": 7.033216293191588e-08, "timer/dataset_eval_avg": 7.033348083496094e-05, "timer/dataset_eval_min": 7.033348083496094e-05, "timer/dataset_eval_max": 7.033348083496094e-05, "fps": 22.1912621543318}
{"step": 459376, "time": 21321.853974342346, "episode/length": 170.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 459384, "time": 21323.684168577194, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 459640, "time": 21333.747250795364, "episode/length": 210.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 460096, "time": 21370.65753698349, "eval_episode/length": 165.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 460096, "time": 21372.49756836891, "eval_episode/length": 174.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 460096, "time": 21374.276373147964, "eval_episode/length": 179.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 460096, "time": 21375.98647093773, "eval_episode/length": 183.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 460096, "time": 21377.74953532219, "eval_episode/length": 186.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 460096, "time": 21379.262538909912, "eval_episode/length": 188.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9947089947089947}
{"step": 460096, "time": 21381.293263196945, "eval_episode/length": 199.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.995}
{"step": 460096, "time": 21383.540465831757, "eval_episode/length": 38.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.8717948717948718}
{"step": 460152, "time": 21385.191499471664, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 460632, "time": 21402.796525001526, "episode/length": 266.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 460824, "time": 21410.637670755386, "episode/length": 239.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 461000, "time": 21418.00134372711, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 461080, "time": 21422.264097213745, "episode/length": 241.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 461136, "time": 21425.85250711441, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 461752, "time": 21447.703577518463, "episode/length": 398.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 461752, "time": 21447.712841033936, "episode/length": 199.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 462088, "time": 21462.291173934937, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 462120, "time": 21464.968059778214, "episode/length": 341.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 462576, "time": 21481.86785054207, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 462648, "time": 21485.590631723404, "episode/length": 251.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 462880, "time": 21495.167424678802, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 463032, "time": 21501.670491695404, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 463232, "time": 21510.091175079346, "episode/length": 184.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 463856, "time": 21532.32066845894, "episode/length": 220.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 464224, "time": 21546.111137390137, "episode/length": 262.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 464344, "time": 21551.517648220062, "episode/length": 220.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 464392, "time": 21554.74236536026, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787735849056604, "episode/intrinsic_return": 0.0}
{"step": 464424, "time": 21557.4237909317, "episode/length": 221.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 464504, "time": 21561.69176864624, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 464568, "time": 21565.414450883865, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 464680, "time": 21570.7128841877, "episode/length": 224.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 465008, "time": 21583.74066758156, "episode/length": 54.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 465200, "time": 21592.452484369278, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 465664, "time": 21610.270800352097, "episode/length": 154.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 465680, "time": 21612.45202732086, "episode/length": 166.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 465792, "time": 21617.674723386765, "episode/length": 174.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 465968, "time": 21625.120427131653, "episode/length": 217.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 466512, "time": 21644.91169834137, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 466728, "time": 21654.103397369385, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 466792, "time": 21657.80047273636, "episode/length": 140.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9716312056737588, "episode/intrinsic_return": 0.0}
{"step": 466800, "time": 21659.783442497253, "episode/length": 199.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 467104, "time": 21672.92245864868, "episode/length": 302.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 467424, "time": 21685.08999323845, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 467488, "time": 21688.792857408524, "episode/length": 47.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 467560, "time": 21692.47699713707, "episode/length": 220.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 467608, "time": 21695.572989940643, "episode/length": 204.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9707317073170731, "episode/intrinsic_return": 0.0}
{"step": 467816, "time": 21704.150745868683, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 468032, "time": 21713.31293296814, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 468040, "time": 21714.957118988037, "episode/length": 154.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 468080, "time": 21718.02046227455, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 468648, "time": 21738.420726776123, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 469008, "time": 21752.706179142, "episode/length": 189.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 469304, "time": 21763.992483139038, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 469328, "time": 21766.68154191971, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 469768, "time": 21782.525321483612, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 469776, "time": 21784.635487556458, "episode/length": 217.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 469856, "time": 21788.896249055862, "episode/length": 286.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9895470383275261, "episode/intrinsic_return": 0.0}
{"step": 470080, "time": 21813.464484214783, "eval_episode/length": 58.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 470080, "time": 21819.19040799141, "eval_episode/length": 164.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9757575757575757}
{"step": 470080, "time": 21821.961104869843, "eval_episode/length": 189.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 470080, "time": 21823.744034528732, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 470080, "time": 21825.94144129753, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9952380952380953}
{"step": 470080, "time": 21827.9915163517, "eval_episode/length": 220.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9864253393665159}
{"step": 470080, "time": 21830.472218990326, "eval_episode/length": 53.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 470080, "time": 21832.6260035038, "eval_episode/length": 258.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9806949806949807}
{"step": 470112, "time": 21833.693283081055, "episode/length": 258.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 470320, "time": 21842.191047906876, "episode/length": 163.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 470552, "time": 21851.304950475693, "episode/length": 237.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 470672, "time": 21857.031373023987, "episode/length": 170.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9941520467836257, "episode/intrinsic_return": 0.0}
{"step": 470704, "time": 21859.6738615036, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 471112, "time": 21874.574969291687, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 471440, "time": 21887.327924966812, "episode/length": 207.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 471856, "time": 21902.750763893127, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 471864, "time": 21904.391627311707, "episode/length": 261.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9847328244274809, "episode/intrinsic_return": 0.0}
{"step": 471912, "time": 21907.44948244095, "episode/length": 169.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9588235294117647, "episode/intrinsic_return": 0.0}
{"step": 471936, "time": 21910.152997732162, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 472040, "time": 21914.965527296066, "episode/length": 240.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 472096, "time": 21918.637188911438, "episode/length": 173.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 473032, "time": 21951.431606292725, "episode/length": 239.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 473176, "time": 21958.0480093956, "episode/length": 163.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 473232, "time": 21961.668481111526, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 473528, "time": 21972.882671117783, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 473864, "time": 21986.119522333145, "episode/length": 250.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 474360, "time": 22005.29707956314, "episode/length": 305.0, "episode/score": 8.099999941885471, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 474512, "time": 22012.562222242355, "episode/length": 301.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9801324503311258, "episode/intrinsic_return": 0.0}
{"step": 474584, "time": 22016.336586475372, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 474776, "time": 22024.251098632812, "episode/length": 155.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 475024, "time": 22034.365256786346, "episode/length": 223.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 475272, "time": 22045.43913626671, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 475776, "time": 22064.07982158661, "episode/length": 324.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 475848, "time": 22067.800956964493, "episode/length": 185.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 475968, "time": 22073.52405357361, "episode/length": 181.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 476000, "time": 22076.203169584274, "episode/length": 507.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9921259842519685, "episode/intrinsic_return": 0.0}
{"step": 476792, "time": 22103.835122346878, "episode/length": 189.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 477408, "time": 22125.98518562317, "episode/length": 328.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9908814589665653, "episode/intrinsic_return": 0.0}
{"step": 477648, "time": 22135.435304641724, "episode/length": 233.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 477656, "time": 22136.97882628441, "episode/length": 383.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 477880, "time": 22145.93252134323, "episode/length": 58.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 478040, "time": 22152.799384593964, "episode/length": 254.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 478304, "time": 22163.28054690361, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 478848, "time": 22183.016645669937, "episode/length": 374.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 479096, "time": 22192.530073165894, "episode/length": 151.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 479104, "time": 22194.582133293152, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 479320, "time": 22203.143570661545, "episode/length": 418.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9976133651551312, "episode/intrinsic_return": 0.0}
{"step": 479624, "time": 22215.44307732582, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 479696, "time": 22219.531401634216, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 480064, "time": 22248.12292599678, "eval_episode/length": 46.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9148936170212766}
{"step": 480064, "time": 22254.34800839424, "eval_episode/length": 163.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 480064, "time": 22256.623025655746, "eval_episode/length": 179.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9944444444444445}
{"step": 480064, "time": 22258.961127996445, "eval_episode/length": 196.0, "eval_episode/score": 9.099999964237213, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 480064, "time": 22260.692207813263, "eval_episode/length": 199.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 480064, "time": 22262.862172842026, "eval_episode/length": 214.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 480064, "time": 22262.871053934097, "eval_episode/length": 214.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 480064, "time": 22267.074883937836, "eval_episode/length": 189.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 480576, "time": 22284.366319179535, "episode/length": 183.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 480672, "time": 22289.605309724808, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 480896, "time": 22298.73548054695, "episode/length": 158.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 480904, "time": 22300.917509794235, "episode/length": 225.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 480920, "time": 22303.51826429367, "episode/length": 359.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9972222222222222, "episode/intrinsic_return": 0.0}
{"step": 480968, "time": 22307.068324804306, "episode/length": 205.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 481056, "time": 22312.29669356346, "episode/length": 424.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9905882352941177, "episode/intrinsic_return": 0.0}
{"step": 481241, "time": 22321.33730173111, "train_stats/sum_log_reward": 7.7500001192092896, "train_stats/max_log_achievement_collect_coal": 0.35, "train_stats/max_log_achievement_collect_drink": 5.58, "train_stats/max_log_achievement_collect_sapling": 1.75, "train_stats/max_log_achievement_collect_stone": 3.63, "train_stats/max_log_achievement_collect_wood": 13.32, "train_stats/max_log_achievement_defeat_skeleton": 0.04, "train_stats/max_log_achievement_defeat_zombie": 0.47, "train_stats/max_log_achievement_eat_cow": 0.11, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.01, "train_stats/max_log_achievement_make_wood_pickaxe": 1.9, "train_stats/max_log_achievement_make_wood_sword": 0.26, "train_stats/max_log_achievement_place_furnace": 0.04, "train_stats/max_log_achievement_place_plant": 1.69, "train_stats/max_log_achievement_place_stone": 1.38, "train_stats/max_log_achievement_place_table": 2.69, "train_stats/max_log_achievement_wake_up": 1.34, "train_stats/mean_log_entropy": 0.6001875226199627, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.382511779339644, "train/action_min": 0.0, "train/action_std": 3.2451876671644895, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03636949664376078, "train/actor_opt_grad_steps": 29300.0, "train/actor_opt_loss": -6.370378283253552, "train/adv_mag": 0.5142728943024238, "train/adv_max": 0.48923662196110634, "train/adv_mean": 0.002388174785067409, "train/adv_min": -0.39071980771357123, "train/adv_std": 0.056686731096166766, "train/cont_avg": 0.9946823677007299, "train/cont_loss_mean": 0.0003628267812727839, "train/cont_loss_std": 0.01046782590595992, "train/cont_neg_acc": 0.9864268359476632, "train/cont_neg_loss": 0.030873658192466374, "train/cont_pos_acc": 0.9999211530615814, "train/cont_pos_loss": 0.00020426151834954413, "train/cont_pred": 0.9946792130052609, "train/cont_rate": 0.9946823677007299, "train/dyn_loss_mean": 14.10101239002534, "train/dyn_loss_std": 8.963478561735501, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.892517934315396, "train/extr_critic_critic_opt_grad_steps": 29300.0, "train/extr_critic_critic_opt_loss": 15476.327818487682, "train/extr_critic_mag": 7.048414463544414, "train/extr_critic_max": 7.048414463544414, "train/extr_critic_mean": 1.933705952915832, "train/extr_critic_min": -0.1695859301699339, "train/extr_critic_std": 1.6619877414981814, "train/extr_return_normed_mag": 1.6034079276732285, "train/extr_return_normed_max": 1.6034079276732285, "train/extr_return_normed_mean": 0.35672639712800075, "train/extr_return_normed_min": -0.128107748354656, "train/extr_return_normed_std": 0.32919662581743114, "train/extr_return_rate": 0.7417655513234382, "train/extr_return_raw_mag": 8.341432595775075, "train/extr_return_raw_max": 8.341432595775075, "train/extr_return_raw_mean": 1.9459520343446384, "train/extr_return_raw_min": -0.5413998218565962, "train/extr_return_raw_std": 1.6890312154797742, "train/extr_reward_mag": 1.0180902707315709, "train/extr_reward_max": 1.0180902707315709, "train/extr_reward_mean": 0.03184692818589889, "train/extr_reward_min": -0.41568710334109565, "train/extr_reward_std": 0.1661400988589238, "train/image_loss_mean": 7.5211319053260075, "train/image_loss_std": 12.340706919231554, "train/model_loss_mean": 16.039183672327194, "train/model_loss_std": 16.01126232982552, "train/model_opt_grad_norm": 63.07282467449413, "train/model_opt_grad_steps": 29271.75182481752, "train/model_opt_loss": 13903.570929088732, "train/model_opt_model_opt_grad_overflow": 0.0072992700729927005, "train/model_opt_model_opt_grad_scale": 862.2262773722628, "train/policy_entropy_mag": 2.4813726783668906, "train/policy_entropy_max": 2.4813726783668906, "train/policy_entropy_mean": 0.5952828226298311, "train/policy_entropy_min": 0.07937514830897324, "train/policy_entropy_std": 0.6737373479961479, "train/policy_logprob_mag": 7.438383509642886, "train/policy_logprob_max": -0.009455709364673081, "train/policy_logprob_mean": -0.5951546737312401, "train/policy_logprob_min": -7.438383509642886, "train/policy_logprob_std": 1.1259766547349248, "train/policy_randomness_mag": 0.8758156643296681, "train/policy_randomness_max": 0.8758156643296681, "train/policy_randomness_mean": 0.21010871427337618, "train/policy_randomness_min": 0.028015944046260666, "train/policy_randomness_std": 0.2377997187584856, "train/post_ent_mag": 56.842327591276515, "train/post_ent_max": 56.842327591276515, "train/post_ent_mean": 40.43381040809798, "train/post_ent_min": 20.05865256455693, "train/post_ent_std": 7.0340842539376585, "train/prior_ent_mag": 65.77659545675681, "train/prior_ent_max": 65.77659545675681, "train/prior_ent_mean": 54.59113954975657, "train/prior_ent_min": 38.63787827874622, "train/prior_ent_std": 4.439294500072507, "train/rep_loss_mean": 14.10101239002534, "train/rep_loss_std": 8.963478561735501, "train/reward_avg": 0.02648979241884973, "train/reward_loss_mean": 0.05708164194204511, "train/reward_loss_std": 0.2629398679646262, "train/reward_max_data": 1.015328470807876, "train/reward_max_pred": 1.0131909368682082, "train/reward_neg_acc": 0.9932689453563551, "train/reward_neg_loss": 0.031064710341883402, "train/reward_pos_acc": 0.9645948318669396, "train/reward_pos_loss": 0.8597726982875462, "train/reward_pred": 0.025721188553058317, "train/reward_rate": 0.03147097399635036, "eval_stats/sum_log_reward": 6.975000162919362, "eval_stats/max_log_achievement_collect_coal": 0.041666666666666664, "eval_stats/max_log_achievement_collect_drink": 4.416666666666667, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 2.375, "eval_stats/max_log_achievement_collect_wood": 10.458333333333334, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 2.0, "eval_stats/max_log_achievement_make_wood_sword": 0.16666666666666666, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 1.0833333333333333, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 6.056891652406193e-05, "report/cont_loss_std": 0.0011569652706384659, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00035493678296916187, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.912451888434589e-05, "report/cont_pred": 0.9950608015060425, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.345788955688477, "report/dyn_loss_std": 8.897436141967773, "report/image_loss_mean": 7.535003185272217, "report/image_loss_std": 11.853909492492676, "report/model_loss_mean": 16.192073822021484, "report/model_loss_std": 15.252321243286133, "report/post_ent_mag": 56.97049331665039, "report/post_ent_max": 56.97049331665039, "report/post_ent_mean": 40.63761520385742, "report/post_ent_min": 17.721954345703125, "report/post_ent_std": 7.122218132019043, "report/prior_ent_mag": 65.84268188476562, "report/prior_ent_max": 65.84268188476562, "report/prior_ent_mean": 54.747459411621094, "report/prior_ent_min": 34.32819366455078, "report/prior_ent_std": 4.725443363189697, "report/rep_loss_mean": 14.345788955688477, "report/rep_loss_std": 8.897436141967773, "report/reward_avg": 0.02998046763241291, "report/reward_loss_mean": 0.04953652620315552, "report/reward_loss_std": 0.1803998351097107, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002274751663208, "report/reward_neg_acc": 0.9979776740074158, "report/reward_neg_loss": 0.02695656195282936, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6875816583633423, "report/reward_pred": 0.029773898422718048, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 0.00016905134543776512, "eval/cont_loss_std": 0.00295799458399415, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.02546747401356697, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 0.00011954367073485628, "eval/cont_pred": 0.9979794025421143, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.96038818359375, "eval/dyn_loss_std": 9.52950668334961, "eval/image_loss_mean": 19.47314453125, "eval/image_loss_std": 22.402982711791992, "eval/model_loss_mean": 30.357486724853516, "eval/model_loss_std": 26.186782836914062, "eval/post_ent_mag": 61.24333953857422, "eval/post_ent_max": 61.24333953857422, "eval/post_ent_mean": 40.9173698425293, "eval/post_ent_min": 21.48626708984375, "eval/post_ent_std": 7.594755172729492, "eval/prior_ent_mag": 65.84268188476562, "eval/prior_ent_max": 65.84268188476562, "eval/prior_ent_mean": 56.289581298828125, "eval/prior_ent_min": 39.1953010559082, "eval/prior_ent_std": 4.126737594604492, "eval/rep_loss_mean": 17.96038818359375, "eval/rep_loss_std": 9.52950668334961, "eval/reward_avg": 0.01923828199505806, "eval/reward_loss_mean": 0.10794050991535187, "eval/reward_loss_std": 0.7942941188812256, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011584758758545, "eval/reward_neg_acc": 0.9920000433921814, "eval/reward_neg_loss": 0.03166764974594116, "eval/reward_pos_acc": 0.625, "eval/reward_pos_loss": 3.2859764099121094, "eval/reward_pred": 0.011357849463820457, "eval/reward_rate": 0.0234375, "replay/size": 480737.0, "replay/inserts": 21888.0, "replay/samples": 21888.0, "replay/insert_wait_avg": 1.3160840635411224e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.327493519810905e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 95912.0, "eval_replay/inserts": 5720.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1108138344504617e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1766998767853, "timer/env.step_count": 2736.0, "timer/env.step_total": 235.74362969398499, "timer/env.step_frac": 0.2357019811829519, "timer/env.step_avg": 0.08616360734429276, "timer/env.step_min": 0.022049903869628906, "timer/env.step_max": 3.34840989112854, "timer/replay._sample_count": 21888.0, "timer/replay._sample_total": 10.950562477111816, "timer/replay._sample_frac": 0.010948627855918708, "timer/replay._sample_avg": 0.0005002998207744799, "timer/replay._sample_min": 0.00041484832763671875, "timer/replay._sample_max": 0.025116920471191406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3451.0, "timer/agent.policy_total": 55.05502939224243, "timer/agent.policy_frac": 0.05504530289400345, "timer/agent.policy_avg": 0.015953355373005632, "timer/agent.policy_min": 0.009169816970825195, "timer/agent.policy_max": 0.09082531929016113, "timer/dataset_train_count": 1368.0, "timer/dataset_train_total": 0.14563846588134766, "timer/dataset_train_frac": 0.00014561273612881534, "timer/dataset_train_avg": 0.00010646086687233015, "timer/dataset_train_min": 9.34600830078125e-05, "timer/dataset_train_max": 0.0010752677917480469, "timer/agent.train_count": 1368.0, "timer/agent.train_total": 614.3637089729309, "timer/agent.train_frac": 0.6142551701600489, "timer/agent.train_avg": 0.4490962784889846, "timer/agent.train_min": 0.43619227409362793, "timer/agent.train_max": 1.6722259521484375, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47362327575683594, "timer/agent.report_frac": 0.0004735396013676213, "timer/agent.report_avg": 0.23681163787841797, "timer/agent.report_min": 0.231292724609375, "timer/agent.report_max": 0.24233055114746094, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 9.918212890625e-05, "timer/dataset_eval_frac": 9.916460653249425e-08, "timer/dataset_eval_avg": 9.918212890625e-05, "timer/dataset_eval_min": 9.918212890625e-05, "timer/dataset_eval_max": 9.918212890625e-05, "fps": 21.883830008159297}
{"step": 482216, "time": 22354.299817562103, "episode/length": 192.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 482248, "time": 22357.45629310608, "episode/length": 318.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9843260188087775, "episode/intrinsic_return": 0.0}
{"step": 482248, "time": 22357.472789287567, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 482272, "time": 22363.06202840805, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 482464, "time": 22371.05784201622, "episode/length": 175.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 482584, "time": 22376.23283815384, "episode/length": 41.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 483144, "time": 22396.436205148697, "episode/length": 108.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 483528, "time": 22412.338723421097, "episode/length": 319.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 483624, "time": 22417.087250232697, "episode/length": 171.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 484000, "time": 22431.42050766945, "episode/length": 191.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 484176, "time": 22438.901628255844, "episode/length": 449.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 484176, "time": 22438.91502380371, "episode/length": 409.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975609756097561, "episode/intrinsic_return": 0.0}
{"step": 484272, "time": 22446.579012155533, "episode/length": 256.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9766536964980544, "episode/intrinsic_return": 0.0}
{"step": 484336, "time": 22450.935765504837, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 484736, "time": 22465.706409931183, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 484880, "time": 22471.996737003326, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 485568, "time": 22497.66830420494, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 485600, "time": 22500.33029317856, "episode/length": 165.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 485640, "time": 22503.705654382706, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 485720, "time": 22507.953815221786, "episode/length": 214.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 485800, "time": 22512.372415065765, "episode/length": 283.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 486032, "time": 22522.654032468796, "episode/length": 48.0, "episode/score": 4.099999979138374, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 486184, "time": 22529.694848060608, "episode/length": 230.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 486320, "time": 22536.669318199158, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 486784, "time": 22554.410996437073, "episode/length": 255.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 487104, "time": 22566.62235379219, "episode/length": 39.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 487120, "time": 22568.726330280304, "episode/length": 193.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 487448, "time": 22581.23511147499, "episode/length": 230.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 487608, "time": 22588.758813619614, "episode/length": 196.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 487608, "time": 22588.768080711365, "episode/length": 225.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9823008849557522, "episode/intrinsic_return": 0.0}
{"step": 488040, "time": 22607.639080762863, "episode/length": 231.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 488048, "time": 22609.617785215378, "episode/length": 215.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 488616, "time": 22630.22565484047, "episode/length": 361.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9751381215469613, "episode/intrinsic_return": 0.0}
{"step": 488632, "time": 22632.915444612503, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 488800, "time": 22640.81816291809, "episode/length": 209.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 488952, "time": 22647.859714746475, "episode/length": 187.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 489680, "time": 22674.208914756775, "episode/length": 203.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 489928, "time": 22683.750047922134, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 490016, "time": 22688.452155828476, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9800664451827242, "episode/intrinsic_return": 0.0}
{"step": 490040, "time": 22691.148418664932, "episode/length": 177.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22693.629662036896, "episode/length": 250.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 490048, "time": 22713.220263957977, "eval_episode/length": 65.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9848484848484849}
{"step": 490048, "time": 22719.237658023834, "eval_episode/length": 152.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 490048, "time": 22722.93995475769, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9791666666666666}
{"step": 490048, "time": 22724.80173945427, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 490048, "time": 22727.59007692337, "eval_episode/length": 225.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.995575221238938}
{"step": 490048, "time": 22729.280678987503, "eval_episode/length": 162.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 490048, "time": 22733.212636470795, "eval_episode/length": 251.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9841269841269841}
{"step": 490048, "time": 22736.326343774796, "eval_episode/length": 283.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9823943661971831}
{"step": 490160, "time": 22741.555365800858, "episode/length": 150.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 490376, "time": 22750.047041654587, "episode/length": 44.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 490424, "time": 22753.100514411926, "episode/length": 351.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 490512, "time": 22757.79043984413, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9626168224299065, "episode/intrinsic_return": 0.0}
{"step": 490552, "time": 22760.365074634552, "episode/length": 63.0, "episode/score": 3.0999999940395355, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 490904, "time": 22773.53882598877, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 491800, "time": 22806.400488376617, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 491944, "time": 22812.888796806335, "episode/length": 178.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 491960, "time": 22815.050595760345, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 492088, "time": 22820.826426267624, "episode/length": 269.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 492520, "time": 22836.811409950256, "episode/length": 267.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 492808, "time": 22847.97611141205, "episode/length": 237.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 493328, "time": 22866.892209768295, "episode/length": 346.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 493424, "time": 22871.588190317154, "episode/length": 166.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 493520, "time": 22876.362800359726, "episode/length": 194.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 493560, "time": 22879.076829195023, "episode/length": 219.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 493656, "time": 22883.845759391785, "episode/length": 403.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9801980198019802, "episode/intrinsic_return": 0.0}
{"step": 493992, "time": 22897.884941101074, "episode/length": 183.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 494576, "time": 22919.11210012436, "episode/length": 155.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 494584, "time": 22920.727756023407, "episode/length": 329.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.990909090909091, "episode/intrinsic_return": 0.0}
{"step": 495072, "time": 22938.84780216217, "episode/length": 176.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 495248, "time": 22946.32030415535, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 495696, "time": 22962.85714316368, "episode/length": 212.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 495840, "time": 22969.30748796463, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 495936, "time": 22974.041504859924, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 495984, "time": 22977.169511556625, "episode/length": 319.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 496112, "time": 22982.949007987976, "episode/length": 318.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 496312, "time": 22990.989993810654, "episode/length": 437.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 496368, "time": 22994.634952545166, "episode/length": 161.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 496624, "time": 23004.674568414688, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 497056, "time": 23020.742418289185, "episode/length": 169.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 497448, "time": 23035.083007335663, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 497864, "time": 23050.77847480774, "episode/length": 240.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 497920, "time": 23055.064748764038, "episode/length": 193.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 498072, "time": 23062.16278362274, "episode/length": 260.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 498216, "time": 23069.000180482864, "episode/length": 262.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 498400, "time": 23076.8550157547, "episode/length": 59.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 498432, "time": 23079.40432548523, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 498760, "time": 23091.72119283676, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 498832, "time": 23095.883202552795, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 498856, "time": 23098.050889492035, "episode/length": 52.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 499464, "time": 23119.741356611252, "episode/length": 155.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 499720, "time": 23130.03851723671, "episode/length": 231.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 499760, "time": 23134.918295621872, "episode/length": 210.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 500032, "time": 23164.841675043106, "eval_episode/length": 158.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9559748427672956}
{"step": 500032, "time": 23166.591972112656, "eval_episode/length": 163.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 500032, "time": 23166.599794387817, "eval_episode/length": 163.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9939024390243902}
{"step": 500032, "time": 23170.444501161575, "eval_episode/length": 171.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 500032, "time": 23172.47934603691, "eval_episode/length": 184.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9837837837837838}
{"step": 500032, "time": 23175.068774461746, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 500032, "time": 23180.322108268738, "eval_episode/length": 301.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9867549668874173}
{"step": 500032, "time": 23182.493165254593, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9736842105263158}
{"step": 500208, "time": 23188.326223373413, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 500272, "time": 23192.02045059204, "episode/length": 352.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 500376, "time": 23196.855060577393, "episode/length": 189.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 500584, "time": 23205.386732578278, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 501016, "time": 23221.09475493431, "episode/length": 281.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9858156028368794, "episode/intrinsic_return": 0.0}
{"step": 501328, "time": 23233.338449954987, "episode/length": 195.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 501424, "time": 23238.070409059525, "episode/length": 143.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 501448, "time": 23240.262395858765, "episode/length": 247.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9838709677419355, "episode/intrinsic_return": 0.0}
{"step": 501512, "time": 23243.956542491913, "episode/length": 223.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 501576, "time": 23248.050519943237, "episode/length": 170.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 501648, "time": 23252.694307804108, "episode/length": 158.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 501872, "time": 23262.427195072174, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 502648, "time": 23290.524143457413, "episode/length": 149.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 502672, "time": 23293.530257940292, "episode/length": 206.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 502808, "time": 23299.914940834045, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 503056, "time": 23309.929901123047, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 503232, "time": 23317.407225608826, "episode/length": 197.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 503289, "time": 23321.707721948624, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.097161731580748, "train/action_min": 0.0, "train/action_std": 2.949825528764377, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03805586536598467, "train/actor_opt_grad_steps": 30670.0, "train/actor_opt_loss": -1.7076725814029248, "train/adv_mag": 0.5448483596317959, "train/adv_max": 0.5085808478132652, "train/adv_mean": 0.003911524530344882, "train/adv_min": -0.4205515983983548, "train/adv_std": 0.059318089327455435, "train/cont_avg": 0.9949175980839416, "train/cont_loss_mean": 0.0002914616029705115, "train/cont_loss_std": 0.008654957301550347, "train/cont_neg_acc": 0.9916990015241834, "train/cont_neg_loss": 0.030042104933279377, "train/cont_pos_acc": 0.9999713127630471, "train/cont_pos_loss": 0.00012668272268997398, "train/cont_pred": 0.9949155454217953, "train/cont_rate": 0.9949175980839416, "train/dyn_loss_mean": 14.122765742949326, "train/dyn_loss_std": 8.912664966861698, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9170001445025423, "train/extr_critic_critic_opt_grad_steps": 30670.0, "train/extr_critic_critic_opt_loss": 15794.64332658531, "train/extr_critic_mag": 7.17528875726853, "train/extr_critic_max": 7.17528875726853, "train/extr_critic_mean": 2.0393816032548893, "train/extr_critic_min": -0.15587461081734538, "train/extr_critic_std": 1.6252538279025224, "train/extr_return_normed_mag": 1.6203989086359958, "train/extr_return_normed_max": 1.6203989086359958, "train/extr_return_normed_mean": 0.3745716317509213, "train/extr_return_normed_min": -0.12516474848218861, "train/extr_return_normed_std": 0.32587911982605927, "train/extr_return_rate": 0.7959193878800329, "train/extr_return_raw_mag": 8.407308898703025, "train/extr_return_raw_max": 8.407308898703025, "train/extr_return_raw_mean": 2.0592931804865815, "train/extr_return_raw_min": -0.4879925076435082, "train/extr_return_raw_std": 1.660737421390784, "train/extr_reward_mag": 1.0160541499618196, "train/extr_reward_max": 1.0160541499618196, "train/extr_reward_mean": 0.03378203074808103, "train/extr_reward_min": -0.40727610396642755, "train/extr_reward_std": 0.1701565124366405, "train/image_loss_mean": 7.506436915293227, "train/image_loss_std": 12.572983122220004, "train/model_loss_mean": 16.035260346684144, "train/model_loss_std": 16.17339873487932, "train/model_opt_grad_norm": 63.69895871016231, "train/model_opt_grad_steps": 30640.649635036498, "train/model_opt_loss": 11627.417027828467, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 725.3649635036496, "train/policy_entropy_mag": 2.5016538435525266, "train/policy_entropy_max": 2.5016538435525266, "train/policy_entropy_mean": 0.5214050396950576, "train/policy_entropy_min": 0.07937515037555765, "train/policy_entropy_std": 0.5807702180242886, "train/policy_logprob_mag": 7.43838358969584, "train/policy_logprob_max": -0.009455711954701556, "train/policy_logprob_mean": -0.5208984089158747, "train/policy_logprob_min": -7.43838358969584, "train/policy_logprob_std": 1.0814394119882236, "train/policy_randomness_mag": 0.882974021626215, "train/policy_randomness_max": 0.882974021626215, "train/policy_randomness_mean": 0.1840330982295266, "train/policy_randomness_min": 0.028015944916401466, "train/policy_randomness_std": 0.20498640063035228, "train/post_ent_mag": 57.11290189645586, "train/post_ent_max": 57.11290189645586, "train/post_ent_mean": 40.53729119962149, "train/post_ent_min": 20.256380206477033, "train/post_ent_std": 7.048105145892958, "train/prior_ent_mag": 65.89012808695327, "train/prior_ent_max": 65.89012808695327, "train/prior_ent_mean": 54.724779142950574, "train/prior_ent_min": 38.651083758277615, "train/prior_ent_std": 4.393994507128305, "train/rep_loss_mean": 14.122765742949326, "train/rep_loss_std": 8.912664966861698, "train/reward_avg": 0.0282012715147142, "train/reward_loss_mean": 0.05487248954111642, "train/reward_loss_std": 0.24622252561750202, "train/reward_max_data": 1.0175182523518582, "train/reward_max_pred": 1.0094453453147498, "train/reward_neg_acc": 0.9935820241914178, "train/reward_neg_loss": 0.028360038176586812, "train/reward_pos_acc": 0.9663682788827993, "train/reward_pos_loss": 0.8478996927720787, "train/reward_pred": 0.027277323492143277, "train/reward_rate": 0.03276830520072993, "train_stats/sum_log_reward": 7.639215810626161, "train_stats/max_log_achievement_collect_coal": 0.19607843137254902, "train_stats/max_log_achievement_collect_drink": 7.588235294117647, "train_stats/max_log_achievement_collect_sapling": 1.8333333333333333, "train_stats/max_log_achievement_collect_stone": 4.186274509803922, "train_stats/max_log_achievement_collect_wood": 12.46078431372549, "train_stats/max_log_achievement_defeat_skeleton": 0.00980392156862745, "train_stats/max_log_achievement_defeat_zombie": 0.5588235294117647, "train_stats/max_log_achievement_eat_cow": 0.09803921568627451, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.6764705882352942, "train_stats/max_log_achievement_make_wood_sword": 0.12745098039215685, "train_stats/max_log_achievement_place_furnace": 0.029411764705882353, "train_stats/max_log_achievement_place_plant": 1.7450980392156863, "train_stats/max_log_achievement_place_stone": 3.1862745098039214, "train_stats/max_log_achievement_place_table": 2.7941176470588234, "train_stats/max_log_achievement_wake_up": 1.2450980392156863, "train_stats/mean_log_entropy": 0.5072659070000929, "eval_stats/sum_log_reward": 7.725000202655792, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 6.6875, "eval_stats/max_log_achievement_collect_wood": 9.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5625, "eval_stats/max_log_achievement_make_wood_sword": 0.0625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5625, "eval_stats/max_log_achievement_place_stone": 5.125, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.0, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.998046875, "report/cont_loss_mean": 5.120145488035632e-06, "report/cont_loss_std": 0.00010986020788550377, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0019545131362974644, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.3052863323537167e-06, "report/cont_pred": 0.9980494976043701, "report/cont_rate": 0.998046875, "report/dyn_loss_mean": 12.576519012451172, "report/dyn_loss_std": 9.000885963439941, "report/image_loss_mean": 7.112112045288086, "report/image_loss_std": 13.27439022064209, "report/model_loss_mean": 14.707761764526367, "report/model_loss_std": 16.742507934570312, "report/post_ent_mag": 55.261356353759766, "report/post_ent_max": 55.261356353759766, "report/post_ent_mean": 41.51005935668945, "report/post_ent_min": 19.322307586669922, "report/post_ent_std": 6.786393165588379, "report/prior_ent_mag": 65.67256164550781, "report/prior_ent_max": 65.67256164550781, "report/prior_ent_mean": 54.46123123168945, "report/prior_ent_min": 38.934242248535156, "report/prior_ent_std": 4.3834099769592285, "report/rep_loss_mean": 12.576519012451172, "report/rep_loss_std": 9.000885963439941, "report/reward_avg": 0.03447265550494194, "report/reward_loss_mean": 0.049733541905879974, "report/reward_loss_std": 0.23344314098358154, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0059814453125, "report/reward_neg_acc": 0.9989867806434631, "report/reward_neg_loss": 0.017882874235510826, "report/reward_pos_acc": 0.9459459185600281, "report/reward_pos_loss": 0.8993717432022095, "report/reward_pred": 0.0312550850212574, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 3.389089397387579e-05, "eval/cont_loss_std": 0.0006824659649282694, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0010853128042072058, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.976766882056836e-05, "eval/cont_pred": 0.9960686564445496, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.52202796936035, "eval/dyn_loss_std": 9.57264518737793, "eval/image_loss_mean": 11.30086612701416, "eval/image_loss_std": 16.34357452392578, "eval/model_loss_mean": 21.948516845703125, "eval/model_loss_std": 20.086193084716797, "eval/post_ent_mag": 55.82894515991211, "eval/post_ent_max": 55.82894515991211, "eval/post_ent_mean": 39.61564636230469, "eval/post_ent_min": 19.550600051879883, "eval/post_ent_std": 6.680832386016846, "eval/prior_ent_mag": 65.67256164550781, "eval/prior_ent_max": 65.67256164550781, "eval/prior_ent_mean": 55.06855773925781, "eval/prior_ent_min": 41.37834167480469, "eval/prior_ent_std": 3.9845962524414062, "eval/rep_loss_mean": 17.52202796936035, "eval/rep_loss_std": 9.57264518737793, "eval/reward_avg": 0.04345703125, "eval/reward_loss_mean": 0.13439959287643433, "eval/reward_loss_std": 0.8217665553092957, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.03322172164917, "eval/reward_neg_acc": 0.9928205013275146, "eval/reward_neg_loss": 0.03361876681447029, "eval/reward_pos_acc": 0.795918345451355, "eval/reward_pos_loss": 2.139732599258423, "eval/reward_pred": 0.034289974719285965, "eval/reward_rate": 0.0478515625, "replay/size": 502785.0, "replay/inserts": 22048.0, "replay/samples": 22048.0, "replay/insert_wait_avg": 1.3233052974861488e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.387537222642165e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4800.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1341770490010579e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3570246696472, "timer/env.step_count": 2756.0, "timer/env.step_total": 249.4944486618042, "timer/env.step_frac": 0.24940540477955456, "timer/env.step_avg": 0.09052773899194637, "timer/env.step_min": 0.022565603256225586, "timer/env.step_max": 4.564205169677734, "timer/replay._sample_count": 22048.0, "timer/replay._sample_total": 11.029876947402954, "timer/replay._sample_frac": 0.011025940414668856, "timer/replay._sample_avg": 0.0005002665524039802, "timer/replay._sample_min": 0.00041675567626953125, "timer/replay._sample_max": 0.00885915756225586, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3356.0, "timer/agent.policy_total": 55.022993087768555, "timer/agent.policy_frac": 0.05500335553292992, "timer/agent.policy_avg": 0.016395409144150344, "timer/agent.policy_min": 0.009336709976196289, "timer/agent.policy_max": 0.10402154922485352, "timer/dataset_train_count": 1378.0, "timer/dataset_train_total": 0.1469125747680664, "timer/dataset_train_frac": 0.00014686014207435796, "timer/dataset_train_avg": 0.00010661289896086097, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.00044083595275878906, "timer/agent.train_count": 1378.0, "timer/agent.train_total": 620.9591608047485, "timer/agent.train_frac": 0.6207375421888109, "timer/agent.train_avg": 0.45062348389314116, "timer/agent.train_min": 0.4364299774169922, "timer/agent.train_max": 1.805492639541626, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47791314125061035, "timer/agent.report_frac": 0.00047774257536546406, "timer/agent.report_avg": 0.23895657062530518, "timer/agent.report_min": 0.23236584663391113, "timer/agent.report_max": 0.24554729461669922, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0040740966796875e-05, "timer/dataset_eval_frac": 3.0030019509002176e-08, "timer/dataset_eval_avg": 3.0040740966796875e-05, "timer/dataset_eval_min": 3.0040740966796875e-05, "timer/dataset_eval_max": 3.0040740966796875e-05, "fps": 22.03982755797208}
{"step": 503496, "time": 23328.424610376358, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 503512, "time": 23330.552223920822, "episode/length": 87.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9886363636363636, "episode/intrinsic_return": 0.0}
{"step": 503888, "time": 23344.791378498077, "episode/length": 48.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 504160, "time": 23355.47655415535, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 504248, "time": 23359.686417102814, "episode/length": 296.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9865319865319865, "episode/intrinsic_return": 0.0}
{"step": 504464, "time": 23368.768384218216, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 504552, "time": 23372.996631860733, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 504688, "time": 23379.347002267838, "episode/length": 203.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 504816, "time": 23385.26649236679, "episode/length": 162.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 505144, "time": 23397.46330142021, "episode/length": 445.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9932735426008968, "episode/intrinsic_return": 0.0}
{"step": 505464, "time": 23409.720563173294, "episode/length": 162.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9815950920245399, "episode/intrinsic_return": 0.0}
{"step": 505728, "time": 23420.264662265778, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 506000, "time": 23430.955797195435, "episode/length": 147.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9932432432432432, "episode/intrinsic_return": 0.0}
{"step": 506096, "time": 23435.74530005455, "episode/length": 230.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 506240, "time": 23442.19029521942, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 506440, "time": 23450.25042128563, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9703389830508474, "episode/intrinsic_return": 0.0}
{"step": 506688, "time": 23460.148249149323, "episode/length": 152.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 506824, "time": 23465.956161499023, "episode/length": 366.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989100817438692, "episode/intrinsic_return": 0.0}
{"step": 506872, "time": 23469.103962183, "episode/length": 78.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 506928, "time": 23472.836951494217, "episode/length": 222.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9865470852017937, "episode/intrinsic_return": 0.0}
{"step": 507288, "time": 23486.056956529617, "episode/length": 160.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 507344, "time": 23489.886805057526, "episode/length": 58.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 507808, "time": 23506.894613027573, "episode/length": 213.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 507880, "time": 23510.587636232376, "episode/length": 268.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9739776951672863, "episode/intrinsic_return": 0.0}
{"step": 508072, "time": 23520.016379356384, "episode/length": 155.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 508232, "time": 23527.53955411911, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 508296, "time": 23531.513746500015, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 508760, "time": 23548.52053618431, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 508768, "time": 23550.781131267548, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 509224, "time": 23567.685529708862, "episode/length": 143.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 509248, "time": 23570.636180639267, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 509496, "time": 23580.905537366867, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 509680, "time": 23589.414176225662, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 509848, "time": 23596.49735212326, "episode/length": 193.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9845360824742269, "episode/intrinsic_return": 0.0}
{"step": 509920, "time": 23600.646488666534, "episode/length": 210.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 510016, "time": 23625.62898492813, "eval_episode/length": 178.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9776536312849162}
{"step": 510016, "time": 23627.61270713806, "eval_episode/length": 186.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9786096256684492}
{"step": 510016, "time": 23629.41095638275, "eval_episode/length": 193.0, "eval_episode/score": 9.100000016391277, "eval_episode/reward_rate": 0.9845360824742269}
{"step": 510016, "time": 23631.065136432648, "eval_episode/length": 197.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9747474747474747}
{"step": 510016, "time": 23632.765996456146, "eval_episode/length": 198.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 510016, "time": 23634.693168640137, "eval_episode/length": 205.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.970873786407767}
{"step": 510016, "time": 23636.70078778267, "eval_episode/length": 214.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9720930232558139}
{"step": 510016, "time": 23639.025116205215, "eval_episode/length": 230.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9653679653679653}
{"step": 510192, "time": 23644.844115257263, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 510984, "time": 23673.198826551437, "episode/length": 185.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9946236559139785, "episode/intrinsic_return": 0.0}
{"step": 511072, "time": 23678.21650981903, "episode/length": 227.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 511120, "time": 23681.467360973358, "episode/length": 179.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 511144, "time": 23683.74162220955, "episode/length": 297.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 511176, "time": 23686.482086658478, "episode/length": 243.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 511840, "time": 23710.28452897072, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 512112, "time": 23721.2597720623, "episode/length": 120.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 512232, "time": 23727.158350467682, "episode/length": 138.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9712230215827338, "episode/intrinsic_return": 0.0}
{"step": 512464, "time": 23737.288559436798, "episode/length": 283.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9823943661971831, "episode/intrinsic_return": 0.0}
{"step": 512768, "time": 23748.967234134674, "episode/length": 81.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9390243902439024, "episode/intrinsic_return": 0.0}
{"step": 512864, "time": 23753.697409152985, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 512960, "time": 23758.449514865875, "episode/length": 388.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 513136, "time": 23765.799113750458, "episode/length": 268.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 513240, "time": 23770.745983600616, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.977859778597786, "episode/intrinsic_return": 0.0}
{"step": 513968, "time": 23796.61505126953, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9627659574468085, "episode/intrinsic_return": 0.0}
{"step": 514232, "time": 23806.832709789276, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 514400, "time": 23814.211884737015, "episode/length": 203.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 514528, "time": 23820.0363073349, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 514560, "time": 23822.568203687668, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 514616, "time": 23825.803003549576, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 514768, "time": 23832.731852054596, "episode/length": 365.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9972677595628415, "episode/intrinsic_return": 0.0}
{"step": 515168, "time": 23847.330929994583, "episode/length": 275.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 515504, "time": 23860.10531926155, "episode/length": 191.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 515536, "time": 23862.68099808693, "episode/length": 121.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9918032786885246, "episode/intrinsic_return": 0.0}
{"step": 515904, "time": 23876.744510173798, "episode/length": 208.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 515952, "time": 23880.349549531937, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 516168, "time": 23891.123106241226, "episode/length": 204.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 516328, "time": 23898.467654943466, "episode/length": 194.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 516464, "time": 23905.0057618618, "episode/length": 257.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9728682170542635, "episode/intrinsic_return": 0.0}
{"step": 516984, "time": 23923.87199640274, "episode/length": 180.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 517216, "time": 23934.00847053528, "episode/length": 255.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 517472, "time": 23944.114486455917, "episode/length": 245.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 517576, "time": 23948.83508515358, "episode/length": 208.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 517584, "time": 23951.01264476776, "episode/length": 156.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9936305732484076, "episode/intrinsic_return": 0.0}
{"step": 518024, "time": 23966.850170612335, "episode/length": 258.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 518160, "time": 23973.174054145813, "episode/length": 248.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9959839357429718, "episode/intrinsic_return": 0.0}
{"step": 518184, "time": 23975.34759235382, "episode/length": 120.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 518312, "time": 23981.292157411575, "episode/length": 230.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 518456, "time": 23987.60223507881, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 519408, "time": 24021.00812649727, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 519488, "time": 24025.301324367523, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 519488, "time": 24025.310443878174, "episode/length": 237.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9747899159663865, "episode/intrinsic_return": 0.0}
{"step": 519784, "time": 24038.22492337227, "episode/length": 165.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 519888, "time": 24043.530439138412, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 519896, "time": 24045.13991713524, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9658119658119658, "episode/intrinsic_return": 0.0}
{"step": 519920, "time": 24047.73507642746, "episode/length": 292.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 520000, "time": 24067.349043369293, "eval_episode/length": 60.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 520000, "time": 24072.584839582443, "eval_episode/length": 129.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9923076923076923}
{"step": 520000, "time": 24075.638845443726, "eval_episode/length": 152.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9673202614379085}
{"step": 520000, "time": 24078.105492830276, "eval_episode/length": 159.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 520000, "time": 24081.51646065712, "eval_episode/length": 184.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.972972972972973}
{"step": 520000, "time": 24083.885820150375, "eval_episode/length": 60.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 520000, "time": 24087.817419052124, "eval_episode/length": 229.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9956521739130435}
{"step": 520000, "time": 24089.706842184067, "eval_episode/length": 230.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9783549783549783}
{"step": 520144, "time": 24094.648827552795, "episode/length": 244.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 520816, "time": 24118.87510061264, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 521128, "time": 24130.586230039597, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 521336, "time": 24139.08832192421, "episode/length": 148.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 521392, "time": 24142.82071328163, "episode/length": 187.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 521624, "time": 24151.92213702202, "episode/length": 212.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 521632, "time": 24153.93484187126, "episode/length": 267.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 522424, "time": 24181.555346250534, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 522496, "time": 24185.669244527817, "episode/length": 324.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9938461538461538, "episode/intrinsic_return": 0.0}
{"step": 522568, "time": 24189.43140244484, "episode/length": 394.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9974683544303797, "episode/intrinsic_return": 0.0}
{"step": 522848, "time": 24200.79559612274, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 522904, "time": 24203.978073358536, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 522968, "time": 24207.64880156517, "episode/length": 196.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 523392, "time": 24223.636853456497, "episode/length": 219.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 523584, "time": 24231.468734025955, "episode/length": 244.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 523888, "time": 24243.117748975754, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 524056, "time": 24250.134766101837, "episode/length": 185.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 524264, "time": 24258.597318649292, "episode/length": 169.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 524288, "time": 24261.42000102997, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 524448, "time": 24269.99160504341, "episode/length": 252.0, "episode/score": 6.1000000312924385, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 524864, "time": 24285.34639263153, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 524936, "time": 24289.03647184372, "episode/length": 245.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 525104, "time": 24296.356949090958, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 525432, "time": 24308.503454446793, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 525753, "time": 24321.755711078644, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.06612834524601, "train/action_min": 0.0, "train/action_std": 2.947617919732493, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03641831564406554, "train/actor_opt_grad_steps": 32060.0, "train/actor_opt_loss": 1.111573002651228, "train/adv_mag": 0.5038982414184733, "train/adv_max": 0.467807744411712, "train/adv_mean": 0.004345565389453021, "train/adv_min": -0.3944317656205901, "train/adv_std": 0.056421762768258436, "train/cont_avg": 0.9951656693262412, "train/cont_loss_mean": 0.00023653862294765454, "train/cont_loss_std": 0.007152104343958854, "train/cont_neg_acc": 0.9950239812727455, "train/cont_neg_loss": 0.03167463919896409, "train/cont_pos_acc": 0.999972088117126, "train/cont_pos_loss": 7.918776338658195e-05, "train/cont_pred": 0.9951567489204677, "train/cont_rate": 0.9951656693262412, "train/dyn_loss_mean": 14.056829925969982, "train/dyn_loss_std": 9.006761956722178, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9342981834783621, "train/extr_critic_critic_opt_grad_steps": 32060.0, "train/extr_critic_critic_opt_loss": 15847.14078429743, "train/extr_critic_mag": 7.603596247679798, "train/extr_critic_max": 7.603596247679798, "train/extr_critic_mean": 2.20897823107158, "train/extr_critic_min": -0.16862528036672172, "train/extr_critic_std": 1.7245018084843953, "train/extr_return_normed_mag": 1.5847249791977254, "train/extr_return_normed_max": 1.5847249791977254, "train/extr_return_normed_mean": 0.37605578499905606, "train/extr_return_normed_min": -0.128160297342226, "train/extr_return_normed_std": 0.32160283456034694, "train/extr_return_rate": 0.8416316200655403, "train/extr_return_raw_mag": 8.846935539380878, "train/extr_return_raw_max": 8.846935539380878, "train/extr_return_raw_mean": 2.2326710300242647, "train/extr_return_raw_min": -0.5257779612397471, "train/extr_return_raw_std": 1.7596711630516864, "train/extr_reward_mag": 1.0199490455870932, "train/extr_reward_max": 1.0199490455870932, "train/extr_reward_mean": 0.03451048662053778, "train/extr_reward_min": -0.4386244809373896, "train/extr_reward_std": 0.17155208005338696, "train/image_loss_mean": 7.510164954138141, "train/image_loss_std": 12.396947945263369, "train/model_loss_mean": 16.000261212071628, "train/model_loss_std": 16.04318095944452, "train/model_opt_grad_norm": 61.693331765790354, "train/model_opt_grad_steps": 32029.936170212764, "train/model_opt_loss": 15706.740580673759, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 979.6099290780141, "train/policy_entropy_mag": 2.524506746454442, "train/policy_entropy_max": 2.524506746454442, "train/policy_entropy_mean": 0.525185595378808, "train/policy_entropy_min": 0.0793751358246127, "train/policy_entropy_std": 0.5872895210347278, "train/policy_logprob_mag": 7.438383548817736, "train/policy_logprob_max": -0.009455712928258359, "train/policy_logprob_mean": -0.5240022529524269, "train/policy_logprob_min": -7.438383548817736, "train/policy_logprob_std": 1.0791631860935942, "train/policy_randomness_mag": 0.8910400960462314, "train/policy_randomness_max": 0.8910400960462314, "train/policy_randomness_mean": 0.18536746766127593, "train/policy_randomness_min": 0.028015939941537296, "train/policy_randomness_std": 0.20728743034051667, "train/post_ent_mag": 57.03553374270175, "train/post_ent_max": 57.03553374270175, "train/post_ent_mean": 40.75618151400952, "train/post_ent_min": 19.98088330072714, "train/post_ent_std": 7.1347515363219784, "train/prior_ent_mag": 66.0248460160925, "train/prior_ent_max": 66.0248460160925, "train/prior_ent_mean": 54.82208817394067, "train/prior_ent_min": 38.83801575248123, "train/prior_ent_std": 4.385473041669697, "train/rep_loss_mean": 14.056829925969982, "train/rep_loss_std": 9.006761956722178, "train/reward_avg": 0.027821641930557313, "train/reward_loss_mean": 0.0557618499436277, "train/reward_loss_std": 0.25844723482926685, "train/reward_max_data": 1.0148936205721917, "train/reward_max_pred": 1.0122567888692762, "train/reward_neg_acc": 0.9931603226255863, "train/reward_neg_loss": 0.028671762919225168, "train/reward_pos_acc": 0.964643915917011, "train/reward_pos_loss": 0.8670515096779411, "train/reward_pred": 0.026955764535946627, "train/reward_rate": 0.03235123005319149, "train_stats/sum_log_reward": 8.307547294868613, "train_stats/max_log_achievement_collect_coal": 0.2358490566037736, "train_stats/max_log_achievement_collect_drink": 3.5849056603773586, "train_stats/max_log_achievement_collect_sapling": 1.5943396226415094, "train_stats/max_log_achievement_collect_stone": 6.518867924528302, "train_stats/max_log_achievement_collect_wood": 12.273584905660377, "train_stats/max_log_achievement_defeat_skeleton": 0.018867924528301886, "train_stats/max_log_achievement_defeat_zombie": 0.6981132075471698, "train_stats/max_log_achievement_eat_cow": 0.09433962264150944, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4245283018867925, "train_stats/max_log_achievement_make_wood_sword": 0.8113207547169812, "train_stats/max_log_achievement_place_furnace": 0.02830188679245283, "train_stats/max_log_achievement_place_plant": 1.5471698113207548, "train_stats/max_log_achievement_place_stone": 5.132075471698113, "train_stats/max_log_achievement_place_table": 2.6320754716981134, "train_stats/max_log_achievement_wake_up": 1.1320754716981132, "train_stats/mean_log_entropy": 0.5340735736601757, "eval_stats/sum_log_reward": 8.100000202655792, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 2.125, "eval_stats/max_log_achievement_collect_sapling": 1.8125, "eval_stats/max_log_achievement_collect_stone": 5.0, "eval_stats/max_log_achievement_collect_wood": 14.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3125, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.8125, "eval_stats/max_log_achievement_place_stone": 3.5, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00011392456508474424, "report/cont_loss_std": 0.0035305125638842583, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 1.4315711268864106e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00011441332753747702, "report/cont_pred": 0.9950094223022461, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 15.201347351074219, "report/dyn_loss_std": 9.091999053955078, "report/image_loss_mean": 7.198282241821289, "report/image_loss_std": 11.778959274291992, "report/model_loss_mean": 16.370220184326172, "report/model_loss_std": 15.38620376586914, "report/post_ent_mag": 55.089820861816406, "report/post_ent_max": 55.089820861816406, "report/post_ent_mean": 39.320091247558594, "report/post_ent_min": 21.56218910217285, "report/post_ent_std": 6.73337984085083, "report/prior_ent_mag": 66.07331848144531, "report/prior_ent_max": 66.07331848144531, "report/prior_ent_mean": 54.56293487548828, "report/prior_ent_min": 37.087467193603516, "report/prior_ent_std": 4.16716194152832, "report/rep_loss_mean": 15.201347351074219, "report/rep_loss_std": 9.091999053955078, "report/reward_avg": 0.05019531399011612, "report/reward_loss_mean": 0.05101630091667175, "report/reward_loss_std": 0.1808839589357376, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011677742004395, "report/reward_neg_acc": 0.9917526245117188, "report/reward_neg_loss": 0.013049358502030373, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7330151200294495, "report/reward_pred": 0.049655403941869736, "report/reward_rate": 0.052734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.6319205542458803e-06, "eval/cont_loss_std": 7.349671705014771e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 9.824963854043745e-06, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.607847025297815e-06, "eval/cont_pred": 0.9970687627792358, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.503643035888672, "eval/dyn_loss_std": 9.823040008544922, "eval/image_loss_mean": 13.404666900634766, "eval/image_loss_std": 15.976289749145508, "eval/model_loss_mean": 24.016845703125, "eval/model_loss_std": 19.676311492919922, "eval/post_ent_mag": 57.81135559082031, "eval/post_ent_max": 57.81135559082031, "eval/post_ent_mean": 39.63146209716797, "eval/post_ent_min": 17.68801498413086, "eval/post_ent_std": 7.137825965881348, "eval/prior_ent_mag": 66.07331848144531, "eval/prior_ent_max": 66.07331848144531, "eval/prior_ent_mean": 55.057952880859375, "eval/prior_ent_min": 39.2909049987793, "eval/prior_ent_std": 4.431105136871338, "eval/rep_loss_mean": 17.503643035888672, "eval/rep_loss_std": 9.823040008544922, "eval/reward_avg": 0.03925780951976776, "eval/reward_loss_mean": 0.10999029129743576, "eval/reward_loss_std": 0.7438329458236694, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.005105972290039, "eval/reward_neg_acc": 0.9948979020118713, "eval/reward_neg_loss": 0.029910651966929436, "eval/reward_pos_acc": 0.8409091234207153, "eval/reward_pos_loss": 1.8935823440551758, "eval/reward_pred": 0.029819341376423836, "eval/reward_rate": 0.04296875, "replay/size": 525249.0, "replay/inserts": 22464.0, "replay/samples": 22464.0, "replay/insert_wait_avg": 1.3073327874186371e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.474354529312873e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3696.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.106749881397594e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0353803634644, "timer/env.step_count": 2808.0, "timer/env.step_total": 249.83747506141663, "timer/env.step_frac": 0.24982863603346997, "timer/env.step_avg": 0.08897345977970678, "timer/env.step_min": 0.022340059280395508, "timer/env.step_max": 3.320786476135254, "timer/replay._sample_count": 22464.0, "timer/replay._sample_total": 11.239863634109497, "timer/replay._sample_frac": 0.01123946597771806, "timer/replay._sample_avg": 0.0005003500549372105, "timer/replay._sample_min": 0.0004169940948486328, "timer/replay._sample_max": 0.010798215866088867, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3270.0, "timer/agent.policy_total": 52.32980298995972, "timer/agent.policy_frac": 0.05232795160801248, "timer/agent.policy_avg": 0.016002997856256793, "timer/agent.policy_min": 0.009411096572875977, "timer/agent.policy_max": 0.10272645950317383, "timer/dataset_train_count": 1404.0, "timer/dataset_train_total": 0.1478867530822754, "timer/dataset_train_frac": 0.00014788152098031346, "timer/dataset_train_avg": 0.00010533244521529586, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0003085136413574219, "timer/agent.train_count": 1404.0, "timer/agent.train_total": 628.7796366214752, "timer/agent.train_frac": 0.6287573909564523, "timer/agent.train_avg": 0.4478487440323898, "timer/agent.train_min": 0.43485212326049805, "timer/agent.train_max": 1.6387710571289062, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4725315570831299, "timer/agent.report_frac": 0.0004725148393363719, "timer/agent.report_avg": 0.23626577854156494, "timer/agent.report_min": 0.2292778491973877, "timer/agent.report_max": 0.2432537078857422, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9324447719873468e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 22.462908726660306}
{"step": 525760, "time": 24321.78413295746, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 525832, "time": 24325.982992887497, "episode/length": 120.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 525952, "time": 24331.74767971039, "episode/length": 236.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 526008, "time": 24335.01964044571, "episode/length": 214.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 526496, "time": 24353.046783685684, "episode/length": 173.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 526736, "time": 24362.589473962784, "episode/length": 355.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9803370786516854, "episode/intrinsic_return": 0.0}
{"step": 526752, "time": 24364.65737581253, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 527096, "time": 24377.551580667496, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 527408, "time": 24389.69255042076, "episode/length": 181.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 527704, "time": 24401.005156993866, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 527752, "time": 24404.287661075592, "episode/length": 156.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 528384, "time": 24426.986861228943, "episode/length": 430.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9976798143851509, "episode/intrinsic_return": 0.0}
{"step": 528552, "time": 24434.156484127045, "episode/length": 348.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9885386819484241, "episode/intrinsic_return": 0.0}
{"step": 528592, "time": 24437.783521413803, "episode/length": 229.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 528840, "time": 24448.2194545269, "episode/length": 217.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 528936, "time": 24453.555666208267, "episode/length": 190.0, "episode/score": 5.1000000312924385, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 529240, "time": 24466.083855867386, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 529432, "time": 24473.987616539, "episode/length": 130.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9618320610687023, "episode/intrinsic_return": 0.0}
{"step": 529456, "time": 24476.458936691284, "episode/length": 218.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 529544, "time": 24481.176291942596, "episode/length": 350.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 529896, "time": 24495.086007356644, "episode/length": 167.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 530088, "time": 24523.994837522507, "eval_episode/length": 180.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 530088, "time": 24526.255985975266, "eval_episode/length": 185.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 530088, "time": 24529.715639829636, "eval_episode/length": 202.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 530088, "time": 24533.190281152725, "eval_episode/length": 208.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 530088, "time": 24536.15783762932, "eval_episode/length": 228.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9737991266375546}
{"step": 530088, "time": 24539.125044345856, "eval_episode/length": 248.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 530088, "time": 24544.626878261566, "eval_episode/length": 333.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9910179640718563}
{"step": 530088, "time": 24548.735678195953, "eval_episode/length": 145.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9657534246575342}
{"step": 530240, "time": 24554.100989818573, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 530464, "time": 24563.09981894493, "episode/length": 202.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 530560, "time": 24567.91041278839, "episode/length": 245.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 530888, "time": 24580.197640419006, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 531152, "time": 24590.755069494247, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 531232, "time": 24594.928956508636, "episode/length": 224.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 531576, "time": 24607.694514751434, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 531648, "time": 24611.915549993515, "episode/length": 273.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 531800, "time": 24618.370971918106, "episode/length": 194.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 532360, "time": 24638.63868331909, "episode/length": 183.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 532400, "time": 24641.911903858185, "episode/length": 241.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 532584, "time": 24650.84587264061, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 532632, "time": 24654.11699938774, "episode/length": 258.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 532736, "time": 24659.292660474777, "episode/length": 116.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9914529914529915, "episode/intrinsic_return": 0.0}
{"step": 533000, "time": 24669.52625322342, "episode/length": 168.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 533368, "time": 24683.35062766075, "episode/length": 223.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 533736, "time": 24697.151852607727, "episode/length": 322.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9969040247678018, "episode/intrinsic_return": 0.0}
{"step": 533904, "time": 24704.68892264366, "episode/length": 158.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 534176, "time": 24715.26342868805, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9819819819819819, "episode/intrinsic_return": 0.0}
{"step": 534240, "time": 24718.95174765587, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 534288, "time": 24722.046553850174, "episode/length": 160.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9503105590062112, "episode/intrinsic_return": 0.0}
{"step": 535368, "time": 24759.763865709305, "episode/length": 328.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9848024316109423, "episode/intrinsic_return": 0.0}
{"step": 535504, "time": 24766.003585100174, "episode/length": 392.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974554707379135, "episode/intrinsic_return": 0.0}
{"step": 535632, "time": 24771.852138757706, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 535664, "time": 24774.98318386078, "episode/length": 219.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 536152, "time": 24792.984409093857, "episode/length": 347.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9913793103448276, "episode/intrinsic_return": 0.0}
{"step": 536304, "time": 24799.672228336334, "episode/length": 257.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 536808, "time": 24817.742189884186, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 536976, "time": 24825.222690343857, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 537368, "time": 24839.440410375595, "episode/length": 398.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 537512, "time": 24845.822058439255, "episode/length": 471.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9978813559322034, "episode/intrinsic_return": 0.0}
{"step": 537624, "time": 24851.19807457924, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 538032, "time": 24866.375092744827, "episode/length": 295.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9898648648648649, "episode/intrinsic_return": 0.0}
{"step": 538160, "time": 24872.176481723785, "episode/length": 315.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 538336, "time": 24879.82684111595, "episode/length": 169.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 538360, "time": 24881.983684301376, "episode/length": 256.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 538456, "time": 24886.808195114136, "episode/length": 205.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 538688, "time": 24896.17851781845, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 539344, "time": 24919.54153418541, "episode/length": 228.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9781659388646288, "episode/intrinsic_return": 0.0}
{"step": 539360, "time": 24921.666285037994, "episode/length": 165.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 539376, "time": 24923.706267356873, "episode/length": 218.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 539992, "time": 24945.55939245224, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 540048, "time": 24949.167342424393, "episode/length": 210.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 540072, "time": 24970.06474995613, "eval_episode/length": 143.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 540072, "time": 24972.45801758766, "eval_episode/length": 161.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 540072, "time": 24974.478536128998, "eval_episode/length": 173.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 540072, "time": 24977.87553691864, "eval_episode/length": 217.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 540072, "time": 24979.824203014374, "eval_episode/length": 228.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9737991266375546}
{"step": 540072, "time": 24981.809939146042, "eval_episode/length": 240.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.995850622406639}
{"step": 540072, "time": 24984.08678650856, "eval_episode/length": 84.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9529411764705882}
{"step": 540072, "time": 24987.304396629333, "eval_episode/length": 300.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9900332225913622}
{"step": 540192, "time": 24991.514097452164, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.978448275862069, "episode/intrinsic_return": 0.0}
{"step": 540456, "time": 25001.55673313141, "episode/length": 286.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 540928, "time": 25020.549181699753, "episode/length": 193.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 540936, "time": 25022.10131764412, "episode/length": 309.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9903225806451613, "episode/intrinsic_return": 0.0}
{"step": 541384, "time": 25038.438101291656, "episode/length": 252.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 541416, "time": 25041.158204317093, "episode/length": 258.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 541856, "time": 25057.776166439056, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 541864, "time": 25059.391396522522, "episode/length": 233.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 542200, "time": 25072.191496372223, "episode/length": 157.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 542512, "time": 25084.412479400635, "episode/length": 256.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 542752, "time": 25094.06017446518, "episode/length": 227.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 543368, "time": 25116.202519655228, "episode/length": 243.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 543440, "time": 25120.436377763748, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9646464646464646, "episode/intrinsic_return": 0.0}
{"step": 543472, "time": 25123.13646531105, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 543568, "time": 25127.858721971512, "episode/length": 212.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 543584, "time": 25129.87285375595, "episode/length": 441.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.997737556561086, "episode/intrinsic_return": 0.0}
{"step": 543640, "time": 25133.01261162758, "episode/length": 179.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 544200, "time": 25153.54101395607, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 544608, "time": 25168.829155683517, "episode/length": 145.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 544928, "time": 25181.05975818634, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 544984, "time": 25184.25826239586, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 544992, "time": 25186.72739505768, "episode/length": 279.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9964285714285714, "episode/intrinsic_return": 0.0}
{"step": 545024, "time": 25189.744415283203, "episode/length": 179.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 545304, "time": 25201.093307733536, "episode/length": 241.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 545744, "time": 25217.941096544266, "episode/length": 271.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9816176470588235, "episode/intrinsic_return": 0.0}
{"step": 546120, "time": 25231.7381772995, "episode/length": 148.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 546280, "time": 25238.68724679947, "episode/length": 161.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 546648, "time": 25252.72985100746, "episode/length": 202.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9852216748768473, "episode/intrinsic_return": 0.0}
{"step": 546720, "time": 25256.853942871094, "episode/length": 314.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 546720, "time": 25256.86034798622, "episode/length": 54.0, "episode/score": 6.0999999940395355, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 546728, "time": 25260.13264155388, "episode/length": 177.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9831460674157303, "episode/intrinsic_return": 0.0}
{"step": 547776, "time": 25296.903337955475, "episode/length": 347.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9885057471264368, "episode/intrinsic_return": 0.0}
{"step": 547816, "time": 25299.642111301422, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 548032, "time": 25308.662920713425, "episode/length": 238.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9832635983263598, "episode/intrinsic_return": 0.0}
{"step": 548216, "time": 25316.14196372032, "episode/length": 195.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 548313, "time": 25321.93237042427, "train_stats/sum_log_reward": 8.342424436049027, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_collect_drink": 4.797979797979798, "train_stats/max_log_achievement_collect_sapling": 1.7373737373737375, "train_stats/max_log_achievement_collect_stone": 7.747474747474747, "train_stats/max_log_achievement_collect_wood": 12.080808080808081, "train_stats/max_log_achievement_defeat_skeleton": 0.030303030303030304, "train_stats/max_log_achievement_defeat_zombie": 0.6363636363636364, "train_stats/max_log_achievement_eat_cow": 0.10101010101010101, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.606060606060606, "train_stats/max_log_achievement_make_wood_sword": 0.5858585858585859, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.696969696969697, "train_stats/max_log_achievement_place_stone": 6.343434343434343, "train_stats/max_log_achievement_place_table": 2.595959595959596, "train_stats/max_log_achievement_wake_up": 1.3131313131313131, "train_stats/mean_log_entropy": 0.5622736299880827, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.180993046320922, "train/action_min": 0.0, "train/action_std": 3.0337109295188958, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03665881577535724, "train/actor_opt_grad_steps": 33470.0, "train/actor_opt_loss": -2.6419195665693875, "train/adv_mag": 0.5147546011928126, "train/adv_max": 0.466310202229953, "train/adv_mean": 0.0038535008116917114, "train/adv_min": -0.4104754339295922, "train/adv_std": 0.056592226900318836, "train/cont_avg": 0.9948470744680851, "train/cont_loss_mean": 0.00043863679726018827, "train/cont_loss_std": 0.012605068307620227, "train/cont_neg_acc": 0.9807244201078482, "train/cont_neg_loss": 0.06018218469572398, "train/cont_pos_acc": 0.9999581769848547, "train/cont_pos_loss": 0.00012606284095413895, "train/cont_pred": 0.9948891342108976, "train/cont_rate": 0.9948470744680851, "train/dyn_loss_mean": 13.93190054521493, "train/dyn_loss_std": 8.955388796244952, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9213043666900472, "train/extr_critic_critic_opt_grad_steps": 33470.0, "train/extr_critic_critic_opt_loss": 15696.249064993352, "train/extr_critic_mag": 7.831849077914623, "train/extr_critic_max": 7.831849077914623, "train/extr_critic_mean": 2.400144227007602, "train/extr_critic_min": -0.17069394030469529, "train/extr_critic_std": 1.7704888125683398, "train/extr_return_normed_mag": 1.5749034678682368, "train/extr_return_normed_max": 1.5749034678682368, "train/extr_return_normed_mean": 0.3900028591883098, "train/extr_return_normed_min": -0.13794343575095455, "train/extr_return_normed_std": 0.32262079248614345, "train/extr_return_rate": 0.8856812833894229, "train/extr_return_raw_mag": 9.038208092358095, "train/extr_return_raw_max": 9.038208092358095, "train/extr_return_raw_mean": 2.421638918261156, "train/extr_return_raw_min": -0.5262078774947647, "train/extr_return_raw_std": 1.801525761895146, "train/extr_reward_mag": 1.020940971712694, "train/extr_reward_max": 1.020940971712694, "train/extr_reward_mean": 0.03556986071222217, "train/extr_reward_min": -0.47306436258004914, "train/extr_reward_std": 0.1752555955809059, "train/image_loss_mean": 7.2868436921572854, "train/image_loss_std": 12.31899363943871, "train/model_loss_mean": 15.701949640368738, "train/model_loss_std": 15.940236585360047, "train/model_opt_grad_norm": 63.24606124390947, "train/model_opt_grad_steps": 33439.0, "train/model_opt_loss": 13321.16034325133, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 846.6312056737588, "train/policy_entropy_mag": 2.5019342764049557, "train/policy_entropy_max": 2.5019342764049557, "train/policy_entropy_mean": 0.5265055355873514, "train/policy_entropy_min": 0.07937512615471022, "train/policy_entropy_std": 0.5944344769132898, "train/policy_logprob_mag": 7.438383569108679, "train/policy_logprob_max": -0.009455700345495914, "train/policy_logprob_mean": -0.5264968436660497, "train/policy_logprob_min": -7.438383569108679, "train/policy_logprob_std": 1.08205014129057, "train/policy_randomness_mag": 0.8830730061159067, "train/policy_randomness_max": 0.8830730061159067, "train/policy_randomness_mean": 0.18583334918985975, "train/policy_randomness_min": 0.02801593636155974, "train/policy_randomness_std": 0.20980928510638838, "train/post_ent_mag": 56.89031333111702, "train/post_ent_max": 56.89031333111702, "train/post_ent_mean": 40.855607999977494, "train/post_ent_min": 20.093221650901416, "train/post_ent_std": 7.096146468575119, "train/prior_ent_mag": 66.08469239363434, "train/prior_ent_max": 66.08469239363434, "train/prior_ent_mean": 54.827555636142165, "train/prior_ent_min": 38.82088916859728, "train/prior_ent_std": 4.372896787968088, "train/rep_loss_mean": 13.93190054521493, "train/rep_loss_std": 8.955388796244952, "train/reward_avg": 0.02694273573604036, "train/reward_loss_mean": 0.05552705366772118, "train/reward_loss_std": 0.2542406617538303, "train/reward_max_data": 1.0120567404632028, "train/reward_max_pred": 1.0099875901607758, "train/reward_neg_acc": 0.9932619274085295, "train/reward_neg_loss": 0.02966540248020955, "train/reward_pos_acc": 0.9656351948460788, "train/reward_pos_loss": 0.8523761904831474, "train/reward_pred": 0.026336654049760485, "train/reward_rate": 0.0315270390070922, "eval_stats/sum_log_reward": 7.78750005364418, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.875, "eval_stats/max_log_achievement_collect_sapling": 1.75, "eval_stats/max_log_achievement_collect_stone": 6.9375, "eval_stats/max_log_achievement_collect_wood": 11.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.75, "eval_stats/max_log_achievement_place_stone": 5.1875, "eval_stats/max_log_achievement_place_table": 2.9375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 7.154308605095139e-06, "report/cont_loss_std": 0.00020589347695931792, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 9.915925329551101e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 6.702860900986707e-06, "report/cont_pred": 0.9951111078262329, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.37987232208252, "report/dyn_loss_std": 8.616212844848633, "report/image_loss_mean": 6.725592136383057, "report/image_loss_std": 10.355387687683105, "report/model_loss_mean": 15.411969184875488, "report/model_loss_std": 14.007035255432129, "report/post_ent_mag": 59.32272720336914, "report/post_ent_max": 59.32272720336914, "report/post_ent_mean": 40.63604736328125, "report/post_ent_min": 19.186357498168945, "report/post_ent_std": 7.413436412811279, "report/prior_ent_mag": 66.393310546875, "report/prior_ent_max": 66.393310546875, "report/prior_ent_mean": 54.965850830078125, "report/prior_ent_min": 40.703060150146484, "report/prior_ent_std": 4.52490234375, "report/rep_loss_mean": 14.37987232208252, "report/rep_loss_std": 8.616212844848633, "report/reward_avg": 0.03046874888241291, "report/reward_loss_mean": 0.05844641104340553, "report/reward_loss_std": 0.2464657723903656, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0020437240600586, "report/reward_neg_acc": 0.986842155456543, "report/reward_neg_loss": 0.026114989072084427, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 0.945764422416687, "report/reward_pred": 0.027097392827272415, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 5.494025390362367e-05, "eval/cont_loss_std": 0.001698734937235713, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.018688565120100975, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.8915913813088991e-07, "eval/cont_pred": 0.9971235394477844, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.957536697387695, "eval/dyn_loss_std": 10.550556182861328, "eval/image_loss_mean": 11.411785125732422, "eval/image_loss_std": 16.1234188079834, "eval/model_loss_mean": 22.258068084716797, "eval/model_loss_std": 20.235536575317383, "eval/post_ent_mag": 54.247684478759766, "eval/post_ent_max": 54.247684478759766, "eval/post_ent_mean": 38.58894729614258, "eval/post_ent_min": 19.86449432373047, "eval/post_ent_std": 6.524654865264893, "eval/prior_ent_mag": 66.393310546875, "eval/prior_ent_max": 66.393310546875, "eval/prior_ent_mean": 54.12879180908203, "eval/prior_ent_min": 41.89170837402344, "eval/prior_ent_std": 4.33932638168335, "eval/rep_loss_mean": 17.957536697387695, "eval/rep_loss_std": 10.550556182861328, "eval/reward_avg": 0.03183593600988388, "eval/reward_loss_mean": 0.07170648872852325, "eval/reward_loss_std": 0.41206225752830505, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0023388862609863, "eval/reward_neg_acc": 0.986842155456543, "eval/reward_neg_loss": 0.025754207745194435, "eval/reward_pos_acc": 0.8611111044883728, "eval/reward_pos_loss": 1.332841157913208, "eval/reward_pred": 0.029576536267995834, "eval/reward_rate": 0.03515625, "replay/size": 547809.0, "replay/inserts": 22560.0, "replay/samples": 22560.0, "replay/insert_wait_avg": 1.311027411873459e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.39879641972535e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5568.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0991747351898543e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1600646972656, "timer/env.step_count": 2820.0, "timer/env.step_total": 234.17519402503967, "timer/env.step_frac": 0.23413771684227486, "timer/env.step_avg": 0.08304084894504953, "timer/env.step_min": 0.02238750457763672, "timer/env.step_max": 3.2548654079437256, "timer/replay._sample_count": 22560.0, "timer/replay._sample_total": 11.321150541305542, "timer/replay._sample_frac": 0.011319338714780913, "timer/replay._sample_avg": 0.000501824048816735, "timer/replay._sample_min": 0.0004143714904785156, "timer/replay._sample_max": 0.010722637176513672, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3516.0, "timer/agent.policy_total": 56.41629076004028, "timer/agent.policy_frac": 0.05640726194873288, "timer/agent.policy_avg": 0.016045588953367544, "timer/agent.policy_min": 0.009387731552124023, "timer/agent.policy_max": 0.14044427871704102, "timer/dataset_train_count": 1410.0, "timer/dataset_train_total": 0.15062975883483887, "timer/dataset_train_frac": 0.00015060565218671511, "timer/dataset_train_avg": 0.00010682961619492118, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0008828639984130859, "timer/agent.train_count": 1410.0, "timer/agent.train_total": 633.9490554332733, "timer/agent.train_frac": 0.6338475988092573, "timer/agent.train_avg": 0.44960925917253425, "timer/agent.train_min": 0.43763279914855957, "timer/agent.train_max": 1.6389110088348389, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47541117668151855, "timer/agent.report_frac": 0.0004753350923138676, "timer/agent.report_avg": 0.23770558834075928, "timer/agent.report_min": 0.2329249382019043, "timer/agent.report_max": 0.24248623847961426, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.693698777768268e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 22.55609081909907}
{"step": 548368, "time": 25323.805902719498, "episode/length": 205.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 548704, "time": 25336.520516872406, "episode/length": 369.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9756756756756757, "episode/intrinsic_return": 0.0}
{"step": 549080, "time": 25351.98197031021, "episode/length": 293.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9965986394557823, "episode/intrinsic_return": 0.0}
{"step": 549256, "time": 25359.47333240509, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9873817034700315, "episode/intrinsic_return": 0.0}
{"step": 549320, "time": 25363.302576065063, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 549416, "time": 25368.035504341125, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 549624, "time": 25376.38742995262, "episode/length": 230.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 549632, "time": 25378.344369888306, "episode/length": 68.0, "episode/score": 3.100000001490116, "episode/reward_rate": 0.927536231884058, "episode/intrinsic_return": 0.0}
{"step": 549688, "time": 25381.690078496933, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 550040, "time": 25395.306792020798, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 550056, "time": 25412.886274576187, "eval_episode/length": 60.0, "eval_episode/score": 4.100000008940697, "eval_episode/reward_rate": 0.9836065573770492}
{"step": 550056, "time": 25417.759171009064, "eval_episode/length": 144.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 550056, "time": 25422.45022368431, "eval_episode/length": 214.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 550056, "time": 25424.094610214233, "eval_episode/length": 217.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 550056, "time": 25426.156563282013, "eval_episode/length": 228.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9781659388646288}
{"step": 550056, "time": 25428.76406478882, "eval_episode/length": 255.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.98046875}
{"step": 550056, "time": 25431.407816171646, "eval_episode/length": 282.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9858657243816255}
{"step": 550056, "time": 25433.938729524612, "eval_episode/length": 245.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9959349593495935}
{"step": 550312, "time": 25442.637516260147, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 550728, "time": 25458.643805503845, "episode/length": 163.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 550776, "time": 25461.79225707054, "episode/length": 189.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 550888, "time": 25467.077971696854, "episode/length": 156.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 551160, "time": 25477.557705163956, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 551552, "time": 25492.33715891838, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 551560, "time": 25493.952856063843, "episode/length": 233.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 552072, "time": 25512.57723426819, "episode/length": 253.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 552400, "time": 25525.19939160347, "episode/length": 208.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 552456, "time": 25528.49060368538, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 552696, "time": 25538.054243803024, "episode/length": 421.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9928909952606635, "episode/intrinsic_return": 0.0}
{"step": 552832, "time": 25544.385389328003, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 553112, "time": 25554.954508304596, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 553128, "time": 25557.039633989334, "episode/length": 245.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 553592, "time": 25573.841613054276, "episode/length": 59.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 553624, "time": 25576.47070789337, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 553816, "time": 25584.378532886505, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 554040, "time": 25593.340571403503, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 554392, "time": 25606.570715904236, "episode/length": 451.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9977876106194691, "episode/intrinsic_return": 0.0}
{"step": 554616, "time": 25615.451037168503, "episode/length": 222.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 554920, "time": 25627.16747403145, "episode/length": 355.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9915730337078652, "episode/intrinsic_return": 0.0}
{"step": 554960, "time": 25630.476734399796, "episode/length": 228.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 555120, "time": 25637.373890161514, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 555136, "time": 25639.445596694946, "episode/length": 188.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 555216, "time": 25643.833012342453, "episode/length": 102.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 555224, "time": 25645.370004415512, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 555552, "time": 25658.083007335663, "episode/length": 188.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 555776, "time": 25667.200185775757, "episode/length": 68.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 556096, "time": 25679.478990793228, "episode/length": 67.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 556392, "time": 25690.734661340714, "episode/length": 178.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 556480, "time": 25695.45198917389, "episode/length": 169.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 556680, "time": 25703.440955638885, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 557000, "time": 25715.587203741074, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 557288, "time": 25728.186564683914, "episode/length": 333.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9880239520958084, "episode/intrinsic_return": 0.0}
{"step": 557792, "time": 25746.82600736618, "episode/length": 321.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 558400, "time": 25768.701622009277, "episode/length": 214.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 558480, "time": 25772.975842237473, "episode/length": 337.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.985207100591716, "episode/intrinsic_return": 0.0}
{"step": 558784, "time": 25784.73512148857, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851190476190477, "episode/intrinsic_return": 0.0}
{"step": 558960, "time": 25792.062145233154, "episode/length": 320.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 559184, "time": 25801.165869951248, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 559896, "time": 25825.984390735626, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953161592505855, "episode/intrinsic_return": 0.0}
{"step": 560040, "time": 25848.08838868141, "eval_episode/length": 57.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 560040, "time": 25854.08379983902, "eval_episode/length": 165.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9939759036144579}
{"step": 560040, "time": 25856.34363436699, "eval_episode/length": 181.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 560040, "time": 25858.843863248825, "eval_episode/length": 205.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9660194174757282}
{"step": 560040, "time": 25860.454040527344, "eval_episode/length": 206.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 560040, "time": 25863.893956184387, "eval_episode/length": 228.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9956331877729258}
{"step": 560040, "time": 25866.433923244476, "eval_episode/length": 230.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 560040, "time": 25874.374758720398, "eval_episode/length": 131.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9545454545454546}
{"step": 560216, "time": 25880.598783254623, "episode/length": 226.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 560384, "time": 25888.228143453598, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 560728, "time": 25900.85799217224, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 560952, "time": 25909.76102423668, "episode/length": 308.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9870550161812298, "episode/intrinsic_return": 0.0}
{"step": 561232, "time": 25920.728900194168, "episode/length": 305.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9771241830065359, "episode/intrinsic_return": 0.0}
{"step": 561648, "time": 25935.95064520836, "episode/length": 307.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9805194805194806, "episode/intrinsic_return": 0.0}
{"step": 561752, "time": 25940.803933620453, "episode/length": 191.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 561928, "time": 25948.255419254303, "episode/length": 253.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724409448818898, "episode/intrinsic_return": 0.0}
{"step": 561952, "time": 25950.967183351517, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 561984, "time": 25953.55275297165, "episode/length": 622.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9983948635634029, "episode/intrinsic_return": 0.0}
{"step": 562168, "time": 25960.99246239662, "episode/length": 151.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 562200, "time": 25963.63272833824, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 562600, "time": 25979.118901729584, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 562928, "time": 25991.95801258087, "episode/length": 94.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9368421052631579, "episode/intrinsic_return": 0.0}
{"step": 563112, "time": 25999.53886771202, "episode/length": 169.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 563376, "time": 26009.99064064026, "episode/length": 55.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 563400, "time": 26012.021488428116, "episode/length": 176.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9661016949152542, "episode/intrinsic_return": 0.0}
{"step": 563712, "time": 26024.22008061409, "episode/length": 257.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9961240310077519, "episode/intrinsic_return": 0.0}
{"step": 563960, "time": 26033.744688987732, "episode/length": 250.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 564424, "time": 26050.67615866661, "episode/length": 311.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9839743589743589, "episode/intrinsic_return": 0.0}
{"step": 564776, "time": 26063.92237520218, "episode/length": 271.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 565600, "time": 26094.86186003685, "episode/length": 204.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 565712, "time": 26100.103320598602, "episode/length": 438.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 565744, "time": 26102.636656999588, "episode/length": 295.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9898648648648649, "episode/intrinsic_return": 0.0}
{"step": 565744, "time": 26102.64524435997, "episode/length": 164.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 565792, "time": 26107.521394252777, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 566176, "time": 26121.804979801178, "episode/length": 346.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9827089337175793, "episode/intrinsic_return": 0.0}
{"step": 566416, "time": 26131.29665875435, "episode/length": 412.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782082324455206, "episode/intrinsic_return": 0.0}
{"step": 566504, "time": 26135.601407527924, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 566944, "time": 26151.991485595703, "episode/length": 143.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 567384, "time": 26168.02987265587, "episode/length": 204.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 567424, "time": 26171.295428991318, "episode/length": 213.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 567536, "time": 26176.710474967957, "episode/length": 223.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 567624, "time": 26181.168883562088, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 567928, "time": 26193.618144750595, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 567928, "time": 26193.624673843384, "episode/length": 37.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 568432, "time": 26214.06541442871, "episode/length": 185.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 568616, "time": 26221.47632265091, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 568728, "time": 26226.716176509857, "episode/length": 167.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 568888, "time": 26233.64911174774, "episode/length": 56.0, "episode/score": 2.0999999940395355, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 568888, "time": 26233.659731388092, "episode/length": 308.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 569112, "time": 26244.44402050972, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 569168, "time": 26248.170197963715, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 570024, "time": 26296.92453932762, "eval_episode/length": 140.0, "eval_episode/score": 8.099999994039536, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 570024, "time": 26299.442631959915, "eval_episode/length": 151.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.993421052631579}
{"step": 570024, "time": 26301.657896995544, "eval_episode/length": 156.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 570024, "time": 26303.972529649734, "eval_episode/length": 164.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9636363636363636}
{"step": 570024, "time": 26306.274010419846, "eval_episode/length": 169.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 570024, "time": 26306.282680273056, "eval_episode/length": 169.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 570024, "time": 26311.332902431488, "eval_episode/length": 185.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 570024, "time": 26313.691089630127, "eval_episode/length": 41.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.8809523809523809}
{"step": 570160, "time": 26318.480162858963, "episode/length": 278.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 570176, "time": 26320.679980516434, "episode/length": 180.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 570177, "time": 26322.881752490997, "train_stats/sum_log_reward": 8.308333503703276, "train_stats/max_log_achievement_collect_coal": 0.3958333333333333, "train_stats/max_log_achievement_collect_drink": 4.354166666666667, "train_stats/max_log_achievement_collect_sapling": 1.4895833333333333, "train_stats/max_log_achievement_collect_stone": 10.770833333333334, "train_stats/max_log_achievement_collect_wood": 12.15625, "train_stats/max_log_achievement_defeat_skeleton": 0.0625, "train_stats/max_log_achievement_defeat_zombie": 0.5208333333333334, "train_stats/max_log_achievement_eat_cow": 0.07291666666666667, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4791666666666667, "train_stats/max_log_achievement_make_wood_sword": 0.6354166666666666, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.375, "train_stats/max_log_achievement_place_stone": 8.947916666666666, "train_stats/max_log_achievement_place_table": 2.5, "train_stats/max_log_achievement_wake_up": 1.3854166666666667, "train_stats/mean_log_entropy": 0.5199731248430908, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.379493264590993, "train/action_min": 0.0, "train/action_std": 3.215600080349866, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03684643827214399, "train/actor_opt_grad_steps": 34855.0, "train/actor_opt_loss": -1.6117135751992464, "train/adv_mag": 0.4747745302670142, "train/adv_max": 0.42818594439064755, "train/adv_mean": 0.004139139595388449, "train/adv_min": -0.3901620490805191, "train/adv_std": 0.05602115488556378, "train/cont_avg": 0.9950741038602942, "train/cont_loss_mean": 0.0002491154762810431, "train/cont_loss_std": 0.0074240363106952145, "train/cont_neg_acc": 0.9922414812095025, "train/cont_neg_loss": 0.0233420982319384, "train/cont_pos_acc": 0.9999783223166185, "train/cont_pos_loss": 0.0001050997595825511, "train/cont_pred": 0.9950862255166558, "train/cont_rate": 0.9950741038602942, "train/dyn_loss_mean": 13.846347423160777, "train/dyn_loss_std": 9.026651165064644, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8956033867948195, "train/extr_critic_critic_opt_grad_steps": 34855.0, "train/extr_critic_critic_opt_loss": 15641.435008329503, "train/extr_critic_mag": 8.17869379941155, "train/extr_critic_max": 8.17869379941155, "train/extr_critic_mean": 2.724254236501806, "train/extr_critic_min": -0.15477068459286408, "train/extr_critic_std": 1.8787688481457092, "train/extr_return_normed_mag": 1.5513131399365032, "train/extr_return_normed_max": 1.5513131399365032, "train/extr_return_normed_mean": 0.4113863228875048, "train/extr_return_normed_min": -0.13993016991983442, "train/extr_return_normed_std": 0.3228834869668764, "train/extr_return_rate": 0.9111979665125117, "train/extr_return_raw_mag": 9.503358707708472, "train/extr_return_raw_max": 9.503358707708472, "train/extr_return_raw_mean": 2.7487263100988724, "train/extr_return_raw_min": -0.5194345230565351, "train/extr_return_raw_std": 1.9133929873214048, "train/extr_reward_mag": 1.0226683388738071, "train/extr_reward_max": 1.0226683388738071, "train/extr_reward_mean": 0.03855576725019252, "train/extr_reward_min": -0.42113027327200947, "train/extr_reward_std": 0.18245144834851518, "train/image_loss_mean": 7.163459599018097, "train/image_loss_std": 12.22899896958295, "train/model_loss_mean": 15.52892175842734, "train/model_loss_std": 15.894606744541841, "train/model_opt_grad_norm": 59.785506080178656, "train/model_opt_grad_steps": 34823.11029411765, "train/model_opt_loss": 17135.755313648897, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1098.3455882352941, "train/policy_entropy_mag": 2.4535957872867584, "train/policy_entropy_max": 2.4535957872867584, "train/policy_entropy_mean": 0.493664234657498, "train/policy_entropy_min": 0.07937510623870526, "train/policy_entropy_std": 0.5589233496609856, "train/policy_logprob_mag": 7.438383523155661, "train/policy_logprob_max": -0.009455688003286281, "train/policy_logprob_mean": -0.494030032745179, "train/policy_logprob_min": -7.438383523155661, "train/policy_logprob_std": 1.059803120791912, "train/policy_randomness_mag": 0.8660116397282657, "train/policy_randomness_max": 0.8660116397282657, "train/policy_randomness_mean": 0.17424181005095735, "train/policy_randomness_min": 0.028015929287956917, "train/policy_randomness_std": 0.19727541626814535, "train/post_ent_mag": 57.2053482392255, "train/post_ent_max": 57.2053482392255, "train/post_ent_mean": 40.93047198127298, "train/post_ent_min": 20.000820762970868, "train/post_ent_std": 7.155136171509238, "train/prior_ent_mag": 66.23482165617101, "train/prior_ent_max": 66.23482165617101, "train/prior_ent_mean": 54.827833876890296, "train/prior_ent_min": 39.201286764705884, "train/prior_ent_std": 4.356126588933608, "train/rep_loss_mean": 13.846347423160777, "train/rep_loss_std": 9.026651165064644, "train/reward_avg": 0.029826803660184583, "train/reward_loss_mean": 0.057404554449021816, "train/reward_loss_std": 0.2594748854856281, "train/reward_max_data": 1.0169117687379612, "train/reward_max_pred": 1.0121402170728235, "train/reward_neg_acc": 0.993007047649692, "train/reward_neg_loss": 0.0290659311474027, "train/reward_pos_acc": 0.9679370040402693, "train/reward_pos_loss": 0.8581832493929302, "train/reward_pred": 0.02882006042636931, "train/reward_rate": 0.03435202205882353, "eval_stats/sum_log_reward": 8.058333615461985, "eval_stats/max_log_achievement_collect_coal": 0.20833333333333334, "eval_stats/max_log_achievement_collect_drink": 2.7083333333333335, "eval_stats/max_log_achievement_collect_sapling": 1.6666666666666667, "eval_stats/max_log_achievement_collect_stone": 9.416666666666666, "eval_stats/max_log_achievement_collect_wood": 10.5, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.2916666666666667, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.5833333333333334, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 7.166666666666667, "eval_stats/max_log_achievement_place_table": 2.0, "eval_stats/max_log_achievement_wake_up": 0.875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 2.3323489585891366e-05, "report/cont_loss_std": 0.0003931736573576927, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002096797339618206, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 9.051794222614262e-06, "report/cont_pred": 0.9931694865226746, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 14.09323787689209, "report/dyn_loss_std": 9.431671142578125, "report/image_loss_mean": 7.245601654052734, "report/image_loss_std": 13.526724815368652, "report/model_loss_mean": 15.754804611206055, "report/model_loss_std": 17.63275718688965, "report/post_ent_mag": 58.95611572265625, "report/post_ent_max": 58.95611572265625, "report/post_ent_mean": 40.462223052978516, "report/post_ent_min": 19.37580680847168, "report/post_ent_std": 6.938350677490234, "report/prior_ent_mag": 66.63178253173828, "report/prior_ent_max": 66.63178253173828, "report/prior_ent_mean": 54.393775939941406, "report/prior_ent_min": 38.26245880126953, "report/prior_ent_std": 4.874240875244141, "report/rep_loss_mean": 14.09323787689209, "report/rep_loss_std": 9.431671142578125, "report/reward_avg": 0.02568359300494194, "report/reward_loss_mean": 0.053237833082675934, "report/reward_loss_std": 0.2253982573747635, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011990070343018, "report/reward_neg_acc": 0.9979838132858276, "report/reward_neg_loss": 0.02865522913634777, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.8152986168861389, "report/reward_pred": 0.02370183914899826, "report/reward_rate": 0.03125, "eval/cont_avg": 1.0, "eval/cont_loss_mean": 2.2734812432645413e-07, "eval/cont_loss_std": 3.7596382185256516e-07, "eval/cont_neg_acc": NaN, "eval/cont_neg_loss": NaN, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.2734812432645413e-07, "eval/cont_pred": 0.9999998807907104, "eval/cont_rate": 1.0, "eval/dyn_loss_mean": 16.725297927856445, "eval/dyn_loss_std": 10.342693328857422, "eval/image_loss_mean": 11.705039024353027, "eval/image_loss_std": 17.610193252563477, "eval/model_loss_mean": 21.832332611083984, "eval/model_loss_std": 21.865997314453125, "eval/post_ent_mag": 57.36243438720703, "eval/post_ent_max": 57.36243438720703, "eval/post_ent_mean": 40.37794494628906, "eval/post_ent_min": 21.74267578125, "eval/post_ent_std": 7.249024868011475, "eval/prior_ent_mag": 66.63178253173828, "eval/prior_ent_max": 66.63178253173828, "eval/prior_ent_mean": 54.66323471069336, "eval/prior_ent_min": 40.104400634765625, "eval/prior_ent_std": 3.6935341358184814, "eval/rep_loss_mean": 16.725297927856445, "eval/rep_loss_std": 10.342693328857422, "eval/reward_avg": 0.04052734375, "eval/reward_loss_mean": 0.09211568534374237, "eval/reward_loss_std": 0.49636146426200867, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030083656311035, "eval/reward_neg_acc": 0.981670081615448, "eval/reward_neg_loss": 0.03577256575226784, "eval/reward_pos_acc": 0.8095238208770752, "eval/reward_pos_loss": 1.4094713926315308, "eval/reward_pred": 0.03868718817830086, "eval/reward_rate": 0.041015625, "replay/size": 569673.0, "replay/inserts": 21864.0, "replay/samples": 21856.0, "replay/insert_wait_avg": 1.3133958718125042e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.386110712110037e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6896.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1445543882188553e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.93332695961, "timer/env.step_count": 2733.0, "timer/env.step_total": 224.1803424358368, "timer/env.step_frac": 0.2239713039796536, "timer/env.step_avg": 0.08202720176942437, "timer/env.step_min": 0.02231597900390625, "timer/env.step_max": 3.438730478286743, "timer/replay._sample_count": 21856.0, "timer/replay._sample_total": 11.119909286499023, "timer/replay._sample_frac": 0.011109540452885468, "timer/replay._sample_avg": 0.0005087806225521149, "timer/replay._sample_min": 0.0003819465637207031, "timer/replay._sample_max": 0.011827230453491211, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3595.0, "timer/agent.policy_total": 58.5900239944458, "timer/agent.policy_frac": 0.05853539133562095, "timer/agent.policy_avg": 0.016297642279400778, "timer/agent.policy_min": 0.009152650833129883, "timer/agent.policy_max": 0.18233728408813477, "timer/dataset_train_count": 1366.0, "timer/dataset_train_total": 0.15428447723388672, "timer/dataset_train_frac": 0.0001541406136436023, "timer/dataset_train_avg": 0.00011294617659874577, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.007966756820678711, "timer/agent.train_count": 1366.0, "timer/agent.train_total": 613.880401134491, "timer/agent.train_frac": 0.6133079842582387, "timer/agent.train_avg": 0.44940000083052045, "timer/agent.train_min": 0.43455004692077637, "timer/agent.train_max": 1.6113159656524658, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4792008399963379, "timer/agent.report_frac": 0.00047875400597553963, "timer/agent.report_avg": 0.23960041999816895, "timer/agent.report_min": 0.23325538635253906, "timer/agent.report_max": 0.24594545364379883, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.0994415283203125e-05, "timer/dataset_eval_frac": 3.096551433385715e-08, "timer/dataset_eval_avg": 3.0994415283203125e-05, "timer/dataset_eval_min": 3.0994415283203125e-05, "timer/dataset_eval_max": 3.0994415283203125e-05, "fps": 21.843316128881074}
{"step": 570328, "time": 26327.99767756462, "episode/length": 299.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 570648, "time": 26340.371885061264, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 570928, "time": 26352.257696390152, "episode/length": 254.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 571160, "time": 26361.35868215561, "episode/length": 255.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 571560, "time": 26376.190393209457, "episode/length": 174.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 571688, "time": 26382.051970243454, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 571752, "time": 26385.701070785522, "episode/length": 357.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9972067039106145, "episode/intrinsic_return": 0.0}
{"step": 571784, "time": 26388.38017630577, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 571792, "time": 26390.402136087418, "episode/length": 327.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9908536585365854, "episode/intrinsic_return": 0.0}
{"step": 572432, "time": 26413.163248062134, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 572528, "time": 26417.86548924446, "episode/length": 234.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9829787234042553, "episode/intrinsic_return": 0.0}
{"step": 572936, "time": 26432.673621416092, "episode/length": 142.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 573152, "time": 26441.790501832962, "episode/length": 170.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 573696, "time": 26463.18286371231, "episode/length": 250.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9840637450199203, "episode/intrinsic_return": 0.0}
{"step": 573736, "time": 26465.843849658966, "episode/length": 247.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 573856, "time": 26471.661960840225, "episode/length": 177.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 574024, "time": 26478.710543632507, "episode/length": 307.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 574184, "time": 26485.655299425125, "episode/length": 55.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 574408, "time": 26494.57474422455, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 574648, "time": 26504.53538441658, "episode/length": 435.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 574736, "time": 26509.19968676567, "episode/length": 197.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 574872, "time": 26515.163690805435, "episode/length": 292.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 575424, "time": 26536.53044104576, "episode/length": 195.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 575560, "time": 26542.978728294373, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 575624, "time": 26547.240288972855, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 575984, "time": 26561.878274440765, "episode/length": 224.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 576472, "time": 26580.10860991478, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 576544, "time": 26584.808358192444, "episode/length": 208.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 577144, "time": 26606.42760014534, "episode/length": 214.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 577272, "time": 26612.194273233414, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 577608, "time": 26625.19895219803, "episode/length": 488.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959100204498977, "episode/intrinsic_return": 0.0}
{"step": 578168, "time": 26646.126453876495, "episode/length": 439.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 578320, "time": 26653.128591299057, "episode/length": 221.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 578408, "time": 26657.487370729446, "episode/length": 458.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9978213507625272, "episode/intrinsic_return": 0.0}
{"step": 578416, "time": 26659.47391819954, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 578464, "time": 26662.62466263771, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 578576, "time": 26667.782281398773, "episode/length": 376.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9893899204244032, "episode/intrinsic_return": 0.0}
{"step": 579256, "time": 26691.767673015594, "episode/length": 247.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 579648, "time": 26706.604688167572, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 579720, "time": 26710.49613928795, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 579784, "time": 26714.179992437363, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 579896, "time": 26719.41986656189, "episode/length": 215.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 579976, "time": 26723.712208747864, "episode/length": 174.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 580008, "time": 26741.449899435043, "eval_episode/length": 57.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 580008, "time": 26747.08028459549, "eval_episode/length": 159.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 580008, "time": 26748.864023923874, "eval_episode/length": 162.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9631901840490797}
{"step": 580008, "time": 26750.988035678864, "eval_episode/length": 174.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9542857142857143}
{"step": 580008, "time": 26752.760182619095, "eval_episode/length": 180.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9668508287292817}
{"step": 580008, "time": 26754.75219154358, "eval_episode/length": 189.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 580008, "time": 26757.56416463852, "eval_episode/length": 157.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 580008, "time": 26759.65610384941, "eval_episode/length": 226.0, "eval_episode/score": 10.100000031292439, "eval_episode/reward_rate": 0.9955947136563876}
{"step": 580080, "time": 26762.261619329453, "episode/length": 201.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 580640, "time": 26782.45850276947, "episode/length": 277.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9784172661870504, "episode/intrinsic_return": 0.0}
{"step": 581248, "time": 26804.3416223526, "episode/length": 190.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 581672, "time": 26821.415026426315, "episode/length": 252.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 581712, "time": 26824.516269922256, "episode/length": 226.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 581776, "time": 26828.286733865738, "episode/length": 314.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9873015873015873, "episode/intrinsic_return": 0.0}
{"step": 581936, "time": 26835.174010276794, "episode/length": 244.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 582144, "time": 26843.56007528305, "episode/length": 58.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 582248, "time": 26848.366257190704, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 582888, "time": 26871.245525836945, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 582976, "time": 26876.06835913658, "episode/length": 398.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9974937343358395, "episode/intrinsic_return": 0.0}
{"step": 583376, "time": 26891.008845806122, "episode/length": 207.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 583480, "time": 26895.831174850464, "episode/length": 212.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 583592, "time": 26901.802317380905, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 583664, "time": 26906.44472384453, "episode/length": 447.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9977678571428571, "episode/intrinsic_return": 0.0}
{"step": 584096, "time": 26923.537541151047, "episode/length": 269.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 584552, "time": 26941.027757406235, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 584760, "time": 26950.269548892975, "episode/length": 145.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9657534246575342, "episode/intrinsic_return": 0.0}
{"step": 584920, "time": 26957.933550596237, "episode/length": 179.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 584952, "time": 26961.004450321198, "episode/length": 196.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 585200, "time": 26971.72891139984, "episode/length": 381.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 585552, "time": 26985.951692342758, "episode/length": 181.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.978021978021978, "episode/intrinsic_return": 0.0}
{"step": 585568, "time": 26988.36588549614, "episode/length": 323.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9845679012345679, "episode/intrinsic_return": 0.0}
{"step": 585664, "time": 26993.658938884735, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 585976, "time": 27006.051333904266, "episode/length": 288.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9826989619377162, "episode/intrinsic_return": 0.0}
{"step": 586232, "time": 27016.228949785233, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 586272, "time": 27019.2835149765, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 586360, "time": 27023.523580551147, "episode/length": 179.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 586440, "time": 27027.661608219147, "episode/length": 57.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 586608, "time": 27035.030216693878, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 587032, "time": 27051.01742196083, "episode/length": 182.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 587256, "time": 27060.572830677032, "episode/length": 212.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 587624, "time": 27074.36928486824, "episode/length": 244.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 587872, "time": 27084.403430700302, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 588072, "time": 27092.437826633453, "episode/length": 203.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 588512, "time": 27108.959466457367, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 588712, "time": 27116.848042488098, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 588752, "time": 27120.104876995087, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 588840, "time": 27124.37065243721, "episode/length": 309.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 589000, "time": 27131.25447177887, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9593023255813954, "episode/intrinsic_return": 0.0}
{"step": 589072, "time": 27135.46119570732, "episode/length": 226.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 589536, "time": 27152.283488035202, "episode/length": 182.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 589720, "time": 27159.905618429184, "episode/length": 230.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 590048, "time": 27174.133520126343, "episode/length": 150.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 590096, "time": 27192.753577947617, "eval_episode/length": 54.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 590096, "time": 27194.52637028694, "eval_episode/length": 61.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9838709677419355}
{"step": 590096, "time": 27199.97732591629, "eval_episode/length": 160.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9937888198757764}
{"step": 590096, "time": 27201.96527647972, "eval_episode/length": 170.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 590096, "time": 27203.776283979416, "eval_episode/length": 177.0, "eval_episode/score": 8.100000031292439, "eval_episode/reward_rate": 0.9662921348314607}
{"step": 590096, "time": 27205.904428958893, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9739583333333334}
{"step": 590096, "time": 27208.215270996094, "eval_episode/length": 211.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 590096, "time": 27211.63260126114, "eval_episode/length": 201.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.995049504950495}
{"step": 590264, "time": 27217.01071691513, "episode/length": 188.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 590272, "time": 27219.055767536163, "episode/length": 158.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 590408, "time": 27224.98408651352, "episode/length": 211.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 590704, "time": 27236.575377464294, "episode/length": 273.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 590776, "time": 27240.289806842804, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 590856, "time": 27244.396067857742, "episode/length": 164.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 591160, "time": 27256.240252256393, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 591552, "time": 27270.894397497177, "episode/length": 48.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 591976, "time": 27286.448813676834, "episode/length": 52.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9245283018867925, "episode/intrinsic_return": 0.0}
{"step": 592008, "time": 27289.187965869904, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 592192, "time": 27297.131816864014, "episode/length": 240.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 592312, "time": 27302.495842933655, "episode/length": 282.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9929328621908127, "episode/intrinsic_return": 0.0}
{"step": 592360, "time": 27305.75799179077, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 592416, "time": 27309.521718978882, "episode/length": 213.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9672897196261683, "episode/intrinsic_return": 0.0}
{"step": 592464, "time": 27312.7266933918, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 592713, "time": 27323.26006627083, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.225464732934397, "train/action_min": 0.0, "train/action_std": 3.1277396154741868, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03591714070198384, "train/actor_opt_grad_steps": 36240.0, "train/actor_opt_loss": -7.72052183979792, "train/adv_mag": 0.49433270709734434, "train/adv_max": 0.43806049502487726, "train/adv_mean": 0.0030068973994004525, "train/adv_min": -0.40068958181861447, "train/adv_std": 0.054000570683191855, "train/cont_avg": 0.9948747783687943, "train/cont_loss_mean": 0.00019356613630682834, "train/cont_loss_std": 0.005500885404331609, "train/cont_neg_acc": 0.9944444450926273, "train/cont_neg_loss": 0.016968920042592078, "train/cont_pos_acc": 0.9999512484733094, "train/cont_pos_loss": 9.041758510160925e-05, "train/cont_pred": 0.9948630176537426, "train/cont_rate": 0.9948747783687943, "train/dyn_loss_mean": 13.705580082345517, "train/dyn_loss_std": 9.07044106341423, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.916734424465937, "train/extr_critic_critic_opt_grad_steps": 36240.0, "train/extr_critic_critic_opt_loss": 15476.443061558068, "train/extr_critic_mag": 8.48366167190227, "train/extr_critic_max": 8.48366167190227, "train/extr_critic_mean": 2.760801954472319, "train/extr_critic_min": -0.13527516101269013, "train/extr_critic_std": 1.9580681002731863, "train/extr_return_normed_mag": 1.5335096298380102, "train/extr_return_normed_max": 1.5335096298380102, "train/extr_return_normed_mean": 0.3936259186436944, "train/extr_return_normed_min": -0.1413075568299767, "train/extr_return_normed_std": 0.32328276389034083, "train/extr_return_rate": 0.9167927676904286, "train/extr_return_raw_mag": 9.806307400372011, "train/extr_return_raw_max": 9.806307400372011, "train/extr_return_raw_mean": 2.7793306907018027, "train/extr_return_raw_min": -0.51861568609028, "train/extr_return_raw_std": 1.9932695999213144, "train/extr_reward_mag": 1.0271506106599848, "train/extr_reward_max": 1.0271506106599848, "train/extr_reward_mean": 0.03794957162376414, "train/extr_reward_min": -0.4713270478214778, "train/extr_reward_std": 0.18089435814965701, "train/image_loss_mean": 7.389648197390509, "train/image_loss_std": 12.58439285535339, "train/model_loss_mean": 15.672155840177062, "train/model_loss_std": 16.278890717959573, "train/model_opt_grad_norm": 66.25369219407968, "train/model_opt_grad_steps": 36206.90780141844, "train/model_opt_loss": 14321.405235344637, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 913.1205673758865, "train/policy_entropy_mag": 2.5176410928685615, "train/policy_entropy_max": 2.5176410928685615, "train/policy_entropy_mean": 0.5135318522757673, "train/policy_entropy_min": 0.07937508171543162, "train/policy_entropy_std": 0.597263737139127, "train/policy_logprob_mag": 7.438383575872327, "train/policy_logprob_max": -0.00945566763031356, "train/policy_logprob_mean": -0.5135508631983547, "train/policy_logprob_min": -7.438383575872327, "train/policy_logprob_std": 1.0759700215454642, "train/policy_randomness_mag": 0.8886168222900823, "train/policy_randomness_max": 0.8886168222900823, "train/policy_randomness_mean": 0.18125420808792114, "train/policy_randomness_min": 0.028015920588522092, "train/policy_randomness_std": 0.2108078903340279, "train/post_ent_mag": 57.33749541154145, "train/post_ent_max": 57.33749541154145, "train/post_ent_mean": 41.222031992377964, "train/post_ent_min": 19.933589624174942, "train/post_ent_std": 7.194861949758327, "train/prior_ent_mag": 66.2807851480254, "train/prior_ent_max": 66.2807851480254, "train/prior_ent_mean": 54.94299770923371, "train/prior_ent_min": 39.18115637488399, "train/prior_ent_std": 4.392336688143142, "train/rep_loss_mean": 13.705580082345517, "train/rep_loss_std": 9.07044106341423, "train/reward_avg": 0.02905654316067907, "train/reward_loss_mean": 0.05896609062527088, "train/reward_loss_std": 0.26645752607930634, "train/reward_max_data": 1.0212766008174166, "train/reward_max_pred": 1.0124514973755423, "train/reward_neg_acc": 0.9926948175362661, "train/reward_neg_loss": 0.030429485947527785, "train/reward_pos_acc": 0.9635982145654395, "train/reward_pos_loss": 0.8736390687049703, "train/reward_pred": 0.027920401423958175, "train/reward_rate": 0.03380568484042553, "train_stats/sum_log_reward": 8.854902155259076, "train_stats/max_log_achievement_collect_coal": 0.24509803921568626, "train_stats/max_log_achievement_collect_drink": 4.833333333333333, "train_stats/max_log_achievement_collect_sapling": 1.5, "train_stats/max_log_achievement_collect_stone": 9.176470588235293, "train_stats/max_log_achievement_collect_wood": 12.735294117647058, "train_stats/max_log_achievement_defeat_skeleton": 0.0392156862745098, "train_stats/max_log_achievement_defeat_zombie": 0.5490196078431373, "train_stats/max_log_achievement_eat_cow": 0.21568627450980393, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5, "train_stats/max_log_achievement_make_wood_sword": 1.2549019607843137, "train_stats/max_log_achievement_place_furnace": 0.029411764705882353, "train_stats/max_log_achievement_place_plant": 1.4509803921568627, "train_stats/max_log_achievement_place_stone": 7.176470588235294, "train_stats/max_log_achievement_place_table": 2.9901960784313726, "train_stats/max_log_achievement_wake_up": 1.3235294117647058, "train_stats/mean_log_entropy": 0.5358453612117207, "eval_stats/sum_log_reward": 7.537500187754631, "eval_stats/max_log_achievement_collect_coal": 0.125, "eval_stats/max_log_achievement_collect_drink": 3.625, "eval_stats/max_log_achievement_collect_sapling": 1.625, "eval_stats/max_log_achievement_collect_stone": 4.625, "eval_stats/max_log_achievement_collect_wood": 8.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 2.875, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 0.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00013607973232865334, "report/cont_loss_std": 0.0034026450011879206, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.004486592020839453, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00011043821723433211, "report/cont_pred": 0.9940624237060547, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.39742660522461, "report/dyn_loss_std": 9.105504035949707, "report/image_loss_mean": 5.411905288696289, "report/image_loss_std": 8.440343856811523, "report/model_loss_mean": 13.502132415771484, "report/model_loss_std": 12.21670150756836, "report/post_ent_mag": 56.122467041015625, "report/post_ent_max": 56.122467041015625, "report/post_ent_mean": 41.55430603027344, "report/post_ent_min": 19.699203491210938, "report/post_ent_std": 7.012928009033203, "report/prior_ent_mag": 66.51410675048828, "report/prior_ent_max": 66.51410675048828, "report/prior_ent_mean": 55.197998046875, "report/prior_ent_min": 39.47517395019531, "report/prior_ent_std": 4.385833263397217, "report/rep_loss_mean": 13.39742660522461, "report/rep_loss_std": 9.105504035949707, "report/reward_avg": 0.03818359225988388, "report/reward_loss_mean": 0.05163431912660599, "report/reward_loss_std": 0.19100332260131836, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.101848840713501, "report/reward_neg_acc": 0.9949030876159668, "report/reward_neg_loss": 0.023172946646809578, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7009506821632385, "report/reward_pred": 0.037810102105140686, "report/reward_rate": 0.0419921875, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.00012465479085221887, "eval/cont_loss_std": 0.0022264979779720306, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.01266996469348669, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.309781747404486e-05, "eval/cont_pred": 0.9951168894767761, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.074581146240234, "eval/dyn_loss_std": 9.794058799743652, "eval/image_loss_mean": 13.39210319519043, "eval/image_loss_std": 18.64046287536621, "eval/model_loss_mean": 23.730514526367188, "eval/model_loss_std": 22.168947219848633, "eval/post_ent_mag": 59.90254211425781, "eval/post_ent_max": 59.90254211425781, "eval/post_ent_mean": 40.779720306396484, "eval/post_ent_min": 21.810232162475586, "eval/post_ent_std": 7.109161853790283, "eval/prior_ent_mag": 66.42070007324219, "eval/prior_ent_max": 66.42070007324219, "eval/prior_ent_mean": 55.78669357299805, "eval/prior_ent_min": 40.0089111328125, "eval/prior_ent_std": 4.138299465179443, "eval/rep_loss_mean": 17.074581146240234, "eval/rep_loss_std": 9.794058799743652, "eval/reward_avg": 0.02724609337747097, "eval/reward_loss_mean": 0.09353939443826675, "eval/reward_loss_std": 0.6498830318450928, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0024709701538086, "eval/reward_neg_acc": 0.9949545860290527, "eval/reward_neg_loss": 0.045494195073843, "eval/reward_pos_acc": 0.9090908765792847, "eval/reward_pos_loss": 1.5363514423370361, "eval/reward_pred": 0.02630203403532505, "eval/reward_rate": 0.0322265625, "replay/size": 592209.0, "replay/inserts": 22536.0, "replay/samples": 22544.0, "replay/insert_wait_avg": 1.3162110517919592e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.371897389484349e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3872.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.08790791724339e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.4007091522216797e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3627126216888, "timer/env.step_count": 2817.0, "timer/env.step_total": 247.36226725578308, "timer/env.step_frac": 0.2472725783706105, "timer/env.step_avg": 0.08781053150720024, "timer/env.step_min": 0.022875547409057617, "timer/env.step_max": 2.247006893157959, "timer/replay._sample_count": 22544.0, "timer/replay._sample_total": 11.410300970077515, "timer/replay._sample_frac": 0.011406163810498396, "timer/replay._sample_avg": 0.0005061347130091161, "timer/replay._sample_min": 0.00039958953857421875, "timer/replay._sample_max": 0.03306698799133301, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3301.0, "timer/agent.policy_total": 53.17727732658386, "timer/agent.policy_frac": 0.05315799625040015, "timer/agent.policy_avg": 0.01610944481265794, "timer/agent.policy_min": 0.009220123291015625, "timer/agent.policy_max": 0.10286951065063477, "timer/dataset_train_count": 1409.0, "timer/dataset_train_total": 0.14990806579589844, "timer/dataset_train_frac": 0.00014985371196316247, "timer/dataset_train_avg": 0.0001063932333540798, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0005249977111816406, "timer/agent.train_count": 1409.0, "timer/agent.train_total": 634.6355874538422, "timer/agent.train_frac": 0.6344054805787677, "timer/agent.train_avg": 0.4504156050062755, "timer/agent.train_min": 0.4348776340484619, "timer/agent.train_max": 1.6491501331329346, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4775424003601074, "timer/agent.report_frac": 0.000477369252507017, "timer/agent.report_avg": 0.2387712001800537, "timer/agent.report_min": 0.23253750801086426, "timer/agent.report_max": 0.24500489234924316, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6941299438476562e-05, "timer/dataset_eval_frac": 2.6931531032249762e-08, "timer/dataset_eval_avg": 2.6941299438476562e-05, "timer/dataset_eval_min": 2.6941299438476562e-05, "timer/dataset_eval_max": 2.6941299438476562e-05, "fps": 22.52752750826821}
{"step": 592808, "time": 27326.267922878265, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 592848, "time": 27329.44605088234, "episode/length": 60.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 593240, "time": 27343.820536851883, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 593712, "time": 27361.459471464157, "episode/length": 189.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 593720, "time": 27363.463997364044, "episode/length": 213.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 593744, "time": 27366.467390298843, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 594056, "time": 27378.900789499283, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 594160, "time": 27384.160254240036, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 594576, "time": 27399.452733039856, "episode/length": 282.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 594768, "time": 27407.483171463013, "episode/length": 190.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9633507853403142, "episode/intrinsic_return": 0.0}
{"step": 595008, "time": 27417.084231853485, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 595184, "time": 27424.49783349037, "episode/length": 183.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 595496, "time": 27436.36896634102, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 595504, "time": 27438.37303519249, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 595912, "time": 27453.31587791443, "episode/length": 51.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 595920, "time": 27455.678719758987, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 596048, "time": 27462.174519062042, "episode/length": 183.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 596216, "time": 27469.57193517685, "episode/length": 420.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.995249406175772, "episode/intrinsic_return": 0.0}
{"step": 596440, "time": 27478.55193400383, "episode/length": 208.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 596832, "time": 27494.938710212708, "episode/length": 205.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 596856, "time": 27497.069657564163, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 597336, "time": 27514.49791789055, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 597360, "time": 27517.0565598011, "episode/length": 293.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9863945578231292, "episode/intrinsic_return": 0.0}
{"step": 598368, "time": 27553.908579826355, "episode/length": 289.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 598408, "time": 27556.618026971817, "episode/length": 193.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9690721649484536, "episode/intrinsic_return": 0.0}
{"step": 598496, "time": 27561.417278051376, "episode/length": 256.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.980544747081712, "episode/intrinsic_return": 0.0}
{"step": 598632, "time": 27567.328498363495, "episode/length": 224.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 598664, "time": 27569.960272073746, "episode/length": 342.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9912536443148688, "episode/intrinsic_return": 0.0}
{"step": 598712, "time": 27573.105657339096, "episode/length": 168.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 598728, "time": 27575.217926740646, "episode/length": 173.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 598768, "time": 27578.898019075394, "episode/length": 318.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968652037617555, "episode/intrinsic_return": 0.0}
{"step": 598928, "time": 27586.746865272522, "episode/length": 53.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 599888, "time": 27621.156957626343, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 599936, "time": 27624.335092306137, "episode/length": 152.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 600016, "time": 27628.68248486519, "episode/length": 200.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 600080, "time": 27647.884336709976, "eval_episode/length": 64.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 600080, "time": 27650.352583646774, "eval_episode/length": 89.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9888888888888889}
{"step": 600080, "time": 27655.06861448288, "eval_episode/length": 168.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9940828402366864}
{"step": 600080, "time": 27656.97146630287, "eval_episode/length": 176.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 600080, "time": 27658.860386371613, "eval_episode/length": 183.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.967391304347826}
{"step": 600080, "time": 27660.58258843422, "eval_episode/length": 185.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.978494623655914}
{"step": 600080, "time": 27665.087569475174, "eval_episode/length": 220.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9864253393665159}
{"step": 600080, "time": 27668.603043317795, "eval_episode/length": 186.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 600136, "time": 27670.411976099014, "episode/length": 183.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9836956521739131, "episode/intrinsic_return": 0.0}
{"step": 600240, "time": 27676.120530366898, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967391304347826, "episode/intrinsic_return": 0.0}
{"step": 600320, "time": 27680.741397619247, "episode/length": 210.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 600456, "time": 27687.190460205078, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9675925925925926, "episode/intrinsic_return": 0.0}
{"step": 600600, "time": 27693.49246764183, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 601552, "time": 27726.916283130646, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 601664, "time": 27732.30008649826, "episode/length": 215.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 601864, "time": 27740.277721881866, "episode/length": 202.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 601944, "time": 27744.559349775314, "episode/length": 202.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 602024, "time": 27748.711691617966, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 602600, "time": 27769.69649362564, "episode/length": 267.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 602760, "time": 27776.572560071945, "episode/length": 358.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9944289693593314, "episode/intrinsic_return": 0.0}
{"step": 602872, "time": 27781.847825288773, "episode/length": 164.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 603288, "time": 27797.282773971558, "episode/length": 393.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771573604060914, "episode/intrinsic_return": 0.0}
{"step": 603584, "time": 27808.835062503815, "episode/length": 214.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 603760, "time": 27816.200415611267, "episode/length": 216.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 604000, "time": 27825.773339748383, "episode/length": 256.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9961089494163424, "episode/intrinsic_return": 0.0}
{"step": 604328, "time": 27838.015172719955, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 604632, "time": 27849.775578022003, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 604648, "time": 27851.78502726555, "episode/length": 372.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9892761394101877, "episode/intrinsic_return": 0.0}
{"step": 604736, "time": 27856.50856614113, "episode/length": 232.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 605288, "time": 27876.127249240875, "episode/length": 335.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9851190476190477, "episode/intrinsic_return": 0.0}
{"step": 605520, "time": 27885.749547958374, "episode/length": 241.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9710743801652892, "episode/intrinsic_return": 0.0}
{"step": 605544, "time": 27887.92257475853, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 605896, "time": 27901.44287252426, "episode/length": 195.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 606032, "time": 27908.347387313843, "episode/length": 174.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 606064, "time": 27911.400827407837, "episode/length": 287.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 606136, "time": 27915.634495973587, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9657142857142857, "episode/intrinsic_return": 0.0}
{"step": 606408, "time": 27927.883007526398, "episode/length": 46.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 606640, "time": 27937.432489156723, "episode/length": 139.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9928571428571429, "episode/intrinsic_return": 0.0}
{"step": 606720, "time": 27941.761699199677, "episode/length": 102.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 607656, "time": 27974.978835105896, "episode/length": 263.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 607680, "time": 27977.963672161102, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 607832, "time": 27984.880901813507, "episode/length": 138.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 607896, "time": 27988.564257383347, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 608048, "time": 27995.356419324875, "episode/length": 344.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.991304347826087, "episode/intrinsic_return": 0.0}
{"step": 608144, "time": 28000.155886650085, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 608152, "time": 28001.809116601944, "episode/length": 437.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 608256, "time": 28007.131089925766, "episode/length": 273.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9781021897810219, "episode/intrinsic_return": 0.0}
{"step": 608536, "time": 28017.72043323517, "episode/length": 60.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9344262295081968, "episode/intrinsic_return": 0.0}
{"step": 609136, "time": 28039.452350378036, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 609400, "time": 28049.59169101715, "episode/length": 187.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 609520, "time": 28055.40279364586, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 609520, "time": 28055.410575151443, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 609624, "time": 28062.009066581726, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 609640, "time": 28064.179856061935, "episode/length": 244.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 610064, "time": 28094.6902718544, "eval_episode/length": 46.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 610064, "time": 28100.59548187256, "eval_episode/length": 159.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.975}
{"step": 610064, "time": 28102.613899469376, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9707602339181286}
{"step": 610064, "time": 28105.241523504257, "eval_episode/length": 147.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 610064, "time": 28106.798283100128, "eval_episode/length": 195.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 610064, "time": 28108.419270515442, "eval_episode/length": 196.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 610064, "time": 28110.0751516819, "eval_episode/length": 198.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9748743718592965}
{"step": 610064, "time": 28112.28705716133, "eval_episode/length": 213.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9953271028037384}
{"step": 610072, "time": 28112.3377327919, "episode/length": 191.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 610624, "time": 28132.835422754288, "episode/length": 185.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 611120, "time": 28151.928755044937, "episode/length": 186.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 611456, "time": 28165.177973747253, "episode/length": 41.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8809523809523809, "episode/intrinsic_return": 0.0}
{"step": 611552, "time": 28169.917135477066, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 611560, "time": 28171.52354168892, "episode/length": 269.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9962962962962963, "episode/intrinsic_return": 0.0}
{"step": 611568, "time": 28173.59161400795, "episode/length": 426.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859484777517564, "episode/intrinsic_return": 0.0}
{"step": 611832, "time": 28183.861369132996, "episode/length": 288.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965397923875432, "episode/intrinsic_return": 0.0}
{"step": 612008, "time": 28191.379457712173, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9653179190751445, "episode/intrinsic_return": 0.0}
{"step": 612088, "time": 28196.0320456028, "episode/length": 305.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836601307189542, "episode/intrinsic_return": 0.0}
{"step": 612856, "time": 28223.40477991104, "episode/length": 174.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 612896, "time": 28226.560374975204, "episode/length": 421.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9976303317535545, "episode/intrinsic_return": 0.0}
{"step": 612976, "time": 28230.84156537056, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 613328, "time": 28244.243272781372, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 613584, "time": 28254.92143702507, "episode/length": 253.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 614184, "time": 28276.05512237549, "episode/length": 261.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9694656488549618, "episode/intrinsic_return": 0.0}
{"step": 614560, "time": 28291.944755792618, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 614560, "time": 28291.953893184662, "episode/length": 207.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 614944, "time": 28308.574541330338, "episode/length": 245.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 614976, "time": 28311.190759658813, "episode/length": 425.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 615040, "time": 28314.99071574211, "episode/length": 400.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 615048, "time": 28316.543289661407, "episode/length": 60.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 615072, "time": 28319.150187015533, "episode/length": 185.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 615129, "time": 28323.418501138687, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.029264613560268, "train/action_min": 0.0, "train/action_std": 2.8458332998411997, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.034858873912266324, "train/actor_opt_grad_steps": 37645.0, "train/actor_opt_loss": -7.525720533089978, "train/adv_mag": 0.4875553597296987, "train/adv_max": 0.4026228419372014, "train/adv_mean": 0.00257590952330377, "train/adv_min": -0.42085348793438504, "train/adv_std": 0.05332247284906251, "train/cont_avg": 0.9949567522321429, "train/cont_loss_mean": 0.00013631750132714972, "train/cont_loss_std": 0.003939944235969506, "train/cont_neg_acc": 0.9975510209798812, "train/cont_neg_loss": 0.012440345423276865, "train/cont_pos_acc": 0.9999859320265906, "train/cont_pos_loss": 6.277527641641102e-05, "train/cont_pred": 0.9949359476566315, "train/cont_rate": 0.9949567522321429, "train/dyn_loss_mean": 13.81061201776777, "train/dyn_loss_std": 9.030078227179391, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.8952036308390754, "train/extr_critic_critic_opt_grad_steps": 37645.0, "train/extr_critic_critic_opt_loss": 15576.395096261162, "train/extr_critic_mag": 8.654126058306012, "train/extr_critic_max": 8.654126058306012, "train/extr_critic_mean": 2.8220002812998635, "train/extr_critic_min": -0.16732367362294878, "train/extr_critic_std": 2.0212686683450425, "train/extr_return_normed_mag": 1.5162666227136339, "train/extr_return_normed_max": 1.5162666227136339, "train/extr_return_normed_mean": 0.4016862339207104, "train/extr_return_normed_min": -0.14117999161992753, "train/extr_return_normed_std": 0.32609058618545533, "train/extr_return_rate": 0.9002055908952441, "train/extr_return_raw_mag": 9.86120947429112, "train/extr_return_raw_max": 9.86120947429112, "train/extr_return_raw_mean": 2.838246190547943, "train/extr_return_raw_min": -0.5825027207178729, "train/extr_return_raw_std": 2.0549233530248916, "train/extr_reward_mag": 1.0225210223879133, "train/extr_reward_max": 1.0225210223879133, "train/extr_reward_mean": 0.0388681001562093, "train/extr_reward_min": -0.4966145839009966, "train/extr_reward_std": 0.18331794046929906, "train/image_loss_mean": 7.138864949771336, "train/image_loss_std": 12.294145100457328, "train/model_loss_mean": 15.48209364073617, "train/model_loss_std": 15.959906789234706, "train/model_opt_grad_norm": 57.420418412344794, "train/model_opt_grad_steps": 37611.0, "train/model_opt_loss": 13385.600160435268, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 861.6071428571429, "train/policy_entropy_mag": 2.4939782091549465, "train/policy_entropy_max": 2.4939782091549465, "train/policy_entropy_mean": 0.479088265980993, "train/policy_entropy_min": 0.07937506863049099, "train/policy_entropy_std": 0.5477729241762842, "train/policy_logprob_mag": 7.438383620125907, "train/policy_logprob_max": -0.009455666857372437, "train/policy_logprob_mean": -0.4780391146029745, "train/policy_logprob_min": -7.438383620125907, "train/policy_logprob_std": 1.0476394836391723, "train/policy_randomness_mag": 0.8802648603916168, "train/policy_randomness_max": 0.8802648603916168, "train/policy_randomness_mean": 0.1690971363868032, "train/policy_randomness_min": 0.028015915996262006, "train/policy_randomness_std": 0.19333980562431471, "train/post_ent_mag": 57.072902515956336, "train/post_ent_max": 57.072902515956336, "train/post_ent_mean": 41.169173676627025, "train/post_ent_min": 19.85880857195173, "train/post_ent_std": 7.1963218450546265, "train/prior_ent_mag": 66.30113045828683, "train/prior_ent_max": 66.30113045828683, "train/prior_ent_mean": 55.0336062840053, "train/prior_ent_min": 39.88203590938023, "train/prior_ent_std": 4.311706553186689, "train/rep_loss_mean": 13.81061201776777, "train/rep_loss_std": 9.030078227179391, "train/reward_avg": 0.028696288893531475, "train/reward_loss_mean": 0.056725193480295796, "train/reward_loss_std": 0.2594122309769903, "train/reward_max_data": 1.014285717691694, "train/reward_max_pred": 1.009764678137643, "train/reward_neg_acc": 0.9930414863995143, "train/reward_neg_loss": 0.029241916623764803, "train/reward_pos_acc": 0.9624905650104795, "train/reward_pos_loss": 0.861442186151232, "train/reward_pred": 0.02785044194731329, "train/reward_rate": 0.03317522321428571, "train_stats/sum_log_reward": 8.792307917888348, "train_stats/max_log_achievement_collect_coal": 0.3942307692307692, "train_stats/max_log_achievement_collect_drink": 4.644230769230769, "train_stats/max_log_achievement_collect_sapling": 1.4519230769230769, "train_stats/max_log_achievement_collect_stone": 11.125, "train_stats/max_log_achievement_collect_wood": 11.326923076923077, "train_stats/max_log_achievement_defeat_skeleton": 0.009615384615384616, "train_stats/max_log_achievement_defeat_zombie": 0.5769230769230769, "train_stats/max_log_achievement_eat_cow": 0.10576923076923077, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7596153846153846, "train_stats/max_log_achievement_make_wood_sword": 0.8557692307692307, "train_stats/max_log_achievement_place_furnace": 0.028846153846153848, "train_stats/max_log_achievement_place_plant": 1.3942307692307692, "train_stats/max_log_achievement_place_stone": 8.490384615384615, "train_stats/max_log_achievement_place_table": 2.576923076923077, "train_stats/max_log_achievement_wake_up": 1.375, "train_stats/mean_log_entropy": 0.499512988787431, "eval_stats/sum_log_reward": 8.725000262260437, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.5, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 7.125, "eval_stats/max_log_achievement_collect_wood": 10.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.6875, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 5.0625, "eval_stats/max_log_achievement_place_table": 3.0, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.0013826795329805e-05, "report/cont_loss_std": 0.0002149190113414079, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.002177528804168105, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.513767756478046e-06, "report/cont_pred": 0.9961007833480835, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 13.573898315429688, "report/dyn_loss_std": 8.876078605651855, "report/image_loss_mean": 7.616420269012451, "report/image_loss_std": 9.699951171875, "report/model_loss_mean": 15.826950073242188, "report/model_loss_std": 13.54520320892334, "report/post_ent_mag": 57.615108489990234, "report/post_ent_max": 57.615108489990234, "report/post_ent_mean": 41.9008674621582, "report/post_ent_min": 14.334051132202148, "report/post_ent_std": 7.286354064941406, "report/prior_ent_mag": 66.02962493896484, "report/prior_ent_max": 66.02962493896484, "report/prior_ent_mean": 55.672630310058594, "report/prior_ent_min": 37.337379455566406, "report/prior_ent_std": 4.572310924530029, "report/rep_loss_mean": 13.573898315429688, "report/rep_loss_std": 8.876078605651855, "report/reward_avg": 0.02988281100988388, "report/reward_loss_mean": 0.06618136167526245, "report/reward_loss_std": 0.2871452569961548, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0005576610565186, "report/reward_neg_acc": 0.996966540813446, "report/reward_neg_loss": 0.038758285343647, "report/reward_pos_acc": 0.9714285731315613, "report/reward_pos_loss": 0.8410789370536804, "report/reward_pred": 0.027442919090390205, "report/reward_rate": 0.0341796875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 4.32653814641526e-06, "eval/cont_loss_std": 8.382441592402756e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0002018645900534466, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.133441052545095e-06, "eval/cont_pred": 0.9990196228027344, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 15.902569770812988, "eval/dyn_loss_std": 10.194389343261719, "eval/image_loss_mean": 14.776652336120605, "eval/image_loss_std": 26.142812728881836, "eval/model_loss_mean": 24.43198585510254, "eval/model_loss_std": 29.940778732299805, "eval/post_ent_mag": 54.93254089355469, "eval/post_ent_max": 54.93254089355469, "eval/post_ent_mean": 40.35163116455078, "eval/post_ent_min": 19.22112464904785, "eval/post_ent_std": 6.967707633972168, "eval/prior_ent_mag": 66.02962493896484, "eval/prior_ent_max": 66.02962493896484, "eval/prior_ent_mean": 54.401527404785156, "eval/prior_ent_min": 35.24034118652344, "eval/prior_ent_std": 4.305120468139648, "eval/rep_loss_mean": 15.902569770812988, "eval/rep_loss_std": 10.194389343261719, "eval/reward_avg": 0.03544921800494194, "eval/reward_loss_mean": 0.11378827691078186, "eval/reward_loss_std": 0.6380665898323059, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0016560554504395, "eval/reward_neg_acc": 0.989847719669342, "eval/reward_neg_loss": 0.05986582115292549, "eval/reward_pos_acc": 0.8461538553237915, "eval/reward_pos_loss": 1.4756758213043213, "eval/reward_pred": 0.031888559460639954, "eval/reward_rate": 0.0380859375, "replay/size": 614625.0, "replay/inserts": 22416.0, "replay/samples": 22416.0, "replay/insert_wait_avg": 1.3051651614976729e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.248601259970818e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3728.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0724998850679193e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.5367431640625e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1469995975494, "timer/env.step_count": 2802.0, "timer/env.step_total": 247.3534095287323, "timer/env.step_frac": 0.24731705402132406, "timer/env.step_avg": 0.08827744808305935, "timer/env.step_min": 0.02225804328918457, "timer/env.step_max": 3.3380002975463867, "timer/replay._sample_count": 22416.0, "timer/replay._sample_total": 11.053001642227173, "timer/replay._sample_frac": 0.011051377094241952, "timer/replay._sample_avg": 0.0004930853694783714, "timer/replay._sample_min": 0.00040459632873535156, "timer/replay._sample_max": 0.00960850715637207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3268.0, "timer/agent.policy_total": 53.348403215408325, "timer/agent.policy_frac": 0.053340562174235655, "timer/agent.policy_avg": 0.016324480788068644, "timer/agent.policy_min": 0.009206771850585938, "timer/agent.policy_max": 0.10702824592590332, "timer/dataset_train_count": 1401.0, "timer/dataset_train_total": 0.14858222007751465, "timer/dataset_train_frac": 0.00014856038176118397, "timer/dataset_train_avg": 0.00010605440405247298, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00024199485778808594, "timer/agent.train_count": 1401.0, "timer/agent.train_total": 634.4011635780334, "timer/agent.train_frac": 0.6343079205689874, "timer/agent.train_avg": 0.45282024523771125, "timer/agent.train_min": 0.4387209415435791, "timer/agent.train_max": 2.003462553024292, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47836828231811523, "timer/agent.report_frac": 0.00047829797270861833, "timer/agent.report_avg": 0.23918414115905762, "timer/agent.report_min": 0.2318887710571289, "timer/agent.report_max": 0.24647951126098633, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.24249267578125e-05, "timer/dataset_eval_frac": 3.2420161007191955e-08, "timer/dataset_eval_avg": 3.24249267578125e-05, "timer/dataset_eval_min": 3.24249267578125e-05, "timer/dataset_eval_max": 3.24249267578125e-05, "fps": 22.412394035567704}
{"step": 615288, "time": 28328.778101444244, "episode/length": 38.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8717948717948718, "episode/intrinsic_return": 0.0}
{"step": 615616, "time": 28342.36218070984, "episode/length": 285.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9755244755244755, "episode/intrinsic_return": 0.0}
{"step": 616264, "time": 28366.763683080673, "episode/length": 259.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 616424, "time": 28373.75954937935, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 616440, "time": 28375.830729484558, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 616584, "time": 28382.13295483589, "episode/length": 204.0, "episode/score": 5.099999964237213, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 616624, "time": 28385.247443675995, "episode/length": 197.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 616768, "time": 28391.565299272537, "episode/length": 143.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 617760, "time": 28426.238965511322, "episode/length": 164.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 618096, "time": 28439.256500720978, "episode/length": 165.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 618184, "time": 28444.02158164978, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 618192, "time": 28446.439646959305, "episode/length": 200.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 618216, "time": 28449.074899196625, "episode/length": 243.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 618376, "time": 28456.798670768738, "episode/length": 76.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.935064935064935, "episode/intrinsic_return": 0.0}
{"step": 618576, "time": 28465.856808900833, "episode/length": 44.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 618584, "time": 28467.877254486084, "episode/length": 438.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 618640, "time": 28472.143617868423, "episode/length": 55.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 619336, "time": 28497.058800697327, "episode/length": 363.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 619544, "time": 28505.547471046448, "episode/length": 531.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9981203007518797, "episode/intrinsic_return": 0.0}
{"step": 619688, "time": 28512.038679599762, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 619704, "time": 28514.07827615738, "episode/length": 200.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 620048, "time": 28541.976019382477, "eval_episode/length": 50.0, "eval_episode/score": 2.1000000089406967, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 620048, "time": 28543.83654665947, "eval_episode/length": 59.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9166666666666666}
{"step": 620048, "time": 28548.341656684875, "eval_episode/length": 134.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9555555555555556}
{"step": 620048, "time": 28550.961834669113, "eval_episode/length": 159.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.96875}
{"step": 620048, "time": 28554.37500357628, "eval_episode/length": 203.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9950980392156863}
{"step": 620048, "time": 28558.41820883751, "eval_episode/length": 131.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9924242424242424}
{"step": 620048, "time": 28560.840324640274, "eval_episode/length": 130.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9694656488549618}
{"step": 620048, "time": 28562.75132083893, "eval_episode/length": 238.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.99581589958159}
{"step": 620392, "time": 28574.07000732422, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 620424, "time": 28576.651509046555, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 620576, "time": 28583.460315465927, "episode/length": 249.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 620768, "time": 28591.391124248505, "episode/length": 298.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9732441471571907, "episode/intrinsic_return": 0.0}
{"step": 621520, "time": 28617.95391869545, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 621896, "time": 28631.896644592285, "episode/length": 164.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9878787878787879, "episode/intrinsic_return": 0.0}
{"step": 621912, "time": 28634.00830721855, "episode/length": 189.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 622088, "time": 28641.444145202637, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 622224, "time": 28648.381354808807, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 622544, "time": 28661.61962747574, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 622640, "time": 28668.621215343475, "episode/length": 368.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 623024, "time": 28683.318204641342, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 623032, "time": 28684.943232536316, "episode/length": 139.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 623440, "time": 28700.25545144081, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 623544, "time": 28704.999038219452, "episode/length": 499.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.994, "episode/intrinsic_return": 0.0}
{"step": 623864, "time": 28717.167805194855, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 624048, "time": 28725.17475605011, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 624472, "time": 28740.482672691345, "episode/length": 180.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 624704, "time": 28749.938836812973, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943019943019943, "episode/intrinsic_return": 0.0}
{"step": 624712, "time": 28751.69824051857, "episode/length": 258.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 624792, "time": 28755.961572170258, "episode/length": 39.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 625208, "time": 28771.651298999786, "episode/length": 167.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 626440, "time": 28816.171845436096, "episode/length": 216.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 626536, "time": 28821.514110803604, "episode/length": 437.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 626680, "time": 28828.43595981598, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9619565217391305, "episode/intrinsic_return": 0.0}
{"step": 626728, "time": 28832.096175670624, "episode/length": 410.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9927007299270073, "episode/intrinsic_return": 0.0}
{"step": 626848, "time": 28838.486018657684, "episode/length": 266.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 627112, "time": 28849.53929567337, "episode/length": 445.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 627224, "time": 28855.463426828384, "episode/length": 396.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9924433249370277, "episode/intrinsic_return": 0.0}
{"step": 628192, "time": 28890.255949020386, "episode/length": 424.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9929411764705882, "episode/intrinsic_return": 0.0}
{"step": 628288, "time": 28895.107241630554, "episode/length": 218.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 628328, "time": 28897.789610624313, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 628432, "time": 28903.068501234055, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 628664, "time": 28912.076256513596, "episode/length": 58.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9322033898305084, "episode/intrinsic_return": 0.0}
{"step": 628776, "time": 28917.356991052628, "episode/length": 261.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 628920, "time": 28923.68667769432, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 629152, "time": 28933.111335277557, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9647058823529412, "episode/intrinsic_return": 0.0}
{"step": 629616, "time": 28950.079474687576, "episode/length": 147.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9662162162162162, "episode/intrinsic_return": 0.0}
{"step": 629808, "time": 28958.1369433403, "episode/length": 384.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9974025974025974, "episode/intrinsic_return": 0.0}
{"step": 629880, "time": 28962.062172412872, "episode/length": 137.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 629912, "time": 28964.668756484985, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 630024, "time": 28970.081807613373, "episode/length": 216.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9723502304147466, "episode/intrinsic_return": 0.0}
{"step": 630032, "time": 28986.86538863182, "eval_episode/length": 41.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 630032, "time": 28988.614471673965, "eval_episode/length": 46.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 630032, "time": 28994.993042707443, "eval_episode/length": 157.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 630032, "time": 28998.550337076187, "eval_episode/length": 187.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 630032, "time": 29000.98382139206, "eval_episode/length": 196.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 630032, "time": 29003.103480815887, "eval_episode/length": 198.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 630032, "time": 29005.18786096573, "eval_episode/length": 210.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9715639810426541}
{"step": 630032, "time": 29007.69311928749, "eval_episode/length": 232.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 630408, "time": 29020.028531074524, "episode/length": 217.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 630416, "time": 29022.093564510345, "episode/length": 186.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 630608, "time": 29030.103546857834, "episode/length": 181.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 630944, "time": 29044.360995292664, "episode/length": 141.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 631432, "time": 29062.635335683823, "episode/length": 189.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 631528, "time": 29067.421827077866, "episode/length": 205.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 631544, "time": 29069.58806324005, "episode/length": 189.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 631688, "time": 29075.979292154312, "episode/length": 258.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9845559845559846, "episode/intrinsic_return": 0.0}
{"step": 632192, "time": 29094.7305495739, "episode/length": 222.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 632456, "time": 29104.863246917725, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9682539682539683, "episode/intrinsic_return": 0.0}
{"step": 632800, "time": 29118.476196289062, "episode/length": 297.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9798657718120806, "episode/intrinsic_return": 0.0}
{"step": 632856, "time": 29122.09303855896, "episode/length": 280.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679715302491103, "episode/intrinsic_return": 0.0}
{"step": 632912, "time": 29126.313136816025, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 633144, "time": 29135.901143074036, "episode/length": 85.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9534883720930233, "episode/intrinsic_return": 0.0}
{"step": 633720, "time": 29156.98902606964, "episode/length": 285.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9685314685314685, "episode/intrinsic_return": 0.0}
{"step": 633720, "time": 29157.006687879562, "episode/length": 190.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 634432, "time": 29184.769205331802, "episode/length": 203.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 634432, "time": 29184.778710126877, "episode/length": 189.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9578947368421052, "episode/intrinsic_return": 0.0}
{"step": 634464, "time": 29189.30360507965, "episode/length": 366.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 634656, "time": 29197.154990911484, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 634968, "time": 29209.00684428215, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 635040, "time": 29213.18325304985, "episode/length": 418.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9952267303102625, "episode/intrinsic_return": 0.0}
{"step": 635048, "time": 29214.771661758423, "episode/length": 72.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9178082191780822, "episode/intrinsic_return": 0.0}
{"step": 635152, "time": 29219.95916867256, "episode/length": 178.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 635424, "time": 29230.67558145523, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 636008, "time": 29251.331817150116, "episode/length": 196.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 636256, "time": 29261.509169578552, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 636312, "time": 29264.70937848091, "episode/length": 157.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 636520, "time": 29273.191334486008, "episode/length": 184.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 636624, "time": 29278.40948534012, "episode/length": 273.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 636704, "time": 29282.535037994385, "episode/length": 193.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9948453608247423, "episode/intrinsic_return": 0.0}
{"step": 636768, "time": 29286.28269457817, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 637224, "time": 29302.636001825333, "episode/length": 281.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9964539007092199, "episode/intrinsic_return": 0.0}
{"step": 637616, "time": 29317.402046442032, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 637729, "time": 29323.41278910637, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.19898105675066, "train/action_min": 0.0, "train/action_std": 3.0337153219840896, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03514393491172035, "train/actor_opt_grad_steps": 39055.0, "train/actor_opt_loss": -8.456805169967685, "train/adv_mag": 0.4721326559362277, "train/adv_max": 0.4177493784629123, "train/adv_mean": 0.0026442637639595722, "train/adv_min": -0.3917082489376337, "train/adv_std": 0.05287035995386016, "train/cont_avg": 0.994903994278169, "train/cont_loss_mean": 0.00024106189983921815, "train/cont_loss_std": 0.0070777378086595046, "train/cont_neg_acc": 0.9926643199484113, "train/cont_neg_loss": 0.02119576684919632, "train/cont_pos_acc": 0.9999654607873567, "train/cont_pos_loss": 0.00012322695972599718, "train/cont_pred": 0.9949087899335674, "train/cont_rate": 0.994903994278169, "train/dyn_loss_mean": 13.736018415907738, "train/dyn_loss_std": 9.071989267644748, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.917960718064241, "train/extr_critic_critic_opt_grad_steps": 39055.0, "train/extr_critic_critic_opt_loss": 15539.224464953786, "train/extr_critic_mag": 8.874761890357648, "train/extr_critic_max": 8.874761890357648, "train/extr_critic_mean": 2.8470499481953366, "train/extr_critic_min": -0.15617544718191656, "train/extr_critic_std": 2.0796562340897573, "train/extr_return_normed_mag": 1.5059354750203415, "train/extr_return_normed_max": 1.5059354750203415, "train/extr_return_normed_mean": 0.3987934578892211, "train/extr_return_normed_min": -0.1298329143352072, "train/extr_return_normed_std": 0.3261555034509847, "train/extr_return_rate": 0.8890052345437063, "train/extr_return_raw_mag": 10.03792101228741, "train/extr_return_raw_max": 10.03792101228741, "train/extr_return_raw_mean": 2.8641877711658745, "train/extr_return_raw_min": -0.5611060955364939, "train/extr_return_raw_std": 2.1136076534298103, "train/extr_reward_mag": 1.0272416145029202, "train/extr_reward_max": 1.0272416145029202, "train/extr_reward_mean": 0.04086326406350438, "train/extr_reward_min": -0.4800316867694049, "train/extr_reward_std": 0.18742588708098507, "train/image_loss_mean": 7.207085102376803, "train/image_loss_std": 12.42395005091815, "train/model_loss_mean": 15.5062315967721, "train/model_loss_std": 16.095178476521667, "train/model_opt_grad_norm": 58.278004565709075, "train/model_opt_grad_steps": 39020.373239436616, "train/model_opt_loss": 20067.724746919015, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1302.8169014084508, "train/policy_entropy_mag": 2.5690836872853025, "train/policy_entropy_max": 2.5690836872853025, "train/policy_entropy_mean": 0.522848376715687, "train/policy_entropy_min": 0.07937506948348502, "train/policy_entropy_std": 0.618729089977036, "train/policy_logprob_mag": 7.438383636340289, "train/policy_logprob_max": -0.009455665060594467, "train/policy_logprob_mean": -0.5228647402894329, "train/policy_logprob_min": -7.438383636340289, "train/policy_logprob_std": 1.083011504629968, "train/policy_randomness_mag": 0.9067738030997801, "train/policy_randomness_max": 0.9067738030997801, "train/policy_randomness_mean": 0.18454253280036886, "train/policy_randomness_min": 0.028015916314448268, "train/policy_randomness_std": 0.21838421731347768, "train/post_ent_mag": 57.267983772385286, "train/post_ent_max": 57.267983772385286, "train/post_ent_mean": 41.329067015312084, "train/post_ent_min": 19.80005456360293, "train/post_ent_std": 7.251322091465265, "train/prior_ent_mag": 66.35920478928257, "train/prior_ent_max": 66.35920478928257, "train/prior_ent_mean": 55.12108880701199, "train/prior_ent_min": 40.12864174641354, "train/prior_ent_std": 4.311049943238917, "train/rep_loss_mean": 13.736018415907738, "train/rep_loss_std": 9.071989267644748, "train/reward_avg": 0.029873184236684735, "train/reward_loss_mean": 0.057294459488820025, "train/reward_loss_std": 0.2543981080533753, "train/reward_max_data": 1.016197186960301, "train/reward_max_pred": 1.0073810874576299, "train/reward_neg_acc": 0.992883411511569, "train/reward_neg_loss": 0.029043195028067896, "train/reward_pos_acc": 0.9660129811562282, "train/reward_pos_loss": 0.8517274226940853, "train/reward_pred": 0.029047267511487007, "train/reward_rate": 0.034502915933098594, "train_stats/sum_log_reward": 8.801031161829368, "train_stats/max_log_achievement_collect_coal": 0.4536082474226804, "train_stats/max_log_achievement_collect_drink": 4.030927835051546, "train_stats/max_log_achievement_collect_sapling": 1.5670103092783505, "train_stats/max_log_achievement_collect_stone": 10.494845360824742, "train_stats/max_log_achievement_collect_wood": 12.216494845360824, "train_stats/max_log_achievement_defeat_skeleton": 0.041237113402061855, "train_stats/max_log_achievement_defeat_zombie": 0.5670103092783505, "train_stats/max_log_achievement_eat_cow": 0.17525773195876287, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010309278350515464, "train_stats/max_log_achievement_make_wood_pickaxe": 1.7731958762886597, "train_stats/max_log_achievement_make_wood_sword": 0.8556701030927835, "train_stats/max_log_achievement_place_furnace": 0.010309278350515464, "train_stats/max_log_achievement_place_plant": 1.402061855670103, "train_stats/max_log_achievement_place_stone": 8.824742268041238, "train_stats/max_log_achievement_place_table": 2.515463917525773, "train_stats/max_log_achievement_wake_up": 1.6288659793814433, "train_stats/mean_log_entropy": 0.5347421448869804, "eval_stats/sum_log_reward": 6.725000128149986, "eval_stats/max_log_achievement_collect_coal": 0.0625, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 1.125, "eval_stats/max_log_achievement_collect_stone": 1.125, "eval_stats/max_log_achievement_collect_wood": 9.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 0.875, "eval_stats/max_log_achievement_place_table": 2.0625, "eval_stats/max_log_achievement_wake_up": 0.75, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00021949569054413587, "report/cont_loss_std": 0.005561378318816423, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0288662388920784, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.065436926088296e-05, "report/cont_pred": 0.9942464232444763, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.204660415649414, "report/dyn_loss_std": 8.789875030517578, "report/image_loss_mean": 6.712714672088623, "report/image_loss_std": 12.068300247192383, "report/model_loss_mean": 14.694417953491211, "report/model_loss_std": 15.53734016418457, "report/post_ent_mag": 57.87698745727539, "report/post_ent_max": 57.87698745727539, "report/post_ent_mean": 41.47408676147461, "report/post_ent_min": 20.231809616088867, "report/post_ent_std": 7.457149982452393, "report/prior_ent_mag": 66.61784362792969, "report/prior_ent_max": 66.61784362792969, "report/prior_ent_mean": 55.069000244140625, "report/prior_ent_min": 39.15828323364258, "report/prior_ent_std": 4.507572650909424, "report/rep_loss_mean": 13.204660415649414, "report/rep_loss_std": 8.789875030517578, "report/reward_avg": 0.03281250223517418, "report/reward_loss_mean": 0.05868833139538765, "report/reward_loss_std": 0.24286681413650513, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0092101097106934, "report/reward_neg_acc": 0.9959391355514526, "report/reward_neg_loss": 0.025605862960219383, "report/reward_pos_acc": 0.9487179517745972, "report/reward_pos_loss": 0.8942327499389648, "report/reward_pred": 0.02920527011156082, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 2.117354415531736e-05, "eval/cont_loss_std": 0.0002497112436685711, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 6.180709169711918e-05, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 2.1014197045587935e-05, "eval/cont_pred": 0.9960731267929077, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 15.662898063659668, "eval/dyn_loss_std": 10.096755981445312, "eval/image_loss_mean": 8.896202087402344, "eval/image_loss_std": 14.403456687927246, "eval/model_loss_mean": 18.38356590270996, "eval/model_loss_std": 18.3798770904541, "eval/post_ent_mag": 55.780120849609375, "eval/post_ent_max": 55.780120849609375, "eval/post_ent_mean": 40.768062591552734, "eval/post_ent_min": 18.75254249572754, "eval/post_ent_std": 7.147367477416992, "eval/prior_ent_mag": 66.61784362792969, "eval/prior_ent_max": 66.61784362792969, "eval/prior_ent_mean": 54.84966278076172, "eval/prior_ent_min": 39.51177978515625, "eval/prior_ent_std": 4.383768558502197, "eval/rep_loss_mean": 15.662898063659668, "eval/rep_loss_std": 10.096755981445312, "eval/reward_avg": 0.02939452975988388, "eval/reward_loss_mean": 0.08960454910993576, "eval/reward_loss_std": 0.5590235590934753, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0021998882293701, "eval/reward_neg_acc": 0.9898989200592041, "eval/reward_neg_loss": 0.03449920937418938, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 1.6941423416137695, "eval/reward_pred": 0.02431609481573105, "eval/reward_rate": 0.033203125, "replay/size": 637225.0, "replay/inserts": 22600.0, "replay/samples": 22592.0, "replay/insert_wait_avg": 1.3258182896976977e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.354018539612421e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4256.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0654330253601074e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 999.986958026886, "timer/env.step_count": 2825.0, "timer/env.step_total": 241.28498530387878, "timer/env.step_frac": 0.24128813217721137, "timer/env.step_avg": 0.08541061426685975, "timer/env.step_min": 0.022472858428955078, "timer/env.step_max": 3.480806589126587, "timer/replay._sample_count": 22592.0, "timer/replay._sample_total": 11.236310720443726, "timer/replay._sample_frac": 0.011236457266017286, "timer/replay._sample_avg": 0.0004973579461952782, "timer/replay._sample_min": 0.00037360191345214844, "timer/replay._sample_max": 0.027985572814941406, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3357.0, "timer/agent.policy_total": 53.650052547454834, "timer/agent.policy_frac": 0.053650752259123344, "timer/agent.policy_avg": 0.015981546782083658, "timer/agent.policy_min": 0.00902414321899414, "timer/agent.policy_max": 0.08853840827941895, "timer/dataset_train_count": 1412.0, "timer/dataset_train_total": 0.1494464874267578, "timer/dataset_train_frac": 0.00014944843652924897, "timer/dataset_train_avg": 0.00010584028854586247, "timer/dataset_train_min": 9.012222290039062e-05, "timer/dataset_train_max": 0.0005540847778320312, "timer/agent.train_count": 1412.0, "timer/agent.train_total": 637.3666253089905, "timer/agent.train_frac": 0.6373749379357946, "timer/agent.train_avg": 0.45139279412818023, "timer/agent.train_min": 0.43834948539733887, "timer/agent.train_max": 1.6654455661773682, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47213149070739746, "timer/agent.report_frac": 0.0004721376483139129, "timer/agent.report_avg": 0.23606574535369873, "timer/agent.report_min": 0.22939085960388184, "timer/agent.report_max": 0.24274063110351562, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8371810913085938e-05, "timer/dataset_eval_frac": 2.8372180942306974e-08, "timer/dataset_eval_avg": 2.8371810913085938e-05, "timer/dataset_eval_min": 2.8371810913085938e-05, "timer/dataset_eval_max": 2.8371810913085938e-05, "fps": 22.599985791167608}
{"step": 638064, "time": 29334.89051747322, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 638088, "time": 29336.959129571915, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 638192, "time": 29342.176776885986, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 638248, "time": 29345.51426577568, "episode/length": 241.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752066115702479, "episode/intrinsic_return": 0.0}
{"step": 638792, "time": 29365.15681886673, "episode/length": 316.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 638920, "time": 29370.852117538452, "episode/length": 211.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 639152, "time": 29382.124079465866, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 639632, "time": 29400.284899950027, "episode/length": 192.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 639664, "time": 29403.053228378296, "episode/length": 392.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.989821882951654, "episode/intrinsic_return": 0.0}
{"step": 639904, "time": 29412.610517024994, "episode/length": 213.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 639944, "time": 29415.293633461, "episode/length": 211.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 640016, "time": 29434.8568046093, "eval_episode/length": 56.0, "eval_episode/score": 5.099999971687794, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 640016, "time": 29442.336982011795, "eval_episode/length": 181.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9945054945054945}
{"step": 640016, "time": 29444.544232606888, "eval_episode/length": 183.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 640016, "time": 29446.719757556915, "eval_episode/length": 187.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9946808510638298}
{"step": 640016, "time": 29448.93762397766, "eval_episode/length": 190.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 640016, "time": 29451.6263794899, "eval_episode/length": 201.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9702970297029703}
{"step": 640016, "time": 29459.7784948349, "eval_episode/length": 236.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 640016, "time": 29462.265234947205, "eval_episode/length": 302.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9966996699669967}
{"step": 640304, "time": 29472.302139759064, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 640392, "time": 29476.574367761612, "episode/length": 290.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9759450171821306, "episode/intrinsic_return": 0.0}
{"step": 640808, "time": 29492.32797718048, "episode/length": 62.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 641112, "time": 29504.020862817764, "episode/length": 244.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 641240, "time": 29509.8939473629, "episode/length": 161.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 641360, "time": 29515.674803733826, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 641360, "time": 29515.68407511711, "episode/length": 211.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 641584, "time": 29526.43992304802, "episode/length": 58.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 642040, "time": 29542.912177801132, "episode/length": 405.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9901477832512315, "episode/intrinsic_return": 0.0}
{"step": 642064, "time": 29545.595807790756, "episode/length": 208.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 642224, "time": 29552.545416355133, "episode/length": 176.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 642504, "time": 29563.298494815826, "episode/length": 324.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9969230769230769, "episode/intrinsic_return": 0.0}
{"step": 642840, "time": 29576.31840968132, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 643080, "time": 29586.246963977814, "episode/length": 186.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 643168, "time": 29591.089829921722, "episode/length": 225.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 643568, "time": 29605.758679628372, "episode/length": 187.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 643832, "time": 29615.95974135399, "episode/length": 165.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 644000, "time": 29623.36413383484, "episode/length": 344.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9971014492753624, "episode/intrinsic_return": 0.0}
{"step": 644232, "time": 29632.440566778183, "episode/length": 273.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963503649635036, "episode/intrinsic_return": 0.0}
{"step": 644320, "time": 29637.128836870193, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 644632, "time": 29648.798880815506, "episode/length": 300.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966777408637874, "episode/intrinsic_return": 0.0}
{"step": 645088, "time": 29665.747834444046, "episode/length": 250.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 645160, "time": 29669.539555072784, "episode/length": 65.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 645240, "time": 29673.73411512375, "episode/length": 208.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 645432, "time": 29681.75887322426, "episode/length": 199.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 645632, "time": 29690.08434152603, "episode/length": 48.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 645656, "time": 29692.31879210472, "episode/length": 177.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 645880, "time": 29701.281549215317, "episode/length": 234.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 646056, "time": 29708.625381231308, "episode/length": 216.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 646336, "time": 29719.75808620453, "episode/length": 436.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794050343249427, "episode/intrinsic_return": 0.0}
{"step": 646656, "time": 29731.800669431686, "episode/length": 195.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9948979591836735, "episode/intrinsic_return": 0.0}
{"step": 647256, "time": 29755.100391626358, "episode/length": 199.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 647432, "time": 29763.266491174698, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 647520, "time": 29768.479223251343, "episode/length": 260.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9808429118773946, "episode/intrinsic_return": 0.0}
{"step": 647616, "time": 29773.941014528275, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9771986970684039, "episode/intrinsic_return": 0.0}
{"step": 648408, "time": 29802.33648109436, "episode/length": 218.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9726027397260274, "episode/intrinsic_return": 0.0}
{"step": 648528, "time": 29809.143629789352, "episode/length": 330.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9909365558912386, "episode/intrinsic_return": 0.0}
{"step": 648600, "time": 29812.894886016846, "episode/length": 282.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9964664310954063, "episode/intrinsic_return": 0.0}
{"step": 648600, "time": 29812.903288125992, "episode/length": 167.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 648808, "time": 29822.991070985794, "episode/length": 396.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9949622166246851, "episode/intrinsic_return": 0.0}
{"step": 648880, "time": 29827.024676799774, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 649128, "time": 29836.525019168854, "episode/length": 188.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9629629629629629, "episode/intrinsic_return": 0.0}
{"step": 649872, "time": 29862.96995830536, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 650000, "time": 29888.308259487152, "eval_episode/length": 161.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 650000, "time": 29891.85452747345, "eval_episode/length": 190.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9947643979057592}
{"step": 650000, "time": 29894.175508499146, "eval_episode/length": 194.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9948717948717949}
{"step": 650000, "time": 29894.18445777893, "eval_episode/length": 194.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9794871794871794}
{"step": 650000, "time": 29899.722196102142, "eval_episode/length": 220.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 650000, "time": 29901.73605632782, "eval_episode/length": 223.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9955357142857143}
{"step": 650000, "time": 29904.323753595352, "eval_episode/length": 237.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9705882352941176}
{"step": 650000, "time": 29911.60884976387, "eval_episode/length": 163.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 650144, "time": 29916.370573282242, "episode/length": 201.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 650272, "time": 29922.261092185974, "episode/length": 208.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 650288, "time": 29924.31196951866, "episode/length": 144.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 650376, "time": 29928.46091747284, "episode/length": 356.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.988795518207283, "episode/intrinsic_return": 0.0}
{"step": 650448, "time": 29932.541388750076, "episode/length": 254.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9686274509803922, "episode/intrinsic_return": 0.0}
{"step": 650496, "time": 29935.706478834152, "episode/length": 210.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 651432, "time": 29967.85987186432, "episode/length": 318.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.987460815047022, "episode/intrinsic_return": 0.0}
{"step": 651752, "time": 29980.170210123062, "episode/length": 200.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9751243781094527, "episode/intrinsic_return": 0.0}
{"step": 651832, "time": 29984.268889665604, "episode/length": 194.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 651832, "time": 29984.277975082397, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 651888, "time": 29989.9482922554, "episode/length": 173.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 652104, "time": 29999.04186820984, "episode/length": 206.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 652248, "time": 30005.90173435211, "episode/length": 244.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9836734693877551, "episode/intrinsic_return": 0.0}
{"step": 652576, "time": 30019.449402809143, "episode/length": 337.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 652904, "time": 30032.632812023163, "episode/length": 183.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 653400, "time": 30050.92915558815, "episode/length": 205.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 653424, "time": 30053.60235309601, "episode/length": 198.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 653624, "time": 30061.59339237213, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 653656, "time": 30064.182144641876, "episode/length": 193.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 654512, "time": 30094.519573926926, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 654784, "time": 30105.177862644196, "episode/length": 275.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 654968, "time": 30112.873222589493, "episode/length": 56.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 655080, "time": 30118.789304494858, "episode/length": 36.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 655096, "time": 30121.33669066429, "episode/length": 355.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 655200, "time": 30126.5534427166, "episode/length": 221.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 656184, "time": 30162.309315681458, "episode/length": 315.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9873417721518988, "episode/intrinsic_return": 0.0}
{"step": 656504, "time": 30174.497430562973, "episode/length": 191.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 656600, "time": 30179.27119731903, "episode/length": 189.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.968421052631579, "episode/intrinsic_return": 0.0}
{"step": 656920, "time": 30191.387237548828, "episode/length": 411.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 657248, "time": 30204.065792560577, "episode/length": 480.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.997920997920998, "episode/intrinsic_return": 0.0}
{"step": 657576, "time": 30216.382977247238, "episode/length": 296.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 657616, "time": 30219.530012845993, "episode/length": 722.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9986168741355463, "episode/intrinsic_return": 0.0}
{"step": 657632, "time": 30221.717895030975, "episode/length": 316.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9810725552050473, "episode/intrinsic_return": 0.0}
{"step": 657656, "time": 30223.87471318245, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 657816, "time": 30230.76345539093, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 658016, "time": 30239.090225458145, "episode/length": 49.0, "episode/score": 5.0999999940395355, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 658176, "time": 30246.065462350845, "episode/length": 156.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 658368, "time": 30254.131586313248, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9819004524886877, "episode/intrinsic_return": 0.0}
{"step": 658464, "time": 30258.855563640594, "episode/length": 55.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 658496, "time": 30261.489943265915, "episode/length": 155.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 658736, "time": 30271.0314245224, "episode/length": 137.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9637681159420289, "episode/intrinsic_return": 0.0}
{"step": 659136, "time": 30285.95139527321, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 659296, "time": 30292.786826372147, "episode/length": 204.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 659656, "time": 30306.60171175003, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 660080, "time": 30322.84502673149, "episode/length": 197.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 660081, "time": 30324.923238754272, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.301365694553732, "train/action_min": 0.0, "train/action_std": 3.0952134818481882, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03430722687366626, "train/actor_opt_grad_steps": 40460.0, "train/actor_opt_loss": -9.628669374173494, "train/adv_mag": 0.447233849506584, "train/adv_max": 0.40421589930280505, "train/adv_mean": 0.0017544473402064777, "train/adv_min": -0.3705888076437463, "train/adv_std": 0.05147328605647567, "train/cont_avg": 0.9949555980215827, "train/cont_loss_mean": 0.0002048135809731592, "train/cont_loss_std": 0.006001330031786114, "train/cont_neg_acc": 0.9878865750573522, "train/cont_neg_loss": 0.031916621237879104, "train/cont_pos_acc": 0.9999858325333904, "train/cont_pos_loss": 6.478420606894566e-05, "train/cont_pred": 0.9949750771625436, "train/cont_rate": 0.9949555980215827, "train/dyn_loss_mean": 13.699513723524355, "train/dyn_loss_std": 9.072488922009365, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9394562531718247, "train/extr_critic_critic_opt_grad_steps": 40460.0, "train/extr_critic_critic_opt_loss": 15733.401732520233, "train/extr_critic_mag": 9.036146308020722, "train/extr_critic_max": 9.036146308020722, "train/extr_critic_mean": 2.7872515299337373, "train/extr_critic_min": -0.14739177724440322, "train/extr_critic_std": 2.123174115050611, "train/extr_return_normed_mag": 1.4943008422851562, "train/extr_return_normed_max": 1.4943008422851562, "train/extr_return_normed_mean": 0.38664684685871753, "train/extr_return_normed_min": -0.10895174114609794, "train/extr_return_normed_std": 0.32277300728739594, "train/extr_return_rate": 0.8604602693653792, "train/extr_return_raw_mag": 10.191713127300893, "train/extr_return_raw_max": 10.191713127300893, "train/extr_return_raw_mean": 2.798959416451214, "train/extr_return_raw_min": -0.5078592863228681, "train/extr_return_raw_std": 2.154225749935178, "train/extr_reward_mag": 1.0226619518060478, "train/extr_reward_max": 1.0226619518060478, "train/extr_reward_mean": 0.04072679437214522, "train/extr_reward_min": -0.458326115882654, "train/extr_reward_std": 0.18719836908707516, "train/image_loss_mean": 6.921961012504084, "train/image_loss_std": 12.528491006480705, "train/model_loss_mean": 15.19938103929698, "train/model_loss_std": 16.20172542462246, "train/model_opt_grad_norm": 61.846570282531296, "train/model_opt_grad_steps": 40423.87769784173, "train/model_opt_loss": 17173.209662348247, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1133.0935251798562, "train/policy_entropy_mag": 2.5952632856025972, "train/policy_entropy_max": 2.5952632856025972, "train/policy_entropy_mean": 0.5356546237314348, "train/policy_entropy_min": 0.07937505578608822, "train/policy_entropy_std": 0.6412587032901297, "train/policy_logprob_mag": 7.438383671877196, "train/policy_logprob_max": -0.009455663520547983, "train/policy_logprob_mean": -0.5372713890007074, "train/policy_logprob_min": -7.438383671877196, "train/policy_logprob_std": 1.0955960446124455, "train/policy_randomness_mag": 0.9160140478353707, "train/policy_randomness_max": 0.9160140478353707, "train/policy_randomness_mean": 0.1890625760709639, "train/policy_randomness_min": 0.02801591144512883, "train/policy_randomness_std": 0.22633618202140862, "train/post_ent_mag": 57.33684932242195, "train/post_ent_max": 57.33684932242195, "train/post_ent_mean": 41.370423461035855, "train/post_ent_min": 19.91046898656612, "train/post_ent_std": 7.26392107558765, "train/prior_ent_mag": 66.47617367531755, "train/prior_ent_max": 66.47617367531755, "train/prior_ent_mean": 55.104050505933145, "train/prior_ent_min": 40.018074364970914, "train/prior_ent_std": 4.301680142930944, "train/rep_loss_mean": 13.699513723524355, "train/rep_loss_std": 9.072488922009365, "train/reward_avg": 0.02971349459932112, "train/reward_loss_mean": 0.05750704986853994, "train/reward_loss_std": 0.2584827104918391, "train/reward_max_data": 1.0122302187432488, "train/reward_max_pred": 1.0070153706365352, "train/reward_neg_acc": 0.9928046194769495, "train/reward_neg_loss": 0.029084704528234417, "train/reward_pos_acc": 0.9621192285482832, "train/reward_pos_loss": 0.8608027443611365, "train/reward_pred": 0.028700070670075555, "train/reward_rate": 0.034299123201438846, "train_stats/sum_log_reward": 8.726262824703948, "train_stats/max_log_achievement_collect_coal": 0.3333333333333333, "train_stats/max_log_achievement_collect_drink": 4.555555555555555, "train_stats/max_log_achievement_collect_sapling": 1.4343434343434343, "train_stats/max_log_achievement_collect_stone": 8.818181818181818, "train_stats/max_log_achievement_collect_wood": 11.373737373737374, "train_stats/max_log_achievement_defeat_skeleton": 0.050505050505050504, "train_stats/max_log_achievement_defeat_zombie": 0.7171717171717171, "train_stats/max_log_achievement_eat_cow": 0.1717171717171717, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.707070707070707, "train_stats/max_log_achievement_make_wood_sword": 0.8181818181818182, "train_stats/max_log_achievement_place_furnace": 0.030303030303030304, "train_stats/max_log_achievement_place_plant": 1.3737373737373737, "train_stats/max_log_achievement_place_stone": 7.333333333333333, "train_stats/max_log_achievement_place_table": 2.2323232323232323, "train_stats/max_log_achievement_wake_up": 1.6363636363636365, "train_stats/mean_log_entropy": 0.5451514778113125, "eval_stats/sum_log_reward": 8.78750017285347, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 2.75, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 9.0625, "eval_stats/max_log_achievement_collect_wood": 11.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.5, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 6.75, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00023673640680499375, "report/cont_loss_std": 0.006058291532099247, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.03158314898610115, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 5.198349026613869e-05, "report/cont_pred": 0.9942584037780762, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 15.921812057495117, "report/dyn_loss_std": 9.302441596984863, "report/image_loss_mean": 7.566882133483887, "report/image_loss_std": 15.030319213867188, "report/model_loss_mean": 17.184673309326172, "report/model_loss_std": 18.450151443481445, "report/post_ent_mag": 59.00824737548828, "report/post_ent_max": 59.00824737548828, "report/post_ent_mean": 39.88203048706055, "report/post_ent_min": 19.62411117553711, "report/post_ent_std": 7.6202287673950195, "report/prior_ent_mag": 66.3203353881836, "report/prior_ent_max": 66.3203353881836, "report/prior_ent_mean": 55.94447326660156, "report/prior_ent_min": 41.26361846923828, "report/prior_ent_std": 3.917501449584961, "report/rep_loss_mean": 15.921812057495117, "report/rep_loss_std": 9.302441596984863, "report/reward_avg": 0.03427734225988388, "report/reward_loss_mean": 0.0644674003124237, "report/reward_loss_std": 0.2772989273071289, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0035903453826904, "report/reward_neg_acc": 0.989847719669342, "report/reward_neg_loss": 0.03232072293758392, "report/reward_pos_acc": 0.9487179517745972, "report/reward_pos_loss": 0.8763772249221802, "report/reward_pred": 0.034096553921699524, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 0.0034180497750639915, "eval/cont_loss_std": 0.07767679542303085, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 1.168959897768218e-05, "eval/cont_pos_acc": 0.9980372786521912, "eval/cont_pos_loss": 0.0034347642213106155, "eval/cont_pred": 0.9934799671173096, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.1456241607666, "eval/dyn_loss_std": 10.042655944824219, "eval/image_loss_mean": 7.494510650634766, "eval/image_loss_std": 12.555436134338379, "eval/model_loss_mean": 17.920814514160156, "eval/model_loss_std": 16.601137161254883, "eval/post_ent_mag": 56.0390625, "eval/post_ent_max": 56.0390625, "eval/post_ent_mean": 39.38447952270508, "eval/post_ent_min": 20.964200973510742, "eval/post_ent_std": 7.079477787017822, "eval/prior_ent_mag": 66.3203353881836, "eval/prior_ent_max": 66.3203353881836, "eval/prior_ent_mean": 54.751312255859375, "eval/prior_ent_min": 37.567054748535156, "eval/prior_ent_std": 3.953847646713257, "eval/rep_loss_mean": 17.1456241607666, "eval/rep_loss_std": 10.042655944824219, "eval/reward_avg": 0.04960937425494194, "eval/reward_loss_mean": 0.13551220297813416, "eval/reward_loss_std": 0.7023139595985413, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0030028820037842, "eval/reward_neg_acc": 0.9824562072753906, "eval/reward_neg_loss": 0.05819202959537506, "eval/reward_pos_acc": 0.8909090757369995, "eval/reward_pos_loss": 1.4977530241012573, "eval/reward_pred": 0.04976025968790054, "eval/reward_rate": 0.0537109375, "replay/size": 659577.0, "replay/inserts": 22352.0, "replay/samples": 22352.0, "replay/insert_wait_avg": 1.313787489681476e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.308928899962986e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5296.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1253302911257096e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.046627044677734e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.4962694644928, "timer/env.step_count": 2794.0, "timer/env.step_total": 236.81808853149414, "timer/env.step_frac": 0.23646427425847774, "timer/env.step_avg": 0.08475951629616826, "timer/env.step_min": 0.022638559341430664, "timer/env.step_max": 3.5893356800079346, "timer/replay._sample_count": 22352.0, "timer/replay._sample_total": 11.066833257675171, "timer/replay._sample_frac": 0.011050299032659089, "timer/replay._sample_avg": 0.0004951160190441648, "timer/replay._sample_min": 0.00041294097900390625, "timer/replay._sample_max": 0.01058506965637207, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3456.0, "timer/agent.policy_total": 57.02899527549744, "timer/agent.policy_frac": 0.056943792018308015, "timer/agent.policy_avg": 0.016501445392215694, "timer/agent.policy_min": 0.009023666381835938, "timer/agent.policy_max": 0.1159203052520752, "timer/dataset_train_count": 1397.0, "timer/dataset_train_total": 0.14544916152954102, "timer/dataset_train_frac": 0.00014523185553882664, "timer/dataset_train_avg": 0.00010411536258378025, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.00030159950256347656, "timer/agent.train_count": 1397.0, "timer/agent.train_total": 628.1378118991852, "timer/agent.train_frac": 0.6271993526596509, "timer/agent.train_avg": 0.44963336571165724, "timer/agent.train_min": 0.4330251216888428, "timer/agent.train_max": 1.6607563495635986, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47359538078308105, "timer/agent.report_frac": 0.00047288781318807695, "timer/agent.report_avg": 0.23679769039154053, "timer/agent.report_min": 0.23097443580627441, "timer/agent.report_max": 0.24262094497680664, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.761523534238366e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.31831159887107}
{"step": 660088, "time": 30340.04343509674, "eval_episode/length": 45.0, "eval_episode/score": 4.0999999940395355, "eval_episode/reward_rate": 0.9782608695652174}
{"step": 660088, "time": 30346.94921016693, "eval_episode/length": 173.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9942528735632183}
{"step": 660088, "time": 30350.011347532272, "eval_episode/length": 209.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 660088, "time": 30351.664609909058, "eval_episode/length": 210.0, "eval_episode/score": 5.0999999940395355, "eval_episode/reward_rate": 0.995260663507109}
{"step": 660088, "time": 30353.325736761093, "eval_episode/length": 212.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9765258215962441}
{"step": 660088, "time": 30356.470737457275, "eval_episode/length": 192.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9637305699481865}
{"step": 660088, "time": 30359.406005382538, "eval_episode/length": 254.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.996078431372549}
{"step": 660088, "time": 30361.61905670166, "eval_episode/length": 47.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.8958333333333334}
{"step": 660096, "time": 30362.12527012825, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9754901960784313, "episode/intrinsic_return": 0.0}
{"step": 660144, "time": 30365.590608119965, "episode/length": 60.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 660464, "time": 30377.92249393463, "episode/length": 39.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9, "episode/intrinsic_return": 0.0}
{"step": 660792, "time": 30390.86740398407, "episode/length": 206.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 660976, "time": 30398.839500904083, "episode/length": 279.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 661048, "time": 30402.619824409485, "episode/length": 334.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 661064, "time": 30404.644181251526, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 661272, "time": 30412.990903139114, "episode/length": 431.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 661432, "time": 30419.817576885223, "episode/length": 45.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8913043478260869, "episode/intrinsic_return": 0.0}
{"step": 661456, "time": 30422.419625997543, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 661592, "time": 30428.151297807693, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 661712, "time": 30434.093277215958, "episode/length": 54.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 662336, "time": 30456.384813308716, "episode/length": 233.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 662696, "time": 30469.8187789917, "episode/length": 137.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 662808, "time": 30475.00400209427, "episode/length": 228.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 662960, "time": 30482.462378501892, "episode/length": 238.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 663064, "time": 30488.011353731155, "episode/length": 203.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 663912, "time": 30520.504147291183, "episode/length": 306.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996742671009772, "episode/intrinsic_return": 0.0}
{"step": 664160, "time": 30530.522589206696, "episode/length": 420.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9786223277909739, "episode/intrinsic_return": 0.0}
{"step": 664368, "time": 30539.0062520504, "episode/length": 331.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9849397590361446, "episode/intrinsic_return": 0.0}
{"step": 664440, "time": 30542.730580568314, "episode/length": 184.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 664512, "time": 30546.92484474182, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 665288, "time": 30574.497354745865, "episode/length": 309.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9806451612903225, "episode/intrinsic_return": 0.0}
{"step": 665304, "time": 30577.008362293243, "episode/length": 173.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 665392, "time": 30582.424419641495, "episode/length": 336.0, "episode/score": 6.099999979138374, "episode/reward_rate": 0.9970326409495549, "episode/intrinsic_return": 0.0}
{"step": 665888, "time": 30601.275799512863, "episode/length": 189.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 665904, "time": 30603.368539333344, "episode/length": 217.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 666096, "time": 30611.26548266411, "episode/length": 469.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 666208, "time": 30616.5532476902, "episode/length": 220.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 666264, "time": 30619.836255550385, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 666464, "time": 30628.255528450012, "episode/length": 146.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 666616, "time": 30634.744423627853, "episode/length": 152.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 666656, "time": 30637.9697701931, "episode/length": 168.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9585798816568047, "episode/intrinsic_return": 0.0}
{"step": 667488, "time": 30667.375536203384, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 667544, "time": 30670.64502429962, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 667744, "time": 30679.282930850983, "episode/length": 191.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 667904, "time": 30686.857056856155, "episode/length": 160.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 667960, "time": 30690.038556098938, "episode/length": 186.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 668224, "time": 30700.84949684143, "episode/length": 244.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 669008, "time": 30728.926819562912, "episode/length": 189.0, "episode/score": 6.099999964237213, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 669200, "time": 30737.17280125618, "episode/length": 161.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 669216, "time": 30739.262704849243, "episode/length": 208.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 669264, "time": 30742.572747945786, "episode/length": 419.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 669456, "time": 30750.554094314575, "episode/length": 213.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 669560, "time": 30755.455719947815, "episode/length": 362.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9972451790633609, "episode/intrinsic_return": 0.0}
{"step": 670072, "time": 30793.271022319794, "eval_episode/length": 156.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9681528662420382}
{"step": 670072, "time": 30795.41819190979, "eval_episode/length": 170.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 670072, "time": 30797.898861408234, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.984375}
{"step": 670072, "time": 30799.832745552063, "eval_episode/length": 198.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9798994974874372}
{"step": 670072, "time": 30801.843054056168, "eval_episode/length": 210.0, "eval_episode/score": 8.099999971687794, "eval_episode/reward_rate": 0.995260663507109}
{"step": 670072, "time": 30804.072875976562, "eval_episode/length": 227.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9956140350877193}
{"step": 670072, "time": 30806.193432092667, "eval_episode/length": 242.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9958847736625515}
{"step": 670072, "time": 30807.939583539963, "eval_episode/length": 35.0, "eval_episode/score": 3.0999999940395355, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 670176, "time": 30811.620374441147, "episode/length": 276.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 670368, "time": 30819.530225276947, "episode/length": 169.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 670624, "time": 30829.67439389229, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 670712, "time": 30834.038780927658, "episode/length": 310.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 670784, "time": 30838.16866993904, "episode/length": 197.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 671040, "time": 30848.100647687912, "episode/length": 197.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 671152, "time": 30853.57407617569, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 671432, "time": 30864.183840990067, "episode/length": 276.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 671712, "time": 30875.19765329361, "episode/length": 124.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 671952, "time": 30886.35671901703, "episode/length": 165.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 672120, "time": 30893.31827187538, "episode/length": 166.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9760479041916168, "episode/intrinsic_return": 0.0}
{"step": 672192, "time": 30897.373502492905, "episode/length": 251.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 672912, "time": 30922.9923248291, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 673216, "time": 30934.664644002914, "episode/length": 257.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 673440, "time": 30943.85913157463, "episode/length": 383.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9869791666666666, "episode/intrinsic_return": 0.0}
{"step": 673520, "time": 30948.202986717224, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731800766283525, "episode/intrinsic_return": 0.0}
{"step": 673600, "time": 30952.895646572113, "episode/length": 175.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 674016, "time": 30968.727972984314, "episode/length": 257.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 674280, "time": 30978.811243534088, "episode/length": 320.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 674512, "time": 30988.275688409805, "episode/length": 161.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 674792, "time": 30998.817022800446, "episode/length": 158.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 674848, "time": 31002.63972043991, "episode/length": 175.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 675264, "time": 31018.09816646576, "episode/length": 207.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 675312, "time": 31021.75068807602, "episode/length": 161.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 675504, "time": 31030.41897726059, "episode/length": 81.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9512195121951219, "episode/intrinsic_return": 0.0}
{"step": 675728, "time": 31040.12006688118, "episode/length": 450.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9889135254988913, "episode/intrinsic_return": 0.0}
{"step": 676168, "time": 31056.671671390533, "episode/length": 406.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9926289926289926, "episode/intrinsic_return": 0.0}
{"step": 676176, "time": 31058.76669383049, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 676416, "time": 31068.33943295479, "episode/length": 143.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9583333333333334, "episode/intrinsic_return": 0.0}
{"step": 676528, "time": 31073.64713859558, "episode/length": 280.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 676648, "time": 31078.93124127388, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 677264, "time": 31101.348675489426, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 677296, "time": 31104.034698724747, "episode/length": 195.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 677656, "time": 31117.347100019455, "episode/length": 292.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9863481228668942, "episode/intrinsic_return": 0.0}
{"step": 677912, "time": 31127.54194188118, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 678168, "time": 31137.585312366486, "episode/length": 218.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 678224, "time": 31141.267833709717, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 678464, "time": 31150.861229896545, "episode/length": 226.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9823788546255506, "episode/intrinsic_return": 0.0}
{"step": 678856, "time": 31165.64892888069, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 679032, "time": 31173.488102674484, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 679608, "time": 31194.160280942917, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953379953379954, "episode/intrinsic_return": 0.0}
{"step": 679640, "time": 31196.750997066498, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 680024, "time": 31213.09779381752, "episode/length": 263.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962121212121212, "episode/intrinsic_return": 0.0}
{"step": 680056, "time": 31240.084179878235, "eval_episode/length": 135.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9558823529411765}
{"step": 680056, "time": 31242.892263174057, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 680056, "time": 31245.925929307938, "eval_episode/length": 195.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 680056, "time": 31248.83064699173, "eval_episode/length": 214.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 680056, "time": 31251.255559444427, "eval_episode/length": 222.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 680056, "time": 31253.776515483856, "eval_episode/length": 234.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9744680851063829}
{"step": 680056, "time": 31257.056920051575, "eval_episode/length": 262.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9961977186311787}
{"step": 680056, "time": 31262.1026699543, "eval_episode/length": 62.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9365079365079365}
{"step": 680120, "time": 31264.325087547302, "episode/length": 352.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9971671388101983, "episode/intrinsic_return": 0.0}
{"step": 680464, "time": 31278.46795773506, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 680544, "time": 31282.685537815094, "episode/length": 210.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 681112, "time": 31302.95440387726, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9840425531914894, "episode/intrinsic_return": 0.0}
{"step": 681152, "time": 31306.036556720734, "episode/length": 85.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9418604651162791, "episode/intrinsic_return": 0.0}
{"step": 681240, "time": 31310.43308019638, "episode/length": 383.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 681400, "time": 31317.107783079147, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 681569, "time": 31324.963072776794, "eval_stats/sum_log_reward": 7.891666918992996, "eval_stats/max_log_achievement_collect_coal": 0.3333333333333333, "eval_stats/max_log_achievement_collect_drink": 4.916666666666667, "eval_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "eval_stats/max_log_achievement_collect_stone": 5.75, "eval_stats/max_log_achievement_collect_wood": 9.416666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5833333333333334, "eval_stats/max_log_achievement_eat_cow": 0.08333333333333333, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 0.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.3333333333333333, "eval_stats/max_log_achievement_place_stone": 3.9166666666666665, "eval_stats/max_log_achievement_place_table": 2.1666666666666665, "eval_stats/max_log_achievement_wake_up": 1.0416666666666667, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 9.026315990247225, "train_stats/max_log_achievement_collect_coal": 0.4105263157894737, "train_stats/max_log_achievement_collect_drink": 4.968421052631579, "train_stats/max_log_achievement_collect_sapling": 1.5789473684210527, "train_stats/max_log_achievement_collect_stone": 9.663157894736843, "train_stats/max_log_achievement_collect_wood": 11.347368421052632, "train_stats/max_log_achievement_defeat_skeleton": 0.021052631578947368, "train_stats/max_log_achievement_defeat_zombie": 0.6421052631578947, "train_stats/max_log_achievement_eat_cow": 0.1368421052631579, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.368421052631579, "train_stats/max_log_achievement_make_wood_sword": 1.0421052631578946, "train_stats/max_log_achievement_place_furnace": 0.0, "train_stats/max_log_achievement_place_plant": 1.5157894736842106, "train_stats/max_log_achievement_place_stone": 8.010526315789473, "train_stats/max_log_achievement_place_table": 2.557894736842105, "train_stats/max_log_achievement_wake_up": 1.768421052631579, "train_stats/mean_log_entropy": 0.5545135403934278, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.1734180591724535, "train/action_min": 0.0, "train/action_std": 2.984474883256135, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.0346958772589763, "train/actor_opt_grad_steps": 41830.0, "train/actor_opt_loss": -8.177617303326864, "train/adv_mag": 0.4371119859041991, "train/adv_max": 0.3979780775529367, "train/adv_mean": 0.0022879096654327847, "train/adv_min": -0.3558117280403773, "train/adv_std": 0.05189769508110152, "train/cont_avg": 0.9949146412037037, "train/cont_loss_mean": 0.00014306039813471183, "train/cont_loss_std": 0.004335435023171983, "train/cont_neg_acc": 0.9940035285773101, "train/cont_neg_loss": 0.011298515235911409, "train/cont_pos_acc": 0.9999708935066506, "train/cont_pos_loss": 8.328608142499484e-05, "train/cont_pred": 0.9949008420661644, "train/cont_rate": 0.9949146412037037, "train/dyn_loss_mean": 13.744904447484899, "train/dyn_loss_std": 8.99971211751302, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9647176654250533, "train/extr_critic_critic_opt_grad_steps": 41830.0, "train/extr_critic_critic_opt_loss": 15821.090813078703, "train/extr_critic_mag": 8.859340745431405, "train/extr_critic_max": 8.859340745431405, "train/extr_critic_mean": 2.7087163324709294, "train/extr_critic_min": -0.16106000829626013, "train/extr_critic_std": 2.099786706323977, "train/extr_return_normed_mag": 1.4890258532983285, "train/extr_return_normed_max": 1.4890258532983285, "train/extr_return_normed_mean": 0.38702021528173375, "train/extr_return_normed_min": -0.10785590360562007, "train/extr_return_normed_std": 0.3264240089390013, "train/extr_return_rate": 0.839357199050762, "train/extr_return_raw_mag": 9.908492081253616, "train/extr_return_raw_max": 9.908492081253616, "train/extr_return_raw_mean": 2.7236105627483793, "train/extr_return_raw_min": -0.5030600825945536, "train/extr_return_raw_std": 2.1283706885797007, "train/extr_reward_mag": 1.0305555202342846, "train/extr_reward_max": 1.0305555202342846, "train/extr_reward_mean": 0.04196156179187475, "train/extr_reward_min": -0.44685402004807084, "train/extr_reward_std": 0.19034245599199223, "train/image_loss_mean": 6.991250228881836, "train/image_loss_std": 12.367080554255732, "train/model_loss_mean": 15.29583805931939, "train/model_loss_std": 16.02682627218741, "train/model_opt_grad_norm": 55.57469554477268, "train/model_opt_grad_steps": 41793.0, "train/model_opt_loss": 14127.978450520834, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 925.925925925926, "train/policy_entropy_mag": 2.586537359378956, "train/policy_entropy_max": 2.586537359378956, "train/policy_entropy_mean": 0.5138470945534883, "train/policy_entropy_min": 0.07937504803692853, "train/policy_entropy_std": 0.612237169124462, "train/policy_logprob_mag": 7.438383699346471, "train/policy_logprob_max": -0.009455661068635959, "train/policy_logprob_mean": -0.5146504863544746, "train/policy_logprob_min": -7.438383699346471, "train/policy_logprob_std": 1.0781436937826652, "train/policy_randomness_mag": 0.9129341818668224, "train/policy_randomness_max": 0.9129341818668224, "train/policy_randomness_mean": 0.18136547693499813, "train/policy_randomness_min": 0.028015908654089327, "train/policy_randomness_std": 0.216092852751414, "train/post_ent_mag": 57.383296203613284, "train/post_ent_max": 57.383296203613284, "train/post_ent_mean": 41.48251888133861, "train/post_ent_min": 19.795477280793367, "train/post_ent_std": 7.204251681433783, "train/prior_ent_mag": 66.53139846236617, "train/prior_ent_max": 66.53139846236617, "train/prior_ent_mean": 55.26904813978407, "train/prior_ent_min": 40.16957524617513, "train/prior_ent_std": 4.204285365563852, "train/rep_loss_mean": 13.744904447484899, "train/rep_loss_std": 8.99971211751302, "train/reward_avg": 0.029930555351354457, "train/reward_loss_mean": 0.0575021548403634, "train/reward_loss_std": 0.25212134608515985, "train/reward_max_data": 1.0111111137602065, "train/reward_max_pred": 1.0087673231407448, "train/reward_neg_acc": 0.9925527413686116, "train/reward_neg_loss": 0.029739464495193074, "train/reward_pos_acc": 0.9682008747701292, "train/reward_pos_loss": 0.8459370304037024, "train/reward_pred": 0.02908614602767759, "train/reward_rate": 0.03441116898148148, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 6.36234972262173e-06, "report/cont_loss_std": 0.00010828178346855566, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 4.0218264985014684e-06, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 6.37152743365732e-06, "report/cont_pred": 0.9960875511169434, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 15.078187942504883, "report/dyn_loss_std": 8.868120193481445, "report/image_loss_mean": 7.224681377410889, "report/image_loss_std": 10.62971019744873, "report/model_loss_mean": 16.333786010742188, "report/model_loss_std": 14.328903198242188, "report/post_ent_mag": 56.493927001953125, "report/post_ent_max": 56.493927001953125, "report/post_ent_mean": 40.483436584472656, "report/post_ent_min": 18.370691299438477, "report/post_ent_std": 7.197544574737549, "report/prior_ent_mag": 66.57667541503906, "report/prior_ent_max": 66.57667541503906, "report/prior_ent_mean": 55.84063720703125, "report/prior_ent_min": 41.845130920410156, "report/prior_ent_std": 3.8539535999298096, "report/rep_loss_mean": 15.078187942504883, "report/rep_loss_std": 8.868120193481445, "report/reward_avg": 0.03583984076976776, "report/reward_loss_mean": 0.062185946851968765, "report/reward_loss_std": 0.31523367762565613, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0085639953613281, "report/reward_neg_acc": 0.9898374676704407, "report/reward_neg_loss": 0.026768215000629425, "report/reward_pos_acc": 0.949999988079071, "report/reward_pos_loss": 0.9334621429443359, "report/reward_pred": 0.037339143455028534, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 8.44651094666915e-06, "eval/cont_loss_std": 0.00014687218936160207, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0012869443744421005, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.173214397771517e-06, "eval/cont_pred": 0.9951213598251343, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 18.214588165283203, "eval/dyn_loss_std": 10.347491264343262, "eval/image_loss_mean": 11.457860946655273, "eval/image_loss_std": 18.775651931762695, "eval/model_loss_mean": 22.470794677734375, "eval/model_loss_std": 22.62273406982422, "eval/post_ent_mag": 58.56382751464844, "eval/post_ent_max": 58.56382751464844, "eval/post_ent_mean": 39.83089065551758, "eval/post_ent_min": 20.97332000732422, "eval/post_ent_std": 7.235278606414795, "eval/prior_ent_mag": 66.57667541503906, "eval/prior_ent_max": 66.57667541503906, "eval/prior_ent_mean": 55.54103088378906, "eval/prior_ent_min": 41.081703186035156, "eval/prior_ent_std": 4.104269981384277, "eval/rep_loss_mean": 18.214588165283203, "eval/rep_loss_std": 10.347491264343262, "eval/reward_avg": 0.02783202938735485, "eval/reward_loss_mean": 0.08416995406150818, "eval/reward_loss_std": 0.49041253328323364, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002397060394287, "eval/reward_neg_acc": 0.9868819117546082, "eval/reward_neg_loss": 0.04806377738714218, "eval/reward_pos_acc": 0.9090908765792847, "eval/reward_pos_loss": 1.1684496402740479, "eval/reward_pred": 0.02938208356499672, "eval/reward_rate": 0.0322265625, "replay/size": 681065.0, "replay/inserts": 21488.0, "replay/samples": 21488.0, "replay/insert_wait_avg": 1.3184920230731978e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.437487990662666e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1314840810250146e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.152557373046875e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0278103351593, "timer/env.step_count": 2686.0, "timer/env.step_total": 231.30947947502136, "timer/env.step_frac": 0.23130304685976483, "timer/env.step_avg": 0.08611670866530952, "timer/env.step_min": 0.022159814834594727, "timer/env.step_max": 2.2268385887145996, "timer/replay._sample_count": 21488.0, "timer/replay._sample_total": 10.58468770980835, "timer/replay._sample_frac": 0.010584393354281709, "timer/replay._sample_avg": 0.0004925859879843797, "timer/replay._sample_min": 0.0003306865692138672, "timer/replay._sample_max": 0.010810375213623047, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3517.0, "timer/agent.policy_total": 58.01057720184326, "timer/agent.policy_frac": 0.05800896395311348, "timer/agent.policy_avg": 0.016494335286279006, "timer/agent.policy_min": 0.009125232696533203, "timer/agent.policy_max": 0.11628341674804688, "timer/dataset_train_count": 1343.0, "timer/dataset_train_total": 0.14260125160217285, "timer/dataset_train_frac": 0.00014259728592385851, "timer/dataset_train_avg": 0.0001061811255414541, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.0006313323974609375, "timer/agent.train_count": 1343.0, "timer/agent.train_total": 604.1813552379608, "timer/agent.train_frac": 0.6041645532192444, "timer/agent.train_avg": 0.44987442683392465, "timer/agent.train_min": 0.4337303638458252, "timer/agent.train_max": 1.751755714416504, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4760098457336426, "timer/agent.report_frac": 0.0004759966081084364, "timer/agent.report_avg": 0.2380049228668213, "timer/agent.report_min": 0.22886371612548828, "timer/agent.report_max": 0.2471461296081543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6702138263960408e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 21.487121079584327}
{"step": 681880, "time": 31335.33985519409, "episode/length": 231.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 681904, "time": 31337.954343557358, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 682616, "time": 31363.127786159515, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 683104, "time": 31381.106964588165, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 683184, "time": 31385.215032100677, "episode/length": 253.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 683432, "time": 31394.83866429329, "episode/length": 253.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 683448, "time": 31396.87366104126, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 683664, "time": 31405.745064496994, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 683992, "time": 31418.05729818344, "episode/length": 171.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 684016, "time": 31420.630410194397, "episode/length": 433.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 684208, "time": 31428.50829267502, "episode/length": 94.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9368421052631579, "episode/intrinsic_return": 0.0}
{"step": 684688, "time": 31446.011190652847, "episode/length": 570.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9842381786339754, "episode/intrinsic_return": 0.0}
{"step": 684784, "time": 31450.932564020157, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 685104, "time": 31463.065150737762, "episode/length": 111.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9553571428571429, "episode/intrinsic_return": 0.0}
{"step": 685224, "time": 31468.325275421143, "episode/length": 254.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 685272, "time": 31471.39653611183, "episode/length": 156.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 685336, "time": 31475.05909395218, "episode/length": 237.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 685368, "time": 31477.67340874672, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 685728, "time": 31491.452117204666, "episode/length": 56.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 685760, "time": 31494.100346565247, "episode/length": 48.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 686560, "time": 31522.614048480988, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 686752, "time": 31530.518617153168, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 686928, "time": 31537.956803798676, "episode/length": 279.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 687112, "time": 31545.56388568878, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 687288, "time": 31552.964772224426, "episode/length": 411.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 687440, "time": 31560.44349503517, "episode/length": 331.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9969879518072289, "episode/intrinsic_return": 0.0}
{"step": 687520, "time": 31565.312791109085, "episode/length": 272.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 688536, "time": 31602.909841775894, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 688640, "time": 31608.16157770157, "episode/length": 235.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9788135593220338, "episode/intrinsic_return": 0.0}
{"step": 688880, "time": 31617.867474794388, "episode/length": 198.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 688976, "time": 31622.623148679733, "episode/length": 232.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 689000, "time": 31624.86106824875, "episode/length": 304.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9967213114754099, "episode/intrinsic_return": 0.0}
{"step": 689144, "time": 31631.288164138794, "episode/length": 426.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 689224, "time": 31635.48267173767, "episode/length": 222.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 689384, "time": 31642.39763736725, "episode/length": 47.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 689584, "time": 31650.93117928505, "episode/length": 54.0, "episode/score": 3.0999999716877937, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 689864, "time": 31661.735648155212, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 690040, "time": 31687.999372005463, "eval_episode/length": 157.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 690040, "time": 31690.742389440536, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 690040, "time": 31692.658219337463, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 690040, "time": 31695.388070583344, "eval_episode/length": 215.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9675925925925926}
{"step": 690040, "time": 31697.191998958588, "eval_episode/length": 220.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.995475113122172}
{"step": 690040, "time": 31699.973457574844, "eval_episode/length": 250.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9840637450199203}
{"step": 690040, "time": 31704.033101558685, "eval_episode/length": 130.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9923664122137404}
{"step": 690040, "time": 31705.81779193878, "eval_episode/length": 317.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9968553459119497}
{"step": 690192, "time": 31711.09775710106, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 690240, "time": 31714.22289299965, "episode/length": 339.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 690600, "time": 31727.685282468796, "episode/length": 171.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 691016, "time": 31742.94853568077, "episode/length": 143.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 691480, "time": 31759.89715027809, "episode/length": 154.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 691504, "time": 31762.492025852203, "episode/length": 60.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9180327868852459, "episode/intrinsic_return": 0.0}
{"step": 691752, "time": 31772.061674118042, "episode/length": 346.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9942363112391931, "episode/intrinsic_return": 0.0}
{"step": 691816, "time": 31775.939862966537, "episode/length": 151.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 691952, "time": 31782.24082660675, "episode/length": 426.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9976580796252927, "episode/intrinsic_return": 0.0}
{"step": 692384, "time": 31797.940324544907, "episode/length": 349.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 692856, "time": 31814.946740865707, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 692928, "time": 31819.169132709503, "episode/length": 442.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 692984, "time": 31822.437333345413, "episode/length": 348.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9828080229226361, "episode/intrinsic_return": 0.0}
{"step": 693000, "time": 31824.490957260132, "episode/length": 186.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 693328, "time": 31837.249859571457, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 693488, "time": 31844.185549497604, "episode/length": 60.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 693544, "time": 31847.39135479927, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 693952, "time": 31862.72504043579, "episode/length": 249.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 694528, "time": 31883.554181814194, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 694672, "time": 31889.938408136368, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 694760, "time": 31894.202818632126, "episode/length": 296.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9730639730639731, "episode/intrinsic_return": 0.0}
{"step": 694928, "time": 31901.6700091362, "episode/length": 249.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.984, "episode/intrinsic_return": 0.0}
{"step": 695016, "time": 31905.939365386963, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 695248, "time": 31915.572049617767, "episode/length": 161.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 695272, "time": 31917.714141130447, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 695352, "time": 31921.828142642975, "episode/length": 52.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 696208, "time": 31952.256843328476, "episode/length": 191.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9635416666666666, "episode/intrinsic_return": 0.0}
{"step": 696256, "time": 31955.437136888504, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 696280, "time": 31957.53433585167, "episode/length": 218.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 696592, "time": 31971.402476787567, "episode/length": 167.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 696816, "time": 31980.5582716465, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 696992, "time": 31988.552100419998, "episode/length": 437.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 697464, "time": 32006.276245832443, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 697624, "time": 32013.517849445343, "episode/length": 176.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 698592, "time": 32048.79868412018, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 698632, "time": 32052.09321117401, "episode/length": 419.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 698640, "time": 32054.6854159832, "episode/length": 452.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9977924944812362, "episode/intrinsic_return": 0.0}
{"step": 698808, "time": 32061.901527643204, "episode/length": 276.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9963898916967509, "episode/intrinsic_return": 0.0}
{"step": 698896, "time": 32066.60185790062, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 699104, "time": 32075.02406477928, "episode/length": 352.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858356940509915, "episode/intrinsic_return": 0.0}
{"step": 699480, "time": 32088.786860466003, "episode/length": 332.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.996996996996997, "episode/intrinsic_return": 0.0}
{"step": 699920, "time": 32105.56559920311, "episode/length": 159.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 699984, "time": 32109.181622505188, "episode/length": 168.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9704142011834319, "episode/intrinsic_return": 0.0}
{"step": 700024, "time": 32131.46733903885, "eval_episode/length": 151.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9671052631578947}
{"step": 700024, "time": 32134.37331676483, "eval_episode/length": 184.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9945945945945946}
{"step": 700024, "time": 32137.762837409973, "eval_episode/length": 228.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.982532751091703}
{"step": 700024, "time": 32140.710126638412, "eval_episode/length": 259.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9961538461538462}
{"step": 700024, "time": 32143.373977661133, "eval_episode/length": 289.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 700024, "time": 32145.75208926201, "eval_episode/length": 309.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9870967741935484}
{"step": 700024, "time": 32147.693132400513, "eval_episode/length": 57.0, "eval_episode/score": 3.1000000089406967, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 700024, "time": 32150.092830896378, "eval_episode/length": 185.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9731182795698925}
{"step": 700176, "time": 32155.380078077316, "episode/length": 159.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 700616, "time": 32171.839040517807, "episode/length": 188.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 700760, "time": 32178.4571557045, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 701024, "time": 32189.374541044235, "episode/length": 424.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788235294117648, "episode/intrinsic_return": 0.0}
{"step": 701200, "time": 32197.133699417114, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 701304, "time": 32202.12606072426, "episode/length": 227.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 701688, "time": 32216.420829057693, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 702064, "time": 32230.74636030197, "episode/length": 180.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 702144, "time": 32234.959765434265, "episode/length": 245.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 702384, "time": 32244.400304317474, "episode/length": 446.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9865771812080537, "episode/intrinsic_return": 0.0}
{"step": 702736, "time": 32258.08345389366, "episode/length": 213.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 702776, "time": 32260.82878303528, "episode/length": 251.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996031746031746, "episode/intrinsic_return": 0.0}
{"step": 703536, "time": 32287.783823013306, "episode/length": 291.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 703696, "time": 32294.77544403076, "episode/length": 298.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.9966555183946488, "episode/intrinsic_return": 0.0}
{"step": 703824, "time": 32300.567123651505, "episode/length": 266.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 703896, "time": 32304.399876356125, "episode/length": 218.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 703920, "time": 32307.06515431404, "episode/length": 231.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 704048, "time": 32312.891345739365, "episode/length": 207.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 704152, "time": 32317.65730690956, "episode/length": 176.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 704297, "time": 32324.994881391525, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.305416483274648, "train/action_min": 0.0, "train/action_std": 3.174338140957792, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03454504333908709, "train/actor_opt_grad_steps": 43215.0, "train/actor_opt_loss": -6.301870970973666, "train/adv_mag": 0.46459698530150134, "train/adv_max": 0.3947324049724659, "train/adv_mean": 0.0024819351930991103, "train/adv_min": -0.38177702523453133, "train/adv_std": 0.05173960553718285, "train/cont_avg": 0.9951859595070423, "train/cont_loss_mean": 0.0001607591581001114, "train/cont_loss_std": 0.004780798854666577, "train/cont_neg_acc": 0.9944947471081371, "train/cont_neg_loss": 0.014041583712100937, "train/cont_pos_acc": 0.9999792701761487, "train/cont_pos_loss": 7.100490100998074e-05, "train/cont_pred": 0.9951888490730608, "train/cont_rate": 0.9951859595070423, "train/dyn_loss_mean": 13.818338400881055, "train/dyn_loss_std": 9.088445287355235, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9322677905290899, "train/extr_critic_critic_opt_grad_steps": 43215.0, "train/extr_critic_critic_opt_loss": 15826.571564150529, "train/extr_critic_mag": 8.876183650863002, "train/extr_critic_max": 8.876183650863002, "train/extr_critic_mean": 2.689963977941325, "train/extr_critic_min": -0.168067239539724, "train/extr_critic_std": 2.1052975260036093, "train/extr_return_normed_mag": 1.4931677814940332, "train/extr_return_normed_max": 1.4931677814940332, "train/extr_return_normed_mean": 0.3886493658515769, "train/extr_return_normed_min": -0.09954314823196807, "train/extr_return_normed_std": 0.324791974689759, "train/extr_return_rate": 0.8208645544421505, "train/extr_return_raw_mag": 9.970041939910029, "train/extr_return_raw_max": 9.970041939910029, "train/extr_return_raw_mean": 2.7062766325305887, "train/extr_return_raw_min": -0.5042546301765342, "train/extr_return_raw_std": 2.136203906065981, "train/extr_reward_mag": 1.0347812662661915, "train/extr_reward_max": 1.0347812662661915, "train/extr_reward_mean": 0.04236924085556201, "train/extr_reward_min": -0.4220679293216114, "train/extr_reward_std": 0.19129099497492885, "train/image_loss_mean": 6.875762059654988, "train/image_loss_std": 12.147682388063888, "train/model_loss_mean": 15.224086439105827, "train/model_loss_std": 15.839159858058876, "train/model_opt_grad_norm": 63.13837753886908, "train/model_opt_grad_steps": 43177.31690140845, "train/model_opt_loss": 20323.32313902949, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1338.0281690140846, "train/policy_entropy_mag": 2.594982855756518, "train/policy_entropy_max": 2.594982855756518, "train/policy_entropy_mean": 0.5273863373088165, "train/policy_entropy_min": 0.07937503810709631, "train/policy_entropy_std": 0.6259788904391544, "train/policy_logprob_mag": 7.438383636340289, "train/policy_logprob_max": -0.009455659229990462, "train/policy_logprob_mean": -0.5268218095453692, "train/policy_logprob_min": -7.438383636340289, "train/policy_logprob_std": 1.0864402664379336, "train/policy_randomness_mag": 0.9159150719642639, "train/policy_randomness_max": 0.9159150719642639, "train/policy_randomness_mean": 0.18614423358944102, "train/policy_randomness_min": 0.028015905099225715, "train/policy_randomness_std": 0.22094307787401576, "train/post_ent_mag": 57.30477902587031, "train/post_ent_max": 57.30477902587031, "train/post_ent_mean": 41.333025865151846, "train/post_ent_min": 19.715945593068298, "train/post_ent_std": 7.302358741491613, "train/prior_ent_mag": 66.62973806891642, "train/prior_ent_max": 66.62973806891642, "train/prior_ent_mean": 55.21416395482883, "train/prior_ent_min": 40.552166065699616, "train/prior_ent_std": 4.163339272351332, "train/rep_loss_mean": 13.818338400881055, "train/rep_loss_std": 9.088445287355235, "train/reward_avg": 0.03010838428958201, "train/reward_loss_mean": 0.0571606291956465, "train/reward_loss_std": 0.2561177277648953, "train/reward_max_data": 1.0218309911204055, "train/reward_max_pred": 1.0123212152803447, "train/reward_neg_acc": 0.9925046030064704, "train/reward_neg_loss": 0.029174053733250205, "train/reward_pos_acc": 0.9688424845816384, "train/reward_pos_loss": 0.8471866829294554, "train/reward_pred": 0.02940778534623309, "train/reward_rate": 0.03444102112676056, "train_stats/sum_log_reward": 8.534343648438503, "train_stats/max_log_achievement_collect_coal": 0.21212121212121213, "train_stats/max_log_achievement_collect_drink": 5.232323232323233, "train_stats/max_log_achievement_collect_sapling": 1.6363636363636365, "train_stats/max_log_achievement_collect_stone": 9.343434343434344, "train_stats/max_log_achievement_collect_wood": 10.8989898989899, "train_stats/max_log_achievement_defeat_skeleton": 0.06060606060606061, "train_stats/max_log_achievement_defeat_zombie": 0.6565656565656566, "train_stats/max_log_achievement_eat_cow": 0.1414141414141414, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1515151515151516, "train_stats/max_log_achievement_make_wood_sword": 1.02020202020202, "train_stats/max_log_achievement_place_furnace": 0.050505050505050504, "train_stats/max_log_achievement_place_plant": 1.5555555555555556, "train_stats/max_log_achievement_place_stone": 7.646464646464646, "train_stats/max_log_achievement_place_table": 2.3737373737373737, "train_stats/max_log_achievement_wake_up": 1.696969696969697, "train_stats/mean_log_entropy": 0.5552554017666614, "eval_stats/sum_log_reward": 8.850000113248825, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.5, "eval_stats/max_log_achievement_collect_sapling": 1.875, "eval_stats/max_log_achievement_collect_stone": 11.75, "eval_stats/max_log_achievement_collect_wood": 10.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.3125, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 8.9375, "eval_stats/max_log_achievement_place_table": 2.3125, "eval_stats/max_log_achievement_wake_up": 1.125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.891475676529808e-06, "report/cont_loss_std": 2.7848569516208954e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0004019910120405257, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 3.224578790650412e-07, "report/cont_pred": 0.9960950613021851, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 14.63376235961914, "report/dyn_loss_std": 8.816173553466797, "report/image_loss_mean": 7.367589950561523, "report/image_loss_std": 12.556438446044922, "report/model_loss_mean": 16.18994903564453, "report/model_loss_std": 16.201984405517578, "report/post_ent_mag": 58.475975036621094, "report/post_ent_max": 58.475975036621094, "report/post_ent_mean": 41.15541076660156, "report/post_ent_min": 21.732898712158203, "report/post_ent_std": 7.388905048370361, "report/prior_ent_mag": 66.79208374023438, "report/prior_ent_max": 66.79208374023438, "report/prior_ent_mean": 55.82619094848633, "report/prior_ent_min": 44.21619415283203, "report/prior_ent_std": 3.6259782314300537, "report/rep_loss_mean": 14.63376235961914, "report/rep_loss_std": 8.816173553466797, "report/reward_avg": 0.02851562574505806, "report/reward_loss_mean": 0.042098745703697205, "report/reward_loss_std": 0.19250597059726715, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011396408081055, "report/reward_neg_acc": 0.9949545860290527, "report/reward_neg_loss": 0.016764363273978233, "report/reward_pos_acc": 0.9696969389915466, "report/reward_pos_loss": 0.8028978109359741, "report/reward_pred": 0.027794457972049713, "report/reward_rate": 0.0322265625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 0.0001849250984378159, "eval/cont_loss_std": 0.004490102641284466, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.06300543993711472, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.3983542380155995e-07, "eval/cont_pred": 0.9972449541091919, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 18.174816131591797, "eval/dyn_loss_std": 10.098114013671875, "eval/image_loss_mean": 14.069280624389648, "eval/image_loss_std": 21.08774185180664, "eval/model_loss_mean": 25.078088760375977, "eval/model_loss_std": 24.737028121948242, "eval/post_ent_mag": 56.107421875, "eval/post_ent_max": 56.107421875, "eval/post_ent_mean": 39.32855224609375, "eval/post_ent_min": 19.84880256652832, "eval/post_ent_std": 6.994241237640381, "eval/prior_ent_mag": 66.79208374023438, "eval/prior_ent_max": 66.79208374023438, "eval/prior_ent_mean": 55.512237548828125, "eval/prior_ent_min": 41.24469757080078, "eval/prior_ent_std": 4.1784138679504395, "eval/rep_loss_mean": 18.174816131591797, "eval/rep_loss_std": 10.098114013671875, "eval/reward_avg": 0.03603515774011612, "eval/reward_loss_mean": 0.10373405367136002, "eval/reward_loss_std": 0.7055472731590271, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006539821624756, "eval/reward_neg_acc": 0.9939025044441223, "eval/reward_neg_loss": 0.020937753841280937, "eval/reward_pos_acc": 0.800000011920929, "eval/reward_pos_loss": 2.1405229568481445, "eval/reward_pred": 0.026777716353535652, "eval/reward_rate": 0.0390625, "replay/size": 703793.0, "replay/inserts": 22728.0, "replay/samples": 22736.0, "replay/insert_wait_avg": 1.3070956622576554e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.381160690447213e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5248.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0906468804289654e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0125768184662, "timer/env.step_count": 2841.0, "timer/env.step_total": 236.5683970451355, "timer/env.step_frac": 0.23656542180477008, "timer/env.step_avg": 0.08326941113873125, "timer/env.step_min": 0.022421836853027344, "timer/env.step_max": 2.182260036468506, "timer/replay._sample_count": 22736.0, "timer/replay._sample_total": 11.20239543914795, "timer/replay._sample_frac": 0.011202254550426057, "timer/replay._sample_avg": 0.0004927161963031294, "timer/replay._sample_min": 0.0004150867462158203, "timer/replay._sample_max": 0.007618904113769531, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3497.0, "timer/agent.policy_total": 55.53304076194763, "timer/agent.policy_frac": 0.055532342341758995, "timer/agent.policy_avg": 0.015880194670273844, "timer/agent.policy_min": 0.008895397186279297, "timer/agent.policy_max": 0.10056614875793457, "timer/dataset_train_count": 1421.0, "timer/dataset_train_total": 0.14913582801818848, "timer/dataset_train_frac": 0.00014913395238754215, "timer/dataset_train_avg": 0.00010495132161730365, "timer/dataset_train_min": 9.226799011230469e-05, "timer/dataset_train_max": 0.00032448768615722656, "timer/agent.train_count": 1421.0, "timer/agent.train_total": 638.0148549079895, "timer/agent.train_frac": 0.6380068308118982, "timer/agent.train_avg": 0.44899004567768436, "timer/agent.train_min": 0.43517589569091797, "timer/agent.train_max": 1.6080963611602783, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4772517681121826, "timer/agent.report_frac": 0.0004772457658788214, "timer/agent.report_avg": 0.2386258840560913, "timer/agent.report_min": 0.23389244079589844, "timer/agent.report_max": 0.24335932731628418, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 3.218650817871094e-05, "timer/dataset_eval_frac": 3.21861033799316e-08, "timer/dataset_eval_avg": 3.218650817871094e-05, "timer/dataset_eval_min": 3.218650817871094e-05, "timer/dataset_eval_max": 3.218650817871094e-05, "fps": 22.727383793333775}
{"step": 704600, "time": 32336.917137145996, "episode/length": 227.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 705136, "time": 32356.619455099106, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 705200, "time": 32360.381244421005, "episode/length": 187.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 705320, "time": 32365.637278318405, "episode/length": 174.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 705400, "time": 32369.7616648674, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 706096, "time": 32396.127709388733, "episode/length": 319.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 706128, "time": 32398.727392196655, "episode/length": 246.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 706632, "time": 32416.961649656296, "episode/length": 253.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9763779527559056, "episode/intrinsic_return": 0.0}
{"step": 706760, "time": 32422.7427175045, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 706816, "time": 32426.32145547867, "episode/length": 186.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 707080, "time": 32436.433385372162, "episode/length": 234.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 707192, "time": 32441.783203125, "episode/length": 223.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 707480, "time": 32453.082884311676, "episode/length": 168.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9881656804733728, "episode/intrinsic_return": 0.0}
{"step": 707816, "time": 32465.74677014351, "episode/length": 214.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 708176, "time": 32479.583755016327, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 708200, "time": 32481.779093265533, "episode/length": 179.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 708704, "time": 32500.426606178284, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 708984, "time": 32511.087656736374, "episode/length": 223.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 709280, "time": 32522.764719724655, "episode/length": 274.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 709328, "time": 32525.855410814285, "episode/length": 230.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 709688, "time": 32539.18465566635, "episode/length": 233.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 709904, "time": 32548.169851779938, "episode/length": 215.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 709984, "time": 32552.304181814194, "episode/length": 222.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 710008, "time": 32576.325667858124, "eval_episode/length": 170.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 710008, "time": 32578.868088006973, "eval_episode/length": 192.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 710008, "time": 32580.51992702484, "eval_episode/length": 195.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9795918367346939}
{"step": 710008, "time": 32582.78905725479, "eval_episode/length": 211.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9764150943396226}
{"step": 710008, "time": 32584.739785194397, "eval_episode/length": 218.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 710008, "time": 32587.48169851303, "eval_episode/length": 247.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9717741935483871}
{"step": 710008, "time": 32590.537673950195, "eval_episode/length": 279.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9785714285714285}
{"step": 710008, "time": 32595.318088054657, "eval_episode/length": 189.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9947368421052631}
{"step": 710376, "time": 32607.564294338226, "episode/length": 173.0, "episode/score": 8.099999964237213, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 710384, "time": 32609.693944454193, "episode/length": 209.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9857142857142858, "episode/intrinsic_return": 0.0}
{"step": 711120, "time": 32636.322020053864, "episode/length": 151.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.993421052631579, "episode/intrinsic_return": 0.0}
{"step": 711192, "time": 32640.545211076736, "episode/length": 150.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 711296, "time": 32646.302005767822, "episode/length": 905.0, "episode/score": 13.100000023841858, "episode/reward_rate": 0.9922737306843267, "episode/intrinsic_return": 0.0}
{"step": 711296, "time": 32646.312494516373, "episode/length": 200.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 711712, "time": 32664.476088762283, "episode/length": 51.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 712544, "time": 32695.38282227516, "episode/length": 401.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 712656, "time": 32700.619898557663, "episode/length": 284.0, "episode/score": 10.100000038743019, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 712768, "time": 32707.497916698456, "episode/length": 435.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 712832, "time": 32711.17899441719, "episode/length": 213.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 712864, "time": 32713.832079172134, "episode/length": 143.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 713072, "time": 32722.33197426796, "episode/length": 221.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 713600, "time": 32741.503934144974, "episode/length": 401.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9925373134328358, "episode/intrinsic_return": 0.0}
{"step": 713888, "time": 32752.62219142914, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 714000, "time": 32757.77974295616, "episode/length": 350.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9886039886039886, "episode/intrinsic_return": 0.0}
{"step": 714600, "time": 32779.21631574631, "episode/length": 228.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 714856, "time": 32789.41482424736, "episode/length": 248.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 715176, "time": 32801.618790864944, "episode/length": 196.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9644670050761421, "episode/intrinsic_return": 0.0}
{"step": 715312, "time": 32808.01926064491, "episode/length": 163.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 715320, "time": 32809.6338365078, "episode/length": 57.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 715752, "time": 32825.453902721405, "episode/length": 53.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 715808, "time": 32829.16487669945, "episode/length": 239.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 715824, "time": 32831.94425344467, "episode/length": 395.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 716200, "time": 32845.74807047844, "episode/length": 390.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9923273657289002, "episode/intrinsic_return": 0.0}
{"step": 716336, "time": 32852.029328107834, "episode/length": 216.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 716440, "time": 32856.83682537079, "episode/length": 450.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9977827050997783, "episode/intrinsic_return": 0.0}
{"step": 716608, "time": 32864.3177523613, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 716856, "time": 32874.52749919891, "episode/length": 192.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 717016, "time": 32881.2881770134, "episode/length": 150.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 717328, "time": 32893.51768755913, "episode/length": 196.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 717592, "time": 32903.6109457016, "episode/length": 220.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 717776, "time": 32911.71844410896, "episode/length": 179.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 717824, "time": 32915.258471250534, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 717896, "time": 32919.420588970184, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 718144, "time": 32929.96175456047, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 718184, "time": 32932.64455199242, "episode/length": 35.0, "episode/score": 2.099999986588955, "episode/reward_rate": 0.8611111111111112, "episode/intrinsic_return": 0.0}
{"step": 718632, "time": 32949.02024650574, "episode/length": 201.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 718664, "time": 32951.83167600632, "episode/length": 225.0, "episode/score": 7.1000000312924385, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 719048, "time": 32966.1650056839, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 719312, "time": 32976.68391370773, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 719368, "time": 32979.93908715248, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 719912, "time": 33000.13179206848, "episode/length": 159.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 719936, "time": 33003.14164829254, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 720096, "time": 33030.06856298447, "eval_episode/length": 162.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9938650306748467}
{"step": 720096, "time": 33031.86409783363, "eval_episode/length": 167.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 720096, "time": 33034.02132868767, "eval_episode/length": 181.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.978021978021978}
{"step": 720096, "time": 33036.79348897934, "eval_episode/length": 210.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.976303317535545}
{"step": 720096, "time": 33038.49753212929, "eval_episode/length": 214.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 720096, "time": 33043.49709057808, "eval_episode/length": 297.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9966442953020134}
{"step": 720096, "time": 33050.098423719406, "eval_episode/length": 211.0, "eval_episode/score": 11.1000000461936, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 720096, "time": 33052.64556646347, "eval_episode/length": 444.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9797752808988764}
{"step": 720168, "time": 33054.85100054741, "episode/length": 252.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 720576, "time": 33070.150388002396, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 720608, "time": 33072.88849782944, "episode/length": 161.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 721208, "time": 33095.52052330971, "episode/length": 428.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 721264, "time": 33099.21269989014, "episode/length": 384.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9922077922077922, "episode/intrinsic_return": 0.0}
{"step": 721336, "time": 33103.09404230118, "episode/length": 174.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 721456, "time": 33108.814708948135, "episode/length": 260.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 721520, "time": 33112.46250009537, "episode/length": 168.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 721640, "time": 33117.769325494766, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 721728, "time": 33122.45645689964, "episode/length": 139.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 722864, "time": 33162.09245824814, "episode/length": 141.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9507042253521126, "episode/intrinsic_return": 0.0}
{"step": 722984, "time": 33167.46958446503, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 723064, "time": 33171.72067284584, "episode/length": 177.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 723088, "time": 33174.26633024216, "episode/length": 313.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9745222929936306, "episode/intrinsic_return": 0.0}
{"step": 723136, "time": 33177.48120355606, "episode/length": 233.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9829059829059829, "episode/intrinsic_return": 0.0}
{"step": 723240, "time": 33182.2179684639, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 724024, "time": 33210.17554831505, "episode/length": 335.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910714285714286, "episode/intrinsic_return": 0.0}
{"step": 724088, "time": 33213.869896650314, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 724368, "time": 33225.06767868996, "episode/length": 159.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 724696, "time": 33237.30777049065, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 724760, "time": 33241.017362356186, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 724784, "time": 33243.60056710243, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 724800, "time": 33245.65505337715, "episode/length": 448.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9799554565701559, "episode/intrinsic_return": 0.0}
{"step": 725168, "time": 33259.44332265854, "episode/length": 134.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 725176, "time": 33261.1410779953, "episode/length": 241.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 725760, "time": 33282.47981548309, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 726016, "time": 33292.51393675804, "episode/length": 153.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.974025974025974, "episode/intrinsic_return": 0.0}
{"step": 726048, "time": 33295.12895154953, "episode/length": 168.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9822485207100592, "episode/intrinsic_return": 0.0}
{"step": 726280, "time": 33304.25597310066, "episode/length": 184.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 726640, "time": 33318.13717389107, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753521126760564, "episode/intrinsic_return": 0.0}
{"step": 726776, "time": 33323.989303827286, "episode/length": 200.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9800995024875622, "episode/intrinsic_return": 0.0}
{"step": 726777, "time": 33326.577788591385, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.519298880440848, "train/action_min": 0.0, "train/action_std": 3.2161474806921824, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03414663793519139, "train/actor_opt_grad_steps": 44625.0, "train/actor_opt_loss": -3.7011481388338976, "train/adv_mag": 0.4581932742680822, "train/adv_max": 0.4031126514077187, "train/adv_mean": 0.003514079341039178, "train/adv_min": -0.3780392810702324, "train/adv_std": 0.051441389162625584, "train/cont_avg": 0.994873046875, "train/cont_loss_mean": 0.0001303147334957495, "train/cont_loss_std": 0.0036060797089914687, "train/cont_neg_acc": 0.9947756091467768, "train/cont_neg_loss": 0.012957296023526285, "train/cont_pos_acc": 0.9999929807015828, "train/cont_pos_loss": 5.7517819051865005e-05, "train/cont_pred": 0.9948809559856142, "train/cont_rate": 0.994873046875, "train/dyn_loss_mean": 13.560428776059831, "train/dyn_loss_std": 9.07945819582258, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9611609420606069, "train/extr_critic_critic_opt_grad_steps": 44625.0, "train/extr_critic_critic_opt_loss": 15870.204966517857, "train/extr_critic_mag": 9.18642567907061, "train/extr_critic_max": 9.18642567907061, "train/extr_critic_mean": 2.812116261039461, "train/extr_critic_min": -0.1648921881403242, "train/extr_critic_std": 2.2410353200776236, "train/extr_return_normed_mag": 1.4791732038770402, "train/extr_return_normed_max": 1.4791732038770402, "train/extr_return_normed_mean": 0.3916764000696795, "train/extr_return_normed_min": -0.09540353808552027, "train/extr_return_normed_std": 0.33143513617771014, "train/extr_return_rate": 0.8182445585727691, "train/extr_return_raw_mag": 10.292225851331438, "train/extr_return_raw_max": 10.292225851331438, "train/extr_return_raw_mean": 2.8361872681549616, "train/extr_return_raw_min": -0.5049862689737763, "train/extr_return_raw_std": 2.273532483407429, "train/extr_reward_mag": 1.0292830075536454, "train/extr_reward_max": 1.0292830075536454, "train/extr_reward_mean": 0.04456108591652342, "train/extr_reward_min": -0.4200691819190979, "train/extr_reward_std": 0.19626649085964476, "train/image_loss_mean": 6.678024472509112, "train/image_loss_std": 11.866590332984924, "train/model_loss_mean": 14.871034526824952, "train/model_loss_std": 15.51618993622916, "train/model_opt_grad_norm": 55.47424549375262, "train/model_opt_grad_steps": 44585.91428571429, "train/model_opt_loss": 21035.084033203126, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1419.642857142857, "train/policy_entropy_mag": 2.577802176134927, "train/policy_entropy_max": 2.577802176134927, "train/policy_entropy_mean": 0.5099368734019143, "train/policy_entropy_min": 0.07937505117484502, "train/policy_entropy_std": 0.5979527745928083, "train/policy_logprob_mag": 7.438383681433542, "train/policy_logprob_max": -0.009455664322844573, "train/policy_logprob_mean": -0.5100623596991811, "train/policy_logprob_min": -7.438383681433542, "train/policy_logprob_std": 1.0743545097964151, "train/policy_randomness_mag": 0.9098510435649327, "train/policy_randomness_max": 0.9098510435649327, "train/policy_randomness_mean": 0.1799853388752256, "train/policy_randomness_min": 0.028015909689877716, "train/policy_randomness_std": 0.2110510900616646, "train/post_ent_mag": 58.006881087166924, "train/post_ent_max": 58.006881087166924, "train/post_ent_mean": 41.704265403747556, "train/post_ent_min": 19.676070267813547, "train/post_ent_std": 7.415235539845058, "train/prior_ent_mag": 66.5608748299735, "train/prior_ent_max": 66.5608748299735, "train/prior_ent_mean": 55.338609313964845, "train/prior_ent_min": 40.936582701546804, "train/prior_ent_std": 4.194673441137586, "train/rep_loss_mean": 13.560428776059831, "train/rep_loss_std": 9.07945819582258, "train/reward_avg": 0.03091378322403346, "train/reward_loss_mean": 0.05662252128656421, "train/reward_loss_std": 0.24771963421787535, "train/reward_max_data": 1.0150000035762787, "train/reward_max_pred": 1.0101156209196362, "train/reward_neg_acc": 0.9929998925754002, "train/reward_neg_loss": 0.028678034778152194, "train/reward_pos_acc": 0.975522552217756, "train/reward_pos_loss": 0.8227157073361533, "train/reward_pred": 0.03020925247775657, "train/reward_rate": 0.035421316964285715, "train_stats/sum_log_reward": 9.038775735971878, "train_stats/max_log_achievement_collect_coal": 0.3979591836734694, "train_stats/max_log_achievement_collect_drink": 5.73469387755102, "train_stats/max_log_achievement_collect_sapling": 1.6326530612244898, "train_stats/max_log_achievement_collect_stone": 10.051020408163266, "train_stats/max_log_achievement_collect_wood": 10.285714285714286, "train_stats/max_log_achievement_defeat_skeleton": 0.07142857142857142, "train_stats/max_log_achievement_defeat_zombie": 0.7142857142857143, "train_stats/max_log_achievement_eat_cow": 0.1836734693877551, "train_stats/max_log_achievement_eat_plant": 0.01020408163265306, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.01020408163265306, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0918367346938775, "train_stats/max_log_achievement_make_wood_sword": 1.2346938775510203, "train_stats/max_log_achievement_place_furnace": 0.05102040816326531, "train_stats/max_log_achievement_place_plant": 1.5510204081632653, "train_stats/max_log_achievement_place_stone": 8.13265306122449, "train_stats/max_log_achievement_place_table": 2.5510204081632653, "train_stats/max_log_achievement_wake_up": 1.4489795918367347, "train_stats/mean_log_entropy": 0.5112690785709693, "eval_stats/sum_log_reward": 9.66250029206276, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 5.0, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 12.25, "eval_stats/max_log_achievement_collect_wood": 10.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.625, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 8.4375, "eval_stats/max_log_achievement_place_table": 2.375, "eval_stats/max_log_achievement_wake_up": 1.375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.00015478191198781133, "report/cont_loss_std": 0.0029898143839091063, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.005499555729329586, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.0001232803042512387, "report/cont_pred": 0.9940539598464966, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.709897994995117, "report/dyn_loss_std": 8.812418937683105, "report/image_loss_mean": 5.739706993103027, "report/image_loss_std": 10.964446067810059, "report/model_loss_mean": 13.428934097290039, "report/model_loss_std": 14.723413467407227, "report/post_ent_mag": 57.563262939453125, "report/post_ent_max": 57.563262939453125, "report/post_ent_mean": 42.198699951171875, "report/post_ent_min": 17.546302795410156, "report/post_ent_std": 7.266106128692627, "report/prior_ent_mag": 66.26437377929688, "report/prior_ent_max": 66.26437377929688, "report/prior_ent_mean": 55.152557373046875, "report/prior_ent_min": 34.6023063659668, "report/prior_ent_std": 4.753260612487793, "report/rep_loss_mean": 12.709897994995117, "report/rep_loss_std": 8.812418937683105, "report/reward_avg": 0.02958984300494194, "report/reward_loss_mean": 0.06313273310661316, "report/reward_loss_std": 0.28393518924713135, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0056655406951904, "report/reward_neg_acc": 0.9979757070541382, "report/reward_neg_loss": 0.029671261087059975, "report/reward_pos_acc": 0.944444477558136, "report/reward_pos_loss": 0.9814642071723938, "report/reward_pred": 0.02665085718035698, "report/reward_rate": 0.03515625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 1.5327998426073464e-06, "eval/cont_loss_std": 1.8784732674248517e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.00023326269001699984, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.240551329028676e-07, "eval/cont_pred": 0.9960941076278687, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 17.8885555267334, "eval/dyn_loss_std": 10.419791221618652, "eval/image_loss_mean": 12.946924209594727, "eval/image_loss_std": 22.62626075744629, "eval/model_loss_mean": 23.776897430419922, "eval/model_loss_std": 26.488046646118164, "eval/post_ent_mag": 58.61225128173828, "eval/post_ent_max": 58.61225128173828, "eval/post_ent_mean": 39.839622497558594, "eval/post_ent_min": 21.109294891357422, "eval/post_ent_std": 7.526186466217041, "eval/prior_ent_mag": 66.26437377929688, "eval/prior_ent_max": 66.26437377929688, "eval/prior_ent_mean": 55.535728454589844, "eval/prior_ent_min": 41.77788543701172, "eval/prior_ent_std": 3.7682371139526367, "eval/rep_loss_mean": 17.8885555267334, "eval/rep_loss_std": 10.419791221618652, "eval/reward_avg": 0.04335937649011612, "eval/reward_loss_mean": 0.09683617949485779, "eval/reward_loss_std": 0.5725350379943848, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.002967357635498, "eval/reward_neg_acc": 0.9917948246002197, "eval/reward_neg_loss": 0.028575683012604713, "eval/reward_pos_acc": 0.8979591727256775, "eval/reward_pos_loss": 1.4550806283950806, "eval/reward_pred": 0.03808892145752907, "eval/reward_rate": 0.0478515625, "replay/size": 726273.0, "replay/inserts": 22480.0, "replay/samples": 22480.0, "replay/insert_wait_avg": 1.3078659030466318e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.464792380553548e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 6448.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.075323994638902e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 1.296401023864746e-06, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.5725376605988, "timer/env.step_count": 2810.0, "timer/env.step_total": 232.4426553249359, "timer/env.step_frac": 0.2320777043945901, "timer/env.step_avg": 0.08271980616545763, "timer/env.step_min": 0.02233719825744629, "timer/env.step_max": 4.382405042648315, "timer/replay._sample_count": 22480.0, "timer/replay._sample_total": 11.427522659301758, "timer/replay._sample_frac": 0.011409580664015954, "timer/replay._sample_avg": 0.0005083417553070177, "timer/replay._sample_min": 0.0004036426544189453, "timer/replay._sample_max": 0.024938344955444336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3616.0, "timer/agent.policy_total": 59.27542686462402, "timer/agent.policy_frac": 0.059182360374092635, "timer/agent.policy_avg": 0.01639254061521682, "timer/agent.policy_min": 0.009245872497558594, "timer/agent.policy_max": 0.11364173889160156, "timer/dataset_train_count": 1405.0, "timer/dataset_train_total": 0.15031790733337402, "timer/dataset_train_frac": 0.00015008189789675723, "timer/dataset_train_avg": 0.00010698783440097796, "timer/dataset_train_min": 8.940696716308594e-05, "timer/dataset_train_max": 0.00077056884765625, "timer/agent.train_count": 1405.0, "timer/agent.train_total": 635.5914242267609, "timer/agent.train_frac": 0.6345935020456228, "timer/agent.train_avg": 0.45237823788381554, "timer/agent.train_min": 0.4344513416290283, "timer/agent.train_max": 2.2436063289642334, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.472869873046875, "timer/agent.report_frac": 0.00047212743487493226, "timer/agent.report_avg": 0.2364349365234375, "timer/agent.report_min": 0.22992944717407227, "timer/agent.report_max": 0.24294042587280273, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.5987625122070312e-05, "timer/dataset_eval_frac": 2.594682276609774e-08, "timer/dataset_eval_avg": 2.5987625122070312e-05, "timer/dataset_eval_min": 2.5987625122070312e-05, "timer/dataset_eval_max": 2.5987625122070312e-05, "fps": 22.444370015308394}
{"step": 726848, "time": 33329.022629737854, "episode/length": 260.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 726928, "time": 33333.31035423279, "episode/length": 218.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680365296803652, "episode/intrinsic_return": 0.0}
{"step": 727488, "time": 33353.483258485794, "episode/length": 183.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 727512, "time": 33355.65532517433, "episode/length": 218.0, "episode/score": 7.100000038743019, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 727592, "time": 33360.010709524155, "episode/length": 163.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9573170731707317, "episode/intrinsic_return": 0.0}
{"step": 728032, "time": 33377.11425113678, "episode/length": 247.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 728200, "time": 33384.123390197754, "episode/length": 158.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 728688, "time": 33402.309037685394, "episode/length": 146.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9591836734693877, "episode/intrinsic_return": 0.0}
{"step": 729240, "time": 33424.4090821743, "episode/length": 205.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9951456310679612, "episode/intrinsic_return": 0.0}
{"step": 729456, "time": 33433.399837970734, "episode/length": 334.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.0}
{"step": 729608, "time": 33439.892414569855, "episode/length": 175.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 729672, "time": 33443.584015607834, "episode/length": 204.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 730008, "time": 33456.39985823631, "episode/length": 420.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9904988123515439, "episode/intrinsic_return": 0.0}
{"step": 730048, "time": 33459.69208788872, "episode/length": 319.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 730080, "time": 33477.50376033783, "eval_episode/length": 58.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 730080, "time": 33480.02055168152, "eval_episode/length": 82.0, "eval_episode/score": 7.099999964237213, "eval_episode/reward_rate": 0.9397590361445783}
{"step": 730080, "time": 33484.09418129921, "eval_episode/length": 147.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.9932432432432432}
{"step": 730080, "time": 33486.847304821014, "eval_episode/length": 176.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 730080, "time": 33488.98926305771, "eval_episode/length": 191.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9635416666666666}
{"step": 730080, "time": 33491.46941900253, "eval_episode/length": 208.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9760765550239234}
{"step": 730080, "time": 33495.29960441589, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 730080, "time": 33500.21548080444, "eval_episode/length": 346.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9884726224783862}
{"step": 730272, "time": 33508.22520709038, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 730688, "time": 33524.33779358864, "episode/length": 180.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 730720, "time": 33526.97066640854, "episode/length": 157.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 730824, "time": 33531.694858551025, "episode/length": 266.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 731024, "time": 33539.98689222336, "episode/length": 176.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 731152, "time": 33545.83518695831, "episode/length": 57.0, "episode/score": 4.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 731176, "time": 33548.002666950226, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 731488, "time": 33560.392849206924, "episode/length": 57.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 731576, "time": 33564.577342033386, "episode/length": 195.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 732344, "time": 33591.6786673069, "episode/length": 148.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 732800, "time": 33608.594651699066, "episode/length": 152.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 732904, "time": 33613.4100022316, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 733296, "time": 33628.18140625954, "episode/length": 308.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9773462783171522, "episode/intrinsic_return": 0.0}
{"step": 733328, "time": 33630.823518037796, "episode/length": 409.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9902439024390244, "episode/intrinsic_return": 0.0}
{"step": 733576, "time": 33640.48592209816, "episode/length": 412.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9927360774818402, "episode/intrinsic_return": 0.0}
{"step": 733600, "time": 33643.02047872543, "episode/length": 359.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9861111111111112, "episode/intrinsic_return": 0.0}
{"step": 734008, "time": 33657.9160759449, "episode/length": 314.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 734280, "time": 33668.502945661545, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 734384, "time": 33673.866221666336, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 735056, "time": 33697.77730727196, "episode/length": 215.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 735144, "time": 33702.076691150665, "episode/length": 349.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9971428571428571, "episode/intrinsic_return": 0.0}
{"step": 735296, "time": 33708.99639940262, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 735416, "time": 33714.32451796532, "episode/length": 229.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 735552, "time": 33720.705904483795, "episode/length": 281.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 735856, "time": 33732.59102344513, "episode/length": 230.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 735984, "time": 33738.391078948975, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 736160, "time": 33745.89225888252, "episode/length": 221.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 736352, "time": 33753.88722681999, "episode/length": 150.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9602649006622517, "episode/intrinsic_return": 0.0}
{"step": 737144, "time": 33781.759129047394, "episode/length": 230.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 737328, "time": 33791.357662677765, "episode/length": 238.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 737488, "time": 33798.37764430046, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 737504, "time": 33800.489827632904, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 737744, "time": 33810.54754567146, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 737928, "time": 33818.7468187809, "episode/length": 220.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 738256, "time": 33832.470556259155, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975, "episode/intrinsic_return": 0.0}
{"step": 739008, "time": 33859.88578104973, "episode/length": 157.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 739120, "time": 33865.18985915184, "episode/length": 445.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 739408, "time": 33876.27668619156, "episode/length": 237.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 739416, "time": 33877.85875439644, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 739432, "time": 33879.97466468811, "episode/length": 242.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 739480, "time": 33883.101403713226, "episode/length": 58.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 739536, "time": 33886.68358540535, "episode/length": 275.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 739928, "time": 33901.038811445236, "episode/length": 249.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 740064, "time": 33926.45346593857, "eval_episode/length": 153.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9935064935064936}
{"step": 740064, "time": 33928.647371053696, "eval_episode/length": 166.0, "eval_episode/score": 7.099999979138374, "eval_episode/reward_rate": 0.9940119760479041}
{"step": 740064, "time": 33930.568518161774, "eval_episode/length": 177.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 740064, "time": 33932.46306991577, "eval_episode/length": 184.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9783783783783784}
{"step": 740064, "time": 33934.57730150223, "eval_episode/length": 198.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.964824120603015}
{"step": 740064, "time": 33936.350350379944, "eval_episode/length": 202.0, "eval_episode/score": 6.099999964237213, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 740064, "time": 33939.180916786194, "eval_episode/length": 233.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9829059829059829}
{"step": 740064, "time": 33942.18398976326, "eval_episode/length": 267.0, "eval_episode/score": 7.100000008940697, "eval_episode/reward_rate": 0.996268656716418}
{"step": 740088, "time": 33942.7587518692, "episode/length": 81.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 740472, "time": 33956.88663315773, "episode/length": 168.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 740944, "time": 33975.178112745285, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 741000, "time": 33979.11862206459, "episode/length": 65.0, "episode/score": 2.1000000089406967, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 741072, "time": 33983.353618621826, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9943181818181818, "episode/intrinsic_return": 0.0}
{"step": 741224, "time": 33990.480566978455, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9678899082568807, "episode/intrinsic_return": 0.0}
{"step": 741296, "time": 33994.67662978172, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 741512, "time": 34003.53363656998, "episode/length": 246.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 741608, "time": 34008.91825389862, "episode/length": 189.0, "episode/score": 9.100000031292439, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 741944, "time": 34022.41212105751, "episode/length": 108.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9908256880733946, "episode/intrinsic_return": 0.0}
{"step": 742288, "time": 34036.424624443054, "episode/length": 167.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 742640, "time": 34049.72958946228, "episode/length": 86.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9540229885057471, "episode/intrinsic_return": 0.0}
{"step": 742832, "time": 34057.612077236176, "episode/length": 362.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9917355371900827, "episode/intrinsic_return": 0.0}
{"step": 742880, "time": 34060.881687641144, "episode/length": 197.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 742976, "time": 34065.612433195114, "episode/length": 246.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 743072, "time": 34070.36535859108, "episode/length": 230.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 743232, "time": 34077.275856256485, "episode/length": 214.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
{"step": 743528, "time": 34088.42993211746, "episode/length": 239.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 743800, "time": 34099.01116108894, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 744416, "time": 34121.315413713455, "episode/length": 197.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9696969696969697, "episode/intrinsic_return": 0.0}
{"step": 744640, "time": 34130.558151483536, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 744824, "time": 34137.98000049591, "episode/length": 230.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783549783549783, "episode/intrinsic_return": 0.0}
{"step": 744848, "time": 34140.6524848938, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9702970297029703, "episode/intrinsic_return": 0.0}
{"step": 745144, "time": 34151.79902148247, "episode/length": 312.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9904153354632588, "episode/intrinsic_return": 0.0}
{"step": 746016, "time": 34184.117307424545, "episode/length": 171.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 746256, "time": 34193.63830494881, "episode/length": 306.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.993485342019544, "episode/intrinsic_return": 0.0}
{"step": 746408, "time": 34200.03542757034, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 746512, "time": 34205.21775197983, "episode/length": 429.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9790697674418605, "episode/intrinsic_return": 0.0}
{"step": 746536, "time": 34207.451561927795, "episode/length": 375.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9973404255319149, "episode/intrinsic_return": 0.0}
{"step": 746576, "time": 34210.7010846138, "episode/length": 269.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9740740740740741, "episode/intrinsic_return": 0.0}
{"step": 746624, "time": 34213.95178079605, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 747272, "time": 34236.79789733887, "episode/length": 305.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 747760, "time": 34255.00393605232, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 747776, "time": 34257.569326639175, "episode/length": 154.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9741935483870968, "episode/intrinsic_return": 0.0}
{"step": 748488, "time": 34283.31381058693, "episode/length": 238.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9748953974895398, "episode/intrinsic_return": 0.0}
{"step": 748600, "time": 34288.82729244232, "episode/length": 260.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9846743295019157, "episode/intrinsic_return": 0.0}
{"step": 748640, "time": 34291.94982433319, "episode/length": 278.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996415770609319, "episode/intrinsic_return": 0.0}
{"step": 749152, "time": 34310.54686546326, "episode/length": 82.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9397590361445783, "episode/intrinsic_return": 0.0}
{"step": 749192, "time": 34313.249004364014, "episode/length": 68.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 749216, "time": 34315.69899439812, "episode/length": 242.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9876543209876543, "episode/intrinsic_return": 0.0}
{"step": 749312, "time": 34320.45903968811, "episode/length": 411.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 749433, "time": 34326.78444266319, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.608203296930018, "train/action_min": 0.0, "train/action_std": 3.254992520305472, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03402916948035569, "train/actor_opt_grad_steps": 46035.0, "train/actor_opt_loss": -7.735160422775383, "train/adv_mag": 0.44245373824952355, "train/adv_max": 0.3905528292689525, "train/adv_mean": 0.0021154882114400686, "train/adv_min": -0.3726983805987197, "train/adv_std": 0.050473614084258885, "train/cont_avg": 0.9952134683098591, "train/cont_loss_mean": 0.0001360761677108818, "train/cont_loss_std": 0.003746824659395677, "train/cont_neg_acc": 0.994651241621501, "train/cont_neg_loss": 0.012508162454241115, "train/cont_pos_acc": 0.9999930833427, "train/cont_pos_loss": 7.095426806733459e-05, "train/cont_pred": 0.9952163801226818, "train/cont_rate": 0.9952134683098591, "train/dyn_loss_mean": 13.438296291190134, "train/dyn_loss_std": 9.072989893631197, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.962538632708536, "train/extr_critic_critic_opt_grad_steps": 46035.0, "train/extr_critic_critic_opt_loss": 15973.915376045334, "train/extr_critic_mag": 9.334182631801552, "train/extr_critic_max": 9.334182631801552, "train/extr_critic_mean": 2.8006945176863334, "train/extr_critic_min": -0.16105639430838573, "train/extr_critic_std": 2.225831564043609, "train/extr_return_normed_mag": 1.4663354972718468, "train/extr_return_normed_max": 1.4663354972718468, "train/extr_return_normed_mean": 0.37842254623980587, "train/extr_return_normed_min": -0.09751250432200835, "train/extr_return_normed_std": 0.3223852507874999, "train/extr_return_rate": 0.8305696580611485, "train/extr_return_raw_mag": 10.41226346727828, "train/extr_return_raw_max": 10.41226346727828, "train/extr_return_raw_mean": 2.8154587107644953, "train/extr_return_raw_min": -0.5093137781384965, "train/extr_return_raw_std": 2.2519331179874045, "train/extr_reward_mag": 1.0352049192912143, "train/extr_reward_max": 1.0352049192912143, "train/extr_reward_mean": 0.04371178946392217, "train/extr_reward_min": -0.42344777265065153, "train/extr_reward_std": 0.19470535869329747, "train/image_loss_mean": 6.684762001037598, "train/image_loss_std": 12.043586408588249, "train/model_loss_mean": 14.806019561391482, "train/model_loss_std": 15.732051708328893, "train/model_opt_grad_norm": 58.993356006246216, "train/model_opt_grad_steps": 45994.58450704225, "train/model_opt_loss": 18628.00010315801, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8028169014085, "train/policy_entropy_mag": 2.6145732671442166, "train/policy_entropy_max": 2.6145732671442166, "train/policy_entropy_mean": 0.5296069662755644, "train/policy_entropy_min": 0.07937504692186773, "train/policy_entropy_std": 0.6331951517454335, "train/policy_logprob_mag": 7.4383836967844355, "train/policy_logprob_max": -0.00945566339470761, "train/policy_logprob_mean": -0.5299696670451635, "train/policy_logprob_min": -7.4383836967844355, "train/policy_logprob_std": 1.0895172756322673, "train/policy_randomness_mag": 0.9228296263117186, "train/policy_randomness_max": 0.9228296263117186, "train/policy_randomness_mean": 0.18692801945226292, "train/policy_randomness_min": 0.028015908234241143, "train/policy_randomness_std": 0.22349010166567815, "train/post_ent_mag": 57.738181557453856, "train/post_ent_max": 57.738181557453856, "train/post_ent_mean": 41.79286782170685, "train/post_ent_min": 19.685961071874054, "train/post_ent_std": 7.398017077378824, "train/prior_ent_mag": 66.61291922985667, "train/prior_ent_max": 66.61291922985667, "train/prior_ent_mean": 55.29803547389071, "train/prior_ent_min": 40.828768421226826, "train/prior_ent_std": 4.192927933075059, "train/rep_loss_mean": 13.438296291190134, "train/rep_loss_std": 9.072989893631197, "train/reward_avg": 0.03038003400597774, "train/reward_loss_mean": 0.05814374303838737, "train/reward_loss_std": 0.258025800258341, "train/reward_max_data": 1.0197183145603663, "train/reward_max_pred": 1.015734915162476, "train/reward_neg_acc": 0.9929036380539478, "train/reward_neg_loss": 0.03015041791401069, "train/reward_pos_acc": 0.9685693135563757, "train/reward_pos_loss": 0.8411889143393073, "train/reward_pred": 0.02954609390400665, "train/reward_rate": 0.03470923195422535, "train_stats/sum_log_reward": 9.028571664070597, "train_stats/max_log_achievement_collect_coal": 0.40816326530612246, "train_stats/max_log_achievement_collect_drink": 5.551020408163265, "train_stats/max_log_achievement_collect_sapling": 1.6326530612244898, "train_stats/max_log_achievement_collect_stone": 9.724489795918368, "train_stats/max_log_achievement_collect_wood": 10.561224489795919, "train_stats/max_log_achievement_defeat_skeleton": 0.02040816326530612, "train_stats/max_log_achievement_defeat_zombie": 0.7040816326530612, "train_stats/max_log_achievement_eat_cow": 0.12244897959183673, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 0.9693877551020408, "train_stats/max_log_achievement_make_wood_sword": 1.4387755102040816, "train_stats/max_log_achievement_place_furnace": 0.061224489795918366, "train_stats/max_log_achievement_place_plant": 1.6020408163265305, "train_stats/max_log_achievement_place_stone": 7.326530612244898, "train_stats/max_log_achievement_place_table": 2.704081632653061, "train_stats/max_log_achievement_wake_up": 1.469387755102041, "train_stats/mean_log_entropy": 0.5527987325069855, "eval_stats/sum_log_reward": 7.537500083446503, "eval_stats/max_log_achievement_collect_coal": 0.0, "eval_stats/max_log_achievement_collect_drink": 5.75, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 3.375, "eval_stats/max_log_achievement_collect_wood": 8.625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.3125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.875, "eval_stats/max_log_achievement_make_wood_sword": 1.0, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.25, "eval_stats/max_log_achievement_place_stone": 2.625, "eval_stats/max_log_achievement_place_table": 2.6875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 4.1153261918225326e-06, "report/cont_loss_std": 7.243807340273634e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0005715391016565263, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.709820124546241e-07, "report/cont_pred": 0.9941432476043701, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 12.22452163696289, "report/dyn_loss_std": 8.660409927368164, "report/image_loss_mean": 5.201999664306641, "report/image_loss_std": 8.56438159942627, "report/model_loss_mean": 12.596464157104492, "report/model_loss_std": 12.161856651306152, "report/post_ent_mag": 57.3698844909668, "report/post_ent_max": 57.3698844909668, "report/post_ent_mean": 42.664825439453125, "report/post_ent_min": 19.282447814941406, "report/post_ent_std": 7.320804119110107, "report/prior_ent_mag": 66.83514404296875, "report/prior_ent_max": 66.83514404296875, "report/prior_ent_mean": 55.09040069580078, "report/prior_ent_min": 39.19023895263672, "report/prior_ent_std": 4.528321743011475, "report/rep_loss_mean": 12.22452163696289, "report/rep_loss_std": 8.660409927368164, "report/reward_avg": 0.03437499701976776, "report/reward_loss_mean": 0.05974707752466202, "report/reward_loss_std": 0.21900574862957, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.00531005859375, "report/reward_neg_acc": 0.9949135184288025, "report/reward_neg_loss": 0.03026682324707508, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7665541172027588, "report/reward_pred": 0.033439747989177704, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 3.206832843716256e-05, "eval/cont_loss_std": 0.0009370084735564888, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0063283429481089115, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.1739441561076092e-06, "eval/cont_pred": 0.9951465129852295, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 17.73822784423828, "eval/dyn_loss_std": 9.874258041381836, "eval/image_loss_mean": 10.08416748046875, "eval/image_loss_std": 14.004239082336426, "eval/model_loss_mean": 20.816234588623047, "eval/model_loss_std": 17.71956443786621, "eval/post_ent_mag": 59.04789733886719, "eval/post_ent_max": 59.04789733886719, "eval/post_ent_mean": 40.615169525146484, "eval/post_ent_min": 19.37474822998047, "eval/post_ent_std": 7.656030654907227, "eval/prior_ent_mag": 66.83514404296875, "eval/prior_ent_max": 66.83514404296875, "eval/prior_ent_mean": 56.47257995605469, "eval/prior_ent_min": 39.494468688964844, "eval/prior_ent_std": 4.115625858306885, "eval/rep_loss_mean": 17.73822784423828, "eval/rep_loss_std": 9.874258041381836, "eval/reward_avg": 0.04062500223517418, "eval/reward_loss_mean": 0.08909665793180466, "eval/reward_loss_std": 0.5741212964057922, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0028512477874756, "eval/reward_neg_acc": 0.9959099888801575, "eval/reward_neg_loss": 0.026306530460715294, "eval/reward_pos_acc": 0.9130434989929199, "eval/reward_pos_loss": 1.4240696430206299, "eval/reward_pred": 0.034595414996147156, "eval/reward_rate": 0.044921875, "replay/size": 748929.0, "replay/inserts": 22656.0, "replay/samples": 22656.0, "replay/insert_wait_avg": 1.3205207000344486e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.422167365833864e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4920.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0818969912645294e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1925504207611, "timer/env.step_count": 2832.0, "timer/env.step_total": 235.99200963974, "timer/env.step_frac": 0.23594657802686378, "timer/env.step_avg": 0.08333051187843926, "timer/env.step_min": 0.02245044708251953, "timer/env.step_max": 2.288435697555542, "timer/replay._sample_count": 22656.0, "timer/replay._sample_total": 11.34068250656128, "timer/replay._sample_frac": 0.011338499273755319, "timer/replay._sample_avg": 0.0005005597857768926, "timer/replay._sample_min": 0.00041556358337402344, "timer/replay._sample_max": 0.011139392852783203, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3447.0, "timer/agent.policy_total": 55.13532042503357, "timer/agent.policy_frac": 0.05512470613967204, "timer/agent.policy_avg": 0.0159951611328789, "timer/agent.policy_min": 0.00941324234008789, "timer/agent.policy_max": 0.11046671867370605, "timer/dataset_train_count": 1416.0, "timer/dataset_train_total": 0.15045619010925293, "timer/dataset_train_frac": 0.00015042722528373062, "timer/dataset_train_avg": 0.00010625437154608257, "timer/dataset_train_min": 9.202957153320312e-05, "timer/dataset_train_max": 0.00023746490478515625, "timer/agent.train_count": 1416.0, "timer/agent.train_total": 640.5955693721771, "timer/agent.train_frac": 0.640472246171691, "timer/agent.train_avg": 0.45239800096905164, "timer/agent.train_min": 0.43798160552978516, "timer/agent.train_max": 1.819640874862671, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47623610496520996, "timer/agent.report_frac": 0.00047614442315618816, "timer/agent.report_avg": 0.23811805248260498, "timer/agent.report_min": 0.23091435432434082, "timer/agent.report_max": 0.24532175064086914, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7894973754882812e-05, "timer/dataset_eval_frac": 2.7889603599974777e-08, "timer/dataset_eval_avg": 2.7894973754882812e-05, "timer/dataset_eval_min": 2.7894973754882812e-05, "timer/dataset_eval_max": 2.7894973754882812e-05, "fps": 22.65134424942206}
{"step": 749576, "time": 34331.40898180008, "episode/length": 226.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 749824, "time": 34341.33080840111, "episode/length": 78.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9367088607594937, "episode/intrinsic_return": 0.0}
{"step": 749840, "time": 34343.42244076729, "episode/length": 154.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 750048, "time": 34370.66704535484, "eval_episode/length": 139.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9571428571428572}
{"step": 750048, "time": 34372.96079850197, "eval_episode/length": 155.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 750048, "time": 34375.20385956764, "eval_episode/length": 171.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9651162790697675}
{"step": 750048, "time": 34377.84269928932, "eval_episode/length": 195.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9744897959183674}
{"step": 750048, "time": 34379.49810886383, "eval_episode/length": 196.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9796954314720813}
{"step": 750048, "time": 34382.83744049072, "eval_episode/length": 236.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 750048, "time": 34385.98668694496, "eval_episode/length": 118.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9663865546218487}
{"step": 750048, "time": 34387.61943650246, "eval_episode/length": 104.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9523809523809523}
{"step": 750176, "time": 34391.96675992012, "episode/length": 443.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 750352, "time": 34399.35443639755, "episode/length": 321.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 750520, "time": 34406.28461718559, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 750768, "time": 34416.576850652695, "episode/length": 201.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9752475247524752, "episode/intrinsic_return": 0.0}
{"step": 751360, "time": 34438.27323961258, "episode/length": 255.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.99609375, "episode/intrinsic_return": 0.0}
{"step": 751648, "time": 34449.39449596405, "episode/length": 225.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 751680, "time": 34452.17751073837, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 751696, "time": 34454.225645303726, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 751736, "time": 34456.95662331581, "episode/length": 238.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9707112970711297, "episode/intrinsic_return": 0.0}
{"step": 752240, "time": 34475.56558060646, "episode/length": 332.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.987987987987988, "episode/intrinsic_return": 0.0}
{"step": 752240, "time": 34475.575097322464, "episode/length": 214.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9674418604651163, "episode/intrinsic_return": 0.0}
{"step": 752744, "time": 34495.511835575104, "episode/length": 130.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9923664122137404, "episode/intrinsic_return": 0.0}
{"step": 752968, "time": 34504.59183382988, "episode/length": 160.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 753376, "time": 34520.02031183243, "episode/length": 251.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9801587301587301, "episode/intrinsic_return": 0.0}
{"step": 753632, "time": 34530.13968038559, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 753944, "time": 34543.599204063416, "episode/length": 212.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 754200, "time": 34553.611515522, "episode/length": 428.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.993006993006993, "episode/intrinsic_return": 0.0}
{"step": 754448, "time": 34563.67813253403, "episode/length": 62.0, "episode/score": 5.100000016391277, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 754648, "time": 34572.059890031815, "episode/length": 158.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 754672, "time": 34574.7926299572, "episode/length": 212.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 754840, "time": 34581.783242464066, "episode/length": 261.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770992366412213, "episode/intrinsic_return": 0.0}
{"step": 755232, "time": 34596.7072429657, "episode/length": 373.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9893048128342246, "episode/intrinsic_return": 0.0}
{"step": 755280, "time": 34599.93154811859, "episode/length": 442.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9796839729119639, "episode/intrinsic_return": 0.0}
{"step": 755424, "time": 34606.1884431839, "episode/length": 223.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9776785714285714, "episode/intrinsic_return": 0.0}
{"step": 755856, "time": 34622.25844311714, "episode/length": 147.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 756096, "time": 34632.00464010239, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 756288, "time": 34640.020122528076, "episode/length": 260.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9693486590038314, "episode/intrinsic_return": 0.0}
{"step": 756496, "time": 34648.55937862396, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9710144927536232, "episode/intrinsic_return": 0.0}
{"step": 756616, "time": 34653.91563129425, "episode/length": 245.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.983739837398374, "episode/intrinsic_return": 0.0}
{"step": 756672, "time": 34657.61462020874, "episode/length": 155.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 757352, "time": 34681.64979147911, "episode/length": 132.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9624060150375939, "episode/intrinsic_return": 0.0}
{"step": 757616, "time": 34692.767838954926, "episode/length": 189.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 758352, "time": 34718.71003365517, "episode/length": 389.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 758624, "time": 34729.41537666321, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9622641509433962, "episode/intrinsic_return": 0.0}
{"step": 758824, "time": 34737.35442662239, "episode/length": 370.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9919137466307277, "episode/intrinsic_return": 0.0}
{"step": 759088, "time": 34747.98812460899, "episode/length": 308.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9805825242718447, "episode/intrinsic_return": 0.0}
{"step": 759376, "time": 34759.3332259655, "episode/length": 511.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 760032, "time": 34801.895565748215, "eval_episode/length": 161.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9691358024691358}
{"step": 760032, "time": 34804.07315301895, "eval_episode/length": 175.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 760032, "time": 34805.96883511543, "eval_episode/length": 183.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9728260869565217}
{"step": 760032, "time": 34808.364653110504, "eval_episode/length": 200.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.9950248756218906}
{"step": 760032, "time": 34810.09128975868, "eval_episode/length": 203.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 760032, "time": 34814.6086397171, "eval_episode/length": 274.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9963636363636363}
{"step": 760032, "time": 34818.53259849548, "eval_episode/length": 334.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9850746268656716}
{"step": 760032, "time": 34822.16880583763, "eval_episode/length": 186.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 760056, "time": 34822.75100708008, "episode/length": 422.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 760296, "time": 34832.291278362274, "episode/length": 183.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 760416, "time": 34837.99653458595, "episode/length": 165.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 760440, "time": 34840.316628694534, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 760568, "time": 34846.12596511841, "episode/length": 368.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 760576, "time": 34848.19349241257, "episode/length": 277.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 761288, "time": 34873.079018116, "episode/length": 89.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9333333333333333, "episode/intrinsic_return": 0.0}
{"step": 761960, "time": 34898.68085384369, "episode/length": 322.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9845201238390093, "episode/intrinsic_return": 0.0}
{"step": 762008, "time": 34902.03224372864, "episode/length": 688.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9956458635703919, "episode/intrinsic_return": 0.0}
{"step": 762072, "time": 34905.95811963081, "episode/length": 221.0, "episode/score": 7.0999999940395355, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 762144, "time": 34910.38425350189, "episode/length": 260.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961685823754789, "episode/intrinsic_return": 0.0}
{"step": 762560, "time": 34926.74536085129, "episode/length": 267.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.996268656716418, "episode/intrinsic_return": 0.0}
{"step": 762800, "time": 34936.99123072624, "episode/length": 277.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9964028776978417, "episode/intrinsic_return": 0.0}
{"step": 762800, "time": 34937.00246858597, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 763016, "time": 34947.435592889786, "episode/length": 321.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9968944099378882, "episode/intrinsic_return": 0.0}
{"step": 763480, "time": 34964.53417134285, "episode/length": 166.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 764136, "time": 34987.92640709877, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9779411764705882, "episode/intrinsic_return": 0.0}
{"step": 764176, "time": 34991.16210603714, "episode/length": 171.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 764224, "time": 34994.35815286636, "episode/length": 268.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9851301115241635, "episode/intrinsic_return": 0.0}
{"step": 764488, "time": 35004.55059719086, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 764544, "time": 35008.22767138481, "episode/length": 247.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 765112, "time": 35029.53367996216, "episode/length": 261.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961832061068703, "episode/intrinsic_return": 0.0}
{"step": 765144, "time": 35032.102810144424, "episode/length": 207.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9663461538461539, "episode/intrinsic_return": 0.0}
{"step": 765416, "time": 35042.72876691818, "episode/length": 425.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 765712, "time": 35054.48650622368, "episode/length": 185.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 765824, "time": 35059.783012866974, "episode/length": 166.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 765968, "time": 35066.20672130585, "episode/length": 177.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 766392, "time": 35081.81805086136, "episode/length": 52.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 766880, "time": 35099.99292564392, "episode/length": 342.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 766944, "time": 35104.33322095871, "episode/length": 190.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 767248, "time": 35116.95051026344, "episode/length": 262.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 767608, "time": 35130.56777596474, "episode/length": 311.0, "episode/score": 9.099999964237213, "episode/reward_rate": 0.9775641025641025, "episode/intrinsic_return": 0.0}
{"step": 767704, "time": 35135.32247495651, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 767720, "time": 35137.335930109024, "episode/length": 442.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9954853273137697, "episode/intrinsic_return": 0.0}
{"step": 767808, "time": 35142.187804698944, "episode/length": 176.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 768008, "time": 35150.10457825661, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790940766550522, "episode/intrinsic_return": 0.0}
{"step": 768536, "time": 35169.23821091652, "episode/length": 198.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 768728, "time": 35177.40090084076, "episode/length": 184.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9621621621621622, "episode/intrinsic_return": 0.0}
{"step": 768960, "time": 35186.97181248665, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9730769230769231, "episode/intrinsic_return": 0.0}
{"step": 769208, "time": 35196.61520600319, "episode/length": 149.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 769264, "time": 35200.411195755005, "episode/length": 206.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 769320, "time": 35203.67616009712, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 769712, "time": 35218.478018283844, "episode/length": 237.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 769736, "time": 35220.6292386055, "episode/length": 253.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9960629921259843, "episode/intrinsic_return": 0.0}
{"step": 770016, "time": 35252.0301823616, "eval_episode/length": 138.0, "eval_episode/score": 8.100000023841858, "eval_episode/reward_rate": 0.9928057553956835}
{"step": 770016, "time": 35254.18996334076, "eval_episode/length": 152.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 770016, "time": 35256.86521196365, "eval_episode/length": 178.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9720670391061452}
{"step": 770016, "time": 35259.65839600563, "eval_episode/length": 64.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.9846153846153847}
{"step": 770016, "time": 35262.360376119614, "eval_episode/length": 230.0, "eval_episode/score": 9.099999994039536, "eval_episode/reward_rate": 0.9956709956709957}
{"step": 770016, "time": 35264.331800699234, "eval_episode/length": 239.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.975}
{"step": 770016, "time": 35267.91521382332, "eval_episode/length": 287.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9756944444444444}
{"step": 770016, "time": 35270.503873348236, "eval_episode/length": 158.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9622641509433962}
{"step": 770112, "time": 35275.3844602108, "episode/length": 172.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 770232, "time": 35280.68530082703, "episode/length": 211.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9952830188679245, "episode/intrinsic_return": 0.0}
{"step": 770584, "time": 35294.14145874977, "episode/length": 171.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 770824, "time": 35303.67703485489, "episode/length": 187.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 770912, "time": 35308.49083566666, "episode/length": 205.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9854368932038835, "episode/intrinsic_return": 0.0}
{"step": 771032, "time": 35313.99628281593, "episode/length": 258.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 771337, "time": 35327.16502213478, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.483273694114963, "train/action_min": 0.0, "train/action_std": 3.201835066732699, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03422844983691717, "train/actor_opt_grad_steps": 47430.0, "train/actor_opt_loss": -6.741152573574035, "train/adv_mag": 0.4340546337792473, "train/adv_max": 0.39844393556135416, "train/adv_mean": 0.0027761812308617533, "train/adv_min": -0.3562864923346652, "train/adv_std": 0.05102990181559194, "train/cont_avg": 0.9953595460766423, "train/cont_loss_mean": 0.00019602372084679442, "train/cont_loss_std": 0.0056850694571033, "train/cont_neg_acc": 0.9907339824377185, "train/cont_neg_loss": 0.02216553714305167, "train/cont_pos_acc": 0.9999642145894739, "train/cont_pos_loss": 8.835492833310395e-05, "train/cont_pred": 0.9953607064093987, "train/cont_rate": 0.9953595460766423, "train/dyn_loss_mean": 13.485607418700726, "train/dyn_loss_std": 9.081045728530327, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9198739324172918, "train/extr_critic_critic_opt_grad_steps": 47430.0, "train/extr_critic_critic_opt_loss": 15820.48190151688, "train/extr_critic_mag": 9.25478694386726, "train/extr_critic_max": 9.25478694386726, "train/extr_critic_mean": 2.7979507533303143, "train/extr_critic_min": -0.16213686187771986, "train/extr_critic_std": 2.2082193315464216, "train/extr_return_normed_mag": 1.4900841860875595, "train/extr_return_normed_max": 1.4900841860875595, "train/extr_return_normed_mean": 0.3857661602053329, "train/extr_return_normed_min": -0.09751972651285847, "train/extr_return_normed_std": 0.3258124827033412, "train/extr_return_rate": 0.8281882470541627, "train/extr_return_raw_mag": 10.41128971628899, "train/extr_return_raw_max": 10.41128971628899, "train/extr_return_raw_mean": 2.8170292020714194, "train/extr_return_raw_min": -0.5068019017250869, "train/extr_return_raw_std": 2.2409855945266948, "train/extr_reward_mag": 1.0341435696956884, "train/extr_reward_max": 1.0341435696956884, "train/extr_reward_mean": 0.04618127207632047, "train/extr_reward_min": -0.4439007531117349, "train/extr_reward_std": 0.20048028633107234, "train/image_loss_mean": 6.693469005779629, "train/image_loss_std": 12.102656576755273, "train/model_loss_mean": 14.842846807772226, "train/model_loss_std": 15.752700032979032, "train/model_opt_grad_norm": 55.848609604104595, "train/model_opt_grad_steps": 47388.357664233576, "train/model_opt_loss": 19632.651816263686, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1322.992700729927, "train/policy_entropy_mag": 2.6355312218631273, "train/policy_entropy_max": 2.6355312218631273, "train/policy_entropy_mean": 0.5459414318095158, "train/policy_entropy_min": 0.0793750257278881, "train/policy_entropy_std": 0.6536975257153058, "train/policy_logprob_mag": 7.438383645384851, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5465195120251092, "train/policy_logprob_min": -7.438383645384851, "train/policy_logprob_std": 1.1033518170788341, "train/policy_randomness_mag": 0.9302268650409949, "train/policy_randomness_max": 0.9302268650409949, "train/policy_randomness_mean": 0.19269337010209578, "train/policy_randomness_min": 0.028015900729563985, "train/policy_randomness_std": 0.23072653997988596, "train/post_ent_mag": 57.826864256475965, "train/post_ent_max": 57.826864256475965, "train/post_ent_mean": 41.7693623173846, "train/post_ent_min": 19.514581986587412, "train/post_ent_std": 7.455238606807959, "train/prior_ent_mag": 66.6899518757841, "train/prior_ent_max": 66.6899518757841, "train/prior_ent_mean": 55.30324367885172, "train/prior_ent_min": 40.51570906256237, "train/prior_ent_std": 4.215507241061134, "train/rep_loss_mean": 13.485607418700726, "train/rep_loss_std": 9.081045728530327, "train/reward_avg": 0.03023351951889748, "train/reward_loss_mean": 0.05781744273692152, "train/reward_loss_std": 0.26070473696628627, "train/reward_max_data": 1.013868616445221, "train/reward_max_pred": 1.0096445892849109, "train/reward_neg_acc": 0.9922128637341687, "train/reward_neg_loss": 0.029290035339820122, "train/reward_pos_acc": 0.9653832599194381, "train/reward_pos_loss": 0.8573605970744669, "train/reward_pred": 0.029317370017677764, "train/reward_rate": 0.03448619981751825, "train_stats/sum_log_reward": 9.411111301845974, "train_stats/max_log_achievement_collect_coal": 0.43333333333333335, "train_stats/max_log_achievement_collect_drink": 5.8, "train_stats/max_log_achievement_collect_sapling": 1.6222222222222222, "train_stats/max_log_achievement_collect_stone": 11.311111111111112, "train_stats/max_log_achievement_collect_wood": 11.044444444444444, "train_stats/max_log_achievement_defeat_skeleton": 0.05555555555555555, "train_stats/max_log_achievement_defeat_zombie": 0.7111111111111111, "train_stats/max_log_achievement_eat_cow": 0.14444444444444443, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.011111111111111112, "train_stats/max_log_achievement_make_wood_pickaxe": 1.211111111111111, "train_stats/max_log_achievement_make_wood_sword": 1.6, "train_stats/max_log_achievement_place_furnace": 0.044444444444444446, "train_stats/max_log_achievement_place_plant": 1.5, "train_stats/max_log_achievement_place_stone": 9.355555555555556, "train_stats/max_log_achievement_place_table": 2.8444444444444446, "train_stats/max_log_achievement_wake_up": 1.7666666666666666, "train_stats/mean_log_entropy": 0.6074380437533061, "eval_stats/sum_log_reward": 9.266666869322458, "eval_stats/max_log_achievement_collect_coal": 0.2916666666666667, "eval_stats/max_log_achievement_collect_drink": 4.083333333333333, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 6.791666666666667, "eval_stats/max_log_achievement_collect_wood": 10.916666666666666, "eval_stats/max_log_achievement_defeat_skeleton": 0.041666666666666664, "eval_stats/max_log_achievement_defeat_zombie": 0.6666666666666666, "eval_stats/max_log_achievement_eat_cow": 0.16666666666666666, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0833333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.4583333333333333, "eval_stats/max_log_achievement_place_furnace": 0.041666666666666664, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 5.625, "eval_stats/max_log_achievement_place_table": 2.5833333333333335, "eval_stats/max_log_achievement_wake_up": 1.5, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.245728746354871e-07, "report/cont_loss_std": 3.2968728191917762e-06, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 3.67615903087426e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.7446555489186721e-07, "report/cont_pred": 0.9931641817092896, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.93985366821289, "report/dyn_loss_std": 8.852953910827637, "report/image_loss_mean": 5.967705726623535, "report/image_loss_std": 8.49557113647461, "report/model_loss_mean": 14.39213752746582, "report/model_loss_std": 12.122159004211426, "report/post_ent_mag": 56.82868957519531, "report/post_ent_max": 56.82868957519531, "report/post_ent_mean": 41.389862060546875, "report/post_ent_min": 20.129520416259766, "report/post_ent_std": 7.501043319702148, "report/prior_ent_mag": 66.46202087402344, "report/prior_ent_max": 66.46202087402344, "report/prior_ent_mean": 55.562713623046875, "report/prior_ent_min": 35.956703186035156, "report/prior_ent_std": 4.382730007171631, "report/rep_loss_mean": 13.93985366821289, "report/rep_loss_std": 8.852953910827637, "report/reward_avg": 0.03349609300494194, "report/reward_loss_mean": 0.060519296675920486, "report/reward_loss_std": 0.2456284612417221, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0347683429718018, "report/reward_neg_acc": 0.9959350228309631, "report/reward_neg_loss": 0.029255591332912445, "report/reward_pos_acc": 0.9750000238418579, "report/reward_pos_loss": 0.8296066522598267, "report/reward_pred": 0.03351764380931854, "report/reward_rate": 0.0390625, "eval/cont_avg": 0.99609375, "eval/cont_loss_mean": 0.0010555641492828727, "eval/cont_loss_std": 0.02625446394085884, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 5.95703131693881e-05, "eval/cont_pos_acc": 0.9990195631980896, "eval/cont_pos_loss": 0.0010594698833301663, "eval/cont_pred": 0.9953129887580872, "eval/cont_rate": 0.99609375, "eval/dyn_loss_mean": 16.73096466064453, "eval/dyn_loss_std": 10.525769233703613, "eval/image_loss_mean": 8.726694107055664, "eval/image_loss_std": 13.33502197265625, "eval/model_loss_mean": 18.841875076293945, "eval/model_loss_std": 17.595556259155273, "eval/post_ent_mag": 57.0126838684082, "eval/post_ent_max": 57.0126838684082, "eval/post_ent_mean": 40.289119720458984, "eval/post_ent_min": 18.038938522338867, "eval/post_ent_std": 7.525383949279785, "eval/prior_ent_mag": 66.46202087402344, "eval/prior_ent_max": 66.46202087402344, "eval/prior_ent_mean": 54.84650421142578, "eval/prior_ent_min": 39.631011962890625, "eval/prior_ent_std": 3.6816890239715576, "eval/rep_loss_mean": 16.73096466064453, "eval/rep_loss_std": 10.525769233703613, "eval/reward_avg": 0.03935546800494194, "eval/reward_loss_mean": 0.07554424554109573, "eval/reward_loss_std": 0.375665545463562, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0018126964569092, "eval/reward_neg_acc": 0.9928643703460693, "eval/reward_neg_loss": 0.029245436191558838, "eval/reward_pos_acc": 0.8837209343910217, "eval/reward_pos_loss": 1.1318031549453735, "eval/reward_pred": 0.03603817895054817, "eval/reward_rate": 0.0419921875, "replay/size": 770833.0, "replay/inserts": 21904.0, "replay/samples": 21904.0, "replay/insert_wait_avg": 1.3009617152746966e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.395286295342568e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 7816.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0824923383542922e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.3537561893463, "timer/env.step_count": 2738.0, "timer/env.step_total": 220.01922607421875, "timer/env.step_frac": 0.2199414204354461, "timer/env.step_avg": 0.08035764283207406, "timer/env.step_min": 0.02257513999938965, "timer/env.step_max": 3.5022058486938477, "timer/replay._sample_count": 21904.0, "timer/replay._sample_total": 11.14668321609497, "timer/replay._sample_frac": 0.011142741402357602, "timer/replay._sample_avg": 0.0005088880211876813, "timer/replay._sample_min": 0.0003905296325683594, "timer/replay._sample_max": 0.010353326797485352, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3715.0, "timer/agent.policy_total": 60.26409101486206, "timer/agent.policy_frac": 0.06024277975865901, "timer/agent.policy_avg": 0.016221827998616975, "timer/agent.policy_min": 0.009283304214477539, "timer/agent.policy_max": 0.10365533828735352, "timer/dataset_train_count": 1369.0, "timer/dataset_train_total": 0.1480412483215332, "timer/dataset_train_frac": 0.0001479888963335007, "timer/dataset_train_avg": 0.00010813823836488912, "timer/dataset_train_min": 9.179115295410156e-05, "timer/dataset_train_max": 0.0022802352905273438, "timer/agent.train_count": 1369.0, "timer/agent.train_total": 617.7937898635864, "timer/agent.train_frac": 0.6175753187721832, "timer/agent.train_avg": 0.4512737690749353, "timer/agent.train_min": 0.43776535987854004, "timer/agent.train_max": 1.6258113384246826, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4779939651489258, "timer/agent.report_frac": 0.0004778249316219405, "timer/agent.report_avg": 0.2389969825744629, "timer/agent.report_min": 0.23322033882141113, "timer/agent.report_max": 0.24477362632751465, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979178335994007e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 21.89593615563848}
{"step": 771392, "time": 35329.157418489456, "episode/length": 209.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 771584, "time": 35337.6405851841, "episode/length": 183.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 771704, "time": 35343.007742881775, "episode/length": 245.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 772384, "time": 35367.501457452774, "episode/length": 268.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 772384, "time": 35367.51120352745, "episode/length": 183.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 772952, "time": 35390.170516490936, "episode/length": 194.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 772968, "time": 35392.3292632103, "episode/length": 297.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 773096, "time": 35398.106399059296, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 773800, "time": 35423.881652355194, "episode/length": 345.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9971098265895953, "episode/intrinsic_return": 0.0}
{"step": 773936, "time": 35430.14143371582, "episode/length": 193.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 774008, "time": 35433.916102170944, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976897689768977, "episode/intrinsic_return": 0.0}
{"step": 774088, "time": 35438.28982949257, "episode/length": 297.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 774312, "time": 35447.68972992897, "episode/length": 240.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 774512, "time": 35456.610365867615, "episode/length": 194.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 774552, "time": 35459.27041745186, "episode/length": 197.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 775096, "time": 35479.353038072586, "episode/length": 161.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 775320, "time": 35488.37959766388, "episode/length": 277.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9856115107913669, "episode/intrinsic_return": 0.0}
{"step": 775424, "time": 35493.60063290596, "episode/length": 176.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 775832, "time": 35508.572033405304, "episode/length": 236.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 775944, "time": 35513.82297682762, "episode/length": 231.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9956896551724138, "episode/intrinsic_return": 0.0}
{"step": 776128, "time": 35521.821590185165, "episode/length": 36.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 776256, "time": 35527.59648871422, "episode/length": 217.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 776552, "time": 35538.85487508774, "episode/length": 249.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.996, "episode/intrinsic_return": 0.0}
{"step": 776632, "time": 35543.22853446007, "episode/length": 191.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 776872, "time": 35552.76856613159, "episode/length": 319.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.98125, "episode/intrinsic_return": 0.0}
{"step": 777128, "time": 35562.957649707794, "episode/length": 225.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 777144, "time": 35565.137161016464, "episode/length": 214.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 777392, "time": 35575.08725500107, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 777584, "time": 35582.95178818703, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 777864, "time": 35593.66113567352, "episode/length": 216.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9815668202764977, "episode/intrinsic_return": 0.0}
{"step": 778392, "time": 35614.659534454346, "episode/length": 229.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 778696, "time": 35626.48572731018, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 778704, "time": 35628.544741392136, "episode/length": 194.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 779040, "time": 35641.3461997509, "episode/length": 181.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 779360, "time": 35653.59748339653, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9903536977491961, "episode/intrinsic_return": 0.0}
{"step": 779416, "time": 35656.726551771164, "episode/length": 46.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9148936170212766, "episode/intrinsic_return": 0.0}
{"step": 779448, "time": 35659.34289288521, "episode/length": 351.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9971590909090909, "episode/intrinsic_return": 0.0}
{"step": 779760, "time": 35672.32103943825, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 779800, "time": 35675.44841361046, "episode/length": 137.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9927536231884058, "episode/intrinsic_return": 0.0}
{"step": 779992, "time": 35684.10395669937, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 780000, "time": 35705.61014986038, "eval_episode/length": 48.0, "eval_episode/score": 2.099999986588955, "eval_episode/reward_rate": 0.8979591836734694}
{"step": 780000, "time": 35711.792669057846, "eval_episode/length": 142.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.993006993006993}
{"step": 780000, "time": 35713.54219484329, "eval_episode/length": 146.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9659863945578231}
{"step": 780000, "time": 35716.57661867142, "eval_episode/length": 180.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9723756906077348}
{"step": 780000, "time": 35719.03163957596, "eval_episode/length": 202.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9655172413793104}
{"step": 780000, "time": 35721.431606054306, "eval_episode/length": 173.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 780000, "time": 35723.10434103012, "eval_episode/length": 224.0, "eval_episode/score": 8.099999979138374, "eval_episode/reward_rate": 0.9955555555555555}
{"step": 780000, "time": 35725.05203962326, "eval_episode/length": 232.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9957081545064378}
{"step": 780584, "time": 35744.210555553436, "episode/length": 152.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 780656, "time": 35748.29504275322, "episode/length": 150.0, "episode/score": 1.099999986588955, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 780784, "time": 35754.00379419327, "episode/length": 456.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9978118161925602, "episode/intrinsic_return": 0.0}
{"step": 781304, "time": 35772.756566524506, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 781768, "time": 35789.74524760246, "episode/length": 487.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9877049180327869, "episode/intrinsic_return": 0.0}
{"step": 781896, "time": 35795.52906417847, "episode/length": 309.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 782056, "time": 35802.535413980484, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 782120, "time": 35806.268946647644, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 782208, "time": 35810.93585443497, "episode/length": 300.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 782336, "time": 35816.59156394005, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 782536, "time": 35824.582195043564, "episode/length": 79.0, "episode/score": 7.099999964237213, "episode/reward_rate": 0.95, "episode/intrinsic_return": 0.0}
{"step": 782696, "time": 35831.58320856094, "episode/length": 173.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 782880, "time": 35839.47504210472, "episode/length": 360.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9861495844875346, "episode/intrinsic_return": 0.0}
{"step": 783256, "time": 35853.480236530304, "episode/length": 149.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 783624, "time": 35868.026458501816, "episode/length": 187.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 783960, "time": 35880.7251226902, "episode/length": 202.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 784032, "time": 35884.85133433342, "episode/length": 186.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9946524064171123, "episode/intrinsic_return": 0.0}
{"step": 784416, "time": 35899.26704740524, "episode/length": 144.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9724137931034482, "episode/intrinsic_return": 0.0}
{"step": 784440, "time": 35901.3653922081, "episode/length": 333.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9940119760479041, "episode/intrinsic_return": 0.0}
{"step": 784456, "time": 35903.4545276165, "episode/length": 196.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9796954314720813, "episode/intrinsic_return": 0.0}
{"step": 784672, "time": 35912.35752916336, "episode/length": 246.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 784888, "time": 35920.916040182114, "episode/length": 55.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 784984, "time": 35925.657806396484, "episode/length": 169.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 785288, "time": 35937.2904613018, "episode/length": 384.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9896103896103896, "episode/intrinsic_return": 0.0}
{"step": 786200, "time": 35969.74203801155, "episode/length": 279.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 786224, "time": 35972.29041624069, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 786280, "time": 35975.534698963165, "episode/length": 200.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 786720, "time": 35993.887607336044, "episode/length": 228.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 786984, "time": 36004.76083731651, "episode/length": 249.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976, "episode/intrinsic_return": 0.0}
{"step": 787112, "time": 36011.225434064865, "episode/length": 336.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9910979228486647, "episode/intrinsic_return": 0.0}
{"step": 787360, "time": 36021.26085758209, "episode/length": 258.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 787456, "time": 36025.96020960808, "episode/length": 427.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 787720, "time": 36036.22044587135, "episode/length": 186.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9732620320855615, "episode/intrinsic_return": 0.0}
{"step": 787824, "time": 36042.19590091705, "episode/length": 202.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 788472, "time": 36065.59580731392, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 788552, "time": 36069.93602490425, "episode/length": 283.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 788760, "time": 36078.46026420593, "episode/length": 221.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 788832, "time": 36082.62838745117, "episode/length": 183.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 789544, "time": 36107.66244268417, "episode/length": 303.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 789720, "time": 36115.071243047714, "episode/length": 236.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 789920, "time": 36123.4583864212, "episode/length": 274.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 790088, "time": 36149.56974983215, "eval_episode/length": 153.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.974025974025974}
{"step": 790088, "time": 36151.800297260284, "eval_episode/length": 169.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9941176470588236}
{"step": 790088, "time": 36153.45913696289, "eval_episode/length": 172.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9653179190751445}
{"step": 790088, "time": 36155.17162942886, "eval_episode/length": 176.0, "eval_episode/score": 4.100000001490116, "eval_episode/reward_rate": 0.96045197740113}
{"step": 790088, "time": 36157.81802940369, "eval_episode/length": 202.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9802955665024631}
{"step": 790088, "time": 36159.84971666336, "eval_episode/length": 211.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9952830188679245}
{"step": 790088, "time": 36161.67541670799, "eval_episode/length": 217.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.963302752293578}
{"step": 790088, "time": 36163.55615401268, "eval_episode/length": 222.0, "eval_episode/score": 7.099999971687794, "eval_episode/reward_rate": 0.9955156950672646}
{"step": 790464, "time": 36176.21587014198, "episode/length": 375.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 790520, "time": 36179.46986222267, "episode/length": 219.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 790536, "time": 36181.54060959816, "episode/length": 247.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 790656, "time": 36187.1626970768, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 790808, "time": 36193.639038562775, "episode/length": 135.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9926470588235294, "episode/intrinsic_return": 0.0}
{"step": 790840, "time": 36196.37629842758, "episode/length": 250.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 791344, "time": 36214.80828976631, "episode/length": 224.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 791616, "time": 36225.574788331985, "episode/length": 143.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 792136, "time": 36244.60081791878, "episode/length": 199.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 792200, "time": 36248.78026008606, "episode/length": 192.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 792456, "time": 36259.70890402794, "episode/length": 241.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9958677685950413, "episode/intrinsic_return": 0.0}
{"step": 792600, "time": 36266.63659620285, "episode/length": 223.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 792680, "time": 36270.78656077385, "episode/length": 229.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 792984, "time": 36282.57695031166, "episode/length": 204.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9951219512195122, "episode/intrinsic_return": 0.0}
{"step": 793544, "time": 36302.596600055695, "episode/length": 167.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 794208, "time": 36326.493247509, "episode/length": 218.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 794209, "time": 36328.68171834946, "train_stats/sum_log_reward": 9.419587881141101, "train_stats/max_log_achievement_collect_coal": 0.44329896907216493, "train_stats/max_log_achievement_collect_drink": 4.690721649484536, "train_stats/max_log_achievement_collect_sapling": 1.5670103092783505, "train_stats/max_log_achievement_collect_stone": 7.628865979381444, "train_stats/max_log_achievement_collect_wood": 11.164948453608247, "train_stats/max_log_achievement_defeat_skeleton": 0.020618556701030927, "train_stats/max_log_achievement_defeat_zombie": 0.845360824742268, "train_stats/max_log_achievement_eat_cow": 0.20618556701030927, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.020618556701030927, "train_stats/max_log_achievement_make_wood_pickaxe": 1.5463917525773196, "train_stats/max_log_achievement_make_wood_sword": 1.3402061855670102, "train_stats/max_log_achievement_place_furnace": 0.030927835051546393, "train_stats/max_log_achievement_place_plant": 1.5051546391752577, "train_stats/max_log_achievement_place_stone": 6.804123711340206, "train_stats/max_log_achievement_place_table": 2.948453608247423, "train_stats/max_log_achievement_wake_up": 1.4536082474226804, "train_stats/mean_log_entropy": 0.5715591584898762, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.512487451513331, "train/action_min": 0.0, "train/action_std": 3.266974694245345, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03285744020363668, "train/actor_opt_grad_steps": 48830.0, "train/actor_opt_loss": -7.543824495864915, "train/adv_mag": 0.4215745617459704, "train/adv_max": 0.37326051180179304, "train/adv_mean": 0.0022403750574937534, "train/adv_min": -0.357161214510044, "train/adv_std": 0.049524740114078654, "train/cont_avg": 0.9952469405594405, "train/cont_loss_mean": 0.0002265443679652572, "train/cont_loss_std": 0.006581822677096975, "train/cont_neg_acc": 0.9916083929422018, "train/cont_neg_loss": 0.028474001150097284, "train/cont_pos_acc": 0.9999656839804216, "train/cont_pos_loss": 0.00010052034471586834, "train/cont_pred": 0.9952477175039012, "train/cont_rate": 0.9952469405594405, "train/dyn_loss_mean": 13.496252313360468, "train/dyn_loss_std": 9.066784965408432, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9174972447482023, "train/extr_critic_critic_opt_grad_steps": 48830.0, "train/extr_critic_critic_opt_loss": 15768.267687390735, "train/extr_critic_mag": 9.44946838592316, "train/extr_critic_max": 9.44946838592316, "train/extr_critic_mean": 2.86421756060807, "train/extr_critic_min": -0.16285427717062143, "train/extr_critic_std": 2.288208918137984, "train/extr_return_normed_mag": 1.4692807647731754, "train/extr_return_normed_max": 1.4692807647731754, "train/extr_return_normed_mean": 0.38591693518878695, "train/extr_return_normed_min": -0.09530526949288128, "train/extr_return_normed_std": 0.3257644016009111, "train/extr_return_rate": 0.8184454641142092, "train/extr_return_raw_mag": 10.584780846442376, "train/extr_return_raw_max": 10.584780846442376, "train/extr_return_raw_mean": 2.880169100694723, "train/extr_return_raw_min": -0.5423569286411459, "train/extr_return_raw_std": 2.316874115617125, "train/extr_reward_mag": 1.0350052143310333, "train/extr_reward_max": 1.0350052143310333, "train/extr_reward_mean": 0.04853784562563979, "train/extr_reward_min": -0.47099986943331634, "train/extr_reward_std": 0.2051410895961148, "train/image_loss_mean": 6.656348478544008, "train/image_loss_std": 12.044133856579974, "train/model_loss_mean": 14.81234349070729, "train/model_loss_std": 15.6940740305227, "train/model_opt_grad_norm": 54.95210991443043, "train/model_opt_grad_steps": 48786.93706293706, "train/model_opt_loss": 19312.284657725086, "train/model_opt_model_opt_grad_overflow": 0.006993006993006993, "train/model_opt_model_opt_grad_scale": 1293.7062937062938, "train/policy_entropy_mag": 2.6084256038799154, "train/policy_entropy_max": 2.6084256038799154, "train/policy_entropy_mean": 0.552577585398734, "train/policy_entropy_min": 0.07937502767239417, "train/policy_entropy_std": 0.6679438900697482, "train/policy_logprob_mag": 7.438383702631597, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5537317330603833, "train/policy_logprob_min": -7.438383702631597, "train/policy_logprob_std": 1.1105845545555328, "train/policy_randomness_mag": 0.9206597721660054, "train/policy_randomness_max": 0.9206597721660054, "train/policy_randomness_mean": 0.19503563777966934, "train/policy_randomness_min": 0.028015901406223957, "train/policy_randomness_std": 0.23575488139282574, "train/post_ent_mag": 57.83277450241409, "train/post_ent_max": 57.83277450241409, "train/post_ent_mean": 41.748165077262826, "train/post_ent_min": 19.707100854886995, "train/post_ent_std": 7.474087745159656, "train/prior_ent_mag": 66.70015327080147, "train/prior_ent_max": 66.70015327080147, "train/prior_ent_mean": 55.32402838860359, "train/prior_ent_min": 40.710914931930866, "train/prior_ent_std": 4.157696448839628, "train/rep_loss_mean": 13.496252313360468, "train/rep_loss_std": 9.066784965408432, "train/reward_avg": 0.03157096799020167, "train/reward_loss_mean": 0.05801717435511259, "train/reward_loss_std": 0.25511210562882725, "train/reward_max_data": 1.0160839199186205, "train/reward_max_pred": 1.011511735149197, "train/reward_neg_acc": 0.9923924028456628, "train/reward_neg_loss": 0.029137166086714586, "train/reward_pos_acc": 0.9712222914595704, "train/reward_pos_loss": 0.8357549343075785, "train/reward_pred": 0.03098378877539735, "train/reward_rate": 0.03594159746503497, "eval_stats/sum_log_reward": 8.03750017285347, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 4.5625, "eval_stats/max_log_achievement_collect_sapling": 1.25, "eval_stats/max_log_achievement_collect_stone": 3.75, "eval_stats/max_log_achievement_collect_wood": 10.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.1875, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.1875, "eval_stats/max_log_achievement_place_stone": 3.4375, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.00011207925854250789, "report/cont_loss_std": 0.0016583201941102743, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00482017919421196, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 7.033256406430155e-05, "report/cont_pred": 0.9911832809448242, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 11.438308715820312, "report/dyn_loss_std": 9.354013442993164, "report/image_loss_mean": 5.400485038757324, "report/image_loss_std": 14.396540641784668, "report/model_loss_mean": 12.323023796081543, "report/model_loss_std": 18.09260368347168, "report/post_ent_mag": 56.38412857055664, "report/post_ent_max": 56.38412857055664, "report/post_ent_mean": 43.315162658691406, "report/post_ent_min": 20.583641052246094, "report/post_ent_std": 7.474492073059082, "report/prior_ent_mag": 66.51458740234375, "report/prior_ent_max": 66.51458740234375, "report/prior_ent_mean": 54.63649368286133, "report/prior_ent_min": 41.19989013671875, "report/prior_ent_std": 3.947629690170288, "report/rep_loss_mean": 11.438308715820312, "report/rep_loss_std": 9.354013442993164, "report/reward_avg": 0.03144530951976776, "report/reward_loss_mean": 0.05944163352251053, "report/reward_loss_std": 0.19757871329784393, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0024223327636719, "report/reward_neg_acc": 0.989847719669342, "report/reward_neg_loss": 0.03473731502890587, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.6833840608596802, "report/reward_pred": 0.03293100371956825, "report/reward_rate": 0.0380859375, "eval/cont_avg": 0.994140625, "eval/cont_loss_mean": 5.738216350437142e-05, "eval/cont_loss_std": 0.0012340850662440062, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0027876626700162888, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.129013541387394e-05, "eval/cont_pred": 0.9941164255142212, "eval/cont_rate": 0.994140625, "eval/dyn_loss_mean": 18.852458953857422, "eval/dyn_loss_std": 10.810697555541992, "eval/image_loss_mean": 14.484603881835938, "eval/image_loss_std": 16.436649322509766, "eval/model_loss_mean": 25.89504623413086, "eval/model_loss_std": 20.929574966430664, "eval/post_ent_mag": 55.862030029296875, "eval/post_ent_max": 55.862030029296875, "eval/post_ent_mean": 39.686012268066406, "eval/post_ent_min": 16.59372329711914, "eval/post_ent_std": 7.227001667022705, "eval/prior_ent_mag": 66.51458740234375, "eval/prior_ent_max": 66.51458740234375, "eval/prior_ent_mean": 55.753273010253906, "eval/prior_ent_min": 43.288578033447266, "eval/prior_ent_std": 3.809837818145752, "eval/rep_loss_mean": 18.852458953857422, "eval/rep_loss_std": 10.810697555541992, "eval/reward_avg": 0.03212890774011612, "eval/reward_loss_mean": 0.09890833497047424, "eval/reward_loss_std": 0.44909408688545227, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0090117454528809, "eval/reward_neg_acc": 0.9837728142738342, "eval/reward_neg_loss": 0.05308638885617256, "eval/reward_pos_acc": 0.8421052694320679, "eval/reward_pos_loss": 1.2878674268722534, "eval/reward_pred": 0.03143969178199768, "eval/reward_rate": 0.037109375, "replay/size": 793705.0, "replay/inserts": 22872.0, "replay/samples": 22864.0, "replay/insert_wait_avg": 1.2992207259304584e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.488328814923638e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3648.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1091561693894236e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.450580596923828e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.5143547058105, "timer/env.step_count": 2859.0, "timer/env.step_total": 236.48916816711426, "timer/env.step_frac": 0.2361315811959397, "timer/env.step_avg": 0.08271744252085143, "timer/env.step_min": 0.02270984649658203, "timer/env.step_max": 3.4569592475891113, "timer/replay._sample_count": 22864.0, "timer/replay._sample_total": 11.498907566070557, "timer/replay._sample_frac": 0.011481520471514657, "timer/replay._sample_avg": 0.0005029263281171517, "timer/replay._sample_min": 0.0004134178161621094, "timer/replay._sample_max": 0.011205673217773438, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3315.0, "timer/agent.policy_total": 53.13265109062195, "timer/agent.policy_frac": 0.053052311073693376, "timer/agent.policy_avg": 0.01602794904694478, "timer/agent.policy_min": 0.009237289428710938, "timer/agent.policy_max": 0.0905005931854248, "timer/dataset_train_count": 1429.0, "timer/dataset_train_total": 0.19248342514038086, "timer/dataset_train_frac": 0.00019219237770877666, "timer/dataset_train_avg": 0.00013469798820180606, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.042551279067993164, "timer/agent.train_count": 1429.0, "timer/agent.train_total": 642.5785961151123, "timer/agent.train_frac": 0.6416069755723735, "timer/agent.train_avg": 0.4496701162457049, "timer/agent.train_min": 0.43311166763305664, "timer/agent.train_max": 1.599228858947754, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4764246940612793, "timer/agent.report_frac": 0.00047570430900236723, "timer/agent.report_avg": 0.23821234703063965, "timer/agent.report_min": 0.2299191951751709, "timer/agent.report_max": 0.2465054988861084, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.666250437041297e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 22.83707850695892}
{"step": 794288, "time": 36331.55598640442, "episode/length": 162.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 794448, "time": 36338.557970523834, "episode/length": 230.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 794832, "time": 36354.73758649826, "episode/length": 160.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9627329192546584, "episode/intrinsic_return": 0.0}
{"step": 794968, "time": 36362.00250864029, "episode/length": 353.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 794992, "time": 36364.60214829445, "episode/length": 633.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 795056, "time": 36368.77705287933, "episode/length": 296.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9966329966329966, "episode/intrinsic_return": 0.0}
{"step": 795368, "time": 36381.43603038788, "episode/length": 468.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9936034115138592, "episode/intrinsic_return": 0.0}
{"step": 795576, "time": 36389.8682911396, "episode/length": 160.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9565217391304348, "episode/intrinsic_return": 0.0}
{"step": 796232, "time": 36413.22593307495, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 796296, "time": 36416.93140745163, "episode/length": 165.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 796528, "time": 36426.366871118546, "episode/length": 211.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 796536, "time": 36427.926542043686, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 796856, "time": 36440.3401222229, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 796864, "time": 36442.430594205856, "episode/length": 70.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9859154929577465, "episode/intrinsic_return": 0.0}
{"step": 796920, "time": 36445.62498641014, "episode/length": 232.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 797496, "time": 36466.25800991058, "episode/length": 157.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 798000, "time": 36484.69374251366, "episode/length": 473.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9852320675105485, "episode/intrinsic_return": 0.0}
{"step": 798192, "time": 36492.86077332497, "episode/length": 207.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 798312, "time": 36498.2477247715, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 798528, "time": 36507.31695795059, "episode/length": 208.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 798624, "time": 36512.11011695862, "episode/length": 219.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 799000, "time": 36526.12337183952, "episode/length": 427.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9789719626168224, "episode/intrinsic_return": 0.0}
{"step": 799144, "time": 36532.41447305679, "episode/length": 64.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 799216, "time": 36536.56679058075, "episode/length": 214.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 799600, "time": 36551.06231379509, "episode/length": 199.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 799848, "time": 36561.433252334595, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 799944, "time": 36566.11752486229, "episode/length": 218.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 800064, "time": 36571.84055900574, "episode/length": 218.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 800072, "time": 36588.70139288902, "eval_episode/length": 55.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9821428571428571}
{"step": 800072, "time": 36593.8304977417, "eval_episode/length": 149.0, "eval_episode/score": 7.100000023841858, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 800072, "time": 36595.728499650955, "eval_episode/length": 157.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 800072, "time": 36597.569555044174, "eval_episode/length": 165.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9698795180722891}
{"step": 800072, "time": 36599.350600004196, "eval_episode/length": 170.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9590643274853801}
{"step": 800072, "time": 36599.36521196365, "eval_episode/length": 170.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9766081871345029}
{"step": 800072, "time": 36603.770631074905, "eval_episode/length": 192.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 800072, "time": 36607.81816959381, "eval_episode/length": 255.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.984375}
{"step": 800672, "time": 36627.835852622986, "episode/length": 181.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 800808, "time": 36633.69209814072, "episode/length": 225.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 800896, "time": 36638.33168673515, "episode/length": 544.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9871559633027523, "episode/intrinsic_return": 0.0}
{"step": 800992, "time": 36643.23026943207, "episode/length": 230.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 801552, "time": 36663.45856261253, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 801568, "time": 36666.00278425217, "episode/length": 202.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9950738916256158, "episode/intrinsic_return": 0.0}
{"step": 801608, "time": 36669.03314423561, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9844559585492227, "episode/intrinsic_return": 0.0}
{"step": 801920, "time": 36682.18000745773, "episode/length": 289.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 802176, "time": 36692.93251013756, "episode/length": 170.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 802416, "time": 36702.52487516403, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 802416, "time": 36702.53553509712, "episode/length": 217.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 802880, "time": 36722.851860523224, "episode/length": 163.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 803016, "time": 36728.85226082802, "episode/length": 182.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 803544, "time": 36748.83997273445, "episode/length": 330.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 803624, "time": 36753.198786497116, "episode/length": 212.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 803720, "time": 36758.13634109497, "episode/length": 263.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9734848484848485, "episode/intrinsic_return": 0.0}
{"step": 803968, "time": 36768.33046460152, "episode/length": 193.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 804128, "time": 36775.33152627945, "episode/length": 243.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 804296, "time": 36782.17945766449, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 804360, "time": 36785.749967098236, "episode/length": 184.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 804648, "time": 36796.88897228241, "episode/length": 203.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 804872, "time": 36805.88030338287, "episode/length": 63.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 805144, "time": 36816.59178233147, "episode/length": 199.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 805392, "time": 36827.039190769196, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9620253164556962, "episode/intrinsic_return": 0.0}
{"step": 805424, "time": 36830.09775018692, "episode/length": 181.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 805528, "time": 36835.53398013115, "episode/length": 225.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9734513274336283, "episode/intrinsic_return": 0.0}
{"step": 805576, "time": 36838.80557346344, "episode/length": 87.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9431818181818182, "episode/intrinsic_return": 0.0}
{"step": 805584, "time": 36840.88924050331, "episode/length": 54.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 805584, "time": 36840.89759135246, "episode/length": 160.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9937888198757764, "episode/intrinsic_return": 0.0}
{"step": 806192, "time": 36864.52931022644, "episode/length": 320.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9937694704049844, "episode/intrinsic_return": 0.0}
{"step": 806624, "time": 36880.438124895096, "episode/length": 129.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9538461538461539, "episode/intrinsic_return": 0.0}
{"step": 807136, "time": 36899.11321473122, "episode/length": 310.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9839228295819936, "episode/intrinsic_return": 0.0}
{"step": 807256, "time": 36904.56270027161, "episode/length": 215.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 807544, "time": 36915.84013366699, "episode/length": 244.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 807696, "time": 36922.69531416893, "episode/length": 283.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 807896, "time": 36930.70958805084, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 808512, "time": 36953.13243293762, "episode/length": 235.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 808608, "time": 36957.880252599716, "episode/length": 88.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9438202247191011, "episode/intrinsic_return": 0.0}
{"step": 808688, "time": 36962.13833999634, "episode/length": 411.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9975728155339806, "episode/intrinsic_return": 0.0}
{"step": 809016, "time": 36974.72647166252, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9575757575757575, "episode/intrinsic_return": 0.0}
{"step": 809232, "time": 36984.26506304741, "episode/length": 210.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 809320, "time": 36988.486530303955, "episode/length": 390.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.989769820971867, "episode/intrinsic_return": 0.0}
{"step": 810056, "time": 37035.82475614548, "eval_episode/length": 155.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9743589743589743}
{"step": 810056, "time": 37038.972571372986, "eval_episode/length": 186.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9732620320855615}
{"step": 810056, "time": 37041.3479616642, "eval_episode/length": 204.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9707317073170731}
{"step": 810056, "time": 37043.38883280754, "eval_episode/length": 215.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9768518518518519}
{"step": 810056, "time": 37045.02753281593, "eval_episode/length": 218.0, "eval_episode/score": 12.099999994039536, "eval_episode/reward_rate": 0.9908675799086758}
{"step": 810056, "time": 37049.00123715401, "eval_episode/length": 274.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9745454545454545}
{"step": 810056, "time": 37053.42381024361, "eval_episode/length": 337.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9881656804733728}
{"step": 810056, "time": 37055.978878736496, "eval_episode/length": 205.0, "eval_episode/score": 10.100000038743019, "eval_episode/reward_rate": 0.9805825242718447}
{"step": 810072, "time": 37056.52383971214, "episode/length": 194.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 810232, "time": 37063.393166065216, "episode/length": 371.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9865591397849462, "episode/intrinsic_return": 0.0}
{"step": 810280, "time": 37066.59334206581, "episode/length": 208.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 810600, "time": 37078.89557719231, "episode/length": 432.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9953810623556582, "episode/intrinsic_return": 0.0}
{"step": 810744, "time": 37085.8689661026, "episode/length": 177.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 810960, "time": 37095.43286275864, "episode/length": 283.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 811344, "time": 37111.36562657356, "episode/length": 290.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.993127147766323, "episode/intrinsic_return": 0.0}
{"step": 811560, "time": 37119.90473985672, "episode/length": 159.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9625, "episode/intrinsic_return": 0.0}
{"step": 811808, "time": 37129.9693043232, "episode/length": 321.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 812208, "time": 37144.80972409248, "episode/length": 155.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.967948717948718, "episode/intrinsic_return": 0.0}
{"step": 812240, "time": 37147.49703836441, "episode/length": 186.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.983957219251337, "episode/intrinsic_return": 0.0}
{"step": 812272, "time": 37150.291362047195, "episode/length": 254.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 812896, "time": 37172.35766839981, "episode/length": 286.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 813616, "time": 37198.02003979683, "episode/length": 175.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 813640, "time": 37200.10597753525, "episode/length": 259.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 813672, "time": 37202.729719638824, "episode/length": 178.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 813680, "time": 37204.85694408417, "episode/length": 291.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.976027397260274, "episode/intrinsic_return": 0.0}
{"step": 813968, "time": 37216.194123506546, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 814136, "time": 37223.018739938736, "episode/length": 507.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9822834645669292, "episode/intrinsic_return": 0.0}
{"step": 814320, "time": 37230.81682085991, "episode/length": 313.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 814616, "time": 37242.039433956146, "episode/length": 214.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 815120, "time": 37260.419185876846, "episode/length": 187.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 815168, "time": 37263.61678528786, "episode/length": 186.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 815464, "time": 37274.792313575745, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 815656, "time": 37282.6970539093, "episode/length": 246.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 815816, "time": 37289.569098472595, "episode/length": 209.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 816184, "time": 37303.357412576675, "episode/length": 232.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9742489270386266, "episode/intrinsic_return": 0.0}
{"step": 816504, "time": 37315.48137140274, "episode/length": 235.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 816825, "time": 37329.08317518234, "train_stats/sum_log_reward": 9.293877737862724, "train_stats/max_log_achievement_collect_coal": 0.2755102040816326, "train_stats/max_log_achievement_collect_drink": 6.051020408163265, "train_stats/max_log_achievement_collect_sapling": 1.816326530612245, "train_stats/max_log_achievement_collect_stone": 7.285714285714286, "train_stats/max_log_achievement_collect_wood": 11.346938775510203, "train_stats/max_log_achievement_defeat_skeleton": 0.061224489795918366, "train_stats/max_log_achievement_defeat_zombie": 0.8571428571428571, "train_stats/max_log_achievement_eat_cow": 0.2653061224489796, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01020408163265306, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3775510204081634, "train_stats/max_log_achievement_make_wood_sword": 1.346938775510204, "train_stats/max_log_achievement_place_furnace": 0.05102040816326531, "train_stats/max_log_achievement_place_plant": 1.7346938775510203, "train_stats/max_log_achievement_place_stone": 6.530612244897959, "train_stats/max_log_achievement_place_table": 2.816326530612245, "train_stats/max_log_achievement_wake_up": 1.6020408163265305, "train_stats/mean_log_entropy": 0.6027319534700744, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.423396983045213, "train/action_min": 0.0, "train/action_std": 3.2136246430958417, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.033391276004572285, "train/actor_opt_grad_steps": 50250.0, "train/actor_opt_loss": -10.302828254534843, "train/adv_mag": 0.4524407272643231, "train/adv_max": 0.40030085850269237, "train/adv_mean": 0.002130640620912313, "train/adv_min": -0.38148582372682316, "train/adv_std": 0.0504077487750679, "train/cont_avg": 0.994957890070922, "train/cont_loss_mean": 0.00012588338890335318, "train/cont_loss_std": 0.0037469806860204336, "train/cont_neg_acc": 0.9952038372163292, "train/cont_neg_loss": 0.018864990924255757, "train/cont_pos_acc": 0.9999790673560285, "train/cont_pos_loss": 4.059607587470242e-05, "train/cont_pred": 0.9949660330799455, "train/cont_rate": 0.994957890070922, "train/dyn_loss_mean": 13.436636769179756, "train/dyn_loss_std": 9.075277639619003, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9640898061982284, "train/extr_critic_critic_opt_grad_steps": 50250.0, "train/extr_critic_critic_opt_loss": 15941.738689882535, "train/extr_critic_mag": 9.393830272322852, "train/extr_critic_max": 9.393830272322852, "train/extr_critic_mean": 2.798154075094994, "train/extr_critic_min": -0.1703290567330435, "train/extr_critic_std": 2.2898284103853483, "train/extr_return_normed_mag": 1.4838516703734161, "train/extr_return_normed_max": 1.4838516703734161, "train/extr_return_normed_mean": 0.38617509793727955, "train/extr_return_normed_min": -0.08923450096490536, "train/extr_return_normed_std": 0.3300042176711644, "train/extr_return_rate": 0.8011160467533355, "train/extr_return_raw_mag": 10.52317840495008, "train/extr_return_raw_max": 10.52317840495008, "train/extr_return_raw_mean": 2.8131128997667463, "train/extr_return_raw_min": -0.5272169480932519, "train/extr_return_raw_std": 2.3183817373099904, "train/extr_reward_mag": 1.0419218337282221, "train/extr_reward_max": 1.0419218337282221, "train/extr_reward_mean": 0.048485939331511234, "train/extr_reward_min": -0.45191598868539146, "train/extr_reward_std": 0.20530491739722853, "train/image_loss_mean": 6.506523196578871, "train/image_loss_std": 11.945353771777864, "train/model_loss_mean": 14.628094936938997, "train/model_loss_std": 15.567592681722438, "train/model_opt_grad_norm": 54.562235379049966, "train/model_opt_grad_steps": 50205.5390070922, "train/model_opt_loss": 18411.610427748226, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.8652482269504, "train/policy_entropy_mag": 2.6398355115389993, "train/policy_entropy_max": 2.6398355115389993, "train/policy_entropy_mean": 0.5638651418770458, "train/policy_entropy_min": 0.07937502728920456, "train/policy_entropy_std": 0.67329023218324, "train/policy_logprob_mag": 7.438383795690875, "train/policy_logprob_max": -0.009455659241805263, "train/policy_logprob_mean": -0.5636953390236442, "train/policy_logprob_min": -7.438383795690875, "train/policy_logprob_std": 1.116035928117468, "train/policy_randomness_mag": 0.9317460901348303, "train/policy_randomness_max": 0.9317460901348303, "train/policy_randomness_mean": 0.1990196503011893, "train/policy_randomness_min": 0.028015901327978633, "train/policy_randomness_std": 0.23764190521646053, "train/post_ent_mag": 57.94481410033314, "train/post_ent_max": 57.94481410033314, "train/post_ent_mean": 41.86630462754703, "train/post_ent_min": 19.624180739653028, "train/post_ent_std": 7.49031126076448, "train/prior_ent_mag": 66.73043671736481, "train/prior_ent_max": 66.73043671736481, "train/prior_ent_mean": 55.364734135620985, "train/prior_ent_min": 40.79396500824191, "train/prior_ent_std": 4.103790704240191, "train/rep_loss_mean": 13.436636769179756, "train/rep_loss_std": 9.075277639619003, "train/reward_avg": 0.03212890608222983, "train/reward_loss_mean": 0.05946394188184265, "train/reward_loss_std": 0.2587748825127351, "train/reward_max_data": 1.0170212806539332, "train/reward_max_pred": 1.0114831442528582, "train/reward_neg_acc": 0.9922705246201644, "train/reward_neg_loss": 0.029995154331814735, "train/reward_pos_acc": 0.9729870984740291, "train/reward_pos_loss": 0.8344376624053251, "train/reward_pred": 0.03123708828253315, "train/reward_rate": 0.036742298315602835, "eval_stats/sum_log_reward": 9.537500232458115, "eval_stats/max_log_achievement_collect_coal": 0.4375, "eval_stats/max_log_achievement_collect_drink": 4.5625, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 7.8125, "eval_stats/max_log_achievement_collect_wood": 11.375, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.6875, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 0.0, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 7.1875, "eval_stats/max_log_achievement_place_table": 2.875, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.994140625, "report/cont_loss_mean": 0.0017274889396503568, "report/cont_loss_std": 0.0552280992269516, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 8.661099127493799e-05, "report/cont_pos_acc": 0.9990177154541016, "report/cont_pos_loss": 0.0017371601425111294, "report/cont_pred": 0.9933310151100159, "report/cont_rate": 0.994140625, "report/dyn_loss_mean": 13.0371732711792, "report/dyn_loss_std": 8.933636665344238, "report/image_loss_mean": 6.727921485900879, "report/image_loss_std": 12.039145469665527, "report/model_loss_mean": 14.605597496032715, "report/model_loss_std": 15.305052757263184, "report/post_ent_mag": 57.05345916748047, "report/post_ent_max": 57.05345916748047, "report/post_ent_mean": 41.97544860839844, "report/post_ent_min": 20.146644592285156, "report/post_ent_std": 7.1310601234436035, "report/prior_ent_mag": 66.7646484375, "report/prior_ent_max": 66.7646484375, "report/prior_ent_mean": 55.60337829589844, "report/prior_ent_min": 42.824363708496094, "report/prior_ent_std": 3.895129442214966, "report/rep_loss_mean": 13.0371732711792, "report/rep_loss_std": 8.933636665344238, "report/reward_avg": 0.02714843675494194, "report/reward_loss_mean": 0.05364466458559036, "report/reward_loss_std": 0.18053051829338074, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001213550567627, "report/reward_neg_acc": 0.992929220199585, "report/reward_neg_loss": 0.0303904190659523, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.7307536005973816, "report/reward_pred": 0.02819409966468811, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.757433877486619e-07, "eval/cont_loss_std": 1.549599073769059e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0001958414795808494, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.0258252675375843e-07, "eval/cont_pred": 0.9970707297325134, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.75851058959961, "eval/dyn_loss_std": 10.385234832763672, "eval/image_loss_mean": 12.931770324707031, "eval/image_loss_std": 17.668113708496094, "eval/model_loss_mean": 23.672006607055664, "eval/model_loss_std": 21.795190811157227, "eval/post_ent_mag": 54.54434585571289, "eval/post_ent_max": 54.54434585571289, "eval/post_ent_mean": 40.62290573120117, "eval/post_ent_min": 20.880931854248047, "eval/post_ent_std": 7.33294677734375, "eval/prior_ent_mag": 66.7646484375, "eval/prior_ent_max": 66.7646484375, "eval/prior_ent_mean": 56.827239990234375, "eval/prior_ent_min": 44.59966278076172, "eval/prior_ent_std": 3.4658255577087402, "eval/rep_loss_mean": 17.75851058959961, "eval/rep_loss_std": 10.385234832763672, "eval/reward_avg": 0.029296875, "eval/reward_loss_mean": 0.08512894064188004, "eval/reward_loss_std": 0.5282349586486816, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0029520988464355, "eval/reward_neg_acc": 0.9909090399742126, "eval/reward_neg_loss": 0.03488362208008766, "eval/reward_pos_acc": 0.8235294222831726, "eval/reward_pos_loss": 1.5481542348861694, "eval/reward_pred": 0.025054708123207092, "eval/reward_rate": 0.033203125, "replay/size": 816321.0, "replay/inserts": 22616.0, "replay/samples": 22624.0, "replay/insert_wait_avg": 1.299273727384607e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.453215172806757e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4944.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0853735760191884e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.387309551239, "timer/env.step_count": 2827.0, "timer/env.step_total": 236.82691264152527, "timer/env.step_frac": 0.23673522282860907, "timer/env.step_avg": 0.0837732269690574, "timer/env.step_min": 0.022578954696655273, "timer/env.step_max": 3.3821136951446533, "timer/replay._sample_count": 22624.0, "timer/replay._sample_total": 11.392706871032715, "timer/replay._sample_frac": 0.011388296075190455, "timer/replay._sample_avg": 0.0005035673121920401, "timer/replay._sample_min": 0.0004019737243652344, "timer/replay._sample_max": 0.03016352653503418, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3445.0, "timer/agent.policy_total": 56.41833138465881, "timer/agent.policy_frac": 0.05639648848601184, "timer/agent.policy_avg": 0.016376874131976433, "timer/agent.policy_min": 0.009229183197021484, "timer/agent.policy_max": 0.10254049301147461, "timer/dataset_train_count": 1414.0, "timer/dataset_train_total": 0.14935708045959473, "timer/dataset_train_frac": 0.00014929925543197305, "timer/dataset_train_avg": 0.00010562735534624804, "timer/dataset_train_min": 8.988380432128906e-05, "timer/dataset_train_max": 0.0008597373962402344, "timer/agent.train_count": 1414.0, "timer/agent.train_total": 635.7024776935577, "timer/agent.train_frac": 0.6354563593761757, "timer/agent.train_avg": 0.449577424111427, "timer/agent.train_min": 0.4331820011138916, "timer/agent.train_max": 1.66654634475708, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4748520851135254, "timer/agent.report_frac": 0.0004746682415698955, "timer/agent.report_avg": 0.2374260425567627, "timer/agent.report_min": 0.2313365936279297, "timer/agent.report_max": 0.2435154914855957, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6464462280273438e-05, "timer/dataset_eval_frac": 2.6454216309626176e-08, "timer/dataset_eval_avg": 2.6464462280273438e-05, "timer/dataset_eval_min": 2.6464462280273438e-05, "timer/dataset_eval_max": 2.6464462280273438e-05, "fps": 22.60692934947952}
{"step": 816896, "time": 37331.61412382126, "episode/length": 365.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9890710382513661, "episode/intrinsic_return": 0.0}
{"step": 816936, "time": 37334.28567647934, "episode/length": 226.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 817080, "time": 37340.507863521576, "episode/length": 157.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 817208, "time": 37346.21513772011, "episode/length": 254.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 817336, "time": 37352.05237197876, "episode/length": 233.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9786324786324786, "episode/intrinsic_return": 0.0}
{"step": 818448, "time": 37390.89417076111, "episode/length": 170.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9707602339181286, "episode/intrinsic_return": 0.0}
{"step": 818536, "time": 37395.06994533539, "episode/length": 165.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 818544, "time": 37397.08125567436, "episode/length": 360.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9916897506925207, "episode/intrinsic_return": 0.0}
{"step": 818984, "time": 37413.12022423744, "episode/length": 55.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 819032, "time": 37416.84595513344, "episode/length": 261.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9809160305343512, "episode/intrinsic_return": 0.0}
{"step": 819104, "time": 37421.59721446037, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 819160, "time": 37425.32492184639, "episode/length": 371.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9973118279569892, "episode/intrinsic_return": 0.0}
{"step": 819808, "time": 37450.5770676136, "episode/length": 363.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 820040, "time": 37475.05569219589, "eval_episode/length": 66.0, "eval_episode/score": 5.100000008940697, "eval_episode/reward_rate": 0.9850746268656716}
{"step": 820040, "time": 37481.64495372772, "eval_episode/length": 180.0, "eval_episode/score": 7.100000001490116, "eval_episode/reward_rate": 0.9668508287292817}
{"step": 820040, "time": 37483.438640356064, "eval_episode/length": 185.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9946236559139785}
{"step": 820040, "time": 37485.971388339996, "eval_episode/length": 210.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.995260663507109}
{"step": 820040, "time": 37487.541816949844, "eval_episode/length": 212.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.971830985915493}
{"step": 820040, "time": 37489.421256542206, "eval_episode/length": 37.0, "eval_episode/score": 1.099999986588955, "eval_episode/reward_rate": 0.8947368421052632}
{"step": 820040, "time": 37491.47611641884, "eval_episode/length": 163.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 820040, "time": 37493.356817007065, "eval_episode/length": 239.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9833333333333333}
{"step": 820112, "time": 37495.937473773956, "episode/length": 450.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9800443458980045, "episode/intrinsic_return": 0.0}
{"step": 820416, "time": 37507.42415642738, "episode/length": 163.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 820784, "time": 37521.28943538666, "episode/length": 218.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 820880, "time": 37526.03052663803, "episode/length": 133.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9552238805970149, "episode/intrinsic_return": 0.0}
{"step": 821264, "time": 37540.21219921112, "episode/length": 262.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 821560, "time": 37551.324043512344, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 821784, "time": 37560.53701162338, "episode/length": 349.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9885714285714285, "episode/intrinsic_return": 0.0}
{"step": 821992, "time": 37569.48472762108, "episode/length": 442.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9909706546275395, "episode/intrinsic_return": 0.0}
{"step": 822360, "time": 37583.14118385315, "episode/length": 196.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9746192893401016, "episode/intrinsic_return": 0.0}
{"step": 822672, "time": 37595.35743689537, "episode/length": 223.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 822888, "time": 37603.941426754, "episode/length": 65.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9393939393939394, "episode/intrinsic_return": 0.0}
{"step": 822992, "time": 37609.13902616501, "episode/length": 215.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 823136, "time": 37615.57446169853, "episode/length": 196.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9695431472081218, "episode/intrinsic_return": 0.0}
{"step": 823432, "time": 37626.6348593235, "episode/length": 610.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9852700490998363, "episode/intrinsic_return": 0.0}
{"step": 824112, "time": 37650.98084640503, "episode/length": 264.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 824280, "time": 37657.90687036514, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 824288, "time": 37660.11728429794, "episode/length": 483.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9834710743801653, "episode/intrinsic_return": 0.0}
{"step": 824432, "time": 37666.409937143326, "episode/length": 192.0, "episode/score": 9.099999994039536, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 824560, "time": 37672.205428123474, "episode/length": 195.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9642857142857143, "episode/intrinsic_return": 0.0}
{"step": 824992, "time": 37688.03310465813, "episode/length": 194.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9692307692307692, "episode/intrinsic_return": 0.0}
{"step": 825168, "time": 37695.38046789169, "episode/length": 422.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9976359338061466, "episode/intrinsic_return": 0.0}
{"step": 825656, "time": 37712.75074005127, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9738562091503268, "episode/intrinsic_return": 0.0}
{"step": 826240, "time": 37733.78924822807, "episode/length": 387.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9871134020618557, "episode/intrinsic_return": 0.0}
{"step": 826256, "time": 37735.853820085526, "episode/length": 211.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9764150943396226, "episode/intrinsic_return": 0.0}
{"step": 826584, "time": 37748.026332616806, "episode/length": 286.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 826600, "time": 37750.220398664474, "episode/length": 289.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 826832, "time": 37759.57143545151, "episode/length": 339.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9823529411764705, "episode/intrinsic_return": 0.0}
{"step": 826856, "time": 37761.66535949707, "episode/length": 149.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 827096, "time": 37771.12690234184, "episode/length": 240.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 827128, "time": 37773.8681204319, "episode/length": 266.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9962546816479401, "episode/intrinsic_return": 0.0}
{"step": 827768, "time": 37799.11447954178, "episode/length": 190.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 828008, "time": 37809.39674425125, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 828040, "time": 37812.74575996399, "episode/length": 150.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9735099337748344, "episode/intrinsic_return": 0.0}
{"step": 828136, "time": 37818.0754172802, "episode/length": 159.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 828176, "time": 37821.718668460846, "episode/length": 239.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9958333333333333, "episode/intrinsic_return": 0.0}
{"step": 828488, "time": 37834.17710852623, "episode/length": 169.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 828496, "time": 37836.25440239906, "episode/length": 39.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 828704, "time": 37844.73046851158, "episode/length": 262.0, "episode/score": 11.100000031292439, "episode/reward_rate": 0.9961977186311787, "episode/intrinsic_return": 0.0}
{"step": 829072, "time": 37858.684703826904, "episode/length": 246.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 829488, "time": 37875.101746082306, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.994475138121547, "episode/intrinsic_return": 0.0}
{"step": 829528, "time": 37877.733145713806, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 829608, "time": 37881.814705848694, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9695652173913043, "episode/intrinsic_return": 0.0}
{"step": 829952, "time": 37895.30629110336, "episode/length": 182.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 830024, "time": 37914.82441186905, "eval_episode/length": 57.0, "eval_episode/score": 4.099999971687794, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 830024, "time": 37919.83563756943, "eval_episode/length": 144.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9517241379310345}
{"step": 830024, "time": 37921.993071079254, "eval_episode/length": 157.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9746835443037974}
{"step": 830024, "time": 37924.04115819931, "eval_episode/length": 168.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9704142011834319}
{"step": 830024, "time": 37926.064007520676, "eval_episode/length": 179.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9777777777777777}
{"step": 830024, "time": 37928.53268408775, "eval_episode/length": 196.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9949238578680203}
{"step": 830024, "time": 37932.26707673073, "eval_episode/length": 42.0, "eval_episode/score": 3.0999999716877937, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 830024, "time": 37934.166935920715, "eval_episode/length": 247.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9798387096774194}
{"step": 830184, "time": 37939.424317359924, "episode/length": 184.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9567567567567568, "episode/intrinsic_return": 0.0}
{"step": 830272, "time": 37944.10331106186, "episode/length": 282.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9893992932862191, "episode/intrinsic_return": 0.0}
{"step": 830312, "time": 37946.87209320068, "episode/length": 226.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 831016, "time": 37971.59892845154, "episode/length": 175.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 831056, "time": 37974.72024130821, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 831240, "time": 37982.10506772995, "episode/length": 270.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 831288, "time": 37985.32140946388, "episode/length": 166.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9700598802395209, "episode/intrinsic_return": 0.0}
{"step": 831896, "time": 38006.98963308334, "episode/length": 295.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 832064, "time": 38014.33763360977, "episode/length": 218.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 832904, "time": 38043.889978170395, "episode/length": 328.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9756838905775076, "episode/intrinsic_return": 0.0}
{"step": 832968, "time": 38048.14404773712, "episode/length": 243.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 833208, "time": 38058.45506024361, "episode/length": 268.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 833544, "time": 38071.75746464729, "episode/length": 205.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.970873786407767, "episode/intrinsic_return": 0.0}
{"step": 833752, "time": 38080.430836200714, "episode/length": 445.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9798206278026906, "episode/intrinsic_return": 0.0}
{"step": 834008, "time": 38090.47945642471, "episode/length": 339.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 834240, "time": 38100.599888563156, "episode/length": 271.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 834648, "time": 38116.03559970856, "episode/length": 425.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 834744, "time": 38120.73517990112, "episode/length": 221.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 834912, "time": 38128.05692625046, "episode/length": 212.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 835040, "time": 38133.767169475555, "episode/length": 186.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9625668449197861, "episode/intrinsic_return": 0.0}
{"step": 835328, "time": 38144.86515378952, "episode/length": 302.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9966996699669967, "episode/intrinsic_return": 0.0}
{"step": 835952, "time": 38168.41247820854, "episode/length": 274.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 836224, "time": 38179.16987609863, "episode/length": 247.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9798387096774194, "episode/intrinsic_return": 0.0}
{"step": 836456, "time": 38188.16625928879, "episode/length": 225.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9778761061946902, "episode/intrinsic_return": 0.0}
{"step": 837080, "time": 38210.43948698044, "episode/length": 270.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.974169741697417, "episode/intrinsic_return": 0.0}
{"step": 837208, "time": 38216.23585486412, "episode/length": 399.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 837272, "time": 38220.036922454834, "episode/length": 242.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9958847736625515, "episode/intrinsic_return": 0.0}
{"step": 837360, "time": 38224.7320599556, "episode/length": 326.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9969418960244648, "episode/intrinsic_return": 0.0}
{"step": 838160, "time": 38253.155215740204, "episode/length": 389.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9897435897435898, "episode/intrinsic_return": 0.0}
{"step": 838504, "time": 38265.97583794594, "episode/length": 284.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9859649122807017, "episode/intrinsic_return": 0.0}
{"step": 838640, "time": 38272.25522661209, "episode/length": 194.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 838936, "time": 38283.41325831413, "episode/length": 207.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 839024, "time": 38288.03605055809, "episode/length": 320.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9906542056074766, "episode/intrinsic_return": 0.0}
{"step": 839408, "time": 38302.30470585823, "episode/length": 255.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.98046875, "episode/intrinsic_return": 0.0}
{"step": 839504, "time": 38307.08596467972, "episode/length": 443.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9797297297297297, "episode/intrinsic_return": 0.0}
{"step": 839592, "time": 38311.457312107086, "episode/length": 81.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9878048780487805, "episode/intrinsic_return": 0.0}
{"step": 839696, "time": 38316.570098638535, "episode/length": 131.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9545454545454546, "episode/intrinsic_return": 0.0}
{"step": 839920, "time": 38325.51425909996, "episode/length": 176.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 839961, "time": 38331.11935734749, "train_stats/sum_log_reward": 9.419149145166925, "train_stats/max_log_achievement_collect_coal": 0.4148936170212766, "train_stats/max_log_achievement_collect_drink": 7.287234042553192, "train_stats/max_log_achievement_collect_sapling": 1.851063829787234, "train_stats/max_log_achievement_collect_stone": 7.223404255319149, "train_stats/max_log_achievement_collect_wood": 10.51063829787234, "train_stats/max_log_achievement_defeat_skeleton": 0.031914893617021274, "train_stats/max_log_achievement_defeat_zombie": 0.9574468085106383, "train_stats/max_log_achievement_eat_cow": 0.19148936170212766, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010638297872340425, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4893617021276595, "train_stats/max_log_achievement_make_wood_sword": 1.0425531914893618, "train_stats/max_log_achievement_place_furnace": 0.2127659574468085, "train_stats/max_log_achievement_place_plant": 1.702127659574468, "train_stats/max_log_achievement_place_stone": 5.627659574468085, "train_stats/max_log_achievement_place_table": 2.5425531914893615, "train_stats/max_log_achievement_wake_up": 1.6170212765957446, "train_stats/mean_log_entropy": 0.6381065940603297, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.391466864224138, "train/action_min": 0.0, "train/action_std": 3.224645864552465, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03255958395271466, "train/actor_opt_grad_steps": 51680.0, "train/actor_opt_loss": -9.220419138772733, "train/adv_mag": 0.4462891843812219, "train/adv_max": 0.4055911553317103, "train/adv_mean": 0.0018851203239670402, "train/adv_min": -0.36634375915445133, "train/adv_std": 0.04931516716706342, "train/cont_avg": 0.9948814655172413, "train/cont_loss_mean": 0.00015249438348852325, "train/cont_loss_std": 0.004544003946096476, "train/cont_neg_acc": 0.9972988510953968, "train/cont_neg_loss": 0.009726352445061915, "train/cont_pos_acc": 0.9999525633351556, "train/cont_pos_loss": 0.00010447502781922704, "train/cont_pred": 0.9948552246751456, "train/cont_rate": 0.9948814655172413, "train/dyn_loss_mean": 13.301802562845165, "train/dyn_loss_std": 9.071082055979762, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9350441143430512, "train/extr_critic_critic_opt_grad_steps": 51680.0, "train/extr_critic_critic_opt_loss": 15752.760445851292, "train/extr_critic_mag": 9.393354843402731, "train/extr_critic_max": 9.393354843402731, "train/extr_critic_mean": 2.784338083760492, "train/extr_critic_min": -0.1785603613689028, "train/extr_critic_std": 2.3271180588623572, "train/extr_return_normed_mag": 1.478073390598955, "train/extr_return_normed_max": 1.478073390598955, "train/extr_return_normed_mean": 0.38666957133802876, "train/extr_return_normed_min": -0.07892099089663604, "train/extr_return_normed_std": 0.3310981571674347, "train/extr_return_rate": 0.7825754732921206, "train/extr_return_raw_mag": 10.555649204911857, "train/extr_return_raw_max": 10.555649204911857, "train/extr_return_raw_mean": 2.797731032042668, "train/extr_return_raw_min": -0.5116785900346164, "train/extr_return_raw_std": 2.3535783792364184, "train/extr_reward_mag": 1.03498650419301, "train/extr_reward_max": 1.03498650419301, "train/extr_reward_mean": 0.049033799060973625, "train/extr_reward_min": -0.42469531585430276, "train/extr_reward_std": 0.20672807025498358, "train/image_loss_mean": 6.260377852670078, "train/image_loss_std": 11.793995025240141, "train/model_loss_mean": 14.301246629912278, "train/model_loss_std": 15.467638055209456, "train/model_opt_grad_norm": 56.020271445964944, "train/model_opt_grad_steps": 51634.206896551725, "train/model_opt_loss": 18246.535782596984, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1275.8620689655172, "train/policy_entropy_mag": 2.6082686276271425, "train/policy_entropy_max": 2.6082686276271425, "train/policy_entropy_mean": 0.5582640353975625, "train/policy_entropy_min": 0.07937502121103221, "train/policy_entropy_std": 0.6519721119568266, "train/policy_logprob_mag": 7.438383793008739, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5587216496467591, "train/policy_logprob_min": -7.438383793008739, "train/policy_logprob_std": 1.1112131200987718, "train/policy_randomness_mag": 0.9206043638032059, "train/policy_randomness_max": 0.9206043638032059, "train/policy_randomness_mean": 0.19704270794473847, "train/policy_randomness_min": 0.028015899182907467, "train/policy_randomness_std": 0.23011754566225512, "train/post_ent_mag": 57.82818487759294, "train/post_ent_max": 57.82818487759294, "train/post_ent_mean": 41.86886302027209, "train/post_ent_min": 19.581586298449285, "train/post_ent_std": 7.471363327420991, "train/prior_ent_mag": 66.77478869207974, "train/prior_ent_max": 66.77478869207974, "train/prior_ent_mean": 55.2523788715231, "train/prior_ent_min": 40.52948008570178, "train/prior_ent_std": 4.117327843041256, "train/rep_loss_mean": 13.301802562845165, "train/rep_loss_std": 9.071082055979762, "train/reward_avg": 0.03281990806732712, "train/reward_loss_mean": 0.059634850996321646, "train/reward_loss_std": 0.25919109993967515, "train/reward_max_data": 1.0234482814525736, "train/reward_max_pred": 1.015374045536436, "train/reward_neg_acc": 0.9926180420250729, "train/reward_neg_loss": 0.03006564585556244, "train/reward_pos_acc": 0.97266925573349, "train/reward_pos_loss": 0.8259910229978891, "train/reward_pred": 0.032079835775597344, "train/reward_rate": 0.03729121767241379, "eval_stats/sum_log_reward": 7.66250017285347, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.125, "eval_stats/max_log_achievement_collect_sapling": 1.5625, "eval_stats/max_log_achievement_collect_stone": 4.0625, "eval_stats/max_log_achievement_collect_wood": 9.8125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0625, "eval_stats/max_log_achievement_defeat_zombie": 0.25, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.375, "eval_stats/max_log_achievement_make_wood_sword": 0.8125, "eval_stats/max_log_achievement_place_furnace": 0.0625, "eval_stats/max_log_achievement_place_plant": 1.5, "eval_stats/max_log_achievement_place_stone": 3.125, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 0.8125, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9931640625, "report/cont_loss_mean": 4.0009846998145804e-05, "report/cont_loss_std": 0.0007832361734472215, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0057243588380515575, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 8.84534529177472e-07, "report/cont_pred": 0.9932020902633667, "report/cont_rate": 0.9931640625, "report/dyn_loss_mean": 13.31075668334961, "report/dyn_loss_std": 8.971819877624512, "report/image_loss_mean": 5.342491626739502, "report/image_loss_std": 9.38320541381836, "report/model_loss_mean": 13.383195877075195, "report/model_loss_std": 12.936241149902344, "report/post_ent_mag": 57.581459045410156, "report/post_ent_max": 57.581459045410156, "report/post_ent_mean": 41.776004791259766, "report/post_ent_min": 20.21750259399414, "report/post_ent_std": 7.807998180389404, "report/prior_ent_mag": 66.90625, "report/prior_ent_max": 66.90625, "report/prior_ent_mean": 55.09994125366211, "report/prior_ent_min": 41.78875732421875, "report/prior_ent_std": 4.02455997467041, "report/rep_loss_mean": 13.31075668334961, "report/rep_loss_std": 8.971819877624512, "report/reward_avg": 0.02324218675494194, "report/reward_loss_mean": 0.05421051010489464, "report/reward_loss_std": 0.22198624908924103, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0053791999816895, "report/reward_neg_acc": 0.9959717988967896, "report/reward_neg_loss": 0.02775687910616398, "report/reward_pos_acc": 0.9677419066429138, "report/reward_pos_loss": 0.9015799760818481, "report/reward_pred": 0.020750997588038445, "report/reward_rate": 0.0302734375, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 4.046121466672048e-05, "eval/cont_loss_std": 0.001256101531907916, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.013567237183451653, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 7.15549958840711e-07, "eval/cont_pred": 0.9971086978912354, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.076974868774414, "eval/dyn_loss_std": 10.576007843017578, "eval/image_loss_mean": 10.87019157409668, "eval/image_loss_std": 12.171947479248047, "eval/model_loss_mean": 22.406644821166992, "eval/model_loss_std": 16.266178131103516, "eval/post_ent_mag": 55.90977478027344, "eval/post_ent_max": 55.90977478027344, "eval/post_ent_mean": 39.2471923828125, "eval/post_ent_min": 20.742809295654297, "eval/post_ent_std": 7.625590801239014, "eval/prior_ent_mag": 66.90625, "eval/prior_ent_max": 66.90625, "eval/prior_ent_mean": 55.899131774902344, "eval/prior_ent_min": 41.88593292236328, "eval/prior_ent_std": 3.717597007751465, "eval/rep_loss_mean": 19.076974868774414, "eval/rep_loss_std": 10.576007843017578, "eval/reward_avg": 0.03466796875, "eval/reward_loss_mean": 0.09022750705480576, "eval/reward_loss_std": 0.49342530965805054, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0124433040618896, "eval/reward_neg_acc": 0.9817259311676025, "eval/reward_neg_loss": 0.03936440125107765, "eval/reward_pos_acc": 0.8974359035491943, "eval/reward_pos_loss": 1.3748470544815063, "eval/reward_pred": 0.035554878413677216, "eval/reward_rate": 0.0380859375, "replay/size": 839457.0, "replay/inserts": 23136.0, "replay/samples": 23136.0, "replay/insert_wait_avg": 1.30832401383797e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.302599494058232e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 3904.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0866244308284071e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.195638656616211e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.00830078125, "timer/env.step_count": 2892.0, "timer/env.step_total": 234.19483733177185, "timer/env.step_frac": 0.23419289334779386, "timer/env.step_avg": 0.08098023420877312, "timer/env.step_min": 0.022412538528442383, "timer/env.step_max": 2.2879483699798584, "timer/replay._sample_count": 23136.0, "timer/replay._sample_total": 11.574750185012817, "timer/replay._sample_frac": 0.011574654106341037, "timer/replay._sample_avg": 0.0005002917611087836, "timer/replay._sample_min": 0.00038242340087890625, "timer/replay._sample_max": 0.008954048156738281, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3380.0, "timer/agent.policy_total": 54.37956643104553, "timer/agent.policy_frac": 0.054379115041907, "timer/agent.policy_avg": 0.016088629121611103, "timer/agent.policy_min": 0.009340286254882812, "timer/agent.policy_max": 0.11070942878723145, "timer/dataset_train_count": 1446.0, "timer/dataset_train_total": 0.15332794189453125, "timer/dataset_train_frac": 0.00015332666916339073, "timer/dataset_train_avg": 0.00010603592108888745, "timer/dataset_train_min": 9.369850158691406e-05, "timer/dataset_train_max": 0.00020122528076171875, "timer/agent.train_count": 1446.0, "timer/agent.train_total": 645.3378593921661, "timer/agent.train_frac": 0.6453325026282283, "timer/agent.train_avg": 0.4462917423182338, "timer/agent.train_min": 0.43297743797302246, "timer/agent.train_max": 1.6619317531585693, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4763150215148926, "timer/agent.report_frac": 0.00047631106776091216, "timer/agent.report_avg": 0.2381575107574463, "timer/agent.report_min": 0.23263335227966309, "timer/agent.report_max": 0.2436816692352295, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.741790900661469e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 23.135516550187216}
{"step": 840008, "time": 38350.895268678665, "eval_episode/length": 136.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9927007299270073}
{"step": 840008, "time": 38353.59665465355, "eval_episode/length": 162.0, "eval_episode/score": 6.099999986588955, "eval_episode/reward_rate": 0.9693251533742331}
{"step": 840008, "time": 38357.79538607597, "eval_episode/length": 225.0, "eval_episode/score": 13.100000016391277, "eval_episode/reward_rate": 0.9778761061946902}
{"step": 840008, "time": 38359.78487277031, "eval_episode/length": 236.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 840008, "time": 38361.98532652855, "eval_episode/length": 250.0, "eval_episode/score": 8.100000008940697, "eval_episode/reward_rate": 0.9960159362549801}
{"step": 840008, "time": 38364.69307088852, "eval_episode/length": 37.0, "eval_episode/score": 2.1000000163912773, "eval_episode/reward_rate": 0.9210526315789473}
{"step": 840008, "time": 38370.45986747742, "eval_episode/length": 297.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.9966442953020134}
{"step": 840008, "time": 38372.43634200096, "eval_episode/length": 299.0, "eval_episode/score": 11.099999979138374, "eval_episode/reward_rate": 0.9966666666666667}
{"step": 840088, "time": 38375.07541871071, "episode/length": 240.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.975103734439834, "episode/intrinsic_return": 0.0}
{"step": 840632, "time": 38394.97368144989, "episode/length": 427.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9929906542056075, "episode/intrinsic_return": 0.0}
{"step": 840888, "time": 38404.869705200195, "episode/length": 148.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9731543624161074, "episode/intrinsic_return": 0.0}
{"step": 841000, "time": 38410.27829742432, "episode/length": 246.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 841208, "time": 38418.62662267685, "episode/length": 224.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 841568, "time": 38432.26828241348, "episode/length": 246.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9959514170040485, "episode/intrinsic_return": 0.0}
{"step": 841768, "time": 38440.377287864685, "episode/length": 230.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9826839826839827, "episode/intrinsic_return": 0.0}
{"step": 842256, "time": 38458.1506626606, "episode/length": 270.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 842696, "time": 38474.30997085571, "episode/length": 115.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 842704, "time": 38476.311745882034, "episode/length": 258.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9961389961389961, "episode/intrinsic_return": 0.0}
{"step": 842728, "time": 38478.49247908592, "episode/length": 229.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 842784, "time": 38482.07553458214, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 842848, "time": 38485.68972706795, "episode/length": 417.0, "episode/score": 14.099999986588955, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 842872, "time": 38487.83266091347, "episode/length": 207.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 843432, "time": 38508.40882849693, "episode/length": 232.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9699570815450643, "episode/intrinsic_return": 0.0}
{"step": 843584, "time": 38515.28652691841, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 844032, "time": 38533.32980489731, "episode/length": 165.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 844368, "time": 38546.07769393921, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 844392, "time": 38548.22485041618, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9711538461538461, "episode/intrinsic_return": 0.0}
{"step": 844408, "time": 38550.31859087944, "episode/length": 213.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 844456, "time": 38553.54025244713, "episode/length": 197.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 844952, "time": 38571.540756225586, "episode/length": 114.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9652173913043478, "episode/intrinsic_return": 0.0}
{"step": 844992, "time": 38575.149844646454, "episode/length": 275.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9746376811594203, "episode/intrinsic_return": 0.0}
{"step": 845336, "time": 38588.68862915039, "episode/length": 47.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 845800, "time": 38606.746925115585, "episode/length": 175.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9715909090909091, "episode/intrinsic_return": 0.0}
{"step": 845832, "time": 38609.4142768383, "episode/length": 280.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 845912, "time": 38613.69842791557, "episode/length": 309.0, "episode/score": 8.100000031292439, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 846248, "time": 38626.52970814705, "episode/length": 156.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9681528662420382, "episode/intrinsic_return": 0.0}
{"step": 846272, "time": 38629.13221645355, "episode/length": 226.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 846392, "time": 38634.370499134064, "episode/length": 247.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 846520, "time": 38640.02809906006, "episode/length": 268.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 846816, "time": 38651.5441069603, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9945945945945946, "episode/intrinsic_return": 0.0}
{"step": 846904, "time": 38655.72877550125, "episode/length": 47.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.8958333333333334, "episode/intrinsic_return": 0.0}
{"step": 847616, "time": 38681.09813952446, "episode/length": 212.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9671361502347418, "episode/intrinsic_return": 0.0}
{"step": 847664, "time": 38684.208580732346, "episode/length": 173.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 847672, "time": 38685.799480199814, "episode/length": 233.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957264957264957, "episode/intrinsic_return": 0.0}
{"step": 848208, "time": 38705.266600608826, "episode/length": 296.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.98989898989899, "episode/intrinsic_return": 0.0}
{"step": 848448, "time": 38714.888865709305, "episode/length": 192.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9792746113989638, "episode/intrinsic_return": 0.0}
{"step": 848568, "time": 38720.192665338516, "episode/length": 44.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 848912, "time": 38733.45481467247, "episode/length": 42.0, "episode/score": 2.0999999716877937, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 849024, "time": 38738.69898343086, "episode/length": 346.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9913544668587896, "episode/intrinsic_return": 0.0}
{"step": 849040, "time": 38740.948026418686, "episode/length": 177.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 849184, "time": 38747.43104529381, "episode/length": 295.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 849384, "time": 38755.29502224922, "episode/length": 214.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 849400, "time": 38757.47812962532, "episode/length": 60.0, "episode/score": 7.099999971687794, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 850096, "time": 38799.55247926712, "eval_episode/length": 42.0, "eval_episode/score": 5.100000001490116, "eval_episode/reward_rate": 0.9069767441860465}
{"step": 850096, "time": 38806.841891765594, "eval_episode/length": 155.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.967948717948718}
{"step": 850096, "time": 38809.34172797203, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9760479041916168}
{"step": 850096, "time": 38812.511644124985, "eval_episode/length": 191.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9947916666666666}
{"step": 850096, "time": 38814.90585398674, "eval_episode/length": 210.0, "eval_episode/score": 11.099999971687794, "eval_episode/reward_rate": 0.995260663507109}
{"step": 850096, "time": 38818.879006147385, "eval_episode/length": 57.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 850096, "time": 38821.38225245476, "eval_episode/length": 248.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9959839357429718}
{"step": 850096, "time": 38823.95804357529, "eval_episode/length": 317.0, "eval_episode/score": 12.100000031292439, "eval_episode/reward_rate": 0.9779874213836478}
{"step": 850128, "time": 38825.01847457886, "episode/length": 209.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 850480, "time": 38838.11213994026, "episode/length": 43.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 850744, "time": 38848.23317670822, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 850824, "time": 38852.47268199921, "episode/length": 222.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 851208, "time": 38866.76852083206, "episode/length": 601.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9983388704318937, "episode/intrinsic_return": 0.0}
{"step": 851552, "time": 38879.8163497448, "episode/length": 484.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9917525773195877, "episode/intrinsic_return": 0.0}
{"step": 851840, "time": 38890.91751909256, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9868852459016394, "episode/intrinsic_return": 0.0}
{"step": 852088, "time": 38901.93219900131, "episode/length": 157.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9810126582278481, "episode/intrinsic_return": 0.0}
{"step": 852296, "time": 38910.47909665108, "episode/length": 193.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 852512, "time": 38919.39410948753, "episode/length": 435.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9793577981651376, "episode/intrinsic_return": 0.0}
{"step": 852744, "time": 38928.54886364937, "episode/length": 444.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9932584269662922, "episode/intrinsic_return": 0.0}
{"step": 852784, "time": 38931.66781258583, "episode/length": 60.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 853224, "time": 38947.553943157196, "episode/length": 208.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9808612440191388, "episode/intrinsic_return": 0.0}
{"step": 853512, "time": 38958.61770749092, "episode/length": 208.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 853744, "time": 38968.02117180824, "episode/length": 407.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 854176, "time": 38983.876353263855, "episode/length": 207.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 854392, "time": 38992.318089962006, "episode/length": 397.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9949748743718593, "episode/intrinsic_return": 0.0}
{"step": 854704, "time": 39004.4009308815, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 854872, "time": 39011.283024311066, "episode/length": 169.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9941176470588236, "episode/intrinsic_return": 0.0}
{"step": 855128, "time": 39021.221093177795, "episode/length": 297.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 855424, "time": 39032.722460746765, "episode/length": 416.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9904076738609112, "episode/intrinsic_return": 0.0}
{"step": 855696, "time": 39043.57854795456, "episode/length": 243.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 855768, "time": 39047.33640766144, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 855960, "time": 39055.179131269455, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 856120, "time": 39061.97062730789, "episode/length": 416.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9952038369304557, "episode/intrinsic_return": 0.0}
{"step": 856560, "time": 39078.36434006691, "episode/length": 178.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 856768, "time": 39086.842145204544, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 857072, "time": 39098.68257403374, "episode/length": 295.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9898648648648649, "episode/intrinsic_return": 0.0}
{"step": 857176, "time": 39104.32197904587, "episode/length": 184.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9837837837837838, "episode/intrinsic_return": 0.0}
{"step": 857312, "time": 39111.1381611824, "episode/length": 304.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 857376, "time": 39115.29125833511, "episode/length": 200.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 857488, "time": 39121.06912255287, "episode/length": 190.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 857576, "time": 39125.347828388214, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 857808, "time": 39134.886143922806, "episode/length": 53.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 857960, "time": 39141.127643823624, "episode/length": 148.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9932885906040269, "episode/intrinsic_return": 0.0}
{"step": 858416, "time": 39157.84745192528, "episode/length": 167.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 858760, "time": 39170.49235534668, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 859176, "time": 39185.694779634476, "episode/length": 210.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 859408, "time": 39195.735032081604, "episode/length": 228.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9737991266375546, "episode/intrinsic_return": 0.0}
{"step": 859568, "time": 39202.78361129761, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 859952, "time": 39216.99999547005, "episode/length": 423.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9976415094339622, "episode/intrinsic_return": 0.0}
{"step": 860080, "time": 39242.20998811722, "eval_episode/length": 146.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9931972789115646}
{"step": 860080, "time": 39247.46741223335, "eval_episode/length": 231.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9698275862068966}
{"step": 860080, "time": 39249.09380245209, "eval_episode/length": 232.0, "eval_episode/score": 10.099999994039536, "eval_episode/reward_rate": 0.9914163090128756}
{"step": 860080, "time": 39251.088250637054, "eval_episode/length": 236.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9789029535864979}
{"step": 860080, "time": 39253.152876615524, "eval_episode/length": 249.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.996}
{"step": 860080, "time": 39256.44913268089, "eval_episode/length": 286.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9825783972125436}
{"step": 860080, "time": 39260.60947370529, "eval_episode/length": 330.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9818731117824774}
{"step": 860080, "time": 39265.347536325455, "eval_episode/length": 388.0, "eval_episode/score": 12.100000008940697, "eval_episode/reward_rate": 0.987146529562982}
{"step": 860432, "time": 39278.826778411865, "episode/length": 308.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 860728, "time": 39289.95060157776, "episode/length": 245.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9959349593495935, "episode/intrinsic_return": 0.0}
{"step": 860736, "time": 39292.07395911217, "episode/length": 427.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9976635514018691, "episode/intrinsic_return": 0.0}
{"step": 860760, "time": 39294.17257785797, "episode/length": 292.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9965870307167235, "episode/intrinsic_return": 0.0}
{"step": 860864, "time": 39299.54514861107, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.981042654028436, "episode/intrinsic_return": 0.0}
{"step": 861016, "time": 39306.4572057724, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 861232, "time": 39315.7746322155, "episode/length": 227.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 861480, "time": 39325.343005657196, "episode/length": 190.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9947643979057592, "episode/intrinsic_return": 0.0}
{"step": 861529, "time": 39329.52334165573, "eval_stats/sum_log_reward": 9.475000192721685, "eval_stats/max_log_achievement_collect_coal": 0.5416666666666666, "eval_stats/max_log_achievement_collect_drink": 4.791666666666667, "eval_stats/max_log_achievement_collect_sapling": 1.2083333333333333, "eval_stats/max_log_achievement_collect_stone": 8.333333333333334, "eval_stats/max_log_achievement_collect_wood": 11.125, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.875, "eval_stats/max_log_achievement_eat_cow": 0.041666666666666664, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.3333333333333333, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.125, "eval_stats/max_log_achievement_place_stone": 5.708333333333333, "eval_stats/max_log_achievement_place_table": 2.4583333333333335, "eval_stats/max_log_achievement_wake_up": 1.2083333333333333, "eval_stats/mean_log_entropy": 0.0, "train_stats/sum_log_reward": 9.546808765289631, "train_stats/max_log_achievement_collect_coal": 0.4148936170212766, "train_stats/max_log_achievement_collect_drink": 5.627659574468085, "train_stats/max_log_achievement_collect_sapling": 1.7127659574468086, "train_stats/max_log_achievement_collect_stone": 7.702127659574468, "train_stats/max_log_achievement_collect_wood": 10.840425531914894, "train_stats/max_log_achievement_defeat_skeleton": 0.07446808510638298, "train_stats/max_log_achievement_defeat_zombie": 1.0, "train_stats/max_log_achievement_eat_cow": 0.1276595744680851, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.02127659574468085, "train_stats/max_log_achievement_make_stone_sword": 0.02127659574468085, "train_stats/max_log_achievement_make_wood_pickaxe": 1.4787234042553192, "train_stats/max_log_achievement_make_wood_sword": 1.2765957446808511, "train_stats/max_log_achievement_place_furnace": 0.24468085106382978, "train_stats/max_log_achievement_place_plant": 1.6170212765957446, "train_stats/max_log_achievement_place_stone": 5.51063829787234, "train_stats/max_log_achievement_place_table": 2.6702127659574466, "train_stats/max_log_achievement_wake_up": 1.3617021276595744, "train_stats/mean_log_entropy": 0.5930320536519619, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.490054457934935, "train/action_min": 0.0, "train/action_std": 3.3283495066770867, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03353192359765074, "train/actor_opt_grad_steps": 53075.0, "train/actor_opt_loss": -4.443339728107398, "train/adv_mag": 0.449329487645804, "train/adv_max": 0.40189930173888133, "train/adv_mean": 0.003132689751971577, "train/adv_min": -0.36598298442897514, "train/adv_std": 0.05086057505278445, "train/cont_avg": 0.9951171875, "train/cont_loss_mean": 0.00019506416426852682, "train/cont_loss_std": 0.0059009353464034575, "train/cont_neg_acc": 0.9939054731112807, "train/cont_neg_loss": 0.026340351692947003, "train/cont_pos_acc": 0.9999853003380904, "train/cont_pos_loss": 6.316850687332095e-05, "train/cont_pred": 0.9951274030244173, "train/cont_rate": 0.9951171875, "train/dyn_loss_mean": 13.24499500331594, "train/dyn_loss_std": 9.048605751635423, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9689988222584796, "train/extr_critic_critic_opt_grad_steps": 53075.0, "train/extr_critic_critic_opt_loss": 16188.170133220616, "train/extr_critic_mag": 9.417312294689577, "train/extr_critic_max": 9.417312294689577, "train/extr_critic_mean": 2.6784858472311677, "train/extr_critic_min": -0.18801364969851367, "train/extr_critic_std": 2.273634977305113, "train/extr_return_normed_mag": 1.4861505565358633, "train/extr_return_normed_max": 1.4861505565358633, "train/extr_return_normed_mean": 0.37858675042195106, "train/extr_return_normed_min": -0.07778158429454067, "train/extr_return_normed_std": 0.3262005440557181, "train/extr_return_rate": 0.7844032235999605, "train/extr_return_raw_mag": 10.51575554662676, "train/extr_return_raw_max": 10.51575554662676, "train/extr_return_raw_mean": 2.7005876409473704, "train/extr_return_raw_min": -0.5197669314915565, "train/extr_return_raw_std": 2.301714944305705, "train/extr_reward_mag": 1.0434456903543046, "train/extr_reward_max": 1.0434456903543046, "train/extr_reward_mean": 0.05148343078847697, "train/extr_reward_min": -0.4402025706732451, "train/extr_reward_std": 0.21164373742110693, "train/image_loss_mean": 6.3045052236585475, "train/image_loss_std": 11.887304672554357, "train/model_loss_mean": 14.309395462719362, "train/model_loss_std": 15.494725085016507, "train/model_opt_grad_norm": 56.611985605154466, "train/model_opt_grad_steps": 53027.880597014926, "train/model_opt_loss": 21198.49168464319, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1483.2089552238806, "train/policy_entropy_mag": 2.626738455758166, "train/policy_entropy_max": 2.626738455758166, "train/policy_entropy_mean": 0.551220483521917, "train/policy_entropy_min": 0.07937502305009472, "train/policy_entropy_std": 0.6597231877828712, "train/policy_logprob_mag": 7.438383764295436, "train/policy_logprob_max": -0.009455658446775, "train/policy_logprob_mean": -0.5503955080882826, "train/policy_logprob_min": -7.438383764295436, "train/policy_logprob_std": 1.1064832815483434, "train/policy_randomness_mag": 0.9271234002575945, "train/policy_randomness_max": 0.9271234002575945, "train/policy_randomness_mean": 0.19455664360256336, "train/policy_randomness_min": 0.028015899819447035, "train/policy_randomness_std": 0.23285333378546275, "train/post_ent_mag": 58.0144311705632, "train/post_ent_max": 58.0144311705632, "train/post_ent_mean": 41.97337355542539, "train/post_ent_min": 19.735088305686837, "train/post_ent_std": 7.580897053675865, "train/prior_ent_mag": 66.84727922126429, "train/prior_ent_max": 66.84727922126429, "train/prior_ent_mean": 55.33590333853195, "train/prior_ent_min": 40.36513376947659, "train/prior_ent_std": 4.100677787367977, "train/rep_loss_mean": 13.24499500331594, "train/rep_loss_std": 9.048605751635423, "train/reward_avg": 0.032667473243521664, "train/reward_loss_mean": 0.05769837483652492, "train/reward_loss_std": 0.2525498015222265, "train/reward_max_data": 1.0156716455274553, "train/reward_max_pred": 1.0143954469196832, "train/reward_neg_acc": 0.9931437350920777, "train/reward_neg_loss": 0.028031930779176418, "train/reward_pos_acc": 0.9703689244256091, "train/reward_pos_loss": 0.8332336082387326, "train/reward_pred": 0.03168609004412124, "train/reward_rate": 0.03705107276119403, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.2727495004583034e-06, "report/cont_loss_std": 1.967796742974315e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 5.376958870328963e-05, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 1.0668794629964395e-06, "report/cont_pred": 0.9960929155349731, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.55052375793457, "report/dyn_loss_std": 8.624643325805664, "report/image_loss_mean": 5.581947326660156, "report/image_loss_std": 11.087881088256836, "report/model_loss_mean": 13.161601066589355, "report/model_loss_std": 14.278105735778809, "report/post_ent_mag": 60.222373962402344, "report/post_ent_max": 60.222373962402344, "report/post_ent_mean": 42.8098258972168, "report/post_ent_min": 20.0511474609375, "report/post_ent_std": 7.838427543640137, "report/prior_ent_mag": 66.92010498046875, "report/prior_ent_max": 66.92010498046875, "report/prior_ent_mean": 55.92262268066406, "report/prior_ent_min": 44.188507080078125, "report/prior_ent_std": 3.637047529220581, "report/rep_loss_mean": 12.55052375793457, "report/rep_loss_std": 8.624643325805664, "report/reward_avg": 0.02763671800494194, "report/reward_loss_mean": 0.049338214099407196, "report/reward_loss_std": 0.1756073236465454, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0011703968048096, "report/reward_neg_acc": 0.9939393401145935, "report/reward_neg_loss": 0.02725067362189293, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.692475438117981, "report/reward_pred": 0.027680205181241035, "report/reward_rate": 0.033203125, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 4.887184559265734e-07, "eval/cont_loss_std": 6.03652415520628e-06, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 2.54667284025345e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 4.643020190542302e-07, "eval/cont_pred": 0.9990230798721313, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 16.33306121826172, "eval/dyn_loss_std": 10.65318775177002, "eval/image_loss_mean": 10.58107852935791, "eval/image_loss_std": 13.78976821899414, "eval/model_loss_mean": 20.50896644592285, "eval/model_loss_std": 18.33155632019043, "eval/post_ent_mag": 56.7432861328125, "eval/post_ent_max": 56.7432861328125, "eval/post_ent_mean": 41.23583984375, "eval/post_ent_min": 17.993595123291016, "eval/post_ent_std": 8.235980987548828, "eval/prior_ent_mag": 66.92010498046875, "eval/prior_ent_max": 66.92010498046875, "eval/prior_ent_mean": 56.25743865966797, "eval/prior_ent_min": 43.17430877685547, "eval/prior_ent_std": 3.6614322662353516, "eval/rep_loss_mean": 16.33306121826172, "eval/rep_loss_std": 10.65318775177002, "eval/reward_avg": 0.05253906548023224, "eval/reward_loss_mean": 0.12805065512657166, "eval/reward_loss_std": 0.6683635115623474, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.008340835571289, "eval/reward_neg_acc": 0.9917441010475159, "eval/reward_neg_loss": 0.04196377471089363, "eval/reward_pos_acc": 0.7999999523162842, "eval/reward_pos_loss": 1.644744634628296, "eval/reward_pred": 0.041974179446697235, "eval/reward_rate": 0.0537109375, "replay/size": 861025.0, "replay/inserts": 21568.0, "replay/samples": 21568.0, "replay/insert_wait_avg": 1.3102741375875049e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.352639730323316e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8056.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1141096586740715e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.897615432739258e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.4083578586578, "timer/env.step_count": 2696.0, "timer/env.step_total": 224.4880838394165, "timer/env.step_frac": 0.2243964497856916, "timer/env.step_avg": 0.08326709341224647, "timer/env.step_min": 0.022695541381835938, "timer/env.step_max": 2.3141186237335205, "timer/replay._sample_count": 21568.0, "timer/replay._sample_total": 10.819551229476929, "timer/replay._sample_frac": 0.010815134784195359, "timer/replay._sample_avg": 0.0005016483322272314, "timer/replay._sample_min": 0.0004165172576904297, "timer/replay._sample_max": 0.025213003158569336, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3703.0, "timer/agent.policy_total": 61.06941771507263, "timer/agent.policy_frac": 0.06104448971796854, "timer/agent.policy_avg": 0.016491876239555125, "timer/agent.policy_min": 0.009244680404663086, "timer/agent.policy_max": 0.12360310554504395, "timer/dataset_train_count": 1348.0, "timer/dataset_train_total": 0.14395785331726074, "timer/dataset_train_frac": 0.00014389909099260019, "timer/dataset_train_avg": 0.0001067936597309056, "timer/dataset_train_min": 9.298324584960938e-05, "timer/dataset_train_max": 0.0005037784576416016, "timer/agent.train_count": 1348.0, "timer/agent.train_total": 601.6548316478729, "timer/agent.train_frac": 0.6014092414578541, "timer/agent.train_avg": 0.44633147748358526, "timer/agent.train_min": 0.4328019618988037, "timer/agent.train_max": 1.6845371723175049, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47731637954711914, "timer/agent.report_frac": 0.00047712154321541216, "timer/agent.report_avg": 0.23865818977355957, "timer/agent.report_min": 0.23090267181396484, "timer/agent.report_max": 0.2464137077331543, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9325485229492188e-05, "timer/dataset_eval_frac": 2.9313514825348372e-08, "timer/dataset_eval_avg": 2.9325485229492188e-05, "timer/dataset_eval_min": 2.9325485229492188e-05, "timer/dataset_eval_max": 2.9325485229492188e-05, "fps": 21.55893322896159}
{"step": 862080, "time": 39348.09803557396, "episode/length": 167.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9702380952380952, "episode/intrinsic_return": 0.0}
{"step": 862232, "time": 39354.49647974968, "episode/length": 187.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 862336, "time": 39359.636003017426, "episode/length": 164.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9636363636363636, "episode/intrinsic_return": 0.0}
{"step": 862472, "time": 39365.56457066536, "episode/length": 254.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.996078431372549, "episode/intrinsic_return": 0.0}
{"step": 862488, "time": 39367.66319799423, "episode/length": 125.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9603174603174603, "episode/intrinsic_return": 0.0}
{"step": 862792, "time": 39379.46919298172, "episode/length": 194.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 863040, "time": 39389.56018590927, "episode/length": 284.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9964912280701754, "episode/intrinsic_return": 0.0}
{"step": 863120, "time": 39393.70491886139, "episode/length": 281.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9822695035460993, "episode/intrinsic_return": 0.0}
{"step": 863480, "time": 39407.07810711861, "episode/length": 54.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 863648, "time": 39414.50336575508, "episode/length": 163.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 863840, "time": 39422.65921640396, "episode/length": 219.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 864176, "time": 39436.272218465805, "episode/length": 210.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 864664, "time": 39454.6514236927, "episode/length": 233.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 865072, "time": 39470.26221013069, "episode/length": 177.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9719101123595506, "episode/intrinsic_return": 0.0}
{"step": 865448, "time": 39484.03975057602, "episode/length": 401.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9900497512437811, "episode/intrinsic_return": 0.0}
{"step": 865584, "time": 39490.51177883148, "episode/length": 217.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 865848, "time": 39500.54792904854, "episode/length": 421.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 866208, "time": 39514.477353811264, "episode/length": 340.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853372434017595, "episode/intrinsic_return": 0.0}
{"step": 866360, "time": 39520.99772286415, "episode/length": 272.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 866456, "time": 39525.85571408272, "episode/length": 172.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 866480, "time": 39530.47344207764, "episode/length": 226.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9691629955947136, "episode/intrinsic_return": 0.0}
{"step": 867496, "time": 39565.8146545887, "episode/length": 238.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 867616, "time": 39572.1847319603, "episode/length": 561.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.998220640569395, "episode/intrinsic_return": 0.0}
{"step": 867728, "time": 39577.61968612671, "episode/length": 158.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9748427672955975, "episode/intrinsic_return": 0.0}
{"step": 867832, "time": 39582.47357439995, "episode/length": 297.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9765100671140939, "episode/intrinsic_return": 0.0}
{"step": 867976, "time": 39588.75064492226, "episode/length": 186.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9786096256684492, "episode/intrinsic_return": 0.0}
{"step": 867976, "time": 39588.75990533829, "episode/length": 220.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9728506787330317, "episode/intrinsic_return": 0.0}
{"step": 868152, "time": 39598.08888673782, "episode/length": 52.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 868392, "time": 39609.14368581772, "episode/length": 317.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9842767295597484, "episode/intrinsic_return": 0.0}
{"step": 868872, "time": 39626.734241724014, "episode/length": 313.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9840764331210191, "episode/intrinsic_return": 0.0}
{"step": 869472, "time": 39648.62687635422, "episode/length": 164.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9939393939393939, "episode/intrinsic_return": 0.0}
{"step": 869480, "time": 39650.25354099274, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 869576, "time": 39655.086245536804, "episode/length": 217.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 869808, "time": 39664.54197764397, "episode/length": 228.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 869968, "time": 39671.469414711, "episode/length": 308.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9967637540453075, "episode/intrinsic_return": 0.0}
{"step": 870024, "time": 39674.697028160095, "episode/length": 300.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9767441860465116, "episode/intrinsic_return": 0.0}
{"step": 870064, "time": 39697.56976032257, "eval_episode/length": 163.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.975609756097561}
{"step": 870064, "time": 39699.52058458328, "eval_episode/length": 173.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9712643678160919}
{"step": 870064, "time": 39701.46053338051, "eval_episode/length": 181.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 870064, "time": 39701.46838092804, "eval_episode/length": 181.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 870064, "time": 39705.153632164, "eval_episode/length": 187.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9840425531914894}
{"step": 870064, "time": 39707.189395189285, "eval_episode/length": 199.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.97}
{"step": 870064, "time": 39709.64733672142, "eval_episode/length": 218.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9726027397260274}
{"step": 870064, "time": 39713.12196922302, "eval_episode/length": 267.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9776119402985075}
{"step": 870232, "time": 39718.41857457161, "episode/length": 229.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9739130434782609, "episode/intrinsic_return": 0.0}
{"step": 870736, "time": 39737.054708004, "episode/length": 95.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9375, "episode/intrinsic_return": 0.0}
{"step": 870784, "time": 39740.76805663109, "episode/length": 162.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 870840, "time": 39744.65961885452, "episode/length": 245.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 870864, "time": 39747.725370407104, "episode/length": 160.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9751552795031055, "episode/intrinsic_return": 0.0}
{"step": 871184, "time": 39760.90232300758, "episode/length": 213.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 871304, "time": 39766.805238723755, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 871880, "time": 39787.391385793686, "episode/length": 231.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 871936, "time": 39791.01353240013, "episode/length": 212.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9765258215962441, "episode/intrinsic_return": 0.0}
{"step": 871992, "time": 39794.19998574257, "episode/length": 140.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9645390070921985, "episode/intrinsic_return": 0.0}
{"step": 872288, "time": 39805.6335542202, "episode/length": 309.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 872520, "time": 39814.7513794899, "episode/length": 222.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9820627802690582, "episode/intrinsic_return": 0.0}
{"step": 872608, "time": 39820.173659563065, "episode/length": 162.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 873312, "time": 39845.83072280884, "episode/length": 315.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 873408, "time": 39850.722761154175, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9738219895287958, "episode/intrinsic_return": 0.0}
{"step": 873464, "time": 39853.91712832451, "episode/length": 183.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 873520, "time": 39857.59483408928, "episode/length": 197.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9747474747474747, "episode/intrinsic_return": 0.0}
{"step": 873816, "time": 39868.70044875145, "episode/length": 161.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 873992, "time": 39876.21256303787, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 874392, "time": 39891.05498576164, "episode/length": 400.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9775561097256857, "episode/intrinsic_return": 0.0}
{"step": 874616, "time": 39900.06215429306, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 874688, "time": 39904.21555018425, "episode/length": 259.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 874776, "time": 39908.46871423721, "episode/length": 170.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9766081871345029, "episode/intrinsic_return": 0.0}
{"step": 875728, "time": 39942.21544456482, "episode/length": 275.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963768115942029, "episode/intrinsic_return": 0.0}
{"step": 875864, "time": 39948.025444984436, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 876232, "time": 39961.7967774868, "episode/length": 181.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 876328, "time": 39966.58349609375, "episode/length": 57.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 876824, "time": 39986.538293361664, "episode/length": 375.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 876864, "time": 39989.6903090477, "episode/length": 271.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 877088, "time": 39998.78599524498, "episode/length": 336.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9881305637982196, "episode/intrinsic_return": 0.0}
{"step": 877392, "time": 40010.59677028656, "episode/length": 424.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9976470588235294, "episode/intrinsic_return": 0.0}
{"step": 878016, "time": 40033.507452726364, "episode/length": 210.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 878120, "time": 40038.442405462265, "episode/length": 437.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9794520547945206, "episode/intrinsic_return": 0.0}
{"step": 878568, "time": 40055.05407834053, "episode/length": 212.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.971830985915493, "episode/intrinsic_return": 0.0}
{"step": 878704, "time": 40061.50372195244, "episode/length": 371.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 878776, "time": 40065.26445698738, "episode/length": 243.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 878848, "time": 40069.4531416893, "episode/length": 326.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9847094801223242, "episode/intrinsic_return": 0.0}
{"step": 878952, "time": 40074.20121192932, "episode/length": 232.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 879432, "time": 40091.84254193306, "episode/length": 163.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9939024390243902, "episode/intrinsic_return": 0.0}
{"step": 879584, "time": 40098.64920449257, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 879848, "time": 40108.803928375244, "episode/length": 159.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 880048, "time": 40138.80475854874, "eval_episode/length": 169.0, "eval_episode/score": 11.099999964237213, "eval_episode/reward_rate": 0.9588235294117647}
{"step": 880048, "time": 40141.069981098175, "eval_episode/length": 188.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9682539682539683}
{"step": 880048, "time": 40141.07949113846, "eval_episode/length": 188.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9788359788359788}
{"step": 880048, "time": 40145.06705188751, "eval_episode/length": 202.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9753694581280788}
{"step": 880048, "time": 40146.99611711502, "eval_episode/length": 212.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9953051643192489}
{"step": 880048, "time": 40149.67312812805, "eval_episode/length": 236.0, "eval_episode/score": 6.100000001490116, "eval_episode/reward_rate": 0.9957805907172996}
{"step": 880048, "time": 40151.64862751961, "eval_episode/length": 246.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9959514170040485}
{"step": 880048, "time": 40154.19722414017, "eval_episode/length": 271.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9742647058823529}
{"step": 880176, "time": 40158.43694519997, "episode/length": 347.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 880216, "time": 40161.1396381855, "episode/length": 188.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9788359788359788, "episode/intrinsic_return": 0.0}
{"step": 880400, "time": 40169.03998398781, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 880880, "time": 40186.75950717926, "episode/length": 59.0, "episode/score": 5.100000001490116, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 881048, "time": 40193.736964702606, "episode/length": 283.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9788732394366197, "episode/intrinsic_return": 0.0}
{"step": 881096, "time": 40196.850197553635, "episode/length": 280.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9822064056939501, "episode/intrinsic_return": 0.0}
{"step": 881248, "time": 40203.71774315834, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.973568281938326, "episode/intrinsic_return": 0.0}
{"step": 881280, "time": 40206.284886837006, "episode/length": 178.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.994413407821229, "episode/intrinsic_return": 0.0}
{"step": 881480, "time": 40214.45791888237, "episode/length": 236.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 881784, "time": 40226.081667900085, "episode/length": 200.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 882264, "time": 40243.840601444244, "episode/length": 255.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 882576, "time": 40256.20628118515, "episode/length": 161.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 882584, "time": 40258.31609797478, "episode/length": 191.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 882624, "time": 40262.637031793594, "episode/length": 190.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685863874345549, "episode/intrinsic_return": 0.0}
{"step": 882792, "time": 40270.19066643715, "episode/length": 192.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9689119170984456, "episode/intrinsic_return": 0.0}
{"step": 883400, "time": 40291.97317790985, "episode/length": 201.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 883560, "time": 40298.82286643982, "episode/length": 259.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 883728, "time": 40306.22788786888, "episode/length": 355.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 883944, "time": 40314.815202236176, "episode/length": 164.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 884064, "time": 40320.590698719025, "episode/length": 224.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9955555555555555, "episode/intrinsic_return": 0.0}
{"step": 884248, "time": 40327.97550916672, "episode/length": 64.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 884249, "time": 40330.67304778099, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.622928243287852, "train/action_min": 0.0, "train/action_std": 3.4315006598620346, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.033426835739486654, "train/actor_opt_grad_steps": 54455.0, "train/actor_opt_loss": -2.096092019387534, "train/adv_mag": 0.42750270685679476, "train/adv_max": 0.37800451630437876, "train/adv_mean": 0.003255117825279791, "train/adv_min": -0.35807123433955956, "train/adv_std": 0.05011867747550279, "train/cont_avg": 0.9952478543133803, "train/cont_loss_mean": 0.0002565262070695105, "train/cont_loss_std": 0.007686043042382716, "train/cont_neg_acc": 0.9949837923049927, "train/cont_neg_loss": 0.013840850870046394, "train/cont_pos_acc": 0.9999516115222179, "train/cont_pos_loss": 0.00017682459894820433, "train/cont_pred": 0.9952271811559167, "train/cont_rate": 0.9952478543133803, "train/dyn_loss_mean": 13.028286228717214, "train/dyn_loss_std": 9.030652093215727, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9675320118245944, "train/extr_critic_critic_opt_grad_steps": 54455.0, "train/extr_critic_critic_opt_loss": 16131.969018210828, "train/extr_critic_mag": 9.552928219378835, "train/extr_critic_max": 9.552928219378835, "train/extr_critic_mean": 2.7396335626991704, "train/extr_critic_min": -0.17542958343532725, "train/extr_critic_std": 2.3215834254949863, "train/extr_return_normed_mag": 1.4827180227763217, "train/extr_return_normed_max": 1.4827180227763217, "train/extr_return_normed_mean": 0.37618839205570626, "train/extr_return_normed_min": -0.07872943666724252, "train/extr_return_normed_std": 0.3265210352313351, "train/extr_return_rate": 0.7896393092585282, "train/extr_return_raw_mag": 10.72417928803135, "train/extr_return_raw_max": 10.72417928803135, "train/extr_return_raw_mean": 2.76302832365036, "train/extr_return_raw_min": -0.5102056982651563, "train/extr_return_raw_std": 2.349499928279662, "train/extr_reward_mag": 1.0422981608081872, "train/extr_reward_max": 1.0422981608081872, "train/extr_reward_mean": 0.05013059831263734, "train/extr_reward_min": -0.4327462676545264, "train/extr_reward_std": 0.2082634220870448, "train/image_loss_mean": 6.498060921548118, "train/image_loss_std": 12.141759492981603, "train/model_loss_mean": 14.373996177189786, "train/model_loss_std": 15.721156167312406, "train/model_opt_grad_norm": 55.04808566939663, "train/model_opt_grad_steps": 54406.69718309859, "train/model_opt_loss": 19671.698097766286, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1382.0422535211267, "train/policy_entropy_mag": 2.6393325832528127, "train/policy_entropy_max": 2.6393325832528127, "train/policy_entropy_mean": 0.6002116322937147, "train/policy_entropy_min": 0.07937502205161981, "train/policy_entropy_std": 0.70272454556445, "train/policy_logprob_mag": 7.438383753870575, "train/policy_logprob_max": -0.009455658397047033, "train/policy_logprob_mean": -0.6005562014982734, "train/policy_logprob_min": -7.438383753870575, "train/policy_logprob_std": 1.1379428065158952, "train/policy_randomness_mag": 0.9315685768362502, "train/policy_randomness_max": 0.9315685768362502, "train/policy_randomness_mean": 0.21184836863212184, "train/policy_randomness_min": 0.02801589948505583, "train/policy_randomness_std": 0.24803092477607055, "train/post_ent_mag": 58.34724348363742, "train/post_ent_max": 58.34724348363742, "train/post_ent_mean": 42.266967504796845, "train/post_ent_min": 19.664115798305456, "train/post_ent_std": 7.577819669750375, "train/prior_ent_mag": 66.86209697454748, "train/prior_ent_max": 66.86209697454748, "train/prior_ent_mean": 55.36393119919468, "train/prior_ent_min": 40.42407696683642, "train/prior_ent_std": 4.17629655146263, "train/rep_loss_mean": 13.028286228717214, "train/rep_loss_std": 9.030652093215727, "train/reward_avg": 0.03161105282709632, "train/reward_loss_mean": 0.05870698297947225, "train/reward_loss_std": 0.25687237839463734, "train/reward_max_data": 1.0218309911204055, "train/reward_max_pred": 1.0121720962121452, "train/reward_neg_acc": 0.992401016849867, "train/reward_neg_loss": 0.029791069656453083, "train/reward_pos_acc": 0.9691713074563255, "train/reward_pos_loss": 0.8395927829641692, "train/reward_pred": 0.03075572564332208, "train/reward_rate": 0.035878356073943664, "train_stats/sum_log_reward": 9.8551022081959, "train_stats/max_log_achievement_collect_coal": 0.6326530612244898, "train_stats/max_log_achievement_collect_drink": 5.479591836734694, "train_stats/max_log_achievement_collect_sapling": 1.7448979591836735, "train_stats/max_log_achievement_collect_stone": 8.428571428571429, "train_stats/max_log_achievement_collect_wood": 11.346938775510203, "train_stats/max_log_achievement_defeat_skeleton": 0.030612244897959183, "train_stats/max_log_achievement_defeat_zombie": 0.9183673469387755, "train_stats/max_log_achievement_eat_cow": 0.20408163265306123, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.01020408163265306, "train_stats/max_log_achievement_make_stone_sword": 0.01020408163265306, "train_stats/max_log_achievement_make_wood_pickaxe": 1.336734693877551, "train_stats/max_log_achievement_make_wood_sword": 1.4795918367346939, "train_stats/max_log_achievement_place_furnace": 0.47959183673469385, "train_stats/max_log_achievement_place_plant": 1.683673469387755, "train_stats/max_log_achievement_place_stone": 5.26530612244898, "train_stats/max_log_achievement_place_table": 2.6020408163265305, "train_stats/max_log_achievement_wake_up": 1.2448979591836735, "train_stats/mean_log_entropy": 0.6322242467074978, "eval_stats/sum_log_reward": 9.787500321865082, "eval_stats/max_log_achievement_collect_coal": 0.25, "eval_stats/max_log_achievement_collect_drink": 5.9375, "eval_stats/max_log_achievement_collect_sapling": 2.125, "eval_stats/max_log_achievement_collect_stone": 6.9375, "eval_stats/max_log_achievement_collect_wood": 9.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.125, "eval_stats/max_log_achievement_defeat_zombie": 0.75, "eval_stats/max_log_achievement_eat_cow": 0.375, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.25, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.1875, "eval_stats/max_log_achievement_place_plant": 1.875, "eval_stats/max_log_achievement_place_stone": 4.8125, "eval_stats/max_log_achievement_place_table": 2.25, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 3.664387986646034e-05, "report/cont_loss_std": 0.0009875849355012178, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00043122057104483247, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 3.4707776649156585e-05, "report/cont_pred": 0.9950851798057556, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 13.538558006286621, "report/dyn_loss_std": 8.748078346252441, "report/image_loss_mean": 6.531261444091797, "report/image_loss_std": 11.195322036743164, "report/model_loss_mean": 14.715473175048828, "report/model_loss_std": 14.570425987243652, "report/post_ent_mag": 57.84929656982422, "report/post_ent_max": 57.84929656982422, "report/post_ent_mean": 42.482940673828125, "report/post_ent_min": 20.64966583251953, "report/post_ent_std": 7.57924222946167, "report/prior_ent_mag": 66.687255859375, "report/prior_ent_max": 66.687255859375, "report/prior_ent_mean": 56.263084411621094, "report/prior_ent_min": 42.36216735839844, "report/prior_ent_std": 4.078917026519775, "report/rep_loss_mean": 13.538558006286621, "report/rep_loss_std": 8.748078346252441, "report/reward_avg": 0.03593749925494194, "report/reward_loss_mean": 0.06104053184390068, "report/reward_loss_std": 0.22639039158821106, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002335548400879, "report/reward_neg_acc": 0.9898270964622498, "report/reward_neg_loss": 0.03323943167924881, "report/reward_pos_acc": 0.9999999403953552, "report/reward_pos_loss": 0.7275888919830322, "report/reward_pred": 0.034682489931583405, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 1.4306200682767667e-05, "eval/cont_loss_std": 0.0003697472857311368, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0004969038418494165, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.288818475586595e-05, "eval/cont_pred": 0.9970589280128479, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 19.647846221923828, "eval/dyn_loss_std": 9.792372703552246, "eval/image_loss_mean": 10.04840087890625, "eval/image_loss_std": 14.382467269897461, "eval/model_loss_mean": 21.927722930908203, "eval/model_loss_std": 18.475509643554688, "eval/post_ent_mag": 58.5709114074707, "eval/post_ent_max": 58.5709114074707, "eval/post_ent_mean": 39.1700325012207, "eval/post_ent_min": 20.236101150512695, "eval/post_ent_std": 7.181082248687744, "eval/prior_ent_mag": 66.687255859375, "eval/prior_ent_max": 66.687255859375, "eval/prior_ent_mean": 56.398170471191406, "eval/prior_ent_min": 43.03700637817383, "eval/prior_ent_std": 3.3246452808380127, "eval/rep_loss_mean": 19.647846221923828, "eval/rep_loss_std": 9.792372703552246, "eval/reward_avg": 0.02314453199505806, "eval/reward_loss_mean": 0.09059938043355942, "eval/reward_loss_std": 0.604224443435669, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0006277561187744, "eval/reward_neg_acc": 0.9899699091911316, "eval/reward_neg_loss": 0.04006879776716232, "eval/reward_pos_acc": 0.7777777910232544, "eval/reward_pos_loss": 1.956488013267517, "eval/reward_pred": 0.017805451527237892, "eval/reward_rate": 0.0263671875, "replay/size": 883745.0, "replay/inserts": 22720.0, "replay/samples": 22720.0, "replay/insert_wait_avg": 1.3164861101499746e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.247106290199388e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4320.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0658745412473325e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.344650268554688e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1001.1367490291595, "timer/env.step_count": 2840.0, "timer/env.step_total": 237.58088207244873, "timer/env.step_frac": 0.23731111888844353, "timer/env.step_avg": 0.08365524016635519, "timer/env.step_min": 0.023014307022094727, "timer/env.step_max": 3.5864994525909424, "timer/replay._sample_count": 22720.0, "timer/replay._sample_total": 11.222307682037354, "timer/replay._sample_frac": 0.011209565219656608, "timer/replay._sample_avg": 0.0004939395986812216, "timer/replay._sample_min": 0.00038743019104003906, "timer/replay._sample_max": 0.009550809860229492, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3380.0, "timer/agent.policy_total": 55.634143114089966, "timer/agent.policy_frac": 0.055570972864636636, "timer/agent.policy_avg": 0.0164598056550562, "timer/agent.policy_min": 0.008944034576416016, "timer/agent.policy_max": 0.1296522617340088, "timer/dataset_train_count": 1420.0, "timer/dataset_train_total": 0.15159964561462402, "timer/dataset_train_frac": 0.00015142751053903074, "timer/dataset_train_avg": 0.00010676031381311551, "timer/dataset_train_min": 9.107589721679688e-05, "timer/dataset_train_max": 0.0006406307220458984, "timer/agent.train_count": 1420.0, "timer/agent.train_total": 637.9733691215515, "timer/agent.train_frac": 0.6372489769656529, "timer/agent.train_avg": 0.4492770205081349, "timer/agent.train_min": 0.4346733093261719, "timer/agent.train_max": 1.6117899417877197, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47797250747680664, "timer/agent.report_frac": 0.00047742978962695635, "timer/agent.report_avg": 0.23898625373840332, "timer/agent.report_min": 0.23320531845092773, "timer/agent.report_max": 0.2447671890258789, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8848648071289062e-05, "timer/dataset_eval_frac": 2.8815891634449237e-08, "timer/dataset_eval_avg": 2.8848648071289062e-05, "timer/dataset_eval_min": 2.8848648071289062e-05, "timer/dataset_eval_max": 2.8848648071289062e-05, "fps": 22.693917386145298}
{"step": 884464, "time": 40337.90320086479, "episode/length": 235.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 884504, "time": 40340.52931404114, "episode/length": 213.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9813084112149533, "episode/intrinsic_return": 0.0}
{"step": 885072, "time": 40363.01447033882, "episode/length": 140.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9929078014184397, "episode/intrinsic_return": 0.0}
{"step": 885240, "time": 40370.19083189964, "episode/length": 229.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 885512, "time": 40380.93391799927, "episode/length": 243.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 885696, "time": 40389.55360078812, "episode/length": 180.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 885944, "time": 40399.927513837814, "episode/length": 184.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 886000, "time": 40403.65082669258, "episode/length": 426.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789227166276346, "episode/intrinsic_return": 0.0}
{"step": 886128, "time": 40409.52530860901, "episode/length": 202.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 886672, "time": 40430.071498155594, "episode/length": 178.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9664804469273743, "episode/intrinsic_return": 0.0}
{"step": 886680, "time": 40431.63729739189, "episode/length": 200.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 886912, "time": 40441.08532786369, "episode/length": 151.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9539473684210527, "episode/intrinsic_return": 0.0}
{"step": 887048, "time": 40446.98789715767, "episode/length": 372.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9946380697050938, "episode/intrinsic_return": 0.0}
{"step": 887272, "time": 40456.121282339096, "episode/length": 165.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9819277108433735, "episode/intrinsic_return": 0.0}
{"step": 887464, "time": 40464.146230220795, "episode/length": 243.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 887632, "time": 40471.55906319618, "episode/length": 187.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 887800, "time": 40478.492810964584, "episode/length": 224.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 888152, "time": 40491.92598485947, "episode/length": 183.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9782608695652174, "episode/intrinsic_return": 0.0}
{"step": 888504, "time": 40505.15675115585, "episode/length": 198.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 888728, "time": 40514.18686270714, "episode/length": 181.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9725274725274725, "episode/intrinsic_return": 0.0}
{"step": 888776, "time": 40517.410024642944, "episode/length": 215.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 888944, "time": 40524.70290017128, "episode/length": 184.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.972972972972973, "episode/intrinsic_return": 0.0}
{"step": 889048, "time": 40529.45549035072, "episode/length": 67.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9852941176470589, "episode/intrinsic_return": 0.0}
{"step": 889072, "time": 40532.12357831001, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9559748427672956, "episode/intrinsic_return": 0.0}
{"step": 890032, "time": 40584.38137745857, "eval_episode/length": 149.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 890032, "time": 40584.38886356354, "eval_episode/length": 149.0, "eval_episode/score": 5.1000000312924385, "eval_episode/reward_rate": 0.9933333333333333}
{"step": 890032, "time": 40590.585079431534, "eval_episode/length": 217.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9724770642201835}
{"step": 890032, "time": 40590.593277454376, "eval_episode/length": 217.0, "eval_episode/score": 8.100000016391277, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 890032, "time": 40596.75216293335, "eval_episode/length": 285.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9825174825174825}
{"step": 890032, "time": 40598.73528218269, "eval_episode/length": 294.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.976271186440678}
{"step": 890032, "time": 40602.299575805664, "eval_episode/length": 57.0, "eval_episode/score": 6.099999971687794, "eval_episode/reward_rate": 0.9827586206896551}
{"step": 890032, "time": 40604.37957215309, "eval_episode/length": 207.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9759615384615384}
{"step": 890184, "time": 40609.163209438324, "episode/length": 181.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9945054945054945, "episode/intrinsic_return": 0.0}
{"step": 890560, "time": 40623.304469347, "episode/length": 222.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 890576, "time": 40625.53237462044, "episode/length": 487.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9979508196721312, "episode/intrinsic_return": 0.0}
{"step": 890912, "time": 40638.24850773811, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780487804878049, "episode/intrinsic_return": 0.0}
{"step": 891008, "time": 40642.98504638672, "episode/length": 356.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9971988795518207, "episode/intrinsic_return": 0.0}
{"step": 891144, "time": 40648.895629405975, "episode/length": 274.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9745454545454545, "episode/intrinsic_return": 0.0}
{"step": 891808, "time": 40672.75792956352, "episode/length": 202.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 892144, "time": 40685.51674866676, "episode/length": 41.0, "episode/score": 6.100000023841858, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 892152, "time": 40687.10340189934, "episode/length": 142.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.965034965034965, "episode/intrinsic_return": 0.0}
{"step": 892264, "time": 40692.41556549072, "episode/length": 210.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.976303317535545, "episode/intrinsic_return": 0.0}
{"step": 892296, "time": 40695.08882880211, "episode/length": 216.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9769585253456221, "episode/intrinsic_return": 0.0}
{"step": 892456, "time": 40702.2388882637, "episode/length": 422.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 892736, "time": 40714.12259864807, "episode/length": 227.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 892768, "time": 40717.24971795082, "episode/length": 464.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9978494623655914, "episode/intrinsic_return": 0.0}
{"step": 893168, "time": 40734.23444080353, "episode/length": 252.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 893408, "time": 40743.78409266472, "episode/length": 138.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9928057553956835, "episode/intrinsic_return": 0.0}
{"step": 893608, "time": 40751.931624650955, "episode/length": 108.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.963302752293578, "episode/intrinsic_return": 0.0}
{"step": 893928, "time": 40764.22472524643, "episode/length": 222.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 894096, "time": 40771.66270947456, "episode/length": 242.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 894472, "time": 40785.6291179657, "episode/length": 212.0, "episode/score": 5.099999979138374, "episode/reward_rate": 0.9953051643192489, "episode/intrinsic_return": 0.0}
{"step": 894504, "time": 40788.29619216919, "episode/length": 255.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.97265625, "episode/intrinsic_return": 0.0}
{"step": 894512, "time": 40790.42481613159, "episode/length": 280.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 894776, "time": 40800.65584945679, "episode/length": 200.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9950248756218906, "episode/intrinsic_return": 0.0}
{"step": 895048, "time": 40811.306389570236, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 895120, "time": 40815.547112226486, "episode/length": 188.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 895656, "time": 40834.763229608536, "episode/length": 194.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9743589743589743, "episode/intrinsic_return": 0.0}
{"step": 895672, "time": 40836.937640190125, "episode/length": 149.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9733333333333334, "episode/intrinsic_return": 0.0}
{"step": 895728, "time": 40840.724578619, "episode/length": 152.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 896168, "time": 40856.628288030624, "episode/length": 279.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 896200, "time": 40859.361390829086, "episode/length": 177.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9606741573033708, "episode/intrinsic_return": 0.0}
{"step": 896496, "time": 40871.21040916443, "episode/length": 171.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 896712, "time": 40879.642837524414, "episode/length": 274.0, "episode/score": 5.100000008940697, "episode/reward_rate": 0.9963636363636363, "episode/intrinsic_return": 0.0}
{"step": 897128, "time": 40895.058762550354, "episode/length": 259.0, "episode/score": 11.100000038743019, "episode/reward_rate": 0.9961538461538462, "episode/intrinsic_return": 0.0}
{"step": 897392, "time": 40905.72707366943, "episode/length": 207.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9951923076923077, "episode/intrinsic_return": 0.0}
{"step": 897520, "time": 40911.505303144455, "episode/length": 230.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 897536, "time": 40913.63940024376, "episode/length": 50.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9803921568627451, "episode/intrinsic_return": 0.0}
{"step": 898064, "time": 40932.85068273544, "episode/length": 232.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 898528, "time": 40950.48810553551, "episode/length": 358.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9916434540389972, "episode/intrinsic_return": 0.0}
{"step": 898784, "time": 40960.721106767654, "episode/length": 173.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 898984, "time": 40968.72208547592, "episode/length": 180.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 899136, "time": 40975.46864390373, "episode/length": 370.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9946091644204852, "episode/intrinsic_return": 0.0}
{"step": 899864, "time": 41000.832169532776, "episode/length": 420.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9904988123515439, "episode/intrinsic_return": 0.0}
{"step": 900016, "time": 41023.11401176453, "eval_episode/length": 63.0, "eval_episode/score": 6.100000008940697, "eval_episode/reward_rate": 0.984375}
{"step": 900016, "time": 41027.44115424156, "eval_episode/length": 134.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9629629629629629}
{"step": 900016, "time": 41030.690264225006, "eval_episode/length": 175.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9715909090909091}
{"step": 900016, "time": 41032.75854063034, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.973404255319149}
{"step": 900016, "time": 41035.41497755051, "eval_episode/length": 214.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9813953488372092}
{"step": 900016, "time": 41037.65809082985, "eval_episode/length": 229.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9739130434782609}
{"step": 900016, "time": 41039.34920787811, "eval_episode/length": 233.0, "eval_episode/score": 11.100000001490116, "eval_episode/reward_rate": 0.9957264957264957}
{"step": 900016, "time": 41044.006341934204, "eval_episode/length": 177.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9719101123595506}
{"step": 900384, "time": 41056.137261629105, "episode/length": 199.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 900488, "time": 41060.90873026848, "episode/length": 471.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9978813559322034, "episode/intrinsic_return": 0.0}
{"step": 900816, "time": 41073.75010943413, "episode/length": 411.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9902912621359223, "episode/intrinsic_return": 0.0}
{"step": 901048, "time": 41082.83622789383, "episode/length": 314.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9841269841269841, "episode/intrinsic_return": 0.0}
{"step": 901448, "time": 41099.17963004112, "episode/length": 132.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9924812030075187, "episode/intrinsic_return": 0.0}
{"step": 901584, "time": 41105.42730355263, "episode/length": 439.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9977272727272727, "episode/intrinsic_return": 0.0}
{"step": 902112, "time": 41125.058579683304, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9704433497536946, "episode/intrinsic_return": 0.0}
{"step": 902496, "time": 41139.89787006378, "episode/length": 438.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.979498861047836, "episode/intrinsic_return": 0.0}
{"step": 902616, "time": 41145.79602432251, "episode/length": 434.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 902688, "time": 41150.52485156059, "episode/length": 352.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9886685552407932, "episode/intrinsic_return": 0.0}
{"step": 903056, "time": 41165.34226822853, "episode/length": 200.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9900497512437811, "episode/intrinsic_return": 0.0}
{"step": 903256, "time": 41173.98217701912, "episode/length": 208.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 903296, "time": 41177.03423142433, "episode/length": 280.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.99644128113879, "episode/intrinsic_return": 0.0}
{"step": 903648, "time": 41190.377662181854, "episode/length": 353.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9971751412429378, "episode/intrinsic_return": 0.0}
{"step": 903896, "time": 41200.114117622375, "episode/length": 79.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9875, "episode/intrinsic_return": 0.0}
{"step": 903920, "time": 41202.80173206329, "episode/length": 177.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9775280898876404, "episode/intrinsic_return": 0.0}
{"step": 904040, "time": 41208.064980983734, "episode/length": 240.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 904128, "time": 41212.75387811661, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 904176, "time": 41215.83745479584, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 904592, "time": 41231.28656101227, "episode/length": 191.0, "episode/score": 13.100000016391277, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 904872, "time": 41241.845233917236, "episode/length": 118.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.957983193277311, "episode/intrinsic_return": 0.0}
{"step": 904912, "time": 41244.95241332054, "episode/length": 201.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 905512, "time": 41266.42558383942, "episode/length": 183.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 905984, "time": 41283.81454730034, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 905992, "time": 41285.51879692078, "episode/length": 226.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 906216, "time": 41294.72505283356, "episode/length": 320.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9968847352024922, "episode/intrinsic_return": 0.0}
{"step": 906376, "time": 41301.524253606796, "episode/length": 187.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.973404255319149, "episode/intrinsic_return": 0.0}
{"step": 906816, "time": 41318.20598220825, "episode/length": 102.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9611650485436893, "episode/intrinsic_return": 0.0}
{"step": 906848, "time": 41321.591086149216, "episode/length": 368.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.994579945799458, "episode/intrinsic_return": 0.0}
{"step": 907033, "time": 41330.71429157257, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.61941720388986, "train/action_min": 0.0, "train/action_std": 3.4467674602161753, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03321287232626985, "train/actor_opt_grad_steps": 55880.0, "train/actor_opt_loss": -6.931813333886904, "train/adv_mag": 0.42366385084765773, "train/adv_max": 0.3898484683953799, "train/adv_mean": 0.0024809497693755868, "train/adv_min": -0.3496733561053976, "train/adv_std": 0.049610991812460904, "train/cont_avg": 0.9949806053321678, "train/cont_loss_mean": 0.00023959108972945246, "train/cont_loss_std": 0.007197180727676677, "train/cont_neg_acc": 0.9936564230749793, "train/cont_neg_loss": 0.025326402556128034, "train/cont_pos_acc": 0.9999725368473079, "train/cont_pos_loss": 5.116162840947057e-05, "train/cont_pred": 0.9949998813909251, "train/cont_rate": 0.9949806053321678, "train/dyn_loss_mean": 13.206100203774191, "train/dyn_loss_std": 9.080300998020839, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9633741870626703, "train/extr_critic_critic_opt_grad_steps": 55880.0, "train/extr_critic_critic_opt_loss": 15766.687062937062, "train/extr_critic_mag": 9.475793958543898, "train/extr_critic_max": 9.475793958543898, "train/extr_critic_mean": 2.790975568177817, "train/extr_critic_min": -0.18126177704417623, "train/extr_critic_std": 2.282957374632775, "train/extr_return_normed_mag": 1.478589869045711, "train/extr_return_normed_max": 1.478589869045711, "train/extr_return_normed_mean": 0.38352372773460575, "train/extr_return_normed_min": -0.08801835441922808, "train/extr_return_normed_std": 0.32523916265764435, "train/extr_return_rate": 0.809055442159826, "train/extr_return_raw_mag": 10.578859729366703, "train/extr_return_raw_max": 10.578859729366703, "train/extr_return_raw_mean": 2.8085544342761275, "train/extr_return_raw_min": -0.5371051096207612, "train/extr_return_raw_std": 2.308080393951256, "train/extr_reward_mag": 1.0517544462964252, "train/extr_reward_max": 1.0517544462964252, "train/extr_reward_mean": 0.049815948909291856, "train/extr_reward_min": -0.448971451579274, "train/extr_reward_std": 0.2088546008913667, "train/image_loss_mean": 6.450707795736673, "train/image_loss_std": 12.225674319100547, "train/model_loss_mean": 14.433079232702722, "train/model_loss_std": 15.828177852230473, "train/model_opt_grad_norm": 55.8877898796455, "train/model_opt_grad_steps": 55830.454545454544, "train/model_opt_loss": 19012.19437008304, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1319.93006993007, "train/policy_entropy_mag": 2.6363627177018385, "train/policy_entropy_max": 2.6363627177018385, "train/policy_entropy_mean": 0.606959970264168, "train/policy_entropy_min": 0.07937501954448807, "train/policy_entropy_std": 0.7067542074026761, "train/policy_logprob_mag": 7.438383792663788, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.6069446995958582, "train/policy_logprob_min": -7.438383792663788, "train/policy_logprob_std": 1.1424725530864475, "train/policy_randomness_mag": 0.9305203498660267, "train/policy_randomness_max": 0.9305203498660267, "train/policy_randomness_mean": 0.21423023480635422, "train/policy_randomness_min": 0.02801589867087094, "train/policy_randomness_std": 0.24945322095930994, "train/post_ent_mag": 57.93592813131693, "train/post_ent_max": 57.93592813131693, "train/post_ent_mean": 42.07550302252069, "train/post_ent_min": 19.54268259435267, "train/post_ent_std": 7.537306845604957, "train/prior_ent_mag": 66.8540102018343, "train/prior_ent_max": 66.8540102018343, "train/prior_ent_mean": 55.369985460401416, "train/prior_ent_min": 40.66238243263084, "train/prior_ent_std": 4.124413907111108, "train/rep_loss_mean": 13.206100203774191, "train/rep_loss_std": 9.080300998020839, "train/reward_avg": 0.032401387345280266, "train/reward_loss_mean": 0.058471769537333844, "train/reward_loss_std": 0.24863716063799557, "train/reward_max_data": 1.0181818225167014, "train/reward_max_pred": 1.0125974725176405, "train/reward_neg_acc": 0.9924788700117098, "train/reward_neg_loss": 0.02936474502842118, "train/reward_pos_acc": 0.9735599568673781, "train/reward_pos_loss": 0.8207765334136002, "train/reward_pred": 0.031522592197504494, "train/reward_rate": 0.036836210664335664, "train_stats/sum_log_reward": 9.657894977770354, "train_stats/max_log_achievement_collect_coal": 0.3684210526315789, "train_stats/max_log_achievement_collect_drink": 5.589473684210526, "train_stats/max_log_achievement_collect_sapling": 1.9263157894736842, "train_stats/max_log_achievement_collect_stone": 7.7894736842105265, "train_stats/max_log_achievement_collect_wood": 11.010526315789473, "train_stats/max_log_achievement_defeat_skeleton": 0.031578947368421054, "train_stats/max_log_achievement_defeat_zombie": 0.7894736842105263, "train_stats/max_log_achievement_eat_cow": 0.18947368421052632, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.021052631578947368, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3789473684210527, "train_stats/max_log_achievement_make_wood_sword": 1.1473684210526316, "train_stats/max_log_achievement_place_furnace": 0.5263157894736842, "train_stats/max_log_achievement_place_plant": 1.8736842105263158, "train_stats/max_log_achievement_place_stone": 4.568421052631579, "train_stats/max_log_achievement_place_table": 2.863157894736842, "train_stats/max_log_achievement_wake_up": 1.4, "train_stats/mean_log_entropy": 0.6305042207241058, "eval_stats/sum_log_reward": 8.85000017285347, "eval_stats/max_log_achievement_collect_coal": 0.8125, "eval_stats/max_log_achievement_collect_drink": 6.375, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 3.8125, "eval_stats/max_log_achievement_collect_wood": 8.0, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 1.1875, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.9375, "eval_stats/max_log_achievement_make_wood_sword": 0.875, "eval_stats/max_log_achievement_place_furnace": 0.125, "eval_stats/max_log_achievement_place_plant": 1.3125, "eval_stats/max_log_achievement_place_stone": 2.875, "eval_stats/max_log_achievement_place_table": 2.125, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 0.00012764940038323402, "report/cont_loss_std": 0.003817519638687372, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 6.624617526540533e-05, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00012795068323612213, "report/cont_pred": 0.9949971437454224, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.776966094970703, "report/dyn_loss_std": 8.634737968444824, "report/image_loss_mean": 7.595017433166504, "report/image_loss_std": 13.844191551208496, "report/model_loss_mean": 14.73045539855957, "report/model_loss_std": 17.293848037719727, "report/post_ent_mag": 57.297157287597656, "report/post_ent_max": 57.297157287597656, "report/post_ent_mean": 43.757049560546875, "report/post_ent_min": 20.80270004272461, "report/post_ent_std": 7.222452640533447, "report/prior_ent_mag": 66.65738677978516, "report/prior_ent_max": 66.65738677978516, "report/prior_ent_mean": 55.57853698730469, "report/prior_ent_min": 39.06128692626953, "report/prior_ent_std": 4.513455867767334, "report/rep_loss_mean": 11.776966094970703, "report/rep_loss_std": 8.634737968444824, "report/reward_avg": 0.02128906175494194, "report/reward_loss_mean": 0.06913092732429504, "report/reward_loss_std": 0.3143593370914459, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.001131534576416, "report/reward_neg_acc": 0.9959840178489685, "report/reward_neg_loss": 0.046991992741823196, "report/reward_pos_acc": 1.0, "report/reward_pos_loss": 0.8566448092460632, "report/reward_pred": 0.01990450546145439, "report/reward_rate": 0.02734375, "eval/cont_avg": 0.9951171875, "eval/cont_loss_mean": 6.523513093270594e-06, "eval/cont_loss_std": 0.00015425834862980992, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 7.013196591287851e-05, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 6.211401341715828e-06, "eval/cont_pred": 0.995111346244812, "eval/cont_rate": 0.9951171875, "eval/dyn_loss_mean": 15.9595947265625, "eval/dyn_loss_std": 10.479150772094727, "eval/image_loss_mean": 8.839994430541992, "eval/image_loss_std": 15.644259452819824, "eval/model_loss_mean": 18.498781204223633, "eval/model_loss_std": 19.344877243041992, "eval/post_ent_mag": 56.400665283203125, "eval/post_ent_max": 56.400665283203125, "eval/post_ent_mean": 41.572723388671875, "eval/post_ent_min": 20.042041778564453, "eval/post_ent_std": 7.694973468780518, "eval/prior_ent_mag": 66.65738677978516, "eval/prior_ent_max": 66.65738677978516, "eval/prior_ent_mean": 55.660980224609375, "eval/prior_ent_min": 43.947288513183594, "eval/prior_ent_std": 3.932431936264038, "eval/rep_loss_mean": 15.9595947265625, "eval/rep_loss_std": 10.479150772094727, "eval/reward_avg": 0.05537109449505806, "eval/reward_loss_mean": 0.08302436769008636, "eval/reward_loss_std": 0.38058215379714966, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 0.9999381303787231, "eval/reward_neg_acc": 0.9927310943603516, "eval/reward_neg_loss": 0.029396049678325653, "eval/reward_pos_acc": 0.950819730758667, "eval/reward_pos_loss": 0.9296486377716064, "eval/reward_pred": 0.05386994779109955, "eval/reward_rate": 0.0595703125, "replay/size": 906529.0, "replay/inserts": 22784.0, "replay/samples": 22784.0, "replay/insert_wait_avg": 1.3483981235643452e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.319776864534014e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5368.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0693304229599885e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.748603820800781e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.0236992835999, "timer/env.step_count": 2848.0, "timer/env.step_total": 232.43811583518982, "timer/env.step_frac": 0.2324326073489104, "timer/env.step_avg": 0.08161450696460316, "timer/env.step_min": 0.022320032119750977, "timer/env.step_max": 2.298757553100586, "timer/replay._sample_count": 22784.0, "timer/replay._sample_total": 11.291870355606079, "timer/replay._sample_frac": 0.011291602752710145, "timer/replay._sample_avg": 0.0004956052649054634, "timer/replay._sample_min": 0.0003604888916015625, "timer/replay._sample_max": 0.008697271347045898, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3519.0, "timer/agent.policy_total": 56.106321573257446, "timer/agent.policy_frac": 0.05610499192514244, "timer/agent.policy_avg": 0.01594382539734511, "timer/agent.policy_min": 0.009241104125976562, "timer/agent.policy_max": 0.09862923622131348, "timer/dataset_train_count": 1424.0, "timer/dataset_train_total": 0.15128326416015625, "timer/dataset_train_frac": 0.00015127967894014216, "timer/dataset_train_avg": 0.00010623824730348052, "timer/dataset_train_min": 9.059906005859375e-05, "timer/dataset_train_max": 0.0009615421295166016, "timer/agent.train_count": 1424.0, "timer/agent.train_total": 641.2458837032318, "timer/agent.train_frac": 0.6412306869953278, "timer/agent.train_avg": 0.45031312057811224, "timer/agent.train_min": 0.43433666229248047, "timer/agent.train_max": 1.6227421760559082, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4793965816497803, "timer/agent.report_frac": 0.00047938522056348456, "timer/agent.report_avg": 0.23969829082489014, "timer/agent.report_min": 0.23448657989501953, "timer/agent.report_max": 0.24491000175476074, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.6702880859375e-05, "timer/dataset_eval_frac": 2.6702248035226058e-08, "timer/dataset_eval_avg": 2.6702880859375e-05, "timer/dataset_eval_min": 2.6702880859375e-05, "timer/dataset_eval_max": 2.6702880859375e-05, "fps": 22.783144553298957}
{"step": 907048, "time": 41330.80435180664, "episode/length": 266.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9850187265917603, "episode/intrinsic_return": 0.0}
{"step": 907176, "time": 41337.65283846855, "episode/length": 44.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 907184, "time": 41340.228219270706, "episode/length": 208.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 907312, "time": 41346.62201476097, "episode/length": 57.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9827586206896551, "episode/intrinsic_return": 0.0}
{"step": 907400, "time": 41351.517365932465, "episode/length": 408.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9902200488997555, "episode/intrinsic_return": 0.0}
{"step": 907736, "time": 41365.01024770737, "episode/length": 218.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 907880, "time": 41371.327652692795, "episode/length": 207.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9855769230769231, "episode/intrinsic_return": 0.0}
{"step": 908160, "time": 41382.64346194267, "episode/length": 222.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 908480, "time": 41395.39395356178, "episode/length": 162.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9938650306748467, "episode/intrinsic_return": 0.0}
{"step": 908608, "time": 41401.30347967148, "episode/length": 55.0, "episode/score": 4.100000016391277, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 908912, "time": 41413.13588166237, "episode/length": 199.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 908976, "time": 41416.89593887329, "episode/length": 240.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995850622406639, "episode/intrinsic_return": 0.0}
{"step": 909016, "time": 41419.50994706154, "episode/length": 201.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 909144, "time": 41425.32276916504, "episode/length": 244.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9755102040816327, "episode/intrinsic_return": 0.0}
{"step": 909696, "time": 41447.15286707878, "episode/length": 244.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959183673469387, "episode/intrinsic_return": 0.0}
{"step": 909696, "time": 41447.16149187088, "episode/length": 135.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9632352941176471, "episode/intrinsic_return": 0.0}
{"step": 910000, "time": 41477.84246087074, "eval_episode/length": 60.0, "eval_episode/score": 3.099999986588955, "eval_episode/reward_rate": 0.9180327868852459}
{"step": 910000, "time": 41483.41013264656, "eval_episode/length": 113.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.956140350877193}
{"step": 910000, "time": 41487.50297117233, "eval_episode/length": 171.0, "eval_episode/score": 12.100000031292439, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 910000, "time": 41489.46176028252, "eval_episode/length": 181.0, "eval_episode/score": 8.100000001490116, "eval_episode/reward_rate": 0.978021978021978}
{"step": 910000, "time": 41492.72792315483, "eval_episode/length": 220.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9728506787330317}
{"step": 910000, "time": 41492.736253499985, "eval_episode/length": 220.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.995475113122172}
{"step": 910000, "time": 41498.74242448807, "eval_episode/length": 217.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9770642201834863}
{"step": 910000, "time": 41502.02647447586, "eval_episode/length": 96.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9896907216494846}
{"step": 910224, "time": 41509.51135444641, "episode/length": 217.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 910248, "time": 41511.64758181572, "episode/length": 295.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9763513513513513, "episode/intrinsic_return": 0.0}
{"step": 910416, "time": 41519.07463264465, "episode/length": 89.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 910584, "time": 41525.92480254173, "episode/length": 195.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 910912, "time": 41538.7040913105, "episode/length": 220.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9773755656108597, "episode/intrinsic_return": 0.0}
{"step": 911032, "time": 41543.95098948479, "episode/length": 97.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 911208, "time": 41551.48696017265, "episode/length": 286.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.9965156794425087, "episode/intrinsic_return": 0.0}
{"step": 911408, "time": 41560.707842588425, "episode/length": 303.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9967105263157895, "episode/intrinsic_return": 0.0}
{"step": 911528, "time": 41566.651623010635, "episode/length": 228.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 911648, "time": 41573.01049017906, "episode/length": 153.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 912592, "time": 41606.215592861176, "episode/length": 209.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9809523809523809, "episode/intrinsic_return": 0.0}
{"step": 912632, "time": 41608.95304751396, "episode/length": 199.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.995, "episode/intrinsic_return": 0.0}
{"step": 912808, "time": 41616.45138955116, "episode/length": 277.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 912864, "time": 41620.21286535263, "episode/length": 206.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 912872, "time": 41621.79208278656, "episode/length": 182.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9726775956284153, "episode/intrinsic_return": 0.0}
{"step": 913456, "time": 41643.088968753815, "episode/length": 403.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975247524752475, "episode/intrinsic_return": 0.0}
{"step": 913592, "time": 41648.967977285385, "episode/length": 257.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9806201550387597, "episode/intrinsic_return": 0.0}
{"step": 913640, "time": 41652.270394563675, "episode/length": 248.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9839357429718876, "episode/intrinsic_return": 0.0}
{"step": 914120, "time": 41670.28314733505, "episode/length": 163.0, "episode/score": 10.100000016391277, "episode/reward_rate": 0.9695121951219512, "episode/intrinsic_return": 0.0}
{"step": 914248, "time": 41676.7984046936, "episode/length": 201.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995049504950495, "episode/intrinsic_return": 0.0}
{"step": 914488, "time": 41686.76487660408, "episode/length": 236.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9831223628691983, "episode/intrinsic_return": 0.0}
{"step": 914544, "time": 41690.84883093834, "episode/length": 208.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9760765550239234, "episode/intrinsic_return": 0.0}
{"step": 915016, "time": 41708.132585048676, "episode/length": 65.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9242424242424242, "episode/intrinsic_return": 0.0}
{"step": 915192, "time": 41716.104449272156, "episode/length": 193.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 915232, "time": 41719.23616242409, "episode/length": 295.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9966216216216216, "episode/intrinsic_return": 0.0}
{"step": 915664, "time": 41735.089475631714, "episode/length": 258.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 915696, "time": 41737.82368302345, "episode/length": 180.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9723756906077348, "episode/intrinsic_return": 0.0}
{"step": 915864, "time": 41744.88753938675, "episode/length": 217.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 916504, "time": 41767.63066530228, "episode/length": 158.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 916696, "time": 41776.311974048615, "episode/length": 209.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9952380952380953, "episode/intrinsic_return": 0.0}
{"step": 916776, "time": 41780.74138045311, "episode/length": 197.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 916864, "time": 41785.30039405823, "episode/length": 145.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9931506849315068, "episode/intrinsic_return": 0.0}
{"step": 917576, "time": 41811.97112393379, "episode/length": 213.0, "episode/score": 10.099999979138374, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 917792, "time": 41820.95396113396, "episode/length": 541.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.992619926199262, "episode/intrinsic_return": 0.0}
{"step": 917808, "time": 41823.18200778961, "episode/length": 407.0, "episode/score": 12.099999964237213, "episode/reward_rate": 0.9975490196078431, "episode/intrinsic_return": 0.0}
{"step": 918080, "time": 41834.044028759, "episode/length": 162.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9693251533742331, "episode/intrinsic_return": 0.0}
{"step": 918152, "time": 41837.75144672394, "episode/length": 181.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.967032967032967, "episode/intrinsic_return": 0.0}
{"step": 918264, "time": 41842.988582372665, "episode/length": 56.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9122807017543859, "episode/intrinsic_return": 0.0}
{"step": 918400, "time": 41849.334342479706, "episode/length": 191.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9739583333333334, "episode/intrinsic_return": 0.0}
{"step": 918440, "time": 41851.937920331955, "episode/length": 346.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9884726224783862, "episode/intrinsic_return": 0.0}
{"step": 918512, "time": 41856.15775060654, "episode/length": 250.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9760956175298805, "episode/intrinsic_return": 0.0}
{"step": 919032, "time": 41874.711446762085, "episode/length": 154.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9612903225806452, "episode/intrinsic_return": 0.0}
{"step": 919560, "time": 41893.894783973694, "episode/length": 247.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9959677419354839, "episode/intrinsic_return": 0.0}
{"step": 919672, "time": 41899.23615026474, "episode/length": 198.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 919960, "time": 41910.44819355011, "episode/length": 211.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9669811320754716, "episode/intrinsic_return": 0.0}
{"step": 920056, "time": 41915.24220132828, "episode/length": 206.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9758454106280193, "episode/intrinsic_return": 0.0}
{"step": 920088, "time": 41934.1111497879, "eval_episode/length": 70.0, "eval_episode/score": 7.100000038743019, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 920088, "time": 41940.02559876442, "eval_episode/length": 156.0, "eval_episode/score": 7.0999999940395355, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 920088, "time": 41942.48897981644, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 920088, "time": 41945.52580142021, "eval_episode/length": 187.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 920088, "time": 41947.65152621269, "eval_episode/length": 189.0, "eval_episode/score": 9.100000001490116, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 920088, "time": 41950.634234666824, "eval_episode/length": 207.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9903846153846154}
{"step": 920088, "time": 41954.08702421188, "eval_episode/length": 235.0, "eval_episode/score": 9.099999971687794, "eval_episode/reward_rate": 0.9957627118644068}
{"step": 920088, "time": 41956.306451797485, "eval_episode/length": 169.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9764705882352941}
{"step": 920256, "time": 41962.328204631805, "episode/length": 152.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9607843137254902, "episode/intrinsic_return": 0.0}
{"step": 920400, "time": 41969.24188995361, "episode/length": 244.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 920440, "time": 41972.50969052315, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 921328, "time": 42005.166669368744, "episode/length": 206.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 921448, "time": 42010.48893713951, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 921640, "time": 42018.36804294586, "episode/length": 172.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9942196531791907, "episode/intrinsic_return": 0.0}
{"step": 921688, "time": 42021.53424811363, "episode/length": 215.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953703703703703, "episode/intrinsic_return": 0.0}
{"step": 922040, "time": 42035.51265478134, "episode/length": 440.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9977324263038548, "episode/intrinsic_return": 0.0}
{"step": 922248, "time": 42044.03247785568, "episode/length": 230.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956709956709957, "episode/intrinsic_return": 0.0}
{"step": 922704, "time": 42060.88423061371, "episode/length": 330.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9879154078549849, "episode/intrinsic_return": 0.0}
{"step": 922872, "time": 42067.75161075592, "episode/length": 103.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9423076923076923, "episode/intrinsic_return": 0.0}
{"step": 922936, "time": 42071.54163694382, "episode/length": 311.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9903846153846154, "episode/intrinsic_return": 0.0}
{"step": 923120, "time": 42079.32571673393, "episode/length": 178.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9776536312849162, "episode/intrinsic_return": 0.0}
{"step": 923384, "time": 42089.48723769188, "episode/length": 217.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 923840, "time": 42106.834178209305, "episode/length": 198.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9698492462311558, "episode/intrinsic_return": 0.0}
{"step": 923848, "time": 42109.013921260834, "episode/length": 314.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9968253968253968, "episode/intrinsic_return": 0.0}
{"step": 923928, "time": 42113.25357961655, "episode/length": 309.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 924280, "time": 42126.63497710228, "episode/length": 196.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 924600, "time": 42139.08631634712, "episode/length": 207.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 925280, "time": 42164.51728105545, "episode/length": 236.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9746835443037974, "episode/intrinsic_return": 0.0}
{"step": 925312, "time": 42167.20862698555, "episode/length": 304.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.980327868852459, "episode/intrinsic_return": 0.0}
{"step": 925592, "time": 42177.96471953392, "episode/length": 123.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9919354838709677, "episode/intrinsic_return": 0.0}
{"step": 925704, "time": 42183.50201702118, "episode/length": 221.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 926352, "time": 42208.671307086945, "episode/length": 312.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9808306709265175, "episode/intrinsic_return": 0.0}
{"step": 926512, "time": 42215.57514286041, "episode/length": 423.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9858490566037735, "episode/intrinsic_return": 0.0}
{"step": 926864, "time": 42228.83872771263, "episode/length": 377.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973544973544973, "episode/intrinsic_return": 0.0}
{"step": 927000, "time": 42234.76212835312, "episode/length": 210.0, "episode/score": 8.100000016391277, "episode/reward_rate": 0.990521327014218, "episode/intrinsic_return": 0.0}
{"step": 927416, "time": 42250.1808719635, "episode/length": 391.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9974489795918368, "episode/intrinsic_return": 0.0}
{"step": 927480, "time": 42254.01878833771, "episode/length": 221.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 927672, "time": 42262.59458422661, "episode/length": 298.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9832775919732442, "episode/intrinsic_return": 0.0}
{"step": 927920, "time": 42273.2774002552, "episode/length": 195.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 927936, "time": 42275.89768600464, "episode/length": 133.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9626865671641791, "episode/intrinsic_return": 0.0}
{"step": 928024, "time": 42280.836886405945, "episode/length": 188.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 928408, "time": 42296.15648341179, "episode/length": 351.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9914772727272727, "episode/intrinsic_return": 0.0}
{"step": 929040, "time": 42320.2642288208, "episode/length": 202.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 929289, "time": 42331.019902944565, "train_stats/sum_log_reward": 9.996907489815937, "train_stats/max_log_achievement_collect_coal": 0.6701030927835051, "train_stats/max_log_achievement_collect_drink": 4.350515463917525, "train_stats/max_log_achievement_collect_sapling": 1.7525773195876289, "train_stats/max_log_achievement_collect_stone": 8.690721649484535, "train_stats/max_log_achievement_collect_wood": 10.938144329896907, "train_stats/max_log_achievement_defeat_skeleton": 0.061855670103092786, "train_stats/max_log_achievement_defeat_zombie": 0.8969072164948454, "train_stats/max_log_achievement_eat_cow": 0.24742268041237114, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010309278350515464, "train_stats/max_log_achievement_make_stone_sword": 0.010309278350515464, "train_stats/max_log_achievement_make_wood_pickaxe": 1.402061855670103, "train_stats/max_log_achievement_make_wood_sword": 1.2474226804123711, "train_stats/max_log_achievement_place_furnace": 0.865979381443299, "train_stats/max_log_achievement_place_plant": 1.6701030927835052, "train_stats/max_log_achievement_place_stone": 4.103092783505154, "train_stats/max_log_achievement_place_table": 2.618556701030928, "train_stats/max_log_achievement_wake_up": 1.288659793814433, "train_stats/mean_log_entropy": 0.6041623287901436, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.548020177607913, "train/action_min": 0.0, "train/action_std": 3.3908634202943433, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03394640032068002, "train/actor_opt_grad_steps": 57290.0, "train/actor_opt_loss": -4.4526737808323595, "train/adv_mag": 0.4487198653409807, "train/adv_max": 0.3959647427788741, "train/adv_mean": 0.003096341015027732, "train/adv_min": -0.3665372889033324, "train/adv_std": 0.050448935586128306, "train/cont_avg": 0.9953771357913669, "train/cont_loss_mean": 0.0002235679104778143, "train/cont_loss_std": 0.006140024245682195, "train/cont_neg_acc": 0.9892600221599607, "train/cont_neg_loss": 0.0233357235613001, "train/cont_pos_acc": 0.9999787588771298, "train/cont_pos_loss": 8.488263389520287e-05, "train/cont_pred": 0.9953933589750057, "train/cont_rate": 0.9953771357913669, "train/dyn_loss_mean": 13.17375113809709, "train/dyn_loss_std": 9.106701425511202, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9622369644453199, "train/extr_critic_critic_opt_grad_steps": 57290.0, "train/extr_critic_critic_opt_loss": 15874.136789006296, "train/extr_critic_mag": 9.638015301107503, "train/extr_critic_max": 9.638015301107503, "train/extr_critic_mean": 2.9473170162104876, "train/extr_critic_min": -0.16282928247245954, "train/extr_critic_std": 2.280750072259697, "train/extr_return_normed_mag": 1.4682698507103131, "train/extr_return_normed_max": 1.4682698507103131, "train/extr_return_normed_mean": 0.39549027962221517, "train/extr_return_normed_min": -0.07952177363762752, "train/extr_return_normed_std": 0.31814733265544015, "train/extr_return_rate": 0.8386484976295087, "train/extr_return_raw_mag": 10.777120789177983, "train/extr_return_raw_max": 10.777120789177983, "train/extr_return_raw_mean": 2.9698289821473813, "train/extr_return_raw_min": -0.4876017686274412, "train/extr_return_raw_std": 2.315339168198675, "train/extr_reward_mag": 1.0435157799892287, "train/extr_reward_max": 1.0435157799892287, "train/extr_reward_mean": 0.05192927716018485, "train/extr_reward_min": -0.44260124422663405, "train/extr_reward_std": 0.21195062501825018, "train/image_loss_mean": 6.295640633260604, "train/image_loss_std": 12.086004439017756, "train/model_loss_mean": 14.256607179161456, "train/model_loss_std": 15.694526720390046, "train/model_opt_grad_norm": 49.98008664906454, "train/model_opt_grad_steps": 57238.38129496403, "train/model_opt_loss": 11642.783378765738, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 818.3453237410072, "train/policy_entropy_mag": 2.6303517835603345, "train/policy_entropy_max": 2.6303517835603345, "train/policy_entropy_mean": 0.5704089096553034, "train/policy_entropy_min": 0.07937502008762291, "train/policy_entropy_std": 0.684210160438963, "train/policy_logprob_mag": 7.438383781652656, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5695550390284696, "train/policy_logprob_min": -7.438383781652656, "train/policy_logprob_std": 1.1187697288801344, "train/policy_randomness_mag": 0.9283987498111862, "train/policy_randomness_max": 0.9283987498111862, "train/policy_randomness_mean": 0.20132931616666505, "train/policy_randomness_min": 0.028015898781821882, "train/policy_randomness_std": 0.24149615880396727, "train/post_ent_mag": 58.16552635577085, "train/post_ent_max": 58.16552635577085, "train/post_ent_mean": 42.075867549978575, "train/post_ent_min": 19.531613384219384, "train/post_ent_std": 7.617691070913411, "train/prior_ent_mag": 66.82475686930924, "train/prior_ent_max": 66.82475686930924, "train/prior_ent_mean": 55.31704525295779, "train/prior_ent_min": 40.62919545345169, "train/prior_ent_std": 4.076915375620342, "train/rep_loss_mean": 13.17375113809709, "train/rep_loss_std": 9.106701425511202, "train/reward_avg": 0.03325441186215809, "train/reward_loss_mean": 0.05649234523340095, "train/reward_loss_std": 0.24181809785554734, "train/reward_max_data": 1.019424465062807, "train/reward_max_pred": 1.0126385774543818, "train/reward_neg_acc": 0.9924355462300691, "train/reward_neg_loss": 0.027338523766119702, "train/reward_pos_acc": 0.9767924967429621, "train/reward_pos_loss": 0.8163559938506256, "train/reward_pred": 0.032598517446530806, "train/reward_rate": 0.03726393884892086, "eval_stats/sum_log_reward": 8.725000143051147, "eval_stats/max_log_achievement_collect_coal": 0.375, "eval_stats/max_log_achievement_collect_drink": 3.0, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 5.625, "eval_stats/max_log_achievement_collect_wood": 7.875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.5625, "eval_stats/max_log_achievement_eat_cow": 0.1875, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 0.75, "eval_stats/max_log_achievement_place_furnace": 0.5, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 2.875, "eval_stats/max_log_achievement_place_table": 2.1875, "eval_stats/max_log_achievement_wake_up": 1.1875, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.99609375, "report/cont_loss_mean": 1.4559616374754114e-06, "report/cont_loss_std": 3.1102630600798875e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00031106555252335966, "report/cont_pos_acc": 0.9999999403953552, "report/cont_pos_loss": 2.418064752873761e-07, "report/cont_pred": 0.996094822883606, "report/cont_rate": 0.99609375, "report/dyn_loss_mean": 12.384651184082031, "report/dyn_loss_std": 8.697333335876465, "report/image_loss_mean": 4.691499710083008, "report/image_loss_std": 11.240558624267578, "report/model_loss_mean": 12.170038223266602, "report/model_loss_std": 14.89532470703125, "report/post_ent_mag": 59.226402282714844, "report/post_ent_max": 59.226402282714844, "report/post_ent_mean": 42.19773483276367, "report/post_ent_min": 18.03506088256836, "report/post_ent_std": 7.010044574737549, "report/prior_ent_mag": 66.82768249511719, "report/prior_ent_max": 66.82768249511719, "report/prior_ent_mean": 54.84220886230469, "report/prior_ent_min": 42.5435791015625, "report/prior_ent_std": 4.1836066246032715, "report/rep_loss_mean": 12.384651184082031, "report/rep_loss_std": 8.697333335876465, "report/reward_avg": 0.03652343526482582, "report/reward_loss_mean": 0.047745849937200546, "report/reward_loss_std": 0.18916760385036469, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0011558532714844, "report/reward_neg_acc": 0.9959308505058289, "report/reward_neg_loss": 0.016759632155299187, "report/reward_pos_acc": 0.9756097197532654, "report/reward_pos_loss": 0.7906592488288879, "report/reward_pred": 0.03380107507109642, "report/reward_rate": 0.0400390625, "eval/cont_avg": 0.9970703125, "eval/cont_loss_mean": 7.966289558680728e-06, "eval/cont_loss_std": 0.00023513741325587034, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0025232790503650904, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 5.755567826781771e-07, "eval/cont_pred": 0.997077226638794, "eval/cont_rate": 0.9970703125, "eval/dyn_loss_mean": 17.691692352294922, "eval/dyn_loss_std": 9.966192245483398, "eval/image_loss_mean": 8.822630882263184, "eval/image_loss_std": 14.702705383300781, "eval/model_loss_mean": 19.55890655517578, "eval/model_loss_std": 18.674131393432617, "eval/post_ent_mag": 57.95922088623047, "eval/post_ent_max": 57.95922088623047, "eval/post_ent_mean": 39.92255401611328, "eval/post_ent_min": 20.466629028320312, "eval/post_ent_std": 7.591587543487549, "eval/prior_ent_mag": 66.82768249511719, "eval/prior_ent_max": 66.82768249511719, "eval/prior_ent_mean": 55.610843658447266, "eval/prior_ent_min": 43.819862365722656, "eval/prior_ent_std": 3.8535315990448, "eval/rep_loss_mean": 17.691692352294922, "eval/rep_loss_std": 9.966192245483398, "eval/reward_avg": 0.05654297024011612, "eval/reward_loss_mean": 0.12125236541032791, "eval/reward_loss_std": 0.644828736782074, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0026745796203613, "eval/reward_neg_acc": 0.9906445145606995, "eval/reward_neg_loss": 0.028666459023952484, "eval/reward_pos_acc": 0.8548386693000793, "eval/reward_pos_loss": 1.5578272342681885, "eval/reward_pred": 0.047021761536598206, "eval/reward_rate": 0.060546875, "replay/size": 928785.0, "replay/inserts": 22256.0, "replay/samples": 22256.0, "replay/insert_wait_avg": 1.3081634070357344e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.198728476386546e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4472.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1885208819121496e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 7.003545761108398e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2967336177826, "timer/env.step_count": 2782.0, "timer/env.step_total": 244.33495044708252, "timer/env.step_frac": 0.24426246956080122, "timer/env.step_avg": 0.08782708499176223, "timer/env.step_min": 0.023117542266845703, "timer/env.step_max": 3.517983913421631, "timer/replay._sample_count": 22256.0, "timer/replay._sample_total": 11.06673264503479, "timer/replay._sample_frac": 0.011063449747566038, "timer/replay._sample_avg": 0.0004972471533534683, "timer/replay._sample_min": 0.000400543212890625, "timer/replay._sample_max": 0.010560989379882812, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3341.0, "timer/agent.policy_total": 55.74067783355713, "timer/agent.policy_frac": 0.05572414260712348, "timer/agent.policy_avg": 0.01668383053982554, "timer/agent.policy_min": 0.009268522262573242, "timer/agent.policy_max": 0.10623502731323242, "timer/dataset_train_count": 1391.0, "timer/dataset_train_total": 0.14965558052062988, "timer/dataset_train_frac": 0.0001496111858521912, "timer/dataset_train_avg": 0.00010758848347996396, "timer/dataset_train_min": 9.1552734375e-05, "timer/dataset_train_max": 0.0008771419525146484, "timer/agent.train_count": 1391.0, "timer/agent.train_total": 625.3363134860992, "timer/agent.train_frac": 0.6251508102245216, "timer/agent.train_avg": 0.44955881630920147, "timer/agent.train_min": 0.4328329563140869, "timer/agent.train_max": 1.602271556854248, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4788491725921631, "timer/agent.report_frac": 0.000478707124095372, "timer/agent.report_avg": 0.23942458629608154, "timer/agent.report_min": 0.2323763370513916, "timer/agent.report_max": 0.24647283554077148, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.765655517578125e-05, "timer/dataset_eval_frac": 2.7648350980569064e-08, "timer/dataset_eval_avg": 2.765655517578125e-05, "timer/dataset_eval_min": 2.765655517578125e-05, "timer/dataset_eval_max": 2.765655517578125e-05, "fps": 22.24911703376515}
{"step": 929800, "time": 42348.195472955704, "episode/length": 221.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 929840, "time": 42351.32819867134, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957983193277311, "episode/intrinsic_return": 0.0}
{"step": 929944, "time": 42356.12999677658, "episode/length": 191.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96875, "episode/intrinsic_return": 0.0}
{"step": 930072, "time": 42379.79119372368, "eval_episode/length": 124.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.96}
{"step": 930072, "time": 42382.78321170807, "eval_episode/length": 157.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9620253164556962}
{"step": 930072, "time": 42384.83284974098, "eval_episode/length": 171.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9941860465116279}
{"step": 930072, "time": 42387.921115875244, "eval_episode/length": 206.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9758454106280193}
{"step": 930072, "time": 42387.92933678627, "eval_episode/length": 206.0, "eval_episode/score": 7.100000016391277, "eval_episode/reward_rate": 0.9855072463768116}
{"step": 930072, "time": 42391.75541615486, "eval_episode/length": 219.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9818181818181818}
{"step": 930072, "time": 42394.28104567528, "eval_episode/length": 243.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9754098360655737}
{"step": 930072, "time": 42398.860367298126, "eval_episode/length": 157.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9683544303797469}
{"step": 930360, "time": 42408.364307403564, "episode/length": 164.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9757575757575757, "episode/intrinsic_return": 0.0}
{"step": 930424, "time": 42412.05627679825, "episode/length": 427.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9953271028037384, "episode/intrinsic_return": 0.0}
{"step": 930592, "time": 42419.39275622368, "episode/length": 364.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9863013698630136, "episode/intrinsic_return": 0.0}
{"step": 931344, "time": 42445.98667907715, "episode/length": 192.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9740932642487047, "episode/intrinsic_return": 0.0}
{"step": 931576, "time": 42455.14377784729, "episode/length": 511.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.98828125, "episode/intrinsic_return": 0.0}
{"step": 931584, "time": 42457.19991636276, "episode/length": 152.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9934640522875817, "episode/intrinsic_return": 0.0}
{"step": 931664, "time": 42461.53485107422, "episode/length": 467.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 931728, "time": 42465.257714271545, "episode/length": 235.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 931832, "time": 42470.01728820801, "episode/length": 154.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 932448, "time": 42492.29702925682, "episode/length": 252.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 932640, "time": 42500.19171953201, "episode/length": 161.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 933056, "time": 42515.54785966873, "episode/length": 388.0, "episode/score": 12.099999979138374, "episode/reward_rate": 0.9974293059125964, "episode/intrinsic_return": 0.0}
{"step": 933280, "time": 42524.67277550697, "episode/length": 193.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9742268041237113, "episode/intrinsic_return": 0.0}
{"step": 933424, "time": 42531.02195096016, "episode/length": 229.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9956521739130435, "episode/intrinsic_return": 0.0}
{"step": 933768, "time": 42543.875366687775, "episode/length": 262.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9771863117870723, "episode/intrinsic_return": 0.0}
{"step": 933960, "time": 42553.58724999428, "episode/length": 297.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9832214765100671, "episode/intrinsic_return": 0.0}
{"step": 934280, "time": 42565.67796278, "episode/length": 305.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 934560, "time": 42576.78899407387, "episode/length": 239.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 934696, "time": 42582.854341983795, "episode/length": 280.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9750889679715302, "episode/intrinsic_return": 0.0}
{"step": 934776, "time": 42587.20252966881, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9572192513368984, "episode/intrinsic_return": 0.0}
{"step": 935176, "time": 42602.78867149353, "episode/length": 59.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9833333333333333, "episode/intrinsic_return": 0.0}
{"step": 935544, "time": 42616.57427406311, "episode/length": 122.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.991869918699187, "episode/intrinsic_return": 0.0}
{"step": 935632, "time": 42621.2908308506, "episode/length": 232.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957081545064378, "episode/intrinsic_return": 0.0}
{"step": 935840, "time": 42629.77898168564, "episode/length": 234.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 936072, "time": 42638.78902506828, "episode/length": 161.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 936576, "time": 42657.347261190414, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 936608, "time": 42660.03834056854, "episode/length": 397.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9974874371859297, "episode/intrinsic_return": 0.0}
{"step": 936624, "time": 42662.22831368446, "episode/length": 445.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9887892376681614, "episode/intrinsic_return": 0.0}
{"step": 936816, "time": 42670.260812044144, "episode/length": 316.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968454258675079, "episode/intrinsic_return": 0.0}
{"step": 937112, "time": 42681.396579265594, "episode/length": 195.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9846938775510204, "episode/intrinsic_return": 0.0}
{"step": 937136, "time": 42683.98985362053, "episode/length": 65.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9848484848484849, "episode/intrinsic_return": 0.0}
{"step": 937664, "time": 42703.28721547127, "episode/length": 198.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9798994974874372, "episode/intrinsic_return": 0.0}
{"step": 937904, "time": 42712.94678449631, "episode/length": 283.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9683098591549296, "episode/intrinsic_return": 0.0}
{"step": 938200, "time": 42724.131048202515, "episode/length": 294.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9796610169491525, "episode/intrinsic_return": 0.0}
{"step": 938472, "time": 42734.75228023529, "episode/length": 206.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9806763285024155, "episode/intrinsic_return": 0.0}
{"step": 938512, "time": 42737.889950037, "episode/length": 171.0, "episode/score": 9.100000016391277, "episode/reward_rate": 0.9883720930232558, "episode/intrinsic_return": 0.0}
{"step": 938736, "time": 42746.90909576416, "episode/length": 269.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9888888888888889, "episode/intrinsic_return": 0.0}
{"step": 939256, "time": 42766.056015729904, "episode/length": 267.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9776119402985075, "episode/intrinsic_return": 0.0}
{"step": 939280, "time": 42768.68948960304, "episode/length": 171.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9941860465116279, "episode/intrinsic_return": 0.0}
{"step": 939296, "time": 42770.69825744629, "episode/length": 203.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9950980392156863, "episode/intrinsic_return": 0.0}
{"step": 940056, "time": 42816.62785387039, "eval_episode/length": 153.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9675324675324676}
{"step": 940056, "time": 42818.66765832901, "eval_episode/length": 166.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9700598802395209}
{"step": 940056, "time": 42820.814661979675, "eval_episode/length": 178.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9664804469273743}
{"step": 940056, "time": 42822.48396611214, "eval_episode/length": 179.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9722222222222222}
{"step": 940056, "time": 42825.18718981743, "eval_episode/length": 209.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 940056, "time": 42830.16296386719, "eval_episode/length": 257.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 940056, "time": 42834.50049328804, "eval_episode/length": 163.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9634146341463414}
{"step": 940056, "time": 42837.64978671074, "eval_episode/length": 352.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9858356940509915}
{"step": 940128, "time": 42840.42641162872, "episode/length": 437.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 940496, "time": 42854.866527080536, "episode/length": 219.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9727272727272728, "episode/intrinsic_return": 0.0}
{"step": 940624, "time": 42860.77864265442, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 940784, "time": 42867.66405630112, "episode/length": 187.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 940872, "time": 42871.964559316635, "episode/length": 299.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9866666666666667, "episode/intrinsic_return": 0.0}
{"step": 940944, "time": 42876.13743829727, "episode/length": 39.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 941760, "time": 42905.62168478966, "episode/length": 312.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9840255591054313, "episode/intrinsic_return": 0.0}
{"step": 941880, "time": 42911.05874347687, "episode/length": 420.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.995249406175772, "episode/intrinsic_return": 0.0}
{"step": 941904, "time": 42913.72209978104, "episode/length": 221.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 941944, "time": 42916.29736638069, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 942184, "time": 42927.557881593704, "episode/length": 174.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 942584, "time": 42943.15350484848, "episode/length": 213.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 942848, "time": 42953.64655542374, "episode/length": 443.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9954954954954955, "episode/intrinsic_return": 0.0}
{"step": 943072, "time": 42962.644255161285, "episode/length": 265.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9774436090225563, "episode/intrinsic_return": 0.0}
{"step": 943096, "time": 42964.84822297096, "episode/length": 63.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.984375, "episode/intrinsic_return": 0.0}
{"step": 943400, "time": 42976.57938504219, "episode/length": 189.0, "episode/score": 12.100000016391277, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 943408, "time": 42978.548959732056, "episode/length": 187.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9787234042553191, "episode/intrinsic_return": 0.0}
{"step": 943600, "time": 42986.50858235359, "episode/length": 176.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9943502824858758, "episode/intrinsic_return": 0.0}
{"step": 944240, "time": 43009.47326397896, "episode/length": 309.0, "episode/score": 9.099999979138374, "episode/reward_rate": 0.9967741935483871, "episode/intrinsic_return": 0.0}
{"step": 944360, "time": 43014.88076210022, "episode/length": 157.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9683544303797469, "episode/intrinsic_return": 0.0}
{"step": 944408, "time": 43017.996059417725, "episode/length": 194.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9794871794871794, "episode/intrinsic_return": 0.0}
{"step": 944568, "time": 43024.8662378788, "episode/length": 40.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 944584, "time": 43026.88772511482, "episode/length": 146.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 945264, "time": 43051.39787530899, "episode/length": 273.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9854014598540146, "episode/intrinsic_return": 0.0}
{"step": 945272, "time": 43053.14506435394, "episode/length": 415.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9975961538461539, "episode/intrinsic_return": 0.0}
{"step": 945552, "time": 43064.33635377884, "episode/length": 268.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9962825278810409, "episode/intrinsic_return": 0.0}
{"step": 945736, "time": 43071.78072476387, "episode/length": 165.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.963855421686747, "episode/intrinsic_return": 0.0}
{"step": 946392, "time": 43095.069814920425, "episode/length": 227.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9956140350877193, "episode/intrinsic_return": 0.0}
{"step": 946472, "time": 43099.3778591156, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9745762711864406, "episode/intrinsic_return": 0.0}
{"step": 946704, "time": 43108.79689216614, "episode/length": 143.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9652777777777778, "episode/intrinsic_return": 0.0}
{"step": 946712, "time": 43110.46113538742, "episode/length": 388.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9922879177377892, "episode/intrinsic_return": 0.0}
{"step": 947016, "time": 43122.09402990341, "episode/length": 218.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9771689497716894, "episode/intrinsic_return": 0.0}
{"step": 947136, "time": 43127.808176994324, "episode/length": 174.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 947384, "time": 43137.29530239105, "episode/length": 377.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 947856, "time": 43154.68594002724, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 947904, "time": 43157.732791900635, "episode/length": 188.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 948128, "time": 43166.737661361694, "episode/length": 356.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9831932773109243, "episode/intrinsic_return": 0.0}
{"step": 948304, "time": 43174.7280626297, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.97, "episode/intrinsic_return": 0.0}
{"step": 948328, "time": 43176.72083735466, "episode/length": 58.0, "episode/score": 3.1000000089406967, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 948696, "time": 43190.58439731598, "episode/length": 45.0, "episode/score": 6.100000001490116, "episode/reward_rate": 0.9130434782608695, "episode/intrinsic_return": 0.0}
{"step": 948896, "time": 43198.94673752785, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 949176, "time": 43209.478929281235, "episode/length": 307.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9837662337662337, "episode/intrinsic_return": 0.0}
{"step": 949416, "time": 43219.102895736694, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9824561403508771, "episode/intrinsic_return": 0.0}
{"step": 949648, "time": 43228.53755760193, "episode/length": 282.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9823321554770318, "episode/intrinsic_return": 0.0}
{"step": 949728, "time": 43232.66808319092, "episode/length": 199.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.985, "episode/intrinsic_return": 0.0}
{"step": 949784, "time": 43235.891500234604, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744680851063829, "episode/intrinsic_return": 0.0}
{"step": 949968, "time": 43243.845022678375, "episode/length": 207.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9759615384615384, "episode/intrinsic_return": 0.0}
{"step": 950040, "time": 43266.246136665344, "eval_episode/length": 144.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9724137931034482}
{"step": 950040, "time": 43270.558252334595, "eval_episode/length": 205.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 950040, "time": 43272.6375246048, "eval_episode/length": 218.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9771689497716894}
{"step": 950040, "time": 43274.38397717476, "eval_episode/length": 223.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 950040, "time": 43276.818860054016, "eval_episode/length": 244.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 950040, "time": 43279.1265707016, "eval_episode/length": 263.0, "eval_episode/score": 13.099999986588955, "eval_episode/reward_rate": 0.9810606060606061}
{"step": 950040, "time": 43286.16046285629, "eval_episode/length": 179.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9666666666666667}
{"step": 950040, "time": 43288.25815320015, "eval_episode/length": 242.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9711934156378601}
{"step": 950720, "time": 43312.858712911606, "episode/length": 192.0, "episode/score": 11.099999971687794, "episode/reward_rate": 0.9948186528497409, "episode/intrinsic_return": 0.0}
{"step": 950928, "time": 43321.51972913742, "episode/length": 278.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.982078853046595, "episode/intrinsic_return": 0.0}
{"step": 951129, "time": 43331.31832575798, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.569454866297105, "train/action_min": 0.0, "train/action_std": 3.333480994491016, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03419054522836471, "train/actor_opt_grad_steps": 58665.0, "train/actor_opt_loss": -2.0357548390165903, "train/adv_mag": 0.430997053928235, "train/adv_max": 0.3919077590107918, "train/adv_mean": 0.003595769946510994, "train/adv_min": -0.3523846887709463, "train/adv_std": 0.05034863255808458, "train/cont_avg": 0.9952177159926471, "train/cont_loss_mean": 0.00016333569491819462, "train/cont_loss_std": 0.0050174975562978326, "train/cont_neg_acc": 0.9962962967378122, "train/cont_neg_loss": 0.02765860839237441, "train/cont_pos_acc": 0.9999999829074916, "train/cont_pos_loss": 2.6130400590067677e-05, "train/cont_pred": 0.9952342637321528, "train/cont_rate": 0.9952177159926471, "train/dyn_loss_mean": 13.255100467625786, "train/dyn_loss_std": 9.115335127886604, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 1.0367902293801308, "train/extr_critic_critic_opt_grad_steps": 58665.0, "train/extr_critic_critic_opt_loss": 15976.688612994025, "train/extr_critic_mag": 9.782904035904828, "train/extr_critic_max": 9.782904035904828, "train/extr_critic_mean": 3.0004272013902664, "train/extr_critic_min": -0.1700280536623562, "train/extr_critic_std": 2.3184455098474728, "train/extr_return_normed_mag": 1.4663313785020042, "train/extr_return_normed_max": 1.4663313785020042, "train/extr_return_normed_mean": 0.3916909420753227, "train/extr_return_normed_min": -0.08654501680832576, "train/extr_return_normed_std": 0.31877223599482984, "train/extr_return_rate": 0.8517813112805871, "train/extr_return_raw_mag": 10.944734601413503, "train/extr_return_raw_max": 10.944734601413503, "train/extr_return_raw_mean": 3.026925991563236, "train/extr_return_raw_min": -0.49716652590124044, "train/extr_return_raw_std": 2.349040011272711, "train/extr_reward_mag": 1.0363819949767168, "train/extr_reward_max": 1.0363819949767168, "train/extr_reward_mean": 0.05284587703371311, "train/extr_reward_min": -0.431423636043773, "train/extr_reward_std": 0.2137660787386053, "train/image_loss_mean": 6.404438095934251, "train/image_loss_std": 12.152493270004497, "train/model_loss_mean": 14.416420046020956, "train/model_loss_std": 15.811845281544853, "train/model_opt_grad_norm": 51.5971575905295, "train/model_opt_grad_steps": 58612.76470588235, "train/model_opt_loss": 19840.544347426472, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1378.6764705882354, "train/policy_entropy_mag": 2.6178302554523243, "train/policy_entropy_max": 2.6178302554523243, "train/policy_entropy_mean": 0.5406941423083053, "train/policy_entropy_min": 0.07937501842046485, "train/policy_entropy_std": 0.6547687963089522, "train/policy_logprob_mag": 7.438383814166574, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5405514433103449, "train/policy_logprob_min": -7.438383814166574, "train/policy_logprob_std": 1.1000787791083841, "train/policy_randomness_mag": 0.9239791991079555, "train/policy_randomness_max": 0.9239791991079555, "train/policy_randomness_mean": 0.1908413039191681, "train/policy_randomness_min": 0.02801589819821803, "train/policy_randomness_std": 0.23110465245211825, "train/post_ent_mag": 58.13138445685892, "train/post_ent_max": 58.13138445685892, "train/post_ent_mean": 42.10836797602036, "train/post_ent_min": 19.309850987266092, "train/post_ent_std": 7.597277974381166, "train/prior_ent_mag": 66.93219964644489, "train/prior_ent_max": 66.93219964644489, "train/prior_ent_mean": 55.42160014545216, "train/prior_ent_min": 40.205169313094196, "train/prior_ent_std": 4.091690940015456, "train/rep_loss_mean": 13.255100467625786, "train/rep_loss_std": 9.115335127886604, "train/reward_avg": 0.03266529721098349, "train/reward_loss_mean": 0.05875840550288558, "train/reward_loss_std": 0.25373217923676267, "train/reward_max_data": 1.0205882402027355, "train/reward_max_pred": 1.0128894080133999, "train/reward_neg_acc": 0.9922895703245612, "train/reward_neg_loss": 0.02925968518727185, "train/reward_pos_acc": 0.9727623445146224, "train/reward_pos_loss": 0.826911614221685, "train/reward_pred": 0.031858959153075427, "train/reward_rate": 0.03704474954044118, "train_stats/sum_log_reward": 10.24130454270736, "train_stats/max_log_achievement_collect_coal": 0.782608695652174, "train_stats/max_log_achievement_collect_drink": 5.228260869565218, "train_stats/max_log_achievement_collect_sapling": 1.5217391304347827, "train_stats/max_log_achievement_collect_stone": 11.097826086956522, "train_stats/max_log_achievement_collect_wood": 9.91304347826087, "train_stats/max_log_achievement_defeat_skeleton": 0.043478260869565216, "train_stats/max_log_achievement_defeat_zombie": 0.75, "train_stats/max_log_achievement_eat_cow": 0.20652173913043478, "train_stats/max_log_achievement_eat_plant": 0.010869565217391304, "train_stats/max_log_achievement_make_stone_pickaxe": 0.0, "train_stats/max_log_achievement_make_stone_sword": 0.010869565217391304, "train_stats/max_log_achievement_make_wood_pickaxe": 1.3369565217391304, "train_stats/max_log_achievement_make_wood_sword": 1.2282608695652173, "train_stats/max_log_achievement_place_furnace": 1.2065217391304348, "train_stats/max_log_achievement_place_plant": 1.4782608695652173, "train_stats/max_log_achievement_place_stone": 4.673913043478261, "train_stats/max_log_achievement_place_table": 2.5, "train_stats/max_log_achievement_wake_up": 1.4456521739130435, "train_stats/mean_log_entropy": 0.5943167842924595, "eval_stats/sum_log_reward": 9.975000222524008, "eval_stats/max_log_achievement_collect_coal": 0.4583333333333333, "eval_stats/max_log_achievement_collect_drink": 4.75, "eval_stats/max_log_achievement_collect_sapling": 1.4583333333333333, "eval_stats/max_log_achievement_collect_stone": 7.791666666666667, "eval_stats/max_log_achievement_collect_wood": 9.25, "eval_stats/max_log_achievement_defeat_skeleton": 0.08333333333333333, "eval_stats/max_log_achievement_defeat_zombie": 0.5833333333333334, "eval_stats/max_log_achievement_eat_cow": 0.20833333333333334, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.125, "eval_stats/max_log_achievement_make_wood_sword": 1.2916666666666667, "eval_stats/max_log_achievement_place_furnace": 0.8333333333333334, "eval_stats/max_log_achievement_place_plant": 1.3333333333333333, "eval_stats/max_log_achievement_place_stone": 3.625, "eval_stats/max_log_achievement_place_table": 2.2083333333333335, "eval_stats/max_log_achievement_wake_up": 1.2083333333333333, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.676252840203233e-06, "report/cont_loss_std": 9.332731133326888e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0006556161097250879, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 2.487146502971882e-06, "report/cont_pred": 0.9951179027557373, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 11.673501968383789, "report/dyn_loss_std": 8.923154830932617, "report/image_loss_mean": 6.253778457641602, "report/image_loss_std": 12.06757640838623, "report/model_loss_mean": 13.322383880615234, "report/model_loss_std": 15.328805923461914, "report/post_ent_mag": 58.90182876586914, "report/post_ent_max": 58.90182876586914, "report/post_ent_mean": 43.47392272949219, "report/post_ent_min": 17.088104248046875, "report/post_ent_std": 7.833722114562988, "report/prior_ent_mag": 67.12322235107422, "report/prior_ent_max": 67.12322235107422, "report/prior_ent_mean": 55.281368255615234, "report/prior_ent_min": 36.996726989746094, "report/prior_ent_std": 4.754807472229004, "report/rep_loss_mean": 11.673501968383789, "report/rep_loss_std": 8.923154830932617, "report/reward_avg": 0.03193359076976776, "report/reward_loss_mean": 0.06449832022190094, "report/reward_loss_std": 0.2698926627635956, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0752909183502197, "report/reward_neg_acc": 0.9929077625274658, "report/reward_neg_loss": 0.03568946570158005, "report/reward_pos_acc": 0.9729729294776917, "report/reward_pos_loss": 0.8329939246177673, "report/reward_pred": 0.03202340006828308, "report/reward_rate": 0.0361328125, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 3.919309619959677e-06, "eval/cont_loss_std": 5.9073936427012086e-05, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000740213377866894, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 2.478421038176748e-06, "eval/cont_pred": 0.9980458617210388, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.519561767578125, "eval/dyn_loss_std": 10.533397674560547, "eval/image_loss_mean": 10.978487968444824, "eval/image_loss_std": 17.276592254638672, "eval/model_loss_mean": 21.61024284362793, "eval/model_loss_std": 21.508934020996094, "eval/post_ent_mag": 56.787784576416016, "eval/post_ent_max": 56.787784576416016, "eval/post_ent_mean": 40.78131866455078, "eval/post_ent_min": 20.347301483154297, "eval/post_ent_std": 7.723489284515381, "eval/prior_ent_mag": 67.12322235107422, "eval/prior_ent_max": 67.12322235107422, "eval/prior_ent_mean": 56.54127502441406, "eval/prior_ent_min": 41.86595153808594, "eval/prior_ent_std": 3.8902976512908936, "eval/rep_loss_mean": 17.519561767578125, "eval/rep_loss_std": 10.533397674560547, "eval/reward_avg": 0.05693359673023224, "eval/reward_loss_mean": 0.12001362442970276, "eval/reward_loss_std": 0.537520706653595, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.0845708847045898, "eval/reward_neg_acc": 0.9906542301177979, "eval/reward_neg_loss": 0.04794268310070038, "eval/reward_pos_acc": 0.9016394019126892, "eval/reward_pos_loss": 1.2577894926071167, "eval/reward_pred": 0.04984966665506363, "eval/reward_rate": 0.0595703125, "replay/size": 950625.0, "replay/inserts": 21840.0, "replay/samples": 21840.0, "replay/insert_wait_avg": 1.3148719137841528e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.336829608176654e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 8456.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.091774387413754e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2777276039124, "timer/env.step_count": 2730.0, "timer/env.step_total": 220.47840666770935, "timer/env.step_frac": 0.22041719072946697, "timer/env.step_avg": 0.08076132112370306, "timer/env.step_min": 0.02285313606262207, "timer/env.step_max": 2.112778902053833, "timer/replay._sample_count": 21840.0, "timer/replay._sample_total": 11.00763726234436, "timer/replay._sample_frac": 0.011004580986434939, "timer/replay._sample_avg": 0.0005040126951622875, "timer/replay._sample_min": 0.000415802001953125, "timer/replay._sample_max": 0.024854183197021484, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3787.0, "timer/agent.policy_total": 61.37274932861328, "timer/agent.policy_frac": 0.06135570915452345, "timer/agent.policy_avg": 0.016206165653185445, "timer/agent.policy_min": 0.009171724319458008, "timer/agent.policy_max": 0.11330890655517578, "timer/dataset_train_count": 1365.0, "timer/dataset_train_total": 0.14559531211853027, "timer/dataset_train_frac": 0.00014555488750838484, "timer/dataset_train_avg": 0.0001066632323212676, "timer/dataset_train_min": 8.96453857421875e-05, "timer/dataset_train_max": 0.0015838146209716797, "timer/agent.train_count": 1365.0, "timer/agent.train_total": 612.9644935131073, "timer/agent.train_frac": 0.612794303619472, "timer/agent.train_avg": 0.4490582370059394, "timer/agent.train_min": 0.4353945255279541, "timer/agent.train_max": 1.612635612487793, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4801602363586426, "timer/agent.report_frac": 0.00048002691963243963, "timer/agent.report_avg": 0.2400801181793213, "timer/agent.report_min": 0.2348024845123291, "timer/agent.report_max": 0.24535775184631348, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.8133392333984375e-05, "timer/dataset_eval_frac": 2.8125581083741345e-08, "timer/dataset_eval_avg": 2.8133392333984375e-05, "timer/dataset_eval_min": 2.8133392333984375e-05, "timer/dataset_eval_max": 2.8133392333984375e-05, "fps": 21.83358603429064}
{"step": 951216, "time": 43334.30919146538, "episode/length": 155.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 951280, "time": 43338.064782619476, "episode/length": 297.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9966442953020134, "episode/intrinsic_return": 0.0}
{"step": 951280, "time": 43338.073806762695, "episode/length": 186.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 951432, "time": 43346.44636416435, "episode/length": 251.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 951544, "time": 43351.74186873436, "episode/length": 236.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9957805907172996, "episode/intrinsic_return": 0.0}
{"step": 952168, "time": 43374.31026220322, "episode/length": 180.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9668508287292817, "episode/intrinsic_return": 0.0}
{"step": 952496, "time": 43386.85973095894, "episode/length": 40.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 952632, "time": 43392.872767686844, "episode/length": 362.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9862258953168044, "episode/intrinsic_return": 0.0}
{"step": 952744, "time": 43398.12586426735, "episode/length": 226.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 952912, "time": 43405.47177052498, "episode/length": 211.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9716981132075472, "episode/intrinsic_return": 0.0}
{"step": 953016, "time": 43410.26060247421, "episode/length": 183.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9728260869565217, "episode/intrinsic_return": 0.0}
{"step": 953056, "time": 43413.43793988228, "episode/length": 202.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9753694581280788, "episode/intrinsic_return": 0.0}
{"step": 953280, "time": 43422.51946091652, "episode/length": 249.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 953456, "time": 43429.82042098045, "episode/length": 271.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 953736, "time": 43440.30934667587, "episode/length": 154.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.967741935483871, "episode/intrinsic_return": 0.0}
{"step": 954200, "time": 43457.15480566025, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 954272, "time": 43461.42741942406, "episode/length": 169.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 954832, "time": 43481.8757519722, "episode/length": 221.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9774774774774775, "episode/intrinsic_return": 0.0}
{"step": 954904, "time": 43486.27268695831, "episode/length": 235.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 955032, "time": 43492.56238746643, "episode/length": 218.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9954337899543378, "episode/intrinsic_return": 0.0}
{"step": 955112, "time": 43496.797178030014, "episode/length": 206.0, "episode/score": 5.099999971687794, "episode/reward_rate": 0.9951690821256038, "episode/intrinsic_return": 0.0}
{"step": 955480, "time": 43510.5314552784, "episode/length": 217.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 955504, "time": 43513.05618262291, "episode/length": 344.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9884057971014493, "episode/intrinsic_return": 0.0}
{"step": 956072, "time": 43533.132934331894, "episode/length": 224.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9822222222222222, "episode/intrinsic_return": 0.0}
{"step": 956176, "time": 43538.441360235214, "episode/length": 142.0, "episode/score": 5.099999986588955, "episode/reward_rate": 0.958041958041958, "episode/intrinsic_return": 0.0}
{"step": 956624, "time": 43555.14869880676, "episode/length": 214.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 956728, "time": 43560.36710214615, "episode/length": 152.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9673202614379085, "episode/intrinsic_return": 0.0}
{"step": 957184, "time": 43578.07680439949, "episode/length": 258.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9806949806949807, "episode/intrinsic_return": 0.0}
{"step": 957344, "time": 43584.841361522675, "episode/length": 313.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9872611464968153, "episode/intrinsic_return": 0.0}
{"step": 957448, "time": 43589.724064826965, "episode/length": 405.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9876847290640394, "episode/intrinsic_return": 0.0}
{"step": 957592, "time": 43596.0411632061, "episode/length": 189.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 958336, "time": 43622.79226732254, "episode/length": 356.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9943977591036415, "episode/intrinsic_return": 0.0}
{"step": 958512, "time": 43632.77158713341, "episode/length": 222.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9955156950672646, "episode/intrinsic_return": 0.0}
{"step": 958552, "time": 43635.9311106205, "episode/length": 170.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9883040935672515, "episode/intrinsic_return": 0.0}
{"step": 958744, "time": 43644.454117536545, "episode/length": 161.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9753086419753086, "episode/intrinsic_return": 0.0}
{"step": 958744, "time": 43644.463277578354, "episode/length": 174.0, "episode/score": 12.100000031292439, "episode/reward_rate": 0.9942857142857143, "episode/intrinsic_return": 0.0}
{"step": 959040, "time": 43658.020756959915, "episode/length": 180.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 959048, "time": 43660.18539619446, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 959216, "time": 43668.22977018356, "episode/length": 58.0, "episode/score": 3.1000000312924385, "episode/reward_rate": 0.9830508474576272, "episode/intrinsic_return": 0.0}
{"step": 959232, "time": 43670.84091615677, "episode/length": 381.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9973821989528796, "episode/intrinsic_return": 0.0}
{"step": 959488, "time": 43681.66022801399, "episode/length": 55.0, "episode/score": 6.099999971687794, "episode/reward_rate": 0.9821428571428571, "episode/intrinsic_return": 0.0}
{"step": 959936, "time": 43699.20691037178, "episode/length": 177.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9943820224719101, "episode/intrinsic_return": 0.0}
{"step": 960024, "time": 43724.9801735878, "eval_episode/length": 142.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.965034965034965}
{"step": 960024, "time": 43727.142135858536, "eval_episode/length": 154.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9935483870967742}
{"step": 960024, "time": 43728.90482401848, "eval_episode/length": 157.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9936708860759493}
{"step": 960024, "time": 43731.28237104416, "eval_episode/length": 174.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9771428571428571}
{"step": 960024, "time": 43733.65364193916, "eval_episode/length": 50.0, "eval_episode/score": 3.1000000312924385, "eval_episode/reward_rate": 0.9803921568627451}
{"step": 960024, "time": 43735.99105143547, "eval_episode/length": 209.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9761904761904762}
{"step": 960024, "time": 43737.802572250366, "eval_episode/length": 216.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9953917050691244}
{"step": 960024, "time": 43740.46751976013, "eval_episode/length": 244.0, "eval_episode/score": 11.100000008940697, "eval_episode/reward_rate": 0.9959183673469387}
{"step": 960160, "time": 43745.19992351532, "episode/length": 227.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9780701754385965, "episode/intrinsic_return": 0.0}
{"step": 960464, "time": 43756.98502397537, "episode/length": 214.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 960776, "time": 43768.6633002758, "episode/length": 160.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.968944099378882, "episode/intrinsic_return": 0.0}
{"step": 960984, "time": 43777.84292769432, "episode/length": 303.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9868421052631579, "episode/intrinsic_return": 0.0}
{"step": 961112, "time": 43783.69255948067, "episode/length": 234.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 961376, "time": 43794.27661943436, "episode/length": 269.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 961680, "time": 43805.92889237404, "episode/length": 151.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9671052631578947, "episode/intrinsic_return": 0.0}
{"step": 961752, "time": 43809.69223713875, "episode/length": 337.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9970414201183432, "episode/intrinsic_return": 0.0}
{"step": 961856, "time": 43814.89483952522, "episode/length": 134.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 961952, "time": 43819.62315917015, "episode/length": 223.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 962552, "time": 43840.77280211449, "episode/length": 195.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9693877551020408, "episode/intrinsic_return": 0.0}
{"step": 963096, "time": 43860.25389409065, "episode/length": 214.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9720930232558139, "episode/intrinsic_return": 0.0}
{"step": 963120, "time": 43862.82652306557, "episode/length": 250.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9721115537848606, "episode/intrinsic_return": 0.0}
{"step": 963304, "time": 43870.478402137756, "episode/length": 168.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9763313609467456, "episode/intrinsic_return": 0.0}
{"step": 963384, "time": 43874.737954854965, "episode/length": 190.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9842931937172775, "episode/intrinsic_return": 0.0}
{"step": 963400, "time": 43876.87997961044, "episode/length": 205.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 963456, "time": 43880.632771253586, "episode/length": 439.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9795454545454545, "episode/intrinsic_return": 0.0}
{"step": 963856, "time": 43895.31972885132, "episode/length": 68.0, "episode/score": 4.100000008940697, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 964368, "time": 43914.25879955292, "episode/length": 335.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9970238095238095, "episode/intrinsic_return": 0.0}
{"step": 964536, "time": 43921.139105796814, "episode/length": 143.0, "episode/score": 9.100000038743019, "episode/reward_rate": 0.9930555555555556, "episode/intrinsic_return": 0.0}
{"step": 964696, "time": 43927.98411822319, "episode/length": 154.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9935483870967742, "episode/intrinsic_return": 0.0}
{"step": 964704, "time": 43930.14780807495, "episode/length": 268.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9814126394052045, "episode/intrinsic_return": 0.0}
{"step": 964808, "time": 43934.93955421448, "episode/length": 210.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9715639810426541, "episode/intrinsic_return": 0.0}
{"step": 964888, "time": 43939.65924286842, "episode/length": 185.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9731182795698925, "episode/intrinsic_return": 0.0}
{"step": 965224, "time": 43953.162313461304, "episode/length": 64.0, "episode/score": 5.100000023841858, "episode/reward_rate": 0.9846153846153847, "episode/intrinsic_return": 0.0}
{"step": 965248, "time": 43955.69465327263, "episode/length": 268.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.9776951672862454, "episode/intrinsic_return": 0.0}
{"step": 965504, "time": 43965.78345012665, "episode/length": 205.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9660194174757282, "episode/intrinsic_return": 0.0}
{"step": 966016, "time": 43984.2044775486, "episode/length": 184.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9783783783783784, "episode/intrinsic_return": 0.0}
{"step": 966536, "time": 44003.053673028946, "episode/length": 205.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9757281553398058, "episode/intrinsic_return": 0.0}
{"step": 966552, "time": 44005.51536035538, "episode/length": 272.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9816849816849816, "episode/intrinsic_return": 0.0}
{"step": 966848, "time": 44019.250552654266, "episode/length": 254.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.984313725490196, "episode/intrinsic_return": 0.0}
{"step": 967264, "time": 44034.74540448189, "episode/length": 219.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9954545454545455, "episode/intrinsic_return": 0.0}
{"step": 967272, "time": 44036.36816692352, "episode/length": 252.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9960474308300395, "episode/intrinsic_return": 0.0}
{"step": 967400, "time": 44042.13679218292, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9595375722543352, "episode/intrinsic_return": 0.0}
{"step": 967896, "time": 44060.11718034744, "episode/length": 399.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9775, "episode/intrinsic_return": 0.0}
{"step": 968168, "time": 44070.78390431404, "episode/length": 367.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9918478260869565, "episode/intrinsic_return": 0.0}
{"step": 968344, "time": 44078.24156188965, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 968664, "time": 44090.50034928322, "episode/length": 263.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 968664, "time": 44090.509937524796, "episode/length": 226.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 968944, "time": 44103.368453502655, "episode/length": 209.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9666666666666667, "episode/intrinsic_return": 0.0}
{"step": 969080, "time": 44109.765280008316, "episode/length": 209.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 969104, "time": 44112.78067922592, "episode/length": 228.0, "episode/score": 9.099999971687794, "episode/reward_rate": 0.9956331877729258, "episode/intrinsic_return": 0.0}
{"step": 969192, "time": 44117.604410648346, "episode/length": 161.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9691358024691358, "episode/intrinsic_return": 0.0}
{"step": 969448, "time": 44128.068143606186, "episode/length": 159.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.99375, "episode/intrinsic_return": 0.0}
{"step": 970008, "time": 44168.32030081749, "eval_episode/length": 174.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9657142857142857}
{"step": 970008, "time": 44170.1012468338, "eval_episode/length": 175.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9772727272727273}
{"step": 970008, "time": 44171.71141552925, "eval_episode/length": 176.0, "eval_episode/score": 10.100000001490116, "eval_episode/reward_rate": 0.9774011299435028}
{"step": 970008, "time": 44173.688390254974, "eval_episode/length": 188.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9735449735449735}
{"step": 970008, "time": 44176.68228888512, "eval_episode/length": 223.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9776785714285714}
{"step": 970008, "time": 44180.77693986893, "eval_episode/length": 281.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9787234042553191}
{"step": 970008, "time": 44184.32746338844, "eval_episode/length": 283.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9859154929577465}
{"step": 970008, "time": 44188.11552619934, "eval_episode/length": 56.0, "eval_episode/score": 4.099999986588955, "eval_episode/reward_rate": 0.9824561403508771}
{"step": 970200, "time": 44194.524508953094, "episode/length": 231.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9741379310344828, "episode/intrinsic_return": 0.0}
{"step": 970408, "time": 44203.169402360916, "episode/length": 217.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9770642201834863, "episode/intrinsic_return": 0.0}
{"step": 970760, "time": 44216.344628572464, "episode/length": 195.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 971224, "time": 44233.28307437897, "episode/length": 127.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9921875, "episode/intrinsic_return": 0.0}
{"step": 971512, "time": 44244.340149879456, "episode/length": 303.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9901315789473685, "episode/intrinsic_return": 0.0}
{"step": 971640, "time": 44250.25198698044, "episode/length": 273.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.9744525547445255, "episode/intrinsic_return": 0.0}
{"step": 971672, "time": 44252.893716573715, "episode/length": 320.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9875389408099688, "episode/intrinsic_return": 0.0}
{"step": 971904, "time": 44262.28750896454, "episode/length": 369.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9918918918918919, "episode/intrinsic_return": 0.0}
{"step": 972024, "time": 44267.68510770798, "episode/length": 419.0, "episode/score": 7.100000001490116, "episode/reward_rate": 0.9785714285714285, "episode/intrinsic_return": 0.0}
{"step": 972088, "time": 44271.29940414429, "episode/length": 165.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 972376, "time": 44282.31510066986, "episode/length": 245.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9796747967479674, "episode/intrinsic_return": 0.0}
{"step": 972656, "time": 44293.44760990143, "episode/length": 178.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9720670391061452, "episode/intrinsic_return": 0.0}
{"step": 972680, "time": 44295.560079813, "episode/length": 129.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9615384615384616, "episode/intrinsic_return": 0.0}
{"step": 972752, "time": 44299.856892585754, "episode/length": 46.0, "episode/score": 4.100000001490116, "episode/reward_rate": 0.9361702127659575, "episode/intrinsic_return": 0.0}
{"step": 973192, "time": 44315.86036539078, "episode/length": 209.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9761904761904762, "episode/intrinsic_return": 0.0}
{"step": 973296, "time": 44321.27364754677, "episode/length": 173.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9712643678160919, "episode/intrinsic_return": 0.0}
{"step": 973513, "time": 44331.47294712067, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.437928989955357, "train/action_min": 0.0, "train/action_std": 3.2935765045029775, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03359266740403005, "train/actor_opt_grad_steps": 60045.0, "train/actor_opt_loss": -1.1442007274499961, "train/adv_mag": 0.40916232722146173, "train/adv_max": 0.3698895275592804, "train/adv_mean": 0.0033967683333685273, "train/adv_min": -0.33826499357819556, "train/adv_std": 0.04901377854070493, "train/cont_avg": 0.9954171316964285, "train/cont_loss_mean": 0.00022102561412801997, "train/cont_loss_std": 0.006383283856526337, "train/cont_neg_acc": 0.9868705041116947, "train/cont_neg_loss": 0.03493746862635908, "train/cont_pos_acc": 0.9999719176973615, "train/cont_pos_loss": 9.638321535326051e-05, "train/cont_pred": 0.9954260093825203, "train/cont_rate": 0.9954171316964285, "train/dyn_loss_mean": 13.130262626920427, "train/dyn_loss_std": 9.094659771238055, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9932753788573402, "train/extr_critic_critic_opt_grad_steps": 60045.0, "train/extr_critic_critic_opt_loss": 15634.086502511162, "train/extr_critic_mag": 9.989681032725743, "train/extr_critic_max": 9.989681032725743, "train/extr_critic_mean": 3.191530614239829, "train/extr_critic_min": -0.15647027492523194, "train/extr_critic_std": 2.3780690354960305, "train/extr_return_normed_mag": 1.4579700231552124, "train/extr_return_normed_max": 1.4579700231552124, "train/extr_return_normed_mean": 0.3939532670591559, "train/extr_return_normed_min": -0.09889795854687691, "train/extr_return_normed_std": 0.3213273321943624, "train/extr_return_rate": 0.889321567756789, "train/extr_return_raw_mag": 11.185820933750698, "train/extr_return_raw_max": 11.185820933750698, "train/extr_return_raw_mean": 3.2169552070753915, "train/extr_return_raw_min": -0.4747955737369401, "train/extr_return_raw_std": 2.4068808163915363, "train/extr_reward_mag": 1.0349536759512765, "train/extr_reward_max": 1.0349536759512765, "train/extr_reward_mean": 0.05188749938138894, "train/extr_reward_min": -0.4321951508522034, "train/extr_reward_std": 0.2117447551872049, "train/image_loss_mean": 6.501963812964303, "train/image_loss_std": 11.934174394607544, "train/model_loss_mean": 14.439763511930193, "train/model_loss_std": 15.566474771499633, "train/model_opt_grad_norm": 51.99044539587838, "train/model_opt_grad_steps": 59991.49285714285, "train/model_opt_loss": 18180.24287109375, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1258.9285714285713, "train/policy_entropy_mag": 2.604156196117401, "train/policy_entropy_max": 2.604156196117401, "train/policy_entropy_mean": 0.5380577934639794, "train/policy_entropy_min": 0.0793750167957374, "train/policy_entropy_std": 0.652593261216368, "train/policy_logprob_mag": 7.438383800642831, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5366797076804297, "train/policy_logprob_min": -7.438383800642831, "train/policy_logprob_std": 1.0920796594449451, "train/policy_randomness_mag": 0.9191528558731079, "train/policy_randomness_max": 0.9191528558731079, "train/policy_randomness_mean": 0.18991079160145352, "train/policy_randomness_min": 0.0280158976758165, "train/policy_randomness_std": 0.23033678393278803, "train/post_ent_mag": 58.23253173828125, "train/post_ent_max": 58.23253173828125, "train/post_ent_mean": 42.24470667157854, "train/post_ent_min": 19.46237780707223, "train/post_ent_std": 7.642321041652134, "train/prior_ent_mag": 66.90497730800084, "train/prior_ent_max": 66.90497730800084, "train/prior_ent_mean": 55.444933836800715, "train/prior_ent_min": 40.54374188014439, "train/prior_ent_std": 4.16494928087507, "train/rep_loss_mean": 13.130262626920427, "train/rep_loss_std": 9.094659771238055, "train/reward_avg": 0.03305036244647844, "train/reward_loss_mean": 0.05942116788189326, "train/reward_loss_std": 0.2572520893067122, "train/reward_max_data": 1.014285717691694, "train/reward_max_pred": 1.0099372574261256, "train/reward_neg_acc": 0.9918757481234414, "train/reward_neg_loss": 0.029321181953751614, "train/reward_pos_acc": 0.971833820428167, "train/reward_pos_loss": 0.8386341214179993, "train/reward_pred": 0.03213015954409327, "train/reward_rate": 0.037318638392857144, "train_stats/sum_log_reward": 10.070588506904302, "train_stats/max_log_achievement_collect_coal": 0.6862745098039216, "train_stats/max_log_achievement_collect_drink": 5.235294117647059, "train_stats/max_log_achievement_collect_sapling": 1.7352941176470589, "train_stats/max_log_achievement_collect_stone": 10.372549019607844, "train_stats/max_log_achievement_collect_wood": 10.186274509803921, "train_stats/max_log_achievement_defeat_skeleton": 0.0196078431372549, "train_stats/max_log_achievement_defeat_zombie": 0.8921568627450981, "train_stats/max_log_achievement_eat_cow": 0.16666666666666666, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.00980392156862745, "train_stats/max_log_achievement_make_stone_sword": 0.0, "train_stats/max_log_achievement_make_wood_pickaxe": 1.2254901960784315, "train_stats/max_log_achievement_make_wood_sword": 1.588235294117647, "train_stats/max_log_achievement_place_furnace": 1.4705882352941178, "train_stats/max_log_achievement_place_plant": 1.5784313725490196, "train_stats/max_log_achievement_place_stone": 3.0686274509803924, "train_stats/max_log_achievement_place_table": 2.676470588235294, "train_stats/max_log_achievement_wake_up": 1.1568627450980393, "train_stats/mean_log_entropy": 0.5188736522606775, "eval_stats/sum_log_reward": 9.662500321865082, "eval_stats/max_log_achievement_collect_coal": 0.3125, "eval_stats/max_log_achievement_collect_drink": 4.0, "eval_stats/max_log_achievement_collect_sapling": 1.5, "eval_stats/max_log_achievement_collect_stone": 10.25, "eval_stats/max_log_achievement_collect_wood": 11.3125, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.4375, "eval_stats/max_log_achievement_eat_cow": 0.25, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 0.9375, "eval_stats/max_log_achievement_make_wood_sword": 1.75, "eval_stats/max_log_achievement_place_furnace": 1.1875, "eval_stats/max_log_achievement_place_plant": 1.4375, "eval_stats/max_log_achievement_place_stone": 3.875, "eval_stats/max_log_achievement_place_table": 2.625, "eval_stats/max_log_achievement_wake_up": 0.9375, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9912109375, "report/cont_loss_mean": 0.00020824030798394233, "report/cont_loss_std": 0.004114767536520958, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.0001942493108799681, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 0.00020836436306126416, "report/cont_pred": 0.9910144209861755, "report/cont_rate": 0.9912109375, "report/dyn_loss_mean": 13.33468246459961, "report/dyn_loss_std": 9.038846015930176, "report/image_loss_mean": 6.157211780548096, "report/image_loss_std": 11.584314346313477, "report/model_loss_mean": 14.2145357131958, "report/model_loss_std": 15.032129287719727, "report/post_ent_mag": 59.26665496826172, "report/post_ent_max": 59.26665496826172, "report/post_ent_mean": 42.185760498046875, "report/post_ent_min": 19.974124908447266, "report/post_ent_std": 7.977697372436523, "report/prior_ent_mag": 66.82030487060547, "report/prior_ent_max": 66.82030487060547, "report/prior_ent_mean": 55.78491973876953, "report/prior_ent_min": 41.02469253540039, "report/prior_ent_std": 4.074074745178223, "report/rep_loss_mean": 13.33468246459961, "report/rep_loss_std": 9.038846015930176, "report/reward_avg": 0.025390625, "report/reward_loss_mean": 0.05630578100681305, "report/reward_loss_std": 0.20230284333229065, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.0010695457458496, "report/reward_neg_acc": 0.9919354319572449, "report/reward_neg_loss": 0.032559316605329514, "report/reward_pos_acc": 0.96875, "report/reward_pos_loss": 0.7924461364746094, "report/reward_pred": 0.025067992508411407, "report/reward_rate": 0.03125, "eval/cont_avg": 0.9931640625, "eval/cont_loss_mean": 8.14500090200454e-05, "eval/cont_loss_std": 0.00156502821482718, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.003065280383452773, "eval/cont_pos_acc": 0.9999999403953552, "eval/cont_pos_loss": 6.091233080951497e-05, "eval/cont_pred": 0.9931254386901855, "eval/cont_rate": 0.9931640625, "eval/dyn_loss_mean": 19.289295196533203, "eval/dyn_loss_std": 10.558809280395508, "eval/image_loss_mean": 12.508358001708984, "eval/image_loss_std": 17.62299346923828, "eval/model_loss_mean": 24.181133270263672, "eval/model_loss_std": 21.836669921875, "eval/post_ent_mag": 59.230010986328125, "eval/post_ent_max": 59.230010986328125, "eval/post_ent_mean": 39.44446563720703, "eval/post_ent_min": 17.63481330871582, "eval/post_ent_std": 7.82451057434082, "eval/prior_ent_mag": 66.82030487060547, "eval/prior_ent_max": 66.82030487060547, "eval/prior_ent_mean": 56.458553314208984, "eval/prior_ent_min": 43.28497314453125, "eval/prior_ent_std": 3.9977147579193115, "eval/rep_loss_mean": 19.289295196533203, "eval/rep_loss_std": 10.558809280395508, "eval/reward_avg": 0.05214843526482582, "eval/reward_loss_mean": 0.09911656379699707, "eval/reward_loss_std": 0.4479750394821167, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0011870861053467, "eval/reward_neg_acc": 0.9865424633026123, "eval/reward_neg_loss": 0.037275999784469604, "eval/reward_pos_acc": 0.8965517282485962, "eval/reward_pos_loss": 1.1290818452835083, "eval/reward_pred": 0.04762960970401764, "eval/reward_rate": 0.056640625, "replay/size": 973009.0, "replay/inserts": 22384.0, "replay/samples": 22384.0, "replay/insert_wait_avg": 1.3898448316943569e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.091844993629482e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 4672.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0675253116921203e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.238719940185547e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.1434960365295, "timer/env.step_count": 2798.0, "timer/env.step_total": 248.01762676239014, "timer/env.step_frac": 0.2479820423221864, "timer/env.step_avg": 0.0886410388714761, "timer/env.step_min": 0.0227353572845459, "timer/env.step_max": 3.6100070476531982, "timer/replay._sample_count": 22384.0, "timer/replay._sample_total": 11.169565439224243, "timer/replay._sample_frac": 0.011167962880814737, "timer/replay._sample_avg": 0.0004989977412090887, "timer/replay._sample_min": 0.0003826618194580078, "timer/replay._sample_max": 0.011126995086669922, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3382.0, "timer/agent.policy_total": 53.89097452163696, "timer/agent.policy_frac": 0.0538832424899043, "timer/agent.policy_avg": 0.015934646517337954, "timer/agent.policy_min": 0.009148359298706055, "timer/agent.policy_max": 0.1186068058013916, "timer/dataset_train_count": 1399.0, "timer/dataset_train_total": 0.1470808982849121, "timer/dataset_train_frac": 0.00014705979578708383, "timer/dataset_train_avg": 0.00010513287940308228, "timer/dataset_train_min": 9.083747863769531e-05, "timer/dataset_train_max": 0.00024580955505371094, "timer/agent.train_count": 1399.0, "timer/agent.train_total": 626.0693473815918, "timer/agent.train_frac": 0.6259795218012647, "timer/agent.train_avg": 0.4475120424457411, "timer/agent.train_min": 0.4354381561279297, "timer/agent.train_max": 1.6733922958374023, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.47798728942871094, "timer/agent.report_frac": 0.00047791870998804435, "timer/agent.report_avg": 0.23899364471435547, "timer/agent.report_min": 0.232194185256958, "timer/agent.report_max": 0.24579310417175293, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.979804648612823e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.380460669826583}
{"step": 973624, "time": 44335.16000127792, "episode/length": 243.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 974024, "time": 44350.73493242264, "episode/length": 49.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 974056, "time": 44353.33698010445, "episode/length": 174.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9771428571428571, "episode/intrinsic_return": 0.0}
{"step": 974216, "time": 44360.197971105576, "episode/length": 182.0, "episode/score": 11.099999964237213, "episode/reward_rate": 0.994535519125683, "episode/intrinsic_return": 0.0}
{"step": 974224, "time": 44362.17612361908, "episode/length": 274.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9854545454545455, "episode/intrinsic_return": 0.0}
{"step": 974408, "time": 44369.647403001785, "episode/length": 289.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.996551724137931, "episode/intrinsic_return": 0.0}
{"step": 974416, "time": 44371.61264920235, "episode/length": 216.0, "episode/score": 8.099999971687794, "episode/reward_rate": 0.9953917050691244, "episode/intrinsic_return": 0.0}
{"step": 975776, "time": 44420.43024849892, "episode/length": 214.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 975888, "time": 44426.378363370895, "episode/length": 207.0, "episode/score": 10.099999964237213, "episode/reward_rate": 0.9807692307692307, "episode/intrinsic_return": 0.0}
{"step": 976000, "time": 44432.39690375328, "episode/length": 246.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.979757085020243, "episode/intrinsic_return": 0.0}
{"step": 976112, "time": 44437.74995446205, "episode/length": 212.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9812206572769953, "episode/intrinsic_return": 0.0}
{"step": 976120, "time": 44439.295828580856, "episode/length": 237.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9789915966386554, "episode/intrinsic_return": 0.0}
{"step": 976448, "time": 44451.99022889137, "episode/length": 406.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9975429975429976, "episode/intrinsic_return": 0.0}
{"step": 976576, "time": 44458.19618535042, "episode/length": 269.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 976848, "time": 44469.153629779816, "episode/length": 33.0, "episode/score": 0.09999998658895493, "episode/reward_rate": 0.8529411764705882, "episode/intrinsic_return": 0.0}
{"step": 977000, "time": 44475.687771081924, "episode/length": 462.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9827213822894169, "episode/intrinsic_return": 0.0}
{"step": 977264, "time": 44486.218445539474, "episode/length": 157.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9556962025316456, "episode/intrinsic_return": 0.0}
{"step": 977512, "time": 44495.816477537155, "episode/length": 202.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9802955665024631, "episode/intrinsic_return": 0.0}
{"step": 977656, "time": 44502.31078124046, "episode/length": 150.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9668874172185431, "episode/intrinsic_return": 0.0}
{"step": 978344, "time": 44526.88933515549, "episode/length": 278.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.985663082437276, "episode/intrinsic_return": 0.0}
{"step": 978472, "time": 44532.9379234314, "episode/length": 101.0, "episode/score": 8.100000023841858, "episode/reward_rate": 0.9901960784313726, "episode/intrinsic_return": 0.0}
{"step": 978536, "time": 44536.645479917526, "episode/length": 191.0, "episode/score": 10.099999971687794, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 978720, "time": 44544.5640039444, "episode/length": 367.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 978776, "time": 44547.74929571152, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 978792, "time": 44549.8888502121, "episode/length": 39.0, "episode/score": 7.100000023841858, "episode/reward_rate": 0.975, "episode/intrinsic_return": 0.0}
{"step": 978800, "time": 44551.95067882538, "episode/length": 334.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9970149253731343, "episode/intrinsic_return": 0.0}
{"step": 979928, "time": 44591.112251996994, "episode/length": 197.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9949494949494949, "episode/intrinsic_return": 0.0}
{"step": 980024, "time": 44595.845863580704, "episode/length": 162.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 980096, "time": 44626.36211466789, "eval_episode/length": 190.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9738219895287958}
{"step": 980096, "time": 44628.513279914856, "eval_episode/length": 192.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9948186528497409}
{"step": 980096, "time": 44631.010612249374, "eval_episode/length": 202.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.9950738916256158}
{"step": 980096, "time": 44633.76743936539, "eval_episode/length": 217.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9954128440366973}
{"step": 980096, "time": 44636.052736759186, "eval_episode/length": 223.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9732142857142857}
{"step": 980096, "time": 44640.69633769989, "eval_episode/length": 85.0, "eval_episode/score": 9.100000023841858, "eval_episode/reward_rate": 0.9883720930232558}
{"step": 980096, "time": 44644.395179748535, "eval_episode/length": 313.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9936305732484076}
{"step": 980096, "time": 44648.735560417175, "eval_episode/length": 140.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9929078014184397}
{"step": 980104, "time": 44648.794703006744, "episode/length": 323.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 980296, "time": 44659.783834934235, "episode/length": 219.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 980368, "time": 44664.41630363464, "episode/length": 195.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 980584, "time": 44673.55533742905, "episode/length": 466.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9892933618843683, "episode/intrinsic_return": 0.0}
{"step": 980768, "time": 44682.23886036873, "episode/length": 248.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9759036144578314, "episode/intrinsic_return": 0.0}
{"step": 981192, "time": 44698.426193237305, "episode/length": 299.0, "episode/score": 13.099999986588955, "episode/reward_rate": 0.98, "episode/intrinsic_return": 0.0}
{"step": 981296, "time": 44704.26406431198, "episode/length": 158.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 981520, "time": 44713.59244990349, "episode/length": 198.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9748743718592965, "episode/intrinsic_return": 0.0}
{"step": 981688, "time": 44720.56302475929, "episode/length": 173.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9770114942528736, "episode/intrinsic_return": 0.0}
{"step": 981816, "time": 44726.42815208435, "episode/length": 213.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9719626168224299, "episode/intrinsic_return": 0.0}
{"step": 981960, "time": 44732.75826001167, "episode/length": 54.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.9818181818181818, "episode/intrinsic_return": 0.0}
{"step": 982192, "time": 44742.29961013794, "episode/length": 200.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9701492537313433, "episode/intrinsic_return": 0.0}
{"step": 982232, "time": 44745.037536621094, "episode/length": 232.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9914163090128756, "episode/intrinsic_return": 0.0}
{"step": 982712, "time": 44762.49589014053, "episode/length": 189.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9947368421052631, "episode/intrinsic_return": 0.0}
{"step": 983208, "time": 44782.14326238632, "episode/length": 238.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.99581589958159, "episode/intrinsic_return": 0.0}
{"step": 983208, "time": 44782.153148412704, "episode/length": 304.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9836065573770492, "episode/intrinsic_return": 0.0}
{"step": 983696, "time": 44802.063495874405, "episode/length": 250.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9960159362549801, "episode/intrinsic_return": 0.0}
{"step": 983704, "time": 44803.63955068588, "episode/length": 188.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9947089947089947, "episode/intrinsic_return": 0.0}
{"step": 983736, "time": 44806.26540637016, "episode/length": 187.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9946808510638298, "episode/intrinsic_return": 0.0}
{"step": 983840, "time": 44811.53519201279, "episode/length": 234.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 984240, "time": 44826.344135046005, "episode/length": 302.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9900990099009901, "episode/intrinsic_return": 0.0}
{"step": 984248, "time": 44827.99988603592, "episode/length": 191.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9947916666666666, "episode/intrinsic_return": 0.0}
{"step": 984568, "time": 44840.1251745224, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 984936, "time": 44853.84350442886, "episode/length": 153.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9675324675324676, "episode/intrinsic_return": 0.0}
{"step": 985064, "time": 44859.7385699749, "episode/length": 165.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 985368, "time": 44871.307295799255, "episode/length": 53.0, "episode/score": 8.100000001490116, "episode/reward_rate": 0.9259259259259259, "episode/intrinsic_return": 0.0}
{"step": 985440, "time": 44875.45908379555, "episode/length": 217.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 985576, "time": 44881.23195409775, "episode/length": 295.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9831081081081081, "episode/intrinsic_return": 0.0}
{"step": 985968, "time": 44896.10217499733, "episode/length": 215.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9768518518518519, "episode/intrinsic_return": 0.0}
{"step": 986288, "time": 44908.286809682846, "episode/length": 305.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9967320261437909, "episode/intrinsic_return": 0.0}
{"step": 986568, "time": 44918.82393193245, "episode/length": 289.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9793103448275862, "episode/intrinsic_return": 0.0}
{"step": 986688, "time": 44924.68740773201, "episode/length": 264.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9735849056603774, "episode/intrinsic_return": 0.0}
{"step": 986824, "time": 44930.78785777092, "episode/length": 172.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.953757225433526, "episode/intrinsic_return": 0.0}
{"step": 986856, "time": 44933.43973684311, "episode/length": 223.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9955357142857143, "episode/intrinsic_return": 0.0}
{"step": 987464, "time": 44955.136407613754, "episode/length": 186.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9679144385026738, "episode/intrinsic_return": 0.0}
{"step": 988128, "time": 44978.97264242172, "episode/length": 194.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9948717948717949, "episode/intrinsic_return": 0.0}
{"step": 988168, "time": 44982.42215871811, "episode/length": 184.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9675675675675676, "episode/intrinsic_return": 0.0}
{"step": 988360, "time": 44990.3403840065, "episode/length": 191.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 988400, "time": 44993.40931200981, "episode/length": 378.0, "episode/score": 7.099999979138374, "episode/reward_rate": 0.9973614775725593, "episode/intrinsic_return": 0.0}
{"step": 988552, "time": 44999.89202666283, "episode/length": 282.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9858657243816255, "episode/intrinsic_return": 0.0}
{"step": 988904, "time": 45013.096685409546, "episode/length": 415.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9783653846153846, "episode/intrinsic_return": 0.0}
{"step": 989040, "time": 45019.37159991264, "episode/length": 113.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 989408, "time": 45033.181824445724, "episode/length": 125.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 989728, "time": 45045.55232214928, "episode/length": 358.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9888579387186629, "episode/intrinsic_return": 0.0}
{"step": 989768, "time": 45048.65835690498, "episode/length": 175.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9659090909090909, "episode/intrinsic_return": 0.0}
{"step": 989928, "time": 45056.08442759514, "episode/length": 171.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9651162790697675, "episode/intrinsic_return": 0.0}
{"step": 990080, "time": 45082.31798529625, "eval_episode/length": 167.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9702380952380952}
{"step": 990080, "time": 45085.162451028824, "eval_episode/length": 195.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 990080, "time": 45087.081366539, "eval_episode/length": 203.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9754901960784313}
{"step": 990080, "time": 45088.79339456558, "eval_episode/length": 205.0, "eval_episode/score": 11.099999994039536, "eval_episode/reward_rate": 0.9951456310679612}
{"step": 990080, "time": 45088.801612854004, "eval_episode/length": 205.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9757281553398058}
{"step": 990080, "time": 45095.72637438774, "eval_episode/length": 94.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9894736842105263}
{"step": 990080, "time": 45097.59164977074, "eval_episode/length": 297.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9899328859060402}
{"step": 990080, "time": 45101.434525728226, "eval_episode/length": 353.0, "eval_episode/score": 12.100000001490116, "eval_episode/reward_rate": 0.9830508474576272}
{"step": 990376, "time": 45110.974066495895, "episode/length": 183.0, "episode/score": 12.099999994039536, "episode/reward_rate": 0.9945652173913043, "episode/intrinsic_return": 0.0}
{"step": 990488, "time": 45116.24670910835, "episode/length": 180.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 990848, "time": 45129.952019929886, "episode/length": 134.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9925925925925926, "episode/intrinsic_return": 0.0}
{"step": 991152, "time": 45141.4567732811, "episode/length": 217.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 991200, "time": 45144.588211774826, "episode/length": 466.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9957173447537473, "episode/intrinsic_return": 0.0}
{"step": 991320, "time": 45151.580047130585, "episode/length": 173.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9942528735632183, "episode/intrinsic_return": 0.0}
{"step": 991496, "time": 45158.87284612656, "episode/length": 36.0, "episode/score": 4.099999986588955, "episode/reward_rate": 0.8648648648648649, "episode/intrinsic_return": 0.0}
{"step": 991552, "time": 45162.69914984703, "episode/length": 422.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9881796690307328, "episode/intrinsic_return": 0.0}
{"step": 991616, "time": 45166.34262728691, "episode/length": 235.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.9957627118644068, "episode/intrinsic_return": 0.0}
{"step": 992560, "time": 45199.18289899826, "episode/length": 132.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9548872180451128, "episode/intrinsic_return": 0.0}
{"step": 992648, "time": 45203.36424636841, "episode/length": 283.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9964788732394366, "episode/intrinsic_return": 0.0}
{"step": 992872, "time": 45212.464993715286, "episode/length": 214.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9953488372093023, "episode/intrinsic_return": 0.0}
{"step": 992952, "time": 45216.70465803146, "episode/length": 262.0, "episode/score": 13.100000001490116, "episode/reward_rate": 0.9847908745247148, "episode/intrinsic_return": 0.0}
{"step": 993000, "time": 45219.96082448959, "episode/length": 172.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9710982658959537, "episode/intrinsic_return": 0.0}
{"step": 993024, "time": 45222.464049100876, "episode/length": 316.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9905362776025236, "episode/intrinsic_return": 0.0}
{"step": 993632, "time": 45244.11258530617, "episode/length": 94.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9473684210526315, "episode/intrinsic_return": 0.0}
{"step": 993656, "time": 45246.29034757614, "episode/length": 291.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.9965753424657534, "episode/intrinsic_return": 0.0}
{"step": 993872, "time": 45255.18050456047, "episode/length": 105.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9433962264150944, "episode/intrinsic_return": 0.0}
{"step": 993976, "time": 45259.88727068901, "episode/length": 121.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9590163934426229, "episode/intrinsic_return": 0.0}
{"step": 994080, "time": 45265.20184350014, "episode/length": 189.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.9736842105263158, "episode/intrinsic_return": 0.0}
{"step": 994224, "time": 45271.569093465805, "episode/length": 333.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9910179640718563, "episode/intrinsic_return": 0.0}
{"step": 994504, "time": 45282.32321071625, "episode/length": 193.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.979381443298969, "episode/intrinsic_return": 0.0}
{"step": 994824, "time": 45294.31907892227, "episode/length": 92.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.989247311827957, "episode/intrinsic_return": 0.0}
{"step": 995016, "time": 45302.16820693016, "episode/length": 169.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 995320, "time": 45313.798688173294, "episode/length": 210.0, "episode/score": 12.099999971687794, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 995472, "time": 45320.63940000534, "episode/length": 199.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.96, "episode/intrinsic_return": 0.0}
{"step": 995672, "time": 45328.58737492561, "episode/length": 377.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 995689, "time": 45331.69774603844, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.441587599061376, "train/action_min": 0.0, "train/action_std": 3.243852061333416, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03413422129673066, "train/actor_opt_grad_steps": 61440.0, "train/actor_opt_loss": -2.6258608732077717, "train/adv_mag": 0.4343171784346052, "train/adv_max": 0.3883788330520657, "train/adv_mean": 0.0036991966729968116, "train/adv_min": -0.3693680681770654, "train/adv_std": 0.05047123233298603, "train/cont_avg": 0.9953911870503597, "train/cont_loss_mean": 0.00016052778962496715, "train/cont_loss_std": 0.0046863351191472015, "train/cont_neg_acc": 0.9940362002352159, "train/cont_neg_loss": 0.017200411128293427, "train/cont_pos_acc": 0.9999646926097733, "train/cont_pos_loss": 7.14546648101154e-05, "train/cont_pred": 0.9953861575332477, "train/cont_rate": 0.9953911870503597, "train/dyn_loss_mean": 13.179442645834504, "train/dyn_loss_std": 9.105017126892967, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9944837740856967, "train/extr_critic_critic_opt_grad_steps": 61440.0, "train/extr_critic_critic_opt_loss": 15647.810048055306, "train/extr_critic_mag": 10.255290237262095, "train/extr_critic_max": 10.255290237262095, "train/extr_critic_mean": 3.457114408342101, "train/extr_critic_min": -0.15092217150351983, "train/extr_critic_std": 2.399878464156775, "train/extr_return_normed_mag": 1.4468811321601593, "train/extr_return_normed_max": 1.4468811321601593, "train/extr_return_normed_mean": 0.41394357115244695, "train/extr_return_normed_min": -0.106636333004605, "train/extr_return_normed_std": 0.31798544633302755, "train/extr_return_rate": 0.9108958638829293, "train/extr_return_raw_mag": 11.384288451654449, "train/extr_return_raw_max": 11.384288451654449, "train/extr_return_raw_mean": 3.485350824946122, "train/extr_return_raw_min": -0.49541764701013086, "train/extr_return_raw_std": 2.4320790416045153, "train/extr_reward_mag": 1.04609141246878, "train/extr_reward_max": 1.04609141246878, "train/extr_reward_mean": 0.0532514137490619, "train/extr_reward_min": -0.47900415067192464, "train/extr_reward_std": 0.21500744504465474, "train/image_loss_mean": 6.296853708706314, "train/image_loss_std": 12.131209877755145, "train/model_loss_mean": 14.263993228939798, "train/model_loss_std": 15.755889906300057, "train/model_opt_grad_norm": 53.91353512496399, "train/model_opt_grad_steps": 61385.21582733813, "train/model_opt_loss": 18905.437752922662, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1339.928057553957, "train/policy_entropy_mag": 2.601934101941774, "train/policy_entropy_max": 2.601934101941774, "train/policy_entropy_mean": 0.5273508678237311, "train/policy_entropy_min": 0.07937501628193067, "train/policy_entropy_std": 0.6521294052652318, "train/policy_logprob_mag": 7.438383767930723, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5265134212782057, "train/policy_logprob_min": -7.438383767930723, "train/policy_logprob_std": 1.0891359431280507, "train/policy_randomness_mag": 0.9183685539437713, "train/policy_randomness_max": 0.9183685539437713, "train/policy_randomness_mean": 0.18613171341607895, "train/policy_randomness_min": 0.028015897508791025, "train/policy_randomness_std": 0.23017306250633954, "train/post_ent_mag": 58.15731468475122, "train/post_ent_max": 58.15731468475122, "train/post_ent_mean": 42.08782920562964, "train/post_ent_min": 19.370610216538683, "train/post_ent_std": 7.6219314945687495, "train/prior_ent_mag": 66.8787859909826, "train/prior_ent_max": 66.8787859909826, "train/prior_ent_mean": 55.35220427478818, "train/prior_ent_min": 40.201088939639305, "train/prior_ent_std": 4.129453173644251, "train/rep_loss_mean": 13.179442645834504, "train/rep_loss_std": 9.105017126892967, "train/reward_avg": 0.03387196470561216, "train/reward_loss_mean": 0.059313477881306365, "train/reward_loss_std": 0.2562709338159012, "train/reward_max_data": 1.019424465062807, "train/reward_max_pred": 1.0132846900885053, "train/reward_neg_acc": 0.9918286916163328, "train/reward_neg_loss": 0.029075611007513758, "train/reward_pos_acc": 0.9728049087009841, "train/reward_pos_loss": 0.8300179513238317, "train/reward_pred": 0.033132806447126885, "train/reward_rate": 0.03794542491007194, "train_stats/sum_log_reward": 10.010891325255432, "train_stats/max_log_achievement_collect_coal": 0.9603960396039604, "train_stats/max_log_achievement_collect_drink": 5.762376237623762, "train_stats/max_log_achievement_collect_sapling": 1.5247524752475248, "train_stats/max_log_achievement_collect_stone": 13.089108910891088, "train_stats/max_log_achievement_collect_wood": 9.683168316831683, "train_stats/max_log_achievement_defeat_skeleton": 0.009900990099009901, "train_stats/max_log_achievement_defeat_zombie": 0.6237623762376238, "train_stats/max_log_achievement_eat_cow": 0.1782178217821782, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.009900990099009901, "train_stats/max_log_achievement_make_stone_sword": 0.009900990099009901, "train_stats/max_log_achievement_make_wood_pickaxe": 1.0495049504950495, "train_stats/max_log_achievement_make_wood_sword": 1.6336633663366336, "train_stats/max_log_achievement_place_furnace": 1.9306930693069306, "train_stats/max_log_achievement_place_plant": 1.396039603960396, "train_stats/max_log_achievement_place_stone": 3.4158415841584158, "train_stats/max_log_achievement_place_table": 2.594059405940594, "train_stats/max_log_achievement_wake_up": 1.188118811881188, "train_stats/mean_log_entropy": 0.5037272788658, "eval_stats/sum_log_reward": 10.350000351667404, "eval_stats/max_log_achievement_collect_coal": 1.0, "eval_stats/max_log_achievement_collect_drink": 3.375, "eval_stats/max_log_achievement_collect_sapling": 1.6875, "eval_stats/max_log_achievement_collect_stone": 17.625, "eval_stats/max_log_achievement_collect_wood": 9.0625, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.375, "eval_stats/max_log_achievement_eat_cow": 0.125, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.0625, "eval_stats/max_log_achievement_make_wood_sword": 1.375, "eval_stats/max_log_achievement_place_furnace": 2.8125, "eval_stats/max_log_achievement_place_plant": 1.6875, "eval_stats/max_log_achievement_place_stone": 3.625, "eval_stats/max_log_achievement_place_table": 2.5625, "eval_stats/max_log_achievement_wake_up": 1.25, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9970703125, "report/cont_loss_mean": 1.477435716878972e-06, "report/cont_loss_std": 4.105028710910119e-05, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.00045176298590376973, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 1.5436368983046123e-07, "report/cont_pred": 0.9970715045928955, "report/cont_rate": 0.9970703125, "report/dyn_loss_mean": 11.536844253540039, "report/dyn_loss_std": 8.814311027526855, "report/image_loss_mean": 6.39860200881958, "report/image_loss_std": 13.121737480163574, "report/model_loss_mean": 13.367490768432617, "report/model_loss_std": 16.705883026123047, "report/post_ent_mag": 56.69333267211914, "report/post_ent_max": 56.69333267211914, "report/post_ent_mean": 43.431068420410156, "report/post_ent_min": 18.444194793701172, "report/post_ent_std": 7.2327656745910645, "report/prior_ent_mag": 66.76068878173828, "report/prior_ent_max": 66.76068878173828, "report/prior_ent_mean": 55.68204879760742, "report/prior_ent_min": 37.62762451171875, "report/prior_ent_std": 4.199223041534424, "report/rep_loss_mean": 11.536844253540039, "report/rep_loss_std": 8.814311027526855, "report/reward_avg": 0.025390625, "report/reward_loss_mean": 0.0467803031206131, "report/reward_loss_std": 0.2146485596895218, "report/reward_max_data": 1.0, "report/reward_max_pred": 1.002366065979004, "report/reward_neg_acc": 0.9969818592071533, "report/reward_neg_loss": 0.02269904501736164, "report/reward_pos_acc": 0.9666666984558105, "report/reward_pos_loss": 0.8446727991104126, "report/reward_pred": 0.023392170667648315, "report/reward_rate": 0.029296875, "eval/cont_avg": 0.998046875, "eval/cont_loss_mean": 7.520453891629586e-06, "eval/cont_loss_std": 0.0002384999388596043, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.0038301204331219196, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 3.9827728670616125e-08, "eval/cont_pred": 0.9980543255805969, "eval/cont_rate": 0.998046875, "eval/dyn_loss_mean": 17.45725440979004, "eval/dyn_loss_std": 11.625415802001953, "eval/image_loss_mean": 9.633262634277344, "eval/image_loss_std": 13.780736923217773, "eval/model_loss_mean": 20.20439910888672, "eval/model_loss_std": 18.092304229736328, "eval/post_ent_mag": 58.513938903808594, "eval/post_ent_max": 58.513938903808594, "eval/post_ent_mean": 40.54428482055664, "eval/post_ent_min": 19.5069637298584, "eval/post_ent_std": 8.550469398498535, "eval/prior_ent_mag": 66.76068878173828, "eval/prior_ent_max": 66.76068878173828, "eval/prior_ent_mean": 55.97351837158203, "eval/prior_ent_min": 42.42198944091797, "eval/prior_ent_std": 3.644103765487671, "eval/rep_loss_mean": 17.45725440979004, "eval/rep_loss_std": 11.625415802001953, "eval/reward_avg": 0.03261718899011612, "eval/reward_loss_mean": 0.0967770516872406, "eval/reward_loss_std": 0.6183574199676514, "eval/reward_max_data": 1.100000023841858, "eval/reward_max_pred": 1.075556755065918, "eval/reward_neg_acc": 0.9888664484024048, "eval/reward_neg_loss": 0.05094151571393013, "eval/reward_pos_acc": 0.8888888955116272, "eval/reward_pos_loss": 1.3547075986862183, "eval/reward_pred": 0.02929740399122238, "eval/reward_rate": 0.03515625, "replay/size": 995185.0, "replay/inserts": 22176.0, "replay/samples": 22176.0, "replay/insert_wait_avg": 1.3269881837467783e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.105252099415613e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5752.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.1296696722590376e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 9.08970832824707e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2055764198303, "timer/env.step_count": 2772.0, "timer/env.step_total": 242.08088326454163, "timer/env.step_frac": 0.242031127371889, "timer/env.step_avg": 0.08733076596844935, "timer/env.step_min": 0.02289438247680664, "timer/env.step_max": 3.4912030696868896, "timer/replay._sample_count": 22176.0, "timer/replay._sample_total": 11.089736461639404, "timer/replay._sample_frac": 0.011087457141895152, "timer/replay._sample_avg": 0.0005000783036453555, "timer/replay._sample_min": 0.0004038810729980469, "timer/replay._sample_max": 0.011046886444091797, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3491.0, "timer/agent.policy_total": 56.279611587524414, "timer/agent.policy_frac": 0.05626804420444601, "timer/agent.policy_avg": 0.016121343909345293, "timer/agent.policy_min": 0.009113311767578125, "timer/agent.policy_max": 0.0862417221069336, "timer/dataset_train_count": 1386.0, "timer/dataset_train_total": 0.14807653427124023, "timer/dataset_train_frac": 0.00014804609948413844, "timer/dataset_train_avg": 0.00010683732631402614, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0002722740173339844, "timer/agent.train_count": 1386.0, "timer/agent.train_total": 621.2169725894928, "timer/agent.train_frac": 0.6210892912765972, "timer/agent.train_avg": 0.448208493931813, "timer/agent.train_min": 0.43300962448120117, "timer/agent.train_max": 2.742152690887451, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.4800858497619629, "timer/agent.report_frac": 0.00047998717571681455, "timer/agent.report_avg": 0.24004292488098145, "timer/agent.report_min": 0.23207402229309082, "timer/agent.report_max": 0.24801182746887207, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.9802322387695312e-05, "timer/dataset_eval_frac": 2.97961969921931e-08, "timer/dataset_eval_avg": 2.9802322387695312e-05, "timer/dataset_eval_min": 2.9802322387695312e-05, "timer/dataset_eval_max": 2.9802322387695312e-05, "fps": 22.171128112930493}
{"step": 995952, "time": 45340.56594777107, "episode/length": 215.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9722222222222222, "episode/intrinsic_return": 0.0}
{"step": 996016, "time": 45344.24605178833, "episode/length": 254.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9764705882352941, "episode/intrinsic_return": 0.0}
{"step": 996152, "time": 45350.04328298569, "episode/length": 165.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9698795180722891, "episode/intrinsic_return": 0.0}
{"step": 996656, "time": 45368.54474258423, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 996680, "time": 45371.29240322113, "episode/length": 150.0, "episode/score": 9.100000008940697, "episode/reward_rate": 0.9933774834437086, "episode/intrinsic_return": 0.0}
{"step": 996752, "time": 45375.580647706985, "episode/length": 280.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9857651245551602, "episode/intrinsic_return": 0.0}
{"step": 997184, "time": 45391.41849112511, "episode/length": 232.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9785407725321889, "episode/intrinsic_return": 0.0}
{"step": 997384, "time": 45399.38449764252, "episode/length": 213.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9766355140186916, "episode/intrinsic_return": 0.0}
{"step": 997456, "time": 45403.777901649475, "episode/length": 187.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9680851063829787, "episode/intrinsic_return": 0.0}
{"step": 997712, "time": 45414.01739668846, "episode/length": 131.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9924242424242424, "episode/intrinsic_return": 0.0}
{"step": 998336, "time": 45437.02548503876, "episode/length": 272.0, "episode/score": 11.100000023841858, "episode/reward_rate": 0.9963369963369964, "episode/intrinsic_return": 0.0}
{"step": 998560, "time": 45445.94920015335, "episode/length": 225.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995575221238938, "episode/intrinsic_return": 0.0}
{"step": 998624, "time": 45449.628680467606, "episode/length": 113.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9912280701754386, "episode/intrinsic_return": 0.0}
{"step": 998760, "time": 45455.40330052376, "episode/length": 196.0, "episode/score": 8.099999994039536, "episode/reward_rate": 0.9949238578680203, "episode/intrinsic_return": 0.0}
{"step": 998904, "time": 45461.8012046814, "episode/length": 360.0, "episode/score": 14.100000023841858, "episode/reward_rate": 0.997229916897507, "episode/intrinsic_return": 0.0}
{"step": 998920, "time": 45463.96355676651, "episode/length": 182.0, "episode/score": 10.1000000461936, "episode/reward_rate": 0.9672131147540983, "episode/intrinsic_return": 0.0}
{"step": 999608, "time": 45489.8663482666, "episode/length": 277.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9748201438848921, "episode/intrinsic_return": 0.0}
{"step": 1000064, "time": 45526.991151571274, "eval_episode/length": 163.0, "eval_episode/score": 5.099999986588955, "eval_episode/reward_rate": 0.9695121951219512}
{"step": 1000064, "time": 45528.82729887962, "eval_episode/length": 167.0, "eval_episode/score": 10.100000008940697, "eval_episode/reward_rate": 0.9642857142857143}
{"step": 1000064, "time": 45530.44372344017, "eval_episode/length": 168.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9763313609467456}
{"step": 1000064, "time": 45532.355078697205, "eval_episode/length": 175.0, "eval_episode/score": 10.099999979138374, "eval_episode/reward_rate": 0.9943181818181818}
{"step": 1000064, "time": 45535.25721669197, "eval_episode/length": 206.0, "eval_episode/score": 13.100000001490116, "eval_episode/reward_rate": 0.9806763285024155}
{"step": 1000064, "time": 45536.82244896889, "eval_episode/length": 207.0, "eval_episode/score": 9.100000008940697, "eval_episode/reward_rate": 0.9951923076923077}
{"step": 1000064, "time": 45543.231308460236, "eval_episode/length": 280.0, "eval_episode/score": 11.100000023841858, "eval_episode/reward_rate": 0.99644128113879}
{"step": 1000064, "time": 45547.40868830681, "eval_episode/length": 176.0, "eval_episode/score": 10.100000023841858, "eval_episode/reward_rate": 0.9943502824858758}
{"step": 1000176, "time": 45551.23274278641, "episode/length": 176.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1000264, "time": 45555.44926190376, "episode/length": 204.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.9902439024390244, "episode/intrinsic_return": 0.0}
{"step": 1000432, "time": 45562.7981467247, "episode/length": 190.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9790575916230366, "episode/intrinsic_return": 0.0}
{"step": 1000688, "time": 45572.83774185181, "episode/length": 293.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9897959183673469, "episode/intrinsic_return": 0.0}
{"step": 1000728, "time": 45575.54753255844, "episode/length": 505.0, "episode/score": 9.100000023841858, "episode/reward_rate": 0.9980237154150198, "episode/intrinsic_return": 0.0}
{"step": 1000776, "time": 45578.74579024315, "episode/length": 276.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9747292418772563, "episode/intrinsic_return": 0.0}
{"step": 1000784, "time": 45580.964634895325, "episode/length": 146.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9931972789115646, "episode/intrinsic_return": 0.0}
{"step": 1001096, "time": 45592.50270628929, "episode/length": 271.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9963235294117647, "episode/intrinsic_return": 0.0}
{"step": 1001688, "time": 45614.298609018326, "episode/length": 188.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9735449735449735, "episode/intrinsic_return": 0.0}
{"step": 1002216, "time": 45634.29310011864, "episode/length": 243.0, "episode/score": 10.100000031292439, "episode/reward_rate": 0.9959016393442623, "episode/intrinsic_return": 0.0}
{"step": 1002736, "time": 45653.494691610336, "episode/length": 204.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9658536585365853, "episode/intrinsic_return": 0.0}
{"step": 1002896, "time": 45660.41093158722, "episode/length": 264.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9962264150943396, "episode/intrinsic_return": 0.0}
{"step": 1003040, "time": 45666.7355492115, "episode/length": 168.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9940828402366864, "episode/intrinsic_return": 0.0}
{"step": 1003256, "time": 45675.214044094086, "episode/length": 315.0, "episode/score": 11.099999979138374, "episode/reward_rate": 0.9968354430379747, "episode/intrinsic_return": 0.0}
{"step": 1003272, "time": 45677.30893135071, "episode/length": 310.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9967845659163987, "episode/intrinsic_return": 0.0}
{"step": 1003424, "time": 45684.075120687485, "episode/length": 47.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9791666666666666, "episode/intrinsic_return": 0.0}
{"step": 1003528, "time": 45688.83542442322, "episode/length": 163.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9634146341463414, "episode/intrinsic_return": 0.0}
{"step": 1003688, "time": 45695.6936378479, "episode/length": 406.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9778869778869779, "episode/intrinsic_return": 0.0}
{"step": 1003712, "time": 45698.241035461426, "episode/length": 377.0, "episode/score": 13.099999964237213, "episode/reward_rate": 0.9920634920634921, "episode/intrinsic_return": 0.0}
{"step": 1004720, "time": 45733.03288269043, "episode/length": 180.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9779005524861878, "episode/intrinsic_return": 0.0}
{"step": 1004920, "time": 45740.97104716301, "episode/length": 272.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9853479853479854, "episode/intrinsic_return": 0.0}
{"step": 1004928, "time": 45743.04420423508, "episode/length": 208.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 1005048, "time": 45748.29328942299, "episode/length": 202.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9655172413793104, "episode/intrinsic_return": 0.0}
{"step": 1005064, "time": 45750.40217876434, "episode/length": 270.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.985239852398524, "episode/intrinsic_return": 0.0}
{"step": 1005216, "time": 45757.241396427155, "episode/length": 210.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.995260663507109, "episode/intrinsic_return": 0.0}
{"step": 1005840, "time": 45779.72092485428, "episode/length": 268.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9628252788104089, "episode/intrinsic_return": 0.0}
{"step": 1006008, "time": 45786.53952050209, "episode/length": 286.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1006320, "time": 45798.564403772354, "episode/length": 158.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 1006448, "time": 45804.32969689369, "episode/length": 54.0, "episode/score": 3.099999986588955, "episode/reward_rate": 0.9272727272727272, "episode/intrinsic_return": 0.0}
{"step": 1006736, "time": 45815.570009469986, "episode/length": 226.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9779735682819384, "episode/intrinsic_return": 0.0}
{"step": 1007008, "time": 45826.28758764267, "episode/length": 285.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9790209790209791, "episode/intrinsic_return": 0.0}
{"step": 1007440, "time": 45842.24705004692, "episode/length": 313.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9968152866242038, "episode/intrinsic_return": 0.0}
{"step": 1007808, "time": 45858.596447229385, "episode/length": 185.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.978494623655914, "episode/intrinsic_return": 0.0}
{"step": 1008160, "time": 45871.623057603836, "episode/length": 289.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9862068965517241, "episode/intrinsic_return": 0.0}
{"step": 1008376, "time": 45880.25245976448, "episode/length": 204.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9804878048780488, "episode/intrinsic_return": 0.0}
{"step": 1008384, "time": 45882.348510980606, "episode/length": 395.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9772727272727273, "episode/intrinsic_return": 0.0}
{"step": 1008808, "time": 45897.989122629166, "episode/length": 467.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1008944, "time": 45904.2399225235, "episode/length": 311.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9935897435897436, "episode/intrinsic_return": 0.0}
{"step": 1009088, "time": 45910.7379629612, "episode/length": 159.0, "episode/score": 10.100000008940697, "episode/reward_rate": 0.95625, "episode/intrinsic_return": 0.0}
{"step": 1009184, "time": 45916.147272348404, "episode/length": 271.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9742647058823529, "episode/intrinsic_return": 0.0}
{"step": 1009248, "time": 45920.32824754715, "episode/length": 225.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9690265486725663, "episode/intrinsic_return": 0.0}
{"step": 1009488, "time": 45929.80844283104, "episode/length": 165.0, "episode/score": 11.099999994039536, "episode/reward_rate": 0.9939759036144579, "episode/intrinsic_return": 0.0}
{"step": 1009680, "time": 45937.66303539276, "episode/length": 161.0, "episode/score": 8.099999979138374, "episode/reward_rate": 0.9938271604938271, "episode/intrinsic_return": 0.0}
{"step": 1010048, "time": 45966.42807626724, "eval_episode/length": 61.0, "eval_episode/score": 7.099999986588955, "eval_episode/reward_rate": 0.9193548387096774}
{"step": 1010048, "time": 45969.79000926018, "eval_episode/length": 42.0, "eval_episode/score": 5.100000023841858, "eval_episode/reward_rate": 0.9767441860465116}
{"step": 1010048, "time": 45972.79745411873, "eval_episode/length": 143.0, "eval_episode/score": 9.099999979138374, "eval_episode/reward_rate": 0.9930555555555556}
{"step": 1010048, "time": 45977.34775471687, "eval_episode/length": 215.0, "eval_episode/score": 11.099999986588955, "eval_episode/reward_rate": 0.9814814814814815}
{"step": 1010048, "time": 45979.25900363922, "eval_episode/length": 222.0, "eval_episode/score": 8.099999986588955, "eval_episode/reward_rate": 0.9775784753363229}
{"step": 1010048, "time": 45983.352184295654, "eval_episode/length": 284.0, "eval_episode/score": 10.099999986588955, "eval_episode/reward_rate": 0.9789473684210527}
{"step": 1010048, "time": 45985.00128173828, "eval_episode/length": 181.0, "eval_episode/score": 9.099999986588955, "eval_episode/reward_rate": 0.9725274725274725}
{"step": 1010048, "time": 45988.029264211655, "eval_episode/length": 320.0, "eval_episode/score": 12.099999986588955, "eval_episode/reward_rate": 0.9844236760124611}
{"step": 1010120, "time": 45990.23270249367, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9724770642201835, "episode/intrinsic_return": 0.0}
{"step": 1010456, "time": 46003.03444862366, "episode/length": 158.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9685534591194969, "episode/intrinsic_return": 0.0}
{"step": 1010480, "time": 46005.58223199844, "episode/length": 208.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9712918660287081, "episode/intrinsic_return": 0.0}
{"step": 1010552, "time": 46009.2791826725, "episode/length": 162.0, "episode/score": 9.099999986588955, "episode/reward_rate": 0.9631901840490797, "episode/intrinsic_return": 0.0}
{"step": 1011112, "time": 46029.25288939476, "episode/length": 270.0, "episode/score": 8.100000008940697, "episode/reward_rate": 0.996309963099631, "episode/intrinsic_return": 0.0}
{"step": 1011304, "time": 46037.1979329586, "episode/length": 226.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9955947136563876, "episode/intrinsic_return": 0.0}
{"step": 1011512, "time": 46045.51005625725, "episode/length": 302.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9867986798679867, "episode/intrinsic_return": 0.0}
{"step": 1011848, "time": 46058.16720986366, "episode/length": 270.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.981549815498155, "episode/intrinsic_return": 0.0}
{"step": 1012048, "time": 46066.56592416763, "episode/length": 195.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9744897959183674, "episode/intrinsic_return": 0.0}
{"step": 1012632, "time": 46087.6998860836, "episode/length": 189.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9631578947368421, "episode/intrinsic_return": 0.0}
{"step": 1012720, "time": 46092.391285419464, "episode/length": 176.0, "episode/score": 11.100000016391277, "episode/reward_rate": 0.9774011299435028, "episode/intrinsic_return": 0.0}
{"step": 1012736, "time": 46094.410251140594, "episode/length": 284.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9754385964912281, "episode/intrinsic_return": 0.0}
{"step": 1013056, "time": 46106.50067234039, "episode/length": 366.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9945504087193461, "episode/intrinsic_return": 0.0}
{"step": 1013168, "time": 46111.76378417015, "episode/length": 206.0, "episode/score": 11.100000001490116, "episode/reward_rate": 0.9855072463768116, "episode/intrinsic_return": 0.0}
{"step": 1013648, "time": 46129.1919772625, "episode/length": 224.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1013872, "time": 46138.115115880966, "episode/length": 141.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9929577464788732, "episode/intrinsic_return": 0.0}
{"step": 1013888, "time": 46140.29284477234, "episode/length": 229.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9826086956521739, "episode/intrinsic_return": 0.0}
{"step": 1013960, "time": 46143.92456293106, "episode/length": 112.0, "episode/score": 11.100000008940697, "episode/reward_rate": 0.9557522123893806, "episode/intrinsic_return": 0.0}
{"step": 1013960, "time": 46143.931190013885, "episode/length": 38.0, "episode/score": 5.100000038743019, "episode/reward_rate": 0.9230769230769231, "episode/intrinsic_return": 0.0}
{"step": 1014096, "time": 46151.79849553108, "episode/length": 171.0, "episode/score": 6.099999986588955, "episode/reward_rate": 0.9709302325581395, "episode/intrinsic_return": 0.0}
{"step": 1014552, "time": 46168.21187543869, "episode/length": 172.0, "episode/score": 10.100000001490116, "episode/reward_rate": 0.976878612716763, "episode/intrinsic_return": 0.0}
{"step": 1014912, "time": 46182.059210538864, "episode/length": 284.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9789473684210527, "episode/intrinsic_return": 0.0}
{"step": 1015104, "time": 46189.92724490166, "episode/length": 153.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9935064935064936, "episode/intrinsic_return": 0.0}
{"step": 1015520, "time": 46205.25173044205, "episode/length": 51.0, "episode/score": 7.099999986588955, "episode/reward_rate": 0.9038461538461539, "episode/intrinsic_return": 0.0}
{"step": 1015656, "time": 46211.259670972824, "episode/length": 211.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9811320754716981, "episode/intrinsic_return": 0.0}
{"step": 1015680, "time": 46213.85082936287, "episode/length": 640.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9875195007800313, "episode/intrinsic_return": 0.0}
{"step": 1015840, "time": 46222.333406209946, "episode/length": 217.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9954128440366973, "episode/intrinsic_return": 0.0}
{"step": 1015840, "time": 46222.341967344284, "episode/length": 234.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9957446808510638, "episode/intrinsic_return": 0.0}
{"step": 1016328, "time": 46241.53601884842, "episode/length": 176.0, "episode/score": 12.100000001490116, "episode/reward_rate": 0.9717514124293786, "episode/intrinsic_return": 0.0}
{"step": 1016712, "time": 46255.84737563133, "episode/length": 269.0, "episode/score": 9.100000001490116, "episode/reward_rate": 0.9777777777777777, "episode/intrinsic_return": 0.0}
{"step": 1017160, "time": 46272.33687090874, "episode/length": 408.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9975550122249389, "episode/intrinsic_return": 0.0}
{"step": 1017448, "time": 46283.44827461243, "episode/length": 220.0, "episode/score": 12.100000008940697, "episode/reward_rate": 0.9683257918552036, "episode/intrinsic_return": 0.0}
{"step": 1017520, "time": 46287.606803417206, "episode/length": 209.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9714285714285714, "episode/intrinsic_return": 0.0}
{"step": 1017552, "time": 46290.22142934799, "episode/length": 48.0, "episode/score": 4.1000000312924385, "episode/reward_rate": 0.9795918367346939, "episode/intrinsic_return": 0.0}
{"step": 1018056, "time": 46308.186876535416, "episode/length": 299.0, "episode/score": 7.100000008940697, "episode/reward_rate": 0.9966666666666667, "episode/intrinsic_return": 0.0}
{"step": 1018096, "time": 46311.24853372574, "episode/length": 220.0, "episode/score": 12.100000023841858, "episode/reward_rate": 0.995475113122172, "episode/intrinsic_return": 0.0}
{"step": 1018152, "time": 46314.42744970322, "episode/length": 328.0, "episode/score": 8.099999986588955, "episode/reward_rate": 0.9817629179331308, "episode/intrinsic_return": 0.0}
{"step": 1018601, "time": 46332.01503229141, "train/action_mag": 16.0, "train/action_max": 16.0, "train/action_mean": 4.550891796192089, "train/action_min": 0.0, "train/action_std": 3.4051135253239346, "train/actor_opt_actor_opt_grad_overflow": 0.0, "train/actor_opt_actor_opt_grad_scale": 10000.0, "train/actor_opt_grad_norm": 0.03280346115100217, "train/actor_opt_grad_steps": 62850.0, "train/actor_opt_loss": -8.127796052635967, "train/adv_mag": 0.4717474139028496, "train/adv_max": 0.39688445929880745, "train/adv_mean": 0.002236049900081137, "train/adv_min": -0.40717433986963925, "train/adv_std": 0.04822800665364399, "train/cont_avg": 0.9951718203671329, "train/cont_loss_mean": 0.000280000465958854, "train/cont_loss_std": 0.008283259454344319, "train/cont_neg_acc": 0.9886779897696488, "train/cont_neg_loss": 0.04272309649055209, "train/cont_pos_acc": 0.9999656864813158, "train/cont_pos_loss": 8.820532703933938e-05, "train/cont_pred": 0.9951816684716231, "train/cont_rate": 0.9951718203671329, "train/dyn_loss_mean": 13.211557701751069, "train/dyn_loss_std": 9.166880914381334, "train/extr_critic_critic_opt_critic_opt_grad_overflow": 0.0, "train/extr_critic_critic_opt_critic_opt_grad_scale": 10000.0, "train/extr_critic_critic_opt_grad_norm": 0.9553704807808349, "train/extr_critic_critic_opt_grad_steps": 62850.0, "train/extr_critic_critic_opt_loss": 15461.250443892046, "train/extr_critic_mag": 10.513020515441895, "train/extr_critic_max": 10.513020515441895, "train/extr_critic_mean": 3.4877540248257297, "train/extr_critic_min": -0.15639857728998144, "train/extr_critic_std": 2.5101835719355337, "train/extr_return_normed_mag": 1.4299516186013923, "train/extr_return_normed_max": 1.4299516186013923, "train/extr_return_normed_mean": 0.41295407576994464, "train/extr_return_normed_min": -0.09324703808431026, "train/extr_return_normed_std": 0.3225683275011036, "train/extr_return_rate": 0.8959066809474171, "train/extr_return_raw_mag": 11.508390880131222, "train/extr_return_raw_max": 11.508390880131222, "train/extr_return_raw_mean": 3.5053417415885657, "train/extr_return_raw_min": -0.47874663092873315, "train/extr_return_raw_std": 2.538592822068221, "train/extr_reward_mag": 1.0427459520059865, "train/extr_reward_max": 1.0427459520059865, "train/extr_reward_mean": 0.05514808113758381, "train/extr_reward_min": -0.46187835640006963, "train/extr_reward_std": 0.21936599608067867, "train/image_loss_mean": 6.3097717211796684, "train/image_loss_std": 12.255398410183567, "train/model_loss_mean": 14.29583442127788, "train/model_loss_std": 15.930581759739589, "train/model_opt_grad_norm": 51.024007703874496, "train/model_opt_grad_steps": 62793.97902097902, "train/model_opt_loss": 21612.733528190558, "train/model_opt_model_opt_grad_overflow": 0.0, "train/model_opt_model_opt_grad_scale": 1512.2377622377621, "train/policy_entropy_mag": 2.601406482549814, "train/policy_entropy_max": 2.601406482549814, "train/policy_entropy_mean": 0.5402283101648717, "train/policy_entropy_min": 0.07937501912767236, "train/policy_entropy_std": 0.6736866392038919, "train/policy_logprob_mag": 7.438383829343569, "train/policy_logprob_max": -0.009455657564103603, "train/policy_logprob_mean": -0.5399093150675713, "train/policy_logprob_min": -7.438383829343569, "train/policy_logprob_std": 1.1002383803154205, "train/policy_randomness_mag": 0.9181823276139639, "train/policy_randomness_max": 0.9181823276139639, "train/policy_randomness_mean": 0.19067688661438603, "train/policy_randomness_min": 0.028015898501539564, "train/policy_randomness_std": 0.2377818179922504, "train/post_ent_mag": 58.080534874976095, "train/post_ent_max": 58.080534874976095, "train/post_ent_mean": 42.133382703874496, "train/post_ent_min": 19.63636451667839, "train/post_ent_std": 7.697092309698358, "train/prior_ent_mag": 67.03350509963668, "train/prior_ent_max": 67.03350509963668, "train/prior_ent_mean": 55.41236434616409, "train/prior_ent_min": 40.70842817613295, "train/prior_ent_std": 4.055824646582971, "train/rep_loss_mean": 13.211557701751069, "train/rep_loss_std": 9.166880914381334, "train/reward_avg": 0.034076567726222785, "train/reward_loss_mean": 0.05884810039526099, "train/reward_loss_std": 0.25051693618297577, "train/reward_max_data": 1.0286713355071062, "train/reward_max_pred": 1.0177156591748857, "train/reward_neg_acc": 0.9926965219991191, "train/reward_neg_loss": 0.02905943267490272, "train/reward_pos_acc": 0.9752573020808346, "train/reward_pos_loss": 0.8088971664021899, "train/reward_pred": 0.03337401371787895, "train/reward_rate": 0.0384137347027972, "train_stats/sum_log_reward": 10.20309298800439, "train_stats/max_log_achievement_collect_coal": 0.7216494845360825, "train_stats/max_log_achievement_collect_drink": 5.690721649484536, "train_stats/max_log_achievement_collect_sapling": 1.3402061855670102, "train_stats/max_log_achievement_collect_stone": 13.628865979381443, "train_stats/max_log_achievement_collect_wood": 10.29896907216495, "train_stats/max_log_achievement_defeat_skeleton": 0.020618556701030927, "train_stats/max_log_achievement_defeat_zombie": 0.7319587628865979, "train_stats/max_log_achievement_eat_cow": 0.15463917525773196, "train_stats/max_log_achievement_eat_plant": 0.0, "train_stats/max_log_achievement_make_stone_pickaxe": 0.010309278350515464, "train_stats/max_log_achievement_make_stone_sword": 0.010309278350515464, "train_stats/max_log_achievement_make_wood_pickaxe": 1.1134020618556701, "train_stats/max_log_achievement_make_wood_sword": 1.4742268041237114, "train_stats/max_log_achievement_place_furnace": 2.216494845360825, "train_stats/max_log_achievement_place_plant": 1.309278350515464, "train_stats/max_log_achievement_place_stone": 3.268041237113402, "train_stats/max_log_achievement_place_table": 2.649484536082474, "train_stats/max_log_achievement_wake_up": 1.3505154639175259, "train_stats/mean_log_entropy": 0.5511945430765447, "eval_stats/sum_log_reward": 9.412500232458115, "eval_stats/max_log_achievement_collect_coal": 0.5, "eval_stats/max_log_achievement_collect_drink": 3.3125, "eval_stats/max_log_achievement_collect_sapling": 1.375, "eval_stats/max_log_achievement_collect_stone": 10.625, "eval_stats/max_log_achievement_collect_wood": 8.6875, "eval_stats/max_log_achievement_defeat_skeleton": 0.0, "eval_stats/max_log_achievement_defeat_zombie": 0.625, "eval_stats/max_log_achievement_eat_cow": 0.0625, "eval_stats/max_log_achievement_eat_plant": 0.0, "eval_stats/max_log_achievement_make_stone_pickaxe": 0.0, "eval_stats/max_log_achievement_make_stone_sword": 0.0, "eval_stats/max_log_achievement_make_wood_pickaxe": 1.1875, "eval_stats/max_log_achievement_make_wood_sword": 1.125, "eval_stats/max_log_achievement_place_furnace": 1.625, "eval_stats/max_log_achievement_place_plant": 1.375, "eval_stats/max_log_achievement_place_stone": 2.75, "eval_stats/max_log_achievement_place_table": 2.4375, "eval_stats/max_log_achievement_wake_up": 1.0625, "eval_stats/mean_log_entropy": 0.0, "report/cont_avg": 0.9951171875, "report/cont_loss_mean": 5.629668521578424e-05, "report/cont_loss_std": 0.0016606650315225124, "report/cont_neg_acc": 1.0, "report/cont_neg_loss": 0.010644769296050072, "report/cont_pos_acc": 1.0, "report/cont_pos_loss": 4.341460680734599e-06, "report/cont_pred": 0.9951635599136353, "report/cont_rate": 0.9951171875, "report/dyn_loss_mean": 14.51986026763916, "report/dyn_loss_std": 9.86455249786377, "report/image_loss_mean": 5.975590229034424, "report/image_loss_std": 10.662883758544922, "report/model_loss_mean": 14.770549774169922, "report/model_loss_std": 15.07567310333252, "report/post_ent_mag": 58.105079650878906, "report/post_ent_max": 58.105079650878906, "report/post_ent_mean": 40.8399658203125, "report/post_ent_min": 16.75969696044922, "report/post_ent_std": 7.930417060852051, "report/prior_ent_mag": 67.01839447021484, "report/prior_ent_max": 67.01839447021484, "report/prior_ent_mean": 55.247154235839844, "report/prior_ent_min": 42.389808654785156, "report/prior_ent_std": 3.965806484222412, "report/rep_loss_mean": 14.51986026763916, "report/rep_loss_std": 9.86455249786377, "report/reward_avg": 0.05351562798023224, "report/reward_loss_mean": 0.08298647403717041, "report/reward_loss_std": 0.29754647612571716, "report/reward_max_data": 1.100000023841858, "report/reward_max_pred": 1.0408530235290527, "report/reward_neg_acc": 0.9916840195655823, "report/reward_neg_loss": 0.037056032568216324, "report/reward_pos_acc": 0.9838709235191345, "report/reward_pos_loss": 0.7956491708755493, "report/reward_pred": 0.05147456377744675, "report/reward_rate": 0.060546875, "eval/cont_avg": 0.9990234375, "eval/cont_loss_mean": 1.5105644706636667e-05, "eval/cont_loss_std": 0.00040495203575119376, "eval/cont_neg_acc": 1.0, "eval/cont_neg_loss": 0.000160943774972111, "eval/cont_pos_acc": 1.0, "eval/cont_pos_loss": 1.4963084140617866e-05, "eval/cont_pred": 0.9990087747573853, "eval/cont_rate": 0.9990234375, "eval/dyn_loss_mean": 17.5142822265625, "eval/dyn_loss_std": 10.22390365600586, "eval/image_loss_mean": 11.428717613220215, "eval/image_loss_std": 15.170815467834473, "eval/model_loss_mean": 22.049612045288086, "eval/model_loss_std": 19.0406436920166, "eval/post_ent_mag": 58.41373825073242, "eval/post_ent_max": 58.41373825073242, "eval/post_ent_mean": 40.54057693481445, "eval/post_ent_min": 17.935489654541016, "eval/post_ent_std": 7.68739652633667, "eval/prior_ent_mag": 67.01839447021484, "eval/prior_ent_max": 67.01839447021484, "eval/prior_ent_mean": 56.312339782714844, "eval/prior_ent_min": 42.96367645263672, "eval/prior_ent_std": 3.8650965690612793, "eval/rep_loss_mean": 17.5142822265625, "eval/rep_loss_std": 10.22390365600586, "eval/reward_avg": 0.04941406100988388, "eval/reward_loss_mean": 0.1123095229268074, "eval/reward_loss_std": 0.6344514489173889, "eval/reward_max_data": 1.0, "eval/reward_max_pred": 1.0053925514221191, "eval/reward_neg_acc": 0.9845520257949829, "eval/reward_neg_loss": 0.043002475053071976, "eval/reward_pos_acc": 0.9056603908538818, "eval/reward_pos_loss": 1.3820669651031494, "eval/reward_pred": 0.04647266864776611, "eval/reward_rate": 0.0517578125, "replay/size": 1000000.0, "replay/inserts": 22912.0, "replay/samples": 22912.0, "replay/insert_wait_avg": 1.2822282713884749e-06, "replay/insert_wait_frac": 1.0, "replay/sample_wait_avg": 7.006043162425803e-07, "replay/sample_wait_frac": 1.0, "eval_replay/size": 100000.0, "eval_replay/inserts": 5328.0, "eval_replay/samples": 16.0, "eval_replay/insert_wait_avg": 1.0791036101790877e-06, "eval_replay/insert_wait_frac": 1.0, "eval_replay/sample_wait_avg": 8.493661880493164e-07, "eval_replay/sample_wait_frac": 1.0, "timer/duration": 1000.2726640701294, "timer/env.step_count": 2864.0, "timer/env.step_total": 232.72675037384033, "timer/env.step_frac": 0.23266331144837105, "timer/env.step_avg": 0.08125934021432972, "timer/env.step_min": 0.022519588470458984, "timer/env.step_max": 3.264770746231079, "timer/replay._sample_count": 22912.0, "timer/replay._sample_total": 11.4371976852417, "timer/replay._sample_frac": 0.011434080022444594, "timer/replay._sample_avg": 0.0004991793682455351, "timer/replay._sample_min": 0.00041031837463378906, "timer/replay._sample_max": 0.009486913681030273, "timer/agent.save_count": 0.0, "timer/agent.save_total": 0.0, "timer/agent.save_frac": 0.0, "timer/agent.policy_count": 3530.0, "timer/agent.policy_total": 57.78835439682007, "timer/agent.policy_frac": 0.0577726018840484, "timer/agent.policy_avg": 0.016370638639325797, "timer/agent.policy_min": 0.009192705154418945, "timer/agent.policy_max": 0.1096653938293457, "timer/dataset_train_count": 1432.0, "timer/dataset_train_total": 0.16003155708312988, "timer/dataset_train_frac": 0.00015998793412184064, "timer/dataset_train_avg": 0.00011175388064464377, "timer/dataset_train_min": 9.441375732421875e-05, "timer/dataset_train_max": 0.0056383609771728516, "timer/agent.train_count": 1432.0, "timer/agent.train_total": 639.4992115497589, "timer/agent.train_frac": 0.6393248906229466, "timer/agent.train_avg": 0.446577661696759, "timer/agent.train_min": 0.4322068691253662, "timer/agent.train_max": 1.73260498046875, "timer/agent.report_count": 2.0, "timer/agent.report_total": 0.474841833114624, "timer/agent.report_frac": 0.00047471239610056236, "timer/agent.report_avg": 0.237420916557312, "timer/agent.report_min": 0.23143553733825684, "timer/agent.report_max": 0.2434062957763672, "timer/dataset_eval_count": 1.0, "timer/dataset_eval_total": 2.7418136596679688e-05, "timer/dataset_eval_frac": 2.7410662693824646e-08, "timer/dataset_eval_avg": 2.7418136596679688e-05, "timer/dataset_eval_min": 2.7418136596679688e-05, "timer/dataset_eval_max": 2.7418136596679688e-05, "fps": 22.90543854806961}
{"step": 1018696, "time": 46334.99759268761, "episode/length": 146.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9523809523809523, "episode/intrinsic_return": 0.0}
{"step": 1018720, "time": 46337.48930001259, "episode/length": 158.0, "episode/score": 10.100000023841858, "episode/reward_rate": 0.9937106918238994, "episode/intrinsic_return": 0.0}
{"step": 1018848, "time": 46343.3989443779, "episode/length": 161.0, "episode/score": 11.099999986588955, "episode/reward_rate": 0.9567901234567902, "episode/intrinsic_return": 0.0}
{"step": 1019120, "time": 46353.94182944298, "episode/length": 409.0, "episode/score": 10.099999986588955, "episode/reward_rate": 0.9926829268292683, "episode/intrinsic_return": 0.0}
{"step": 1019128, "time": 46355.510810136795, "episode/length": 53.0, "episode/score": 6.100000008940697, "episode/reward_rate": 0.9814814814814815, "episode/intrinsic_return": 0.0}
{"step": 1019176, "time": 46358.67393493652, "episode/length": 40.0, "episode/score": 4.0999999940395355, "episode/reward_rate": 0.975609756097561, "episode/intrinsic_return": 0.0}
{"step": 1019392, "time": 46367.72813177109, "episode/length": 334.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.982089552238806, "episode/intrinsic_return": 0.0}
{"step": 1019448, "time": 46370.905303001404, "episode/length": 33.0, "episode/score": 4.100000023841858, "episode/reward_rate": 0.9705882352941176, "episode/intrinsic_return": 0.0}
{"step": 1019728, "time": 46382.069261074066, "episode/length": 208.0, "episode/score": 10.099999994039536, "episode/reward_rate": 0.9952153110047847, "episode/intrinsic_return": 0.0}
{"step": 1019816, "time": 46386.36249041557, "episode/length": 214.0, "episode/score": 12.099999986588955, "episode/reward_rate": 0.9813953488372092, "episode/intrinsic_return": 0.0}
